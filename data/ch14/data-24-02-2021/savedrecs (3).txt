FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Zhan, LK
AF Zhan, Likan
TI Using Eye Movements Recorded in the Visual World Paradigm to Explore the
   Online Processing of Spoken Language
SO JOVE-JOURNAL OF VISUALIZED EXPERIMENTS
LA English
DT Article
DE Behavior; Issue 140; Eye tracking technique; visual world paradigm;
   spoken language; online processing; complex statement; generalized
   linear mixed model; binomial distribution; familywise error; Bonferroni
   adjustment
ID SCALAR IMPLICATURES; SPEECH-PERCEPTION; RECOGNITION; INFORMATION;
   EYETRACKING; TRACKING; MODELS
AB In a typical eye tracking study using the visual world paradigm, participants' eye movements to objects or pictures in the visual workspace are recorded via an eye tracker as the participant produces or comprehends a spoken language describing the concurrent visual world. This paradigm has high versatility, as it can be used in a wide range of populations, including those who cannot read and/or who cannot overtly give their behavioral responses, such as preliterate children, elderly adults, and patients. More importantly, the paradigm is extremely sensitive to fine grained manipulations of the speech signal, and it can be used to study the online processing of most topics in language comprehension at multiple levels, such as the fine grained acoustic phonetic features, the properties of words, and the linguistic structures. The protocol described in this article illustrates how a typical visual world eye tracking study is conducted, with an example showing how the online processing of some semantically complex statements can be explored with the visual world paradigm.
C1 [Zhan, Likan] Beijing Language & Culture Univ, Sch Commun Sci, Inst Speech Pathol & Brain Sci, Beijing, Peoples R China.
RP Zhan, LK (corresponding author), Beijing Language & Culture Univ, Sch Commun Sci, Inst Speech Pathol & Brain Sci, Beijing, Peoples R China.
EM zhanlikan@hotmail.com
RI Zhan, Likan/B-5684-2019
OI Zhan, Likan/0000-0002-9275-3557
FU Science Foundation of Beijing Language and Cultural University under the
   Fundamental Research Funds for the Central Universities [15YJ050003]
FX This research was supported by Science Foundation of Beijing Language
   and Cultural University under the Fundamental Research Funds for the
   Central Universities (Approval number 15YJ050003).
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen RH, 2018, QUANT METH HUMAN SOC, P49, DOI 10.1007/978-3-319-69830-4_4
   Barr DJ, 2014, J EXP PSYCHOL GEN, V143, P404, DOI 10.1037/a0031813
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002
   Bolker BM, 2009, TRENDS ECOL EVOL, V24, P127, DOI 10.1016/j.tree.2008.10.008
   Brown-Schmidt S, 2008, COGNITIVE SCI, V32, P643, DOI 10.1080/03640210802066816
   Chambers CG, 2004, J EXP PSYCHOL LEARN, V30, P687, DOI 10.1037/0278-7393.30.3.687
   Chierchia G, 2017, ANNU REV LINGUIST, V3, P245, DOI 10.1146/annurev-linguistics-011516-033846
   Conklin K., 2018, EYE TRACKING GUIDE A
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Dahan Delphine, 2007, P471, DOI 10.1016/B978-008044980-7/50023-9
   Dickey MW, 2007, BRAIN LANG, V100, P1, DOI 10.1016/j.bandl.2006.06.004
   Duchowski A., 2007, EYE TRACKING METHODO
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fox D, 2007, PALG STUD PRAGM LANG, P71
   Grice H. Paul, 1975, SYNTAX SEMANTICS, V3, P41, DOI [10.1057/9780230005853_5., DOI 10.1111/J.1365-2664.2006.01229.X]
   Griffin ZM, 2000, PSYCHOL SCI, V11, P274, DOI 10.1111/1467-9280.00255
   Helfer KS, 2014, EAR HEARING, V35, P161, DOI 10.1097/AUD.0b013e3182a830cf
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   McQueen JM, 2007, Q J EXP PSYCHOL, V60, P661, DOI 10.1080/17470210601183890
   Meyer AS, 1998, COGNITION, V66, pB25, DOI 10.1016/S0010-0277(98)00009-2
   Meyer M.A., 2013, THESIS
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   Moscati V, 2017, J CHILD LANG, V44, P1025, DOI 10.1017/S0305000916000313
   Nixon JS, 2016, J MEM LANG, V90, P103, DOI 10.1016/j.jml.2016.03.005
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Reinisch E, 2010, Q J EXP PSYCHOL, V63, P772, DOI 10.1080/17470210903104412
   Salverda A. P., 2017, RES METHODS PSYCHOLI
   Sauerland U, 2004, LINGUIST PHILOS, V27, P367, DOI 10.1023/B:LING.0000023378.71748.db
   Snedeker J, 2004, COGNITIVE PSYCHOL, V49, P238, DOI 10.1016/j.cogpsych.2004.03.001
   SR Research Ltd, 2017, SR RES EXP BUILD US
   SR Research Ltd, 2017, EYELINK 1000 PLUS US
   SR Research Ltd, 2017, EYELINK 1000 PLUS BR
   SR Research Ltd, 2017, EYELINK 1000 PLUS TE
   SR Research Ltd, 2017, EYELINK DAT VIEW US
   Tanenhaus M. K., 2005, APPROACHES STUDYING
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Trueswell JC, 1999, COGNITION, V73, P89, DOI 10.1016/S0010-0277(99)00032-3
   YOUNG LR, 1975, BEHAV RES METH INSTR, V7, P397, DOI 10.3758/BF03201553
   Zhan LK, 2018, LANG COGN NEUROSCI, V33, P1049, DOI 10.1080/23273798.2018.1448935
   Zhan LK, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00061
   Zhan LK, 2015, J COGN PSYCHOL, V27, P367, DOI 10.1080/20445911.2015.1016527
   Zhou P, 2014, COGNITION, V133, P262, DOI 10.1016/j.cognition.2014.06.018
   Zhou P, 2012, J MEM LANG, V67, P149, DOI 10.1016/j.jml.2012.03.005
   Zhou P, 2012, J CHILD LANG, V39, P687, DOI 10.1017/S0305000911000249
NR 51
TC 0
Z9 0
U1 2
U2 10
PU JOURNAL OF VISUALIZED EXPERIMENTS
PI CAMBRIDGE
PA 1 ALEWIFE CENTER, STE 200, CAMBRIDGE, MA 02140 USA
SN 1940-087X
J9 JOVE-J VIS EXP
JI J. Vis. Exp.
PD OCT
PY 2018
IS 140
AR e58086
DI 10.3791/58086
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HI4WM
UT WOS:000456452800008
PM 30371678
OA Green Published
DA 2021-02-24
ER

PT J
AU Brochier, T
   McKay, C
   McDermott, H
AF Brochier, Tim
   McKay, Colette
   McDermott, Hugh
TI Encoding speech in cochlear implants using simultaneous amplitude and
   rate modulation
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PULSATILE ELECTRICAL-STIMULATION; FREQUENCY-MODULATION; RECOGNITION;
   PERCEPTION; LOUDNESS; INTELLIGIBILITY; ADAPTATION; EMPHASIS; ENVELOPE;
   HEARING
AB To improve speech perception for cochlear implant (CI) users, it is essential to improve the transmission of temporal envelopes. The most common speech processors deliver temporal envelopes via the CI using fixed-rate amplitude modulated (AM) pulse trains. Psychophysical studies suggest that rate modulation (RM) and AM are perceived by a shared temporal integration mechanism, but the potential for them to constructively combine to encode temporal envelopes has yet to be explored. In this experiment, a speech processing strategy called amplitude and rate temporal modulation was developed to encode speech temporal envelopes with simultaneous AM and RM. The strategy was tested for perception of clean speech at 60 and 40 dBA, and 60 dBA speech in noise (+10 dB SNR). The amount of RM was varied and the amount of AM was held constant to determine whether the addition of RM could enhance the perception of temporal envelopes and improve speech understanding. At the lowest RM amount, speech scores were poorest for all speech conditions. For 60 dBA clean speech and speech in noise, speech scores were significantly better at the highest RM amounts, suggesting that RM combined with AM can be used to enhance perception of temporal envelopes. (C) 2018 Acoustical Society of America.
C1 [Brochier, Tim; McKay, Colette; McDermott, Hugh] Univ Melbourne, Dept Med Bion, 384-388 Albert St, East Melbourne, Vic 3002, Australia.
   [Brochier, Tim; McKay, Colette; McDermott, Hugh] Bion Inst, 384-388 Albert St, East Melbourne, Vic 3002, Australia.
RP Brochier, T (corresponding author), Univ Melbourne, Dept Med Bion, 384-388 Albert St, East Melbourne, Vic 3002, Australia.
EM TBrochier@bionicsinstitute.org
FU Melbourne International Research Scholarship; Melbourne International
   Fee Remission Scholarship; Veski Fellowship; Victorian Government
   through its Operational Infrastructure Support Program
FX We are grateful to our dedicated participants, who graciously
   volunteered time and energy in many test sessions. T.B. is sponsored by
   the Melbourne International Research Scholarship and the Melbourne
   International Fee Remission Scholarship. The research was supported by a
   Veski Fellowship to C.M. The Bionics Institute acknowledges support it
   receives from the Victorian Government through its Operational
   Infrastructure Support Program.
CR Arai T, 1998, INT CONF ACOUST SPEE, P933, DOI 10.1109/ICASSP.1998.675419
   Arnoldner C, 2007, ACTA OTO-LARYNGOL, V127, P1298, DOI 10.1080/00016480701275261
   Azadpour M, 2016, HEARING RES, V342, P48, DOI 10.1016/j.heares.2016.09.008
   Azadpour M, 2014, EAR HEARING, V35, pE192, DOI 10.1097/AUD.0000000000000048
   Brochier T, 2018, J ACOUST SOC AM, V143, P1214, DOI 10.1121/1.5025048
   Brochier T, 2017, J ACOUST SOC AM, V141, P4097, DOI 10.1121/1.4983658
   De Ruiter AM, 2015, EAR HEARING, V36, P557, DOI 10.1097/AUD.0000000000000162
   Fishman KE, 1997, J SPEECH LANG HEAR R, V40, P1201, DOI 10.1044/jslhr.4005.1201
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu QJ, 2000, J ACOUST SOC AM, V107, P589, DOI 10.1121/1.428325
   Fu QJ, 2002, NEUROREPORT, V13, P1635, DOI 10.1097/00001756-200209160-00013
   Fu QJ, 2001, J ACOUST SOC AM, V109, P1166, DOI 10.1121/1.1344158
   Garadat SN, 2013, AUDIOL NEURO-OTOL, V18, P247, DOI 10.1159/000351302
   Garadat SN, 2012, J ACOUST SOC AM, V131, P4030, DOI 10.1121/1.3701879
   Geurts L, 1999, J ACOUST SOC AM, V105, P2476, DOI 10.1121/1.426851
   Gnansia D, 2014, INT J AUDIOL, V53, P48, DOI 10.3109/14992027.2013.844367
   Holden LK, 2005, J SPEECH LANG HEAR R, V48, P681, DOI 10.1044/1092-4388(2005/047)
   Koning R, 2016, HEARING RES, V342, P13, DOI 10.1016/j.heares.2016.09.002
   Luo X, 2007, J ACOUST SOC AM, V122, P1046, DOI 10.1121/1.2751258
   Magnusson L, 2011, INT J AUDIOL, V50, P279, DOI 10.3109/14992027.2010.537378
   McKay CM, 2003, J ACOUST SOC AM, V113, P2054, DOI 10.1121/1.1558378
   McKay CM, 2001, J ACOUST SOC AM, V110, P1514, DOI 10.1121/1.1394222
   McKay CM, 1998, J ACOUST SOC AM, V104, P1061, DOI 10.1121/1.423316
   McKay CM, 2013, JARO-J ASSOC RES OTO, V14, P103, DOI 10.1007/s10162-012-0354-z
   Nie K, 2006, EAR HEARING, V27, P208, DOI 10.1097/01.aud.0000202312.31837.25
   Nie KB, 2005, IEEE T BIO-MED ENG, V52, P64, DOI 10.1109/TBME.2004.839799
   Oxenham AJ, 2001, J ACOUST SOC AM, V109, P732, DOI 10.1121/1.1336501
   OXENHAM AJ, 1994, HEARING RES, V80, P105, DOI 10.1016/0378-5955(94)90014-0
   Plack CJ, 2002, ACTA ACUST UNITED AC, V88, P348
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Shannon Robert V, 2002, Am J Audiol, V11, P124, DOI 10.1044/1059-0889(2002/013)
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Vandali AE, 2001, J ACOUST SOC AM, V109, P2049, DOI 10.1121/1.1358300
   Vandali AE, 2000, EAR HEARING, V21, P608, DOI 10.1097/00003446-200012000-00008
   Weatherby Alexandra, 2003, J Am Acad Audiol, V14, P582, DOI 10.3766/jaaa.14.10.7
   Won JH, 2011, J ACOUST SOC AM, V130, P376, DOI 10.1121/1.3592521
   Wouters J, 2015, IEEE SIGNAL PROC MAG, V32, P67, DOI 10.1109/MSP.2014.2371671
NR 37
TC 2
Z9 2
U1 0
U2 7
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2018
VL 144
IS 4
BP 2042
EP 2051
DI 10.1121/1.5055989
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HF2XX
UT WOS:000454101100021
PM 30404505
DA 2021-02-24
ER

PT J
AU Oster, MM
   Werner, LA
AF Oster, Monika-Maria
   Werner, Lynne A.
TI Infants use onset asynchrony cues in auditory scene analysis
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; NEWBORN-INFANTS; FREQUENCY; DISCRIMINATION; CHILDREN;
   SOUND; ADULTS; ENVIRONMENTS; RECOGNITION; SEGREGATION
AB This experiment investigated the effect of onset asynchrony on the segregation of concurrent vowels in infants and adults. Two vowels, randomly chosen from seven American-English vowels, were superimposed. Each vowel pair contained one vowel by a male and one by a female talker. A train of such vowel pairs was presented to listeners, who were trained to respond to the male target vowel /i:/or /u:/. The ability to identify the target vowel was compared among three conditions: synchronous onset, 100-, and 200-ms onset asynchrony. Experiment 1 measured performance, in d0, in 7-month-old infants and adults. Infants and adults performed better with asynchronous than synchronous vowel onset, regardless of asynchrony duration. Experiment 2 compared the proportion of 3-month-old infants achieving an 80% correct criterion with and without onset asynchrony. Significantly more infants reached criterion with asynchronous than with synchronous vowel onset. Asynchrony duration did not influence performance. These experiments show that infants, as young as 3 months old, benefit from onset asynchrony. (C) 2018 Acoustical Society of America.
C1 [Oster, Monika-Maria; Werner, Lynne A.] Univ Washington, Dept Speech & Hearing Sci, 1417 Northeast 42nd St, Seattle, WA 98105 USA.
RP Oster, MM (corresponding author), Univ Washington, Dept Speech & Hearing Sci, 1417 Northeast 42nd St, Seattle, WA 98105 USA.
EM mmoster@uw.edu
FU National Institute on Deafness and Other Communication Disorders
   (NIDCD)United States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F31 DC016209, R01 DC000396];
   Council of Academic Programs in Communication Sciences; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [F31DC016209] Funding Source: NIH RePORTER
FX The authors thank the families and individuals who participated in this
   research, as well as Jennifer Lentz and two anonymous reviewers for
   helpful comments on an earlier version of this manuscript. The research
   reported here was supported by funding from The National Institute on
   Deafness and Other Communication Disorders (NIDCD) under Grant Nos. F31
   DC016209 (M.-M.O.) and R01 DC000396 (L.A.W.), as well as by the Council
   of Academic Programs in Communication Sciences and Disorders Ph.D.
   Scholarship (M.-M.O.).
CR Alston E, 2005, INT J LANG COMM DIS, V40, P123, DOI 10.1080/13682820400006861
   ASSMANN PF, 1990, J ACOUST SOC AM, V88, P680, DOI 10.1121/1.399772
   BARGONES JY, 1994, PSYCHOL SCI, V5, P170, DOI 10.1111/j.1467-9280.1994.tb00655.x
   Bendixen A, 2015, DEV NEUROSCI-BASEL, V37, P172, DOI 10.1159/000370237
   Bernstein JGW, 2009, J ACOUST SOC AM, V125, P3358, DOI 10.1121/1.3110132
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   BROKX JPL, 1982, J PHONETICS, V10, P23, DOI 10.1016/S0095-4470(19)30909-X
   BULL D, 1984, J ACOUST SOC AM, V76, P13, DOI 10.1121/1.391110
   Buss E, 2012, SPRINGER HANDB AUDIT, V42, P107, DOI 10.1007/978-1-4614-1421-6_4
   Cabrera L, 2017, EAR HEARING, V38, P497, DOI 10.1097/AUD.0000000000000422
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   DEMANY L, 1982, INFANT BEHAV DEV, V5, P261, DOI 10.1016/S0163-6383(82)80036-2
   Eggermont JJ, 2012, SPRINGER HANDB AUDIT, V42, P61, DOI 10.1007/978-1-4614-1421-6_3
   Folland NA, 2015, J COGNITIVE NEUROSCI, V27, P1060, DOI 10.1162/jocn_a_00764
   Folland NA, 2012, J ACOUST SOC AM, V131, P993, DOI 10.1121/1.3651254
   Hall JW, 2008, J ACOUST SOC AM, V123, P2213, DOI 10.1121/1.2839006
   Hall JW, 2005, J ACOUST SOC AM, V118, P1605, DOI 10.1121/1.1992675
   Hedrick MS, 2009, J SPEECH LANG HEAR R, V52, P696, DOI 10.1044/1092-4388(2008/07-0094)
   Hill NI, 1996, J ACOUST SOC AM, V100, P2352, DOI 10.1121/1.417945
   KUHL PK, 1979, J ACOUST SOC AM, V66, P1668, DOI 10.1121/1.383639
   Leibold L. J., 2013, J ACOUST SOC AM, V133, P3338, DOI DOI 10.1121/1.4805624
   Leibold LJ, 2007, J ACOUST SOC AM, V121, P3666, DOI 10.1121/1.2723664
   Leibold LJ, 2006, J ACOUST SOC AM, V119, P3960, DOI 10.1121/1.2200150
   Leibold LJ, 2017, J SPEECH LANG HEAR R, V60, P3001, DOI 10.1044/2017_JSLHR-H-17-0070
   Lentz JJ, 2006, J SPEECH LANG HEAR R, V49, P1354, DOI 10.1044/1092-4388(2006/097)
   McAllister AM, 2009, J VOICE, V23, P587, DOI 10.1016/j.jvoice.2007.10.017
   Newman RS, 2017, J ACOUST SOC AM, V141, pEL164, DOI 10.1121/1.4976498
   Nittrouer S, 2004, J ACOUST SOC AM, V115, P1777, DOI 10.1121/1.1651192
   NOZZA RJ, 1990, J ACOUST SOC AM, V87, P339, DOI 10.1121/1.399301
   NOZZA RJ, 1988, J SPEECH HEAR RES, V31, P212, DOI 10.1044/jshr.3102.212
   NOZZA RJ, 1984, J SPEECH HEAR RES, V27, P613, DOI 10.1044/jshr.2704.613
   Occelli F, 2016, CEREB CORTEX, V26, P2483, DOI 10.1093/cercor/bhv071
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Ramirez-Esparza N, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01008
   Singh PG, 1997, J ACOUST SOC AM, V102, P1943, DOI 10.1121/1.419688
   SINNOTT JM, 1985, J ACOUST SOC AM, V78, P1986, DOI 10.1121/1.392655
   Sussman E, 2007, HEARING RES, V225, P117, DOI 10.1016/j.heares.2006.12.013
   Valentine S, 2012, J SPEECH LANG HEAR R, V55, P1750, DOI 10.1044/1092-4388(2012/11-0033)
   WERNER LA, 1995, BIOMETHODS, V6, P135
   Werner LA, 2009, J ACOUST SOC AM, V125, P1040, DOI 10.1121/1.3050254
   Winkler I, 2003, P NATL ACAD SCI USA, V100, P11812, DOI 10.1073/pnas.2031891100
NR 42
TC 1
Z9 1
U1 0
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2018
VL 144
IS 4
BP 2052
EP 2060
DI 10.1121/1.5058397
PG 9
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HF2XX
UT WOS:000454101100022
PM 30404496
OA Green Published
DA 2021-02-24
ER

PT J
AU Lucchetti, F
   Deltenre, P
   Avan, P
   Giraudet, F
   Fan, XY
   Nonclercq, A
AF Lucchetti, Federico
   Deltenre, Paul
   Avan, Paul
   Giraudet, Fabrice
   Fan, Xiaoya
   Nonclercq, Antoine
TI Generalization of the primary tone phase variation method: An exclusive
   way of isolating the frequency-following response components
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID HUMAN BRAIN-STEM; TEMPORAL FINE-STRUCTURE; NORMAL-HEARING;
   DISTORTION-PRODUCT; SPEECH-PERCEPTION; ENVELOPE; PITCH; REPRESENTATION;
   MODULATION
AB The primary tone phase variation (PTPV) technique combines selective sub-averaging with systematic variation of the phases of multitone stimuli. Each response component having a known phase relationship with the stimulus components phases can be isolated in the time domain. The method was generalized to the frequency-following response (FFR) evoked by a two-tone (f(1) and f(2)) stimulus comprising both linear and non-linear, as well as transient components. The generalized PTPV technique isolated each spectral component present in the FFR, including those sharing the same frequency, allowing comparison of their latencies. After isolation of the envelope component f(2)-f(1) from its harmonic distortion 2f(2)-2f(1) and from the transient auditory brainstem response, a computerized analysis of instantaneous amplitudes and phases was applied in order to objectively determine the onset and offset latencies of the response components. The successive activation of two generators separated by 3.7 ms could be detected in all (N = 12) awake adult normal subjects, but in none (N = 10) of the sleeping/sedated children with normal hearing thresholds. The method offers an unprecedented way of disentangling the various FFR subcomponents. These results open the way for renewed investigations of the FFR components in both human and animal research as well as for clinical applications. (C) 2018 Acoustical Society of America.
C1 [Lucchetti, Federico; Deltenre, Paul] Brugmann Univ Hosp, Lab Neurophysiol Sensorielle & Cognit CP403 22, Pl Van Gehuchten 4, B-1060 Brussels, Belgium.
   [Lucchetti, Federico; Fan, Xiaoya; Nonclercq, Antoine] Univ Libre Bruxelles, Bioelectro & Mech Syst CP165 56, Ave FD Roosevelt 50, B-1050 Brussels, Belgium.
   [Avan, Paul; Giraudet, Fabrice] Univ Clermont Auvergne, INSERM, UMR 1107, Lab Neurosensory Biophys, 28 Pl Henri Dunant,BP38, F-63001 Clermont Ferrand 1, France.
RP Lucchetti, F (corresponding author), Brugmann Univ Hosp, Lab Neurophysiol Sensorielle & Cognit CP403 22, Pl Van Gehuchten 4, B-1060 Brussels, Belgium.
EM federico.lucchetti@ulb.ac.be
RI GIRAUDET, Fabrice/Y-2287-2019
OI GIRAUDET, Fabrice/0000-0001-7816-7503; FAN, Xiaoya/0000-0002-5002-6968
FU Belgian Kids Fund for Pediatric Research; Belgian Fonds National de la
   Recherche ScientifiqueFonds de la Recherche Scientifique - FNRS
   [J.0092.13]; Brugmann Foundation
FX This research was financially supported by the Belgian Kids Fund for
   Pediatric Research (F.L.), the Belgian Fonds National de la Recherche
   Scientifique (Grant No. J.0092.13; P.D.), and the Brugmann Foundation
   (P.D.).
CR Aiken S J., 2013, P M AC, V19, DOI [10.1121/1.4800244, DOI 10.1121/1.4800244]
   Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004
   Ananthakrishnan S, 2016, EAR HEARING, V37, pe91, DOI 10.1097/AUD.0000000000000247
   AOYAGI M, 1993, HEARING RES, V65, P253, DOI 10.1016/0378-5955(93)90218-P
   Bidelman GM, 2015, HEARING RES, V323, P68, DOI 10.1016/j.heares.2015.01.011
   BILLINGS SA, 1994, MECH SYST SIGNAL PR, V8, P45, DOI 10.1006/mssp.1994.1004
   Elsisy H, 2008, INT J AUDIOL, V47, P431, DOI 10.1080/14992020801987396
   Henry KS, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00020
   Hurtado JM, 2004, J NEUROPHYSIOL, V91, P1883, DOI 10.1152/jn.00853.2003
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   Kale S, 2010, JARO-J ASSOC RES OTO, V11, P657, DOI 10.1007/s10162-010-0223-6
   King A, 2016, JARO-J ASSOC RES OTO, V17, P133, DOI 10.1007/s10162-016-0556-x
   Kraus N, 2005, TRENDS NEUROSCI, V28, P176, DOI 10.1016/j.tins.2005.02.003
   Kraus N., 2017, FREQUENCY FOLLOWING
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Krizman J, 2015, CLIN NEUROPHYSIOL, V126, P2348, DOI 10.1016/j.clinph.2015.01.026
   Le Van Quyen M, 2001, J NEUROSCI METH, V111, P83, DOI 10.1016/S0165-0270(01)00372-7
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Oxenham AJ, 2004, P NATL ACAD SCI USA, V101, P1421, DOI 10.1073/pnas.0306958101
   Pandya Pritesh K, 2004, J Am Acad Audiol, V15, P184, DOI 10.3766/jaaa.15.3.2
   SCHIMMEL H, 1967, SCIENCE, V157, P92, DOI 10.1126/science.157.3784.92
   Schreier P. J., 2010, STAT SIGNAL PROCESSI
   Shaheen LA, 2015, JARO-J ASSOC RES OTO, V16, P727, DOI 10.1007/s10162-015-0539-3
   Shera CA, 2012, J ACOUST SOC AM, V132, P927, DOI 10.1121/1.4730916
   Shinn-Cunningham B, 2017, SPRINGER HANDB AUDIT, V61, P159, DOI 10.1007/978-3-319-47944-6_7
   Smith SB, 2017, HEARING RES, V356, P25, DOI 10.1016/j.heares.2017.10.009
   Verpy E, 2008, NATURE, V456, P255, DOI 10.1038/nature07380
   Whitehead ML, 1996, J ACOUST SOC AM, V100, P1663, DOI 10.1121/1.416065
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   WORDEN FG, 1968, ELECTROEN CLIN NEURO, V25, P42, DOI 10.1016/0013-4694(68)90085-0
   Xu Q, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P383, DOI 10.1109/BMEI.2014.7002804
   Zhong ZW, 2014, HEARING RES, V309, P55, DOI 10.1016/j.heares.2013.11.006
NR 33
TC 0
Z9 0
U1 1
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2018
VL 144
IS 4
BP 2400
EP 2412
DI 10.1121/1.5063821
PG 13
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HF2XX
UT WOS:000454101100054
PM 30404467
OA Green Published
DA 2021-02-24
ER

PT J
AU Redford, MA
   Kallay, JE
   Bogdanov, SV
   Vatikiotis-Bateson, E
AF Redford, Melissa A.
   Kallay, Jeffrey E.
   Bogdanov, Sergei V.
   Vatikiotis-Bateson, Eric
TI Leveraging audiovisual speech perception to measure anticipatory
   coarticulation
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID HORIZONTAL VIEWING ANGLE; TO-VOWEL COARTICULATION; MOTOR CONTROL; LIP;
   MOVEMENT; CHILDREN; ENGLISH; EXTENT
AB A noninvasive method for accurately measuring anticipatory coarticulation at experimentally defined temporal locations is introduced. The method leverages work in audiovisual (AV) speech perception to provide a synthetic and robust measure that can be used to inform psycholinguistic theory. In this validation study, speakers were audio-video recorded while producing simple subject-verb-object sentences with contrasting object noun rhymes. Coarticulatory resistance of target noun onsets was manipulated as was metrical context for the determiner that modified the noun. Individual sentences were then gated from the verb to sentence end at segmental landmarks. These stimuli were presented to perceivers who were tasked with guessing the sentence-final rhyme. An audio-only condition was included to estimate the contribution of visual information to perceivers' performance. Findings were that perceivers accurately identified rhymes earlier in the AV condition than in the audio-only condition (i.e., at determiner onset vs determiner vowel). Effects of coarticulatory resistance and metrical context were similar across conditions and consistent with previous work on coarticulation. These findings were further validated with acoustic measurement of the determiner vowel and a cumulative video-based measure of perioral movement. Overall, gated AV speech perception can be used to test specific hypotheses regarding coarticulatory scope and strength in running speech. (C) 2018 Acoustical Society of America.
C1 [Redford, Melissa A.; Kallay, Jeffrey E.; Bogdanov, Sergei V.] Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
   [Vatikiotis-Bateson, Eric] Univ British Columbia, Dept Linguist, Vancouver, BC, Canada.
RP Redford, MA (corresponding author), Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
EM redford@uoregon.edu
OI Redford, Melissa/0000-0002-0692-2810
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   Development (NICHD)United States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD087452]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH
   & HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD087452, R01HD087452, R01HD087452, R01HD087452] Funding Source: NIH
   RePORTER
FX E.V.-B. (1952-2017) contributed substantially to this study, but passed
   away before the manuscript was written. Any problems with the analyses
   or interpretation of results presented herein should be attributed to
   the other authors. The work reported herein was supported by the Eunice
   Kennedy Shriver National Institute of Child Health and Human Development
   (NICHD) under Grant No. R01HD087452 (PI: Redford). The content is solely
   the authors' responsibility and does not necessarily reflect the views
   of NICHD.
CR Barbosa AV, 2008, AUDITORY VISUAL SPEE, P173
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BELLBERTI F, 1979, J ACOUST SOC AM, V65, P1268, DOI 10.1121/1.382794
   Bladon R. A. W, 1976, J PHONETICS, V4, P137
   Boersma P., 2018, PRAAT DOING PHONETIC
   Cathiard M. A., 1996, SPEECHREADING HUMANS, P211
   DANILOFF R, 1968, J SPEECH HEAR RES, V11, P707, DOI 10.1044/jshr.1104.707
   Fuchs S, 2013, J PHONETICS, V41, P29, DOI 10.1016/j.wocn.2012.08.007
   Goffman L, 1999, J EXP PSYCHOL HUMAN, V25, P649, DOI 10.1037/0096-1523.25.3.649
   Green JR, 2000, J SPEECH LANG HEAR R, V43, P239, DOI 10.1044/jslhr.4301.239
   Grosvald M, 2009, J PHONETICS, V37, P173, DOI 10.1016/j.wocn.2009.01.002
   HADAR U, 1983, HUM MOVEMENT SCI, V2, P35, DOI 10.1016/0167-9457(83)90004-0
   HAYES B, 1982, LINGUIST INQ, V13, P227
   Huber JE, 2008, RESP PHYSIOL NEUROBI, V164, P323, DOI 10.1016/j.resp.2008.08.007
   Jordan M. I., 1997, ADV PSYCHOL, V121, P471, DOI [DOI 10.1016/S0166-4115(97)80111-2, 10.1016/s0166-4115(97)80111-2]
   Jordan T, 1997, IEEE SYS MAN CYBERN, P1626, DOI 10.1109/ICSMC.1997.638235
   Jordan TR, 1997, J EXP PSYCHOL HUMAN, V23, P388, DOI 10.1037/0096-1523.23.2.388
   Jordan TR, 2001, J EXP PSYCHOL HUMAN, V27, P1386, DOI 10.1037//0096-1523.27.6.1386
   KATZ WF, 1991, J SPEECH HEAR RES, V34, P1222, DOI 10.1044/jshr.3406.1222
   KEATING PA, 1994, J PHONETICS, V22, P407, DOI 10.1016/S0095-4470(19)30293-1
   KELSO JAS, 1984, J EXP PSYCHOL HUMAN, V10, P812, DOI 10.1037/0096-1523.10.6.812
   Kozhevnikov A., 1965, RECH ARTIKULYATSIA V, P543
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Magen HS, 1997, J PHONETICS, V25, P187, DOI 10.1006/jpho.1996.0041
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Moradi S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00359
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Munhall KG, 1998, J ACOUST SOC AM, V104, P530, DOI 10.1121/1.423300
   Noiray A., 2008, EMERGENCE LINGUISTIC, P100
   Noiray A, 2013, J ACOUST SOC AM, V133, P444, DOI 10.1121/1.4763983
   Nolan F, 1977, J PHONETICS, V5, P185
   OHMAN SEG, 1966, J ACOUST SOC AM, V39, P151, DOI 10.1121/1.1909864
   Perkell J. S., 1986, INVARIANCE VARIABILI
   R Core Team, 2014, R LANG ENV STAT COMP
   RECASENS D, 1984, J ACOUST SOC AM, V76, P1624, DOI 10.1121/1.391609
   Recasens D, 1997, J ACOUST SOC AM, V102, P544, DOI 10.1121/1.419727
   Roelofs A, 1998, J EXP PSYCHOL LEARN, V24, P922, DOI 10.1037/0278-7393.24.4.922
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   SAVARIAUX C, 1995, J ACOUST SOC AM, V98, P2428, DOI 10.1121/1.413277
   Sergeant P. C, 1998, HEARING EYE 2, P155
   Smeele P. M. T., 1994, THESIS
   Stone M., 2010, HDB PHONETIC SCI
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Thomas SM, 2004, J EXP PSYCHOL HUMAN, V30, P873, DOI 10.1037/0096-1523.30.5.873
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Vatikiotis-Bateson E, 1998, HEARING EYE 2, P123
   WHALEN DH, 1990, J PHONETICS, V18, P3, DOI 10.1016/S0095-4470(19)30356-0
   WINKWORTH AL, 1995, J SPEECH HEAR RES, V38, P124, DOI 10.1044/jshr.3801.124
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
   Zharkova N, 2011, MOTOR CONTROL, V15, P118, DOI 10.1123/mcj.15.1.118
NR 51
TC 2
Z9 2
U1 4
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2018
VL 144
IS 4
BP 2447
EP 2461
DI 10.1121/1.5064783
PG 15
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HF2XX
UT WOS:000454101100058
PM 30404498
OA Green Published
DA 2021-02-24
ER

PT J
AU Curtin, A
   Ayaz, H
AF Curtin, Adrian
   Ayaz, Hasan
TI The Age of Neuroergonomics: Towards Ubiquitous and Continuous
   Measurement of Brain Function with fNIRS
SO JAPANESE PSYCHOLOGICAL RESEARCH
LA English
DT Article
DE functional near-infrared spectroscopy (fNIRS); neuroadaptive systems;
   human-machine interaction; mobile brain/body imaging (MoBI);
   brain-computer interface (BCI)
ID NEAR-INFRARED SPECTROSCOPY; WORKING-MEMORY; SPATIAL REGISTRATION; MENTAL
   WORKLOAD; PREFRONTAL CORTEX; EXPLORATION; PERFORMANCE; ACTIVATION;
   INTERFACES; CAPACITY
AB Neuroergonomics is an emerging field that investigates the human brain in relation to behavioral performance in natural environments and everyday settings. Functional near-infrared spectroscopy (fNIRS), a noninvasive brain-monitoring technology that relies on optical techniques to detect changes of cortical hemodynamic responses to human perceptual, cognitive, and motor functioning, is an ideal candidate tool. Ultraportable wearable and wireless fNIRS sensors are already breaking the limitations of traditional neuroimaging approaches that have imposed limitations on experimental protocols, data-collection settings, and task conditions at the expense of ecological validity. This review summarizes emerging trends for fNIRS applications, from aerospace to medicine, with diverse populations and towards clinical solutions. We will review recent studies, such as mental workload assessment of specialized operators performing standardized and complex cognitive tasks and development of expertise during practice of complex cognitive and visuomotor tasks (ranging from aircraft piloting and robot control). Various recent synergistic fNIRS applications for human-human and human-machine interaction, including synthetic speech perception, interpersonal neural synchronization, and brain computer interfaces, highlight the potential use and are ushering the dawn of a new age in applied neuroscience and neuroengineering.
C1 [Curtin, Adrian; Ayaz, Hasan] Drexel Univ, Philadelphia, PA 19104 USA.
RP Ayaz, H (corresponding author), Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, 3508 Market St,Monell Suite 101, Philadelphia, PA 19104 USA.
EM hasan.ayaz@drexel.edu
RI Curtin, Adrian/AAF-7193-2020
OI Curtin, Adrian/0000-0002-7108-7057
CR Ayaz Hasan, 2012, Advances in Brain Inspired Cognitive Systems. Proceedings 5th International Conference, BICS 2012, P147, DOI 10.1007/978-3-642-31561-9_16
   AYAZ H, 2013, FRONT HUM NEUROSCI, V7, DOI DOI 10.3389/FNHUM.2013.00871
   Ayaz H, 2007, 2007 3RD INTERNATIONAL IEEE/EMBS CONFERENCE ON NEURAL ENGINEERING, VOLS 1 AND 2, P342, DOI 10.1109/CNE.2007.369680
   Ayaz H, 2011, JOVE-J VIS EXP, DOI 10.3791/3443
   Ayaz H, 2012, NEUROIMAGE, V59, P36, DOI 10.1016/j.neuroimage.2011.06.023
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Balconi M, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00163
   Burgess PW, 2007, TRENDS COGN SCI, V11, P290, DOI 10.1016/j.tics.2007.05.004
   Byrne EA, 1996, BIOL PSYCHOL, V42, P249, DOI 10.1016/0301-0511(95)05161-9
   Cakir MP, 2016, Z PSYCHOL, V224, P297, DOI 10.1027/2151-2604/a000267
   Callicott JH, 1999, CEREB CORTEX, V9, P20, DOI 10.1093/cercor/9.1.20
   Cauli Bruno, 2010, Front Neuroenergetics, V2, P9, DOI 10.3389/fnene.2010.00009
   CHANCE B, 1993, P NATL ACAD SCI USA, V90, P3770, DOI 10.1073/pnas.90.8.3770
   Clark VP, 2014, NEUROIMAGE, V85, P889, DOI 10.1016/j.neuroimage.2013.08.071
   Collins D. L., 2000, J COMPUTER ASSISTED, V18, P192, DOI [10. 1093/cercor/10. 4. 433, DOI 10.1093/CERCOR/10.4.433]
   Cui X, 2012, NEUROIMAGE, V59, P2430, DOI 10.1016/j.neuroimage.2011.09.003
   Cui X, 2011, NEUROIMAGE, V54, P2808, DOI 10.1016/j.neuroimage.2010.10.069
   Curtin A, 2017, LECT NOTES ARTIF INT, V10275, P106, DOI 10.1007/978-3-319-58472-0_9
   Cutini S, 2011, NEUROIMAGE, V54, P919, DOI 10.1016/j.neuroimage.2010.09.030
   Daly JJ, 2008, LANCET NEUROL, V7, P1032, DOI 10.1016/S1474-4422(08)70223-0
   DELPY DT, 1988, PHYS MED BIOL, V33, P1433, DOI 10.1088/0031-9155/33/12/008
   EVANS AC, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1813, DOI 10.1109/NSSMIC.1993.373602
   Fishburn FA, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00076
   Garavan H, 2000, MICROSC RES TECHNIQ, V51, P54, DOI 10.1002/1097-0029(20001001)51:1<54::AID-JEMT6>3.3.CO;2-A
   Gateau T, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00187
   Gibson BS, 2013, MEM COGNITION, V41, P726, DOI 10.3758/s13421-013-0295-8
   Harrison J, 2014, IEEE T HUM-MACH SYST, V44, P429, DOI 10.1109/THMS.2014.2319822
   Herff C, 2014, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00935
   Holper L, 2012, NEUROIMAGE, V63, P212, DOI 10.1016/j.neuroimage.2012.06.028
   Hoshi Y, 2003, NEUROIMAGE, V20, P1493, DOI 10.1016/S1053-8119(03)00412-9
   Hunter MA, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00495
   Izzetoglu K, 2004, INT J HUM-COMPUT INT, V17, P211, DOI 10.1207/s15327590ijhc1702_6
   JOBSIS FF, 1977, SCIENCE, V198, P1264, DOI 10.1126/science.929199
   Kuruvilla MS, 2013, COGN NEUROSCI-UK, V4, P115, DOI 10.1080/17588928.2013.797889
   KYLLONEN PC, 1990, INTELLIGENCE, V14, P389, DOI 10.1016/S0160-2896(05)80012-1
   Liu N, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00082
   Liu YC, 2017, BRAIN-COMPUT INTERFA, V4, P175, DOI 10.1080/2326263X.2017.1304020
   Liu Y, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00389
   Liu YC, 2017, SCI REP-UK, V7, DOI 10.1038/srep43293
   LIU YL, 1994, ERGONOMICS, V37, P1843, DOI 10.1080/00140139408964953
   McCabe DP, 2010, NEUROPSYCHOLOGY, V24, P222, DOI 10.1037/a0017619
   McKendrick R, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00027
   McKendrick R, 2014, NEUROIMAGE, V85, P1014, DOI 10.1016/j.neuroimage.2013.05.103
   Merzagora A., 2010, THESIS
   Merzagora AC, 2010, NEUROIMAGE, V49, P2304, DOI 10.1016/j.neuroimage.2009.10.044
   Milton J, 2007, NEUROIMAGE, V35, P804, DOI 10.1016/j.neuroimage.2007.01.003
   Naseer Noman, 2015, Front Hum Neurosci, V9, P3, DOI 10.3389/fnhum.2015.00003
   Neubauer AC, 2009, NEUROSCI BIOBEHAV R, V33, P1004, DOI 10.1016/j.neubiorev.2009.04.001
   Nozawa T, 2016, NEUROIMAGE, V133, P484, DOI 10.1016/j.neuroimage.2016.03.059
   Okamoto M, 2004, NEUROIMAGE, V21, P99, DOI 10.1016/j.neuroimage.2003.08.026
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Paas F, 2003, EDUC PSYCHOL, V38, P1, DOI 10.1207/S15326985EP3801_1
   Parasuraman R., 2006, NEUROERGONOMICS BRAI, DOI [10. 1093/acprof:oso/9780195177619. 001. 0001, DOI 10.1093/ACPR0F:OSO/9780195177619.001.0001]
   Peck E. M. M., 2013, P SIGCHI C HUM FACT, P473, DOI [DOI 10.1145/2470654.2470723, 10.1145/2470654.2470723]
   Putze F, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00373
   Sibi S, 2016, IEEE INT VEH SYM, P419, DOI 10.1109/IVS.2016.7535420
   Singh AK, 2005, NEUROIMAGE, V27, P842, DOI 10.1016/j.neuroimage.2005.05.019
   Smith EE, 1996, CEREB CORTEX, V6, P11, DOI 10.1093/cercor/6.1.11
   Solovey E., 2012, P SIGCHI C HUM FACT, P2193, DOI DOI 10.1145/2207676.2208372
   Solovey ET, 2015, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2687926
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107
   Stojanovic-Radic J, 2015, BRAIN IMAGING BEHAV, V9, P302, DOI 10.1007/s11682-014-9307-y
   Nguyen T, 2017, SCI REP-UK, V7, DOI 10.1038/srep43933
   Tsunashima Hitoshi, 2009, Comput Intell Neurosci, P164958, DOI 10.1155/2009/164958
   Tsuzuki D, 2007, NEUROIMAGE, V34, P1506, DOI 10.1016/j.neuroimage.2006.10.043
   Tsuzuki D, 2014, NEUROIMAGE, V85, P92, DOI 10.1016/j.neuroimage.2013.07.025
   Tsuzuki D, 2012, NEUROSCI RES, V72, P163, DOI 10.1016/j.neures.2011.10.008
   Wiggins IM, 2016, HEARING RES, V339, P142, DOI 10.1016/j.heares.2016.07.007
   Yoshino K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00895
   Zander TO, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/1/016003
NR 70
TC 22
Z9 22
U1 3
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0021-5368
EI 1468-5884
J9 JPN PSYCHOL RES
JI Jpn. Psychol. Res.
PD OCT
PY 2018
VL 60
IS 4
SI SI
BP 374
EP 386
DI 10.1111/jpr.12227
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA GV7CP
UT WOS:000446279900014
OA Bronze
DA 2021-02-24
ER

PT J
AU Mattingly, MM
   Donell, BM
   Rosen, MJ
AF Mattingly, Michelle M.
   Donell, Brittany M.
   Rosen, Merri J.
TI Late maturation of backward masking in auditory cortex
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE auditory; cortex; detection; development; masking
ID BASILAR-MEMBRANE NONLINEARITY; INFERIOR COLLICULUS NEURONS;
   FREQUENCY-MODULATED SWEEPS; DURATION-TUNED NEURONS; TEMPORAL
   INTEGRATION; CORTICAL-LESIONS; COCHLEAR NUCLEUS; SINGLE NEURONS; NEURAL
   CODES; RESPONSES
AB Speech perception relies on the accurate resolution of brief, successive sounds that change rapidly over time. Deficits in the perception of such sounds, indicated by a reduced ability to detect signals during auditory backward masking, strongly relate to language processing difficulties in children. Backward masking during normal development has a longer maturational trajectory than many other auditory percepts, implicating the involvement of central auditory neural mechanisms with protracted developmental time courses. Despite the importance of this percept, its neural correlates are not well described at any developmental stage. We therefore measured auditory cortical responses to masked signals in juvenile and adult Mongolian gerbils and quantified the detection ability of individual neurons and neural populations in a manner comparable with psychoa-coustic measurements. Perceptually, auditory backward masking manifests as higher thresholds for detection of a short signal followed by a masker than for the same signal in silence. Cortical masking was driven by a combination of suppressed responses to the signal and a reduced dynamic range available for signal detection in the presence of the masker. Both coding elements contributed to greater masked threshold shifts in juveniles compared with adults, but signal-evoked firing suppression was more pronounced in juveniles. Neural threshold shifts were a better match to human psychophysical threshold shifts when quantified with a longer temporal window that included the response to the delayed masker, suggesting that temporally selective listening may contribute to age-related differences in backward masking.
   NEW & NOTEWORTHY In children, auditory detection of backward masked signals is immature well into adolescence. and detection deficits correlate with problems in speech processing. Our auditory cortical recordings reveal immature backward masking in adolescent animals that mirrors the prolonged development seen in children. This is driven by both signal-evoked suppression and dynamic range reduction. An extended window of analysis suggests that differences in temporally focused listening may contribute to late maturing thresholds for backward masked signals.
C1 [Mattingly, Michelle M.; Donell, Brittany M.; Rosen, Merri J.] Northeast Ohio Med Univ, Dept Anat & Neurobiol, 4209 State Route 44,POB 95, Rootstown, OH 44272 USA.
RP Rosen, MJ (corresponding author), Northeast Ohio Med Univ, Dept Anat & Neurobiol, 4209 State Route 44,POB 95, Rootstown, OH 44272 USA.
EM mrosen@neomed.edu
FU National Institute of Deafness and Other Communications DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC013314]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC013314, R01DC013314, R01DC013314, R01DC013314, R01DC013314,
   R01DC013314] Funding Source: NIH RePORTER
FX This work was supported by National Institute of Deafness and Other
   Communications Disorders Grant R01 DC013314 (to M. J. Rosen).
CR Alves-Pinto A, 2010, JARO-J ASSOC RES OTO, V11, P477, DOI 10.1007/s10162-010-0215-6
   Backoff PM, 1997, HEARING RES, V110, P155, DOI 10.1016/S0378-5955(97)00081-6
   Benasich AA, 2006, NEUROPSYCHOLOGIA, V44, P396, DOI 10.1016/j.neuropsychologia.2005.06.004
   Benasich AA, 2002, BEHAV BRAIN RES, V136, P31, DOI 10.1016/S0166-4328(02)00098-0
   Brosch M, 1998, NEUROREPORT, V9, P2551, DOI 10.1097/00001756-199808030-00023
   Brosch M, 1997, J NEUROPHYSIOL, V77, P923
   Budinger E, 2006, NEUROSCIENCE, V143, P1065, DOI 10.1016/j.neuroscience.2006.08.035
   Budinger E, 2000, EUR J NEUROSCI, V12, P2425, DOI 10.1046/j.1460-9568.2000.00142.x
   Buss E, 1999, J SPEECH LANG HEAR R, V42, P844, DOI 10.1044/jslhr.4204.844
   Cai DQ, 2018, CEREB CORTEX, V28, P1610, DOI 10.1093/cercor/bhx057
   CALFORD MB, 1995, J NEUROPHYSIOL, V73, P1876
   Capsius B, 1996, HEARING RES, V96, P59, DOI 10.1016/0378-5955(96)00038-X
   CARNEY LH, 1989, J NEUROPHYSIOL, V62, P144
   Chang EF, 2005, P NATL ACAD SCI USA, V102, P16460, DOI 10.1073/pnas.0508239102
   Connour JR, 2000, J ZOOL, V251, P79, DOI 10.1111/j.1469-7998.2000.tb00595.x
   CONOVER WJ, 1982, BIOMETRICS, V38, P715, DOI 10.2307/2530051
   Covey E, 1996, J NEUROSCI, V16, P3009
   Curto C, 2009, J NEUROSCI, V29, P10600, DOI 10.1523/JNEUROSCI.2053-09.2009
   DUIFHUIS H, 1973, J ACOUST SOC AM, V54, P1471, DOI 10.1121/1.1914446
   ELLIOTT DN, 1972, PSYCHOL BULL, V77, P198, DOI 10.1037/h0032281
   ELLIOTT LL, 1962, J ACOUST SOC AM, V34, P1108, DOI 10.1121/1.1918253
   Esser KH, 1997, P NATL ACAD SCI USA, V94, P14019, DOI 10.1073/pnas.94.25.14019
   Faure PA, 2003, J NEUROSCI, V23, P3052
   Fox AM, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-49
   Gao WJ, 1999, J COMP NEUROL, V409, P261, DOI 10.1002/(SICI)1096-9861(19990628)409:2<261::AID-CNE7>3.0.CO;2-R
   Gay JD, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00162
   Geissler DB, 2004, EUR J NEUROSCI, V19, P1027, DOI 10.1111/j.1460-9568.2004.03205.x
   Green DB, 2017, J NEUROSCI, V37, P7759, DOI 10.1523/JNEUROSCI.0916-17.2017
   Hall JW, 2007, J ACOUST SOC AM, V121, P401, DOI 10.1121/1.2400673
   Hara K, 2002, ANESTH ANALG, V94, P313, DOI 10.1097/00000539-200202000-00015
   Hartley DEH, 2000, J SPEECH LANG HEAR R, V43, P1402, DOI 10.1044/jslhr.4306.1402
   He SM, 2010, J ACOUST SOC AM, V127, P3643, DOI 10.1121/1.3397464
   Heil P, 1997, J NEUROPHYSIOL, V77, P2616
   Huyck JJ, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12574
   Ingham NJ, 2016, BRAIN RES, V1639, P13, DOI 10.1016/j.brainres.2016.02.043
   Jen PHS, 2002, HEARING RES, V174, P281, DOI 10.1016/S0378-5955(02)00702-5
   Kaas JH, 2000, P NATL ACAD SCI USA, V97, P11793, DOI 10.1073/pnas.97.22.11793
   Kelly JB, 1996, BEHAV NEUROSCI, V110, P542, DOI 10.1037/0735-7044.110.3.542
   KILLIAN MJP, 1994, HEARING RES, V81, P66, DOI 10.1016/0378-5955(94)90154-6
   Luna R, 2005, NAT NEUROSCI, V8, P1210, DOI 10.1038/nn1513
   Ma L, 2015, NEUROSCIENCE, V290, P608, DOI 10.1016/j.neuroscience.2015.01.074
   Mooney R, 2002, J COMP PHYSIOL A, V188, P879, DOI 10.1007/s00359-002-0353-3
   Muluk NB, 2011, AURIS NASUS LARYNX, V38, P6, DOI 10.1016/j.anl.2010.05.007
   Nelson PC, 2009, J NEUROSCI, V29, P2553, DOI 10.1523/JNEUROSCI.5359-08.2009
   Nienborg H, 2012, ANNU REV NEUROSCI, V35, P463, DOI 10.1146/annurev-neuro-062111-150403
   Ohl FW, 1999, LEARN MEMORY, V6, P347
   Oxenham AJ, 1997, J ACOUST SOC AM, V101, P3666, DOI 10.1121/1.418327
   OXENHAM AJ, 1995, J ACOUST SOC AM, V98, P1921, DOI 10.1121/1.413376
   Panzeri S, 2010, TRENDS NEUROSCI, V33, P111, DOI 10.1016/j.tins.2009.12.001
   Paolini AG, 1999, J NEUROPHYSIOL, V81, P2347
   Parker AJ, 1998, ANNU REV NEUROSCI, V21, P227, DOI 10.1146/annurev.neuro.21.1.227
   PICKETT JM, 1959, J ACOUST SOC AM, V31, P1613, DOI 10.1121/1.1907668
   Plack CJ, 1998, J ACOUST SOC AM, V103, P1598, DOI 10.1121/1.421294
   Purushothaman G, 2005, NAT NEUROSCI, V8, P99, DOI 10.1038/nn1373
   Razak KA, 2007, J NEUROSCI, V27, P1769, DOI 10.1523/JNEUROSCI.3851-06.2007
   Razak KA, 2009, J NEUROPHYSIOL, V102, P1366, DOI 10.1152/jn.00334.2009
   RELKIN EM, 1988, J ACOUST SOC AM, V84, P584, DOI 10.1121/1.396836
   Romanski LM, 2005, J NEUROPHYSIOL, V93, P734, DOI 10.1152/jn.00675.2004
   Rosen MJ, 2010, J NEUROSCI, V30, P15509, DOI 10.1523/JNEUROSCI.3340-10.2010
   Sayegh R, 2014, J NEUROSCI, V34, P481, DOI 10.1523/JNEUROSCI.3732-13.2014
   Shadlen MN, 1996, J NEUROSCI, V16, P1486
   Sokal RR, 1995, BIOMETRY
   Sun YJ, 2010, NATURE, V465, P927, DOI 10.1038/nature09079
   Takesian AE, 2012, J NEUROPHYSIOL, V107, P937, DOI 10.1152/jn.00515.2011
   Trehub SE, 1996, J SPEECH HEAR RES, V39, P1315, DOI 10.1044/jshr.3906.1315
   VOLKOV IO, 1992, EXP BRAIN RES, V91, P115
   Voytenko SV, 2007, J NEUROPHYSIOL, V97, P1368, DOI 10.1152/jn.00976.2006
   Wang L, 2007, J NEUROSCI, V27, P582, DOI 10.1523/JNEUROSCI.3699-06.2007
   WATANABE T, 1971, JPN J PHYSIOL, V21, P537
   Wehr M, 2005, NEURON, V47, P437, DOI 10.1016/j.neuron.2005.06.009
   Wiegand K, 2012, NEUROIMAGE, V61, P62, DOI 10.1016/j.neuroimage.2012.02.067
   Wright BA, 2004, P NATL ACAD SCI USA, V101, P9942, DOI 10.1073/pnas.0401825101
   Wright BA, 1997, NATURE, V387, P176, DOI 10.1038/387176a0
   Zhang LI, 2003, NATURE, V424, P201, DOI 10.1038/nature01796
   Zwicker E, 2013, PSYCHOACOUSTICS FACT
NR 75
TC 0
Z9 0
U1 0
U2 2
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD OCT
PY 2018
VL 120
IS 4
BP 1558
EP 1571
DI 10.1152/jn.00114.2018
PG 14
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA HB8OO
UT WOS:000451350100010
PM 29995598
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Shayman, CS
   Seo, JH
   Oh, Y
   Lewis, RF
   Peterka, RJ
   Hullar, TE
AF Shayman, Corey S.
   Seo, Jae-Hyun
   Oh, Yonghee
   Lewis, Richard F.
   Peterka, Robert J.
   Hullar, Timothy E.
TI Relationship between vestibular sensitivity and multisensory temporal
   integration
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE motion perception; perceptual threshold; temporal binding; temporal
   integration; vestibular hypofunction
ID AUDIOVISUAL ASYNCHRONY DETECTION; SPEECH-PERCEPTION; REACTION-TIME;
   BINDING; LATENCY; WINDOW
AB A single event can generate asynchronous sensory cues due to variable encoding, transmission, and processing delays. To be interpreted as being associated in time, these cues must occur within a limited time window, referred to as a "temporal binding window" (TBW). We investigated the hypothesis that vestibular deficits could disrupt temporal visual-vestibular integration by determining the relationships between vestibular threshold and TBW in participants with normal vestibular function and with vestibular hypofunction. Vestibular perceptual thresholds to yaw rotation were characterized and compared with the TBWs obtained from participants who judged whether a suprathreshold rotation occurred before or after a brief visual stimulus. Vestibular thresholds ranged from 0.7 to 16.5 deg/s and TBWs ranged from 13.8 to 395 ms. Among all participants, TBW and vestibular thresholds were well correlated (R-2 = 0.674, P < 0.001), with vestibular-deficient patients having higher thresholds and wider TBWs. Participants reported that the rotation onset needed to lead the light flash by an average of 80 ms for the visual and vestibular cues to be perceived as occurring simultaneously. The wide TBWs in vestibular-deficient participants compared with normal functioning participants indicate that peripheral sensory loss can lead to abnormal multisensory integration. A reduced ability to temporally combine sensory cues appropriately may provide a novel explanation for some symptoms reported by patients with vestibular deficits. Even among normal functioning participants. a high correlation between TBW and vestibular thresholds was observed, suggesting that these perceptual measurements are sensitive to small differences in vestibular function.
   NEW & NOTEWORTHY While spatial visual-vestibular integration has been well characterized, the temporal integration of these cues is not well understood. The relationship between sensitivity to whole body rotation and duration of the temporal window of visual-vestibular integration was examined using psychophysical techniques. These parameters were highly correlated for those with normal vestibular function and for patients with vestibular hypofunction. Reduced temporal integration performance in patients with vestibular hypofunction may explain some symptoms associated with vestibular loss.
C1 [Shayman, Corey S.; Seo, Jae-Hyun; Oh, Yonghee; Hullar, Timothy E.] Oregon Hlth & Sci Univ, Dept Otolaryngol Head & Neck Surg, Portland, OR 97201 USA.
   [Seo, Jae-Hyun] Catholic Univ Korea, Dept Otolaryngol Head & Neck Surg, Seoul, South Korea.
   [Lewis, Richard F.] Harvard Med Sch, Dept Otolaryngol, Boston, MA USA.
   [Lewis, Richard F.] Harvard Med Sch, Dept Neurol, Boston, MA USA.
   [Lewis, Richard F.] Massachusetts Eye & Ear Infirm, Jenks Vestibular Physiol Lab, Boston, MA 02114 USA.
   [Peterka, Robert J.] VA Portland Hlth Care Syst, Natl Ctr Rehabil Auditory Res, Portland, OR USA.
   [Peterka, Robert J.] Oregon Hlth & Sci Univ, Dept Neurol, Portland, OR 97201 USA.
RP Hullar, TE (corresponding author), 3181 SW Sam Jackson Pk Rd,PV01, Portland, OR 97239 USA.
EM hullar@ohsu.edu
RI Oh, Yonghee/AAC-3302-2021
OI Shayman, Corey/0000-0002-5487-0007
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC-013069]
FX This study was supported, in part, by the National Institute on Deafness
   and Other Communication Disorders Grant R01 DC-013069 to R. F. Lewis.
CR Barnett-Cowan M, 2013, MULTISENS RES, V26, P387, DOI 10.1163/22134808-00002421
   Baskent D, 2011, EAR HEARING, V32, P582, DOI 10.1097/AUD.0b013e31820fca23
   Buker TJ, 2012, HUM FACTORS, V54, P235, DOI 10.1177/0018720811428734
   Carriot J, 2014, J NEUROSCI, V34, P8347, DOI 10.1523/JNEUROSCI.0692-14.2014
   Chang NYN, 2012, LARYNGOSCOPE, V122, P1379, DOI 10.1002/lary.23329
   Chang NYN, 2014, EAR HEARING, V35, P565, DOI 10.1097/AUD.0000000000000052
   Chaudhuri SE, 2013, J NEUROPHYSIOL, V110, P2764, DOI 10.1152/jn.00091.2013
   Colonius H, 2004, J COGNITIVE NEUROSCI, V16, P1000, DOI 10.1162/0898929041502733
   Deneve S, 2004, J PHYSIOLOGY-PARIS, V98, P249, DOI 10.1016/j.jphysparis.2004.03.011
   DiCarlo JJ, 2005, J NEUROPHYSIOL, V93, P2974, DOI 10.1152/jn.00508.2004
   Fetsch CR, 2010, EUR J NEUROSCI, V31, P1721, DOI 10.1111/j.1460-9568.2010.07207.x
   Fister JK, 2016, NEUROPSYCHOLOGIA, V88, P92, DOI 10.1016/j.neuropsychologia.2016.02.016
   Garzorz IT, 2017, CURR BIOL, V27, P2856, DOI 10.1016/j.cub.2017.08.011
   Hairston WD, 2005, EXP BRAIN RES, V166, P474, DOI 10.1007/s00221-005-2387-6
   Hay-McCutcheon MJ, 2009, INT J AUDIOL, V48, P321, DOI 10.1080/14992020802644871
   HOPFIELD JJ, 1995, NATURE, V376, P33, DOI 10.1038/376033a0
   Huth M E, 2011, Int J Otolaryngol, V2011, P937861, DOI 10.1155/2011/937861
   Hwang S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088132
   Jahn KN, 2017, EAR HEARING, V38, P236, DOI 10.1097/AUD.0000000000000379
   Karmali F, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00578
   KATZMAN R, 1983, AM J PSYCHIAT, V140, P734
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lewald J, 2000, J NEUROPHYSIOL, V84, P1107
   Lewis RF, 2008, J NEUROPHYSIOL, V100, P140, DOI 10.1152/jn.01012.2007
   Lupo J, 2018, GAIT POSTURE, V59, P40, DOI 10.1016/j.gaitpost.2017.09.037
   Mallery RM, 2010, EXP BRAIN RES, V204, P11, DOI 10.1007/s00221-010-2288-1
   Martin B, 2013, NEUROPSYCHOLOGIA, V51, P358, DOI 10.1016/j.neuropsychologia.2012.07.002
   McCollum G, 1996, J THEOR BIOL, V180, P257, DOI 10.1006/jtbi.1996.0101
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   MEREDITH MA, 1986, J NEUROPHYSIOL, V56, P640
   Peterka Robert J, 2011, Front Neurol, V2, P57, DOI 10.3389/fneur.2011.00057
   Rey MCB, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00162
   Sanders MC, 2011, EXP BRAIN RES, V210, P539, DOI 10.1007/s00221-011-2554-x
   Selimoglu E, 2007, CURR PHARM DESIGN, V13, P119, DOI 10.2174/138161207779313731
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stevenson RA, 2013, EXP BRAIN RES, V227, P249, DOI 10.1007/s00221-013-3507-3
   Tilikete C, 2011, CURR OPIN NEUROL, V24, P38, DOI 10.1097/WCO.0b013e328341e3b5
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Xie YJ, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00173
NR 39
TC 4
Z9 4
U1 0
U2 8
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD OCT
PY 2018
VL 120
IS 4
BP 1572
EP 1577
DI 10.1152/jn.00379.2018
PG 6
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA HB8OO
UT WOS:000451350100011
PM 30020839
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Moharramipour, A
   Mostame, P
   Hossein-Zadeh, GA
   Wheless, JW
   Babajani-Feremi, A
AF Moharramipour, Ali
   Mostame, Parham
   Hossein-Zadeh, Gholam-Ali
   Wheless, James W.
   Babajani-Feremi, Abbas
TI Comparison of statistical tests in effective connectivity analysis of
   ECoG data
SO JOURNAL OF NEUROSCIENCE METHODS
LA English
DT Article
DE Statistical test; Effective connectivity; Electrocorticography (ECoG);
   Multivariate autoregressive (MVAR); Partial directed coherence (PDC)
ID PARTIAL DIRECTED COHERENCE; SUPERIOR TEMPORAL GYRUS; EVENT-RELATED
   CAUSALITY; HIGH-RESOLUTION EEG; HIGH GAMMA ACTIVITY; FUNCTIONAL
   CONNECTIVITY; CORTICAL CONNECTIVITY; SPEECH-PERCEPTION; BROCAS AREA;
   ELECTROCORTICOGRAPHY
AB Background: The effects of statistical testing on the results of multivariate autoregressive (MVAR)-based effective connectivity analysis have not been adequately investigated, and it is still unclear which statistical test can provide the most accurate results.
   New methods: Using simulated and real electrocorticographic (ECoG) data, we investigated the performance of three nonparametric statistical tests - Monte Carlo permutation, bootstrap resampling, and surrogate data method in MVAR-based effective connectivity analysis. Receiver operating characteristic (ROC) analysis and area under the ROC curve (AUC) were used to assess the performance of each statistical test method. In addition, we found optimal p-values for each method based on ROC analysis. Finally, we investigated the application of statistical tests on partial directed coherence analysis of ECoG data collected in a patient with epilepsy.
   Results: The bootstrap statistical test performed more accurately than other methods. The surrogate method slightly outperformed the Monte Carlo permutation method. Optimal p-values of statistical tests depended on signal-to-noise ratio (SNR) of data, and its value increased by reducing SNR of data. By considering the typical SNR range of electrophysiological data, we recommended an optimal p-value range for the application of each statistical test method.
   Comparison with existing methods: Limited studies have investigated the performance of statistical tests for MVAR-based effective connectivity analysis. For the first time, we have investigated the effects of baseline connections on the various performances of statistical tests.
   Conclusions: We recommend utilizing the bootstrap statistical test with p-value between 0.05 and 0.1 for effective connectivity analysis of ECoG data.
C1 [Moharramipour, Ali; Mostame, Parham; Hossein-Zadeh, Gholam-Ali] Univ Tehran, Sch ECE, Coll Engn, Tehran, Iran.
   [Wheless, James W.; Babajani-Feremi, Abbas] Univ Tennessee, Hlth Sci Ctr, Dept Pediat, Memphis, TN 38163 USA.
   [Wheless, James W.; Babajani-Feremi, Abbas] Le Bonheur Childrens Hosp, Neurosci Inst, Memphis, TN USA.
   [Babajani-Feremi, Abbas] Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
RP Babajani-Feremi, A (corresponding author), Univ Tennessee, Hlth Sci Ctr, Dept Pediat, Neurosci Inst,Le Bonheur Childrens Hosp, 848 Adams Ave,Suite L445A, Memphis, TN 38103 USA.
EM ababajan@uthsc.edu
FU Children's Foundation Research Institute at Le Bonheur Children's
   Hospital; Le Bonheur Associate Board, Memphis, TN
FX This study was supported by the Children's Foundation Research Institute
   at Le Bonheur Children's Hospital and the Le Bonheur Associate Board,
   Memphis, TN.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Akobeng AK, 2007, ACTA PAEDIATR, V96, P644, DOI 10.1111/j.1651-2227.2006.00178.x
   Astolfi L, 2005, P ANN INT IEEE EMBS, P4484, DOI 10.1109/IEMBS.2005.1615463
   Astolfi L, 2005, IEEE T BIO-MED ENG, V52, P757, DOI 10.1109/TBME.2005.845371
   Astolfi L, 2007, HUM BRAIN MAPP, V28, P143, DOI 10.1002/hbm.20263
   Astolfi L, 2006, IEEE T BIO-MED ENG, V53, P1802, DOI 10.1109/TBME.2006.873692
   Astolfi L, 2009, IEEE T NEUR SYS REH, V17, P224, DOI 10.1109/TNSRE.2008.2010472
   Babajani-Feremi A, 2018, CLIN NEUROPHYSIOL, V129, P560, DOI 10.1016/j.clinph.2017.12.031
   Babajani-Feremi A, 2016, CLIN NEUROPHYSIOL, V127, P1822, DOI 10.1016/j.clinph.2015.11.017
   Babajani-Feremi A, 2014, NEUROREPORT, V25, P1411, DOI 10.1097/WNR.0000000000000276
   Baccala LA, 2001, BIOL CYBERN, V84, P463, DOI 10.1007/PL00007990
   Ball T, 2009, NEUROIMAGE, V46, P708, DOI 10.1016/j.neuroimage.2009.02.028
   Boatman DF, 2005, J NEUROSCI, V25, P5475, DOI 10.1523/JNEUROSCI.0936-05.2005
   Brunner C, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00121
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575
   Coben R., 2014, NEUROREGULATION, V1, P109, DOI DOI 10.15540/NR.1.2.109
   Crone NE, 2006, PROG BRAIN RES, V159, P275, DOI 10.1016/S0079-6123(06)59019-3
   Daly I, 2012, PATTERN RECOGN, V45, P2123, DOI 10.1016/j.patcog.2011.04.034
   Deshpande G, 2008, NEUROIMAGE, V40, P1807, DOI 10.1016/j.neuroimage.2008.01.044
   Ding MZ, 2000, BIOL CYBERN, V83, P35, DOI 10.1007/s004229900137
   Engel A. K, 2005, NAT REV NEUROSCI, V35
   Faes L, 2012, COMPUT MATH METHODS, V2012
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   Florin E, 2011, J NEUROSCI METH, V198, P344, DOI 10.1016/j.jneumeth.2011.04.005
   Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201
   Gomez-Herrero G, 2008, NEUROIMAGE, V43, P497, DOI 10.1016/j.neuroimage.2008.07.032
   Greenblatt RE, 2012, J NEUROSCI METH, V207, P1, DOI 10.1016/j.jneumeth.2012.02.025
   Hamedi M, 2016, NEURAL COMPUT, V28, P999, DOI 10.1162/NECO_a_00838
   He B, 2011, J NEUROSCI METH, V195, P261, DOI 10.1016/j.jneumeth.2010.11.015
   Hettiarachchi I, 2015, IEEE SYS MAN CYBERN, P1845, DOI 10.1109/SMC.2015.323
   Korzeniewska A, 2008, HUM BRAIN MAPP, V29, P1170, DOI 10.1002/hbm.20458
   Korzeniewska A, 2011, NEUROIMAGE, V56, P2218, DOI 10.1016/j.neuroimage.2011.03.030
   Langers DRM, 2011, BRAIN CONNECT, V1, P233, DOI 10.1089/brain.2011.0023
   Leff AP, 2009, BRAIN, V132, P3401, DOI 10.1093/brain/awp273
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Micheli C, 2015, NEUROIMAGE, V119, P417, DOI 10.1016/j.neuroimage.2015.06.043
   Nishida M, 2017, CLIN NEUROPHYSIOL, V128, P1473, DOI 10.1016/j.clinph.2017.05.002
   Okada K., 2017, PSYCHONOMIC B REV, P1
   PAIVIO A, 1968, J EXP PSYCHOL, V76, P1, DOI 10.1037/h0025327
   Porcaro C, 2013, CLIN NEUROPHYSIOL, V124, P1216, DOI 10.1016/j.clinph.2012.12.004
   Porcaro C, 2009, CLIN NEUROPHYSIOL, V120, P436, DOI 10.1016/j.clinph.2008.11.011
   Raichle ME, 2005, J COMP NEUROL, V493, P167, DOI 10.1002/cne.20752
   Regan D., 1989, HUMAN BRAIN ELECTROP
   Schlogl A, 2006, PROG BRAIN RES, V159, P135, DOI 10.1016/S0079-6123(06)59009-0
   Schoffelen JM, 2009, HUM BRAIN MAPP, V30, P1857, DOI 10.1002/hbm.20745
   Sekihara K, 2004, P ANN INT IEEE EMBS, V26, P1018
   Sinai A, 2005, BRAIN, V128, P1556, DOI 10.1093/brain/awh491
   Takahashi DY, 2007, J APPL STAT, V34, P1259, DOI 10.1080/02664760701593065
   Thatcher R. W, 2014, Z SCORE NEUROFEEDBAC
   Toppi J, 2016, IEEE T BIO-MED ENG, V63, P2461, DOI 10.1109/TBME.2016.2621668
   Vaden KI, 2011, J COGNITIVE NEUROSCI, V23, P2665, DOI 10.1162/jocn.2011.21620
   Van de Steen F, 2019, BRAIN TOPOGR, V32, P643, DOI 10.1007/s10548-016-0538-7
   van Wijk BCM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013701
   Vicente R, 2011, J COMPUT NEUROSCI, V30, P45, DOI 10.1007/s10827-010-0262-3
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Whitley E, 2002, CRIT CARE, V6, P509, DOI 10.1186/cc1820
   Wiener N., 1956, MODERN MATH ENG, P125
NR 58
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0165-0270
EI 1872-678X
J9 J NEUROSCI METH
JI J. Neurosci. Methods
PD OCT 1
PY 2018
VL 308
BP 317
EP 329
DI 10.1016/j.jneumeth.2018.08.026
PG 13
WC Biochemical Research Methods; Neurosciences
SC Biochemistry & Molecular Biology; Neurosciences & Neurology
GA GZ5GP
UT WOS:000449447500030
PM 30189285
DA 2021-02-24
ER

PT J
AU Nittrouer, S
   Muir, M
   Tietgens, K
   Moberly, AC
   Lowenstein, JH
AF Nittrouer, Susan
   Muir, Meganne
   Tietgens, Kierstyn
   Moberly, Aaron C.
   Lowenstein, Joanna H.
TI Development of Phonological, Lexical, and Syntactic Abilities in
   Children With Cochlear Implants Across the Elementary Grades
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPOKEN WORD RECOGNITION; SPEECH-PERCEPTION; SIMILARITY NEIGHBORHOODS;
   LANGUAGE PERFORMANCE; HEARING CHILDREN; AGE; MEMORY; SCHOOL; USERS; DEAF
AB Purpose: This study assessed phonological, lexical, and morphosyntactic abilities at 6th grade for a group of children previously tested at 2nd grade to address 4 questions: (a) Do children with cochlear implants (CIs) demonstrate deficits at 6th grade? (b) Are those deficits greater, the same, or lesser in magnitude than those observed at 2nd grade? (c) How do the measured skills relate to each other? and (d) How do treatment variables affect outcome measures?
   Participants: Sixty-two 6th graders (29 with normal hearing, 33 with CIs) participated, all of whom had their language assessed at 2nd grade.
   Method: Data are reported for 12 measures obtained at 6th grade, assessing phonological, lexical, and morphosyntactic abilities. Between-groups analyses were conducted on 6th-grade measures and the magnitude of observed effects compared with those observed at 2nd grade. Correlational analyses were performed among the measures at 6th grade. Cross-lagged analyses were performed on specific 2nd- and 6th-grade measures of phonological awareness, vocabulary, and literacy to assess factors promoting phonological and lexical development. Treatment effects of age of 1st CI, preimplant thresholds, and bimodal experience were evaluated.
   Results: Deficits remained fairly consistent in type and magnitude across elementary school. The largest deficits were found for phonological skills and the least for morphosyntactic skills, with lexical skills intermediate. Phonological and morphosyntactic skills were largely independent of each other; lexical skills were moderately related to phonological skills but not morphosyntactic skills. Literacy acquisition strongly promoted both phonological and lexical development. Of the treatment variables, only bimodal experience affected outcomes and did so positively.
   Conclusions: Congenital hearing loss puts children at continued risk of language deficits, especially for phonologically based skills. Two interventions that appear to ameliorate that risk are providing a period of bimodal stimulation and strong literacy instruction.
C1 [Nittrouer, Susan; Muir, Meganne; Tietgens, Kierstyn; Lowenstein, Joanna H.] Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32611 USA.
   [Moberly, Aaron C.] Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
RP Nittrouer, S (corresponding author), Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32611 USA.
EM snittrouer@phhp.ufl.edu
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC006237, R01 DC015992]; Department
   of Otolaryngology-Head and Neck Cancer at The Ohio State University;
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC015992, R01DC006237, R01DC015992,
   R01DC006237, R01DC006237, R01DC006237, R01DC015992, R01DC006237,
   R01DC006237, R01DC006237, R01DC006237, R01DC006237, R01DC006237] Funding
   Source: NIH RePORTER
FX This work was supported by Grants R01 DC006237 and R01 DC015992 (awarded
   to Susan Nittrouer) from the National Institute on Deafness and Other
   Communication Disorders. The support of bridge funding (awarded to Susan
   Nittrouer) from the Department of Otolaryngology-Head and Neck Cancer at
   The Ohio State University is also gratefully acknowledged.
CR BRADY S, 1983, J EXP CHILD PSYCHOL, V35, P345, DOI 10.1016/0022-0965(83)90087-5
   Brownell R., 2000, EXPRESSIVE ONE WORD
   Carrow-Woolfolk E., 1999, COMPREHENSIVE ASSESS
   CHARLESLUCE J, 1990, J CHILD LANG, V17, P205, DOI 10.1017/S0305000900013180
   Ching TYC, 2006, INT J AUDIOL, V45, pS108, DOI 10.1080/14992020600783087
   Ching TYC, 2013, EAR HEARING, V34, P535, DOI 10.1097/AUD.0b013e3182857718
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Gallego C, 2016, RES DEV DISABIL, V49-50, P153, DOI 10.1016/j.ridd.2015.11.020
   Geers AE, 2016, J SPEECH LANG HEAR R, V59, P155, DOI 10.1044/2015_JSLHR-H-14-0173
   Geers AE, 2013, EAR HEARING, V34, P562, DOI 10.1097/AUD.0b013e31828d2bd6
   Geers AE, 2013, J SPEECH LANG HEAR R, V56, P643, DOI 10.1044/1092-4388(2012/11-0347)
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   HALL JW, 1983, MEM COGNITION, V11, P520, DOI 10.3758/BF03196989
   Harris M, 2017, J DEAF STUD DEAF EDU, V22, P233, DOI 10.1093/deafed/enw101
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   Hogan TP, 2011, J COMMUN DISORD, V44, P49, DOI 10.1016/j.jcomdis.2010.07.002
   Holt RF, 2008, EAR HEARING, V29, P492, DOI 10.1097/AUD.0b013e31816c409f
   KATZ RB, 1981, J EXP CHILD PSYCHOL, V32, P474, DOI 10.1016/0022-0965(81)90109-0
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   Lederberg AR, 2014, J DEAF STUD DEAF EDU, V19, P438, DOI 10.1093/deafed/enu022
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   LIBERMAN IY, 1974, J EXP CHILD PSYCHOL, V18, P201, DOI 10.1016/0022-0965(74)90101-5
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   Martin N.A., 2011, EXPRESSIVE ONE WORD
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Miller J, 2016, SYSTEMATIC ANAL LANG
   Miller J., 2010, SYSTEMATIC ANAL LANG
   Moberly AC, 2016, OTOL NEUROTOL, V37, P24, DOI 10.1097/MAO.0000000000000871
   Nittrouer S, 2005, J COMMUN DISORD, V38, P29, DOI 10.1016/j.jcomdis.2004.03.006
   Nittrouer S, 2001, VOLTA REV, V103, P5
   Nittrouer S, 1999, APPL PSYCHOLINGUIST, V20, P563, DOI 10.1017/S0142716499004051
   Nittrouer S., 2010, EARLY DEV CHILDREN H
   Nittrouer S., 2016, PEDIAT COCHLEAR IMPL, P177, DOI [10.1007/978-1-4939-2788-3_11, 10.1121/1.4919316, DOI 10.1007/978-1-4939-2788-3_11]
   Nittrouer S., 2016, PEDIAT COCHLEAR IMPL, P299, DOI 10.1007/978-1-4939-2788-3_20
   Nittrouer S, 2016, J SPEECH LANG HEAR R, V59, P1520, DOI 10.1044/2016_JSLHR-H-15-0404
   Nittrouer S, 2014, EAR HEARING, V35, P506, DOI 10.1097/AUD.0000000000000051
   Nittrouer S, 2013, RES DEV DISABIL, V34, P2304, DOI 10.1016/j.ridd.2013.04.018
   Nittrouer S, 2012, EAR HEARING, V33, P683, DOI 10.1097/AUD.0b013e318258c98e
   Nittrouer S, 2011, J EXP CHILD PSYCHOL, V108, P762, DOI 10.1016/j.jecp.2010.10.012
   Nittrouer Susan, 2009, Trends Amplif, V13, P190, DOI 10.1177/1084713809346160
   NOBLE TH, 1980, DAY JIMMYS BOA ATE W
   Port R, 2007, NEW IDEAS PSYCHOL, V25, P143, DOI 10.1016/j.newideapsych.2007.02.001
   Roid G. H., 2002, LEITER INT PERFORMAN
   Semel E. M., 2003, CLIN EVALUATION LANG
   Snowling M., 2000, DYSLEXIA
   Storkel HL, 2002, J CHILD LANG, V29, P251, DOI 10.1017/S0305000902005032
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   WALLEY AC, 1986, MEM COGNITION, V14, P220, DOI 10.3758/BF03197696
   WALLEY AC, 1993, DEV REV, V13, P286, DOI 10.1006/drev.1993.1015
   Wilkinson G.S., 2006, WIDE RANGE ACHIEVEME
   Zimmerman I. L., 2002, PRESCHOOL LANGUAGE S
NR 53
TC 9
Z9 9
U1 0
U2 19
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD OCT
PY 2018
VL 61
IS 10
BP 2561
EP 2577
DI 10.1044/2018_JSLHR-H-18-0047
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GY2US
UT WOS:000448400000009
PM 30242344
OA Green Published
DA 2021-02-24
ER

PT J
AU Holmes, E
   Domingo, Y
   Johnsrude, IS
AF Holmes, Emma
   Domingo, Ysabel
   Johnsrude, Ingrid S.
TI Familiar Voices Are More Intelligible, Even if They Are Not Recognized
   as Familiar
SO PSYCHOLOGICAL SCIENCE
LA English
DT Article
DE auditory perception; attention; speech perception
ID VOCAL-TRACT LENGTH; SPEECH-PERCEPTION; FACIAL IDENTITY; SPEAKER;
   INTONATION; IDENTIFICATION; FACE
AB We can recognize familiar people by their voices, and familiar talkers are more intelligible than unfamiliar talkers when competing talkers are present. However, whether the acoustic voice characteristics that permit recognition and those that benefit intelligibility are the same or different is unknown. Here, we recruited pairs of participants who had known each other for 6 months or longer and manipulated the acoustic correlates of two voice characteristics (vocal tract length and glottal pulse rate). These had different effects on explicit recognition of and the speech-intelligibility benefit realized from familiar voices. Furthermore, even when explicit recognition of familiar voices was eliminated, they were still more intelligible than unfamiliar voicesdemonstrating that familiar voices do not need to be explicitly recognized to benefit intelligibility. Processing familiar-voice information appears therefore to depend on multiple, at least partially independent, systems that are recruited depending on the perceptual goal of the listener.
C1 [Holmes, Emma; Domingo, Ysabel; Johnsrude, Ingrid S.] Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
   [Johnsrude, Ingrid S.] Univ Western Ontario, Sch Commun Sci & Disorders, London, ON, Canada.
RP Holmes, E (corresponding author), UCL, Wellcome Ctr Human Neuroimaging, Inst Neurol, 12 Queen Sq, London WC1N 3BG, England.
EM emma.holmes@ucl.ac.uk
RI Holmes, Emma/H-8494-2019; Johnsrude, Ingrid S/G-4694-2011
OI Holmes, Emma/0000-0002-0314-6588; Johnsrude, Ingrid
   S/0000-0002-7810-1333; Domingo, Ysabel/0000-0002-8688-2600
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP 133450]; Natural Sciences and Engineering Research
   Council of CanadaNatural Sciences and Engineering Research Council of
   Canada (NSERC)CGIAR [327429-2012]
FX This work was supported by funding from the Canadian Institutes of
   Health Research (Operating Grant MOP 133450) and the Natural Sciences
   and Engineering Research Council of Canada (Discovery Grant
   327429-2012).
CR ABBERTON E, 1978, LANG SPEECH, V21, P305, DOI 10.1177/002383097802100405
   Banziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Baumann O, 2010, PSYCHOL RES-PSYCH FO, V74, P110, DOI 10.1007/s00426-008-0185-z
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Boersma P., 2013, PRAAT DOING PHONETIC
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   Calder AJ, 2005, NAT REV NEUROSCI, V6, P641, DOI 10.1038/nrn1724
   Chiba T., 1941, VOWEL ITS NATURE STR
   Domingo Y., 2018, BENEFIT SPEECH UNPUB
   EADY SJ, 1986, J ACOUST SOC AM, V80, P402, DOI 10.1121/1.394091
   Fant G., 1960, ACOUSTIC THEORY SPEE
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Gaudrain E, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P152
   Halle M., 1985, PHONETIC LINGUISTICS, P101
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Holmes E., 2018, ZENODO, DOI [10.5281/zenodo.1165402, DOI 10.5281/ZENODO.1165402]
   HUMPHREYS GW, 1993, NEUROPSYCHOLOGIA, V31, P173, DOI 10.1016/0028-3932(93)90045-2
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Joos Martin, 1948, LANGUAGE, V24, P5, DOI DOI 10.2307/522229
   KAERNBACH C, 1991, PERCEPT PSYCHOPHYS, V49, P227, DOI 10.3758/BF03214307
   Kidd G, 2008, J ACOUST SOC AM, V124, P3793, DOI 10.1121/1.2998980
   Kreitewolf J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01584
   LARIVIERE C, 1975, PHONETICA, V31, P185, DOI 10.1159/000259668
   Lavner Y, 2000, SPEECH COMMUN, V30, P9, DOI 10.1016/S0167-6393(99)00028-X
   Lavner Y., 2001, INT J SPEECH TECHNOL, V4, P63, DOI [10.1023/A:1009656816383, DOI 10.1023/A:1009656816383]
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   MATSUMOTO H, 1973, IEEE T ACOUST SPEECH, VAU21, P428, DOI 10.1109/TAU.1973.1162507
   MURRY T, 1980, J ACOUST SOC AM, V68, P1294, DOI 10.1121/1.385122
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Smith DRR, 2005, J ACOUST SOC AM, V118, P3177, DOI 10.1121/1.2047107
   TITZE IR, 1989, J ACOUST SOC AM, V85, P1699, DOI 10.1121/1.397959
   Turner RE, 2009, J ACOUST SOC AM, V125, P2374, DOI 10.1121/1.3079772
   Van Lancker D R, 1982, Brain Cogn, V1, P185, DOI 10.1016/0278-2626(82)90016-1
   VANDOMMELEN WA, 1990, LANG SPEECH, V33, P259, DOI 10.1177/002383099003300302
   VANDOMMELEN WA, 1987, LANG SPEECH, V30, P325, DOI 10.1177/002383098703000403
   von Kriegstein K, 2005, J COGNITIVE NEUROSCI, V17, P367, DOI 10.1162/0898929053279577
   WALDEN BE, 1978, J SPEECH HEAR RES, V21, P265, DOI 10.1044/jshr.2102.265
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
NR 40
TC 12
Z9 12
U1 0
U2 15
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0956-7976
EI 1467-9280
J9 PSYCHOL SCI
JI Psychol. Sci.
PD OCT
PY 2018
VL 29
IS 10
BP 1575
EP 1583
DI 10.1177/0956797618779083
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA GW4EF
UT WOS:000446863000001
PM 30096018
OA Green Published
DA 2021-02-24
ER

PT J
AU Lev-Ari, S
AF Lev-Ari, Shiri
TI The influence of social network size on speech perception
SO QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE Social network; individual differences; speech perception
ID TALKER VARIABILITY; LISTENERS
AB Infants and adults learn new phonological varieties better when exposed to multiple rather than a single speaker. This article tests whether having a larger social network similarly facilitates phonological performance. Experiment 1 shows that people with larger social networks are better at vowel perception in noise, indicating that the benefit of laboratory exposure to multiple speakers extends to real life experience and to adults tested in their native language. Furthermore, the experiment shows that this association is not due to differences in amount of input or to cognitive differences between people with different social network sizes. Follow-up computational simulations reveal that the benefit of larger social networks is mostly due to increased input variability. Additionally, the simulations show that the boost that larger social networks provide is independent of the amount of input received but is larger if the population is more heterogeneous. Finally, a comparison of adult and child simulations reconciles previous conflicting findings by suggesting that input variability along the relevant dimension might be less useful at the earliest stages of learning. Together, this article shows when and how the size of our social network influences our speech perception. It thus shows how aspects of our lifestyle can influence our linguistic performance.
C1 [Lev-Ari, Shiri] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Lev-Ari, Shiri] Royal Holloway Univ London, Egham TW20 0EX, Surrey, England.
RP Lev-Ari, S (corresponding author), Royal Holloway Univ London, Egham TW20 0EX, Surrey, England.
EM Shiri.LevAri@rhul.ac.uk
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Bachorowski JA, 1999, J ACOUST SOC AM, V106, P1054, DOI 10.1121/1.427115
   Barcroft J, 2005, STUD SECOND LANG ACQ, V27, P387, DOI 10.1017/S0272263105050175
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Eriksen C. W., 1995, VIS COGN, V2, P101, DOI DOI 10.1080/13506289508401726
   Fraley C, 2012, 597 U WASH DEP STAT
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476
   Hill R. A., 2003, HUMAN NATURE, V14, P153
   HUTTENLOCHER J, 1991, DEV PSYCHOL, V27, P236, DOI 10.1037/0012-1649.27.2.236
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Janse E, 2013, LANG SPEECH, V56, P421, DOI 10.1177/0023830912447914
   Kleinschmidt D. F., 2016, THESIS
   Lev-Ari S, 2016, COGNITIVE SCI, V40, P2050, DOI 10.1111/cogs.12317
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PISONI DB, 1993, SPEECH COMMUN, V13, P109, DOI 10.1016/0167-6393(93)90063-Q
   POSNER MI, 1968, J EXP PSYCHOL, V77, P353, DOI 10.1037/h0025953
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Rost G. C., 2009, DEVELOPMENTAL SCI, V12, P2339
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Sumner M, 2011, COGNITION, V119, P131, DOI 10.1016/j.cognition.2010.10.018
   Thompson SP, 2007, LANG LEARN DEV, V3, P1, DOI 10.1080/15475440709336999
   Tingley D, 2014, J STAT SOFTW, V59
   Unsworth N, 2005, BEHAV RES METHODS, V37, P498, DOI 10.3758/BF03192720
   Vosoughi S, 2010, COGNITION IN FLUX, P1822
NR 31
TC 11
Z9 11
U1 0
U2 7
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1747-0218
EI 1747-0226
J9 Q J EXP PSYCHOL
JI Q. J. Exp. Psychol.
PD OCT
PY 2018
VL 71
IS 10
BP 2249
EP 2260
DI 10.1177/1747021817739865
PG 12
WC Psychology, Biological; Physiology; Psychology; Psychology, Experimental
SC Psychology; Physiology
GA GU0YV
UT WOS:000444981700016
PM 30226426
OA Green Published
DA 2021-02-24
ER

PT J
AU Kleinschmidt, DF
   Weatherholtz, K
   Jaeger, TF
AF Kleinschmidt, Dave F.
   Weatherholtz, Kodi
   Jaeger, T. Florian
TI Sociolinguistic Perception as Inference Under Uncertainty
SO TOPICS IN COGNITIVE SCIENCE
LA English
DT Article
DE Speech perception; Social perception; Computational modeling
ID SPEECH-PERCEPTION; ACOUSTIC CHARACTERISTICS; AMERICAN-ENGLISH; VOWELS;
   GENDER; RECOGNITION; STEREOTYPES; INFORMATION; CATEGORIES; EMERGENCE
AB Social and linguistic perceptions are linked. On one hand, talker identity affects speech perception. On the other hand, speech itself provides information about a talker's identity. Here, we propose that the same probabilistic knowledge might underlie both socially conditioned linguistic inferences and linguistically conditioned social inferences. Our computational-level approachthe ideal adapterstarts from the idea that listeners use probabilistic knowledge of covariation between social, linguistic, and acoustic cues in order to infer the most likely explanation of the speech signals they hear. As a first step toward understanding social inferences in this framework, we use a simple ideal observer model to show that it would be possible to infer aspects of a talker's identity using cue distributions based on actual speech production data. This suggests the possibility of a single formal framework for social and linguistic inferences and the interactions between them.
   Kleinschmidt, Weatherholtz and Jaeger (2018) use distributions of sociolinguistic variables from annotated corpora of spontaneous speech to train and test computational models. Their findings support the hypothesis that - when exposed to talker variability - the same kind of statistical knowledge seems to be at play for both social inferences and speech perception. In turn these findings support the development of a unified theoretical framework for social and linguistic knowledge, and the interactions between them.
C1 [Kleinschmidt, Dave F.] Princeton Univ, Princeton Neurosci Inst, Washington Rd, Princeton, NJ 08544 USA.
   [Kleinschmidt, Dave F.; Weatherholtz, Kodi; Jaeger, T. Florian] Univ Rochester, Dept Brain & Cognit Sci, Rochester, NY 14627 USA.
   [Jaeger, T. Florian] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
   [Jaeger, T. Florian] Univ Rochester, Dept Linguist, Rochester, NY 14627 USA.
RP Kleinschmidt, DF (corresponding author), Princeton Univ, Princeton Neurosci Inst, Washington Rd, Princeton, NJ 08544 USA.
EM dave.f.kleinschmidt@gmail.com
RI Jaeger, T. Florian/O-8224-2019
OI Jaeger, T. Florian/0000-0002-1158-7308
FU NIH NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01 HD075797, F31
   HD082893]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH &
   HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD075797, F31HD082893, R01HD075797, F31HD082893, R01HD075797,
   R01HD075797, R01HD075797] Funding Source: NIH RePORTER
FX We gratefully acknowledge Cynthia Clopper, Shannon Heald, Andy Wedel,
   and Noah Nelson for sharing their expertly annotated speech production
   data with us. Without their generosity this work would not have been
   possible. We also thank Johnny Kim and two other anonymous reviewers for
   feedback that helped substantially improve this paper. This work was
   partially funded by NIH NICHD R01 HD075797 to TFJ and NIH NICHD F31
   HD082893 to DFK. The views expressed here are those of the authors and
   not necessarily those of the funding agencies.
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Bahari MH, 2013, INT CONF ACOUST SPEE, P7344, DOI 10.1109/ICASSP.2013.6639089
   BLADON RAW, 1984, LANG COMMUN, V4, P59, DOI 10.1016/0271-5309(84)90019-3
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Clopper Cynthia G, 2006, Lang Var Change, V18, P193
   Eckert P, 2012, ANNU REV ANTHROPOL, V41, P87, DOI 10.1146/annurev-anthro-092611-145828
   Eckert Penelope, 2000, LINGUISTIC VARIATION
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Flynn N., 2011, P 17 INT C PHON SCI
   Foulkes Paul, 2015, HDB LANGUAGE EMERGEN, P292, DOI [10.1002/9781118346136.ch13., DOI 10.1002/9781118346136.CH13]
   Geisler WS, 2011, VISION RES, V51, P771, DOI 10.1016/j.visres.2010.09.027
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Griffiths, 2008, PROBABILISTIC MIND P, P303, DOI DOI 10.1093/ACPROF:OSO/9780199216093.003.0014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Jacobs R. A., 2010, WILEY INTERDISCIPLIN, V2, P8
   Jaeger TF, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01115
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Kleinschmidt D. F., 2016, P 38 ANN M COGN SCI
   Kleinschmidt D. F, 2018, STRUCTURE TALK UNPUB, DOI [10. 17605/osf. io/a4tkn, DOI 10.17605/OSF.IO/A4TKN]
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Knill D. C., 1996, PERCEPTION BAYESIAN
   Labov William, 2006, ATLAS N AM ENGLISH
   Labov William., 2001, PRINCIPLES LINGUISTI
   Labov William, 1972, SOCIOLINGUISTIC PATT
   Levon E, 2014, LANG SOC, V43, P539, DOI 10.1017/S0047404514000554
   Li M, 2013, COMPUT SPEECH LANG, V27, P151, DOI 10.1016/j.csl.2012.01.008
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396
   Mitchel AD, 2016, J PHONETICS, V56, P66, DOI 10.1016/j.wocn.2016.02.003
   Nelson NR, 2017, J PHONETICS, V64, P51, DOI 10.1016/j.wocn.2017.01.008
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Patrick P. L., 2008, HDB LANGUAGE VARIATI, P381, DOI [10. 1111/b. 9781405116923. 2003. x, DOI 10.1111/B.9781405116923.2003.X]
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Podesva RJ, 2007, J SOCIOLING, V11, P478, DOI 10.1111/j.1467-9841.2007.00334.x
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Stuart-Smith J, 2015, LAB PHONOL, V6, P505, DOI 10.1515/lp-2015-0015
   Sumner M, 2015, TRENDS COGN SCI, V19, P238, DOI 10.1016/j.tics.2015.03.007
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Torre P, 2009, J COMMUN DISORD, V42, P324, DOI 10.1016/j.jcomdis.2009.03.001
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   Watt D., 2002, LEEDS WORKING PAPERS, V9, P159
   Weatherholtz K., 2016, OXFORD RES ENCY LING, DOI [10.1093/acrefore/9780199384655.013.95, DOI 10.1093/ACREFORE/9780199384655.013.95]
NR 55
TC 11
Z9 11
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1756-8757
EI 1756-8765
J9 TOP COGN SCI
JI Top. Cogn. Sci.
PD OCT
PY 2018
VL 10
IS 4
SI SI
BP 818
EP 834
DI 10.1111/tops.12331
PG 17
WC Psychology, Experimental
SC Psychology
GA GY8DI
UT WOS:000448849900012
PM 29542857
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU Verschooten, E
   Desloovere, C
   Joris, PX
AF Verschooten, Eric
   Desloovere, Christian
   Joris, Philip X.
TI High-resolution frequency tuning but not temporal coding in the human
   cochlea
SO PLOS BIOLOGY
LA English
DT Article
ID NEURAL PHASE-LOCKING; PATHOLOGICAL HUMAN; AUDITORY-NERVE;
   FINE-STRUCTURE; SPEECH-PERCEPTION; PITCH PERCEPTION; SELECTIVITY;
   RESPONSES; HEARING; LIMITS
AB Frequency tuning and phase-locking are two fundamental properties generated in the cochlea, enabling but also limiting the coding of sounds by the auditory nerve ( AN). In humans, these limits are unknown, but high resolution has been postulated for both properties. Electrophysiological recordings from the AN of normal-hearing volunteers indicate that human frequency tuning, but not phase-locking, exceeds the resolution observed in animal models.
C1 [Verschooten, Eric; Joris, Philip X.] Katholieke Univ Leuven, Lab Auditory Neurophysiol, Leuven, Belgium.
   [Desloovere, Christian] Katholieke Univ Leuven, Dept Otorhinolaryngol Head & Neck Surg, Leuven, Belgium.
RP Joris, PX (corresponding author), Katholieke Univ Leuven, Lab Auditory Neurophysiol, Leuven, Belgium.
EM philip.joris@kuleuven.de
RI Verschooten, Eric/AAW-3818-2020; Joris, Philip X/D-9608-2011
OI Verschooten, Eric/0000-0001-8010-363X; Joris, Philip
   X/0000-0002-9759-5375
FU Bijzonder Onderzoeksfonds [OT-14-118]
FX Bijzonder Onderzoeksfonds (grant number OT-14-118). Received by Philip
   Joris. The funder had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR ANTOLICANDELA F, 1978, EVOKED ELECTRICAL AC, P165
   Bergevin C, 2012, J COMP PHYSIOL A, V198, P617, DOI 10.1007/s00359-012-0734-1
   Bernstein LR, 1996, J ACOUST SOC AM, V100, P3774, DOI 10.1121/1.417237
   Braga J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127780
   Brown DJ, 2010, HEARING RES, V267, P12, DOI 10.1016/j.heares.2010.03.091
   Brughera A, 2013, J ACOUST SOC AM, V133, P2839, DOI 10.1121/1.4795778
   Burton JA, 2018, HEARING RES, V357, P73, DOI 10.1016/j.heares.2017.11.012
   Cedolin L, 2010, J NEUROSCI, V30, P12712, DOI 10.1523/JNEUROSCI.6365-09.2010
   Delgutte B., 1997, HDB PHONETIC SCI, P507
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   EGGERMONT JJ, 1977, J ACOUST SOC AM, V62, P1247, DOI 10.1121/1.381639
   Eustaquio-Martin A, 2011, JARO-J ASSOC RES OTO, V12, P281, DOI 10.1007/s10162-010-0252-1
   FAY RR, 1992, EVOLUTIONARY BIOLOGY OF HEARING, P229
   GOLDSTEIN MH, 1958, J ACOUST SOC AM, V30, P107, DOI 10.1121/1.1909497
   Harrison R V, 1982, Br J Audiol, V16, P179, DOI 10.3109/03005368209081496
   HARRISON RV, 1981, ARCH OTO-RHINO-LARYN, V230, P221, DOI 10.1007/BF00456322
   HARRISON RV, 1981, J ACOUST SOC AM, V69, P1374, DOI 10.1121/1.385819
   Hartmann WM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00034
   Heinz MG, 2001, NEURAL COMPUT, V13, P2273, DOI 10.1162/089976601750541804
   Henry KS, 2012, NAT NEUROSCI, V15, P1362, DOI 10.1038/nn.3216
   JOHNSON DH, 1980, J ACOUST SOC AM, V68, P1115, DOI 10.1121/1.384982
   Joris PX, 2013, ADV EXP MED BIOL, V787, P101, DOI 10.1007/978-1-4614-1590-9_12
   Joris PX, 2011, P NATL ACAD SCI USA, V108, P17516, DOI 10.1073/pnas.1105867108
   KAWASE T, 1993, J NEUROPHYSIOL, V70, P2519
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Manley GA, 2016, HEARING RES, V336, P53, DOI 10.1016/j.heares.2016.04.004
   MARTIN WH, 1995, EVOKED POTENTIAL, V96, P357, DOI 10.1016/0168-5597(94)00326-A
   Moore BCJ, 2014, AUDITORY PROCESSING OF TEMPORAL FINE STRUCTURE: EFFECTS OF AGE AND HEARING LOSS, P1, DOI 10.1142/9064
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Osmanski MS, 2016, HEARING RES, V341, P1, DOI 10.1016/j.heares.2016.07.006
   Osmanski MS, 2013, J NEUROSCI, V33, P9161, DOI 10.1523/JNEUROSCI.0066-13.2013
   Oxenham AJ, 2003, JARO-J ASSOC RES OTO, V4, P541, DOI 10.1007/s10162-002-3058-y
   PATTERSON RD, 1976, J ACOUST SOC AM, V59, P640, DOI 10.1121/1.380914
   PRIJS VF, 1986, HEARING RES, V21, P127, DOI 10.1016/0378-5955(86)90034-1
   Recio A, 2002, J ACOUST SOC AM, V111, P2213, DOI 10.1121/1.1468878
   Robles L, 2001, PHYSIOL REV, V81, P1305
   Ruggero MA, 2005, P NATL ACAD SCI USA, V102, P18614, DOI 10.1073/pnas.0509323102
   SACHS MB, 1983, ANN NY ACAD SCI, V405, P94, DOI 10.1111/j.1749-6632.1983.tb31622.x
   Santurette S, 2012, J ACOUST SOC AM, V132, P3883, DOI 10.1121/1.4764897
   Santurette S, 2011, J ACOUST SOC AM, V129, P282, DOI 10.1121/1.3518718
   Shera CA, 2002, P NATL ACAD SCI USA, V99, P3318, DOI 10.1073/pnas.032675099
   STEGEMAN DF, 1987, ELECTROEN CLIN NEURO, V67, P176
   Verschooten E, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00331
   Verschooten E, 2015, J NEUROSCI, V35, P2255, DOI 10.1523/JNEUROSCI.2979-14.2015
   Verschooten E, 2014, JARO-J ASSOC RES OTO, V15, P767, DOI 10.1007/s10162-014-0465-9
   Verschooten E, 2012, JARO-J ASSOC RES OTO, V13, P799, DOI 10.1007/s10162-012-0346-z
   WEISS TF, 1988, HEARING RES, V33, P175, DOI 10.1016/0378-5955(88)90030-5
NR 47
TC 14
Z9 14
U1 1
U2 1
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1544-9173
EI 1545-7885
J9 PLOS BIOL
JI PLoS. Biol.
PD OCT
PY 2018
VL 16
IS 10
AR e2005164
DI 10.1371/journal.pbio.2005164
PG 18
WC Biochemistry & Molecular Biology; Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics
GA GZ3XQ
UT WOS:000449322300003
PM 30321166
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Shatzer, H
   Shen, S
   Kerlin, JR
   Pitt, MA
   Shahin, AJ
AF Shatzer, Hannah
   Shen, Stanley
   Kerlin, Jess R.
   Pitt, Mark A.
   Shahin, Antoine J.
TI Neurophysiology underlying influence of stimulus reliability on
   audiovisual integration
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE alpha oscillations; audiovisual asynchrony; audiovisual integration;
   event-related potentials
ID HUMAN AUDITORY-CORTEX; SPEECH-PERCEPTION; ELECTROPHYSIOLOGICAL EVIDENCE;
   SIMULTANEITY JUDGMENTS; TEMPORAL-ORDER; INFORMATION; SYNCHRONY
AB We tested the predictions of the dynamic reweighting model (DRM) of audiovisual (AV) speech integration, which posits that spectrotemporally reliable (informative) AV speech stimuli induce a reweighting of processing from low-level to high-level auditory networks. This reweighting decreases sensitivity to acoustic onsets and in turn increases tolerance to AV onset asynchronies (AVOA). EEG was recorded while subjects watched videos of a speaker uttering trisyllabic nonwords that varied in spectrotemporal reliability and asynchrony of the visual and auditory inputs. Subjects judged the stimuli as in-sync or out-ofsync. Results showed that subjects exhibited greater AVOA tolerance for non-blurred than blurred visual speech and for less than more degraded acoustic speech. Increased AVOA tolerance was reflected in reduced amplitude of the P1-P2 auditory evoked potentials, a neurophysiological indication of reduced sensitivity to acoustic onsets and successful AV integration. There was also sustained visual alpha band (8-14 Hz) suppression (desynchronization) following acoustic speech onsets for nonblurred vs. blurred visual speech, consistent with continuous engagement of the visual system as the speech unfolds. The current findings suggest that increased spectrotemporal reliability of acoustic and visual speech promotes robust AV integration, partly by suppressing sensitivity to acoustic onsets, in support of the DRM's reweighting mechanism. Increased visual signal reliability also sustains the engagement of the visual system with the auditory system to maintain alignment of information across modalities.
C1 [Shatzer, Hannah; Pitt, Mark A.] Ohio State Univ, Dept Psychol, Columbus, OH USA.
   [Shen, Stanley; Kerlin, Jess R.; Shahin, Antoine J.] Univ Calif Davis, Ctr Mind & Brain, 267 Cousteau Pl, Davis, CA 95618 USA.
RP Shahin, AJ (corresponding author), Univ Calif Davis, Ctr Mind & Brain, 267 Cousteau Pl, Davis, CA 95618 USA.
EM ajshahin@ucdavis.edu
FU National Institute of Health (NIH/NIDCD)United States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01-DC013543]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC013543, R01DC013543,
   R01DC013543, R01DC013543, R01DC013543, R01DC013543] Funding Source: NIH
   RePORTER
FX This work was supported by the National Institute of Health (NIH/NIDCD)
   [grant number R01-DC013543] (AJS).
CR Andersen TS, 2015, J ACOUST SOC AM, V137, P2884, DOI 10.1121/1.4916691
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Bhat J, 2015, J NEUROPHYSIOL, V113, P1437, DOI 10.1152/jn.00200.2014
   Bhat J, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00173
   Boenke LT, 2009, EXP BRAIN RES, V198, P233, DOI 10.1007/s00221-009-1917-z
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Chau W, 2004, NEUROIMAGE, V23, P983, DOI 10.1016/j.neuroimage.2004.07.007
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Conrey B.L., 2003, AVSP, V2003, P25
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Eg R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00736
   Eg R, 2015, MULTIMED TOOLS APPL, V74, P345, DOI 10.1007/s11042-014-2136-6
   Eskelund K, 2011, EXP BRAIN RES, V208, P447, DOI 10.1007/s00221-010-2495-9
   Foxe JJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00154
   Ganesh AC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01340
   Ginter J, 2001, J NEUROSCI METH, V110, P113, DOI 10.1016/S0165-0270(01)00424-1
   Harris KC, 2012, EAR HEARING, V33, P330, DOI 10.1097/AUD.0b013e31823fb585
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Keceli S, 2015, BRAIN TOPOGR, V28, P459, DOI 10.1007/s10548-013-0300-3
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   Mazaheri A, 2014, NEUROIMAGE, V87, P356, DOI 10.1016/j.neuroimage.2013.10.052
   Megevand P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071608
   Michalewski HJ, 2005, CLIN NEUROPHYSIOL, V116, P669, DOI 10.1016/j.clinph.2004.09.027
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Patterson RD, 2002, NEURON, V36, P767, DOI 10.1016/S0896-6273(02)01060-7
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Shahin AJ, 2017, LANG COGN NEUROSCI, V32, P1102, DOI 10.1080/23273798.2017.1283428
   Shahin AJ, 2009, BRAIN COGNITION, V70, P259, DOI 10.1016/j.bandc.2009.02.008
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Stekelenburg JJ, 2012, NEUROPSYCHOLOGIA, V50, P1425, DOI 10.1016/j.neuropsychologia.2012.02.027
   Stevenson RA, 2013, EXP BRAIN RES, V227, P249, DOI 10.1007/s00221-013-3507-3
   Stevenson RA, 2013, EXP BRAIN RES, V225, P479, DOI 10.1007/s00221-012-3387-y
   Tian B, 2001, SCIENCE, V292, P290, DOI 10.1126/science.1058911
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vatakis A, 2008, EXP BRAIN RES, V185, P521, DOI 10.1007/s00221-007-1168-9
   Vatakis A, 2006, BRAIN RES, V1111, P134, DOI 10.1016/j.brainres.2006.05.078
   Vroomen J, 2011, COGNITION, V118, P75, DOI 10.1016/j.cognition.2010.10.002
   Weisz N, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00073
   Zampini M, 2005, PERCEPT PSYCHOPHYS, V67, P531, DOI 10.3758/BF03193329
NR 48
TC 5
Z9 5
U1 3
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD OCT
PY 2018
VL 48
IS 8
SI SI
BP 2836
EP 2848
DI 10.1111/ejn.13843
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA GY8OH
UT WOS:000448890800015
PM 29363844
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Hay, J
AF Hay, Jennifer
TI Sociophonetics: The Role of Words, the Role of Context, and the Role of
   Words in Context
SO TOPICS IN COGNITIVE SCIENCE
LA English
DT Article
DE Sociophonetics; Exemplar theory; Lexicon; Context; Language variation
   and change
ID SPEECH-PERCEPTION; DEPENDENT MEMORY; LEXICAL ACCESS; PREDICTABILITY;
   IMPLICIT; ENGLISH; REPRESENTATIONS; RECOGNITION; DURATIONS; ATTENTION
AB This paper synthesizes a wide range of literature from sociolinguistics and cognitive psychology, to argue for a central role for the word as a vehicle of language variation and change. Three crucially interlinked strands of research are reviewedthe role of context in associative learning, the word-level storage of phonetic and contextual detail, and the phonetic consequences of skewed distributions of words across different contexts. I argue that the human capacity for associative learning, combined with attention to fine-phonetic detail at the level of the word, plays a significant role in predicting a range of subtle but systematically robust observed socioindexical patterns in speech production and perception.
   By synthesizing literature from sociolinguistics and cognitive psychology, Hay (2018) argues for a central role of the word in language variation and change. The variants of a word produced in different linguistic and social environments are characterized by phonetic details. Because speakers learn to associate this phonetic information and cues from the context, the phonetic variants of a word are the vehicle that connects the language system to contextual and social information.
C1 [Hay, Jennifer] Univ Canterbury, New Zealand Inst Language Brain & Behav, Private Bag 4800, Canterbury, New Zealand.
RP Hay, J (corresponding author), Univ Canterbury, New Zealand Inst Language Brain & Behav, Private Bag 4800, Canterbury, New Zealand.
EM jen.hay@canterbury.ac.nz
FU Royal Society of New ZealandRoyal Society of New Zealand; John Templeton
   Foundation
FX This manuscript has benefited from the valuable feedback of the
   reviewers and editors of this volume. Its writing was supported by a
   James Cook Fellowship awarded by the Royal Society of New Zealand and a
   subaward under a grant to Northwestern University from the John
   Templeton Foundation. The opinions expressed in this publication are
   those of the author and do not necessarily reflect the views of the John
   Templeton Foundation or the Royal Society of New Zealand. Many thanks to
   my many collaborators on the joint publications cited herein, to Sarah
   Hawkins and Abby Walker for feedback on an earlier draft, and to Jacq
   Jones for proofreading and editorial assistance.
CR BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   Brady TF, 2008, PSYCHOL SCI, V19, P678, DOI 10.1111/j.1467-9280.2008.02142.x
   Brown E. L., 2016, NEW WAYS AN VAR 45 V
   Brown EL, 2012, DIACHRONICA, V29, P139, DOI 10.1075/dia.29.2.02bro
   Bybee Joan, 2002, LANG VAR CHANGE, V14, P261, DOI DOI 10.1017/S0954394502143018
   Cai ZGG, 2017, COGNITIVE PSYCHOL, V98, P73, DOI 10.1016/j.cogpsych.2017.08.003
   Campbell-Kibler K, 2010, LANG VAR CHANGE, V22, P423, DOI 10.1017/S0954394510000177
   Chun MM, 2000, TRENDS COGN SCI, V4, P170, DOI 10.1016/S1364-6613(00)01476-5
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   Cooke M, 2010, J ACOUST SOC AM, V128, P2059, DOI 10.1121/1.3478775
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Creel SC, 2012, LANG COGNITIVE PROC, V27, P1021, DOI 10.1080/01690965.2011.610597
   Creel SC, 2011, J MEM LANG, V65, P264, DOI 10.1016/j.jml.2011.06.005
   Docherty GJ, 2013, LINGUISTICS, V51, P355, DOI 10.1515/ling-2013-0014
   Docherty Gerard J., 2000, PHONOLOGICAL KNOWLED, P105
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Eckert Penelope, 2000, LINGUISTIC VARIATION
   Fiser J, 2002, J EXP PSYCHOL LEARN, V28, P458, DOI 10.1037//0278-7393.28.3.458
   Fiser J, 2001, PSYCHOL SCI, V12, P499, DOI 10.1111/1467-9280.00392
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Foulkes Paul, 2015, HDB LANGUAGE EMERGEN, P292, DOI [10.1002/9781118346136.ch13., DOI 10.1002/9781118346136.CH13]
   GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325, DOI 10.1111/j.2044-8295.1975.tb01468.x
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 2004, PSYCHON B REV, V11, P716, DOI 10.3758/BF03196625
   Gordon E., 2004, NZ ENGLISH ORIGINS E
   Guy G., 2008, 11 LAB PHON C WELL N
   Hay J, 2017, J PHONETICS, V65, P94, DOI 10.1016/j.wocn.2017.06.005
   Hay J, 2016, LANGUAGE, V92, P298, DOI 10.1353/lan.2016.0036
   Hay J, 2012, LINGUISTICS, V50, P745, DOI 10.1515/ling-2012-0023
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Hay JB, 2015, COGNITION, V139, P83, DOI 10.1016/j.cognition.2015.02.012
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Ju M, 2006, J EXP PSYCHOL HUMAN, V32, P120, DOI 10.1037/0096-1523.32.1.120
   Kiesling S. F., 2009, STANCE SOCIOLINGUIST, P171, DOI [10.1093/acprof:oso/9780195331646.001.0001, DOI 10.1093/ACPROF:OSO/9780195331646.003.0008, DOI 10.1093/ACPROF:OSO/9780195331646.001.0001]
   Kim J, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.33
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Labov William, 1972, SOCIOLINGUISTIC PATT
   Mahowald K, 2013, COGNITION, V126, P313, DOI 10.1016/j.cognition.2012.09.010
   McDonald SA, 2003, PSYCHOL SCI, V14, P648, DOI 10.1046/j.0956-7976.2003.psci_1480.x
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pufahl A, 2014, COGNITIVE PSYCHOL, V70, P1, DOI 10.1016/j.cogpsych.2014.01.001
   Qian T, 2016, COGNITION, V157, P156, DOI 10.1016/j.cognition.2016.09.002
   Racz P, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00051
   Raymond WD, 2016, LANG VAR CHANGE, V28, P175, DOI 10.1017/S0954394516000041
   Raymond WD, 2012, TRENDS LINGUIST-STUD, V244, P35
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sarah Hawkins, 2001, ITALIAN J LINGUISTIC, V13, P99
   SCHACTER DL, 1992, J EXP PSYCHOL LEARN, V18, P915, DOI 10.1037/0278-7393.18.5.915
   Schapiro A., 2015, BRAIN MAPPING ENCY R, V3, P501, DOI DOI 10.1016/B978-0-12-397025-1.00276-1
   Seyfarth S, 2014, COGNITION, V133, P140, DOI 10.1016/j.cognition.2014.06.013
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013
   Smith SM, 2001, PSYCHON B REV, V8, P203, DOI 10.3758/BF03196157
   Soskuthy M., 2015, P 18 INT C PHON SCI, P10
   Soskuthy M, 2017, COGNITION, V166, P298, DOI 10.1016/j.cognition.2017.05.032
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Sumner M, 2015, TRENDS COGN SCI, V19, P238, DOI 10.1016/j.tics.2015.03.007
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   YAEGERDROR M, 1992, LANG SPEECH, V35, P251, DOI 10.1177/002383099203500301
NR 67
TC 7
Z9 7
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1756-8757
EI 1756-8765
J9 TOP COGN SCI
JI Top. Cogn. Sci.
PD OCT
PY 2018
VL 10
IS 4
SI SI
BP 696
EP 706
DI 10.1111/tops.12326
PG 11
WC Psychology, Experimental
SC Psychology
GA GY8DI
UT WOS:000448849900004
PM 29498479
OA Bronze
DA 2021-02-24
ER

PT J
AU Harrington, J
   Kleber, F
   Reubold, U
   Schiel, F
   Stevens, M
AF Harrington, Jonathan
   Kleber, Felicitas
   Reubold, Ulrich
   Schiel, Florian
   Stevens, Mary
TI Linking Cognitive and Social Aspects of Sound Change Using Agent-Based
   Modeling
SO TOPICS IN COGNITIVE SCIENCE
LA English
DT Article
DE Sound change; Human speech processing; Agent-based modeling;
   Coarticulation; Speech accommodation
ID DIALECT ACQUISITION; SPEECH-PERCEPTION; ADULTS; VARIABILITY; CONTEXT;
   NEUTRALIZATION; RECALIBRATION; CONVERGENCE; RECOGNITION; PERSPECTIVE
AB The paper defines the core components of an interactive-phonetic (IP) sound change model. The starting point for the IP-model is that a phonological category is often skewed phonetically in a certain direction by the production and perception of speech. A prediction of the model is that sound change is likely to come about as a result of perceiving phonetic variants in the direction of the skew and at the probabilistic edge of the listener's phonological category. The results of agent-based computational simulations applied to the sound change in progress, /u/-fronting in Standard Southern British, were consistent with this hypothesis. The model was extended to sound changes involving splits and mergers by using the interaction between the agents to drive the phonological reclassification of perceived speech signals. The simulations showed no evidence of any acoustic change when this extended model was applied to Australian English data in which /s/ has been shown to retract due to coarticulation in /str/ clusters. Some agents nevertheless varied in their phonological categorizations during interaction between /str/ and /?tr/: This vacillation may represent the potential for sound change to occur. The general conclusion is that many types of sound change are the outcome of how phonetic distributions are oriented with respect to each other, their association to phonological classes, and how these types of information vary between speakers that happen to interact with each other.
   Using agent-based modelling, Harrington, Kleber, Reubold, Schiel & Stevens (2018) develop a unified model of sound change based on cognitive processing of human speech and theories of how social factors constrain the spread of change throughout a community. They conclude that many types of change result from how biases in the phonetic distribution of phonological categories are transmitted via accommodation processes between individuals in interaction.
C1 [Harrington, Jonathan; Kleber, Felicitas; Reubold, Ulrich; Schiel, Florian; Stevens, Mary] Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc IPS, Schellingstr 3, D-80799 Munich, Germany.
RP Harrington, J (corresponding author), Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc IPS, Schellingstr 3, D-80799 Munich, Germany.
EM jmh@phonetik.uni-muenchen.de
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [742289]
FX This research was supported by the European Research Council Advanced
   Grant no. 742289 "Human Interaction and the Evolution of Spoken Accent"
   (2017-2022). Our thanks to editor Paul Foulkes and to two anonymous
   reviewers for very helpful comments.
CR Abrego-Collier C., 2013, P 37 ANN M BERK LING, P3
   Alderete J., 2006, CAMBRIDGE HDB PHONOL, P379
   Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   Beddor PS, 2009, LANGUAGE, V85, P785
   Bigham DS, 2010, J ENGL LINGUIST, V38, P193, DOI 10.1177/0075424210373542
   Blevins J, 2009, DIACHRONICA, V26, P143, DOI 10.1075/dia.26.2.01ble
   Bybee Joan, 2001, PHONOLOGY LANGUAGE U
   Bybee Joan, 2000, USAGE BASED MODELS L, P65, DOI DOI 10.1093/ACPROF:OSO/9780195301571.003.0009
   CHAMBERS JK, 1992, LANGUAGE, V68, P673, DOI 10.2307/416850
   Chang S, 2001, ROLE SPEECH PERCEPTI, P79
   Cohen E, 2012, CURR ANTHROPOL, V53, P588, DOI 10.1086/667654
   Cox F., 2012, AUSTR ENGLISH TRANSC
   Dinkin AJ, 2017, LANG VAR CHANGE, V29, P101, DOI 10.1017/S0954394517000035
   Docherty GJ, 2014, LINGUA, V142, P42, DOI 10.1016/j.lingua.2013.01.011
   Duda R.O, 2001, PATTERN CLASSIFICATI
   Eckert P, 2012, ANNU REV ANTHROPOL, V41, P87, DOI 10.1146/annurev-anthro-092611-145828
   Egurtzegi A., 2014, THESIS
   Ettlinger M., 2007, P 16 INT C PHON SCI, P685
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Fowler CA, 2000, PERCEPT PSYCHOPHYS, V62, P21, DOI 10.3758/BF03212058
   Garrett Andrew, 2013, ORIGINS SOUND CHANGE, P51, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0003
   German JS, 2013, J PHONETICS, V41, P228, DOI 10.1016/j.wocn.2013.03.001
   Giles H., 1972, LANG SOC, V2, DOI [https://doi.org/10.1017/S0047404500000701, DOI 10.1017/S0047404500000701]
   Guion SG, 1998, PHONETICA, V55, P18
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Harrington J, 2017, LANGUAGE, V93, P414, DOI 10.1353/lan.2017.0019
   Harrington J, 2014, LAB PHONOL, V5, P1, DOI 10.1515/lp-2014-0001
   Harrington J, 2011, J PHONETICS, V39, P121, DOI 10.1016/j.wocn.2010.12.006
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hay JB, 2015, COGNITION, V139, P83, DOI 10.1016/j.cognition.2015.02.012
   Hayes Bruce, 2004, PHONETICALLY BASED P, P117, DOI DOI 10.1017/CBO9780511486401
   Hyman L. M., 2013, ORIGINS SOUND CHANGE, P3, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0001
   Janda Richard, 2003, HIST LINGUISTICS 200, P205, DOI DOI 10.1075/CILT.237.14JAN
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   JONGMAN A, 1992, LANG SPEECH, V35, P137, DOI 10.1177/002383099203500212
   Kataoka R., 2011, THESIS
   Kerswill P., 2000, LANGUAGE SOC, V29, P15
   Kerswill P., 1985, THESIS
   Kiparsky P., 2015, OXFORD HDB HIST PHON, P563, DOI DOI 10.1093/OXFORDHB/9780199232819.013.017
   Kiparsky P, 2016, J SOCIOLING, V20, P464, DOI 10.1111/josl.12196
   Kirby J., 2013, ORIGINS SOUND CHANGE, P228, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0011
   Kirby JP, 2014, LAB PHONOL, V5, P195, DOI 10.1515/lp-2014-0008
   Kummel Martin Joachim, 2007, KONSONANTENWANDEL BA
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Labov W., 2010, PRINCIPLES LINGUISTI
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Labov W, 2007, LANGUAGE, V83, P344, DOI 10.1353/lan.2007.0082
   Labov W, 2006, J PHONETICS, V34, P500, DOI 10.1016/j.wocn.2006.05.002
   Lindblom B., 1998, APPROACHES EVOLUTION, P242
   LINDBLOM BE, 1967, J ACOUST SOC AM, V42, P830, DOI 10.1121/1.1910655
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   McQueen JM, 2012, LANG LEARN DEV, V8, P317, DOI 10.1080/15475441.2011.641887
   Milroy James, 1992, SOCIOLINGUISTICS TOD, P146
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Munro MJ, 1999, J PHONETICS, V27, P385, DOI 10.1006/jpho.1999.0101
   Nardy A, 2014, LANG VAR CHANGE, V26, P273, DOI 10.1017/S0954394514000131
   Nielsen K, 2014, J SPEECH LANG HEAR R, V57, P2065, DOI 10.1044/2014_JSLHR-S-13-0093
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nycz J, 2015, LANG LINGUIST COMPAS, V9, P469, DOI 10.1111/lnc3.12163
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   OHALA JJ, 1994, PHONETICA, V51, P111, DOI 10.1159/000261963
   Pardo JS, 2012, J PHONETICS, V40, P190, DOI 10.1016/j.wocn.2011.10.001
   Payne Arvilla, 1980, LOCATING LANGUAGE TI, P143
   Pierrehumbert J., 2014, ARXIV14081985V1
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pierrehumbert JB, 2003, PROBABILISTIC LINGUISTICS, P177
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   Pouplier M., 2011, J LAB PHONOL, V2, P1, DOI DOI 10.1515/LABPHON.2011.001
   Raymond WD, 2016, LANG VAR CHANGE, V28, P175, DOI 10.1017/S0954394516000041
   Recasens D, 2013, PHONETICA, V70, P298, DOI 10.1159/000356628
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Rohena-Madrazo M, 2015, LANG VAR CHANGE, V27, P287, DOI 10.1017/S0954394515000113
   Rohlfs Gerhard, 1966, GRAMMATICA STORICA L
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Shockley K, 2009, TOP COGN SCI, V1, P305, DOI 10.1111/j.1756-8765.2009.01021.x
   Siegel Jeff, 2010, 2 DIALECT ACQUISITIO
   Sole M-J., 2010, LAB PHONOLOGY, P607
   Sole MJ, 2014, LAB PHONOL, V5, P37, DOI 10.1515/lp-2014-0003
   Stevens M, 2016, J PHONETICS, V58, P118, DOI 10.1016/j.wocn.2016.08.003
   Trudgill P., 2012, CURR ANTHROPOL, V53, P609
   Trudgill P., 2011, SOCIOLINGUISTIC TYPO
   Trudgill P, 2008, LANG SOC, V37, P241, DOI 10.1017/S0047404508080287
   Trudgill Peter, 2004, DIALECT CONTACT NEW
   Trudgill Peter, 1999, CUADERNOS FILOLOGIA, V8, P1
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
   Warren P., 1996, P 11 AUSTR INT C SPE, P466
   Watson CI, 1999, J ACOUST SOC AM, V106, P458, DOI 10.1121/1.427069
   Weinreich U., 1968, DIRECTIONS HIST LING, P95
   Yaeger-Dror Malcah, 1996, SOCIAL SCI LANGUAGE, P263, DOI DOI 10.1075/CILT.127
   Yu A. C. L., 2013, ORIGINS SOUND CHANGE, P201, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0010
   Yu Alan., 2007, PHONOLOGY, V24, P187, DOI [DOI 10.1017/S0952675707001157, 10.1017/S0952675707001157]
NR 96
TC 6
Z9 6
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1756-8757
EI 1756-8765
J9 TOP COGN SCI
JI Top. Cogn. Sci.
PD OCT
PY 2018
VL 10
IS 4
SI SI
BP 707
EP 728
DI 10.1111/tops.12329
PG 22
WC Psychology, Experimental
SC Psychology
GA GY8DI
UT WOS:000448849900005
PM 29582572
OA Other Gold
DA 2021-02-24
ER

PT J
AU Kim, J
   Drager, K
AF Kim, Jonny
   Drager, Katie
TI Rapid Influence of Word-Talker Associations on Lexical Access
SO TOPICS IN COGNITIVE SCIENCE
LA English
DT Article
DE Speech perception; Lexical access; Listener expectations; Talker
   characteristics
AB Previous work on English and Korean demonstrates that words are more quickly identified as real words when they are produced by a voice congruent with the age of the talkers who are most likely to use the word (Kim, 2016, Laboratory Phonology, 7, 18; Walker & Hay, 2011, Laboratory Phonology, 2, 219-237). However, this previous work presents stimuli blocked by voice, giving the participant ample time to form expectations about the talker and the words that the talker would likely use. To test whether the effect can be observed in the absence of cues to talker age prior to word onset, the current experiment replicates Kim (2016, Laboratory Phonology, 7, 18) but without blocking by talker. Results from the current experiment confirm earlier findings and they demonstrate that the effect can be observed even without the listener having any expectations about the talker prior to hearing the word. We discuss the implications of these results for models of speech perception, suggesting that lexical access is rapidly boosted by socio-indexical phonetic cues that are congruent with socio-indexical lexical information.
   Kim & Drager (2018) provide new evidence confirming that socially-indexed phonetic cues affect lexical access. They show that young listeners are faster and more accurate when responding to words associated with young people and spoken by younger talkers, compared with old-associated words and older talkers. The effect of phonetic detail on lexical access is rapid and obtains even when the listener holds no expectations about the talker's age prior to the onset of the word.
C1 [Kim, Jonny] Hanyang Univ, Hanyang Inst Phonet & Cognit Sci Language, Seoul, South Korea.
   [Drager, Katie] Univ Hawaii Manoa, Dept Linguist, Honolulu, HI 96822 USA.
RP Kim, J (corresponding author), Hanyang Univ, Hanyang Inst Phonet & Cognit Sci Language, Seoul, South Korea.
EM jonnykkim@hanyang.ac.kr
CR Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Burkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Frank SL, 2016, COGNITIVE SCI, V40, P554, DOI 10.1111/cogs.12247
   Gelman A., 1992, STAT SCI, V7, P457, DOI DOI 10.1214/SS/1177011136
   Hofmeister P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01237
   Husain S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100986
   Johnson K, 1997, TALKER VARIABILITY S, P146
   Kim J, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.33
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Nicenboim B, 2016, LANG LINGUIST COMPAS, V10, P591, DOI 10.1111/lnc3.12207
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
NR 14
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1756-8757
EI 1756-8765
J9 TOP COGN SCI
JI Top. Cogn. Sci.
PD OCT
PY 2018
VL 10
IS 4
SI SI
BP 775
EP 786
DI 10.1111/tops.12351
PG 12
WC Psychology, Experimental
SC Psychology
GA GY8DI
UT WOS:000448849900009
PM 29900689
OA Bronze
DA 2021-02-24
ER

PT J
AU Ronen, M
   Lifshitz-Ben-Basat, A
   Taitelbaum-Swead, R
   Fostick, L
AF Ronen, Michal
   Lifshitz-Ben-Basat, Adi
   Taitelbaum-Swead, Riki
   Fostick, Leah
TI Auditory temporal processing, reading, and phonological awareness among
   aging adults
SO ACTA PSYCHOLOGICA
LA English
DT Article
DE Aging; Dyslexia; Speech perception; Reading; Phonological awareness;
   Auditory temporal processing
ID AGE-RELATED-CHANGES; OF-THE-TONGUE; COMPUTER-BASED INTERVENTION;
   SPEECH-PERCEPTION; ORDER JUDGMENT; OLDER-ADULTS; FAST FORWORD;
   DEVELOPMENTAL DYSLEXIA; LANGUAGE IMPAIRMENT; HEARING SENSITIVITY
AB Auditory temporal processing (ATP) has been related in the literature to both speech perception as well as reading and phonological awareness. In aging adults, it is known to be related to difficulties in speech perception. In the present study, we aimed to test whether an age-related deficit in ATP would also be accompanied by poor reading and phonological awareness. Thirty-eight aging adults were compared to 55 readers with dyslexia and 42 young normal readers on temporal order judgment (TOJ), speech perception, reading, and phonological awareness tests. Aging adults had longer TOJ thresholds than young normal readers, but shorter than readers with dyslexia; however, they had lower speech perception accuracy than both groups. Phonological awareness of the aging adults was better than readers with dyslexia, but poorer than young normal readers, although their reading accuracy was similar to that of the young controls. This is the first report on poor phonological awareness among aging adults. Suprisingly, it was not accompanied by difficulties in reading ability, and might instead be related to aging adults' difficulties in speech perception. This newly discovered relationship between ATP and phonological awareness among aging adults appears to extend the existing understanding of this relationship, and suggests it should be explored in other groups with ATP deficits.
C1 [Ronen, Michal] Ariel Univ, Dept Psychol, Ariel, Israel.
   [Lifshitz-Ben-Basat, Adi; Taitelbaum-Swead, Riki; Fostick, Leah] Ariel Univ, Dept Commun Disorders, Ariel, Israel.
RP Fostick, L (corresponding author), Ariel Univ, Dept Commun Disorders, Ariel, Israel.
EM leah.fostick@ariel.ac.il
RI Fostick, Leah/E-6115-2017
OI Fostick, Leah/0000-0003-3594-6229; Taitelbaum - Swead,
   Riki/0000-0002-4850-8589
CR Ahissar M, 2000, P NATL ACAD SCI USA, V97, P6832, DOI 10.1073/pnas.97.12.6832
   Allen PA, 2011, EXP AGING RES, V37, P261, DOI 10.1080/0361073X.2011.568805
   Anderson S, 2013, J ACOUST SOC AM, V133, P3030, DOI 10.1121/1.4799804
   Babkoff H, 2005, J SLEEP RES, V14, P7, DOI 10.1111/j.1365-2869.2004.00423.x
   Babkoff H., 2017, EUR J AGEING, P1
   Babkoff H, 2013, ATTEN PERCEPT PSYCHO, V75, P654, DOI 10.3758/s13414-013-0449-6
   Ben-Artzi E, 2005, NEUROPSYCHOLOGIA, V43, P714, DOI 10.1016/j.neuropsychologia.2004.08.004
   Ben-Artzi E., 2011, AUDIOLOGY RES, V1, DOI [10.4081/audiores.2011.8, DOI 10.4081/AUDI0RES.2011.E6]
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   BENTIN S, 1991, PSYCHOL SCI, V2, P271, DOI 10.1111/j.1467-9280.1991.tb00148.x
   Bone RB, 2002, DEV NEUROPSYCHOL, V21, P305
   BOOTHROYD A, 1984, J SPEECH HEAR RES, V27, P134, DOI 10.1044/jshr.2701.134
   Borod JC, 1980, J CLIN NEUROPSYCHOLO, V2, P209, DOI DOI 10.1080/01688638008403793
   Breier JI, 2001, J EXP CHILD PSYCHOL, V80, P245, DOI 10.1006/jecp.2001.2630
   BRUCK M, 1992, DEV PSYCHOL, V28, P874, DOI 10.1037/0012-1649.28.5.874
   BRUCK M, 1990, DEV PSYCHOL, V26, P439, DOI 10.1037/0012-1649.26.3.439
   Chall J.S., 1983, STAGES READING DEV
   Cohen W, 2005, J SPEECH LANG HEAR R, V48, P715, DOI 10.1044/1092-4388(2005/049)
   de Boer-Schellekens L, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00008
   Dole M, 2014, NEUROPSYCHOLOGIA, V60, P103, DOI 10.1016/j.neuropsychologia.2014.05.016
   Ehri L C., 2002, WHAT RES HAS SAY REA, P110
   Ehri LC, 2001, READ RES QUART, V36, P250, DOI 10.1598/RRQ.36.3.2
   ELBRO C, 1994, ANN DYSLEXIA, V44, P205, DOI 10.1007/BF02648162
   Ezzatian P, 2015, EAR HEARING, V36, P482, DOI 10.1097/AUD.0000000000000139
   Facal D, 2012, AGING CLIN EXP RES, V24, P647, DOI 10.3275/8586
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Farrell MT, 2011, J EXP PSYCHOL LEARN, V37, P277, DOI 10.1037/a0021328
   Fink M, 2006, BEHAV PROCESS, V71, P344, DOI 10.1016/j.beproc.2005.12.007
   Fink M, 2005, RESTOR NEUROL NEUROS, V23, P281
   Fitzgibbons PJ, 2010, SPRINGER HANDB AUDIT, V34, P111, DOI 10.1007/978-1-4419-0993-0_5
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fostick L, 2012, PSYCHOL RES, V2, P77
   Fostick L., 2012, PSYCHOL RES, V2, P308, DOI DOI 10.17265/2159-5542/2012.05.004
   Fostick L, 2018, ACTA PSYCHOL, V183, P19, DOI 10.1016/j.actpsy.2017.12.010
   Fostick L, 2017, J SPEECH LANG HEAR R, V60, P2124, DOI 10.1044/2017_JSLHR-H-16-0074
   Fostick L, 2017, J EXP PSYCHOL HUMAN, V43, P1002, DOI 10.1037/xhp0000359
   Fostick L, 2014, J EXP PSYCHOL HUMAN, V40, P1799, DOI 10.1037/a0037527
   Fostick L, 2014, J SPEECH LANG HEAR R, V57, P1078, DOI 10.1044/1092-4388(2013/13-0031)
   Fostick L, 2013, EXP PSYCHOL, V60, P432, DOI 10.1027/1618-3169/a000216
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P191, DOI 10.1515/jbcpp-2013-0049
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P175, DOI 10.1515/jbcpp-2013-0048
   Friedmann N, 2016, HDB COMMUNICATION DI
   FROST R, 1994, J EXP PSYCHOL LEARN, V20, P116, DOI 10.1037/0278-7393.20.1.116
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Gillarn RB, 2008, J SPEECH LANG HEAR R, V51, P97, DOI 10.1044/1092-4388(2008/007)
   Given BK, 2008, BRAIN LANG, V106, P83, DOI 10.1016/j.bandl.2007.12.001
   Gonzalez GF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143914
   Gordon-Salant S, 2005, J REHABIL RES DEV, V42, P9, DOI 10.1682/JRRD.2005.01.0006
   Gordon-Salant S, 2008, J ACOUST SOC AM, V124, P3249, DOI 10.1121/1.2982409
   GRIFFITH PL, 1992, READ TEACH, V45, P516
   Harris KC, 2010, HEARING RES, V264, P21, DOI 10.1016/j.heares.2009.09.017
   Hatcher J, 2002, BRIT J EDUC PSYCHOL, V72, P119, DOI 10.1348/000709902158801
   Heim S, 2001, NEUROREPORT, V12, P507, DOI 10.1097/00001756-200103050-00016
   Heinrich A., 2016, SOC INQ WELL BEING, V2, P51, DOI DOI 10.13165/SIIW-16-2-1-05
   Heinrich A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00782
   Hook PE, 2001, ANN DYSLEXIA, V51, P75
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Jafari Zahra, 2013, Med J Islam Repub Iran, V27, P195
   Jin SH, 2014, J AM ACAD AUDIOL, V25, P656, DOI 10.3766/jaaa.25.7.4
   Keen AG, 2000, VISION RES, V40, P705, DOI 10.1016/S0042-6989(99)00208-4
   KINSBOURNE M, 1991, DEV MED CHILD NEUROL, V33, P763
   Kraus Nina, 2014, Hear J, V67, P3
   Kumar UA, 2011, J AM ACAD AUDIOL, V22, P5, DOI 10.3766/jaaa.22.1.2
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   LAMM O, 1994, NEUROPSYCHOLOGIA, V32, P757, DOI 10.1016/0028-3932(94)90016-7
   Lesaux NK, 2006, READ WRIT, V19, P21, DOI 10.1007/s11145-005-4714-5
   LEVINTHAL CF, 1992, READ WRIT, V4, P231, DOI 10.1007/BF01027149
   Lindfield KC, 1999, APPL PSYCHOLINGUIST, V20, P395, DOI 10.1017/S0142716499003045
   Lohvansuu K, 2014, INT J PSYCHOPHYSIOL, V94, P298, DOI 10.1016/j.ijpsycho.2014.10.002
   Maughan B, 2009, J CHILD PSYCHOL PSYC, V50, P893, DOI 10.1111/j.1469-7610.2009.02079.x
   MAUGHAN B, 1994, READ WRIT, V6, P125, DOI 10.1007/BF01026909
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Meyler A, 2005, DYSLEXIA, V11, P93, DOI 10.1002/dys.294
   Miller-Shaul S, 2005, DYSLEXIA, V11, P132, DOI 10.1002/dys.290
   Noordenbos MW, 2012, RES DEV DISABIL, V33, P1469, DOI 10.1016/j.ridd.2012.03.021
   Noordenbos MW, 2013, CLIN NEUROPHYSIOL, V124, P1151, DOI 10.1016/j.clinph.2012.12.044
   Nowak K, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00002
   Olson M. W., 1993, READ WRIT Q, V9, P351
   Ortiz R, 2014, RES DEV DISABIL, V35, P2673, DOI 10.1016/j.ridd.2014.07.007
   Ostroff JM, 2003, HEARING RES, V181, P1, DOI 10.1016/S0378-5955(03)00113-8
   Ozmeral EJ, 2016, NEUROBIOL AGING, V43, P72, DOI 10.1016/j.neurobiolaging.2015.12.024
   Palmer SB, 2014, J AM ACAD AUDIOL, V25, P999, DOI 10.3766/jaaa.25.10.8
   Park DC, 2002, PSYCHOL AGING, V17, P299, DOI 10.1037//0882-7974.17.2.299
   PENNINGTON BF, 1990, CHILD DEV, V61, P1753, DOI 10.2307/1130836
   Ram-Tsur R, 2008, J LEARN DISABIL-US, V41, P437, DOI 10.1177/0022219408321141
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Salthouse TA, 2013, PSYCHOL SCI, V24, P2489, DOI 10.1177/0956797613495881
   Schlaghecken F, 2011, PSYCHOL AGING, V26, P905, DOI 10.1037/a0023832
   Schneider B, 1998, CAN J EXP PSYCHOL, V52, P184, DOI 10.1037/h0087291
   Schneider BA, 2005, PSYCHOL AGING, V20, P261, DOI 10.1037/0882-7974.20.2.261
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schneider Bruce A., 2001, Seminars in Hearing, V22, P227, DOI 10.1055/s-2001-15628
   Share DL, 1995, ISSUES ED CONTRIBUTI, V1, P1, DOI DOI 10.1111/J.1467-9817.1995.TB00075.X
   Shatil E., 1995, ONE MINUTE TES UNPUB
   Shatil E., 1995, PIG LATIN UNPUB
   Shatil E., 1995, SPOONERISM UNPUB
   SHAYWITZ SE, 1992, NEW ENGL J MED, V326, P145, DOI 10.1056/NEJM199201163260301
   Shaywitz SE, 1999, PEDIATRICS, V104, P1351, DOI 10.1542/peds.104.6.1351
   Snowling M.J., 1995, J RES READ, V18, P132, DOI [10.1111/j.1467-9817.1995.tb00079.x, DOI 10.1111/J.1467-9817.1995.TB00079.X]
   Snowling MJ, 2007, J CHILD PSYCHOL PSYC, V48, P609, DOI 10.1111/j.1469-7610.2006.01725.x
   Stevens C, 2008, BRAIN RES, V1205, P55, DOI 10.1016/j.brainres.2007.10.108
   Szymaszek A, 2006, NEUROSCI LETT, V403, P190, DOI 10.1016/j.neulet.2006.04.062
   Szymaszek A, 2009, COGN NEUROPSYCHOL, V26, P135, DOI 10.1080/02643290802504742
   Taitelbaum-Swead R, 2017, INT J PEDIATR OTORHI, V92, P146, DOI 10.1016/j.ijporl.2016.11.022
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Taitelbaum-Swead R, 2016, CLIN LINGUIST PHONET, V30, P531, DOI 10.3109/02699206.2016.1151938
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Temple E, 2003, P NATL ACAD SCI USA, V100, P2860, DOI 10.1073/pnas.0030098100
   Turgeon M, 2011, PSYCHOL AGING, V26, P150, DOI 10.1037/a0020606
   Undheim AM, 2009, DYSLEXIA, V15, P291, DOI 10.1002/dys.384
   Valentine D, 2006, PERCEPT MOTOR SKILL, V103, P183, DOI 10.2466/PMS.103.1.183-196
   Verhaeghen P, 2003, PSYCHOL AGING, V18, P332, DOI 10.1037/0882-7974.18.2.332
   von Steinbuchel N, 1999, NEUROSCI LETT, V264, P168, DOI 10.1016/S0304-3940(99)00204-9
   Welch LW, 1996, BRAIN LANG, V53, P260, DOI 10.1006/brln.1996.0047
   Wilson AM, 2001, J LEARN DISABIL-US, V34, P394, DOI 10.1177/002221940103400501
   Wittmann M, 2003, PERCEPT MOTOR SKILL, V96, P105, DOI 10.2466/PMS.96.1.105-112
   Witton C, 1998, CURR BIOL, V8, P791, DOI 10.1016/S0960-9822(98)70320-3
   YAP R, 1993, READ WRIT, V5, P261, DOI 10.1007/BF01027391
   Zec RF, 2007, CLIN NEUROPSYCHOL, V21, P587, DOI 10.1080/13854040701220028
NR 121
TC 2
Z9 2
U1 2
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0001-6918
EI 1873-6297
J9 ACTA PSYCHOL
JI Acta Psychol.
PD OCT
PY 2018
VL 190
BP 1
EP 10
DI 10.1016/j.actpsy.2018.06.010
PG 10
WC Psychology, Experimental
SC Psychology
GA GX9BO
UT WOS:000448093700001
PM 29986206
DA 2021-02-24
ER

PT J
AU Tune, S
   Wostmann, M
   Obleser, J
AF Tune, Sarah
   Woestmann, Malte
   Obleser, Jonas
TI Probing the limits of alpha power lateralisation as a neural marker of
   selective attention in middle-aged and older listeners
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE alpha oscillations; EEG; spatial attention; speech processing
ID DOWN SUPPRESSION DEFICIT; EVENT-RELATED POTENTIALS; IN-NOISE PERCEPTION;
   HEARING-LOSS; SPATIAL ATTENTION; WORKING-MEMORY; INDIVIDUAL-DIFFERENCES;
   SPEECH-PERCEPTION; YOUNGER; ADULTS
AB In recent years, hemispheric lateralisation of alpha power has emerged as a neural mechanism thought to underpin spatial attention across sensory modalities. Yet, how healthy ageing, beginning in middle adulthood, impacts the modulation of lateralised alpha power supporting auditory attention remains poorly understood. In the current electroencephalography study, middle-aged and older adults (N=29; similar to 40-70years) performed a dichotic listening task that simulates a challenging, multitalker scenario. We examined the extent to which the modulation of 8-12Hz alpha power would serve as neural marker of listening success across age. With respect to the increase in interindividual variability with age, we examined an extensive battery of behavioural, perceptual and neural measures. Similar to findings on younger adults, middle-aged and older listeners' auditory spatial attention induced robust lateralisation of alpha power, which synchronised with the speech rate. Notably, the observed relationship between this alpha lateralisation and task performance did not co-vary with age. Instead, task performance was strongly related to an individual's attentional and working memory capacity. Multivariate analyses revealed a separation of neural and behavioural variables independent of age. Our results suggest that in age-varying samples as the present one, the lateralisation of alpha power is neither a sufficient nor necessary neural strategy for an individual's auditory spatial attention, as higher age might come with increased use of alternative, compensatory mechanisms. Our findings emphasise that explaining interindividual variability will be key to understanding the role of alpha oscillations in auditory attention in the ageing listener.
C1 [Tune, Sarah; Woestmann, Malte; Obleser, Jonas] Univ Lubeck, Dept Psychol, Maria Goeppert Str 9a, D-23562 Lubeck, Germany.
RP Tune, S; Obleser, J (corresponding author), Univ Lubeck, Dept Psychol, Maria Goeppert Str 9a, D-23562 Lubeck, Germany.
EM sarah.tune@uni-luebeck.de; jonas.obleser@uni-luebeck.de
RI ; Obleser, Jonas/C-9891-2011
OI Tune, Sarah/0000-0001-9022-9965; Obleser, Jonas/0000-0002-7619-0459
FU ERC grant (ERC-CoG-2014 AUDADAPT)
FX This research was supported by an ERC grant (ERC-CoG-2014 AUDADAPT) to
   Jonas Obleser. The authors are grateful to Franziska Scharata, Philipp
   Seidel, Elisabeth Ni and Felix Deilmann for their help with data
   acquisition.
CR Ahveninen J, 2013, J COGNITIVE NEUROSCI, V25, P1926, DOI 10.1162/jocn_a_00452
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Banerjee S, 2011, J NEUROSCI, V31, P9923, DOI 10.1523/JNEUROSCI.4660-10.2011
   Bates ME, 2004, J INT NEUROPSYCH SOC, V10, P392, DOI 10.1017/S135561770410307X
   Bauer M, 2012, J NEUROPHYSIOL, V107, P2342, DOI 10.1152/jn.00973.2011
   Bengson JJ, 2012, NEUROIMAGE, V59, P1534, DOI 10.1016/j.neuroimage.2011.08.034
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bennett IJ, 2004, CLIN NEUROPHYSIOL, V115, P2602, DOI 10.1016/j.clinph.2004.06.011
   Brickenkamp R., 2010, TEST D2 REVISION AUF
   Cabeza R, 2002, NEUROIMAGE, V17, P1394, DOI 10.1006/nimg.2002.1280
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Cousijn H, 2014, P NATL ACAD SCI USA, V111, P9301, DOI 10.1073/pnas.1321072111
   Deal JA, 2017, J GERONTOL A-BIOL, V72, P703, DOI 10.1093/gerona/glw069
   Fabiani M, 2012, PSYCHOPHYSIOLOGY, V49, P283, DOI 10.1111/j.1469-8986.2011.01331.x
   FORD JM, 1979, J GERONTOL, V34, P388, DOI 10.1093/geronj/34.3.388
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P175, DOI 10.1515/jbcpp-2013-0048
   Foxe JJ, 1998, NEUROREPORT, V9, P3929, DOI 10.1097/00001756-199812010-00030
   Frey JN, 2014, J NEUROSCI, V34, P6634, DOI 10.1523/JNEUROSCI.4813-13.2014
   Fries P, 2001, SCIENCE, V291, P1560, DOI 10.1126/science.1055465
   Gaeta H, 2003, PSYCHOPHYSIOLOGY, V40, P389, DOI 10.1111/1469-8986.00042
   Gao R, 2017, NEUROIMAGE, V158, P70, DOI 10.1016/j.neuroimage.2017.06.078
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Gazzaley A, 2005, NAT NEUROSCI, V8, P1298, DOI 10.1038/nn1543
   Gazzaley A, 2008, P NATL ACAD SCI USA, V105, P13122, DOI 10.1073/pnas.0806074105
   Getzmann S, 2016, NEUROBIOL AGING, V41, P138, DOI 10.1016/j.neurobiolaging.2016.02.018
   Getzmann S, 2015, NEUROPSYCHOLOGIA, V70, P43, DOI 10.1016/j.neuropsychologia.2015.02.009
   Getzmann S, 2012, J PSYCHOPHYSIOL, V26, P132, DOI 10.1027/0269-8803/a000076
   Getzmann S, 2011, BRAIN RES, V1415, P8, DOI 10.1016/j.brainres.2011.08.001
   Grady C, 2012, NAT REV NEUROSCI, V13, P491, DOI 10.1038/nrn3256
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694
   Haegens S, 2011, J NEUROSCI, V31, P5197, DOI 10.1523/JNEUROSCI.5199-10.2011
   Handel BF, 2011, J COGNITIVE NEUROSCI, V23, P2494, DOI 10.1162/jocn.2010.21557
   Hasher Lynn, 1988, PSYCHOL LEARN MOTIV, V22, P193, DOI DOI 10.1016/S0079-7421(08)60041-9
   Hedden T, 2004, NAT REV NEUROSCI, V5, P87, DOI 10.1038/nrn1323
   Henry MJ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15801
   Hong XF, 2015, NEUROIMAGE, V106, P353, DOI 10.1016/j.neuroimage.2014.11.019
   Jefferies K., 2013, COGNITIVE SCREENING, P209, DOI DOI 10.1007/978-1-4471-2452-8_11
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   KARAYANIDIS F, 1995, PSYCHOPHYSIOLOGY, V32, P335, DOI 10.1111/j.1469-8986.1995.tb01216.x
   Kelly SP, 2006, J NEUROPHYSIOL, V95, P3844, DOI 10.1152/jn.01234.2005
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Krakauer JW, 2017, NEURON, V93, P480, DOI 10.1016/j.neuron.2016.12.041
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   Leenders MP, 2018, CEREB CORTEX, V28, P21, DOI 10.1093/cercor/bhw345
   LEHRL S, 1995, ACTA NEUROL SCAND, V91, P335, DOI 10.1111/j.1600-0404.1995.tb07018.x
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Li SC, 2001, TRENDS COGN SCI, V5, P479, DOI 10.1016/S1364-6613(00)01769-1
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Lindenberger U, 1997, PSYCHOL AGING, V12, P410, DOI 10.1037/0882-7974.12.3.410
   Luke SG, 2017, BEHAV RES METHODS, V49, P1494, DOI 10.3758/s13428-016-0809-y
   Madden DJ, 2007, CURR DIR PSYCHOL SCI, V16, P70, DOI 10.1111/j.1467-8721.2007.00478.x
   McDermott JH, 2009, CURR BIOL, V19, pR1024, DOI 10.1016/j.cub.2009.09.005
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Mok RM, 2016, CEREB CORTEX, V26, P1831, DOI 10.1093/cercor/bhw011
   Muller N, 2012, CEREB CORTEX, V22, P1604, DOI 10.1093/cercor/bhr232
   NISSEN MJ, 1985, J GERONTOL, V40, P185, DOI 10.1093/geronj/40.2.185
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   R Core Team, 2017, R LANG ENV STAT COMP
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   RAPP PR, 1992, TRENDS NEUROSCI, V15, P340, DOI 10.1016/0166-2236(92)90051-9
   Raz N, 2005, CEREB CORTEX, V15, P1676, DOI 10.1093/cercor/bhi044
   Rihs TA, 2007, EUR J NEUROSCI, V25, P603, DOI 10.1111/j.1460-9568.2007.05278.x
   Rosenthal R, 2003, PSYCHOL METHODS, V8, P492, DOI 10.1037/1082-989X.8.4.492
   Rosenthal R., 1994, HDB RES SYNTHESIS, P231, DOI DOI 10.7758/9781610441377.20
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Sander MC, 2012, NEUROIMAGE, V59, P646, DOI 10.1016/j.neuroimage.2011.06.092
   Sauseng P, 2009, CURR BIOL, V19, P1846, DOI 10.1016/j.cub.2009.08.062
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Strauss A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00350
   Thut G, 2006, J NEUROSCI, V26, P9494, DOI 10.1523/JNEUROSCI.0875-06.2006
   Vaden RJ, 2012, NEUROIMAGE, V63, P1127, DOI 10.1016/j.neuroimage.2012.07.050
   Verhaeghen P, 2002, NEUROSCI BIOBEHAV R, V26, P849, DOI 10.1016/S0149-7634(02)00071-4
   Voytek B, 2015, J NEUROSCI, V35, P13257, DOI 10.1523/JNEUROSCI.2332-14.2015
   Waschke L, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17766-4
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   Wechsler D., 2008, WECHSLER ADULT INTEL, V22, P498
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   Wostmann M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00538
   Wostmann M, 2016, P NATL ACAD SCI USA, V113, P3873, DOI 10.1073/pnas.1523357113
   Wostmann M, 2015, J COGNITIVE NEUROSCI, V27, P988, DOI 10.1162/jocn_a_00761
   Wostmann M, 2015, J NEUROSCI, V35, P1458, DOI 10.1523/JNEUROSCI.3250-14.2015
   WOODS DL, 1992, ELECTROEN CLIN NEURO, V84, P456, DOI 10.1016/0168-5597(92)90033-8
   Worden MS, 2000, J NEUROSCI, V20
   Zanto T. P., 2014, OXFORD HDB ATTENTION, V927-971, DOI DOI 10.1093/OXFORDHB/9780199675111.013.020
NR 89
TC 14
Z9 14
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD OCT
PY 2018
VL 48
IS 7
SI SI
BP 2537
EP 2550
DI 10.1111/ejn.13862
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA GY0AG
UT WOS:000448170100014
PM 29430736
DA 2021-02-24
ER

PT J
AU Fernandez, LM
   Torralba, M
   Soto-Faraco, S
AF Moris Fernandez, Luis
   Torralba, Mireia
   Soto-Faraco, Salvador
TI Theta oscillations reflect conflict processing in the perception of the
   McGurk illusion
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE audiovisual; EEG; multisensory; speech
ID AUDIOVISUAL SPEECH-PERCEPTION; ANTERIOR CINGULATE CORTEX; VISUAL SPEECH;
   NEURAL OSCILLATIONS; HAND GESTURES; SEEING VOICES; HEARING LIPS;
   BOTTOM-UP; INTEGRATION; ATTENTION
AB The McGurk illusion is one of the most famous illustrations of cross-modal integration in human perception. It has been often used as a proxy of audiovisual (AV) integration and to infer the properties of the integration process in natural (congruent) AV conditions. Nonetheless, a blatant difference between McGurk stimuli and natural, congruent, AV speech is the conflict between the auditory and the visual information in the former. Here, we hypothesized that McGurk stimuli (and any AV incongruency) engage brain responses similar to those found in more general cases of perceptual conflict (e.g., Stroop), and propose that the McGurk illusion arises as a result of the resolution of such conflict. We used electroencephalography to measure variations in the power of theta, a well-known marker of the brain response to conflict. The results showed that perception of AV McGurk stimuli, just like AV incongruence in general, induces an increase in activity in the theta band. This response was similar to that evoked by Stroop stimuli, as measured in the same participants. This finding suggests that the McGurk illusion is mediated by general-purpose conflict mechanisms, and calls for caution in generalizing findings obtained using the McGurk illusion, to the general case of multisensory integration.
C1 [Moris Fernandez, Luis; Torralba, Mireia; Soto-Faraco, Salvador] Univ Pompeu Fabra, Multisensory Res Grp, Ctr Brain & Cognit, Dept Tecnol Informacio & Comunicac, Off 55-128,Roc Boronat 138, Barcelona 08018, Spain.
   [Soto-Faraco, Salvador] ICREA, Dept Tecnol Informacio & Comunicac, Barcelona, Spain.
RP Fernandez, LM (corresponding author), ICREA, Dept Tecnol Informacio & Comunicac, Barcelona, Spain.
EM luis.moris.fernandez@gmail.com
RI Fernandez, Luis Moris/AAQ-2418-2020
OI Fernandez, Luis Moris/0000-0001-5247-7503; Torralba Cuello,
   Mireia/0000-0003-3035-3918
FU Ministerio de Economia y CompetitividadSpanish Government
   [PSI2016-75558-P AEI/FEDER]; AGAUR Generalitat de CatalunyaAgencia de
   Gestio D'Ajuts Universitaris de Recerca Agaur (AGAUR)Generalitat de
   Catalunya [2014SGR856]; European Research CouncilEuropean Research
   Council (ERC)European Commission [StG-2010 263145]
FX We thank Mallick, D.B., Magnotti, J.F. & Beauchamp, M.S. for furnishing
   us with the stimuli used in this study. This research was supported by
   the Ministerio de Economia y Competitividad (PSI2016-75558-P AEI/FEDER),
   AGAUR Generalitat de Catalunya (2014SGR856) and the European Research
   Council (StG-2010 263145).
CR Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Andersen TS, 2009, SPEECH COMMUN, V51, P184, DOI 10.1016/j.specom.2008.07.004
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   BERNSTEIN LE, 2004, HDB MULTISENSORY PRO, P203
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Bernstein LE, 2008, BRAIN RES, V1242, P172, DOI 10.1016/j.brainres.2008.04.018
   Biau E, 2016, NEUROIMAGE, V132, P129, DOI 10.1016/j.neuroimage.2016.02.018
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018
   Brunelliere A, 2013, INT J PSYCHOPHYSIOL, V89, P136, DOI 10.1016/j.ijpsycho.2013.06.016
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Cavanagh JF, 2014, TRENDS COGN SCI, V18, P414, DOI 10.1016/j.tics.2014.04.012
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cohen MX, 2015, INT J PSYCHOPHYSIOL, V97, P245, DOI 10.1016/j.ijpsycho.2014.09.013
   Cohen MX, 2014, TRENDS NEUROSCI, V37, P480, DOI 10.1016/j.tins.2014.06.004
   Cohen MX, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057293
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   DEKLE DJ, 1992, PERCEPT PSYCHOPHYS, V51, P355, DOI 10.3758/BF03211629
   Ergen M, 2014, INT J PSYCHOPHYSIOL, V94, P463, DOI 10.1016/j.ijpsycho.2014.08.177
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Festa EK, 2017, J ALZHEIMERS DIS, V59, P155, DOI 10.3233/JAD-161062
   Gau R, 2016, NEUROIMAGE, V124, P876, DOI 10.1016/j.neuroimage.2015.09.045
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   GUTHRIE D, 1991, PSYCHOPHYSIOLOGY, V28, P240, DOI 10.1111/j.1469-8986.1991.tb00417.x
   Hanslmayr S, 2008, J COGNITIVE NEUROSCI, V20, P215, DOI 10.1162/jocn.2008.20020
   Hartcher-O'Brien J, 2017, FRONT INTEGR NEUROSC, V11, DOI 10.3389/fnint.2017.00005
   Hasson U, 2007, NEURON, V56, P1116, DOI 10.1016/j.neuron.2007.09.037
   Jaekl P, 2015, NEUROPSYCHOLOGIA, V75, P402, DOI 10.1016/j.neuropsychologia.2015.06.025
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Keil J, 2012, CEREB CORTEX, V22, P221, DOI 10.1093/cercor/bhr125
   Kiebel SJ, 2005, HUM BRAIN MAPP, V26, P170, DOI 10.1002/hbm.20153
   Kislyuk DS, 2008, J COGNITIVE NEUROSCI, V20, P2175, DOI 10.1162/jocn.2008.20152
   MACLEOD CM, 1991, PSYCHOL BULL, V109, P163, DOI 10.1037/0033-2909.109.2.163
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Maris E, 2007, J NEUROSCI METH, V163, P161, DOI 10.1016/j.jneumeth.2007.02.011
   Massaro D., 1987, SPEECH PERCEPTION EA, P221
   Massaro DW, 1998, AM SCI, V86, P236, DOI 10.1511/1998.25.861
   Matchin W, 2014, J COGNITIVE NEUROSCI, V26, P606, DOI 10.1162/jocn_a_00515
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Fernandez LM, 2017, HUM BRAIN MAPP, V38, P5691, DOI 10.1002/hbm.23758
   Fernandez LM, 2015, NEUROIMAGE, V119, P272, DOI 10.1016/j.neuroimage.2015.06.052
   Munhall KG, 2009, CURR BIOL, V19, P735, DOI 10.1016/j.cub.2009.03.019
   Murray MM, 2008, BRAIN TOPOGR, V20, P249, DOI 10.1007/s10548-008-0054-5
   Nahorna O, 2015, J ACOUST SOC AM, V137, P362, DOI 10.1121/1.4904536
   Nahorna O, 2012, J ACOUST SOC AM, V132, P1061, DOI 10.1121/1.4728187
   Nee DE, 2007, COGN AFFECT BEHAV NE, V7, P1, DOI 10.3758/CABN.7.1.1
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Orr JM, 2009, CEREB CORTEX, V19, P703, DOI 10.1093/cercor/bhn119
   Pekkola J, 2006, NEUROIMAGE, V29, P797, DOI 10.1016/j.neuroimage.2005.09.069
   Pomper U, 2015, HUM BRAIN MAPP, V36, P3246, DOI 10.1002/hbm.22845
   Romero YR, 2015, J NEUROPHYSIOL, V113, P2342, DOI 10.1152/jn.00783.2014
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Sanchez-Garcia C, 2018, MULTISENS RES, V31, P57, DOI 10.1163/22134808-00002560
   Sanchez-Garcia C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025198
   Shenhav A, 2013, NEURON, V79, P217, DOI 10.1016/j.neuron.2013.07.007
   SIMON JR, 1967, J APPL PSYCHOL, V51, P300, DOI 10.1037/h0020586
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Soto-Faraco S, 2004, COGNITION, V92, pB13, DOI 10.1016/j.cognition.2003.10.005
   Soto-Faraco S, 2007, NEUROREPORT, V18, P347, DOI 10.1097/WNR.0b013e32801776f9
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1984, Q J EXP PSYCHOL-A, V36, P51, DOI 10.1080/14640748408401503
   Szycik GR, 2009, HUM BRAIN MAPP, V30, P1990, DOI 10.1002/hbm.20640
   Talsma D, 2010, TRENDS COGN SCI, V14, P400, DOI 10.1016/j.tics.2010.06.008
   ten Oever S, 2016, EXP BRAIN RES, V234, P1307, DOI 10.1007/s00221-016-4590-z
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Van Engen KJ, 2017, ATTEN PERCEPT PSYCHO, V79, P396, DOI 10.3758/s13414-016-1238-9
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Weissman DH, 2004, J NEUROSCI, V24, P10941, DOI 10.1523/JNEUROSCI.3669-04.2004
   YONOVITZ A, 1977, J ACOUST SOC AM, V62, pS3, DOI 10.1121/1.2016172
   Zimmer U, 2010, NEUROIMAGE, V52, P606, DOI 10.1016/j.neuroimage.2010.04.245
NR 83
TC 4
Z9 4
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD OCT
PY 2018
VL 48
IS 7
SI SI
BP 2630
EP 2641
DI 10.1111/ejn.13804
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA GY0AG
UT WOS:000448170100021
PM 29250857
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Lee, SJ
   Park, KW
   Kim, LS
   Kim, H
AF Lee, Soo Jung
   Park, Kyung Won
   Kim, Lee-Suk
   Kim, HyangHee
TI Association between Frontal-Executive Dysfunction and Speech-in-Noise
   Perception Deficits in Mild Cognitive Impairment
SO JOURNAL OF CLINICAL NEUROLOGY
LA English
DT Article
DE mild cognitive impairment; frontal-executive dysfunction;
   speech-in-noise perception; central auditory processing
ID CENTRAL AUDITORY DYSFUNCTION; WORKING-MEMORY CAPACITY; RECOGNITION;
   DEMENTIA
AB Background and Purpose Speech-in-noise perception deficits have been demonstrated in patients with mild cognitive impairment (MCI). However, it remains unclear whether the impairment of speech perception varies between MCI subtypes. The purpose of this study was twofold: 1) to compare speech perception performance among MCI subgroups, and 2) to identify the cognitive domains specifically related to speech-in-noise perception.
   Methods We studied 46 patients with MCI and 39 hearing-threshold-matched cognitively normal elderly (CNE) subjects. Two different patient classifications were used: 1) patients with amnestic mild cognitive impairment (aMCI) (n=21) or nonamnestic mild cognitive impairment (naMCI) (n=25), and 2) patients with frontal-executive dysfunction (FED) (n=16) or without FED (n=30). All of the subjects underwent audiometric, neuropsychological, and speech perception assessments. Speech-in-noise perception was measured using sentence recognition tests in the presence of two types of background noise at four levels.
   Results First, as the level of background noise increased, the MCI with FED group scored lower than both the MCI without FED and CNE groups under both types of noise. Second, both the naMCI and aMCI groups scored lower than the CNE group, but there were no differences between the naMCI and aMCI groups in sentence recognition under any noise conditions. Third, significant correlations were found between sentence recognition and executive function scores both in the MCI groups and in the CNE group.
   Conclusions Our findings suggest that frontal-executive function is strongly related to speech in-noise perception and that MCI patients with FED have greater deficits in speech-in-noise perception compared to other subgroups of MCI.
C1 [Lee, Soo Jung] Daegu Catholic Univ, Dept Audiol & Speech Language Pathol, Gyongsan, South Korea.
   [Park, Kyung Won] Dong A Univ, Coll Med, Dept Neurol, Busan, South Korea.
   [Kim, Lee-Suk] Dong A Univ, Coll Med, Dept Otolaryngol Head & Neck Surg, Busan, South Korea.
   [Kim, HyangHee] Yonsei Univ, Coll Med, Grad Program Speech Language Pathol, 50-1 Yonsei Ro, Seoul 03722, South Korea.
   [Kim, HyangHee] Yonsei Univ, Coll Med, Dept & Res Inst Rehabil Med, 50-1 Yonsei Ro, Seoul 03722, South Korea.
RP Kim, H (corresponding author), Yonsei Univ, Coll Med, Grad Program Speech Language Pathol, 50-1 Yonsei Ro, Seoul 03722, South Korea.; Kim, H (corresponding author), Yonsei Univ, Coll Med, Dept & Res Inst Rehabil Med, 50-1 Yonsei Ro, Seoul 03722, South Korea.
EM h.kim@yonsei.ac.kr
OI KIM, HyangHee "Hope"/0000-0003-4949-2512
CR Aimoni C, 2014, J INT ADV OTOL, V10, P228, DOI 10.5152/iao.2014.349
   Albers MW, 2015, ALZHEIMERS DEMENT, V11, P70, DOI 10.1016/j.jalz.2014.04.514
   D'Ausilio A, 2012, J NEUROLINGUIST, V25, P328, DOI 10.1016/j.jneuroling.2010.02.003
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Gates GA, 1996, ARCH OTOLARYNGOL, V122, P161
   Gates GA, 2002, J AM GERIATR SOC, V50, P482, DOI 10.1046/j.1532-5415.2002.50114.x
   Gates GA, 2011, ARCH OTOLARYNGOL, V137, P390, DOI 10.1001/archoto.2011.28
   Gates GA, 2010, COGN BEHAV NEUROL, V23, P218, DOI 10.1097/WNN.0b013e3181d748d7
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   Kang Y., 2003, SEOUL NEUROPSYCHOLOG
   Kang Y, 2000, KOREAN J CLIN PSYCHO, V19, P385
   Kang Y., 2012, SEOUL NEUROPSYCHOLOG
   Kang Yeonwook, 2002, Korean Journal of Clinical Psychology, V21, P911
   Kang Yeonwook, 2006, [Korean Journal of Psychology: General, 한국심리학회지:일반], V25, P1
   Kim HH, 1999, J CLIN EXP NEUROPSYC, V21, P127, DOI 10.1076/jcen.21.1.127.942
   Koelewijn Thomas, 2012, Int J Otolaryngol, V2012, P865731, DOI 10.1155/2012/865731
   Lee J, 2000, KOREAN J CLIN PSYCHO, V19, P807
   Lee J. H., 2010, KOREAN SPEECH AUDIOM
   Lee SJ, 2016, COGN BEHAV NEUROL, V29, P68, DOI 10.1097/WNN.0000000000000092
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McCabe DP, 2010, NEUROPSYCHOLOGY, V24, P222, DOI 10.1037/a0017619
   Panza F, 2015, NAT REV NEUROL, V11
   Petersen RC, 2004, J INTERN MED, V256, P183, DOI 10.1111/j.1365-2796.2004.01388.x
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Shao Z, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00772
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
NR 28
TC 1
Z9 1
U1 0
U2 4
PU KOREAN NEUROLOGICAL ASSOC
PI SEOUL
PA 1111 DAEIL BLD, 43 INSA-DONG, JONGNO-GU, SEOUL, 110-741, SOUTH KOREA
SN 1738-6586
EI 2005-5013
J9 J CLIN NEUROL
JI J. Clin. Neurol.
PD OCT
PY 2018
VL 14
IS 4
BP 513
EP 522
DI 10.3988/jcn.2018.14.4.513
PG 10
WC Clinical Neurology
SC Neurosciences & Neurology
GA GW9WG
UT WOS:000447357300011
PM 30198228
OA Green Published
DA 2021-02-24
ER

PT J
AU Hansson, K
   Ibertsson, T
   Asker-Arnason, L
   Sahlen, B
AF Hansson, Kristina
   Ibertsson, Tina
   Asker-Arnason, Lena
   Sahlen, Birgitta
TI Language impairment in children with CI: An investigation of Swedish
SO LINGUA
LA English
DT Article
DE Cochlear implants; Language impairment; Clinical marker; Nonword
   repetition; Language comprehension; Past tense inflection
ID NON-WORD REPETITION; NONWORD REPETITION; COCHLEAR IMPLANTS; HEARING
   IMPAIRMENT; SPEAKING CHILDREN; VERB MORPHOLOGY; WORKING-MEMORY;
   DIAGNOSTIC-ACCURACY; CLINICAL MARKER; AGE-CHILDREN
AB In spite of earlier implantation, bilateral implants and advances in the care of deaf children with cochlear implants (CI) within-group variation in language skills is large. We use three tasks with predictive value of language impairment in Swedish to identify children with CI most at risk for persistent difficulties in language development, in need of language intervention. The clinical markers investigated are nonword repetition and past tense inflection. We also assessed language comprehension, a predictor of severe language impairment associated with poorer prognosis. Fifteen Swedish-speaking deaf children with CI and 15 controls aged 5-8 years participated. Most children with CI had bilateral implants and had been fitted with Cls before 12 months. At least 70% in the group with CI performed >1.25 and 47% >2 SD below controls on more than one measure, showing risk for persistent language impairment. Speech perception was more crucial in the nonword repetition and language comprehension tasks. No time factor was significantly related to outcome. We conclude that it is important to allocate resources for continuous follow-up and language intervention. Research and care of children with CI will profit from better integration of knowledge from the fields of audiology, speech-language pathology and linguistics. (C) 2018 The Authors. Published by Elsevier B.V.
C1 [Hansson, Kristina] Lund Univ, Dept Clin Sci, S-22185 Lund, Sweden.
   Skane Univ Hosp, Logoped Phoniatr & Audiol, S-22185 Lund, Sweden.
RP Hansson, K (corresponding author), Lund Univ, Dept Clin Sci, S-22185 Lund, Sweden.
EM kristina.hansson@med.lu.se; tina.ibertsson@med.lu.se;
   lena.asker-arnason@med.lu.se; birgitta.sahlen@med.lu.se
RI Sahlen, Birgitta/O-1245-2014
OI Sahlen, Birgitta/0000-0002-8468-0546
FU Bank of Sweden Tercentenary Foundation [P10-0107]; Linnaeus Centre
   Thinking in Time: Cognition, Communication, and Learning - Swedish
   Research Council [349-2007-8695]
FX This work was financed by the Bank of Sweden Tercentenary Foundation,
   project number P10-0107. The authors also acknowledge the support from
   the Linnaeus Centre Thinking in Time: Cognition, Communication, and
   Learning, financed by the Swedish Research Council, grant no.
   349-2007-8695. Finally, our sincere thanks go to the Swedish parent
   association for children with CI, Barnplantorna, and all participating
   children and their parents.
CR Adams AM, 2000, INT J LANG COMM DIS, V35, P95
   Archibald LMD, 2009, J SPEECH LANG HEAR R, V52, P899, DOI 10.1044/1092-4388(2009/08-0099)
   Asker-Arnason L., 2015, VOLTA REV, V115, P35
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Benasich AA, 2002, BEHAV BRAIN RES, V136, P31, DOI 10.1016/S0166-4328(02)00098-0
   Bishop D., 2009, TEST RECEPTION GRAMM
   Bishop DVM, 2014, INT J LANG COMM DIS, V49, P381, DOI 10.1111/1460-6984.12101
   BISHOP DVM, 1987, J SPEECH HEAR DISORD, V52, P156, DOI 10.1044/jshd.5202.156
   Bishop DVM, 1996, J CHILD PSYCHOL PSYC, V37, P391, DOI 10.1111/j.1469-7610.1996.tb01420.x
   Boons T, 2013, RES DEV DISABIL, V34, P2008, DOI 10.1016/j.ridd.2013.03.003
   Botting N, 2001, INT J LANG COMM DIS, V36, P421, DOI 10.1080/13682820110074971
   Bowey JA, 2006, APPL PSYCHOLINGUIST, V27, P548, DOI 10.1017/S0142716406220393
   Brinton Bonnie, 2005, Seminars in Speech and Language, V26, P151, DOI 10.1055/s-2005-917120
   Bruce B, 2003, ACTA PAEDIATR, V92, P1090, DOI 10.1080/08035250310004414
   Bruce B., 2010, 1 LANGUAGE SPECIAL I, V30, P493, DOI DOI 10.11777/0142723710370523
   Carter AK, 2002, CLIN LINGUIST PHONET, V16, P619, DOI 10.1080/02699200021000034958
   Christensen RV, 2012, J SPEECH LANG HEAR R, V55, P1671, DOI 10.1044/1092-4388(2012/10-0350)
   Coene M, 2014, LINGUA, V139, P1, DOI 10.1016/j.lingua.2013.12.005
   Coene Martine, 2010, Cochlear Implants Int, V11 Suppl 1, P272, DOI 10.1179/146701010X12671177989156
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Conti-Ramsden G, 2001, J CHILD PSYCHOL PSYC, V42, P741, DOI 10.1111/1469-7610.00770
   Corrigan R, 2008, COMMUNICATION DISORD, V29, P109, DOI DOI 10.1177/1525740108315880
   Deevy P, 2010, LANG SPEECH HEAR SER, V41, P277, DOI 10.1044/0161-1461(2009/08-0096)
   Delage H, 2007, J SPEECH LANG HEAR R, V50, P1300, DOI 10.1044/1092-4388(2007/091)
   Dillon CM, 2006, VOLTA REV, V106, P121
   Dispaldro M, 2013, J SPEECH LANG HEAR R, V56, P323, DOI 10.1044/1092-4388(2012/11-0304)
   Duchesne L., 2015, OXFORD HDB DEAF STUD, P113
   Ebbels SH, 2019, INT J LANG COMM DIS, V54, P3, DOI 10.1111/1460-6984.12387
   Eisenberg SL, 2013, LANG SPEECH HEAR SER, V44, P20, DOI 10.1044/0161-1461(2012/11-0089)
   Fey M., 1986, LANGUAGE INTERVENTIO
   Fey ME, 2003, AM J SPEECH-LANG PAT, V12, P3, DOI 10.1044/1058-0360(2003/048)
   Fulcher A, 2012, INT J PEDIATR OTORHI, V76, P1785, DOI 10.1016/j.ijporl.2012.09.001
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   Gathercole SE, 2006, APPL PSYCHOLINGUIST, V27, P599, DOI 10.1017/S014271640606053X
   Gathercole SE, 2006, APPL PSYCHOLINGUIST, V27, P513, DOI 10.1017/S0142716406060383
   Geers A., 2015, J SPEECH LANG HEAR R, DOI [10.1044/2015_jsIhr-h-14-0173, DOI 10.1044/2015_JSIHR-H-14-0173]
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   GILBERTSON M, 1995, J SPEECH HEAR RES, V38, P630, DOI 10.1044/jshr.3803.630
   Guasti MT, 2014, APPL PSYCHOLINGUIST, V35, P739, DOI 10.1017/S0142716412000562
   Hammer A, 2014, LINGUA, V139, P68, DOI 10.1016/j.lingua.2013.11.010
   Hansson K, 2000, J SPEECH LANG HEAR R, V43, P848, DOI 10.1044/jslhr.4304.848
   Hansson K, 2003, LINGUISTICS, V41, P351, DOI 10.1515/ling.2003.012
   Hansson K., 2014, INT J LANG COMM DIS, V49, P407
   Hansson K, 2007, INT J LANG COMM DIS, V42, P307, DOI 10.1080/13682820600933526
   Hawker K, 2008, EAR HEARING, V29, P467, DOI 10.1097/AUD.0b013e318167b857
   Ibertsson T, 2008, LOGOP PHONIATR VOCO, V33, P168, DOI 10.1080/14015430801945299
   KAIL R, 1994, J SPEECH HEAR RES, V37, P418, DOI 10.1044/jshr.3702.418
   Kalnak N, 2012, GENES BRAIN BEHAV, V11, P921, DOI 10.1111/j.1601-183X.2012.00841.x
   Kalnak N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089544
   Kral A, 2016, LANCET NEUROL, V15, P610, DOI 10.1016/S1474-4422(16)00034-X
   Law J, 2000, INT J LANG COMM DIS, V35, P165, DOI 10.1080/136828200247133
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   Leonard Laurence B, 2004, Lang Acquis, V12, P219, DOI 10.1207/s15327817la1203&4_3
   Leonard LB, 2007, J SPEECH LANG HEAR R, V50, P408, DOI 10.1044/1092-4388(2007/029)
   Leonard LB, 2014, CHILDREN WITH SPECIFIC LANGUAGE IMPAIRMENT, 2ND EDITION, P1
   Locke JL, 1997, BRAIN LANG, V58, P265, DOI 10.1006/brln.1997.1791
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   Lyberg-Ahlander V, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00871
   Marchman VA, 1999, J SPEECH LANG HEAR R, V42, P206, DOI 10.1044/jslhr.4201.206
   Metsala JL, 1999, J EDUC PSYCHOL, V91, P3, DOI 10.1037/0022-0663.91.1.3
   Montgomery JW, 2010, AM J SPEECH-LANG PAT, V19, P78, DOI 10.1044/1058-0360(2009/09-0028)
   Montgomery JW, 2009, J SPEECH LANG HEAR R, V52, P269, DOI 10.1044/1092-4388(2008/07-0116)
   Moore BCJ, 2003, OTOL NEUROTOL, V24, P243, DOI 10.1097/00129492-200303000-00019
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nittrouer S, 2014, AM J SPEECH-LANG PAT, V23, P679, DOI 10.1044/2014_AJSLP-14-0040
   Perkins M., 2007, PRAGMATIC IMPAIRMENT
   Peterson NR, 2010, RESTOR NEUROL NEUROS, V28, P237, DOI 10.3233/RNN-2010-0535
   Redmond SM, 2011, J SPEECH LANG HEAR R, V54, P99, DOI 10.1044/1092-4388(2010/10-0010)
   Reilly S, 2014, INT J LANG COMM DIS, V49, P452, DOI 10.1111/1460-6984.12111
   Reilly S, 2014, INT J LANG COMM DIS, V49, P416, DOI 10.1111/1460-6984.12102
   Rice ML, 1996, J SPEECH HEAR RES, V39, P1239, DOI 10.1044/jshr.3906.1239
   Sahlen B, 1999, INT J LANG COMM DIS, V34, P337, DOI 10.1080/136828299247441
   Sahlen B, 1999, CLIN LINGUIST PHONET, V13, P369
   Sahlen B., 2018, EVIDENCE BASED INTER
   Sandgren O, 2014, J SPEECH LANG HEAR R, V57, P942, DOI 10.1044/2013_JSLHR-L-12-0333
   Schorr E. A., 2008, COMMUN DISORD Q, V29, P195, DOI DOI 10.1177/1525740108321217
   Spencer Patricia E, 2004, J Deaf Stud Deaf Educ, V9, P395, DOI 10.1093/deafed/enh033
   Stokes SF, 2009, J SPEECH LANG HEAR R, V52, P872, DOI 10.1044/1092-4388(2009/08-0030)
   Svirsky MA, 2002, ANN OTO RHINOL LARYN, V111, P109
   Szagun G, 2004, J CHILD LANG, V31, P1, DOI 10.1017/S0305000903005889
   Tobey EA, 2012, J AM ACAD AUDIOL, V23, P438, DOI 10.3766/jaaa.23.6.6
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Vugs B, 2016, CHILD NEUROPSYCHOL, V22, P955, DOI 10.1080/09297049.2015.1058348
   Wass Malin, 2010, Cochlear Implants Int, V11 Suppl 1, P395, DOI 10.1179/146701010X12671178103751
   Wass M, 2008, SCAND J PSYCHOL, V49, P559, DOI 10.1111/j.1467-9450.2008.00680.x
   Weismer SE, 2000, J SPEECH LANG HEAR R, V43, P865, DOI 10.1044/jslhr.4304.865
   Willstedt-Svensson U, 2004, INT J AUDIOL, V43, P506, DOI 10.1080/14992020400050065
   World Health Organization, 2010, ICD 10 INT STAT CLAS
   Young GA, 2002, ANN OTO RHINOL LARYN, V111, P802, DOI 10.1177/000348940211100908
NR 89
TC 1
Z9 1
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0024-3841
EI 1872-6135
J9 LINGUA
JI Lingua
PD OCT
PY 2018
VL 213
BP 63
EP 77
DI 10.1016/j.lingua.2018.07.001
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA GW1OS
UT WOS:000446649500004
OA Other Gold
DA 2021-02-24
ER

PT J
AU Hertrich, I
   Dietrich, S
   Ackermann, H
AF Hertrich, Ingo
   Dietrich, Susanne
   Ackermann, Hermann
TI Cortical phase locking to accelerated speech in blind and sighted
   listeners prior to and after training
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Magnetoencephalography; Auditory processing; Speech perception;
   Blindness; Speech rate; Phase locking
ID SUPPLEMENTARY MOTOR AREA; PRIMARY VISUAL-CORTEX; HUMAN AUDITORY-CORTEX;
   CONGENITALLY BLIND; FUSIFORM GYRUS; ULTRA-FAST; LANGUAGE; PERCEPTION;
   PATTERNS; SIGNAL
AB Cross-correlation of magnetoencephalography (MEG) with time courses derived from the speech signal has shown differences in phase-locking between blind subjects able to comprehend accelerated speech and sighted controls. The present training study contributes to disentangle the effects of blindness and training. Both subject groups (baseline: n = 16 blind, 13 sighted; trained: 10 blind, 3 sighted) were able to enhance speech comprehension up to ca. 18 syllables per second. MEG responses phase-locked to syllable onsets were captured in five pre-defined source locations comprising left and right auditory cortex (A1), right visual cortex (V1), left inferior frontal gyrus (IFG) and left pre-supplementary motor area. Phase locking in A1 was consistently increased while V1 showed opposite training effects in blind and sighted subjects. Also the IFG showed some group differences indicating enhanced top-down strategies in sighted subjects while blind subjects may have a more fine-grained bottom-up resolution for accelerated speech.
C1 [Hertrich, Ingo; Ackermann, Hermann] Univ Tubingen, Hertie Inst Clin Brain Res, Dept Neurol, Tubingen, Germany.
   [Dietrich, Susanne] Univ Tubingen, Dept Psychol Evolutionary Cognit Cognit Sci, Tubingen, Germany.
RP Hertrich, I (corresponding author), Univ Tubingen, Hertie Inst Clin Brain Res, Ctr Neurol, Hoppe Seyler Str 3, D-72076 Tubingen, Germany.
EM ingo.hertrich@uni-tuebingen.de
RI Hertrich, Ingo/T-1154-2018
OI Hertrich, Ingo/0000-0001-8965-6249
FU German Research Foundation (DFG)German Research Foundation (DFG) [HE
   1573/6-2]; Hertie Institute for Clinical Brain Research, Tubingen
FX This study was supported by the German Research Foundation (DFG; HE
   1573/6-2) and the Hertie Institute for Clinical Brain Research,
   Tubingen. The authors would like to thank Maike Borutta and Fotini
   Scherer for excellent technical assistance, Jurgen Dax for the
   implementation and maintenance of a precisely timed acoustic stimulus
   presentation device, and Inka Rosel and Lisa Wang for helpful advice and
   discussions regarding statistical analysis.
CR Aarts E, 2015, BMC NEUROSCI, V16, DOI 10.1186/s12868-015-0228-5
   Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Abrams DA, 2009, J NEUROSCI, V29, P7686, DOI 10.1523/JNEUROSCI.5242-08.2009
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Amedi A, 2004, NAT NEUROSCI, V7, P1266, DOI 10.1038/nn1328
   Bedny M, 2015, J NEUROSCI, V35, P11674, DOI 10.1523/JNEUROSCI.0634-15.2015
   Bedny M, 2012, BRAIN LANG, V122, P162, DOI 10.1016/j.bandl.2011.10.005
   Buchel C, 2003, NAT NEUROSCI, V6, P657, DOI 10.1038/nn0703-657
   Buchel C, 1998, BRAIN, V121, P409, DOI 10.1093/brain/121.3.409
   BULL R, 1983, PERCEPTION, V12, P223, DOI 10.1068/p120223
   Chao HHA, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-75
   Crouzet O., 2007, MATH SOC SCI, V180, P57, DOI [10.4000/msh.7813, DOI 10.4000/MSH.7813]
   Deng SY, 2010, BRAIN RES, V1346, P132, DOI 10.1016/j.brainres.2010.05.027
   Dietrich S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132196
   Dietrich S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122863
   Dietrich S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00701
   Dietrich S, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-74
   Elbert T, 2002, J NEUROSCI, V22, P9941
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Forstmeier W, 2011, BEHAV ECOL SOCIOBIOL, V65, P47, DOI 10.1007/s00265-010-1038-5
   Gelman A, 2008, STAT MED, V27, P2865, DOI 10.1002/sim.3107
   Gougoux F, 2009, NEUROPSYCHOLOGIA, V47, P2967, DOI 10.1016/j.neuropsychologia.2009.06.027
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Hertrich I, 2002, NEUROPSYCHOLOGIA, V40, P1902, DOI 10.1016/S0028-3932(02)00063-5
   Hertrich I, 2016, NEUROSCI BIOBEHAV R, V68, P602, DOI 10.1016/j.neubiorev.2016.06.030
   Hertrich I, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00530
   Hertrich I, 2013, BRAIN LANG, V124, P9, DOI 10.1016/j.bandl.2012.10.006
   Hertrich I, 2012, PSYCHOPHYSIOLOGY, V49, P322, DOI 10.1111/j.1469-8986.2011.01314.x
   Hertrich I, 2009, NEUROCASE, V15, P163, DOI 10.1080/13554790802709054
   Karnekull SC, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01450
   Korzyukov O, 2007, NEUROIMAGE, V35, P814, DOI 10.1016/j.neuroimage.2006.12.011
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010
   Leh SE, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/789539
   Lerner Y, 2014, J NEUROPHYSIOL, V111, P2433, DOI 10.1152/jn.00497.2013
   Li QJ, 2017, BRAIN IMAGING BEHAV, V11, P1029, DOI 10.1007/s11682-016-9576-8
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   Macaluso E, 2005, TRENDS NEUROSCI, V28, P264, DOI 10.1016/j.tins.2005.03.008
   NIEMEYER W, 1981, AUDIOLOGY, V20, P510
   Nilsson ME, 2016, HEARING RES, V332, P223, DOI 10.1016/j.heares.2015.09.012
   Penhune VB, 2003, NEUROIMAGE, V20, P1215, DOI 10.1016/S1053-8119(03)00373-2
   Poldrack RA, 2001, J COGNITIVE NEUROSCI, V13, P687, DOI 10.1162/089892901750363235
   Qin W, 2015, CEREB CORTEX, V25, P2507, DOI 10.1093/cercor/bhu051
   Roder B, 2002, EUR J NEUROSCI, V16, P930, DOI 10.1046/j.1460-9568.2002.02147.x
   Roder B, 1999, NEUROSCI LETT, V264, P53, DOI 10.1016/S0304-3940(99)00182-2
   Roder B, 2013, P NATL ACAD SCI USA, V110, P16760, DOI 10.1073/pnas.1309963110
   Schielzeth H, 2009, BEHAV ECOL, V20, P416, DOI 10.1093/beheco/arn145
   Stevens AA, 2005, NEUROPSYCHOLOGIA, V43, P1901, DOI 10.1016/j.neuropsychologia.2005.03.007
   Stevens AA, 2007, J NEUROSCI, V27, P10734, DOI 10.1523/JNEUROSCI.1669-07.2007
   Stevens AA, 2009, BEHAV BRAIN RES, V196, P134, DOI 10.1016/j.bbr.2008.07.041
   Tal I, 2017, J NEUROSCI, V37, P6331, DOI 10.1523/JNEUROSCI.2500-16.2017
   TROUVAIN J, 2007, SAARLAND WORKING PAP, V1, P5
   Vagharchakian L, 2012, J NEUROSCI, V32, P9089, DOI 10.1523/JNEUROSCI.5685-11.2012
   Watanabe T, 2015, J NEUROSCI, V35, P4813, DOI 10.1523/JNEUROSCI.3761-14.2015
   Watkins KE, 2012, BRAIN, V135, P1566, DOI 10.1093/brain/aws067
NR 56
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD OCT
PY 2018
VL 185
BP 19
EP 29
DI 10.1016/j.bandl.2018.07.002
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA GU9ZL
UT WOS:000445715700003
PM 30025355
DA 2021-02-24
ER

PT J
AU Dorsi, J
   Viswanathan, N
   Rosenblum, LD
   Dias, JW
AF Dorsi, Josh
   Viswanathan, Navin
   Rosenblum, Lawrence D.
   Dias, James W.
TI The role of speech fidelity in the irrelevant sound effect: Insights
   from noise-vocoded speech backgrounds
SO QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE Irrelevant sound effect; noise-vocoded speech; speech perception
ID SHORT-TERM-MEMORY; AUDITORY DISTRACTION; UNATTENDED SPEECH; DISRUPTION;
   INFORMATION; NUMBER
AB The Irrelevant Sound Effect (ISE) is the finding that background sound impairs accuracy for visually presented serial recall tasks. Among various auditory backgrounds, speech typically acts as the strongest distractor. Based on the changing-state hypothesis, speech is a disruptive background because it is more complex than other nonspeech backgrounds. In the current study, we evaluate an alternative explanation by examining whether the speech-likeness of the background (speech fidelity) contributes, beyond signal complexity, to the ISE. We did this by using noise-vocoded speech as a background. In Experiment 1, we varied the complexity of the background by manipulating the number of vocoding channels. Results indicate that the ISE increases with the number of channels, suggesting that more complex signals produce greater ISEs. In Experiment 2, we varied complexity and speech fidelity independently. At each channel level, we selectively reversed a subset of channels to design a low-fidelity signal that was equated in overall complexity. Experiment 2 results indicated that speech-like noise-vocoded speech produces a larger ISE than selectively reversed noise-vocoded speech. Finally, in Experiment 3, we evaluated the locus of the speech-fidelity effect by assessing the distraction produced by these stimuli in a missing-item task. In this task, even though noise-vocoded speech disrupted task performance relative to silence, neither its complexity nor speech fidelity contributed to this effect. Together, these findings indicate a clear role for speech fidelity of the background beyond its changing-state quality and its attention capture potential.
C1 [Dorsi, Josh; Rosenblum, Lawrence D.; Dias, James W.] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Viswanathan, Navin] Univ Kansas, Lawrence, KS 66045 USA.
RP Dorsi, J (corresponding author), Univ Calif Riverside, Dept Psychol, 900 Univ Ave, Riverside, CA 92521 USA.
EM jdors002@ucr.edu
FU NIDCD grant [R15 DC011875-01]; NSF grantNational Science Foundation
   (NSF) [1632530]
FX The authors disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: This research
   was supported by NIDCD grant R15 DC011875-01 to NV and NSF grant 1632530
   to LDR.
CR Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   Buchner A, 2004, MEM COGNITION, V32, P722, DOI 10.3758/BF03195862
   COLLE HA, 1976, J VERB LEARN VERB BE, V15, P17, DOI 10.1016/S0022-5371(76)90003-7
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Ellermeier W, 2015, J ACOUST SOC AM, V138, P1561, DOI 10.1121/1.4928954
   Ellermeier W, 2014, ACOUST SCI TECHNOL, V35, P10, DOI 10.1250/ast.35.10
   Elliott EM, 2016, J MEM LANG, V88, P39, DOI 10.1016/j.jml.2015.12.008
   Elliott EM, 2012, ACTA PSYCHOL, V140, P64, DOI 10.1016/j.actpsy.2012.02.009
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Hughes RW, 2007, J EXP PSYCHOL LEARN, V33, P1050, DOI 10.1037/0278-7393.33.6.1050
   Hughes RW, 2017, J EXP PSYCHOL LEARN, V43, P537, DOI 10.1037/xlm0000325
   Hughes RW, 2014, PSYCH J, V3, P30, DOI 10.1002/pchj.44
   Jones D. M., 1993, ATTENTION SELECTION, P87, DOI DOI 10.1037/A0017008
   JONES DM, 1990, APPL COGNITIVE PSYCH, V4, P89, DOI 10.1002/acp.2350040203
   JONES DM, 1993, J EXP PSYCHOL LEARN, V19, P369, DOI 10.1037/0278-7393.19.2.369
   Jones DM, 2004, J EXP PSYCHOL LEARN, V30, P656, DOI 10.1037/0278-7393.30.3.656
   Larsen JD, 2000, MEMORY, V8, P145, DOI 10.1080/096582100387579
   Loizou PC, 1999, J ACOUST SOC AM, V106, P2097, DOI 10.1121/1.427954
   Macken B, 2014, PSYCH J, V3, P4, DOI 10.1002/pchj.46
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Roer JP, 2013, J COGN PSYCHOL, V25, P925, DOI 10.1080/20445911.2013.828063
   SALAME P, 1987, ERGONOMICS, V30, P1185, DOI 10.1080/00140138708966007
   SALAME P, 1989, Q J EXP PSYCHOL-A, V41, P107, DOI 10.1080/14640748908402355
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Schlittmeier SJ, 2012, ATTEN PERCEPT PSYCHO, V74, P194, DOI 10.3758/s13414-011-0230-7
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sundara M, 2001, NEUROREPORT, V12, P1341, DOI 10.1097/00001756-200105250-00010
   Tremblay S, 2000, J EXP PSYCHOL LEARN, V26, P1750, DOI 10.1037/0278-7393.26.6.1750
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   Viswanathan N, 2014, Q J EXP PSYCHOL, V67, P581, DOI 10.1080/17470218.2013.821708
   Wostmann M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00538
NR 31
TC 4
Z9 4
U1 0
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1747-0218
EI 1747-0226
J9 Q J EXP PSYCHOL
JI Q. J. Exp. Psychol.
PD OCT
PY 2018
VL 71
IS 10
BP 2152
EP 2161
DI 10.1177/1747021817739257
PG 10
WC Psychology, Biological; Physiology; Psychology; Psychology, Experimental
SC Psychology; Physiology
GA GU0YV
UT WOS:000444981700009
PM 30226434
DA 2021-02-24
ER

PT J
AU Song, J
   Iverson, P
AF Song, Jieun
   Iverson, Paul
TI Listening effort during speech perception enhances auditory and lexical
   processing for non-native listeners and accents
SO COGNITION
LA English
DT Article
DE Listening effort; Non-native language (L2) speech recognition; Cognitive
   load; Entrainment to the speech envelope; N400; Accent processing
ID SINGLE-TRIAL EEG; COCKTAIL PARTY; SPOKEN WORDS; LANGUAGE COMPREHENSION;
   FOREIGN ACCENT; PHASE PATTERNS; RECOGNITION; RESPONSES; CORTEX;
   ATTENTION
AB Speech communication in a non-native language (L2) can feel effortful, and the present study suggests that this effort affects both auditory and lexical processing. EEG recordings (electroencephalography) were made from native English (L1) and Korean listeners while they listened to English sentences spoken with two accents (English and Korean) in the presence of a distracting talker. Neural entrainment (i.e., phase locking between the EEG recording and the speech amplitude envelope) was measured for target and distractor talkers. L2 listeners had relatively greater entrainment for target talkers than did L1 listeners, likely because their difficulty with L2 speech recognition caused them to focus more attention on the speech signal. N400 was measured for the final word in each sentence, and L2 listeners had greater lexical processing in high-predictability sentences than did L1 listeners. L1 listeners had greater target-talker entrainment when listening to the more difficult L2 accent than their own L1 accent, and similarly had larger N400 responses for the L2 accent. It thus appears that the increased effort of L2 listeners, as well as L1 listeners understanding L2 speech, modulates their auditory and lexical processing during speech recognition. This may provide a mechanism to compensate for their perceptual challenges under adverse conditions.
C1 [Song, Jieun; Iverson, Paul] UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
RP Song, J (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
EM jieun.song@ucl.ac.uk
FU Economic and Social Research Council of the UKUK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC); Kwanjeong Educational
   Foundation of South Korea
FX We thank G. Borghini and K. McCarthy for comments on the manuscript.
   This study was supported by the Economic and Social Research Council of
   the UK and the Kwanjeong Educational Foundation of South Korea.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aydelott J, 2006, PSYCHOPHYSIOLOGY, V43, P454, DOI 10.1111/j.1469-8986.2006.00448.x
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bonte M, 2006, CEREB CORTEX, V16, P115, DOI 10.1093/cercor/bhi091
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Calandruccio L, 2012, J SPEECH LANG HEAR R, V55, P1342, DOI 10.1044/1092-4388(2012/11-0260)
   Carey D, 2014, NEUROPSYCHOLOGIA, V65, P102, DOI 10.1016/j.neuropsychologia.2014.10.016
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Flege JE, 1992, PHONOLOGICAL DEV MOD, P565
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hagoort P, 2008, PHILOS T R SOC B, V363, P1055, DOI 10.1098/rstb.2007.2159
   Hahne A, 2001, J PSYCHOLINGUIST RES, V30, P251, DOI 10.1023/A:1010490917575
   Hahne A., 2001, BILING-LANG COGN, V4, P123, DOI DOI 10.1017/S1366728901000232
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Haufe S, 2014, NEUROIMAGE, V87, P96, DOI 10.1016/j.neuroimage.2013.10.067
   Howard MF, 2010, J NEUROPHYSIOL, V104, P2500, DOI 10.1152/jn.00251.2010
   Imai S, 2005, J ACOUST SOC AM, V117, P896, DOI 10.1121/1.1823291
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Kong YY, 2015, JARO-J ASSOC RES OTO, V16, P783, DOI 10.1007/s10162-015-0540-x
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2015, J ACOUST SOC AM, V137, P1464, DOI 10.1121/1.4913507
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   McQueen JM, 2012, J ACOUST SOC AM, V131, P509, DOI 10.1121/1.3664087
   Mirman D, 2008, COGNITIVE SCI, V32, P398, DOI 10.1080/03640210701864063
   Molloy K, 2015, J NEUROSCI, V35, P16046, DOI 10.1523/JNEUROSCI.2931-15.2015
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Obleser J, 2011, NEUROIMAGE, V55, P713, DOI 10.1016/j.neuroimage.2010.12.020
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Pinet M, 2011, J ACOUST SOC AM, V130, P1653, DOI 10.1121/1.3613698
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   Romero-Rivas C, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.7015.00167, 10.3389/fnhum.2015.00167]
   Stowe L., 2005, IRAL-INT REV APPL LI, V43, P329, DOI DOI 10.1515/IRAL.2005.43.4.329
   Stringer L. M., 2015, THESIS
   van Wijngaarden SJ, 2002, J ACOUST SOC AM, V112, P3004, DOI 10.1121/1.1512289
   VANPETTEN C, 1990, MEM COGNITION, V18, P380, DOI 10.3758/BF03197127
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
NR 58
TC 12
Z9 11
U1 1
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD OCT
PY 2018
VL 179
BP 163
EP 170
DI 10.1016/j.cognition.2018.06.001
PG 8
WC Psychology, Experimental
SC Psychology
GA GR5TM
UT WOS:000442704800013
PM 29957515
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kosem, A
   Bosker, HR
   Takashima, A
   Meyer, A
   Jensen, O
   Hagoort, P
AF Kosem, Anne
   Bosker, Hans Rutger
   Takashima, Atsuko
   Meyer, Antje
   Jensen, Ole
   Hagoort, Peter
TI Neural Entrainment Determines the Words We Hear
SO CURRENT BIOLOGY
LA English
DT Article
ID AUDITORY-CORTEX; SPEECH RATE; NEURONAL OSCILLATIONS; CORTICAL
   ENTRAINMENT; PHASE ENTRAINMENT; PERCEPTION; RESPONSES; TRACKING;
   LATERALIZATION; COMPREHENSION
AB Low-frequency neural entrainment to rhythmic input has been hypothesized as a canonical mechanism that shapes sensory perception in time. Neural entrainment is deemed particularly relevant for speech analysis, as it would contribute to the extraction of discrete linguistic elements from continuous acoustic signals. However, its causal influence in speech perception has been difficult to establish. Here, we provide evidence that oscillations build temporal predictions about the duration of speech tokens that affect perception. Using magnetoencephalography (MEG), we studied neural dynamics during listening to sentences that changed in speech rate. We observed neural entrainment to preceding speech rhythms persisting for several cycles after the change in rate. The sustained entrainment was associated with changes in the perceived duration of the last word's vowel, resulting in the perception of words with different meanings. These findings support oscillatory models of speech processing, suggesting that neural oscillations actively shape speech perception.
C1 [Kosem, Anne; Bosker, Hans Rutger; Takashima, Atsuko; Meyer, Antje; Hagoort, Peter] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Kosem, Anne; Bosker, Hans Rutger; Takashima, Atsuko; Meyer, Antje; Jensen, Ole; Hagoort, Peter] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Kosem, Anne] Univ Claude Bernard Lyon 1, CNRS UMR5292, INSERM U1028, Brain Dynam & Cognit Team,CRNL, Lyon, France.
   [Jensen, Ole] Univ Birmingham, Ctr Human Brain Hlth, Birmingham, W Midlands, England.
RP Kosem, A (corresponding author), Max Planck Inst Psycholinguist, Nijmegen, Netherlands.; Kosem, A (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.; Kosem, A (corresponding author), Univ Claude Bernard Lyon 1, CNRS UMR5292, INSERM U1028, Brain Dynam & Cognit Team,CRNL, Lyon, France.
EM anne.kosem@inserm.fr
RI Hagoort, Peter/B-7417-2012; Jensen, Ole/D-2120-2010; Kosem,
   Anne/M-2344-2019
OI Jensen, Ole/0000-0001-8193-8348; Kosem, Anne/0000-0002-2692-9999;
   Bosker, Hans Rutger/0000-0002-2628-7738
FU Netherlands Organisation for Scientific Research (NWO)Netherlands
   Organization for Scientific Research (NWO) [24.001.006]; Royal
   Netherlands Academy of Arts and Sciences; James S. McDonnell Foundation
   [220020448]; Welcome TrustWellcome Trust [207550]; Royal Society Wolfson
   Research Merit AwardRoyal Society of London
FX We would like to thank Annelies van Wijngaarden for the recordings of
   her voice and Anne van Hoek for help with pretesting. This research was
   supported by the Netherlands Organisation for Scientific Research (NWO)
   Gravitation Grant 24.001.006 to the Language in Interaction Consortium,
   the NWO Spinoza Prize, the Academy Professorship Award of the Royal
   Netherlands Academy of Arts and Sciences to P.H., the James S. McDonnell
   Foundation grant 220020448, the Welcome Trust grant 207550, and the
   Royal Society Wolfson Research Merit Award to O.J.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Alagapan S, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002424
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Belin P, 1998, J COGNITIVE NEUROSCI, V10, P536, DOI 10.1162/089892998562834
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   BOERSMA P, 2007, PRAAT
   Bosker HR, 2017, INTERSPEECH, P2416, DOI 10.21437/Interspeech.2017-73
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442
   Breska A, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001665
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2009, J NEUROPHYSIOL, V102, P2731, DOI 10.1152/jn.00523.2009
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Falk S, 2017, J COGNITIVE NEUROSCI, V29, P1378, DOI 10.1162/jocn_a_01136
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Herrmann B, 2016, NEUROIMAGE, V124, P487, DOI 10.1016/j.neuroimage.2015.09.019
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   Holt LL, 2002, HEARING RES, V167, P156, DOI 10.1016/S0378-5955(02)00383-0
   Hyafil A, 2015, ELIFE, V4, DOI 10.7554/eLife.06213
   Kayser SJ, 2015, J NEUROSCI, V35, P14691, DOI 10.1523/JNEUROSCI.2243-15.2015
   Kosem A, 2014, NEUROIMAGE, V92, P274, DOI 10.1016/j.neuroimage.2014.02.010
   Kosem A., 2016, LANG COGN NEUROSCI, V32
   Kosem A, 2016, J NEUROPHYSIOL, V116, P2497, DOI 10.1152/jn.00074.2016
   Lafon B, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01045-x
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   Morillon B, 2015, ANN NY ACAD SCI, V1337, P26, DOI 10.1111/nyas.12629
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Obleser J, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00250
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Scott SK, 2013, BRAIN LANG, V127, P36, DOI 10.1016/j.bandl.2013.07.006
   Spaak E, 2014, J NEUROSCI, V34, P3536, DOI 10.1523/JNEUROSCI.4385-13.2014
   ten Oever S, 2015, P NATL ACAD SCI USA, V112, P15833, DOI 10.1073/pnas.1517519112
   Teng XB, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2000812
   Thut G, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00170
   VanRullen R, 2016, TRENDS COGN SCI, V20, P723, DOI 10.1016/j.tics.2016.07.006
   Wilsch A., 2017, BIORXIV, DOI [10.1101/097576, DOI 10.1101/097576]
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zoefel B, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00095
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
   Zoefel B, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00651, 10.1038/NATURE11020]
NR 65
TC 33
Z9 33
U1 0
U2 10
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD SEP 24
PY 2018
VL 28
IS 18
BP 2867
EP +
DI 10.1016/j.cub.2018.07.023
PG 12
WC Biochemistry & Molecular Biology; Biology; Cell Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA GU6JL
UT WOS:000445418500017
PM 30197083
OA Bronze
DA 2021-02-24
ER

PT J
AU Legris, E
   Galvin, J
   Roux, S
   Gomot, M
   Aoustin, JM
   Marx, M
   He, SM
   Bakhos, D
AF Legris, Elsa
   Galvin, John
   Roux, Sylvie
   Gomot, Marie
   Aoustin, Jean-Marie
   Marx, Mathieu
   He, Shuman
   Bakhos, David
TI Cortical reorganization after cochlear implantation for adults with
   single-sided deafness
SO PLOS ONE
LA English
DT Article
ID AUDITORY-EVOKED-POTENTIALS; UNILATERAL HEARING-LOSS; SOUND SOURCE
   LOCALIZATION; EVENT-RELATED POTENTIALS; BONE-ANCHORED HEARING; SIGNAL
   AMPLIFICATION; SPEECH-PERCEPTION; BINAURAL HEARING; RESPONSES; CHILDREN
AB Background
   Adults with single sided deafness (SSD) have lost binaural function, which limits sound source localization, speech understanding in noise, and quality of life. For SSD patients, restoration of bilateral auditory input is possible only with a cochlear implant (CI). In this study, cortical auditory evoked potentials (CAEPs) and behavioral performance were measured in left-implanted (SSD-CI-L) and right-implanted (SSD-CI-R) patients before and after cochlear implantation. We hypothesized that improvements in behavioral performance would be accompanied by changes in CAEPs after cochlear implantation.
   Design
   Prospective longitudinal study.
   Setting
   Tertiary referral center.
   Method
   Nine right-handed adult SSD CI patients participated in the study. CAEPs were recorded before cochlear implantation and at 6 and 12 months post-implantation. CAEPs were elicited using speech stimuli (/ba/) delivered in sound field at 70 dBA. Global field power (GFP) latency and amplitude were calculated for P1, N1 and P2 peaks at each test session. CAEP were analyzed at frontocentral (Cz) and temporal (P7, P8, T7 and T8) and mastoid electrodes (M1 and M2) contralateral to the CI ear. Behavioral measures (sentence recognition in noise, with and without spatial cues) were collected at the same test sessions as for CAEPs. Speech performance and CAEPs were also measured in a control group of normal-hearing (NH) subjects.
   Results
   While increased N1 amplitude was observed in the scalp potential maps for GFP and Cz for SSD-CI-L patients after implantation, the changes were not statistically significant. Peak CAEP amplitude at electrodes to contralateral to the CI ear increased after cochlear implantation for all SSD-CI patients, but significant increases were observed only for mastoid sites. Peak latencies for some components at temporal and mastoid sites remained significantly longer than for the NH control group, even after cochlear implantation. For SSD-CI-R patients, P2 peak amplitude for baseline GFP and Cz was significantly lower than for the NH control group. A significant improvement for speech understanding in noise was observed at 12 months post-implantation when speech was presented to the CI ear and noise to the non-implanted ear.
   Conclusion
   After cochlear implantation, speech understanding significantly improved when speech and noise were spatially separated. The increased N1 amplitude for SSD-CI-L patients and the increased bilateral activation for all SSD-CI patients may reflect cortical reorganization and restoration of binaural function after one year of experience with the CI. However, because of the limited number of SSD patients, significant changes in cortical activity after cochlear implantation were often difficult to observe.
C1 [Legris, Elsa; Roux, Sylvie; Gomot, Marie; Bakhos, David] Univ Francois Rabelais Tours, CHRU Tours, UMR S1253, Tours, France.
   [Legris, Elsa; Aoustin, Jean-Marie; Bakhos, David] Ear Nose & Throat Dept, Tours, France.
   [Galvin, John] House Ear Res Inst, Los Angeles, CA USA.
   [Marx, Mathieu] Ear Nose & Throat Dept, Toulouse, France.
   [He, Shuman] Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
RP Legris, E (corresponding author), Univ Francois Rabelais Tours, CHRU Tours, UMR S1253, Tours, France.; Legris, E (corresponding author), Ear Nose & Throat Dept, Tours, France.
EM legris.elsa@gmail.com
RI Gomot, Marie/N-3135-2016; Roux, Sylvie/N-5655-2016; Bakhos,
   David/P-5827-2016
OI Gomot, Marie/0000-0003-1747-5806; Elsa, Legris/0000-0001-5458-4644;
   Bakhos, David/0000-0003-1417-5082
CR Aguera PE, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/158970
   Arndt S, 2017, HNO, V65, P98, DOI 10.1007/s00106-016-0297-5
   Bakhos D, 2012, INT J PEDIATR OTORHI, V76, P1627, DOI 10.1016/j.ijporl.2012.07.034
   Bilecen D, 2000, NEUROLOGY, V54, P765, DOI 10.1212/WNL.54.3.765
   Cabral F, 2016, INT ARCH OTORHINOLAR, V20, P69, DOI 10.1055/s-0035-1559586
   Canete Oscar M, 2017, Cochlear Implants Int, V18, P335, DOI 10.1080/14670100.2017.1373499
   Ceponiene R, 2008, CLIN NEUROPHYSIOL, V119, P1560, DOI 10.1016/j.clinph.2008.03.005
   Ceponiene R, 2005, PSYCHOPHYSIOLOGY, V42, P391, DOI 10.1111/j.1469-8986.2005.00305.x
   CONNOLLY JF, 1985, PSYCHOPHYSIOLOGY, V22, P87, DOI 10.1111/j.1469-8986.1985.tb01564.x
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   Debener S, 2008, PSYCHOPHYSIOLOGY, V45, P20, DOI 10.1111/j.1469-8986.2007.00610.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Deprez H, 2014, EUR SIGNAL PR CONF, P1995
   Dorman MF, 2016, AUDIOL NEURO-OTOL, V21, P127, DOI 10.1159/000444740
   Firszt JB, 2012, EAR HEARING, V33, P521, DOI 10.1097/AUD.0b013e31824b9dfc
   Fournier J.E., 1951, AUDIOMETRIE VOCALE E
   Fujiki N, 1998, NEUROREPORT, V9, P3129, DOI 10.1097/00001756-199810050-00002
   Giardina CK, 2014, CURR SURG REP, V2, DOI 10.1007/s40137-014-0075-9
   Gordon KA, 2005, NEUROREPORT, V16, P2041, DOI 10.1097/00001756-200512190-00015
   Groenen P, 1996, Audiol Neurootol, V1, P112
   Hanss J, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-23
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Khosla D, 2003, JARO-J ASSOC RES OTO, V4, P235, DOI 10.1007/s10162-002-3014-x
   Kitterick PT, 2015, AUDIOL NEURO-OTOL, V20, P79, DOI 10.1159/000380753
   KNIGHT RT, 1980, ELECTROEN CLIN NEURO, V50, P112, DOI 10.1016/0013-4694(80)90328-4
   KNIGHT RT, 1988, ELECTROEN CLIN NEURO, V70, P499, DOI 10.1016/0013-4694(88)90148-4
   Kral A, 2007, BRAIN RES REV, V56, P259, DOI 10.1016/j.brainresrev.2007.07.021
   Kral A, 2013, BRAIN, V136, P180, DOI 10.1093/brain/aws305
   KRAUS N, 1995, EAR HEARING, V16, P19, DOI 10.1097/00003446-199502000-00003
   LEHMANN D, 1980, ELECTROEN CLIN NEURO, V48, P609, DOI 10.1016/0013-4694(80)90419-8
   Leterme G, 2015, AUDIOL NEURO-OTOL, V20, P251, DOI 10.1159/000381329
   Lieu JEC, 2010, PEDIATRICS, V125, pE1348, DOI 10.1542/peds.2009-2448
   Lin LM, 2006, OTOL NEUROTOL, V27, P172, DOI 10.1097/01.mao.0000196421.30275.73
   Lippe S, 2009, NEUROSCIENCE, V164, P1108, DOI 10.1016/j.neuroscience.2009.07.066
   Lister JJ, 2011, INT J AUDIOL, V50, P211, DOI 10.3109/14992027.2010.526967
   MCCALLUM WC, 1979, HUMAN EVOKED POTENTI, P235, DOI DOI 10.1007/978-1-4684-3483-5_16
   Mertens G, 2016, CLIN OTOLARYNGOL, V41, P511, DOI 10.1111/coa.12555
   Michel CM, 2004, CLIN NEUROPHYSIOL, V115, P2195, DOI 10.1016/j.clinph.2004.06.001
   MOORE DR, 1991, AUDIOLOGY, V30, P125
   Moore DR, 2004, SPR HDB AUD, V23, P96
   MOORE DR, 1990, SEMIN PERINATOL, V14, P294
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Niparko JK, 2003, OTOL NEUROTOL, V24, P73, DOI 10.1097/00129492-200301000-00015
   Penfield W, 1954, EPILEPSY FUNCTIONAL
   PERRAULT N, 1984, ELECTROEN CLIN NEURO, V59, P177, DOI 10.1016/0168-5597(84)90058-3
   PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6
   Petersen B, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00007
   Polonenko MJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17129-z
   Ponton CW, 2001, HEARING RES, V154, P32, DOI 10.1016/S0378-5955(01)00214-3
   Ponton CW, 1996, EAR HEARING, V17, P430, DOI 10.1097/00003446-199610000-00009
   REALE RA, 1987, DEV BRAIN RES, V34, P281, DOI 10.1016/0165-3806(87)90215-X
   Roman S, 2005, HEARING RES, V201, P10, DOI 10.1016/j.heares.2004.08.021
   Ross DS, 2010, EAR HEARING, V31, P126, DOI 10.1097/AUD.0b013e3181bb69db
   Sandmann P, 2015, CLIN NEUROPHYSIOL, V126, P594, DOI 10.1016/j.clinph.2014.06.029
   Scheffler K, 1998, CEREB CORTEX, V8, P156, DOI 10.1093/cercor/8.2.156
   Shafer VL, 2011, CLIN NEUROPHYSIOL, V122, P1137, DOI 10.1016/j.clinph.2010.10.046
   Sharma A, 2016, OTOL NEUROTOL, V37, pE26, DOI 10.1097/MAO.0000000000000904
   Sharma Mridula, 2004, J Am Acad Audiol, V15, P616, DOI 10.3766/jaaa.15.9.3
   Singh S, 2004, EAR HEARING, V25, P598, DOI 10.1097/00003446-200412000-00008
   SKRANDIES W, 1990, Brain Topography, V3, P137, DOI 10.1007/BF01128870
   SPRENG M, 1979, SCAND AUDIOL, P211
   Tavora-Vieira D, 2015, EAR HEARING, V36, pE93, DOI 10.1097/AUD.0000000000000130
   VASAMA JP, 1995, HEARING RES, V87, P132, DOI 10.1016/0378-5955(95)00086-J
   VAUGHAN HG, 1970, ELECTROEN CLIN NEURO, V28, P360, DOI 10.1016/0013-4694(70)90228-2
   Vermeire K, 2009, AUDIOL NEURO-OTOL, V14, P163, DOI 10.1159/000171478
   Vidal J, 2005, NEUROSCI LETT, V378, P145, DOI 10.1016/j.neulet.2004.12.022
   Wagner M, 2017, J SPEECH LANG HEAR R, V60, P2105, DOI 10.1044/2017_JSLHR-H-16-0056
   Wedekind A, 2018, NEUROREPORT, V29, P408, DOI 10.1097/WNR.0000000000000984
   Wong DDE, 2009, IEEE T BIO-MED ENG, V56, P2851, DOI 10.1109/TBME.2009.2029239
   WOOD CC, 1982, ELECTROEN CLIN NEURO, V54, P25, DOI 10.1016/0013-4694(82)90228-0
   Yang M, 2014, HEARING RES, V316, P37, DOI 10.1016/j.heares.2014.07.006
   Zeitler DM, 2015, OTOL NEUROTOL, V36, P1467, DOI 10.1097/MAO.0000000000000841
   [张功成 Zhang Gongcheng], 2014, [天然气工业, Natural Gas Industry], V34, P11
NR 73
TC 7
Z9 7
U1 1
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD SEP 24
PY 2018
VL 13
IS 9
AR e0204402
DI 10.1371/journal.pone.0204402
PG 21
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GV3MI
UT WOS:000445998100036
PM 30248131
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Shearer, AE
   Tejani, VD
   Brown, CJ
   Abbas, PJ
   Hansen, MR
   Gantz, BJ
   Smith, RJH
AF Shearer, A. Eliot
   Tejani, Viral D.
   Brown, Carolyn J.
   Abbas, Paul J.
   Hansen, Marian R.
   Gantz, Bruce J.
   Smith, Richard J. H.
TI In Vivo Electrocochleography in Hybrid Cochlear Implant Users Implicates
   TMPRSS3 in Spiral Ganglion Function
SO SCIENTIFIC REPORTS
LA English
DT Article
ID ROUND WINDOW ELECTROCOCHLEOGRAPHY; NEUROPATHY SPECTRUM DISORDER;
   AUTOSOMAL RECESSIVE DEAFNESS; MULTICENTER CLINICAL-TRIAL; HAIR CELL;
   HEARING PRESERVATION; SPEECH-PERCEPTION; WORD RECOGNITION; OUTCOMES;
   ONSET
AB Cochlear implantation, a surgical method to bypass cochlear hair cells and directly stimulate the spiral ganglion, is the standard treatment for severe-to-profound hearing loss. Changes in cochlear implant electrode array design and surgical approach now allow for preservation of acoustic hearing in the implanted ear. Electrocochleography (ECochG) was performed in eight hearing preservation subjects to assess hair cell and neural function and elucidate underlying genetic hearing loss. Three subjects had pathogenic variants in TMPRSS3 and five had pathogenic variants in genes known to affect the cochlear sensory partition. The mechanism by which variants in TMPRSS3 cause genetic hearing loss is unknown. We used a 500-Hz tone burst to record ECochG responses from an intracochlear electrode. Responses consist of a cochlear microphonic (hair cell) and an auditory nerve neurophonic. Cochlear microphonics did not differ between groups. Auditory nerve neurophonics were smaller, on average, in subjects with TMPRSS3 deafness. Results of this proof-of-concept study provide evidence that pathogenic variants in TMPRSS3 may impact function of the spiral ganglion. While ECochG as a clinical and research tool has been around for decades, this study illustrates a new application of ECochG in the study of genetic hearing and deafness in vivo.
C1 [Shearer, A. Eliot; Tejani, Viral D.; Brown, Carolyn J.; Abbas, Paul J.; Hansen, Marian R.; Gantz, Bruce J.; Smith, Richard J. H.] Univ Iowa, Dept Otolaryngol Head & Neck Surg, Carver Coll Med, Iowa City, IA 52242 USA.
   [Smith, Richard J. H.] Univ Iowa, Interdept PhD Program Genet, Iowa City, IA 52242 USA.
   [Smith, Richard J. H.] Univ Iowa, Coll Med, Dept Mol Physiol & Biophys, Iowa City, IA 52242 USA.
RP Smith, RJH (corresponding author), Univ Iowa, Dept Otolaryngol Head & Neck Surg, Carver Coll Med, Iowa City, IA 52242 USA.; Smith, RJH (corresponding author), Univ Iowa, Interdept PhD Program Genet, Iowa City, IA 52242 USA.; Smith, RJH (corresponding author), Univ Iowa, Coll Med, Dept Mol Physiol & Biophys, Iowa City, IA 52242 USA.
EM richard-smith@uiowa.edu
OI Hansen, Marlan/0000-0002-6884-4897; Smith, Richard/0000-0003-1201-6731;
   Shearer, Aiden/0000-0002-5324-4805; Tejani, Viral/0000-0001-7585-9619;
   Gantz, Bruce/0000-0002-9916-6048
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [RO1 DC003544, RO1 DC002842, RO1
   DC012049, P50 DC000242]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC012049, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, R01DC002842,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC012049, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC012049, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   R01DC003544, P50DC000242, P50DC000242, P50DC000242, R01DC012049,
   P50DC000242, P50DC000242, P50DC000242, R01DC002842, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC012049, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC002842, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   R01DC002842, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC003544] Funding Source: NIH RePORTER
FX This work was supported by NIDCD RO1s DC003544, DC002842 and DC012049 to
   RJHS and NIDCD P50 DC000242 to BJG.
CR Abbas PJ, 2017, EAR HEARING, V38, P409, DOI 10.1097/AUD.0000000000000400
   ABBAS PJ, 1991, HEARING RES, V51, P123, DOI 10.1016/0378-5955(91)90011-W
   Acharya AN, 2016, OTOL NEUROTOL, V37, pE148, DOI 10.1097/MAO.0000000000000950
   Aran J. M, 1976, CLIN VALUE COCHLEAR
   Berlin CI, 2010, INT J AUDIOL, V49, P30, DOI 10.3109/14992020903160892
   BonneTamir B, 1996, AM J HUM GENET, V58, P1254
   Brackmann DE, 2000, AM J OTOL, V21, P417, DOI 10.1016/S0196-0709(00)80054-X
   BROWN CJ, 1995, EAR HEARING, V16, P439, DOI 10.1097/00003446-199510000-00001
   Campbell L, 2016, OTOL NEUROTOL, V37, P332, DOI 10.1097/MAO.0000000000000972
   CARHART R, 1959, J SPEECH HEAR DISORD, V24, P330, DOI 10.1044/jshd.2404.330
   Chung J, 2014, J MOL MED, V92, P651, DOI 10.1007/s00109-014-1128-3
   Fasquelle L, 2011, J BIOL CHEM, V286, P17383, DOI 10.1074/jbc.M110.190652
   Fayad JN, 2006, LARYNGOSCOPE, V116, P1310, DOI 10.1097/01.mlg.0000227176.09500.28
   FERRARO JA, 1989, EAR HEARING, V10, P161, DOI 10.1097/00003446-198906000-00004
   Fitzpatrick DC, 2014, OTOL NEUROTOL, V35, P64, DOI 10.1097/MAO.0000000000000219
   Forgues M, 2014, J NEUROPHYSIOL, V111, P580, DOI 10.1152/jn.00446.2013
   Formeister EJ, 2015, EAR HEARING, V36, P249, DOI 10.1097/AUD.0000000000000106
   Gantz BJ, 2005, LARYNGOSCOPE, V115, P796, DOI 10.1097/01.MLG.0000157695.07536.D2
   Gantz BJ, 2003, LARYNGOSCOPE, V113, P1726, DOI 10.1097/00005537-200310000-00012
   Gantz BJ, 2016, LARYNGOSCOPE, V126, P962, DOI 10.1002/lary.25572
   Gao X, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/4707315
   Ge Shenglei, 2011, Zhong Nan Da Xue Xue Bao Yi Xue Ban, V36, P794, DOI 10.3969/j.issn.1672-7347.2011.08.018
   Guipponi M, 2002, HUM MOL GENET, V11, P2829, DOI 10.1093/hmg/11.23.2829
   Guipponi M, 2008, HUM MUTAT, V29, P130, DOI 10.1002/humu.20617
   HENRY KR, 1995, HEARING RES, V90, P176, DOI 10.1016/0378-5955(95)00162-6
   Jurawitz MC, 2014, AUDIOL NEURO-OTOL, V19, P293, DOI 10.1159/000360601
   Khan AM, 2005, LARYNGOSCOPE, V115, P672, DOI 10.1097/01.mlg.0000161335.62139.80
   Kim JR, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00216
   Kim JR, 2010, OTOL NEUROTOL, V31, P1041, DOI 10.1097/MAO.0b013e3181ec1d92
   Koka K, 2017, EAR HEARING, V38, pE161, DOI 10.1097/AUD.0000000000000385
   Lee YJ, 2003, J MED GENET, V40, P629, DOI 10.1136/jmg.40.8.629
   Lenarz T, 2013, INT J AUDIOL, V52, P838, DOI 10.3109/14992027.2013.802032
   Li YZ, 2014, HEARING RES, V314, P60, DOI 10.1016/j.heares.2014.05.002
   Lichtenhan JT, 2014, JARO-J ASSOC RES OTO, V15, P395, DOI 10.1007/s10162-014-0447-y
   Miyagawa M, 2015, ANN OTOLOGY S, V124s, P193
   Molina L, 2013, HUM MOL GENET, V22, P1289, DOI 10.1093/hmg/dds532
   Nadol JB, 2001, INT J PEDIATR OTORHI, V61, P1, DOI 10.1016/S0165-5876(01)00546-8
   O'Connell B. P, 2017, FRONT NEUROSCI, V11, pe148
   O'Connell BP, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00291
   PATUZZI RB, 1989, HEARING RES, V42, P47, DOI 10.1016/0378-5955(89)90117-2
   PETERSON GE, 1962, J SPEECH HEAR DISORD, V27, P62, DOI 10.1044/jshd.2701.62
   Portmann M, 2016, ANN OTOLOGY RHINOLOG, V92, P621
   Roland JT, 2016, LARYNGOSCOPE, V126, P175, DOI 10.1002/lary.25451
   RUTH RA, 1988, AM J OTOL, V9, P1
   Scheperle R. A, 2013, RELATIONSHIPS PERIPH
   Schoonhoven R, 1995, EAR HEARING, V16, P619, DOI 10.1097/00003446-199512000-00008
   Scott HS, 2001, NAT GENET, V27, P59
   Seyyedi M, 2014, OTOL NEUROTOL, V35, P1446, DOI 10.1097/MAO.0000000000000443
   Shearer AE, 2017, HEARING RES, V348, P138, DOI 10.1016/j.heares.2017.02.008
   Shearer AE, 2013, J MED GENET, V50, P627, DOI 10.1136/jmedgenet-2013-101749
   Sloan-Heggen CM, 2016, HUM GENET, V135, P441, DOI 10.1007/s00439-016-1648-8
   Teagle HFB, 2010, EAR HEARING, V31, P325, DOI 10.1097/AUD.0b013e3181ce693b
   van Eijl RHM, 2017, LARYNGOSCOPE, V127, P476, DOI 10.1002/lary.26154
   Verpy E, 2008, NATURE, V456, P255, DOI 10.1038/nature07380
   Veske A, 1996, HUM MOL GENET, V5, P165, DOI 10.1093/hmg/5.1.165
   Weegerink NJD, 2011, JARO-J ASSOC RES OTO, V12, P753, DOI 10.1007/s10162-011-0282-3
   Zheng XY, 1997, HEARING RES, V113, P76, DOI 10.1016/S0378-5955(97)00127-5
NR 57
TC 5
Z9 5
U1 0
U2 7
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD SEP 21
PY 2018
VL 8
AR 14165
DI 10.1038/s41598-018-32630-9
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GU4SY
UT WOS:000445276000009
PM 30242206
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ishida, M
   Arai, T
   Kashino, M
AF Ishida, Mako
   Arai, Takayuki
   Kashino, Makio
TI Perceptual Restoration of Temporally Distorted Speech in L1 vs. L2:
   Local Time Reversal and Modulation Filtering
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE speech perception; perceptual restoration; temporal processing; locally
   time-reversed speech; modulation filtering; L1; L2
ID PHONEMIC RESTORATION; INTELLIGIBILITY; COMPREHENSION; ORGANIZATION
AB Speech is intelligible even when the temporal envelope of speech is distorted. The current study investigates how native and non-native speakers perceptually restore temporally distorted speech. Participants were native English speakers (NS), and native Japanese speakers who spoke English as a second language (NNS). In Experiment 1, participants listened to "locally time-reversed speech" where every x-ms of speech signal was reversed on the temporal axis. Here, the local time reversal shifted the constituents of the speech signal forward or backward from the original position, and the amplitude envelope of speech was altered as a function of reversed segment length. In Experiment 2, participants listened to "modulation-filtered speech" where the modulation frequency components of speech were low-pass filtered at a particular cut-off frequency. Here, the temporal envelope of speech was altered as a function of cut-off frequency. The results suggest that speech becomes gradually unintelligible as the length of reversed segments increases (Experiment 1), and as a lower cut-off frequency is imposed (Experiment 2). Both experiments exhibit the equivalent level of speech intelligibility across six levels of degradation for native and non-native speakers respectively, which poses a question whether the regular occurrence of local time reversal can be discussed in the modulation frequency domain, by simply converting the length of reversed segments (ms) into frequency (Hz).
C1 [Ishida, Mako; Kashino, Makio] NTT Commun Sci Labs, Atsugi, Kanagawa, Japan.
   [Ishida, Mako] Japan Soc Promot Sci, Tokyo, Japan.
   [Ishida, Mako; Arai, Takayuki] Sophia Univ, Dept Informat & Commun Sci, Tokyo, Japan.
RP Ishida, M (corresponding author), NTT Commun Sci Labs, Atsugi, Kanagawa, Japan.; Ishida, M (corresponding author), Japan Soc Promot Sci, Tokyo, Japan.; Ishida, M (corresponding author), Sophia Univ, Dept Informat & Commun Sci, Tokyo, Japan.
EM mako.ishida.office@gmail.com
FU Japan Society for the Promotion of Science (JSPS)Ministry of Education,
   Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for
   the Promotion of Science [15J00033, 17J00285]
FX This study is supported by the Japan Society for the Promotion of
   Science (JSPS): Grant-in-Aid for JSPS Fellows (15J00033 and 17J00285).
CR Aitchison J., 2012, WORDS MIND INTRO MEN
   Alderson J. C., 2006, DIAGNOSING FOREIGN L
   Arai T, 1998, INT CONF ACOUST SPEE, P933, DOI 10.1109/ICASSP.1998.675419
   Arai T., 1997, P EUR RHOD GREEC, P1011
   BASHFORD JA, 1992, PERCEPT PSYCHOPHYS, V51, P211, DOI 10.3758/BF03212247
   BROADBENT DE, 1954, J EXP PSYCHOL, V47, P191, DOI 10.1037/h0054182
   Brown J.D., 2006, PERSPECTIVES TEACHIN
   Brown J. D., 1995, NEW WAYS TEACHING LI, P124
   Brown J. D., 1982, TESOL CONV HON HAW
   Brown J. D., 1986, RELC J, V17, P59, DOI DOI 10.1177/003368828601700204
   CHERRY C, 1967, NATURE, V214, P1164, DOI 10.1038/2141164a0
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Dalby J., 1986, PHONETIC STRUCTURE F
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Dolch E., 1948, PROBLEMS IN READING
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Grataloup C, 2009, J SPEECH LANG HEAR R, V52, P827, DOI 10.1044/1092-4388(2008/06-0235
   Greenberg S, 1999, SPEECH COMMUN, V29, P159, DOI 10.1016/S0167-6393(99)00050-3
   Greenberg S., 1998, P 5 INT C SPOK LANG, p[74, 0074]
   GREENBERG S, 2001, P 7 EUR C SPEECH COM, P473
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   HOUTGAST T, 1972, J ACOUST SOC AM, V51, P1885, DOI 10.1121/1.1913048
   HUGGINS AWF, 1964, J ACOUST SOC AM, V36, P1055, DOI 10.1121/1.1919151
   HUGGINS AWF, 1975, PERCEPT PSYCHOPHYS, V18, P149, DOI 10.3758/BF03204103
   Ishida M, 2017, INTERSPEECH, P571, DOI 10.21437/Interspeech.2017-83
   Ishida M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3408
   Ishida M, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2479-8
   Ishida M, 2016, COGNITION, V151, P68, DOI 10.1016/j.cognition.2016.03.008
   Johnson K, 2004, SPONTANEOUS SPEECH D, P29
   Kaiser J., 1966, SYSTEM ANALYSIS DIGI
   Kashino M., 1992, Journal of the Acoustical Society of Japan, V48, P76
   Kashino M, 1994, P INT C SPOK LANG PR, P2047
   Kashino M., 1992, ICSLP 1992, P1079
   Kashino M, 2006, ACOUST SCI TECHNOL, V27, P318, DOI 10.1250/ast.27.318
   Kiss M, 2008, ACTA NEUROBIOL EXP, V68, P204
   Lancaster University, 2014, DIALANG
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Magrin-Chagnolleau I., 2002, P 7 INT C SPOK LANG, V3, P1669
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   Mattys SL, 2014, PSYCHON B REV, V21, P748, DOI 10.3758/s13423-013-0544-7
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MILLER GA, 1963, J VERB LEARN VERB BE, V2, P217, DOI 10.1016/S0022-5371(63)80087-0
   Nation ISP, 2006, CAN MOD LANG REV, V63, P59, DOI 10.3138/cmlr.63.1.59
   Nation I. S. P., 2001, LEARNING VOCABULARY, DOI [10.1017/CBO9781139524759, DOI 10.1017/CBO9781139524759]
   Nation P., 1992, READING FOREIGN LANG, V8, P689
   Oppenheim A., 1999, DISCRETE TIME SIGNAL
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Rabiner L.R., 1975, THEORY APPL DIGITAL
   Remez RE, 2013, ATTEN PERCEPT PSYCHO, V75, P1353, DOI 10.3758/s13414-013-0542-x
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Samuel AG, 1996, J EXP PSYCHOL GEN, V125, P28, DOI 10.1037/0096-3445.125.1.28
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   SAMUEL AG, 1981, J EXP PSYCHOL HUMAN, V7, P1124, DOI 10.1037/0096-1523.7.5.1124
   Samuel AG, 2015, PSYCHON B REV, V22, P1746, DOI 10.3758/s13423-015-0847-y
   Saragi T., 1978, SYSTEM, V6, P72, DOI DOI 10.1016/0346-251X(78)90027-1
   STEFFEN A, 1994, SPRECHWISSENSCHAFT P, V6, P189
   Stilp CE, 2010, J ACOUST SOC AM, V128, P2112, DOI 10.1121/1.3483719
   Tinkham T., 1993, SYSTEM, V21, P371, DOI DOI 10.1016/0346-251X(93)90027-E
   TREISMAN AM, 1969, PSYCHOL REV, V76, P282, DOI 10.1037/h0027242
   Ueda K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01831-z
   WARREN RM, 1974, PERCEPT PSYCHOPHYS, V16, P150, DOI 10.3758/BF03203268
   WARREN RM, 1970, SCI AM, V223, P30, DOI 10.1038/scientificamerican1270-30
   WARREN RM, 1972, SCIENCE, V176, P1149, DOI 10.1126/science.176.4039.1149
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   WARREN RM, 1971, PERCEPT PSYCHOPHYS, V9, P358, DOI 10.3758/BF03212667
   Wickham P. J., 2013, LISTEN WRITE READ SE
NR 69
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 19
PY 2018
VL 9
AR 1749
DI 10.3389/fpsyg.2018.01749
PG 16
WC Psychology, Multidisciplinary
SC Psychology
GA GU2EQ
UT WOS:000445082600002
PM 30283390
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Breshears, JD
   Hamilton, LS
   Chang, EF
AF Breshears, Jonathan D.
   Hamilton, Liberty S.
   Chang, Edward F.
TI Spontaneous Neural Activity in the Superior Temporal Gyrus Recapitulates
   Tuning for Speech Features
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE electrocorticography (ECoG); speech perception; high gamma activity;
   resting state networks; spatiotemporal dynamics
ID AUDITORY-CORTEX; FUNCTIONAL ARCHITECTURE; CORTICAL REPRESENTATION;
   NETWORKS; COMPREHENSION; ORGANIZATION; PERCEPTION; BRAIN
AB Background: Numerous studies have demonstrated that individuals exhibit structured neural activity in many brain regions during rest that is also observed during different tasks, however it is still not clear whether and how resting state activity patterns may relate to underlying tuning for specific stimuli. In the posterior superior temporal gyrus (STG), distinct neural activity patterns are observed during the perception of specific linguistic speech features. We hypothesized that spontaneous resting-state neural dynamics of the STG would be structured to reflect its role in speech perception, exhibiting an organization along speech features as seen during speech perception.
   Methods: Human cortical local field potentials were recorded from the superior temporal gyrus (STG) in 8 patients undergoing surgical treatment of epilepsy. Signals were recorded during speech perception and rest. Patterns of neural activity (high gamma power: 70-150 Hz) during rest, extracted with spatiotemporal principal component analysis, were compared to spatiotemporal neural responses to speech features during perception. Hierarchical clustering was applied to look for patterns in rest that corresponded to speech feature tuning.
   Results: Significant correlations were found between neural responses to speech features (sentence onsets, consonants, and vowels) and the spontaneous neural activity in the STG. Across subjects, these correlations clustered into five groups, demonstrating tuning for speech features-most robustly for acoustic onsets. These correlations were not seen in other brain areas, or during motor and spectrally-rotated speech control tasks.
   Conclusions: In this study, we present evidence that the RS structure of STG activity robustly recapitulates its stimulus-evoked response to acoustic onsets. Further, secondary patterns in RS activity appear to correlate with stimulus-evoked responses to speech features. The role of these spontaneous spatiotemporal activity patterns remains to be elucidated.
C1 [Breshears, Jonathan D.; Hamilton, Liberty S.; Chang, Edward F.] Univ Calif San Francisco, Dept Neurosurg, San Francisco, CA 94117 USA.
   [Hamilton, Liberty S.] Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78712 USA.
   [Hamilton, Liberty S.] Univ Texas Austin, Dept Neurol, Dell Med Sch, Austin, TX 78712 USA.
RP Chang, EF (corresponding author), Univ Calif San Francisco, Dept Neurosurg, San Francisco, CA 94117 USA.
EM edward.chang@ucsf.edu
RI Hamilton, Liberty/V-2542-2019
OI Hamilton, Liberty/0000-0003-0182-2500
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [1 F32 DC014624-01, F32-DC014192-01,
   DP2-OD00862, R01-DC012379]; New York Stem Cell Foundation; McKnight
   Foundation; Shurl and Kay Curci Foundation; William K. Bowes Foundation;
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC012379, F32DC014624, R01DC012379,
   R01DC012379, R01DC012379, R01DC012379, R01DC012379, R01DC012379,
   F32DC014192, R01DC012379, R01DC012379, F32DC014192, R01DC012379,
   F32DC014192] Funding Source: NIH RePORTER
FX This study was funded through grants from the National Institute on
   Deafness and Other Communication Disorders (1 F32 DC014624-01 to JB, and
   F32-DC014192-01 to LH, and DP2-OD00862 and R01-DC012379 to EC). EC is a
   New York Stem Cell Foundation-Robertson Investigator. This research was
   also supported by The New York Stem Cell Foundation, The McKnight
   Foundation, The Shurl and Kay Curci Foundation, and The William K. Bowes
   Foundation.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Berezutskaya J, 2017, J NEUROSCI, V37, P7906, DOI 10.1523/JNEUROSCI.0238-17.2017
   BLESSER B, 1972, J SPEECH HEAR RES, V15, P5, DOI 10.1044/jshr.1501.05
   Breshears JD, 2010, P NATL ACAD SCI USA, V107, P21170, DOI 10.1073/pnas.1011949107
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chelaru MI, 2016, J NEUROPHYSIOL, V115, P3090, DOI 10.1152/jn.00724.2015
   Elhilali M, 2009, NEURON, V61, P317, DOI 10.1016/j.neuron.2008.12.005
   Foster BL, 2015, NEURON, V86, P578, DOI 10.1016/j.neuron.2015.03.018
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Fukushima M, 2012, NEURON, V74, P899, DOI 10.1016/j.neuron.2012.04.014
   Garofolo J. S., 1993, 93 NASA STIRECON
   Gratton C, 2018, NEURON, V98, P439, DOI 10.1016/j.neuron.2018.03.035
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Hamilton LS, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00062
   He BYJ, 2008, P NATL ACAD SCI USA, V105, P16039, DOI 10.1073/pnas.0807010105
   Leaver AM, 2010, J NEUROSCI, V30, P7604, DOI 10.1523/JNEUROSCI.0296-10.2010
   Lewis CM, 2016, P NATL ACAD SCI USA, V113, pE606, DOI 10.1073/pnas.1513773113
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Moses DA, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/056004
   Steinschneider M, 2011, CEREB CORTEX, V21, P2332, DOI 10.1093/cercor/bhr014
   Tang C, 2017, SCIENCE, V357, P797, DOI 10.1126/science.aam8577
   Vincent JL, 2007, NATURE, V447, P83, DOI 10.1038/nature05758
NR 22
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD SEP 18
PY 2018
VL 12
AR 360
DI 10.3389/fnhum.2018.00360
PG 8
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA GT9IY
UT WOS:000444855800001
PM 30279650
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Krasotkina, A
   Gotz, A
   Hohle, B
   Schwarzer, G
AF Krasotkina, Anna
   Goetz, Antonia
   Hoehle, Barbara
   Schwarzer, Gudrun
TI Perceptual Narrowing in Speech and Face Recognition: Evidence for
   Intra-individual Cross-Domain Relations
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE perceptual narrowing; perceptual reorganization; other-race effect; face
   perception; speech perception; habituation
ID PHONETIC PERCEPTION; RACE FACES; INFANTS; LANGUAGE; REORGANIZATION;
   PREFERENCES; LIFE; TONE
AB During the first year of life, infants undergo perceptual narrowing in the domains of speech and face perception. This is typically characterized by improvements in infants' abilities in discriminating among stimuli of familiar types, such as native speech tones and same-race faces. Simultaneously, infants begin to decline in their ability to discriminate among stimuli of types with which they have little experience, such as nonnative tones and other-race faces. The similarity in time-frames during which perceptual narrowing seems to occur in the domains of speech and face perception has led some researchers to hypothesize that the perceptual narrowing in these domains could be driven by shared domain-general processes. To explore this hypothesis, we tested 53 Caucasian 9-month-old infants from monolingual German households on their ability to discriminate among non-native Cantonese speech tones, as well among same-race German faces and other-race Chinese faces. We tested the infants using an infant-controlled habituation-dishabituation paradigm, with infants' preferences for looking at novel stimuli versus the habituated stimuli (dishabituation scores) acting as indicators of discrimination ability. As expected for their age, infants were able to discriminate between same-race faces, but not between other-race faces or non-native speech tones. Most interestingly, we found that infants' dishabituation scores for the non-native speech tones and other-race faces showed significant positive correlations, while the dishabituation scores for non-native speech tones and same-race faces did not. These results therefore support the hypothesis that shared domain-general mechanisms may drive perceptual narrowing in the domains of speech and face perception.
C1 [Krasotkina, Anna; Schwarzer, Gudrun] Justus Liebig Univ Giessen, Fac Psychol & Sports Sci 06, Dept Dev Psychol, Giessen, Germany.
   [Goetz, Antonia; Hoehle, Barbara] Univ Potsdam, Linguist Dept, Potsdam, Germany.
RP Krasotkina, A (corresponding author), Justus Liebig Univ Giessen, Fac Psychol & Sports Sci 06, Dept Dev Psychol, Giessen, Germany.
EM Anna.Krasotkina@psychol.uni-giessen.de
RI Krasotkina, Anna/AAC-9943-2021
OI Hohle, Barbara/0000-0002-9240-6117
FU DFG (German Research Foundation) as part of the Research Unit Crossing
   the Borders [FOR 2253, Schw 665/12-1, HO 1960/19-1]
FX The research presented here was funded by the DFG (German Research
   Foundation) as part of the Research Unit Crossing the Borders (FOR 2253)
   with grants to GS (Schw 665/12-1) and BH (HO 1960/19-1).
CR de Haan M, 2002, J COGNITIVE NEUROSCI, V14, P199, DOI 10.1162/089892902317236849
   Gotz A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00477
   Heron-Delaney M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019858
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   Kelly DJ, 2007, INFANCY, V11, P87, DOI 10.1207/s15327078in1101_4
   Kelly DJ, 2009, J EXP CHILD PSYCHOL, V104, P105, DOI 10.1016/j.jecp.2009.01.006
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Liu SY, 2011, J EXP CHILD PSYCHOL, V108, P180, DOI 10.1016/j.jecp.2010.06.008
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Minar NJ, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12604
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Schwarzer G, 2014, CHILD DEV PERSPECT, V8, P213, DOI 10.1111/cdep.12093
   Spangler SM, 2013, INFANCY, V18, P516, DOI 10.1111/j.1532-7078.2012.00137.x
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wheeler A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018621
   Xiao WS, 2014, DEV PSYCHOBIOL, V56, P262, DOI 10.1002/dev.21196
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
NR 18
TC 2
Z9 2
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 12
PY 2018
VL 9
AR 1711
DI 10.3389/fpsyg.2018.01711
PG 5
WC Psychology, Multidisciplinary
SC Psychology
GA GT4GT
UT WOS:000444462900001
PM 30258388
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Maslowski, M
   Meyer, AS
   Bosker, HR
AF Maslowski, Merel
   Meyer, Antje S.
   Bosker, Hans Rutger
TI Listening to yourself is special: Evidence from global speech rate
   tracking
SO PLOS ONE
LA English
DT Article
ID SPEAKING RATE; SOUND FAST; PERCEPTION; SELF; MINE; NORMALIZATION;
   OBJECT; VOICE
AB Listeners are known to use adjacent contextual speech rate in processing temporally ambiguous speech sounds. For instance, an ambiguous vowel between short /alpha/ and long /a:/ in Dutch sounds relatively long (i.e., as /a:/) embedded in a fast precursor sentence, but short in a slow sentence. Besides the local speech rate, listeners also track talker-specific global speech rates. However, it is yet unclear whether other talkers' global rates are encoded with reference to a listener's self-produced rate. Three experiments addressed this question. In Experiment 1, one group of participants was instructed to speak fast, whereas another group had to speak slowly. The groups were compared on their perception of ambiguous /alpha/-/a:/vowels embedded in neutral rate speech from another talker. In Experiment 2, the same participants listened to playback of their own speech and again evaluated target vowels in neutral rate speech. Neither of these experiments provided support for the involvement of self-produced speech in perception of another talker's speech rate. Experiment 3 repeated Experiment 2 but with a new participant sample that was unfamiliar with the participants from Experiment 2. This experiment revealed fewer /a:/ responses in neutral speech in the group also listening to a fast rate, suggesting that neutral speech sounds slow in the presence of a fast talker and vice versa. Taken together, the findings show that self-produced speech is processed differently from speech produced by others. They carry implications for our understanding of rate-dependent speech perception in dialogue settings, suggesting that both perceptual and cognitive mechanisms are involved.
C1 [Maslowski, Merel; Meyer, Antje S.; Bosker, Hans Rutger] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Maslowski, Merel] Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
   [Meyer, Antje S.; Bosker, Hans Rutger] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Maslowski, M (corresponding author), Max Planck Inst Psycholinguist, Nijmegen, Netherlands.; Maslowski, M (corresponding author), Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
EM Merel.Maslowski@mpi.nl
RI Maslowski, Merel/AAK-1828-2020
OI Bosker, Hans Rutger/0000-0002-2628-7738
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Bosker HR, 2015, 18 INT C PHON SCI IC
   Bosker HR, 2018, LANG COGN NEUROSCI, P1
   Bybee J., 2006, FREQUENCY USE ORG LA
   Creel SC, 2011, LANG LINGUIST COMPAS, V5, P190, DOI 10.1111/j.1749-818x.2011.00276.x
   Cunningham SJ, 2008, CONSCIOUS COGN, V17, P312, DOI 10.1016/j.concog.2007.04.003
   Dent ML, 1997, J ACOUST SOC AM, V102, P1891, DOI 10.1121/1.420111
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   DIEHL RL, 1980, PERCEPT PSYCHOPHYS, V27, P435, DOI 10.3758/BF03204461
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Eger NA, 2019, J EXP PSYCHOL LEARN, V45, P552, DOI 10.1037/xlm0000599
   EIMAS PD, 1980, SCIENCE, V209, P1140, DOI 10.1126/science.7403875
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Forrin ND, 2018, MEMORY, V26, P574, DOI 10.1080/09658211.2017.1383434
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   GORDON PC, 1988, PERCEPT PSYCHOPHYS, V43, P137, DOI 10.3758/BF03214191
   Graux J, 2013, BRAIN TOPOGR, V26, P72, DOI 10.1007/s10548-012-0233-2
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Jardri R, 2007, NEUROIMAGE, V35, P1645, DOI 10.1016/j.neuroimage.2007.02.002
   Keyes H, 2010, Q J EXP PSYCHOL, V63, P840, DOI 10.1080/17470211003611264
   Knoblich G, 2002, Q J EXP PSYCHOL-A, V55, P1027, DOI 10.1080/02724980143000631
   Knoblich G, 2001, PSYCHOL SCI, V12, P467, DOI 10.1111/1467-9280.00387
   Koreman J, 2006, J ACOUST SOC AM, V119, P582, DOI 10.1121/1.2133436
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   MILLER JL, 1981, PHONETICA, V38, P159, DOI 10.1159/000260021
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   R Core Team, 2014, R LANG ENV STAT COMP
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Schuerman WL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129731
   Schuerman WL, 2017, SENSORIMOTOR EXPERIE
   Schwab S, 2011, PHONETICA, V68, P243, DOI 10.1159/000335578
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106
   Sui J, 2012, J EXP PSYCHOL HUMAN, V38, P1105, DOI 10.1037/a0029792
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Treille A, 2015, 7 ANN M SOC NEUR LAN
   Truong G, 2017, J COGNITIVE NEUROSCI, V29, P937, DOI 10.1162/jocn_a_01083
   Truong G, 2017, J EXP PSYCHOL HUMAN, V43, P192, DOI 10.1037/xhp0000295
   Turk DJ, 2011, J COGNITIVE NEUROSCI, V23, P3725, DOI 10.1162/jocn_a_00101
   Ventura MI, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-58
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   Xu MD, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00735
NR 57
TC 6
Z9 5
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD SEP 5
PY 2018
VL 13
IS 9
AR e0203571
DI 10.1371/journal.pone.0203571
PG 19
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GS6HC
UT WOS:000443789900075
PM 30183780
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Needle, JM
   Pierrehumbert, JB
AF Needle, Jeremy M.
   Pierrehumbert, Janet B.
TI Gendered associations of English morphology
SO LABORATORY PHONOLOGY
LA English
DT Article
DE pseudowords; morphology; sociolinguistics; indexicality
ID SPEECH-PERCEPTION; FREQUENCY; LANGUAGE; SIMILARITY; IDENTITY; MODELS
AB Morphological systems arise from language experience encoded in the lexicon, which includes much statistical and episodic information (see Pierrehumbert, 2006; Racz, Pierrehumbert, Hay, & Papp, 2015). Lexical statistics have been successfully applied in theories of morphological learning and change (Bybee, 1995), but there remains much unexplained variation in speakers' morphological choices and patterns of generalization. A promising route for explanation is the role of social-indexical information in shaping morphological systems. We present a quantitative experimental study on the relationship of morphological perception to speaker gender, a highly salient aspect of the linguistic context that is known to be important in language variation and change. We show that people have significant success in associating English words with speaker gender, and that their implicit knowledge generalizes to gender associations of novel words (pseudowords) on the basis of their component morphemes. By analyzing judgments of morphological decomposition in conjunction with these indexical judgments, we also make inferences about the cognitive architecture for social-indexical effects in morphology.
C1 [Needle, Jeremy M.] Northwestern Univ, Dept Linguist, Evanston, IL 60208 USA.
   [Pierrehumbert, Janet B.] Univ Oxford, Dept Engn Sci, Oxford, England.
RP Needle, JM (corresponding author), Northwestern Univ, Dept Linguist, Evanston, IL 60208 USA.
EM jneedle@u.northwestern.edu
FU John Templeton Foundation [36617]
FX This project was made possible through the support of a grant to
   Northwestern University from the John Templeton Foundation (Award ID
   36617). The opinions expressed in this publication are those of the
   authors and do not necessarily reflect the views of the John Templeton
   Foundation. For assistance in stimuli preparation, data collection, and
   statistical analysis, the authors would like to thank Jennifer Hay, Chun
   Liang Chan, and Matt Goldrick. We thank the audience at LSA 2018 for
   their feedback.
CR Albright A, 2003, COGNITION, V90, P119, DOI 10.1016/S0010-0277(03)00146-X
   [Anonymous], 2007, BRIT NAT CORP VERS 3
   Baayen Harald, 1999, ENGL LANG LINGUIST, V3, P209, DOI DOI 10.1017/S1360674399000222
   Baayen RH, 2013, LANG SPEECH, V56, P329, DOI 10.1177/0023830913484896
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bauer L, 2001, MORPHOLOGICAL PRODUC, DOI [10.1017/CBO9780511486210, DOI 10.1017/CBO9780511486210]
   Beckner C, 2016, J LANG SOC PSYCHOL, V35, P158, DOI 10.1177/0261927X15584682
   Boulis C., 2005, P INT WORKSH FEAT SE, P9
   Bucholtz M, 1999, LANG SOC, V28, P203
   Bucholtz M, 2001, J LINGUIST ANTHROPOL, V11, P84, DOI DOI 10.1525/JLIN.2001.11.1.84
   BYBEE J, 1995, LANG COGNITIVE PROC, V10, P425, DOI 10.1080/01690969508407111
   Bybee Joan, 1997, BERKELEY LINGUISTICS, V23, P378, DOI DOI 10.3765/BLS.V23I1.1293
   Clapper CG, 2016, J PHONETICS, V58, P87, DOI 10.1016/j.wocn.2016.06.002
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Clopper Cynthia G, 2004, Lang Var Change, V16, P31
   Daelemans W., 2010, ILK RES GROUP TECHNI, V10-01
   Daland R, 2011, COGNITIVE SCI, V35, P119, DOI 10.1111/j.1551-6709.2010.01160.x
   Dawdy-Hesterberg LG, 2014, LANG COGN NEUROSCI, V29, P1268, DOI 10.1080/23273798.2014.899377
   Eckert P, 2008, J SOCIOLING, V12, P453, DOI 10.1111/j.1467-9841.2008.00374.x
   Eckert Penelope, 1989, LANG VAR CHANGE, V1, P245, DOI [DOI 10.1017/S095439450000017X, 10.1017/S095439450000017X]
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   German JS, 2013, J PHONETICS, V41, P228, DOI 10.1016/j.wocn.2013.03.001
   Haspelmath M., 2013, UNDERSTING MORPHO
   Hay J, 2002, LANGUAGE, V78, P527, DOI 10.1353/lan.2002.0159
   Hay J., 2001, YB MORPHOLOGY 2001, P203
   Hay J., 2004, PAPERS LAB PHONOLOGY, VVI, P58, DOI DOI 10.1017/CBO9780511486425
   Hay JB, 2005, TRENDS COGN SCI, V9, P342, DOI 10.1016/j.tics.2005.04.002
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Komarova NL, 2001, B MATH BIOL, V63, P451, DOI 10.1006/bulm.2000.0222
   Kuperman V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00203
   Labov W., 2001, SOCIAL FACTORS, V2
   Lakoff Robin., 1973, LANGUAGE SOC, V2, P45, DOI [10.1017/S0047404500000051, DOI 10.1017/S0047404500000051]
   Mihalcea R, 2016, IEEE INTELL SYST, V31, P62, DOI 10.1109/MIS.2016.71
   Nation K, 2009, COGNITION, V110, P273, DOI 10.1016/j.cognition.2008.11.004
   Needle J. M., PHONOTACTIC MORPHOLO
   Nevalainen T, 2011, LANG VAR CHANGE, V23, P1, DOI 10.1017/S0954394510000207
   NOSOFSKY RM, 1988, J EXP PSYCHOL LEARN, V14, P54, DOI 10.1037/0278-7393.14.1.54
   NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A
   Ochs Elinor, 1992, RETHINKING CONTEXT L, P335
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Purnell T, 1999, J LANG SOC PSYCHOL, V18, P10, DOI 10.1177/0261927X99018001002
   QUINA K, 1987, PSYCHOL WOMEN QUART, V11, P111, DOI 10.1111/j.1471-6402.1987.tb00778.x
   R Core Team, 2014, R LANG ENV STAT COMP
   Racz P., 2015, HDB LANGUAGE EMERGEN, P123, DOI [10.1002/9781118346136.ch5, DOI 10.1002/9781118346136.CH5]
   Racz P, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00051
   Rickford J. R., 2000, SPOKEN SOUL STORY BL
   Robert Daland, 2007, P 45 ANN M ASS COMP, P936
   Silverstein M, 2003, LANG COMMUN, V23, P193, DOI 10.1016/S0271-5309(03)00013-2
   Social Security Administration, 2016, TOP NAM LAST 100 YEA
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Taft M, 2004, Q J EXP PSYCHOL-A, V57, P745, DOI 10.1080/02724980343000477
NR 55
TC 3
Z9 3
U1 0
U2 7
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD SEP 5
PY 2018
VL 9
IS 1
AR 14
DI 10.5334/labphon.134
PG 23
WC Linguistics; Language & Linguistics
SC Linguistics
GA GS8SO
UT WOS:000443983500001
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kasisopa, B
   Antonios, LE
   Jongman, A
   Sereno, JA
   Burnham, D
AF Kasisopa, Benjawan
   Antonios, Lamya El-Khoury
   Jongman, Allard
   Sereno, Joan A.
   Burnham, Denis
TI Training Children to Perceive Non-native Lexical Tones: Tone Language
   Background, Bilingualism, and Auditory-Visual Information
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE lexical tone; auditory-visual; speech perception; bilingualism;
   perceptual attunement
ID MANDARIN-SPEAKING CHILDREN; SPEECH-PERCEPTION; DEVELOPMENTAL-CHANGES;
   CHINESE TONES; EYE-MOVEMENTS; 1ST YEAR; INFANTS; THAI; LISTENERS;
   ENGLISH
AB This study investigates the role of language background and bilingual status in the perception of foreign lexical tones. Eight groups of participants, consisting of children of 6 and 8 years from one of four language background (tone or non-tone) x bilingual status (monolingual or bilingual)-Thai monolingual, English monolingual, English-Thai bilingual, and English-Arabic bilingual were trained to perceive the four Mandarin lexical tones. Half the children in each of these eight groups were given auditory-only (AO) training and half auditory-visual (AV) training. In each group Mandarin tone identification was tested before and after (pre- and post-) training with both auditory-only test (ao-test) and auditory-visual test (av test). The effect of training on Mandarin tone identification was minimal for 6-year-olds. On the other hand, 8-year-olds, particularly those with tone language experience showed greater pre- to post-training improvement, and this was best indexed by ao-test trials. Bilingual vs. monolingual background did not facilitate overall improvement due to training, but it did modulate the efficacy of the Training mode: for bilinguals both AO and AV training, and especially AO, resulted in performance gain; but for monolinguals training was most effective with AV stimuli. Again this effect was best indexed by ao-test trials. These results suggest that tone language experience, be it monolingual or bilingual, is a strong predictor of learning unfamiliar tones; that monolinguals learn best from AV training trials and bilinguals from AO training trials; and that there is no metalinguistic advantage due to bilingualism in learning to perceive lexical tones.
C1 [Kasisopa, Benjawan; Antonios, Lamya El-Khoury; Burnham, Denis] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.
   [Jongman, Allard; Sereno, Joan A.] Univ Kansas, Coll Liberal Arts & Sci, Dept Linguist, Lawrence, KS 66045 USA.
   [Jongman, Allard; Sereno, Joan A.] Univ Kansas, Coll Liberal Arts & Sci, Dept Linguist, Phonet & Psycholinguist Lab, Lawrence, KS 66045 USA.
RP Kasisopa, B (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.
EM b.kasisopa@westernsydney.edu.au
RI Burnham, Denis/L-3742-2019; jongman, allard/A-8377-2009
OI Burnham, Denis/0000-0002-1980-3458; jongman, allard/0000-0002-7384-2036
FU Australian Research Council (ARC)Australian Research Council [DP0988201]
FX This research was supported by an Australian Research Council (ARC)
   Discovery grant (DP0988201) to the last author and some funding for an
   honors project to the first author.
CR ABRAMSON AS, 1978, LANG SPEECH, V21, P319, DOI 10.1177/002383097802100406
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Burnham D., 2001, P 7 C SPEECH COMM TE, P395
   Burnham D, 2017, P 11 INT SEM SPEECH, P141
   Burnham D., 2001, P INT C AUD VIS SPEE, P155
   Burnham D., 2003, READ WRIT, V16, P573, DOI DOI 10.1023/A:1025593911070
   Burnham D., 2010, WILEY BLACKWELL HDB, V1, P81
   Burnham D. K, 1995, P INT C PHON SCI STO, V4, P558
   Burnham D, 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI 10.1017/S0142716414000496
   Burnham D, 2011, J EXP CHILD PSYCHOL, V108, P693, DOI 10.1016/j.jecp.2010.07.008
   BURNHAM DK, 1991, J CHILD LANG, V18, P231, DOI 10.1017/S0305000900011041
   CAMPBELL R, 1995, BRIT J DEV PSYCHOL, V13, P61, DOI 10.1111/j.2044-835X.1995.tb00664.x
   CAMPBELL R, 1998, HEARING EYE 2 ADV PS
   Chang Y. S, 2011, P 23 N AM C CHIN LIN, V1, P84
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   Choi J, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160660
   Davis C, 2016, LANG SPEECH, V59, P196, DOI 10.1177/0023830915586033
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Erdener D, 2013, J EXP CHILD PSYCHOL, V116, P120, DOI 10.1016/j.jecp.2013.03.003
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Friesen DC, 2012, RIV PSICOLINGUIST AP, V12, P47
   Fromkin V.A., 1978, TONE LINGUISTIC SURV
   Grosjean F., 2010, BILINGUAL, DOI [10.4159/9780674056459, DOI 10.4159/9780674056459]
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Hockley N., 1994, J ACOUST SOC AM, V96, P3309, DOI DOI 10.1121/1.410782
   Horlyck S, 2012, SCI STUD READ, V16, P218, DOI 10.1080/10888438.2010.546460
   Jensen B. T, 2008, METALINGUISTIC AWARE
   Kasisopa B, 2016, VISION RES, V123, P8, DOI 10.1016/j.visres.2015.07.009
   Kasisopa B, 2013, VISION RES, V86, P71, DOI 10.1016/j.visres.2013.04.007
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   MASSARO DW, 1984, CHILD DEV, V55, P1777, DOI 10.1111/j.1467-8624.1984.tb00420.x
   MASSARO DW, 1986, J EXP CHILD PSYCHOL, V41, P93, DOI 10.1016/0022-0965(86)90053-6
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   McBride-Chang C, 2003, J EDUC PSYCHOL, V95, P743, DOI 10.1037/0022-0663.95.4.743
   MCDOUGALL S, 1994, J EXP CHILD PSYCHOL, V58, P112, DOI 10.1006/jecp.1994.1028
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mixdorff H., 2005, P AUD VIS SPEECH PRO, P3
   Mixdorff H., 2005, P 9 EUR C SPEECH COM, P405
   Mixdorff H, 2005, P 9 EUR C SPEECH COM
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Sereno J, 2006, ABSTR PSYCHON SOC, V11, P4041
   Sereno J. A, 2017, SPEECH PROCESSING LE, P192, DOI [10.1515/9783110422658-010, DOI 10.1515/9783110422658-010]
   Singh L, 2012, COGNITION, V124, P128, DOI 10.1016/j.cognition.2012.05.008
   Smith D, 2012, J ACOUST SOC AM, V131, P1480, DOI 10.1121/1.3672703
   Tyler MD, 2006, Q J EXP PSYCHOL, V59, P2010, DOI 10.1080/17470210500521828
   VATIKTIOTISBATE.E, 2000, LP 98 ITEM ORDER LAN, P439
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wang Y., 2003, P 15 INT C PHON SCI, P1537
   Wayland R, 2003, APPL PSYCHOLINGUIST, V24, P113, DOI 10.1017/S0142716403000067
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE, P1
NR 62
TC 0
Z9 0
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 4
PY 2018
VL 9
AR 1508
DI 10.3389/fpsyg.2018.01508
PG 14
WC Psychology, Multidisciplinary
SC Psychology
GA GS4WP
UT WOS:000443657600001
PM 30233446
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Polonenko, MJ
   Papsin, BC
   Gordon, KA
AF Polonenko, Melissa Jane
   Papsin, Blake Croll
   Gordon, Karen Ann
TI Limiting asymmetric hearing improves benefits of bilateral hearing in
   children using cochlear implants
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SINGLE-SIDED DEAFNESS; SPATIAL UNMASKING; AUDITORY EXPERIENCE; BIMODAL
   STIMULATION; AURAL PREFERENCE; SPEECH DETECTION; YOUNG-CHILDREN;
   OPPOSITE EARS; BRAIN-STEM; PERCEPTION
AB Neurodevelopmental changes occur with asymmetric hearing loss, limiting binaural/spatial hearing and putting children at risk for social and educational challenges. These deficits may be mitigated by providing bilateral hearing in children through auditory prostheses. Effects on speech perception and spatial hearing were measured in a large cohort of > 450 children who were deaf and used bilateral cochlear implants or bimodal devices (one cochlear implant and a contralateral hearing aid). Results revealed an advantage of bilateral over unilateral device use but this advantage decreased as hearing in the two ears became increasingly asymmetric. Delayed implantation of an ear with severe to profound deafness allowed asymmetric hearing, creating aural preference for the better hearing ear. These findings indicate that bilateral input with the most appropriate device for each ear should be provided early and without delay during development.
C1 [Polonenko, Melissa Jane; Papsin, Blake Croll; Gordon, Karen Ann] Univ Toronto, Inst Med Sci, Toronto, ON M5S 1A8, Canada.
   [Polonenko, Melissa Jane; Gordon, Karen Ann] Hosp Sick Children, Neurosci & Mental Hlth, Toronto, ON M5G 1X8, Canada.
   [Papsin, Blake Croll; Gordon, Karen Ann] Univ Toronto, Dept Otolaryngol Head & Neck Surg, Toronto, ON M5G 2N2, Canada.
   [Papsin, Blake Croll; Gordon, Karen Ann] Hosp Sick Children, Otolaryngol Head & Neck Surg, Toronto, ON M5G 1X8, Canada.
RP Polonenko, MJ (corresponding author), Univ Toronto, Inst Med Sci, Toronto, ON M5S 1A8, Canada.; Polonenko, MJ (corresponding author), Hosp Sick Children, Neurosci & Mental Hlth, Toronto, ON M5G 1X8, Canada.
EM melissa.polonenko@mail.utoronto.ca
OI Polonenko, Melissa/0000-0003-1914-6117
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP-97924, MFE1748241]; Hospital for Sick
   ChildrenUniversity of Toronto; Ontario Ministry of Training; University
   of TorontoUniversity of Toronto
FX We would like to thank the Cochlear Implant Program audiologists
   (Patricia Di Santo, Susan Druker, Mary Lynn Feness, Gina Goulding,
   Laurie MacDonald, Rebecca Malcolmson, Valerie Simard and Vicky
   Papaioannou) for administering the tests during their clinical
   appointments. We gratefully acknowledge the time and help of the
   families and children who participated in this study. Funding was
   provided by: Canadian Institutes of Health Research (MOP-97924 to KAG,
   MFE1748241 to MJP), the Hospital for Sick Children (Restracomp and
   Clinician-Scientist Training awards to MJP), Ontario Ministry of
   Training (Graduate Scholarship to MJP), and the University of Toronto.
CR Arndt S, 2015, AUDIOL NEURO-OTOL, V20, P21, DOI 10.1159/000380744
   Bartov T, 2014, J SPEECH LANG HEAR R, V57, P1929, DOI 10.1044/2014_JSLHR-H-13-0190
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   BESS FH, 1984, PEDIATRICS, V74, P206
   Boons T, 2013, RES DEV DISABIL, V34, P2008, DOI 10.1016/j.ridd.2013.03.003
   Borton SA, 2010, AM J AUDIOL, V19, P61, DOI 10.1044/1059-0889(2010/07-0043)
   Cadieux JH, 2013, OTOL NEUROTOL, V34, P408, DOI 10.1097/MAO.0b013e31827850b8
   Chadha NK, 2011, OTOL NEUROTOL, V32, P1057, DOI 10.1097/MAO.0b013e3182267de7
   Ching T Y C, 2007, Trends Amplif, V11, P161, DOI 10.1177/1084713807304357
   Ching TYC, 2018, INT J AUDIOL, V57, pS70, DOI 10.1080/14992027.2017.1346307
   Ching Teresa Y C, 2014, Cochlear Implants Int, V15 Suppl 1, pS43, DOI 10.1179/1467010014Z.000000000168
   Ching TYC, 2009, J SPEECH LANG HEAR R, V52, P1241, DOI 10.1044/1092-4388(2009/08-0261)
   Clemmens CS, 2013, OTOLARYNG HEAD NECK, V149, P318, DOI 10.1177/0194599813487681
   Cullington H E, 2017, Cochlear Implants Int, V18, P2, DOI 10.1080/14670100.2016.1265055
   Das Purkayastha PK, 2011, OTOL NEUROTOL, V32, P780, DOI 10.1097/MAO.0b013e318214ea88
   Easwar V., 2017, J AM ACAD AUDIOL, P1
   Easwar V, 2017, BRAIN BEHAV, V7, DOI 10.1002/brb3.638
   Easwar V, 2017, J NEUROSCI, V37, P2349, DOI 10.1523/JNEUROSCI.2538-16.2017
   Easwar V, 2016, J AM ACAD AUDIOL, V27, P824, DOI 10.3766/jaaa.15138
   Galvin KL, 2017, EAR HEARING, V38, pE325, DOI 10.1097/AUD.0000000000000442
   Garadat SN, 2007, J ACOUST SOC AM, V121, P1047, DOI 10.1121/1.2409863
   Giannantonio S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136685
   Gordon K, 2015, PEDIATRICS, V136, P141, DOI 10.1542/peds.2014-3520
   Gordon KA, 2013, BRAIN, V136, P1609, DOI 10.1093/brain/awt052
   Gordon KA, 2012, J NEUROSCI, V32, P4212, DOI 10.1523/JNEUROSCI.5741-11.2012
   Gordon KA, 2009, OTOL NEUROTOL, V30, P319, DOI 10.1097/MAO.0b013e31819a8f4c
   Grainger Joe, 2012, Cochlear Implants Int, V13, P137, DOI 10.1179/146701011X12950038111891
   Gratacap M, 2015, ANN OTO RHINOL LARYN, V124, P443, DOI 10.1177/0003489414566121
   Gray L, 2009, INT J PEDIATR OTORHI, V73, P1281, DOI 10.1016/j.ijporl.2009.05.024
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   Hess C, 2014, EAR HEARING, V35, P387, DOI 10.1097/AUD.0000000000000023
   Holt RF, 2005, EAR HEARING, V26, p82S, DOI 10.1097/00003446-200508001-00010
   Illg A, 2019, HEARING RES, V372, P80, DOI 10.1016/j.heares.2017.10.010
   Illg A, 2013, OTOL NEUROTOL, V34, P682, DOI 10.1097/MAO.0b013e31828bb75e
   Jiwani S, 2016, HUM BRAIN MAPP, V37, P135, DOI 10.1002/hbm.23019
   Keating P, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00123
   Kilian CF, 2015, INT J PEDIATR OTORHI, V79, P2159, DOI 10.1016/j.ijporl.2015.09.039
   Killan Catherine F, 2015, Cochlear Implants Int, V16, P270, DOI 10.1179/1754762815Y.0000000001
   Kocdor P, 2016, LARYNGOSCOPE, V126, P2389, DOI 10.1002/lary.26012
   Kral A, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00093
   Kral A, 2013, BRAIN, V136, P180, DOI 10.1093/brain/aws305
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lieu JEC, 2010, PEDIATRICS, V125, pE1348, DOI 10.1542/peds.2009-2448
   Lin L, 2002, J AM STAT ASSOC, V97, P257, DOI 10.1198/016214502753479392
   Lin PH, 2017, JAMA OTOLARYNGOL, V143, P912, DOI 10.1001/jamaoto.2017.0945
   Litovsky RY, 2006, INT J AUDIOL, V45, pS78, DOI 10.1080/14992020600782956
   Litovsky RY, 2016, HEARING RES, V338, P76, DOI 10.1016/j.heares.2016.01.003
   Luntz M, 2005, ACTA OTO-LARYNGOL, V125, P863, DOI 10.1080/00016480510035395
   McCulloch C. E., 2013, ENCY ENV, P28, DOI [10.1002/9780470057339.vag009.pub2, DOI 10.1002/9780470057339.VAG009.PUB2]
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   Merdad M, 2014, Cochlear Implants Int, V15, P43, DOI 10.1179/1754762813Y.0000000042
   Moberly AC, 2016, OTOL NEUROTOL, V37, P24, DOI 10.1097/MAO.0000000000000871
   Mok M, 2007, AUDIOL NEURO-OTOL, V12, P295, DOI 10.1159/000103210
   Mok M, 2010, AUDIOL NEURO-OTOL, V15, P44, DOI 10.1159/000219487
   Murphy J, 2011, INT J PEDIATR OTORHI, V75, P489, DOI 10.1016/j.ijporl.2011.01.002
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nittrouer Susan, 2009, Trends Amplif, V13, P190, DOI 10.1177/1084713809346160
   Peters BR, 2007, OTOL NEUROTOL, V28, P649, DOI 10.1097/01.mao.0000281807.89938.60
   Polley DB, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3547
   Polonenko MJ, 2017, J ACOUST SOC AM, V141, P4494, DOI 10.1121/1.4985123
   Polonenko MJ, 2016, J AM ACAD AUDIOL, V27, P790, DOI 10.3766/jaaa.15092
   Polonenko MJ, 2015, AUDIOL NEURO-OTOL, V20, P13, DOI 10.1159/000380743
   Polonenko MJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17129-z
   Polonenko MJ, 2018, NEUROIMAGE-CLIN, V17, P415, DOI 10.1016/j.nicl.2017.10.036
   Polonenko MJ, 2017, EAR HEARING, V38, P681, DOI 10.1097/AUD.0000000000000452
   Popescu MV, 2010, NEURON, V65, P718, DOI 10.1016/j.neuron.2010.02.019
   Ramsden JD, 2009, LARYNGOSCOPE, V119, P2444, DOI 10.1002/lary.20630
   Sangen A, 2017, CLIN OTOLARYNGOL, V42, P979, DOI 10.1111/coa.12826
   Sarant JZ, 2001, EAR HEARING, V22, P18, DOI 10.1097/00003446-200102000-00003
   Schafer EC, 2012, EAR HEARING, V33, pE32, DOI 10.1097/AUD.0b013e318258c616
   Schmithorst VJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00164
   Scorpecci A, 2016, OTOLARYNG HEAD NECK, V155, P1028, DOI 10.1177/0194599816661705
   Sherbecoe RL, 2004, INT J AUDIOL, V43, P442, DOI 10.1080/14992020400050056
   Shirvani S, 2016, ANN OTO RHINOL LARYN, V125, P470, DOI 10.1177/0003489415619943
   Simons-McCandless M., 2000, HEARING REV, V11, P38
   Sokolov M, 2017, CURR OTORHINOLARYNGO, V5, P275, DOI DOI 10.1007/S40136-017-0173-1
   Sparreboom M, 2011, AUDIOL NEURO-OTOL, V16, P203, DOI 10.1159/000320270
   Straatman LV, 2010, J ACOUST SOC AM, V128, P1884, DOI 10.1121/1.3474236
   Strom-Roum H, 2012, INT J PEDIATR OTORHI, V76, P95, DOI 10.1016/j.ijporl.2011.10.009
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tillein J, 2016, CEREB CORTEX, V26, P1762, DOI 10.1093/cercor/bhv351
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   Trimble K, 2008, J AM ACAD AUDIOL, V19, P602, DOI 10.3766/jaaa.19.8.4
   van Wieringen A, 2019, HEARING RES, V372, P29, DOI 10.1016/j.heares.2018.01.010
   Watson PF, 2010, THERIOGENOLOGY, V73, P1167, DOI 10.1016/j.theriogenology.2010.01.003
   Wong LLN, 2012, J ACOUST SOC AM, V132, P2642, DOI 10.1121/1.4751538
NR 86
TC 11
Z9 12
U1 0
U2 9
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD SEP 4
PY 2018
VL 8
AR 13201
DI 10.1038/s41598-018-31546-8
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GS3TA
UT WOS:000443543700011
PM 30181590
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ward, RM
   Kelty-Stephen, DG
AF Ward, Rachel M.
   Kelty-Stephen, Damian G.
TI Bringing the Nonlinearity of the Movement System to Gestural Theories of
   Language Use: Multifractal Structure of Spoken English Supports the
   Compensation for Coarticulation in Human Speech Perception
SO FRONTIERS IN PHYSIOLOGY
LA English
DT Article
DE speech perception; phoneme; coarticulation; multifractal; mouse-tracking
ID PARKINSONS-DISEASE; MOTOR THEORY; INFORMATION; TURBULENCE; FORMALISM;
   TRANSFORM; CASCADES; FEEDBACK; BEHAVIOR; SIGNALS
AB Coarticulation is the tendency for speech vocalization and articulation even at the phonemic level to change with context, and compensation for coarticulation (CfC) reflects the striking human ability to perceive phonemic stability despite this variability. A current controversy centers on whether CfC depends on contrast between formants of a speech-signal spectrogram-specifically, contrast between offset formants concluding context stimuli and onset formants opening the target sound-or on speech-sound variability specific to the coordinative movement of speech articulators (e.g., vocal folds, postural muscles, lips, tongues). This manuscript aims to encode that coordinative-movement context in terms of speech-signal multifractal structure and to determine whether speech's multifractal structure might explain the crucial gestural support for any proposed spectral contrast. We asked human participants to categorize individual target stimuli drawn from an 11-step [ga]-to-[da] continuum as either phonemes "GA" or "DA." Three groups each heard a specific-type context stimulus preceding target stimuli: either real-speech [al] or [ar], sine-wave tones at the third-formant offset frequency of either [al] or [ar], and either simulated-speech contexts [al] or [ar] Here, simulating speech contexts involved randomizing the sequence of relatively homogeneous pitch periods within vowel-sound [a] of each [al] and [ar]. Crucially, simulated-speech contexts had the same offset and extremely similar vowel formants as and, to additional naive participants, sounded identical to real-speech contexts. However, randomization distorted original speech-context multifractality, and effects of spectral contrast following speech only appeared after regression modeling of trial-by-trial "GA" judgments controlled for context-stimulus multifractality. Furthermore, simulated-speech contexts elicited faster responses (like tone contexts do) and weakened known biases in CfC, suggesting that spectral contrast depends on the nonlinear interactions across multiple scales that articulatory gestures express through the speech signal. Traditional mouse-tracking behaviors measured as participants moved their computer-mouse cursor to register their "GA"-or-"DA" decisions with mouse-clicks suggest that listening to speech leads the movement system to resonate with the multifractality of context stimuli. We interpret these results as shedding light on a new multifractal terrain upon which to found a better understanding in which movement systems play an important role in shaping how speech perception makes use of acoustic information.
C1 [Ward, Rachel M.; Kelty-Stephen, Damian G.] Grinnell Coll, Dept Psychol, Grinnell, IA 50112 USA.
RP Kelty-Stephen, DG (corresponding author), Grinnell Coll, Dept Psychol, Grinnell, IA 50112 USA.
EM foovian@gmail.com
FU Grinnell College Mentored Advanced Project program
FX The authors acknowledge the generous funding of the Grinnell College
   Mentored Advanced Project program.
CR Abney DH, 2014, J EXP PSYCHOL GEN, V143, P2304, DOI 10.1037/xge0000021
   Almurad ZMH, 2017, HUM MOVEMENT SCI, V54, P125, DOI 10.1016/j.humov.2017.04.008
   Amaral LAN, 2001, PHYS REV LETT, V86, P6026, DOI 10.1103/PhysRevLett.86.6026
   Ashenfelter KT, 2009, J EXP PSYCHOL HUMAN, V35, P1072, DOI 10.1037/a0015017
   Ashkenazy Y, 2003, PHYSICA A, V323, P19, DOI 10.1016/S0378-4371(03)00008-6
   Ashkenazy Y, 2002, PHYSICA A, V316, P662, DOI 10.1016/S0378-4371(02)01453-X
   Bashan A, 2008, PHYSICA A, V387, P5080, DOI 10.1016/j.physa.2008.04.023
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Calcagni A, 2017, BEHAV RES METHODS, V49, P2012, DOI 10.3758/s13428-016-0839-5
   Carver NS, 2017, HUM MOVEMENT SCI, V55, P61, DOI 10.1016/j.humov.2017.07.005
   Chambers C, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15027
   CHHABRA A, 1989, PHYS REV LETT, V62, P1327, DOI 10.1103/PhysRevLett.62.1327
   CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334
   Delignieres D, 2016, EXP BRAIN RES, V234, P2773, DOI 10.1007/s00221-016-4679-4
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Fowler CA, 2000, J EXP PSYCHOL HUMAN, V26, P877, DOI 10.1037/0096-1523.26.3.877
   Fowler CA, 2006, PERCEPT PSYCHOPHYS, V68, P161, DOI 10.3758/BF03193666
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   Fowler CA, 2008, PSYCHON B REV, V15, P458, DOI 10.3758/PBR.15.2.458
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   GIBSON CH, 1986, J FLUID MECH, V168, P89, DOI 10.1017/S0022112086000307
   Gomez-Extremera M, 2016, PHYS REV E, V93, DOI 10.1103/PhysRevE.93.042201
   Hill DR, 2017, CAN J LING/REV CAN L, V62, P371, DOI 10.1017/cnj.2017.15
   Hlavnicka J, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00047-5
   Ihlen EAF, 2010, J EXP PSYCHOL GEN, V139, P436, DOI 10.1037/a0019098
   Ivanov PC, 1998, EUROPHYS LETT, V43, P363, DOI 10.1209/epl/i1998-00366-3
   Ivanov PC, 2004, PHYSICA A, V344, P685, DOI 10.1016/j.physa.2004.08.016
   Ivanov PC, 1999, NATURE, V399, P461, DOI 10.1038/20924
   Ivanov PC, 2001, CHAOS, V11, P641, DOI 10.1063/1.1395631
   Ivanov PC, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.041920
   Kantelhardt JW, 2002, PHYSICA A, V316, P87, DOI 10.1016/S0378-4371(02)01383-3
   Kello CT, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2017.0231
   KELSO JAS, 1984, J EXP PSYCHOL HUMAN, V10, P812, DOI 10.1037/0096-1523.10.6.812
   Kelty-Stephen DG, 2018, LANG SPEECH, V61, P71, DOI 10.1177/0023830917699441
   Kelty-Stephen DG, 2014, J EXP PSYCHOL HUMAN, V40, P2289, DOI 10.1037/a0038159
   Lachs L, 2004, J EXP PSYCHOL HUMAN, V30, P378, DOI 10.1037/0096-1523.30.2.378
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Laurent R, 2017, PSYCHOL REV, V124, P572, DOI 10.1037/rev0000069
   Levinson SC, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0302
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Mahmoodi K, 2017, ARXIV170705988
   MANDELBROT BB, 1974, J FLUID MECH, V62, P331, DOI 10.1017/S0022112074000711
   Marcus PS, 2016, ASTROPHYS J, V833, DOI 10.3847/1538-4357/833/2/148
   Maruthy S, 2018, LANG SPEECH, V61, P31, DOI 10.1177/0023830917695853
   Masapollo M, 2018, J EXP PSYCHOL HUMAN, V44, P1103, DOI 10.1037/xhp0000518
   Mitra V, 2017, SPEECH COMMUN, V89, P103, DOI 10.1016/j.specom.2017.03.003
   MUZY JF, 1993, PHYS REV E, V47, P875, DOI 10.1103/PhysRevE.47.875
   MUZY JF, 1994, INT J BIFURCAT CHAOS, V4, P245, DOI 10.1142/S0218127494000204
   MUZY JF, 1991, PHYS REV LETT, V67, P3515, DOI 10.1103/PhysRevLett.67.3515
   Roeske TC, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22933-2
   Rotter J, 2007, PHYS FLUIDS, V19, DOI 10.1063/1.2740305
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Saenz-Lechon N, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P3667
   SCHERTZER D, 1985, PHYSICOCHEM HYDRODYN, V6, P623
   Schmitt DT, 2009, IEEE T BIO-MED ENG, V56, P1564, DOI 10.1109/TBME.2009.2014819
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Stephen DG, 2011, CHAOS SOLITON FRACT, V44, P160, DOI 10.1016/j.chaos.2011.01.005
   STEVENS KN, 1971, J ACOUST SOC AM, V50, P1180, DOI 10.1121/1.1912751
   Stilp CE, 2018, ATTEN PERCEPT PSYCHO, V80, P1300, DOI 10.3758/s13414-018-1488-9
   Tilsen S, 2009, COGNITIVE SCI, V33, P839, DOI 10.1111/j.1551-6709.2009.01037.x
   Tobin SJ, 2017, J PHONETICS, V65, P45, DOI 10.1016/j.wocn.2017.05.006
   Turvey MT, 2014, J MOTOR BEHAV, V46, P143, DOI 10.1080/00222895.2013.798252
   Viswanathan N, 2018, ATTEN PERCEPT PSYCHO, V80, P316, DOI 10.3758/s13414-017-1449-8
   Viswanathan N, 2016, J ACOUST SOC AM, V140, pEL465, DOI 10.1121/1.4968034
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   Viswanathan N, 2009, PSYCHON B REV, V16, P74, DOI 10.3758/PBR.16.1.74
   Wallot S, 2018, MIND MACH, V28, P353, DOI 10.1007/s11023-017-9455-0
   Xiong WT, 2017, PHYS REV E, V95, DOI 10.1103/PhysRevE.95.062114
   Zamuner TS, 2016, J EXP CHILD PSYCHOL, V152, P136, DOI 10.1016/j.jecp.2016.07.012
   Zhou Y, 2013, PHYSICA A, V392, P1336, DOI 10.1016/j.physa.2012.11.055
NR 71
TC 3
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-042X
J9 FRONT PHYSIOL
JI Front. Physiol.
PD SEP 3
PY 2018
VL 9
AR 1152
DI 10.3389/fphys.2018.01152
PG 22
WC Physiology
SC Physiology
GA GS3IE
UT WOS:000443485100001
PM 30233386
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zhang, J
   Yan, HB
AF Zhang, Jie
   Yan, Hanbo
TI Contextually dependent cue realization and cue weighting for a laryngeal
   contrast in Shanghai Wu
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID VOICE QUALITY; ACOUSTIC CUES; INCOMPLETE NEUTRALIZATION;
   FUNDAMENTAL-FREQUENCY; SPEECH-PERCEPTION; TRADING RELATIONS; PHONATION
   TYPES; ENGLISH; TONE; PHONETICS
AB Phonological categories are often differentiated by multiple phonetic cues. This paper reports a production and perception study of a laryngeal contrast in Shanghai Wu that is not only cued in multiple dimensions, but also cued differently on different manners (stops, fricatives, sonorants) and in different positions (non-sandhi, sandhi). Acoustic results showed that, although this contrast has been described as phonatory in earlier literature, its primary cue is in tone in the non-sandhi context, with vowel phonation and consonant properties appearing selectively for specific manners of articulation. In the sandhi context where the tonal distinction is neutralized, these other cues may remain depending on the manner of articulation. Sonorants, in both contexts, embody the weakest cues. The perception results were largely consistent with the aggregate acoustic results, indicating that speakers adjust the perceptual weights of individual cues for a contrast according to manner and context. These findings support the position that phonological contrasts are formed by the integration of multiple cues in a language-specific, context-specific fashion and should be represented as such. (C) 2018 Acoustical Society of America.
C1 [Zhang, Jie] Univ Kansas, Dept Linguist, 1541 Lilac Lane, Lawrence, KS 66045 USA.
   [Yan, Hanbo] Shanghai Int Studies Univ, Sch Chinese Studies & Exchange, Shanghai 200083, Peoples R China.
RP Zhang, J (corresponding author), Univ Kansas, Dept Linguist, 1541 Lilac Lane, Lawrence, KS 66045 USA.
EM zhang@ku.edu
FU  [2 301 618]
FX We are grateful to Dan Yuan and Zhongmin Chen for hosting us at Fudan
   University for data collection, Yifeng Li and Zhenzhen Xu for serving as
   our Shanghai consultants, Kelly Berkson, Christina Esposito, and Goun
   Lee for helping us with VoiceSauce, Mingxing Li for helping us with the
   linear discriminant analysis, and the University of Kansas General
   Research Fund No. 2 301 618 for financial support. We also thank the
   Associate Editor Megha Sundara and four anonymous reviewers for their
   many insightful comments, which helped improve both the content and the
   presentation of the paper. All remaining errors are our own.
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Abramson AS, 2007, PHONETICA, V64, P80, DOI 10.1159/000107911
   Andruski Jean E., 2000, J INT PHON ASSOC, V30, P37, DOI DOI 10.1017/S0025100300006654
   AOKI H, 1970, PHONETICA, V21, P65, DOI 10.1159/000259291
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Berkson K., 2013, THESIS
   Berkson K., 2016, INDIAN LINGUISTICS, V76, P7
   Berkson K. H., 2016, FORMAL APPROACHES S, V6, P4
   Blankenship B, 2002, J PHONETICS, V30, P163, DOI 10.1006/jpho.2001.0155
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Breiman L, 1984, CLASSIFICATION REGRE
   Brunelle M, 2012, J ACOUST SOC AM, V131, P3088, DOI 10.1121/1.3693651
   Brunelle M, 2009, J PHONETICS, V37, P79, DOI 10.1016/j.wocn.2008.09.003
   CAO JF, 1992, J PHONETICS, V20, P77
   CHAO YR, 1967, LANGUAGE, V43, P92, DOI 10.2307/411386
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Chen YY, 2011, J PHONETICS, V39, P612, DOI 10.1016/j.wocn.2011.04.001
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Clements GN, 2009, CURR STUD LINGUIST, P19
   DAVIS K, 1994, J PHONETICS, V22, P177, DOI 10.1016/S0095-4470(19)30192-5
   DEKROM G, 1993, J SPEECH HEAR RES, V36, P254, DOI 10.1044/jshr.3602.254
   DiCanio C, 2014, J ACOUST SOC AM, V135, P884, DOI 10.1121/1.4861921
   DINNSEN DA, 1984, J PHONETICS, V12, P49, DOI 10.1016/S0095-4470(19)30850-2
   Dmitrieva O, 2010, J PHONETICS, V38, P483, DOI 10.1016/j.wocn.2010.06.001
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dutta I., 2009, ACOUSTICS STOP CONSO
   Esposito CM, 2012, J PHONETICS, V40, P466, DOI 10.1016/j.wocn.2012.02.007
   Esposito CM, 2010, J INT PHON ASSOC, V40, P181, DOI 10.1017/S0025100310000046
   Esposito CM, 2010, J PHONETICS, V38, P306, DOI 10.1016/j.wocn.2010.02.002
   FLEGE JE, 1989, J PHONETICS, V17, P299, DOI 10.1016/S0095-4470(19)30446-2
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Gao J., 2017, CAHIERS LINGUISTIQUE, V46, P1, DOI DOI 10.1163/19606028-04601001
   Gao J., 2013, P INT 2013, V2013, P3157
   Gao J.G., 2015, THESIS
   Gao J.-Y., 2015, P ICPHS 18 GLASG SCO
   Gao J.-Y., 2016, PAPERS HIST PHONOLOG, V1, P166, DOI DOI 10.2218/PIHPH.1.2016.1698
   Garellek M, 2013, J ACOUST SOC AM, V133, P1078, DOI 10.1121/1.4773259
   Garellek M, 2011, J INT PHON ASSOC, V41, P185, DOI 10.1017/S0025100311000193
   Gordon M, 2001, J PHONETICS, V29, P383, DOI 10.1006/jpho.2001.0147
   Halle Morris, 1971, MIT Q PROGR REPORT, V101, P198
   Halle PA, 2007, J ACOUST SOC AM, V121, P2899, DOI 10.1121/1.2534656
   Hanson HM, 2001, J PHONETICS, V29, P451, DOI 10.1006/jpho.2001.0146
   HILLENBRAND J, 1994, J SPEECH HEAR RES, V37, P769, DOI 10.1044/jshr.3704.769
   HOLMBERG EB, 1995, J SPEECH HEAR RES, V38, P1212, DOI 10.1044/jshr.3806.1212
   Holt LL, 2001, J ACOUST SOC AM, V109, P764, DOI 10.1121/1.1339825
   HUFFMAN MK, 1987, J ACOUST SOC AM, V81, P495, DOI 10.1121/1.394915
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Keyser SJ, 2006, LANGUAGE, V82, P33, DOI 10.1353/lan.2006.0051
   Khan SUD, 2012, J PHONETICS, V40, P780, DOI 10.1016/j.wocn.2012.07.001
   Kim HS, 1996, J PHONETICS, V24, P295, DOI 10.1006/jpho.1996.0016
   KINGSTON J, 1992, LANG SPEECH, V35, P99, DOI 10.1177/002383099203500209
   Kingston J, 2008, J PHONETICS, V36, P28, DOI 10.1016/j.wocn.2007.02.001
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   Kuznetsova A., 2016, TESTS LINEAR MIXED E
   Laver J., 1980, PHONETIC DESCRIPTION
   Lemon SC, 2003, ANN BEHAV MED, V26, P172, DOI 10.1207/S15324796ABM2603_02
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   Llanos F, 2013, J ACOUST SOC AM, V134, P2213, DOI 10.1121/1.4817845
   Massaro D. W., 1987, PSYCHOPHYSICS SPEECH, P46, DOI DOI 10.1007/978-94-009-3629-4_3
   MASSARO DW, 1983, PERCEPT PSYCHOPHYS, V34, P338, DOI 10.3758/BF03203046
   McMurray B., 2011, DO FEATURES COME, P197, DOI DOI 10.1075/LFAB.6.08MCM
   Mikuteit S, 2007, LANG SPEECH, V50, P247, DOI 10.1177/00238309070500020401
   Miller AL, 2007, J PHONETICS, V35, P56, DOI 10.1016/j.wocn.2005.11.001
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   PARKER EM, 1986, PERCEPT PSYCHOPHYS, V39, P129, DOI 10.3758/BF03211495
   PORT R, 1989, J PHONETICS, V17, P257, DOI 10.1016/S0095-4470(19)30444-9
   R Core Team, 2014, R LANG ENV STAT COMP
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Ren N., 1992, THESIS
   REPP BH, 1983, SPEECH COMMUN, V2, P341, DOI 10.1016/0167-6393(83)90050-X
   Roman Jakobson, 1952, PRELIMINARIES SPEECH
   Shen Z.-W., 1995, WUYU YANJIU, P219
   Shue Y.-L., 2011, VOICESAUCE PROGRAM V
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Sjolander K., 2004, SNACK SOUND TOOLKIT
   Steriade D., 1999, UCLA WORKING PAPERS, V2, P25
   Steriade D, 2008, NATURE WORD, P151, DOI DOI 10.7551/MITPRESS/9780262083799.003.0007
   Stevens KN, 2010, J PHONETICS, V38, P10, DOI 10.1016/j.wocn.2008.10.004
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   STEVENS KN, 1977, PHONETICA, V34, P264, DOI 10.1159/000259885
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   TRAILL A, 1988, J PHONETICS, V16, P385, DOI 10.1016/S0095-4470(19)30517-0
   Venables W. N, 2002, MODERN APPL STAT S
   Wang Y. L, 2011, THESIS
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
   Wayland R, 2003, J PHONETICS, V31, P181, DOI 10.1016/S0095-4470(02)00086-4
   Weihs C, 2005, ST CLASS DAT ANAL, P335
   Xu Bao-hua, 1988, SHANGHAI SHIQU FANGY
   Xu Y, 2005, PROSODYPRO PRAAT
   ZEE E, 1980, GLOSSA, V14, P45
   Zhu X., 1999, SHANGHAI TONETICS
   Zhu Xiaonong, 2006, GRAMMAR SHANGHAI WU
NR 96
TC 4
Z9 4
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2018
VL 144
IS 3
BP 1293
EP 1308
DI 10.1121/1.5054014
PG 16
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HK3GU
UT WOS:000457802200034
PM 30424656
OA Bronze
DA 2021-02-24
ER

PT J
AU Clayards, M
AF Clayards, Meghan
TI Differences in cue weights for speech perception are correlated for
   individuals within and across contrasts
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PHONEME; DISCRIMINATION; CATEGORIZATION; DISTINCTNESS; VARIABILITY;
   LINKS
AB Speech perception requires multiple acoustic cues. Cue weighting may differ across individuals but be systematic within individuals. The current study compared individuals' cue weights within and across contrasts. Forty-two listeners performed a two-alternative forced choice task for four out of five sets of minimal pairs, each varying orthogonally in two dimensions. Individuals' cue weights within a contrast were positively correlated for bet-bat, Luce-lose, and sock-shock, but not for bog-dog and dear-tear. Importantly, individuals' cue weights were also positively correlated across contrasts. This indicates that some individuals are better able to extract and use phonetic information across different dimensions. (C) 2018 Acoustical Society of America
C1 [Clayards, Meghan] McGill Univ, Dept Linguist, Montreal, PQ, Canada.
   [Clayards, Meghan] McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
RP Clayards, M (corresponding author), McGill Univ, Dept Linguist, Montreal, PQ, Canada.; Clayards, M (corresponding author), McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
EM meghan.clayards@mcgill.ca
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2016-0747]
FX This research was supported by SSHRC Grant No. 435-2016-0747 to M.C. The
   author would like to thank David Fleischer and Melanie Oriana for help
   with stimulus creation and data collection and Dave Kleinschmidt for a
   tutorial on using TANDEM-STRAIGHT.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Baese-Berk M. M., 2015, P ICPHS GLASG UK
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Benard MR, 2014, J ACOUST SOC AM, V135, pEL88, DOI 10.1121/1.4862879
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Clayards M., 2018, INDIVIDUAL DIFFERENC
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   HAZAN V, 1991, PERCEPT PSYCHOPHYS, V49, P187, DOI 10.3758/BF03205038
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   Kim D, 2018, J PHONETICS, V67, P1, DOI 10.1016/j.wocn.2017.11.003
   Kong E. J., 2015, P ICPHS GLASG UK
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   Moberly AC, 2014, J SPEECH LANG HEAR R, V57, P566, DOI 10.1044/2014_JSLHR-H-12-0323
   Neger TM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00628
   Perkell JS, 2004, J SPEECH LANG HEAR R, V47, P1259, DOI 10.1044/1092-4388(2004/095)
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   R Core Team, 2016, R LANG ENV STAT COMP
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
NR 29
TC 8
Z9 8
U1 1
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2018
VL 144
IS 3
BP EL172
EP EL177
DI 10.1121/1.5052025
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HK3GU
UT WOS:000457802200004
PM 30424660
OA Bronze
DA 2021-02-24
ER

PT J
AU Abbasi, AM
   Pathan, H
   Channa, MA
AF Abbasi, Abdul Malik
   Pathan, Habibullah
   Channa, Mansoor Ahmed
TI Experimental Phonetics and Phonology in Indo-Aryan & European Languages
SO JOURNAL OF LANGUAGE AND CULTURAL EDUCATION
LA English
DT Article
DE experimental phonetics; phonology; lexical stress; stress patterns
ID SYLLABLE STRUCTURE; DRIVEN ACCOUNT; STRESS; EXTRAMETRICALITY
AB Phonetics and phonology are very interesting areas of Linguistics, and are interrelated. They are based on the human speech system, speech perception, native speakers' intuition, and vocalic and consonantal systems of languages spoken in this world. There are more than six thousand languages spoken in the world. Every language has its own phonemic inventory, sound system, and phonological and phonetic rules that differ from other languages; most even have distinct orthographic systems. While languages spoken in developed countries are well-studied, those spoken in underdeveloped countries are not. There is a great need to examine them using a scientific approach. These under-studied languages need to be documented scientifically using advanced technological instruments to bring objective results, and linguistics itself provides the scientific basis for the study of a language. Most research studies to date have also been carried out with reference to old or existing written literature in poetry and drama. In the current era of research, scholars are looking for objective scientific approaches, e.g., experimental and instrumental studies that include acoustic research on the sound systems of less privileged languages spoken locally in developing countries. In this context, Sindhi is an example of this phenomenon, and un-researched with reference to syllable structure and the exponents of lexical stress patterns.
C1 [Abbasi, Abdul Malik] Sindh Madressatul Islam Univ, Karachi, Pakistan.
   [Pathan, Habibullah] Mehran Engn Univ, Hyderabad, Sindh, Pakistan.
   [Channa, Mansoor Ahmed] Quaid I Awaam Univ, Nawab Shah, Sindh, Pakistan.
RP Abbasi, AM (corresponding author), Sindh Madressatul Islam Univ, Expt Phonet & Phonol Indoayran & European Languag, Main Bldg,Room A-19, Karachi 74000, Pakistan.
EM amabbasi@smiu.edu.pk
RI Pathan, Habibullah/AAV-7602-2020; Abbasi, Abdul Malik/A-9367-2019;
   Channa, Mansoor/C-9385-2016
OI Abbasi, Abdul Malik/0000-0002-0481-2992; Channa,
   Mansoor/0000-0002-0554-5785
FU Higher Education Commission of PakistanHigher Education Commission of
   Pakistan
FX The author is much indebted to Higher Education Commission of Pakistan
   for funding the entire project.
CR Abbasi A A. M., 2012, INT J SOCIAL SCI ED, V2, P146
   Abbasi A. M., 2015, Sindh University Research Journal -Science Series, V47, P749
   Abbasi A. M., 2012, INT J RES, V1, P120
   Abbasi A. M., 2017, STRESS PATTERN SINDH
   Abbasi A. M., 2015, ANN RES J ENGLISH LA, V17, P9
   Abbasi A. M., 2010, PRODUCTION ENGLISH C
   Abbasi A. M., 2014, M 6 ANN 2 LANG ACQ T
   Abbasi AM, 2018, INT J ENGL LINGUIST, V8, P115, DOI 10.5539/ijel.v8n4p115
   Abbasi AM, 2018, INT J ENGL LINGUIST, V8, P101, DOI 10.5539/ijel.v8n3p101
   Abbasi AM, 2018, INT J ENGL LINGUIST, V8, P92, DOI 10.5539/ijel.v8n2p92
   Allana G. A., 1996, PAPERS SINDHI LANGUA
   Allana G. A., 2009, SINDHI PHONETICS
   Beckman M., 1993, GUIDELINES TOBI LABE
   Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Beckman M. E., 1986, STRESS NONSTRESS ACC
   Bosch A. R. K., 2011, SYLLABLE INTERNAL ST
   Broselow E, 1999, COMMUNICATION
   Broselow E, 1992, LANGUAGE TRANSFER LA
   Bughio M. Q, 2001, COMP STUDY SOCIOLING
   Bukhari, 2000, SYLLABIFICATION RESY
   Carmen J, 2008, P 26 W COAST C FORM, P208
   Carr P., 2008, GLOSSARY PHONOLOGY
   Cole J., 2006, ENCY LANGUAGE LINGUI, V11, P384
   COLE J, 2005, ENCY LINGUISTICS
   Cole Jennifer S., 2001, FACTS WORLDS LANGUAG, P647
   Cox F., 1984, SYLLABLE PHONOTACTIC
   Crosswhite K. M., 2001, STRESS PLACEME UNPUB
   Crosswhite K. M, 2001, PHONETICALLY BASED P, P191
   Crystal D., 2008, DICT LINGUISTICS PHO
   Crystal D., 1997, DICT LINGUISTICS PHO
   DAVENPORT M, 1998, INTRO PHONETICS PHON
   de Lacy P, 2007, CAMBRIDGE HANDBOOK OF PHONOLOGY, P281, DOI 10.1017/CBO9780511486371.013
   Dixon R. M. W., 1977, A GRAMMAR OF YIDIN
   DOGIL G, 1995, ARBEITSPAPIERE I MAS, V2, P1
   Dogil G, 1999, WORD PROSODIC SYSTEM, P273
   Duanmu S, 2005, TAIWAN J LINGUIST, V3, P45, DOI 10.6519/TJL.2005.3(2).2
   Dyrud L, 1997, THESIS
   FEINSTEIN MH, 1979, LINGUIST INQ, V10, P245
   Fleischhacker H, 2000, THESIS
   Flemming E. S., 2002, AUDITORY REPRESENTAT
   Flemming Edward, 2005, 149 M AC SOC AM VANC
   FRY DB, 1955, J ACOUST SOC AM, V27, P765, DOI 10.1121/1.1908022
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   Fujisaka H., 1984, Journal of the Acoustical Society of Japan (E), V5, P233
   GAY T, 1978, J ACOUST SOC AM, V63, P223, DOI 10.1121/1.381717
   Giegrich H. J., 1998, ENGLISH PHONOLOGY
   Gordon M, 2005, NAT LANG LINGUIST TH, V23, P595, DOI 10.1007/s11049-004-8874-9
   Gordon M, 2002, LANGUAGE, V78, P51, DOI 10.1353/lan.2002.0020
   Gordon M, 2002, LINGUA, V112, P901, DOI 10.1016/S0024-3841(02)00052-9
   Gordon M., 2011, BLACKWELL COMPANION, P924, DOI DOI 10.1002/9781444335262
   Gordon M, 2012, ACOUSTIC CORRELATES
   Gordon M., 2010, U CONN WORKSH STRESS
   Gordon M., 1999, THESIS
   Gordon M, 2010, STUD LANG, V34, P131, DOI 10.1075/sl.34.1.15gor
   Gordon Matthew, 2004, INT J AM LINGUIST, V70, P1, DOI DOI 10.1086/422264
   Gouskova M, 2001, CLS 37, V1
   Gussenhoven C, 2003, UNDERSTANDING PHONOL
   Halle Morris, 1987, AN ESSAY ON STRESS
   HAUGEN E, 1956, INT J AM LINGUIST, V22, P196, DOI 10.1086/464366
   HAWKINS P, 1992, INTRO PHONOLOGY
   HAYES B, 1982, LINGUIST INQ, V13, P227
   Hayes B, 1985, P 11 ANN M BERK LING, P429
   Hayes B., 1981, THESIS
   Hayes Bruce, 1995, METRICAL STRESS THEO
   Hualde J. I., 1999, WORD PROSODIC SYSTEM, P947
   Hualde Jose I., 1991, BASQUE PHONOLOGY
   Hussain S., 2010, THESIS
   Hussain S., 2005, PHONOLOGICAL PROCESS
   Hyman L, 1977, SO CALIFORNIA OCCASI, P37
   International  Phonetic. Association, 1999, HDB INT PHONETIC ASS
   Isacenko A., 1970, MODEL STANDARD GERMA
   ITO J, 1989, NAT LANG LINGUIST TH, V7, P217, DOI 10.1007/BF00138077
   Jatoi N. A, 1996, LINGUISTICS SINDHI L
   Jatoi N. A., 1983, LINGUISTICS SINDHI L
   Jones D., 1972, OUTLINE ENGLISH PHON
   Kachru Yamuna, 2006, LONDON ORIENTAL AFRI, V12
   KAGER R, 1992, P 11 W COAST C FORM, P298
   Kager R., 1989, METRICAL THEORY STRE
   Keerio A, 2010, THESIS
   KenstowIcz M., 1994, PHONOLOGY GENERATIVE
   Kidder E, 2008, COYOTE PAPERS WORKIN
   Kleber F, ACOUSTIC INVESTIGATI
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   Ladd D.Robert., 1996, INTONATIONAL PHONOLO
   Ladefoged P., 2001, COURSE PHONETICS
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lewis M. Paul, 2016, ETHNOLOGUE LANGUAGES
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   Maidment J., 2008, INTRO PHONETIC SCI
   Masica C., 1991, INDOARYAN LANGUAGES
   McDonough Joyce M., 2003, NAVAJO SOUND SYSTEM
   McMahon A., 2002, INTRO ENGLISH PHONOL
   Mehrotra R. C., 1965, INDIAN LINGUISTICS, V26
   Moore R. R., 1965, THESIS
   Nair R., 2001, P SALA 18 ROUNDT
   Nair R., 1999, THESIS
   Nayyar S., 2000, CRULP ANN STUDENT RE, P202
   Nihalani P, 1995, J INT PHON ASSOC, V25, P95, DOI DOI 10.1017/S0025100200005235
   Parker S., 2011, BLACKWELL COMPANION
   Parker Stephen G., 2002, THESIS
   Parsons T. W., 1987, VOICE SPEECH PROCESS
   Pickett J. M., 1999, ACOUSTICS SPEECH COM
   PIE, 2000, INTR PROT IND EUR ST
   Pierrehumbert J., 1980, THESIS
   Pierrehumbert J., 1996, CURRENT TRENDS PHONO, P549
   Puri V., 2013, THESIS
   Raphael LJ, 2006, SPEECH SCI PRIMER PH
   Reetz Henning, 2009, PHONETICS
   Roach P., 2004, ENGLISH PHONETICS PH
   SAPIR E, 1960, U CALIFORNIA PUBLICA, V22
   SINGH R, 1985, LINGUA, V67, P269, DOI 10.1016/0024-3841(85)90001-4
   Vogel I., 2001, PHONOLOGY, V18, P315, DOI [10.1017/S0952675701004201, DOI 10.1017/S0952675701004201]
   Wang HY, 2006, AVT PUBL, V23, P237
   Wheeler K, 1995, ACOUSTICAL SOC AM, V97
NR 114
TC 2
Z9 2
U1 0
U2 2
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 1339-4045
EI 1339-4584
J9 J LANG CULT EDUC
JI J. Lang. Cult. Educ.
PD SEP
PY 2018
VL 6
IS 3
BP 21
EP 52
DI 10.2478/jolace-2018-0023
PG 32
WC Education & Educational Research
SC Education & Educational Research
GA HH9TM
UT WOS:000456083000002
OA Other Gold
DA 2021-02-24
ER

PT J
AU Verhulst, S
   Ernst, F
   Garrett, M
   Vasilkov, V
AF Verhulst, Sarah
   Ernst, Frauke
   Garrett, Markus
   Vasilkov, Viacheslav
TI Suprathreshold Psychoacoustics and Envelope-Following Response
   Relations: Normal-Hearing, Synaptopathy and Cochlear Gain Loss
SO ACTA ACUSTICA UNITED WITH ACUSTICA
LA English
DT Article; Proceedings Paper
CT 18th International Symposium on Hearing (ISH)
CY JUN 10-15, 2018
CL Snekkersten, DENMARK
ID SPEECH-PERCEPTION; NOISE; MODULATION; EXPOSURE; YOUNG
AB The perceptual consequences of cochlear synaptopathy are presently not well understood as a direct quantification of synaptopathy is not possible in humans. To study its role for human hearing, recent studies have instead correlated changes in basic suprathreshold psychoacoustic tasks with individual differences in subcortical EEG responses, as a proxy measure for synaptopathy. It is not clear whether the reported missing relationships between the psychoacoustic quantities and the EEG are due to the adopted methods, or to a minor role of synaptopathy for sound perception. We address this topic by studying the theoretical relationship between subcortical EEG and psychoacoustic methods for different sensorineural hearing deficits. (c) 2018 The Author(s).
C1 [Verhulst, Sarah; Vasilkov, Viacheslav] Univ Ghent, Dept Informat Technol, Hearing Technol WAVES, Technol Pk 15, B-9052 Zwijnaarde, Belgium.
   [Ernst, Frauke; Garrett, Markus] Oldenburg Univ, Med Phys, Carl von Ossietzky Str 9-11, D-26129 Oldenburg, Germany.
   [Ernst, Frauke; Garrett, Markus] Oldenburg Univ, Cluster Excellence Hearing4all, Carl von Ossietzky Str 9-11, D-26129 Oldenburg, Germany.
RP Verhulst, S (corresponding author), Univ Ghent, Dept Informat Technol, Hearing Technol WAVES, Technol Pk 15, B-9052 Zwijnaarde, Belgium.
EM s.verhulst@ugent.be
OI Garrett, Markus/0000-0002-0115-5288; Vasilkov,
   Viacheslav/0000-0002-3202-8070
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [678120]; DFG Cluster of ExcellenceGerman Research Foundation
   (DFG) [EXC 1077-1]; DFGGerman Research Foundation (DFG)European
   Commission [PP 1608 VE924/1-1]
FX European Research Council grant agreement No 678120 (SV,VV). DFG Cluster
   of Excellence EXC 1077-1 "Hearing4all" (MG) and DFG PP 1608 VE924/1-1
   (FE).
CR Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Garrett M., TRENDS HEAR
   Jin SH, 2014, J AM ACAD AUDIOL, V25, P656, DOI 10.3766/jaaa.25.7.4
   Kale S, 2010, JARO-J ASSOC RES OTO, V11, P657, DOI 10.1007/s10162-010-0223-6
   Kohlrausch A, 2000, J ACOUST SOC AM, V108, P723, DOI 10.1121/1.429605
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Lobarinas E., 2015, JARO-J ASSOC RES OTO, V17, P89
   Mohrle D, 2016, NEUROBIOL AGING, V44, P173, DOI 10.1016/j.neurobiolaging.2016.05.001
   Oxenham AJ, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516686768
   Prendergast G, 2017, HEARING RES, V356, P74, DOI 10.1016/j.heares.2017.10.007
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   TAKAHASHI GA, 1992, J SPEECH HEAR RES, V35, P1410, DOI 10.1044/jshr.3506.1410
   Valero MD, 2017, HEARING RES, V353, P213, DOI 10.1016/j.heares.2017.07.003
   Verhulst S, 2018, HEARING RES, V360, P55, DOI 10.1016/j.heares.2017.12.018
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
NR 16
TC 8
Z9 8
U1 1
U2 4
PU S HIRZEL VERLAG
PI STUTTGART
PA POSTFACH 10 10 61, D-70 009 STUTTGART, GERMANY
SN 1610-1928
EI 1861-9959
J9 ACTA ACUST UNITED AC
JI Acta Acust. United Acust.
PD SEP-OCT
PY 2018
VL 104
IS 5
SI SI
BP 800
EP 803
DI 10.3813/AAA.919227
PG 4
WC Acoustics
SC Acoustics
GA GX7SK
UT WOS:000447976300016
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Bergelson, E
   Swingley, D
AF Bergelson, Elika
   Swingley, Daniel
TI Young Infants' Word Comprehension Given An Unfamiliar Talker or Altered
   Pronunciations
SO CHILD DEVELOPMENT
LA English
DT Article
ID OWN-NAME RECOGNITION; LEXICAL REPRESENTATION; DEVELOPMENTAL-CHANGES;
   SPEECH-PERCEPTION; VOWELS; VARIABILITY; CONSONANTS; CHILDREN
AB To understand spoken words, listeners must appropriately interpret co-occurring talker characteristics and speech sound content. This ability was tested in 6- to 14-months-olds by measuring their looking to named food and body part images. In the new talker condition (n=90), pictures were named by an unfamiliar voice; in the mispronunciation condition (n=98), infants' mothers mispronounced the words (e.g., nazz for nose). Six- to 7-month-olds fixated target images above chance across conditions, understanding novel talkers, and mothers' phonologically deviant speech equally. Eleven- to 14-months-olds also understood new talkers, but performed poorly with mispronounced speech, indicating sensitivity to phonological deviation. Between these ages, performance was mixed. These findings highlight the changing roles of acoustic and phonetic variability in early word comprehension, as infants learn which variations alter meaning.
C1 [Bergelson, Elika] Duke Univ, Durham, NC 27706 USA.
   [Swingley, Daniel] Univ Penn, Philadelphia, PA 19104 USA.
RP Bergelson, E (corresponding author), Duke Univ, Psychol & Neurosci, Box 90086, Durham, NC 27708 USA.
EM elika.bergelson@duke.edu
RI Swingley, Daniel/AAH-3230-2019
OI Swingley, Daniel/0000-0002-2891-0175; Bergelson,
   Elika/0000-0003-2742-4797
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01-HD049681]; NSF-IGERT/GRFP, NIH
   [T32-DC000035, DP5-OD019812-01]; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD073890, R01HD049681, R01HD049681, R01HD073890,
   R01HD049681, R01HD049681, R01HD073890, R01HD049681, R01HD073890] Funding
   Source: NIH RePORTER; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH &HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD049681, R01HD049681, R01HD049681, R01HD049681, R01HD049681]
   Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035, T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035, T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035, T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035, T32DC000035] Funding
   Source: NIH RePORTER; OFFICE OF THE DIRECTOR, NATIONAL INSTITUTES OF
   HEALTHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [DP5OD019812, DP5OD019812, DP5OD019812,
   DP5OD019812, DP5OD019812] Funding Source: NIH RePORTER
FX The authors would like to acknowledge members of the Penn Infant
   Language Center, in particular Elizabeth Crutchley, as well as the
   infants and families involved in this research. This work was funded by
   NIH R01-HD049681 to Daniel Swingley and by NSF-IGERT/GRFP, NIH
   T32-DC000035, and DP5-OD019812-01 to Elika Bergelson.
CR Bergelson E., EARLY NOUN RELATIONS
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   Dale PS, 1996, BEHAV RES METH INS C, V28, P125, DOI 10.3758/BF03203646
   Delle Luche C, 2017, INFANCY, V22, P362, DOI 10.1111/infa.12151
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fernald A, 2008, DEVELOPMENTAL PSYCHOLINGUISTICS: ON-LINE METHODS IN CHILDREN'S LANGUAGE PROCESSING, P97
   Halle PA, 1996, INFANT BEHAV DEV, V19, P463, DOI 10.1016/S0163-6383(96)90007-7
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Johnson EK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083546
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1979, J ACOUST SOC AM, V66, P1668, DOI 10.1121/1.383639
   Mani N, 2007, J MEM LANG, V57, P252, DOI 10.1016/j.jml.2007.03.005
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   Parise E, 2012, PSYCHOL SCI, V23, P728, DOI 10.1177/0956797612438734
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   ROVEECOLLIER C, 1992, DEV PSYCHOL, V28, P307, DOI 10.1037/0012-1649.28.2.307
   Schmale R, 2010, INFANCY, V15, P650, DOI 10.1111/j.1532-7078.2010.00032.x
   Seidl A, 2014, LANG LEARN DEV, V10, P297, DOI 10.1080/15475441.2013.858575
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Swingley D, 2009, J MEM LANG, V60, P252, DOI 10.1016/j.jml.2008.11.003
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   van Heugten M, 2012, J SPEECH LANG HEAR R, V55, P554, DOI 10.1044/1092-4388(2011/10-0347)
   Vihman MM, 2004, J MEM LANG, V50, P336, DOI 10.1016/j.jml.2003.11.004
   Walker A., 2011, CONGRUENCE WORD AGE
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
NR 37
TC 14
Z9 14
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0009-3920
EI 1467-8624
J9 CHILD DEV
JI Child Dev.
PD SEP-OCT
PY 2018
VL 89
IS 5
BP 1567
EP 1576
DI 10.1111/cdev.12888
PG 10
WC Psychology, Educational; Psychology, Developmental
SC Psychology
GA GS8CW
UT WOS:000443935700010
PM 28639708
OA Bronze, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Feng, L
   Oxenham, AJ
AF Feng, Lei
   Oxenham, Andrew J.
TI Spectral Contrast Effects Produced by Competing Speech Contexts
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE speech perception; phoneme categorization; attention; auditory
   perception; spectral contrast
ID STOP-CONSONANT PERCEPTION; COCHLEAR-IMPLANT USERS; AUDITORY ENHANCEMENT;
   PRECEDING LIQUID; IDENTIFICATION; CATEGORIZATION; COMPENSATION;
   COMPONENTS; LISTENERS; MASKING
AB The long-term spectrum of a preceding sentence can alter the perception of a following speech sound in a contrastive manner. This speech context effect contributes to our ability to extract reliable spectral characteristics of the surrounding acoustic environment and to compensate for the voice characteristics of different speakers or spectral colorations in different listening environments to maintain perceptual constancy. The extent to which such effects are mediated by low-level "automatic" processes, or require directed attention, remains unknown. This study investigated spectral context effects by measuring the effects of two competing sentences on the phoneme category boundary between /I/ and /epsilon/ in a following target word, while directing listeners' attention to one or the other context sentence. Spatial separation of the context sentences was achieved either by presenting them to different ears, or by presenting them to both ears but imposing an interaural time difference (ITD) between the ears. The results confirmed large context effects based on ear of presentation. Smaller effects were observed based on either ITD or attention. The results, combined with predictions from a two-stage model, suggest that ear-specific factors dominate speech context effects but that the effects can be modulated by higher-level features, such as perceived location, and by attention.
C1 [Feng, Lei; Oxenham, Andrew J.] Univ Minnesota, Dept Psychol, N218 Elliott Hall,75 East River Rd, Minneapolis, MN 55455 USA.
RP Feng, L (corresponding author), Univ Minnesota, Dept Psychol, N218 Elliott Hall,75 East River Rd, Minneapolis, MN 55455 USA.
EM fengl@umn.edu
OI Oxenham, Andrew/0000-0002-9365-1157
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 DC012262];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC012262, R01DC012262, R01DC012262,
   R01DC012262, R01DC012262, R01DC012262, R01DC012262, R01DC012262,
   R01DC012262, R01DC012262] Funding Source: NIH RePORTER
FX This work was supported by National Institutes of Health Grant R01
   DC012262.
CR ARAVAMUDHAN R, 2005, J ACOUST SOC AM, V118, P1962, DOI [10.1121/1.4781551, DOI 10.1121/1.4781551]
   Barlow H. B., 1961, SENS COMMUN, P217, DOI [10.7551/mitpress/9780262518420.003.0002, DOI 10.7551/MITPRESS/9780262518420.003.0013, 10.7551/mitpress/9780262518420.003.0013]
   Besle J, 2011, J NEUROSCI, V31, P3176, DOI 10.1523/JNEUROSCI.4518-10.2011
   Blauert J., 1997, SPATIAL HEARING PSYC
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Darwin CJ, 1997, TRENDS COGN SCI, V1, P327, DOI 10.1016/S1364-6613(97)01097-8
   Elhilali M, 2009, PLOS BIOL, V7, DOI 10.1371/journal.pbio.1000129
   FOWLER CA, 1990, PERCEPT PSYCHOPHYS, V48, P559, DOI 10.3758/BF03211602
   Goupell MJ, 2012, J ACOUST SOC AM, V131, P1007, DOI 10.1121/1.3672650
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2002, HEARING RES, V167, P156, DOI 10.1016/S0378-5955(02)00383-0
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Kreft HA, 2017, JARO-J ASSOC RES OTO, V18, P483, DOI 10.1007/s10162-017-0618-8
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   LINDBLOM BE, 1967, J ACOUST SOC AM, V42, P830, DOI 10.1121/1.1910655
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Lotto AJ, 1997, J ACOUST SOC AM, V102, P1134, DOI 10.1121/1.419865
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   MANN VA, 1986, COGNITION, V24, P169, DOI 10.1016/S0010-0277(86)80001-4
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   MANN VA, 1981, J ACOUST SOC AM, V69, P548, DOI 10.1121/1.385483
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Schouten JF, 1940, P K NED AKAD WETENSC, V43, P356
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   STILP CE, 2016, J ACOUST SOC AM, V139, P2047, DOI [10.1121/2.0000233, DOI 10.1121/2.0000233]
   Stilp CE, 2017, JARO-J ASSOC RES OTO, V18, P465, DOI 10.1007/s10162-017-0615-y
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Viemeister N. F., 1980, PSYCHOPHYSICAL PHYSL, P190, DOI DOI 10.1007/978-94-009-9144-6_28
   VIEMEISTER NF, 1982, J ACOUST SOC AM, V71, P1502, DOI 10.1121/1.387849
   Wang NY, 2016, HEARING RES, V333, P150, DOI 10.1016/j.heares.2016.01.012
   Wang NY, 2012, J ACOUST SOC AM, V131, pEL421, DOI 10.1121/1.4710838
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Winn MB, 2012, J ACOUST SOC AM, V131, P1465, DOI 10.1121/1.3672705
NR 38
TC 7
Z9 7
U1 0
U2 0
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD SEP
PY 2018
VL 44
IS 9
BP 1447
EP 1457
DI 10.1037/xhp0000546
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA GR4OA
UT WOS:000442590900011
PM 29847973
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Yao, N
   Ritchie, C
   Cornwell, T
   Leff, B
AF Yao, Nengliang (Aaron)
   Ritchie, Christine
   Cornwell, Thomas
   Leff, Bruce
TI Use of Home-Based Medical Care and Disparities
SO JOURNAL OF THE AMERICAN GERIATRICS SOCIETY
LA English
DT Article
DE hearing loss; cognitive decline; rehabilitation; speech perception;
   elderly
ID BARRIERS
AB ObjectivesDesignTo examine the volume of home-based medical care (HBMC) visits made to frail older adults between 2011 and 2014 and sex, racial, ethnic, frailty-related comorbidity, and geographic disparities in HBMC use.
   Observational study using secondary data.
   SettingParticipants5% Medicare claims for 2011 to 2014.
   Medicare beneficiaries.
   MeasurementsResultsUsage rates of HBMC of frail Medicare beneficiaries were compared using descriptive statistics and multivariate logistic regression.
   From 2011 to 2014, use of HBMC increased from 8.7% to 10.1% in beneficiaries with medium comorbidity and from 14.2% to 15.7% in those with high comorbidity. After adjustment for multiple factors, blacks were 21% more likely (95% confidence interval (CI)=17-25%, p<.001) to use HBMC, and Asians were 31% less likely (95% CI=24-38%, p<.001) to use HBMC than whites. Women were 24% more likely (95% CI=21-27%, p<.001) to use HBMC than men. Rural residents were 78% less likely (95% CI=76-79%) than those in the largest metropolitan county to receive HBMC. Nurse practitioners made 40% of HBMC visits to rural residents, and internists made 32% of HBMC visits in large metropolitan counties. There were substantial geographic variations in the use of HBMC in frail older adults; the national usage rate was 11%, and 7 states had rates less than 5%.
   ConclusionAlthough there was a small increase in the use of HBMC between 2011 and 2014, the majority of eligible home-limited individuals have not received medical care at home, particularly rural residents and those living in underserved states. More HBMC practices are needed, and programs may need to integrate telemedicine to expand HBMC in rural communities.
C1 [Yao, Nengliang (Aaron)] Univ Virginia, Sch Med, Dept Publ Hlth Sci, POB 800765, Charlottesville, VA 22903 USA.
   [Ritchie, Christine] Univ Calif San Francisco, Dept Med, Div Geriatr, San Francisco, CA USA.
   [Cornwell, Thomas] Home Ctr Care Inst, Baltimore, MD USA.
   [Leff, Bruce] Johns Hopkins Univ, Div Geriatr Med, Baltimore, MD USA.
RP Yao, N (corresponding author), Univ Virginia, Sch Med, Dept Publ Hlth Sci, POB 800765, Charlottesville, VA 22903 USA.
EM ayao@virginia.edu
OI Yao, Nengliang (Aaron)/0000-0001-9000-0378
CR Barrera TL, 2017, CLIN GERONTOLOGIST, V40, P114, DOI 10.1080/07317115.2016.1254133
   Centers for Medicare & Medicaid Services, 2015, AFF CAR ACT PAYM MOD
   De Jonge KE, 2014, J AM GERIATR SOC, V62, P1825, DOI 10.1111/jgs.12974
   Galdas PM, 2005, J ADV NURS, V49, P616, DOI 10.1111/j.1365-2648.2004.03331.x
   Home Centered Care Institute, 2017, HCCI LAUNCH NAT NETW
   Klein S, 2017, OVERVIEW HOMEBASED P
   Landers SH, 2005, JAMA-J AM MED ASSOC, V294, P2431
   Lee S, 2010, AM J HEALTH BEHAV, V34, P21
   Ngo-Metzger Q, 2003, J GEN INTERN MED, V18, P44, DOI 10.1046/j.1525-1497.2003.20205.x
   Peterson LE, 2012, J AM BOARD FAM MED, V25, P862, DOI 10.3122/jabfm.2012.06.120046
   US Census Bureau, 2011, BLACK POP 2010
   Yao NL, 2016, HEALTH AFFAIR, V35, P1404, DOI 10.1377/hlthaff.2015.1437
   Yao NL, 2017, J AM GERIATR SOC, V65, P847, DOI 10.1111/jgs.14698
   Yousaf O, 2015, HEALTH PSYCHOL REV, V9, P264, DOI 10.1080/17437199.2013.840954
NR 14
TC 6
Z9 6
U1 3
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0002-8614
EI 1532-5415
J9 J AM GERIATR SOC
JI J. Am. Geriatr. Soc.
PD SEP
PY 2018
VL 66
IS 9
BP 1716
EP 1720
DI 10.1111/jgs.15444
PG 5
WC Geriatrics & Gerontology; Gerontology
SC Geriatrics & Gerontology
GA HD1SL
UT WOS:000452291700011
PM 30084141
DA 2021-02-24
ER

PT J
AU Kong, EJ
   Lee, H
AF Kong, Eun Jong
   Lee, Hyunjung
TI Attentional Modulation and Individual Differences in Explaining the
   Changing Role of Fundamental Frequency in Korean Laryngeal Stop
   Perception
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Attention; cue weighting; Korean stop perception; laryngeal contrast;
   individual difference
ID ACOUSTIC CUES; INITIAL STOPS; SELECTIVE ATTENTION; SPEECH SEGMENTATION;
   CATEGORIZATION; CONTRAST; ENGLISH; RECOGNITION; DISTINCTION; INFORMATION
AB Previous research has shown differential degrees of attention in processing hierarchical linguistic information where higher order cues require greater attention in speech processing. The current study investigated the influence of attentional resources on acoustic cue weightings in speech perception by examining Korean listeners' identifications of the three-way laryngeal stops (tense vs. lax vs. aspirated). Using a dual-task paradigm, we presented 28 adult Korean listeners with identification tasks blocked by no-distractor versus distractor conditions where arithmetic calculations distracted the listeners' speech processing. Auditory stimuli were prepared by combining voice-onset times (VOTs) and fundamental frequencies (F0s) based on natural production. Group analyses revealed that VOT was an informative parameter across the three stop laryngeal categories and the listeners' reliance on VOT was consistently reduced under the distracting condition. Subsequent individual-level analysis further showed that listeners with heavier perceptual reliance on VOT were hindered by the distractor more than others in utilizing VOT. Unlike VOT, the F0 cue did not systematically interact with the distracting listening condition. The findings indicated that VOT (but not F0) required greater attention in processing the Korean laryngeal stops, and was presumably a higher order acoustic cue than F0. The current study contributes to the understanding of attention and cue primacy in general as well as to the clarification of the relative roles of VOT and F0 for the Korean stop laryngeal contrast.
C1 [Kong, Eun Jong] Korea Aerosp Univ, 100 Hanggongdae Gil, Goyang 10540, Gyeonggi Do, South Korea.
   [Lee, Hyunjung] Incheon Natl Univ, 12 Gaebeol Ro, Incheon 21999, South Korea.
RP Kong, EJ (corresponding author), Korea Aerosp Univ, 100 Hanggongdae Gil, Goyang 10540, Gyeonggi Do, South Korea.; Lee, H (corresponding author), Incheon Natl Univ, 12 Gaebeol Ro, Incheon 21999, South Korea.
EM ekong@kau.ac.kr; hyunjunglee123@gmail.com
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Bang H. Y., 2015, P 18 INT C PHON SCI
   Beddor P.S., 2015, P 18 INT C PHON SCI
   Beddor PS, 2009, LANGUAGE, V85, P785
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Choi TH, 2013, J ACOUST SOC AM, V134, pEL541, DOI 10.1121/1.4829059
   Cohen MR, 2009, NAT NEUROSCI, V12, P1594, DOI 10.1038/nn.2439
   Cutler A., 1987, COMPUTER SPEECH LANG, V2, P3
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Eun-Jong Kong, 2013, [Phonetics and Speech Sciences, 말소리와 음성과학], V5, P81, DOI 10.13064/KSSS.2013.5.4.081
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Francis AL, 2006, J ACOUST SOC AM, V120, P2884, DOI 10.1121/1.2346131
   Francis AL, 2009, ATTEN PERCEPT PSYCHO, V71, P1360, DOI 10.3758/APP.71.6.1360
   GORDON PC, 1993, COGNITIVE PSYCHOL, V25, P1, DOI 10.1006/cogp.1993.1001
   HAN MS, 1970, PHONETICA, V22, P112, DOI 10.1159/000259311
   Harrington J, 2014, LAB PHONOL, V5, P1, DOI 10.1515/lp-2014-0001
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kang KH, 2006, J ACOUST SOC AM, V119, P1672, DOI 10.1121/1.2166607
   Kang KH, 2008, J ACOUST SOC AM, V124, P3909, DOI 10.1121/1.2988292
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   KIM CW, 1965, WORD, V21, P339, DOI 10.1080/00437956.1965.11435434
   Kim M, 2004, P 8 INT C SPOK LANG, P49
   Kim MR, 2004, J EAST ASIAN LINGUIS, V13, P59, DOI 10.1023/B:JEAL.0000007344.43938.4e
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kong EJ, 2011, J PHONETICS, V39, P196, DOI 10.1016/j.wocn.2011.02.002
   Lavie N, 2004, J EXP PSYCHOL GEN, V133, P339, DOI 10.1037/0096-3445.133.3.339
   Lee H, 2013, J PHONETICS, V41, P117, DOI 10.1016/j.wocn.2012.12.002
   Lee H, 2012, J INT PHON ASSOC, V42, P145, DOI 10.1017/S0025100312000035
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2004, J EXP PSYCHOL HUMAN, V30, P397, DOI 10.1037/0096-1523.30.2.397
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Morrison GS, 2007, SEGMENTAL PROSODIC I, P219
   Norris D, 1997, COGNITIVE PSYCHOL, V34, P191, DOI 10.1006/cogp.1997.0671
   R Core Team, 2012, R LANG ENV STAT COMP
   REPP BH, 1983, SPEECH COMMUN, V2, P341, DOI 10.1016/0167-6393(83)90050-X
   Schertz J, 2016, ATTEN PERCEPT PSYCHO, V78, P355, DOI 10.3758/s13414-015-0987-1
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Stevens M, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.003
   SUMMERFIELD Q, 1977, J ACOUST SOC AM, V62, P435, DOI 10.1121/1.381544
   Vuilleumier P, 2007, PHILOS T R SOC B, V362, P837, DOI 10.1098/rstb.2007.2092
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Wright J., 2007, THESIS
   Yu ACL, 2011, P INT C PHON SCI 17, P2236
   Yu ACL, 2016, J ACOUST SOC AM, V139, P1672, DOI 10.1121/1.4944992
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
   김미령, 2013, [The Linguistic Association of Korea Journal, 언어학], V21, P1
   강경호, 2010, [Phonetics and Speech Sciences, 말소리와 음성과학], V2, P3
NR 55
TC 6
Z9 6
U1 1
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD SEP
PY 2018
VL 61
IS 3
BP 384
EP 408
DI 10.1177/0023830917729840
PG 25
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA GQ7PR
UT WOS:000441937100003
PM 28937301
DA 2021-02-24
ER

PT J
AU Gennari, SP
   Millman, RE
   Hymers, M
   Mattys, SL
AF Gennari, Silvia P.
   Millman, Rebecca E.
   Hymers, Mark
   Mattys, Sven L.
TI Anterior paracingulate and cingulate cortex mediates the effects of
   cognitive load on speech sound discrimination
SO NEUROIMAGE
LA English
DT Article
DE Speech perception; Cognitive load; Visual memory load; Divided
   attention; Anterior cingulate gyrus; fMRI
ID COMPREHENSION
AB Perceiving speech while performing another task is a common challenge in everyday life. How the brain controls resource allocation during speech perception remains poorly understood. Using functional magnetic resonance imaging (fMRI), we investigated the effect of cognitive load on speech perception by examining brain responses of participants performing a phoneme discrimination task and a visual working memory task simultaneously. The visual task involved holding either a single meaningless image in working memory (low cognitive load) or four different images (high cognitive load). Performing the speech task under high load, compared to low load, resulted in decreased activity in pSTG/pMTG and increased activity in visual occipital cortex and two regions known to contribute to visual attention regulation-the superior parietal lobule (SPL) and the paracingulate and anterior cingulate gyrus (PaCG, ACG). Critically, activity in PaCG/ACG was correlated with performance in the visual task and with activity in pSTG/pMTG: Increased activity in PaCG/ACG was observed for individuals with poorer visual performance and with decreased activity in pSTG/pMTG. Moreover, activity in a pSTG/pMTG seed region showed psychophysiological interactions with areas of the PaCG/ACG, with stronger interaction in the high-load than the low-load condition. These findings show that the acoustic analysis of speech is affected by the demands of a concurrent visual task and that the PaCG/ACG plays a role in allocating cognitive resources to concurrent auditory and visual information.
C1 [Gennari, Silvia P.; Hymers, Mark; Mattys, Sven L.] Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
   [Millman, Rebecca E.] Univ Manchester, Fac Biol Med & Hlth, Sch Hlth Sci, Manchester Ctr Audiol & Deafness, Manchester M13 9PL, Lancs, England.
   [Millman, Rebecca E.] Cent Manchester Univ Hosp Fdn Trust, Manchester Acad Hlth Sci Ctr, NIHR Manchester Biomed Res Ctr, Manchester M13 9WL, Lancs, England.
RP Mattys, SL (corresponding author), Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
EM sven.mattys@york.ac.uk
OI Millman, Rebecca/0000-0001-8606-0167
FU ESRCUK Research & Innovation (UKRI)Economic & Social Research Council
   (ESRC) [RES-062-23-2746]
FX This study was supported in part by an ESRC grant to S. L. Mattys
   (RES-062-23-2746). We thank Tatjana Zimasa, Francesca Mandino, and Kris
   Farrant for help with testing and data analysis.
CR BAKER E, 1981, NEUROPSYCHOLOGIA, V19, P1, DOI 10.1016/0028-3932(81)90039-7
   Barton M, 2015, J NEUROSCI METH, V253, P218, DOI 10.1016/j.jneumeth.2015.06.021
   Bates D., 2015, ARXIV150604967STAT
   Beckmann CF, 2003, NEUROIMAGE, V20, P1052, DOI 10.1016/S1053-8119(03)00435-X
   Beckmann M, 2009, J NEUROSCI, V29, P1175, DOI 10.1523/JNEUROSCI.3328-08.2009
   Botvinick MM, 2004, TRENDS COGN SCI, V8, P539, DOI 10.1016/j.tics.2004.10.003
   Botvinick MM, 2007, COGN AFFECT BEHAV NE, V7, P356, DOI 10.3758/CABN.7.4.356
   Botvinick MM, 2001, PSYCHOL REV, V108, P624, DOI 10.1037//0033-295X.108.3.624
   Brungart D., 2013, P M AC, V19, DOI DOI 10.1121/1.4800033
   Catani M, 2002, NEUROIMAGE, V17, P77, DOI 10.1006/nimg.2002.1136
   Davis MH, 2003, J NEUROSCI, V23, P3423
NR 11
TC 14
Z9 14
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD SEP
PY 2018
VL 178
BP 735
EP 743
DI 10.1016/j.neuroimage.2018.06.035
PG 9
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GM8IF
UT WOS:000438467800062
PM 29902588
OA Other Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Baese-Berk, M
   Morrill, TH
   Dilley, L
AF Baese-Berk, Melissa
   Morrill, Tuuli H.
   Dilley, Laura
TI Predictability and perception for native and non-native listeners
SO LINGUISTICS VANGUARD
LA English
DT Article
DE predictability; non-native speech; speaking rate; frequency; collocation
   strength
ID SPEECH RATE; CONTEXT; TIME; FREQUENCY; KNOWLEDGE; DURATION; WORDS; TEMPO
AB Phonological knowledge is influenced by a variety of cues that reflect predictability (e.g. semantic predictability). Listeners utilize various aspects of predictability when determining what they have heard. In the present paper, we ask how aspects of the acoustic phonetic signal (e.g. speaking rate) interact with other knowledge reflecting predictability (e.g. lexical frequency and collocation strength) to influence how speech is perceived. Specifically, we examine perception of function words by native and non-native speakers. Our results suggest that both native and non-native speakers are sensitive to factors that influence the predictability of the signal, including speaking rate, frequency, and collocation strength, when listening to speech, and use these factors to predict the phonological structure of stretches of ambiguous speech. However, reliance on these cues differs as a function of their experience and proficiency with the target language. Non-native speakers are less sensitive to some aspects of the acoustic phonetic signal (e.g. speaking rate). However, they appear to be quite sensitive to other factors, including frequency. We discuss how these results inform our understanding of the interplay between predictability and speech perception by different listener populations and how use of features reflecting predictability interacts with recovery of phonological structure of spoken language.
C1 [Baese-Berk, Melissa] Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
   [Dilley, Laura] Michigan State Univ, E Lansing, MI 48824 USA.
RP Baese-Berk, M (corresponding author), Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
EM mbaesebe@uoregon.edu
CR Baese-Berk M. M, 2016, P SPEECH PROSODY, V8, P979
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Barnes R, 2000, COGNITIVE PSYCHOL, V41, P254, DOI 10.1006/cogp.2000.0738
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Clopper CG, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0044
   Daland R, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0045
   Davies M., 2008, CORPUS CONT AM ENGLI
   Dilley LC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01002
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Gahl S, 2004, LANGUAGE, V80, P748, DOI 10.1353/lan.2004.0185
   Gahl S, 2008, LANGUAGE, V84, P474
   HUNNICUTT S, 1985, LANG SPEECH, V28, P47, DOI 10.1177/002383098502800103
   Jones MR, 2005, PERCEPT PSYCHOPHYS, V67, P398, DOI 10.3758/BF03193320
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Lai W, 2016, P SPEECH PROSODY, V8, P1124, DOI [10.13140/RG.2.1.1749.4165, DOI 10.21437/SPEECHPROSODY.2016-231]
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   LIBERMAN AM, 1956, J EXP PSYCHOL, V52, P127, DOI 10.1037/h0041240
   LIEBERMAN P, 1963, LANG SPEECH, V6, P172, DOI 10.1177/002383096300600306
   Lotto AJ, 1996, PERCEPT PSYCHOPHYS, V58, P1005, DOI 10.3758/BF03206828
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   McAuley JD, 2007, PERCEPT PSYCHOPHYS, V69, P709, DOI 10.3758/BF03193773
   McAuley JD, 2003, J EXP PSYCHOL HUMAN, V29, P1102, DOI 10.1037/0096-1523.29.6.1102
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   Morrill T, 2015, PSYCHON B REV, V22, P1451, DOI 10.3758/s13423-015-0820-9
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   PICKETT JM, 1960, LANG SPEECH, V3, P11, DOI 10.1177/002383096000300103
   PISONI DB, 1983, PERCEPT PSYCHOPHYS, V34, P314, DOI 10.3758/BF03203043
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Priva UC, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0028
   R Development Core Team, 2014, R LANG ENV STAT COMP
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Sawusch JR, 2000, PERCEPT PSYCHOPHYS, V62, P285, DOI 10.3758/BF03205549
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
NR 40
TC 2
Z9 2
U1 0
U2 0
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2199-174X
J9 LINGUIST VANGUARD
JI Linguist. Vanguard
PD SEP
PY 2018
VL 4
SU 2
AR 20170022
DI 10.1515/lingvan-2017-0022
PG 10
WC Linguistics; Language & Linguistics
SC Linguistics
GA HB5JG
UT WOS:000451095900005
DA 2021-02-24
ER

PT J
AU Daland, R
   Zuraw, K
AF Daland, Robert
   Zuraw, Kie
TI Loci and locality of informational effects on phonetic implementation
SO LINGUISTICS VANGUARD
LA English
DT Article
DE predictability; informativity; information; duration
ID TRACE MODEL; SPEECH; WORDS; PREDICTABILITY; FREQUENCY; DURATION
AB Recent evidence suggests that the phonetic realization of linguistic units is sensitive to informational context. For example, the duration of a word is shorter when it is probable given the following word. Word-specific phonetic variation is unexpected according to modular/feedforward models. We consider various challenges to identifying the loci of informational effects on phonetic implementation - do they arise in production, perception, memory, or some combination? Section 2 addresses a theoretical issue: what are the right measure(s) of predictability/informativity? An urgent direction for future work is to understand what kinds of context matter and why. Section 3 reviews second-mention reduction and other non-local discourse effects, which strongly suggest a production locus (rather than arising in speech perception or memory). Important future directions include modeling discourse/topic in corpus studies, and experimentally assessing the role of nonlocal context in perception and memory. Section 4 addresses the role of computational modeling. We call for integrated, implemented end-to-end models which include speech perception, lexical representation, and speech production components.
C1 [Daland, Robert; Zuraw, Kie] Univ Calif Los Angeles, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
RP Daland, R (corresponding author), Univ Calif Los Angeles, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
EM r.daland@gmail.com
CR Altmann EG, 2009, PLOS ONE, V4, pA31, DOI 10.1371/journal.pone.0007678
   ANDERSON A. H., 2002, P 6 WORKSH SEM PRAGM, P13
   Baker RE, 2009, LANG SPEECH, V52, P391, DOI 10.1177/0023830909336575
   Bard EG, 2000, J MEM LANG, V42, P1, DOI 10.1006/jmla.1999.2667
   Bard Ellen G, 1989, P EUR 89, P573
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   Bishop J., 2012, PROSODY MEANING INTE
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Braun B, 2006, J ACOUST SOC AM, V119, P4006, DOI 10.1121/1.2195267
   Bybee Joan, 2001, PHONOLOGY LANGUAGE U
   Carbary K, 2015, LANG COGN NEUROSCI, V30, P197, DOI 10.1080/23273798.2014.885534
   CHURCH K, 2000, P 18 C COMP LING, V1, P173
   Cohen Priva U., 2008, P 27 W COAST C FORM, P90
   Cohen Priva U., 2012, THESIS
   Daland R, 2015, LINGUA, V159, P70, DOI 10.1016/j.lingua.2015.03.002
   Daland R, 2013, J CHILD LANG, V40, P1091, DOI 10.1017/S0305000912000372
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   Fink Angela, 2015, Linguist Vanguard, V1, P215
   Flege J. E., 2007, LAB PHONOLOGY, P353
   Fosler-Lussier E, 1999, SPEECH COMMUN, V29, P137, DOI 10.1016/S0167-6393(99)00035-7
   Fowler CA, 1997, J MEM LANG, V37, P24, DOI 10.1006/jmla.1996.2504
   FOWLER CA, 1988, LANG SPEECH, V31, P307, DOI 10.1177/002383098803100401
   German James, 2009, THESIS
   Hale J, 2003, J PSYCHOLINGUIST RES, V32, P101, DOI 10.1023/A:1022492123056
   Hall Kathleen, MESSAGE SHAPES PHONO
   Kello CT, 2004, J ACOUST SOC AM, V116, P2354, DOI 10.1121/1.1715112
   Kirchner R, 2010, J PHONETICS, V38, P540, DOI 10.1016/j.wocn.2010.07.005
   Lam TQ, 2014, J EXP PSYCHOL LEARN, V40, P829, DOI 10.1037/a0035780
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Levy R, 2009, P NATL ACAD SCI USA, V106, P21086, DOI 10.1073/pnas.0907664106
   Luce R.D., 1959, INDIVIDUAL CHOICE BE
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Munson B, 2001, J SPEECH LANG HEAR R, V44, P778, DOI 10.1044/1092-4388(2001/061)
   Niyogi P, 2006, CURR STUD LINGUIST, V43, P1
   Piantadosi ST, 2011, P NATL ACAD SCI USA, V108, P3526, DOI 10.1073/pnas.1012551108
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Plaut DC, 1999, CARN S COGN, P381
   Priva UC, 2017, LANGUAGE, V93, P569, DOI 10.1353/lan.2017.0037
   Roelofs A, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P313
   Roy B. C., 2012, P 34 ANN M COGN SCI
   Schreuder R., 1995, MORPHOLOGICAL ASPECT, P131, DOI DOI 10.1002/0470018860.S00254
   Seyfarth S, 2014, COGNITION, V133, P140, DOI 10.1016/j.cognition.2014.06.013
   Shaw JA, 2019, LANG SPEECH, V62, P80, DOI 10.1177/0023830917737331
   Strauss TJ, 2007, BEHAV RES METHODS, V39, P19, DOI 10.3758/BF03192840
   Tanaka Yu., 2015, P N E LINGUISTIC SOC, V45, P131
   Tomasello M, 2004, J CHILD LANG, V31, P101, DOI 10.1017/S0305000903005944
   Vajrabhaya Prakiwan, 1 TIMES CHARM 1 MENT
   Van Son Rob J. J. H, 2003, P 25 I PHON SCI, V25, P171, DOI DOI 10.1177/1745691612459060
   Zipf G. K., 1935, PSYCHOBIOLOGY LANGUA
NR 52
TC 7
Z9 7
U1 1
U2 2
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2199-174X
J9 LINGUIST VANGUARD
JI Linguist. Vanguard
PD SEP
PY 2018
VL 4
SU 2
AR 20170045
DI 10.1515/lingvan-2017-0045
PG 10
WC Linguistics; Language & Linguistics
SC Linguistics
GA HB5JG
UT WOS:000451095900012
DA 2021-02-24
ER

PT J
AU Foulkes, P
   Docherty, G
   Hufnagel, SS
   Hughes, V
AF Foulkes, Paul
   Docherty, Gerry
   Hufnagel, Stefanie Shattuck
   Hughes, Vincent
TI Three steps forward for predictability. Consideration of methodological
   robustness, indexical and prosodic factors, and replication in the
   laboratory
SO LINGUISTICS VANGUARD
LA English
DT Article
DE predictability; informativity; indexical factors; prosodic factors;
   corpus linguistics
ID SPEECH-PERCEPTION; FORMANT; INFORMATIVITY; REALIZATION; MODEL
AB There is now abundant evidence that phonetic forms are shaped by probabilistic effects reflecting predictability or informativity. We outline a number of challenges for such work, where theoretical claims are often based on small differences in acoustic measurements, or interpretations of small statistical effect sizes. We outline caveats about the methods and assumptions encountered in many studies of predictability effects, particularly regarding corpus-based approaches. We consider the wide range of factors that influence patterns of variability in phonetic forms, taking a broad perspective on what is meant by "the message" in order to show that predictability effects need to be considered alongsidemany others, including indexical and prosodic factors. We suggest a number of ways forward to extend our understanding of the form-predictability relationship.
C1 [Foulkes, Paul; Hughes, Vincent] Univ York, Language & Linguist Sci, York, N Yorkshire, England.
   [Docherty, Gerry] Griflth Univ, Brisbane, Qld, Australia.
   [Hufnagel, Stefanie Shattuck] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Foulkes, P (corresponding author), Univ York, Language & Linguist Sci, York, N Yorkshire, England.
EM paul.foulkes@york.ac.uk
OI Docherty, Gerard/0000-0003-3908-9834
CR Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babinski S, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0024
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   BERKOVITS R, 1993, LANG SPEECH, V36, P89, DOI 10.1177/002383099303600105
   Brognaux Sandrine, 2012, Advances in Natural Language Processing. Proceedings 8th International Conference on NLP, JapTAL 2012, P300, DOI 10.1007/978-3-642-33983-7_30
   Buz E, 2016, J MEM LANG, V89, P68, DOI 10.1016/j.jml.2015.12.009
   Byrne C, 2004, INT J SPEECH LANG LA, V11, P83, DOI 10.1558/sll.2004.11.1.83
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Clopper CG, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0044
   Daland R, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0045
   Das R, 2010, FORCED ALIGNMENT ADV
   De Decker P, 2016, LINGUIST VANGUARD, V2, DOI 10.1515/lingvan-2015-0010
   Deng L, 2006, INT CONF ACOUST SPEE, P369
   Duckworth M, 2011, INT J SPEECH LANG LA, V18, P35, DOI 10.1558/ijsll.v18i1.35
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Franco-Pedroso J, 2016, SPEECH COMMUN, V76, P61, DOI 10.1016/j.specom.2015.11.002
   Fromont R, 2016, CORPORA, V11, P401, DOI 10.3366/cor.2016.0101
   Gordon E, 2007, CREATING AND DIGITIZING LANGUAGE CORPORA VOLUME 2: DIACHRONIC DATABASES, P82
   Harrington J., 2010, PHONETIC ANAL SPEECH
   Harrison P., 2013, THESIS
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Hay J. B, 2016, EVOLUTION MEDIAL T R
   Hay JB, 2015, COGNITION, V139, P83, DOI 10.1016/j.cognition.2015.02.012
   Hughes V., 2014, THESIS
   Hughes V, 2015, SPEECH COMMUN, V66, P218, DOI 10.1016/j.specom.2014.10.006
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kunzel HJ, 2002, FORENSIC LINGUIST, V9, P83
   Ladefoged P., 2003, PHONETIC DATA ANAL I
   Lam TQ, 2014, J EXP PSYCHOL LEARN, V40, P829, DOI 10.1037/a0035780
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   Local J, 2012, J INT PHON ASSOC, V42, P255, DOI 10.1017/S0025100312000187
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Olejarczuk P, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0020
   Pardo JS, 2017, ATTEN PERCEPT PSYCHO, V79, P637, DOI 10.3758/s13414-016-1226-0
   Priva UC, 2017, LANGUAGE, V93, P569, DOI 10.1353/lan.2017.0037
   Priva UC, 2015, LAB PHONOL, V6, P243, DOI 10.1515/lp-2015-0008
   Rathcke T, 2017, SPEECH COMMUN, V86, P24, DOI 10.1016/j.specom.2016.11.001
   Schleef E., 2016, ENGL LANG LINGUIST, V22, P35
   Schuppler B, 2012, J PHONETICS, V40, P595, DOI 10.1016/j.wocn.2012.05.004
   Shaw J, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2018-0042
   Sonderegger M, 2012, J ACOUST SOC AM, V132, P3965, DOI 10.1121/1.4763995
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   Stuart-Smith J, 2015, LAB PHONOL, V6, P505, DOI 10.1515/lp-2015-0015
   Tabachnick B., 1996, USING MULTIVARIATE S, V3rd ed
   Tomaschek F, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0018
   Turk AE, 1999, J PHONETICS, V27, P171, DOI 10.1006/jpho.1999.0093
   Turk AE, 2007, J PHONETICS, V35, P445, DOI 10.1016/j.wocn.2006.12.001
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   Wedel A, 2013, LANG SPEECH, V56, P395, DOI 10.1177/0023830913489096
   West P, 1999, J PHONETICS, V27, P405, DOI 10.1006/jpho.1999.0102
   Zhang CL, 2013, SPEECH COMMUN, V55, P796, DOI 10.1016/j.specom.2013.01.011
NR 53
TC 11
Z9 11
U1 1
U2 1
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2199-174X
J9 LINGUIST VANGUARD
JI Linguist. Vanguard
PD SEP
PY 2018
VL 4
SU 2
AR 20170032
DI 10.1515/lingvan-2017-0032
PG 11
WC Linguistics; Language & Linguistics
SC Linguistics
GA HB5JG
UT WOS:000451095900009
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Zheng, AN
   Hirata, Y
   Kelly, SD
AF Zheng, Annie
   Hirata, Yukari
   Kelly, Spencer D.
TI Exploring the Effects of Imitating Hand Gestures and Head Nods on L1 and
   L2 Mandarin Tone Production
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; LINGUISTIC EXPERIENCE; LANGUAGE-DEVELOPMENT; PITCH;
   INTONATION; LISTENERS; LENGTH; LIPS
AB Purpose: This study investigated the impact of metaphoric actions-head nods and hand gestures-in producing Mandarin tones for first language (L1) and second language (L2) speakers.
   Method: In 2 experiments, participants imitated videos of Mandarin tones produced under 3 conditions: (a) speech alone, (b) speech + head nods, and (c) speech + hand gestures. Fundamental frequency was recorded for both L1 (Experiment 1) and L2 (Experiment 2a) speakers, and the output of the L2 speakers was rated for tonal accuracy by 7 native Mandarin judges (Experiment 2b).
   Results: Experiment 1 showed that 12 L1 speakers' fundamental frequency spectral data did not differ among the 3 conditions. In Experiment 2a, the conditions did not affect the production of 24 English speakers for the most part, but there was some evidence that hand gestures helped Tone 4. In Experiment 2b, native Mandarin judges found limited conditional differences in L2 productions, with Tone 3 showing a slight head nods benefit in a subset of "correct" L2 tokens.
   Conclusion: Results suggest that metaphoric bodily actions do not influence the lowest levels of L1 speech production in a tonal language and may play a very modest role during preliminary L2 learning.
C1 [Zheng, Annie] Washington Univ, Dept Neurosci, St Louis, MO USA.
   [Hirata, Yukari] Colgate Univ, Dept East Asian Languages & Literatures, Hamilton, NY 13346 USA.
   [Kelly, Spencer D.] Colgate Univ, Neurosci Program, Dept Psychol & Brain Sci, Hamilton, NY 13346 USA.
   [Zheng, Annie; Hirata, Yukari; Kelly, Spencer D.] Colgate Univ, Ctr Language & Brain, Hamilton, NY 13346 USA.
RP Kelly, SD (corresponding author), Colgate Univ, Neurosci Program, Dept Psychol & Brain Sci, Hamilton, NY 13346 USA.; Kelly, SD (corresponding author), Colgate Univ, Ctr Language & Brain, Hamilton, NY 13346 USA.
EM skelly@colgate.edu
FU Colgate's Center for Language and Brain
FX The authors thank Colgate's Center for Language and Brain for providing
   funding for participants. The authors would like to thank Youngsun Cho,
   Eve Yi, Jack Polikoff, Solhee Bae, Yuan Lou, and Ryan Hildebrandt for
   their efforts in preparing stimuli, running participants and collecting
   data, and for all their intelligent contributions to and support for the
   project.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P, 2015, PRAAT DOING PHONETIC
   BOLINGER D, 1983, AM SPEECH, V58, P156, DOI 10.2307/455326
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Burnham D., 2006, P 7 INT SEM SPEECH P, P1
   Burnham D., 2001, P INT C AUD VIS SPEE, P155
   Carpenter SK, 2012, J EXP PSYCHOL LEARN, V38, P92, DOI 10.1037/a0024828
   Casasanto D, 2003, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, PTS 1 AND 2, P1323
   Chang Y. S, 2011, P 23 N AM C CHIN LIN, V1, P84
   Chen C.-M., 2013, TRENDS APPL LINGUIST, V9, P143
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   Connell L, 2013, BRAIN COGNITION, V81, P124, DOI 10.1016/j.bandc.2012.09.005
   Eng K., 2013, P M AC, V19, DOI 10.1121/1.4799746
   Fox J., 2011, R COMPANION APPL REG
   Gentilucci M, 2003, EUR J NEUROSCI, V17, P179, DOI 10.1046/j.1460-9568.2003.02438.x
   Gentilucci M, 2009, NEUROPSYCHOLOGIA, V47, P3190, DOI 10.1016/j.neuropsychologia.2009.07.020
   Gluhareva D, 2017, LANG TEACH RES, V21, P609, DOI 10.1177/1362168816651463
   Hannah B, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02051
   Hirata Y, 2014, J SPEECH LANG HEAR R, V57, P2090, DOI 10.1044/2014_JSLHR-S-14-0049
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   IVERSON JANA M, 1999, J CONSCIOUSNESS STUD, V6, P19
   Jongman A, 2006, HANDBOOK OF EAST ASIAN PSYCHOLINGUISTICS, VOL 1: CHINESE, P209
   Karmiloff-Smith A., 1995, MODULARITY DEV PERSP
   Kelly S. D., 2004, GESTURE, V4, P25, DOI DOI 10.1075/GEST.4.1.03KEL
   Kelly S. D., 2017, WHY GESTURE HANDS FU, P243, DOI DOI 10.1075/GS.7
   Kelly SD, 2017, WHY GESTURE HANDS FU, P3
   Kelly S, 2017, COLLABRA-PSYCHOL, V3, DOI 10.1525/collabra.76
   Kelly SD, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00673
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Kuang JJ, 2017, J ACOUST SOC AM, V142, P1693, DOI 10.1121/1.5003649
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Lakoff G, 1980, METAPHORS WE LIVE
   Lemaitre G, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181786
   Lenneberg E., 1967, BIOL FDN LANGUAGE, P125
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Lieberman P., 1988, SPEECH PHYSL SPEECH
   Liu Y, 2011, LANG LEARN, V61, P1119, DOI 10.1111/j.1467-9922.2011.00673.x
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Loehr D., 2007, GESTURE, V7, P179, DOI [10.1075/gest.7.2.04loe, DOI 10.1075/GEST.7.2.04LOE]
   McClave E, 1998, J PSYCHOLINGUIST RES, V27, P69, DOI 10.1023/A:1023274823974
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McNeill D., 2005, GESTURE THOUGHT
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Morett LM, 2015, LANG COGN NEUROSCI, V30, P347, DOI 10.1080/23273798.2014.923105
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   OYAMA S, 1976, J PSYCHOLINGUIST RES, V5, P261, DOI 10.1007/BF01067377
   Paivio A., 1986, MENTAL REPRESENTATIO
   PISONI DB, 1982, J EXP PSYCHOL HUMAN, V8, P297, DOI 10.1037/0096-1523.8.2.297
   R Core Team, 2016, R LANG ENV STAT COMP
   Roberge C., 1996, PRONUNCIATION TRAINI, P1
   Semin GR, 2008, EMBODIED GROUNDING: SOCIAL, COGNITIVE, AFFECTIVE, AND NEUROSCIENTIFIC APPROACHES, P1
   Tao L., 2008, J CHINESE LANGUAGE T, V43, P17
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Wang Y, 2003, J COGNITIVE NEUROSCI, V15, P1019, DOI 10.1162/089892903770007407
   Wang Y, 2004, APPL PSYCHOLINGUIST, V25, P449, DOI 10.1017/S0142716404001213
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wang Y, 2006, HANDBOOK OF EAST ASIAN PSYCHOLINGUISTICS, VOL 1: CHINESE, P250
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
NR 62
TC 3
Z9 3
U1 3
U2 9
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD SEP
PY 2018
VL 61
IS 9
BP 2179
EP 2195
DI 10.1044/2018_JSLHR-S-17-0481
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GU0ZM
UT WOS:000444983700003
PM 30193334
DA 2021-02-24
ER

PT J
AU Lund, E
AF Lund, Emily
TI Pairing New Words With Unfamiliar Objects: Comparing Children With and
   Without Cochlear Implants
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID EARLY AUDITORY EXPERIENCE; LANGUAGE-DEVELOPMENT; SPEECH-PERCEPTION;
   DIRECTED SPEECH; DEAF-CHILDREN; HEARING-LOSS; ACQUISITION; VOCABULARY;
   SKILLS; CONSTRAINTS
AB Purpose: This study investigates differences between preschool children with cochlear implants and age-matched children with normal hearing during an initial stage in word learning to evaluate whether they (a) match novel words to unfamiliar objects and (b) solicit information about unfamiliar objects during play.
   Method: Twelve preschool children with cochlear implants and 12 children with normal hearing matched for age completed 2 experimental tasks. In the 1st task, children were asked to point to a picture that matched either a known word or a novel word. In the 2nd task, children were presented with unfamiliar objects during play and were given the opportunity to ask questions about those objects.
   Results: In Task 1, children with cochlear implants paired novel words with unfamiliar pictures in fewer trials than children with normal hearing. In Task 2, children with cochlear implants were less likely to solicit information about new objects than children with normal hearing. Performance on the 1st task, but not the 2nd, significantly correlated with expressive vocabulary standard scores of children with cochlear implants.
   Conclusion: This study provides preliminary evidence that children with cochlear implants approach mapping novel words to and soliciting information about unfamiliar objects differently than children with normal hearing.
C1 [Lund, Emily] Texas Christian Univ, Davies Sch Commun Sci & Disorders, Ft Worth, TX 76129 USA.
RP Lund, E (corresponding author), Texas Christian Univ, Davies Sch Commun Sci & Disorders, Ft Worth, TX 76129 USA.
EM e.lund@tcu.edu
FU Texas Christian University Research and Creative Activities Fund
FX The author gratefully acknowledges the support from the Texas Christian
   University Research and Creative Activities Fund.
CR Akhtar N, 2001, CHILD DEV, V72, P416, DOI 10.1111/1467-8624.00287
   Bloom P., 2000, CHILDREN LEARN MEANI
   Brownell R., 2000, EXPRESSIVE ONE WORD
   Carlson ML, 2018, OTOL NEUROTOL, V39, pE12, DOI 10.1097/MAO.0000000000001632
   Caza GA, 2012, LANG LEARN DEV, V8, P113, DOI 10.1080/15475441.2011.581144
   Cole E. B., 2016, CHILDREN HEARING LOS
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407
   Convertino C, 2014, J DEAF STUD DEAF EDU, V19, P471, DOI 10.1093/deafed/enu024
   Davidson Lisa S, 2014, Cochlear Implants Int, V15, P211, DOI 10.1179/1754762813Y.0000000051
   Diesendruck G, 2001, DEV PSYCHOL, V37, P630, DOI 10.1037//0012-1649.37.5.630
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Ehrler D. J., 2008, PRIMARY TEST NONVERB
   Fagan MK, 2014, INFANT BEHAV DEV, V37, P249, DOI 10.1016/j.infbeh.2014.04.001
   Fenson L, 2006, MACARTHUR BATES COMM
   Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P2, DOI 10.1037/a0024338
   Fudala J. B., 2000, ARIZONA ARTICULATION
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   Geers AE, 2016, J SPEECH LANG HEAR R, V59, P155, DOI 10.1044/2015_JSLHR-H-14-0173
   Golinkoff R. M., 2000, BECOMING WORD LEARNE
   Gopnik A., 1997, WORDS THOUGHTS THEOR, V1
   Grassmann S, 2009, COGNITION, V112, P488, DOI 10.1016/j.cognition.2009.06.010
   HEIBECK TH, 1987, CHILD DEV, V58, P1021, DOI 10.1111/j.1467-8624.1987.tb01438.x
   Hollich G., 2000, MONOGR SOC RES CHILD, V65, P3, DOI [10.1111/1540-5834.00090., DOI 10.1111/1540-5834.00090]
   Horst JS, 2008, INFANCY, V13, P128, DOI 10.1080/15250000701795598
   Houston DM, 2012, DEVELOPMENTAL SCI, V15, P448, DOI 10.1111/j.1467-7687.2012.01140.x
   Houston DM, 2010, OTOL NEUROTOL, V31, P1248, DOI 10.1097/MAO.0b013e3181f1cc6a
   Houston Derek M, 2005, Volta Rev, V105, P41
   Houston-Price C, 2005, J CHILD LANG, V32, P175, DOI 10.1017/S0305000904006610
   Hresko W. P., 1999, TEST EARLY LANGUAGE
   Laible D, 2004, DEV PSYCHOL, V40, P979, DOI 10.1037/0012-1649.40.6.979
   Lederberg AR, 2000, CHILD DEV, V71, P1571, DOI 10.1111/1467-8624.00249
   Levine D, 2016, OTOL NEUROTOL, V37, pE56, DOI 10.1097/MAO.0000000000000908
   Lund E, 2018, AM J SPEECH-LANG PAT, V27, P765, DOI 10.1044/2018_AJSLP-16-0239
   Lund E, 2017, CLIN LINGUIST PHONET, V31, P777, DOI 10.1080/02699206.2017.1320587
   Lund E, 2016, EXCEPT CHILDREN, V83, P26, DOI 10.1177/0014402916651848
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   Lund E, 2015, EAR HEARING, V36, P229, DOI 10.1097/AUD.0000000000000104
   Lund E, 2014, J DEAF STUD DEAF EDU, V19, P68, DOI 10.1093/deafed/ent036
   MARKMAN EM, 1988, COGNITIVE PSYCHOL, V20, P121, DOI 10.1016/0010-0285(88)90017-5
   MARKMAN EM, 1994, LINGUA, V92, P199, DOI 10.1016/0024-3841(94)90342-5
   Meinzen-Derr J, 2007, ANN OTO RHINOL LARYN, V116, P812, DOI 10.1177/000348940711601104
   Mellon N. K., 2016, PEDIAT COCHLEAR IMPL, P341
   MERVIS CB, 1994, CHILD DEV, V65, P1646, DOI 10.2307/1131285
   Nation K, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0387
   Nelson DGK, 2004, PSYCHOL SCI, V15, P384
   Newman RS, 2016, J CHILD LANG, V43, P1158, DOI 10.1017/S0305000915000446
   Phillips A. L., 1977, BASIC VOCABULARY LAN
   Quine W.V., 1960, WORD OBJECT
   Quittner AL, 2013, J PEDIATR-US, V162, P343, DOI 10.1016/j.jpeds.2012.08.003
   Robertson VS, 2017, EAR HEARING, V38, P701, DOI 10.1097/AUD.0000000000000455
   Roland JT, 2015, OTOLARYNG HEAD NECK, V152, P592, DOI 10.1177/0194599815575276
   SAMEROFF A, 1975, HUM DEV, V18, P65, DOI 10.1159/000271476
   SHRIBERG LD, 1993, J SPEECH HEAR RES, V36, P105, DOI 10.1044/jshr.3601.105
   Storkel HL, 2013, BEHAV RES METHODS, V45, P1159, DOI 10.3758/s13428-012-0309-7
   Tamis-LeMonda CS, 2001, CHILD DEV, V72, P748, DOI 10.1111/1467-8624.00313
   Tomblin JB, 2007, INT J AUDIOL, V46, P512, DOI 10.1080/14992020701383043
   Walker EA, 2013, J SPEECH LANG HEAR R, V56, P375, DOI 10.1044/1092-4388(2012/11-0343)
   Wechsler-Kashi D, 2014, J SPEECH LANG HEAR R, V57, P1870, DOI 10.1044/2014_JSLHR-L-13-0321
NR 58
TC 0
Z9 0
U1 0
U2 8
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD SEP
PY 2018
VL 61
IS 9
BP 2325
EP 2336
DI 10.1044/2018_JSLHR-L-17-0467
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GU0ZM
UT WOS:000444983700015
PM 30178030
DA 2021-02-24
ER

PT J
AU Garcia, PB
   Leibold, L
   Buss, E
   Calandruccio, L
   Rodriguez, B
AF Garcia, Paula B.
   Leibold, Lori
   Buss, Emily
   Calandruccio, Lauren
   Rodriguez, Barbara
TI Code-Switching in Highly Proficient Spanish/English Bilingual Adults:
   Impact on Masked Word Recognition
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID NONNATIVE LISTENERS; SPEECH-PERCEPTION; NORMAL-HEARING; NOISE-LEVELS;
   LANGUAGES; INTELLIGIBILITY; ENGLISH; REVERBERATION; SELECTION; COSTS
AB Purpose: The purpose of this study was to evaluate the impact of code-switching on Spanish/English bilingual listeners' speech recognition of English and Spanish words in the presence of competing speech-shaped noise.
   Method: Participants were Spanish/English bilingual adults (N = 27) who were highly proficient in both languages. Target stimuli were English and Spanish words presented in speech-shaped noise at a -14-dB signal-to-noise ratio. There were 4 target conditions: (a) English only, (b) Spanish only, (c) mixed English, and (d) mixed Spanish. In the mixed-English condition, 75% of the words were in English, whereas 25% of the words were in Spanish. The percentages were reversed in the mixed-Spanish condition.
   Results: Accuracy was poorer for the majority (75%) and minority (25%) languages in both mixed-language conditions compared with the corresponding single-language conditions. Results of a follow-up experiment suggest that this finding cannot be explained in terms of an increase in the number of possible response alternatives for each picture in the mixed-language condition relative to the single-language condition.
   Conclusions: Results suggest a cost of language mixing on speech perception when bilingual listeners alternate between languages in noisy environments. In addition, the cost of code-switching on speech recognition in noise was similar for both languages in this group of highly proficient Spanish/English bilingual speakers. Differences in response-set size could not account for the poorer results in the mixed-language conditions.
C1 [Garcia, Paula B.] Univ Andes, Bogota, Colombia.
   [Garcia, Paula B.; Leibold, Lori] Boys Town Natl Res Hosp, Omaha, NE 68131 USA.
   [Buss, Emily] Univ N Carolina, Chapel Hill, NC 27515 USA.
   [Calandruccio, Lauren] Case Western Reserve Univ, Cleveland, OH 44106 USA.
   [Rodriguez, Barbara] Univ New Mexico, Albuquerque, NM 87131 USA.
RP Garcia, PB (corresponding author), Univ Andes, Bogota, Colombia.; Garcia, PB (corresponding author), Boys Town Natl Res Hosp, Omaha, NE 68131 USA.
EM pb.garcia@uniandes.edu.co
OI Buss, Emily/0000-0001-8244-3013
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC015056]; National Institute of
   General Medical Sciences of the National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of General Medical Sciences
   (NIGMS) [P20GM109023]; NATIONAL INSTITUTE OF GENERAL MEDICAL
   SCIENCESUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of General
   Medical Sciences (NIGMS) [P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC015056, R01DC015056, R01DC015056, R01DC015056] Funding
   Source: NIH RePORTER
FX This research was funded by the National Institute on Deafness and Other
   Communication Disorders Grant R01 DC015056. Participant recruitment was
   facilitated by the Clinical Measurement Core of Boys Town National
   Research Hospital, which is supported by the National Institute of
   General Medical Sciences of the National Institutes of Health under
   Award P20GM109023. The content is solely the responsibility of the
   authors and does not necessarily represent the official views of the
   National Institutes of Health.
CR Abutalebi J, 2007, J NEUROSCI, V27, P13762, DOI 10.1523/JNEUROSCI.3294-07.2007
   Alvarez RP, 2003, BRAIN LANG, V87, P290, DOI 10.1016/S0093-934X(03)00108-1
   Barker G. C., 1947, ACTA AM, V5, P185
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Calandruccio L, 2014, AM J AUDIOL, V23, P158, DOI 10.1044/2014_AJA-13-0055
   Chauncey K, 2008, BRAIN LANG, V105, P161, DOI 10.1016/j.bandl.2007.11.006
   Cooper G., 2013, J NW ANTHR, V47, P215
   Costa A, 2004, J MEM LANG, V50, P491, DOI 10.1016/j.jml.2004.02.002
   Costa A, 2006, J EXP PSYCHOL LEARN, V32, P1057, DOI 10.1037/0278-7393.32.5.1057
   Dijkstra Ton, 2005, HDB BILINGUALISM PSY, P179
   Filippi R, 2014, BILING-LANG COGN, V17, P294, DOI 10.1017/S1366728913000485
   Flamme GA, 2012, INT J AUDIOL, V51, pS3, DOI 10.3109/14992027.2011.635316
   Florentine M, 1984, J ACOUST SOC AM, V75, pS84, DOI [10.1121/ 1.2021645, DOI 10.1121/1.2021645]
   Gertken Libby, 2012, BILINGUAL LANGUAGE P
   Green D. W., 1998, BILING-LANG COGN, V1, P67, DOI [10.1017/S1366728998000133, DOI 10.1017/S1366728998000133]
   Hazan V, 2000, LANG SPEECH, V43, P273, DOI 10.1177/00238309000430030301
   Hochmuth S, 2015, INT J AUDIOL, V54, P62, DOI 10.3109/14992027.2015.1046502
   Hodgson M, 2007, J ACOUST SOC AM, V121, P2023, DOI 10.1121/1.2535571
   Lecumberri MLG, 2006, J ACOUST SOC AM, V119, P2445, DOI 10.1121/1.2180210
   Macizo P, 2012, SECOND LANG RES, V28, P131, DOI 10.1177/0267658311434893
   Marian V., 2007, LANGUAGE EXPERIENCE, P940, DOI [10.1044/1092-4388(2007/067), DOI 10.1044/1092-4388(2007/067)]
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   Mendel LL, 2016, INT J AUDIOL, V55, P126, DOI 10.3109/14992027.2015.1061710
   Meuter RFI, 1999, J MEM LANG, V40, P25, DOI 10.1006/jmla.1998.2602
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Moreno EM, 2002, BRAIN LANG, V80, P188, DOI 10.1006/brln.2001.2588
   Myers-Scotton C, 2006, BILING-LANG COGN, V9, P203, DOI 10.1017/S1366728906002549
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   Olson DJ, 2017, LANG COGN NEUROSCI, V32, P494, DOI 10.1080/23273798.2016.1250927
   Pearson, 2011, VERS ENGL TEST DESCR
   PICCINI PE, 2014, SOCIAL LINGUISTIC SP, P885
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Rusnock CF, 2012, J OCCUP ENVIRON HYG, V9, pD108, DOI 10.1080/15459624.2012.683716
   Shi LF, 2015, AM J AUDIOL, V24, P53, DOI 10.1044/2014_AJA-14-0041
   Spivey MJ, 1999, PSYCHOL SCI, V10, P281, DOI 10.1111/1467-9280.00151
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   van Wijngaarden SJ, 2004, J ACOUST SOC AM, V115, P1281, DOI 10.1121/1.1647145
   VanHell J. G., 2009, MULTIDISCIPLINARY AP, P53, DOI 10.1075/sibi1.41.06hel
   Weiss D, 2008, J AM ACAD AUDIOL, V19, P5, DOI 10.3766/jaaa.19.1.2
NR 41
TC 10
Z9 10
U1 1
U2 11
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD SEP
PY 2018
VL 61
IS 9
BP 2353
EP 2363
DI 10.1044/2018_JSLHR-H-17-0399
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GU0ZM
UT WOS:000444983700018
PM 30076419
OA Green Published
DA 2021-02-24
ER

PT J
AU Fisher, LM
   Martinez, AS
   Richmond, FJ
   Krieger, MD
   Wilkinson, EP
   Eisenberg, LS
AF Fisher, Laurel M.
   Martinez, Amy S.
   Richmond, Frances J.
   Krieger, Mark D.
   Wilkinson, Eric P.
   Eisenberg, Laurie S.
TI Assessing the Benefit-Risk Profile for Pediatric Implantable Auditory
   Prostheses
SO THERAPEUTIC INNOVATION & REGULATORY SCIENCE
LA English
DT Article
DE auditory brainstem implant; cochlear implant; cochleovestibular
   abnormality; pediatric; deaf
ID BRAIN-STEM IMPLANT; SENSORINEURAL HEARING-LOSS; COCHLEAR NERVE
   DEFICIENCY; INNER-EAR MALFORMATIONS; SPOKEN LANGUAGE-DEVELOPMENT;
   SPEECH-PERCEPTION; NEUROFIBROMATOSIS TYPE-2; BEHAVIORAL OUTCOMES;
   DECISION-MAKING; YOUNG-CHILDREN
AB Background/Aims: Children with congenital cochleovestibular abnormalities associated with profound hearing loss have few treatment options if cochlear implantation does not yield benefit. An alternative is the auditory brainstem implant (ABI). Regulatory authority device approvals currently include a structured benefit-risk assessment. Such an assessment, for regulatory purposes or to guide clinical decision making, has not been published, to our knowledge, for the ABI and may lead to the design of a research program that incorporates regulatory authority, family, and professional input. Methods: Much structured benefit-risk research has been conducted in the context of drug trials; here we apply this approach to device studies. A qualitative framework organized benefit (speech recognition, parent self-report measures) and risk (surgery- and device-related) information to guide the selection of candidates thought to have potential benefit from ABI. Results: Children with cochleovestibular anatomical abnormalities are challenging for appropriate assessment of candidacy for a cochlear implant or an ABI. While the research is still preliminary, children with an ABI appear to slowly obtain benefit over time. A team of professionals, including audiological, occupational, and educational therapy, affords maximum opportunity for benefit. Conclusions: Pediatric patients who have abnormal anatomy and are candidates for an implantable auditory prosthetic require an individualized, multisystems review. The qualitative benefit-risk assessment used here to characterize the condition, the medical need, potential benefits, risks, and risk management strategies has revealed the complex factors involved. After implantation, continued team support for the family during extensive postimplant therapy is needed to develop maximum auditory skill benefit.
C1 [Fisher, Laurel M.; Martinez, Amy S.; Eisenberg, Laurie S.] Univ Southern Calif, Tina & Rick Caruso Dept Otolaryngol Head & Neck S, Keck Sch Med, 1540 Alcazar St,Suite 204, Los Angeles, CA 90033 USA.
   [Richmond, Frances J.] Univ Southern Calif, Keck Sch Med, Sch Pharm, Dept Regulatory Sci, Los Angeles, CA USA.
   [Krieger, Mark D.] Univ Southern Calif, Keck Sch Med, Neurosurg, Los Angeles, CA USA.
   [Wilkinson, Eric P.] Huntington Med Res Inst, Pasadena, CA USA.
RP Fisher, LM (corresponding author), Univ Southern Calif, Tina & Rick Caruso Dept Otolaryngol Head & Neck S, Keck Sch Med, 1540 Alcazar St,Suite 204, Los Angeles, CA 90033 USA.
EM Laurel.fisher@med.usc.edu
FU NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [U01DC013031, U01DC013031, U01DC013031,
   U01DC013031, U01DC013031, U01DC013031] Funding Source: NIH RePORTER;
   NIDCD NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [U01 DC013031] Funding Source:
   Medline
CR Adunka OF, 2012, OTOL NEUROTOL, V33, P1489, DOI 10.1097/MAO.0b013e31826a50a0
   Agapova M, 2014, ACAD RADIOL, V21, P1138, DOI 10.1016/j.acra.2014.05.006
   ASLIN RN, 1988, ANNU REV PSYCHOL, V39, P435, DOI 10.1146/annurev.psych.39.1.435
   Backeljauw B, 2015, PEDIATRICS, V136, pE1, DOI 10.1542/peds.2014-3526
   Benz HL, 2017, EXP NEUROL, V287, P486, DOI 10.1016/j.expneurol.2016.07.017
   Bille J, 2015, EUR ARCH OTO-RHINO-L, V272, P583, DOI 10.1007/s00405-014-2883-z
   Birman CS, 2016, OTOL NEUROTOL, V37, P438, DOI 10.1097/MAO.0000000000000997
   Birman CS, 2012, OTOL NEUROTOL, V33, P1347, DOI 10.1097/MAO.0b013e31826939cc
   Bradley Jane, 2008, Cochlear Implants Int, V9, P34, DOI 10.1179/cim.2008.9.1.34
   Buchman CA, 2004, LARYNGOSCOPE, V114, P309, DOI 10.1097/00005537-200402000-00025
   Buchman CA, 2011, LARYNGOSCOPE, V121, P1979, DOI 10.1002/lary.22032
   Carney A, 1996, AMPLIFICATION CHILDR
   Coelho DH, 2012, OTOLARYNG CLIN N AM, V45, P91, DOI 10.1016/j.otc.2011.08.019
   Colletti L, 2008, LARYNGOSCOPE, V118, P1443, DOI 10.1097/MLG.0b013e318173a011
   Colletti L, 2007, ACTA OTO-LARYNGOL, V127, P943, DOI 10.1080/00016480601110253
   Colletti V, 2005, LARYNGOSCOPE, V115, P1974, DOI 10.1097/01.mlg.0000178327.42926.ec
   Colletti V, 2010, OTOL NEUROTOL, V31, P558, DOI 10.1097/MAO.0b013e3181db7055
   Colopy MW, 2015, THER INNOV REGUL SCI, V49, P425, DOI 10.1177/2168479014565469
   Coplan PM, 2011, CLIN PHARMACOL THER, V89, P312, DOI 10.1038/clpt.2010.291
   Cote M, 2007, LARYNGOSCOPE, V117, P1225, DOI 10.1097/MLG.0b013e31805c9a06
   Courchesne E, 2000, RADIOLOGY, V216, P672, DOI 10.1148/radiology.216.3.r00au37672
   DesJardin JL, 2007, EAR HEARING, V28, P456, DOI 10.1097/AUD.0b013e31806dc1ab
   Eisenberg L S, 1987, J Rehabil Res Dev, V24, P9, DOI 10.1682/JRRD.1987.07.0009
   Eisenberg LS, 2008, OTOL NEUROTOL, V29, P251, DOI 10.1097/mao.0b013e31815a352d
   Eisenberg LS, 2006, AUDIOL NEURO-OTOL, V11, P259, DOI 10.1159/000093302
   Eisenberg LS, 2012, J AM ACAD AUDIOL, V23, P412, DOI 10.3766/jaaa.23.6.4
   Eisenman DJ, 2001, OTOL NEUROTOL, V22, P834, DOI 10.1097/00129492-200111000-00020
   Erber N. P., 1982, AUDITORY TRAINING
   Faria AV, 2010, NEUROIMAGE, V52, P415, DOI 10.1016/j.neuroimage.2010.04.238
   FDA, 2015, RAR DIS COMM ISS DRU
   FDA, 2016, FACT CONS MAK BEN RI
   Fischhoff B, 2012, DRUG SAFETY, V35, P983, DOI 10.2165/11636170-000000000-00000
   Fisher LM, 2016, CLIN MANAGEMENT CHIL, P821
   Flick RP, 2011, PEDIATRICS, V128, pE1053, DOI 10.1542/peds.2011-0351
   Frey P, 2012, BENEFIT RISK CONSIDE
   Frohne C, 2000, J LARYNGOL OTOL, V114, P11
   Glastonbury CM, 2002, AM J NEURORADIOL, V23, P635
   Gordon KA, 2011, BRAIN TOPOGR, V24, P204, DOI 10.1007/s10548-011-0181-2
   HOUSE WF, 1981, ACTA OTO-LARYNGOL, V91, P457, DOI 10.3109/00016488109138528
   Huang BY, 2012, AM J NEURORADIOL, V33, P211, DOI 10.3174/ajnr.A2498
   Irony T, 2016, STAT BIOPHARM RES, V8, P230, DOI 10.1080/19466315.2015.1135820
   JACKLER RK, 1987, LARYNGOSCOPE, V97, P2
   Jeong SW, 2015, AUDIOL NEURO-OTOL, V20, P90, DOI 10.1159/000365584
   Jeong SW, 2012, ACTA OTO-LARYNGOL, V132, P910, DOI 10.3109/00016489.2012.675627
   Johnson K., 2009, CLIN MANAGEMENT CHIL
   Johnson KC, 2017, COMPREHENSIVE HDB PE, P915
   Kim LS, 2006, ANN OTO RHINOL LARYN, V115, P205, DOI 10.1177/000348940611500309
   Koch DB, 2007, EAR HEARING, V28, p38S, DOI 10.1097/AUD.0b013e31803150de
   Kontorinis G, 2013, OTOL NEUROTOL, V34, P1253, DOI 10.1097/MAO.0b013e318291c48f
   Kral A, 2010, NEW ENGL J MED, V363, P1438, DOI 10.1056/NEJMra0911225
   Kutz JW, 2011, OTOL NEUROTOL, V32, P956, DOI 10.1097/MAO.0b013e31821f473b
   Lassig AAD, 2005, OTOL NEUROTOL, V26, P624, DOI 10.1097/01.mao.0000178123.35988.96
   Li YJ, 2015, EUR ARCH OTO-RHINO-L, V272, P1587, DOI 10.1007/s00405-014-2951-4
   Marlowe AL, 2010, OTOL NEUROTOL, V31, P74, DOI 10.1097/MAO.0b013e3181c29fad
   Matthies C, 2014, J NEUROSURG, V120, P546, DOI 10.3171/2013.9.JNS12686
   Meinzen-Derr J, 2007, ANN OTO RHINOL LARYN, V116, P812, DOI 10.1177/000348940711601104
   Merkus P, 2013, AURIS NASUS LARYNX, V40, P113, DOI 10.1016/j.anl.2012.10.003
   Merkus P, 2014, EUR ARCH OTO-RHINO-L, V271, P3, DOI 10.1007/s00405-013-2378-3
   Moeller M, 1993, REHABILITATIVE AUDIO, P106
   Moog JS, 2010, OTOL NEUROTOL, V31, P1315, DOI 10.1097/MAO.0b013e3181eb3226
   Mt-Isa S, 2014, PHARMACOEPIDEM DR S, V23, P667, DOI 10.1002/pds.3636
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Noij KS, 2015, OTOLARYNG HEAD NECK, V153, P739, DOI 10.1177/0194599815596929
   Pagarkar W, 2011, INT J PEDIATR OTORHI, V75, P764, DOI 10.1016/j.ijporl.2011.02.017
   Papsin Blake C, 2005, Laryngoscope, V115, P1, DOI 10.1097/00005537-200501001-00001
   Physiological Closed-Loop Controlled (PCLC), 2015, PHYS CLOS LOOP CONTR, P1
   Puram SV, 2016, OTOLARYNG HEAD NECK, V155, P133, DOI 10.1177/0194599816637599
   Puram SV, 2015, OTOLARYNG CLIN N AM, V48, P1117, DOI 10.1016/j.otc.2015.07.013
   Puram SV, 2015, OTOL NEUROTOL, V36, P618, DOI 10.1097/MAO.0000000000000676
   Quittner AL, 2013, J PEDIATR-US, V162, P343, DOI 10.1016/j.jpeds.2012.08.003
   Rachovitsas D, 2012, INT J PEDIATR OTORHI, V76, P1370, DOI 10.1016/j.ijporl.2012.06.009
   ROBBINS AM, 1991, AM J OTOL, V12, P144
   Rosahl SK, 2013, NEUROSURGERY, V72, P58, DOI 10.1227/NEU.0b013e31826cde82
   Rubin LG, 2010, PEDIATRICS, V126, P381, DOI 10.1542/peds.2010-1427
   Rubinstein Jay T, 2004, Curr Opin Otolaryngol Head Neck Surg, V12, P444, DOI 10.1097/01.moo.0000134452.24819.c0
   Ryugo D, 2015, CELL TISSUE RES, V361, P251, DOI 10.1007/s00441-014-2004-8
   Goffi-Gomez MVS, 2012, INT J PEDIATR OTORHI, V76, P257, DOI 10.1016/j.ijporl.2011.11.016
   Sennaroglu L, 2002, LARYNGOSCOPE, V112, P2230, DOI 10.1097/00005537-200212000-00019
   Sennaroglu L, 2012, AURIS NASUS LARYNX, V39, P439, DOI 10.1016/j.anl.2011.10.013
   Sennaroglu Levent, 2010, Cochlear Implants Int, V11, P4, DOI 10.1002/cii.416
   Sennaroglu L, 2011, OTOL NEUROTOL, V32, P187, DOI 10.1097/MAO.0b013e318206fc1e
   Sepahdari AR, 2014, OPER TECH OTOLARYNGO, V25, P13
   SHANNON RV, 1993, OTOLARYNG HEAD NECK, V108, P634, DOI 10.1177/019459989310800603
   Shapiro WH, 2012, OTOLARYNG CLIN N AM, V45, P111, DOI 10.1016/j.otc.2011.08.020
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   SILVERSTEIN H, 1988, AM J OTOL, V9, P269
   Snyder RL, 2008, HEARING RES, V235, P23, DOI 10.1016/j.heares.2007.09.013
   Thompson DC, 2001, JAMA-J AM MED ASSOC, V286, P2000, DOI 10.1001/jama.286.16.2000
   Valero J, 2012, EAR HEARING, V33, P3, DOI 10.1097/AUD.0b013e3182263460
   van Iersel M, 2017, THER INNOV REGUL SCI, V51, P288, DOI 10.1177/2168479017705156
   Waring M D, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P33
   Warren FM, 2010, OTOL NEUROTOL, V31, P1088, DOI 10.1097/MAO.0b013e3181eb3272
   Wilkinson EP, 2017, OTOL NEUROTOL, V38, P212, DOI 10.1097/MAO.0000000000001287
   Yamazaki H, 2015, OTOL NEUROTOL, V36, P977, DOI 10.1097/MAO.0000000000000721
   Yi JS, 2013, INT J PEDIATR OTORHI, V77, P530, DOI 10.1016/j.ijporl.2012.12.031
   Young JY, 2014, RADIOGRAPHICS, V34, pE133, DOI 10.1148/rg.345130083
   Young NM, 2012, INT J PEDIATR OTORHI, V76, P1442, DOI 10.1016/j.ijporl.2012.06.019
   Zhang ZH, 2012, INT J PEDIATR OTORHI, V76, P1188, DOI 10.1016/j.ijporl.2012.05.003
   Zimmerman-Phillips S, 2000, ANN OTO RHINOL LARYN, V109, P42
   Zimmerman-Phillips S., 2001, INFANT TODDLER MEANI
NR 101
TC 1
Z9 1
U1 0
U2 8
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2168-4790
EI 2168-4804
J9 THER INNOV REGUL SCI
JI Ther. Innov. Regul. Sci.
PD SEP
PY 2018
VL 52
IS 5
BP 669
EP 679
DI 10.1177/2168479017741111
PG 11
WC Medical Informatics; Pharmacology & Pharmacy
SC Medical Informatics; Pharmacology & Pharmacy
GA GT3WL
UT WOS:000444434600015
PM 29714549
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Nilakantan, A
   Raj, P
   Saini, S
   Mittal, R
AF Nilakantan, Ajith
   Raj, Poonam
   Saini, Sachin
   Mittal, Ruchika
TI Early Speech Perception Test Outcome in Children with Severe
   Sensorineural Hearing Loss with Unilateral Cochlear Implants Alone
   versus Bimodal Stimulation
SO INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY
LA English
DT Article
DE Auditory deprivation; Binaural hearing; Bimodal Stimulation; Cochlear
   implantee; Early Speech Perception Test
ID OPPOSITE EARS; AID; LOCALIZATION; RECOGNITION; PERFORMANCE
AB Bilateral stimulation of the auditory system has clear advantages over unilateral hearing. Hearing-impaired children are, therefore, generally fitted with hearing aids in both ears so that they can have the benefits of binaural hearing. Children who use acochlear implant in one ear and no acoustic stimulation in the opposite ear are at a definite disadvantage. This study was undertaken to determine the advantages of bimodal stimulation in pediatric population especially in terms of speech recognition. This study comprised of 30 children between 3 and 6 years of age with profound bilateral sensorineural hearing loss with cochlear implant in one ear and fitted with digital hearing aid in non-implanted ear. Speech recognition performance was compared in unilateral cochlear implant only and with bimodal hearing stimulation in the same set of children. A statistically significant difference was found between speech reception scores in children with a unilateral cochlear implant only and those with a cochlear implant in one ear and a hearing aid in the non implanted ear in quiet surroundings. It is suggested that the use of bimodal fitting be considered as an effective management method to obtain the advantage of binaural hearing in children who undergo unilateral cochlear implantation.
C1 [Nilakantan, Ajith] AFMC, Dept ENT & HNS, Pune 411040, Maharashtra, India.
   [Raj, Poonam; Saini, Sachin; Mittal, Ruchika] Army Hosp R&R, Dept ENT & HNS, New Delhi 110010, India.
RP Raj, P (corresponding author), Army Hosp R&R, Dept ENT & HNS, New Delhi 110010, India.
EM ajith.nil@gmail.com; poonam_mehra13@yahoo.co.in;
   sachin10s2002@gmail.com; ruchikamittal07@gmail.com
RI RAJ, PROFESSOR(DR) DES/AAA-1007-2020
OI RAJ, PROFESSOR(DR) DES/0000-0002-4050-4778; Saini,
   Sachin/0000-0002-0608-5389
FU Ministry of Defense, Government of India
FX This study was funded by Ministry of Defense, Government of India
CR Bhat R, 2011, EARLY SPEECH PERCEPT
   Ching TYC, 2005, INT J AUDIOL, V44, P677, DOI 10.1080/00222930500271630
   Ching TYC, 2005, INT J AUDIOL, V44, P513, DOI 10.1080/14992020500190003
   Ching TYC, 2004, EAR HEARING, V25, P9, DOI 10.1097/01.AUD.0000111261.84611.C8
   Ching TYC, HEARING AID COMPLEME
   Eisenberg LS, 2006, AUDIOL NEURO-OTOL, V11, P259, DOI 10.1159/000093302
   Hamzavi J, 2004, INT J AUDIOL, V43, P61, DOI 10.1080/14992020400050010
   Heo Ji-Hye, 2013, Korean J Audiol, V17, P65, DOI 10.7874/kja.2013.17.2.65
   Johnstone PM, 2010, J AM ACAD AUDIOL, V21, P522, DOI 10.3766/jaaa.21.8.4
   Kumar SBR, 2010, INDIAN J OTOLARYNGOL, V62, P342, DOI 10.1007/s12070-010-0050-4
   Luntz M, 2007, ACTA OTO-LARYNGOL, V127, P1045, DOI 10.1080/00016480601158740
   Phanindra R, 2010, LANG INDIA, V10, P28
   Potts LG, 2009, J AM ACAD AUDIOL, V20, P353, DOI 10.3766/jaaa.20.6.4
   Tyler RS, 2002, EAR HEARING, V23, P98, DOI 10.1097/00003446-200204000-00003
   Waltzman SB, 2005, PEDIATRICS, V116, pE487, DOI 10.1542/peds.2005-0282
   Xue T, 2009, OTOL NEUROTOL, V30, P690, DOI 10.1097/MAO.0b013e3181a66d43
NR 16
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 2231-3796
EI 0973-7707
J9 INDIAN J OTOLARYNGOL
JI Indian J. Otolaryngol. Head Neck Surg.
PD SEP
PY 2018
VL 70
IS 3
BP 398
EP 404
DI 10.1007/s12070-018-1398-0
PG 7
WC Surgery
SC Surgery
GA GT0YQ
UT WOS:000444180600015
PM 30211097
OA Green Published
DA 2021-02-24
ER

PT J
AU Feng, GY
   Gan, ZZ
   Wang, SP
   Wong, PCM
   Chandrasekaran, B
AF Feng, Gangyi
   Gan, Zhenzhong
   Wang, Suiping
   Wong, Patrick C. M.
   Chandrasekaran, Bharath
TI Task-General and Acoustic-Invariant Neural Representation of Speech
   Categories in the Human Brain
SO CEREBRAL CORTEX
LA English
DT Article
DE Mandarin tone categories; multivariate pattern analysis; speech
   perception; task-general neural representation
ID SUPERIOR TEMPORAL GYRUS; LANGUAGE EXPERIENCE; LEXICAL TONE; FUNCTIONAL
   CONNECTIVITY; LINGUISTIC EXPERIENCE; MISMATCH NEGATIVITY; INTELLIGIBLE
   SPEECH; MANDARIN CHINESE; PITCH CONTOURS; PERCEPTION
AB A significant neural challenge in speech perception includes extracting discrete phonetic categories from continuous and multidimensional signals despite varying task demands and surface-acoustic variability. While neural representations of speech categories have been previously identified in frontal and posterior temporal-parietal regions, the task dependency and dimensional specificity of these neural representations are still unclear. Here, we asked native Mandarin participants to listen to speech syllables carrying 4 distinct lexical tone categories across passive listening, repetition, and categorization tasks while they underwent functional magnetic resonance imaging (fMRI). We used searchlight classification and representational similarity analysis (RSA) to identify the dimensional structure underlying neural representation across tasks and surface-acoustic properties. Searchlight classification analyses revealed significant "cross-task" lexical tone decoding within the bilateral superior temporal gyrus (STG) and left inferior parietal lobule (LIPL). RSA revealed that the LIPL and LSTG, in contrast to the RSTG, relate to 2 critical dimensions (pitch height, pitch direction) underlying tone perception. Outside this core representational network, we found greater activation in the inferior frontal and parietal regions for stimuli that are more perceptually similar during tone categorization. Our findings reveal the specific characteristics of fronto-tempo-parietal regions that support speech representation and categorization processing.
C1 [Feng, Gangyi; Wong, Patrick C. M.] Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Shatin, Hong Kong, Peoples R China.
   [Feng, Gangyi; Wong, Patrick C. M.] Chinese Univ Hong Kong, Brain & Mind Inst, Shatin, Hong Kong, Peoples R China.
   [Feng, Gangyi; Chandrasekaran, Bharath] Univ Texas Austin, Moody Coll Commun, Dept Commun Sci & Disorders, 2504A Whitis Ave A1100, Austin, TX 78712 USA.
   [Gan, Zhenzhong; Wang, Suiping] South China Normal Univ, Ctr Study Appl Psychol, Guangzhou 510631, Guangdong, Peoples R China.
   [Gan, Zhenzhong; Wang, Suiping] South China Normal Univ, Sch Psychol, Guangzhou 510631, Guangdong, Peoples R China.
   [Wang, Suiping] South China Normal Univ, Guangdong Prov Key Lab Mental Hlth & Cognit Sci, Guangzhou 510631, Guangdong, Peoples R China.
   [Chandrasekaran, Bharath] Univ Texas Austin, Dept Psychol, 108 E Dean Keeton Stop A8000, Austin, TX 78712 USA.
   [Chandrasekaran, Bharath] Univ Texas Austin, Dept Linguist, 305 E 23rd St STOP B5100, Austin, TX 78712 USA.
   [Chandrasekaran, Bharath] Univ Texas Austin, Coll Liberal Arts, Inst Mental Hlth Res, 305 E 23rd St Stop E9000, Austin, TX 78712 USA.
   [Chandrasekaran, Bharath] Univ Texas Austin, Inst Neurosci, 1 Univ Stn Stop C7000, Austin, TX 78712 USA.
RP Wang, SP (corresponding author), South China Normal Univ, Ctr Study Appl Psychol, Guangzhou 510631, Guangdong, Peoples R China.; Wang, SP (corresponding author), South China Normal Univ, Sch Psychol, Guangzhou 510631, Guangdong, Peoples R China.; Chandrasekaran, B (corresponding author), Univ Texas Austin, 2504A Whitis Ave A1100, Austin, TX 78712 USA.
EM wangsuiping@m.scnu.edu.cn; bchandra@utexas.edu
OI Wong, Patrick/0000-0002-6105-5027; Feng, Gangyi/0000-0003-2239-5296;
   Chandrasekaran, Bharath/0000-0002-3673-9435
FU National Institute on Deafness and other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC013315 834];
   Key Project of National Social Science Foundation of China [15AZD048];
   Key Project of National Natural Science Foundation of Guangdong
   Province, China [2014A030311016]; NATIONAL INSTITUTE ON DEAFNESS AND
   OTHER COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC013315,
   R01DC013315, R01DC015504, R01DC015504, R01DC015504, R01DC013315,
   R01DC013315, R01DC013315, R01DC015504, R01DC013315] Funding Source: NIH
   RePORTER
FX National Institute on Deafness and other Communication Disorders of the
   National Institutes of Health under Award No. (R01DC013315 834 to B.C.),
   Key Project of National Social Science Foundation of China (15AZD048),
   and Key Project of National Natural Science Foundation of Guangdong
   Province, China (2014A030311016).
CR Alho J, 2016, NEUROIMAGE, V129, P214, DOI 10.1016/j.neuroimage.2016.01.016
   Arsenault JS, 2016, PSYCHON B REV, V23, P1231, DOI 10.3758/s13423-015-0988-z
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   BLUMSTEIN SE, 1977, NEUROPSYCHOLOGIA, V15, P19, DOI 10.1016/0028-3932(77)90111-7
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Bonte M, 2014, J NEUROSCI, V34, P4548, DOI 10.1523/JNEUROSCI.4339-13.2014
   Buchel C, 1998, NEUROIMAGE, V8, P140, DOI 10.1006/nimg.1998.0351
   Buchel C, 1996, NEUROIMAGE, V4, P60, DOI 10.1006/nimg.1996.0029
   CAPLAN D, 1995, NEUROLOGY, V45, P293, DOI 10.1212/WNL.45.2.293
   Chandrasekaran B, 2007, RESTOR NEUROL NEUROS, V25, P195
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chandrasekaran B, 2016, ATTEN PERCEPT PSYCHO, V78, P566, DOI 10.3758/s13414-015-0999-x
   Chandrasekaran B, 2015, J NEUROSCI, V35, P7808, DOI 10.1523/JNEUROSCI.4706-14.2015
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chen JY, 2002, J MEM LANG, V46, P751, DOI 10.1006/jmla.2001.2825
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   Cukur T, 2013, NAT NEUROSCI, V16, P763, DOI 10.1038/nn.3381
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Fairhall SL, 2013, J NEUROSCI, V33, P10552, DOI 10.1523/JNEUROSCI.0051-13.2013
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   GANDOUR JT, 1978, PHONETICA, V35, P169, DOI 10.1159/000259928
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Geng JJ, 2009, J COGNITIVE NEUROSCI, V21, P1584, DOI 10.1162/jocn.2009.21103
   GRIESER D, 1989, DEV PSYCHOL, V25, P577, DOI 10.1037/0012-1649.25.4.577
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Hall DA, 2009, CEREB CORTEX, V19, P576, DOI 10.1093/cercor/bhn108
   Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   Kok P, 2012, NEURON, V75, P265, DOI 10.1016/j.neuron.2012.04.034
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Kriegeskorte N, 2013, TRENDS COGN SCI, V17, P401, DOI 10.1016/j.tics.2013.06.007
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Maddox WT, 2014, CORTEX, V58, P186, DOI 10.1016/j.cortex.2014.06.013
   MAZOYER BM, 1993, J COGNITIVE NEUROSCI, V5, P467, DOI 10.1162/jocn.1993.5.4.467
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Misaki M, 2010, NEUROIMAGE, V53, P103, DOI 10.1016/j.neuroimage.2010.05.051
   Myers EB, 2007, NEUROPSYCHOLOGIA, V45, P1463, DOI 10.1016/j.neuropsychologia.2006.11.005
   Myers EB, 2012, J COGNITIVE NEUROSCI, V24, P1695, DOI 10.1162/jocn_a_00243
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Narain C, 2003, CEREB CORTEX, V13, P1362, DOI 10.1093/cercor/bhg083
   Oosterhof NN, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00027
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005
   Scharinger M, 2015, NEUROIMAGE, V106, P373, DOI 10.1016/j.neuroimage.2014.11.050
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Simanova I, 2014, CEREB CORTEX, V24, P426, DOI 10.1093/cercor/bhs324
   Spitsyna G, 2006, J NEUROSCI, V26, P7328, DOI 10.1523/JNEUROSCI.0559-06.2006
   Stevens WD, 2010, CEREB CORTEX, V20, P1997, DOI 10.1093/cercor/bhp270
   Tomasi D, 2014, CEREB CORTEX, V24, P2619, DOI 10.1093/cercor/bht119
   Tong F, 2012, ANNU REV PSYCHOL, V63, P483, DOI 10.1146/annurev-psych-120710-100412
   Tong YX, 2008, LANG COGNITIVE PROC, V23, P689, DOI 10.1080/01690960701728261
   Tung KC, 2013, NEUROIMAGE, V78, P316, DOI 10.1016/j.neuroimage.2013.04.006
   Wang Y, 2003, J COGNITIVE NEUROSCI, V15, P1019, DOI 10.1162/089892903770007407
   Wang Y, 2004, APPL PSYCHOLINGUIST, V25, P449, DOI 10.1017/S0142716404001213
   Warren JD, 2003, P NATL ACAD SCI USA, V100, P10038, DOI 10.1073/pnas.1730682100
   Wong PCM, 2007, HUM BRAIN MAPP, V28, P995, DOI 10.1002/hbm.20330
   Xu YS, 2006, HUM BRAIN MAPP, V27, P173, DOI 10.1002/hbm.20176
   Yi HG, 2016, CEREB CORTEX, V26, P1409, DOI 10.1093/cercor/bhu236
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 75
TC 11
Z9 11
U1 1
U2 6
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD SEP
PY 2018
VL 28
IS 9
BP 3241
EP 3254
DI 10.1093/cercor/bhx195
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA GS3TR
UT WOS:000443545600014
PM 28968658
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Schwartz, G
   Arndt, D
AF Schwartz, Geoffrey
   Arndt, Dania
TI Laryngeal Realism vs. Modulation Theory - evidence from VOT
   discrimination in Polish
SO LANGUAGE SCIENCES
LA English
DT Article
DE Laryngeal phonology; Modulation theory; Polish phonology; Speech
   perception; Laryngeal realism; Onset prominence
ID LANGUAGE; NEUTRALIZATION; ASSIMILATION; GERMAN; STOPS
AB A perception study testing Polish listeners' discrimination of the voice-voiceless contrast in stop consonants is presented. Results show that the absence of pre-voicing in /bdg/ does not hinder perception of voiced stops in Polish. These findings are presented within a wider discussion of the phonological representation of laryngeal contrasts in languages with two series of consonants. The approach of Laryngeal Realism is compared with a new approach based on the assumptions of Modulation Theory (MT) and couched within the Onset Prominence (OP) representational framework. It is suggested that the MT/OP approach offers an insightful way forward for further study into laryngeal phonology. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Schwartz, Geoffrey; Arndt, Dania] Adam Mickiewicz Univ, Fac English, Al Niepodleglosci 4, PL-61874 Poznan, Poland.
RP Schwartz, G (corresponding author), Adam Mickiewicz Univ, Fac English, Al Niepodleglosci 4, PL-61874 Poznan, Poland.
EM geoff@wa.amu.edu.pl; darndt@wa.amu.edu.pl
OI Schwartz, Geoffrey/0000-0002-0728-7820
FU Polish National Science Centre (Narodowe Centrum Nauki)
   [UMO-2016/21/B/HS2/00610]
FX This research was supported by a grant from the Polish National Science
   Centre (Narodowe Centrum Nauki), project number UMO-2016/21/B/HS2/00610.
   Thanks go to Bartosz Brzoza and Olga Witczak for their help in the
   laboratory, and of course to our experimental participants.
CR Antoniou M, 2011, J PHONETICS, V39, P558, DOI 10.1016/j.wocn.2011.03.001
   Antoniou M, 2010, J PHONETICS, V38, P640, DOI 10.1016/j.wocn.2010.09.005
   Beckman J, 2013, J LINGUIST, V49, P259, DOI 10.1017/S0022226712000424
   Bethin Christina, 1984, INT J SLAV LING POET, V29, P17
   Blevins Juliette, 2004, EVOLUTIONARY PHONOLO
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   Cho Young-mee Yu, 1990, THESIS
   Cyran Eugeniusz, 2014, PHONOLOGY PHONETICS
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   Grosjean F., 1998, BILING-LANG COGN, V1, P131, DOI DOI 10.1017/S136672899800025X
   GUSSMANN E, 1992, LINGUIST INQ, V23, P29
   Harris J, 2009, STUD GENERAT GRAMM, V103, P9, DOI 10.1515/9783110218596.1.9
   Harris John, 1994, ENGLISH SOUND STRUCT
   Haspelmath M, 2006, J LINGUIST, V42, P25, DOI 10.1017/S0022226705003683
   Herd Wendy, 2015, P M ACOUST, V23
   Honeybone Patrick, 2005, INTERNAL ORG PHONOLO, P317, DOI [10.1515/9783110890402.317, DOI 10.1515/9783110890402]
   Hume E., 2011, BLACKWELL COMPANION, V1, P79
   Jessen M., 1998, PHONETICS PHONOLOGY
   Keating P. A., 1979, THESIS
   KEATING PA, 1984, LANGUAGE, V60, P286, DOI 10.2307/413642
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lombardi L, 1999, NAT LANG LINGUIST TH, V17, P267, DOI 10.1023/A:1006182130229
   Lombardi L., 1991, THESIS
   Maddieson I., 1984, PATTERNS SOUNDS
   OHDE RN, 1984, J ACOUST SOC AM, V75, P224, DOI 10.1121/1.390399
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   Roettger TB, 2014, J PHONETICS, V43, P11, DOI 10.1016/j.wocn.2014.01.002
   Rubach J, 1996, LINGUIST INQ, V27, P69
   Salmons J. C., 1995, PHONOLOGY, V12, P369, DOI DOI 10.1017/S0952675700002566
   Schwartz G, 2018, LANG SCI, V69, P98, DOI 10.1016/j.langsci.2018.07.001
   Schwartz G, 2017, GLOSSA-UK, V2, DOI 10.5334/gjgl.465
   Schwartz G, 2010, POZ STUD CONTEMP LIN, V46, P499, DOI 10.2478/v10010-010-0025-3
   Schwartz Geoffrey, 2018, SINFONIA 11 JAG U KR
   Schwartz Geoffrey, 2016, PHONOLOGY ITS FACES, P103
   Schwartz Geoffrey, 2017, 11 INT S NAT NONN AC
   Schwartz Geoffrey, 2018, 26 MANCH PHON M
   Schwartz Geoffrey, 2017, 3 APPR PHON PHON APA
   STEVENS KN, 1974, J ACOUST SOC AM, V55, P653, DOI 10.1121/1.1914578
   TRAUNMULLER H, 1994, PHONETICA, V51, P170, DOI 10.1159/000261968
   van der Hulst Harry, 2015, SEGMENTS EXPT LINGUI, P323
   Vaux B., 2005, PHONOLOGY, V22, P395
   Wetzels WL, 2001, LANGUAGE, V77, P207
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
   Zajc M, 2015, THESIS
NR 44
TC 3
Z9 3
U1 0
U2 1
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0388-0001
EI 1873-5746
J9 LANG SCI
JI Lang. Sci.
PD SEP
PY 2018
VL 69
BP 98
EP 112
DI 10.1016/j.langsci.2018.07.001
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA GS4ZQ
UT WOS:000443666800007
OA Other Gold
DA 2021-02-24
ER

PT J
AU Escudero, P
   Mulak, KE
   Elvin, J
   Traynor, NM
AF Escudero, Paola
   Mulak, Karen E.
   Elvin, Jaydene
   Traynor, Nicole M.
TI "Mummy, keep it steady": phonetic variation shapes word learning at 15
   and 17 months
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID SPEECH-PERCEPTION; VOWELS; ASYMMETRIES; INFANTS; ENGLISH; DETAIL; TIME
AB Fifteen-month-olds have difficulty detecting differences between novel words differing in a single vowel. Previous work showed that Australian English (AusE) infants habituated to the word-object pair DEET detected an auditory switch to DIT and DOOT in Canadian English (CanE) but not in their native AusE (Escudero et al., 2014). The authors speculated that this may be because the vowel inherent spectral change variation (VISC) in AusE DEET is larger than in CanE DEET. We investigated whether VISC leads to difficulty in encoding phonetic detail during early word learning, and whether this difficulty dissipates with age. In Experiment 1, we familiarized AusE-learning 15-month-olds to AusE DIT, which contains smaller VISC than AusE DEET. Unlike infants familiarized with AusE DEET (Escudero et al., 2014), infants detected a switch to DEET and DOOT. In Experiment 2, we familiarized AusE-learning 17-month-olds to AusE DEET. This time, infants detected a switch to DOOT, and marginally detected a switch to DIT. Our acoustic analysis showed that AusE DEET and DOOT are differentiated by the second vowel formant, while DEET and DIT can only be distinguished by their changing dynamic properties throughout the vowel trajectory. Thus, by 17 months, AusE infants can encode highly dynamic acoustic properties, enabling them to learn the novel vowel minimal pairs that are difficult at 15 months. These findings suggest that the development of word learning is shaped by the phonetic properties of the specific word minimal pair.
C1 [Escudero, Paola; Mulak, Karen E.; Elvin, Jaydene; Traynor, Nicole M.] Western Sydney Univ, ARC Ctr Excellence Dynam Language, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.
RP Escudero, P (corresponding author), Western Sydney Univ, MARCS Inst, Locked Bag 1797, Penrith, NSW 2751, Australia.
EM paola.escudero@westernsydney.edu.au
RI Escudero, Paola/Q-5310-2019
OI Escudero, Paola/0000-0002-8071-7663; Traynor, Nicole/0000-0001-5650-1136
FU ARC (Australian Research Council) Centre of Excellence for the Dynamics
   of LanguageAustralian Research Council [CE140100041]
FX ARC (Australian Research Council) Centre of Excellence for the Dynamics
   of Language (project number CE140100041).
CR ASLIN RN, 1981, CHILD DEV, V52, P1135, DOI 10.1111/j.1467-8624.1981.tb03159.x
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Boersma P., 2003, P 15 INT C PHON SCI, P1013
   BURNHAM DK, 1986, APPL PSYCHOLINGUIST, V7, P207, DOI 10.1017/S0142716400007542
   Curtin S, 2009, DEVELOPMENTAL SCI, V12, P725, DOI 10.1111/j.1467-7687.2009.00814.x
   Elvin J., 2016, P 16 AUSTR INT C SPE, P293
   Elvin J, 2016, J ACOUST SOC AM, V140, P576, DOI 10.1121/1.4952387
   Elvin J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01188
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P., 2016, LANG SCI, V7, P1218, DOI [10.3389/fpsyg.2016.01218, DOI 10.3389/FPSYG.2016.01218]
   Escudero P., 2005, DISSERTATION SERIES, V113
   Escudero P., 2009, PHONOLOGY PERCEPTION, P151
   Escudero P, 2016, COGNITIVE SCI, V40, P455, DOI 10.1111/cogs.12243
   Escudero P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01059
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Kriengwatana BP, 2017, J SPEECH LANG HEAR R, V60, P1088, DOI 10.1044/2016_JSLHR-H-16-0050
   Ladefoged Peter, 1975, COURSE PHONETICS
   Nittrouer S, 2014, LANG SPEECH, V57, P487, DOI 10.1177/0023830913508075
   Oakes LM, 2010, INFANCY, V15, P1, DOI 10.1111/j.1532-7078.2010.00030.x
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   R Core Team, 2016, R LANG ENV STAT COMP
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Thomas E. R., 2001, ACOUSTIC ANAL VOWEL
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Watson CI, 1999, J ACOUST SOC AM, V106, P458, DOI 10.1121/1.427069
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   Williams D, 2014, J ACOUST SOC AM, V136, P2751, DOI 10.1121/1.4896471
NR 34
TC 2
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD SEP
PY 2018
VL 21
IS 5
AR e12640
DI 10.1111/desc.12640
PG 11
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GR8PQ
UT WOS:000442987400011
PM 29285844
OA Bronze
DA 2021-02-24
ER

PT J
AU Fort, M
   Lammertink, I
   Peperkamp, S
   Guevara-Rukoz, A
   Fikkert, P
   Tsuji, S
AF Fort, Mathilde
   Lammertink, Imme
   Peperkamp, Sharon
   Guevara-Rukoz, Adriana
   Fikkert, Paula
   Tsuji, Sho
TI Symbouki: a meta-analysis on the emergence of sound symbolism in early
   language acquisition
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID SHAPE CORRESPONDENCES; PREVERBAL INFANTS; SPEECH-PERCEPTION;
   SENSITIVITY; ASSOCIATION; ICONICITY; SIZE
AB Adults and toddlers systematically associate pseudowords such as "bouba" and "kiki" with round and spiky shapes, respectively, a sound symbolic phenomenon known as the "bouba-kiki effect". To date, whether this sound symbolic effect is a property of the infant brain present at birth or is a learned aspect of language perception remains unknown. Yet, solving this question is fundamental for our understanding of early language acquisition. Indeed, an early sensitivity to such sound symbolic associations could provide a powerful mechanism for language learning, playing a bootstrapping role in the establishment of novel sound-meaning associations. The aim of the present meta-analysis (SymBouKi) is to provide a quantitative overview of the emergence of the bouba-kiki effect in infancy and early childhood. It allows a high-powered assessment of the true sound symbolic effect size by pooling over the entire set of 11 extant studies (six published, five unpublished), entailing data from 425 participants between 4 and 38 months of age. The quantitative data provide statistical support for a moderate, but significant, sound symbolic effect. Further analysis found a greater sensitivity to sound symbolism for bouba-type pseudowords (i.e., round sound-shape correspondences) than for kiki-type pseudowords (i.e., spiky sound-shape correspondences). For the kiki-type pseudowords, the effect emerged with age. Such discrepancy challenges the view that sensitivity to sound symbolism is an innate language mechanism rooted in an exuberant interconnected brain. We propose alternative hypotheses where both innate and learned mechanisms are at play in the emergence of sensitivity to sound symbolic relationships.
C1 [Fort, Mathilde] Univ Grenoble Alpes, CNRS, Grenoble Inst Engn, Inria,GIPSA Lab,Dept Speech & Cognit,UMR 5216, Grenoble, France.
   [Fort, Mathilde] Univ Savoie Mt Blanc, Univ Grenoble Alpes, CNRS, LPNC,UMR 5105, Grenoble, France.
   [Lammertink, Imme] Univ Amsterdam, Amsterdam Ctr Language & Commun, Amsterdam, Netherlands.
   [Peperkamp, Sharon; Guevara-Rukoz, Adriana; Tsuji, Sho] PSL Univ, CNRS, EHESS, LSCP,ENS,Dept Etudes Cognit, Paris, France.
   [Peperkamp, Sharon] Maternite Port Royal, AP HP, Fac Med Paris Descartes, Paris, France.
   [Fikkert, Paula] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.
   [Tsuji, Sho] Univ Penn, Dept Psychol, 425 S Univ Ave, Philadelphia, PA 19104 USA.
RP Tsuji, S (corresponding author), Univ Penn, Dept Psychol, 425 S Univ Ave, Philadelphia, PA 19104 USA.
EM tsujish@gmail.com
RI peperkamp, sharon/V-6994-2017
OI peperkamp, sharon/0000-0001-5985-8878; Lammertink,
   Imme/0000-0001-6625-4108; Fort, Mathilde/0000-0003-4519-6185
FU Agence Nationale de la RechercheFrench National Research Agency
   (ANR)European Commission [ANR-13-APPR-0012, ANR-10-LABX-0087 IEC,
   ANR-10-IDEX-0001-02 PSL*]; European Commission Horizon 2020 Marie
   Sklodowska-Curie Individual Fellowship [659553]; Fondation de
   FranceFondation de France
FX Agence Nationale de la Recherche (ANR-13-APPR-0012; ANR-10-LABX-0087
   IEC; ANR-10-IDEX-0001-02 PSL*); European Commission Horizon 2020 Marie
   Sklodowska-Curie Individual Fellowship, Grant Number: 659553 and the
   Fondation de France
CR Asano M, 2015, CORTEX, V63, P196, DOI 10.1016/j.cortex.2014.08.025
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Bergmann C, 2016, DEVELOPMENTAL SCI, V19, P901, DOI 10.1111/desc.12341
   Blasi DE, 2016, P NATL ACAD SCI USA, V113, P10818, DOI 10.1073/pnas.1605782113
   Cuskley C., 2015, PSYCHOL RES, V81, P119, DOI DOI 10.1007/500426-015-0709-2
   D'Onofrio A, 2014, LANG SPEECH, V57, P367, DOI 10.1177/0023830913507694
   De Saussure Ferdinand, 1959, COURSE GEN LINGUISTI
   Dingemanse M, 2016, LANGUAGE, V92, pE117, DOI 10.1353/lan.2016.0034
   Dingemanse M, 2015, TRENDS COGN SCI, V19, P603, DOI 10.1016/j.tics.2015.07.013
   Egger M, 1997, BMJ-BRIT MED J, V315, P629, DOI 10.1136/bmj.315.7109.629
   Ernst MO, 2007, J VISION, V7, DOI 10.1167/7.5.7
   Fernandez-Prieto I, 2015, INFANT BEHAV DEV, V38, P77, DOI 10.1016/j.infbeh.2014.12.008
   Fort M., 2013, AUDIOVISUAL SPEECH P
   Fort M., 2015, LOOKING BOUBA KIKI E
   Hedges L, 1981, J EDUC STAT, V6, P107, DOI [10.3102/10769986006002107, DOI 10.3102/10769986006002107]
   Hedges LV, 2010, RES SYNTH METHODS, V1, P39, DOI 10.1002/jrsm.5
   Imai M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116494
   Imai M, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0298
   Imai M, 2008, COGNITION, V109, P54, DOI 10.1016/j.cognition.2008.07.015
   Jadva V, 2010, ARCH SEX BEHAV, V39, P1261, DOI 10.1007/s10508-010-9618-z
   Kantartzis K, 2011, COGNITIVE SCI, V35, P575, DOI 10.1111/j.1551-6709.2010.01169.x
   Kellman P. J., 2007, HDB CHILD PSYCHOL, V2, P109
   Kohler W., 1947, GESTALT PSYCHOL INTR
   Kovic V, 2010, COGNITION, V114, P19, DOI 10.1016/j.cognition.2009.08.016
   Lammertink I., 2015, BIENN M SOC RES CHIL
   Lany J, 2013, COMPREHENSIVE DEVELOPMENTAL NEUROSCIENCE: NEURAL CIRCUIT DEVELOPMENT AND FUNCTION IN THE HEALTHY AND DISEASED BRAIN, P231, DOI 10.1016/B978-0-12-397267-5.00034-0
   Lewkowicz DJ, 2014, PSYCHOL SCI, V25, P832, DOI 10.1177/0956797613516011
   Lewkowicz DJ, 2009, TRENDS COGN SCI, V13, P470, DOI 10.1016/j.tics.2009.08.004
   Lockwood G, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01246
   Matthew Jones John, 2014, P 36 ANN M COGN SCI, P2459
   Maurer D, 2006, DEVELOPMENTAL SCI, V9, P316, DOI 10.1111/j.1467-7687.2006.00495.x
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1371/journal.pmed.1000097, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535]
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299
   Monaghan P, 2012, J EXP PSYCHOL LEARN, V38, P1152, DOI 10.1037/a0027747
   Nygaard LC, 2009, COGNITION, V112, P181, DOI 10.1016/j.cognition.2009.04.001
   Ozturk O, 2013, J EXP CHILD PSYCHOL, V114, P173, DOI 10.1016/j.jecp.2012.05.004
   Palumbo L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140043
   Pejovic J, 2017, DEV PSYCHOL, V53, P581, DOI 10.1037/dev0000237
   Pena M, 2011, PSYCHOL SCI, V22, P1419, DOI 10.1177/0956797611421791
   Perry LK, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12572
   Perry LK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137147
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Quinn PC, 1997, INFANT BEHAV DEV, V20, P35, DOI 10.1016/S0163-6383(97)90059-X
   R Core Team, 2016, R LANG ENV STAT COMP
   Ramachandran V, 2001, J CONSCIOUSNESS STUD, V8, P3
   Spector F., 2009, THESIS
   Spector F, 2013, I-PERCEPTION, V4, P239, DOI 10.1068/i0535
   Spector F, 2009, DEV PSYCHOL, V45, P175, DOI 10.1037/a0014171
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Starr A., 2012, BIENN M INT SOC INF
   Teglas E, 2016, COGNITION, V157, P227, DOI 10.1016/j.cognition.2016.09.003
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Tsuji S, 2014, PERSPECT PSYCHOL SCI, V9, P661, DOI 10.1177/1745691614552498
   Tzeng CY, 2017, J EXP CHILD PSYCHOL, V160, P107, DOI 10.1016/j.jecp.2017.03.004
   Viechtbauer W, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i03
   Walker P, 2016, J EXP PSYCHOL LEARN, V42, P1339, DOI 10.1037/xlm0000253
   Walker P, 2014, PSYCHOL SCI, V25, P835, DOI 10.1177/0956797613520170
   Walker P, 2010, PSYCHOL SCI, V21, P21, DOI 10.1177/0956797609354734
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
NR 60
TC 13
Z9 13
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD SEP
PY 2018
VL 21
IS 5
AR e12659
DI 10.1111/desc.12659
PG 13
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GR8PQ
UT WOS:000442987400027
PM 29542266
DA 2021-02-24
ER

PT J
AU Toscano, JC
   Anderson, ND
   Fabiani, M
   Gratton, G
   Garnsey, SM
AF Toscano, Joseph C.
   Anderson, Nathaniel D.
   Fabiani, Monica
   Gratton, Gabriele
   Garnsey, Susan M.
TI The time-course of cortical responses to speech revealed by fast optical
   imaging
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Speech perception; Phonological categorization; Spoken language
   processing; Optical imaging; Event-related potentials
ID FUNCTIONAL-ORGANIZATION; PERCEPTION; CORTEX; LANGUAGE; SIGNAL; DYNAMICS;
   MODEL; BRAIN; REPRESENTATIONS; COMPENSATION
AB Recent work has sought to describe the time-course of spoken word recognition, from initial acoustic cue encoding through lexical activation, and identify cortical areas involved in each stage of analysis. However, existing methods are limited in either temporal or spatial resolution, and as a result, have only provided partial answers to the question of how listeners encode acoustic information in speech. We present data from an experiment using a novel neuroimaging method, fast optical imaging, to directly assess the time-course of speech perception, providing non-invasive measurement of speech sound representations, localized to specific cortical areas. We find that listeners encode speech in terms of continuous acoustic cues at early stages of processing (ca. 96 ms post-stimulus onset), and begin activating phonological category representations rapidly (ca. 144 ms post-stimulus). Moreover, cue-based representations are widespread in the brain and overlap in time with graded category-based representations, suggesting that spoken word recognition involves simultaneous activation of both continuous acoustic cues and phonological categories.
C1 [Toscano, Joseph C.] Villanova Univ, Dept Psychol & Brain Sci, 800 E Lancaster Ave, Villanova, PA 19085 USA.
   [Toscano, Joseph C.; Anderson, Nathaniel D.; Fabiani, Monica; Gratton, Gabriele; Garnsey, Susan M.] Univ Illinois, Beckman Inst Adv Sci & Technol, Champaign, IL USA.
   [Anderson, Nathaniel D.; Fabiani, Monica; Gratton, Gabriele; Garnsey, Susan M.] Univ Illinois, Dept Psychol, Champaign, IL USA.
RP Toscano, JC (corresponding author), Villanova Univ, Dept Psychol & Brain Sci, 800 E Lancaster Ave, Villanova, PA 19085 USA.
EM joseph.toscano@villanova.edu
OI Gratton, Gabriele/0000-0003-3634-7463; Toscano,
   Joseph/0000-0001-8141-0084; Fabiani, Monica/0000-0002-7579-2773
FU University of Illinois Research Board; Beckman Postdoctoral Fellowship;
   NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [S10-RR029294]; NATIONAL CENTER FOR
   RESEARCH RESOURCESUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Center for
   Research Resources (NCRR) [S10RR029294] Funding Source: NIH RePORTER
FX We would like to thank Jian Huang, Erika Hussey, Eric Holmes, Alex
   Senetar, Justin Gumina, and Heather Mauch for assistance with data
   collection; Edward Wlotko for assistance with the experiment design; and
   Ed Maclin for assistance with data analysis. Funding for this project
   was provided by a University of Illinois Research Board Grant to SMG and
   JCT, by a Beckman Postdoctoral Fellowship to JCT, and by NIH
   S10-RR029294.
CR Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Burton MW, 2000, J COGNITIVE NEUROSCI, V12, P679, DOI 10.1162/089892900562309
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Davis MH, 2003, J NEUROSCI, V23, P3423
   de Peralta-Menendez RG, 1998, IEEE T BIO-MED ENG, V45, P440, DOI 10.1109/10.664200
   DehaeneLambertz G, 1997, NEUROREPORT, V8, P919, DOI 10.1097/00001756-199703030-00021
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   FOWLER CA, 1984, PERCEPT PSYCHOPHYS, V36, P359, DOI 10.3758/BF03202790
   FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1
   Frye RE, 2007, J COGNITIVE NEUROSCI, V19, P1476, DOI 10.1162/jocn.2007.19.9.1476
   GIARD MH, 1994, ELECTROEN CLIN NEURO, V92, P238, DOI 10.1016/0168-5597(94)90067-1
   Gow DW, 2016, LANG COGN NEUROSCI, V31, P841, DOI 10.1080/23273798.2015.1029498
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   Gratton G, 2000, PSYCHOPHYSIOLOGY, V37, pS44
   Gratton G, 1997, NEUROIMAGE, V6, P168, DOI 10.1006/nimg.1997.0298
   GRATTON G, 1995, PSYCHOPHYSIOLOGY, V32, P292, DOI 10.1111/j.1469-8986.1995.tb02958.x
   Gratton G, 2003, PSYCHOPHYSIOLOGY, V40, P561, DOI 10.1111/1469-8986.00058
   Gratton G, 2001, TRENDS COGN SCI, V5, P357, DOI 10.1016/S1364-6613(00)01701-0
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Joanisse MF, 2007, NEUROREPORT, V18, P901, DOI 10.1097/WNR.0b013e3281053c4e
   Khalighinejad B, 2017, J NEUROSCI, V37, P2176, DOI 10.1523/JNEUROSCI.2383-16.2017
   KOSSLYN SM, 1989, J EXP PSYCHOL HUMAN, V15, P723, DOI 10.1037/0096-1523.15.4.723
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liebenthal E., 2000, CEREB CORTEX, V15, P1621
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   MASSARO DW, 1983, SPEECH COMMUN, V2, P15, DOI 10.1016/0167-6393(83)90061-4
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Miller JL, 1997, LANG COGNITIVE PROC, V12, P865, DOI 10.1080/016909697386754
   Munson C.M., 2011, THESIS
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   Nourski KV, 2015, BRAIN LANG, V148, P37, DOI 10.1016/j.bandl.2015.03.003
   Nourski KV, 2014, NEUROIMAGE, V101, P598, DOI 10.1016/j.neuroimage.2014.07.004
   Obleser J, 2003, NEUROIMAGE, V20, P1839, DOI 10.1016/j.neuroimage.2003.07.019
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Parks NA, 2015, NEUROPSYCHOLOGIA, V78, P153, DOI 10.1016/j.neuropsychologia.2015.10.002
   Parks NA, 2012, NEUROIMAGE, V59, P2504, DOI 10.1016/j.neuroimage.2011.08.097
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Phillips C, 2000, J COGNITIVE NEUROSCI, V12, P1038, DOI 10.1162/08989290051137567
   PICTON TW, 1974, ELECTROEN CLIN NEURO, V36, P179, DOI 10.1016/0013-4694(74)90155-2
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rogers JC, 2017, J COGNITIVE NEUROSCI, V29, P919, DOI 10.1162/jocn_a_01096
   Scharenborg O, 2007, SPEECH COMMUN, V49, P336, DOI 10.1016/j.specom.2007.01.009
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   SHARMA A, 1993, ELECTROEN CLIN NEURO, V88, P64, DOI 10.1016/0168-5597(93)90029-O
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   TRUESWELL JC, 1994, J MEM LANG, V33, P285, DOI 10.1006/jmla.1994.1014
   Tse CY, 2007, P NATL ACAD SCI USA, V104, P17157, DOI 10.1073/pnas.0707901104
   Tse CY, 2012, J COGNITIVE NEUROSCI, V24, P1941, DOI 10.1162/jocn_a_00229
   Viswanathan N, 2009, PSYCHON B REV, V16, P74, DOI 10.3758/PBR.16.1.74
   Whalen C, 2007, HUMAN BRIAN MAPPING, V29, P1288
   Xie X, 2018, J COGNITIVE NEUROSCI, V30, P267, DOI 10.1162/jocn_a_01208
NR 64
TC 8
Z9 8
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD SEP
PY 2018
VL 184
BP 32
EP 42
DI 10.1016/j.bandl.2018.06.006
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA GR5XC
UT WOS:000442714200004
PM 29960165
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Quass, GL
   Kurt, S
   Hildebrandt, KJ
   Kral, A
AF Quass, Gunnar Lennart
   Kurt, Simone
   Hildebrandt, K. Jannis
   Kral, Andrej
TI Electrical stimulation of the midbrain excites the auditory cortex
   asymmetrically
SO BRAIN STIMULATION
LA English
DT Article
DE Inferior colliculus; Auditory midbrain implant; Current focusing;
   Neuroprosthetic stimulation; Hearing loss; Mouse
ID COCHLEAR IMPLANT PATIENTS; DEEP BRAIN-STIMULATION; INFERIOR COLLICULUS;
   ELECTRODE CONFIGURATION; GUINEA-PIG; CORTICOFUGAL MODULATION;
   EVOKED-POTENTIALS; CENTRAL NUCLEUS; ORGANIZATION; SYSTEM
AB Background: Auditory midbrain implant users cannot achieve open speech perception and have limited frequency resolution. It remains unclear whether the spread of excitation contributes to this issue and how much it can be compensated by current-focusing, which is an effective approach in cochlear implants.
   Objective: The present study examined the spread of excitation in the cortex elicited by electric midbrain stimulation. We further tested whether current-focusing via bipolar and tripolar stimulation is effective with electric midbrain stimulation and whether these modes hold any advantage over monopolar stimulation also in conditions when the stimulation electrodes are in direct contact with the target tissue.
   Methods: Using penetrating multielectrode arrays, we recorded cortical population responses to single pulse electric midbrain stimulation in 10 ketamine/xylazine anesthetized mice. We compared monopolar, bipolar, and tripolar stimulation configurations with regard to the spread of excitation and the characteristic frequency difference between the stimulation/recording electrodes.
   Results: The cortical responses were distributed asymmetrically around the characteristic frequency of the stimulated midbrain region with a strong activation in regions tuned up to one octave higher. We found no significant differences between monopolar, bipolar, and tripolar stimulation in threshold, evoked firing rate, or dynamic range.
   Conclusion: The cortical responses to electric midbrain stimulation are biased towards higher tonotopic frequencies. Current-focusing is not effective in direct contact electrical stimulation. Electrode maps should account for the asymmetrical spread of excitation when fitting auditory midbrain implants by shifting the frequency-bands downward and stimulating as dorsally as possible. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Quass, Gunnar Lennart; Kurt, Simone; Kral, Andrej] Hannover Med Sch, Inst AudioNeuroTechnol VIANNA, Dept Expt Otol, ENT Clin, D-30625 Hannover, Germany.
   [Quass, Gunnar Lennart; Kurt, Simone; Hildebrandt, K. Jannis; Kral, Andrej] Cluster Excellence Hearing4all, Hannover, Germany.
   [Hildebrandt, K. Jannis] Carl von Ossietzky Univ Oldenburg, Res Ctr Neurosensory Sci, D-26111 Oldenburg, Germany.
   [Kurt, Simone] Univ Saarland, Dept Biophys, D-66424 Homburg, Germany.
RP Quass, GL (corresponding author), Hannover Med Sch, Inst AudioNeuroTechnol VIANNA, OE8891, D-30625 Hannover, Germany.
EM quass.gunnar@mh-hannover.de
OI Hildebrandt, K Jannis/0000-0003-4455-7495; Quass,
   Gunnar/0000-0002-6408-9206; Kurt, Simone/0000-0002-1820-2597; Kral,
   Andrej/0000-0002-7762-4642
FU DFG Cluster of ExcellenceGerman Research Foundation (DFG) [EXC 1077/1]
FX This work was supported by the DFG Cluster of Excellence EXC 1077/1
   "Hearing4all". The authors thank Dr. Peter Baumhoff and Dr. Rudiger Land
   for their assistance during the experiments.
CR Allitt BJ, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/4/046008
   Asthagiri AR, 2009, LANCET, V373, P1974, DOI 10.1016/S0140-6736(09)60259-2
   Atencio CA, 2014, J NEUROPHYSIOL, V111, P1077, DOI 10.1152/jn.00749.2012
   Barnstedt O, 2015, J NEUROSCI, V35, P10927, DOI 10.1523/JNEUROSCI.0103-15.2015
   Beebe NL, 2016, J NEUROSCI, V36, P3988, DOI 10.1523/JNEUROSCI.0217-16.2016
   Berenstein CK, 2010, HEARING RES, V270, P28, DOI 10.1016/j.heares.2010.10.001
   Berger C, 2017, J COMP NEUROL, V525, P3110, DOI 10.1002/cne.24267
   BESSER GM, 1967, BRIT J PHARM CHEMOTH, V30, P329, DOI 10.1111/j.1476-5381.1967.tb02139.x
   Bierer JA, 2002, J NEUROPHYSIOL, V87, P478, DOI 10.1152/jn.00212.2001
   Bierer JA, 2007, J ACOUST SOC AM, V121, P1642, DOI 10.1121/1.2436712
   Bierer JA, 2010, TRENDS AMPLIF, V14, P84, DOI 10.1177/1084713810375249
   Calixto R, 2012, J NEUROPHYSIOL, V108, P1199, DOI 10.1152/jn.00111.2012
   Cao PJ, 2015, GRAEF ARCH CLIN EXP, V253, P2171, DOI 10.1007/s00417-015-3121-0
   Chatterjee M, 2006, JARO-J ASSOC RES OTO, V7, P15, DOI 10.1007/s10162-005-0019-2
   CLOPTON BM, 1973, BRAIN RES, V56, P355, DOI 10.1016/0006-8993(73)90352-1
   De Martino F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2379
   Delbeke J, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00663
   deSauvage RC, 1997, HEARING RES, V110, P119, DOI 10.1016/S0378-5955(97)00066-X
   Galvan A, 2017, J NEUROSCI, V37, P10894, DOI 10.1523/JNEUROSCI.1839-17.2017
   George SS, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/3/036003
   Grumet AE, 1999, THESIS
   Hayzoun K, 2007, NEUROSCI RES, V58, P378, DOI 10.1016/j.neures.2007.04.008
   Joachimsthaler B, 2014, EUR J NEUROSCI, V39, P904, DOI 10.1111/ejn.12478
   Kral A, 2000, CEREB CORTEX, V10, P714, DOI 10.1093/cercor/10.7.714
   Kral A, 1998, HEARING RES, V121, P11, DOI 10.1016/S0378-5955(98)00061-6
   Lee CC, 2010, P NATL ACAD SCI USA, V107, P372, DOI 10.1073/pnas.0907873107
   Lenarz T, 2006, OTOL NEUROTOL, V27, P838, DOI 10.1097/01.mao.0000232010.01116.e9
   LIM HH, 1989, J ACOUST SOC AM, V86, P971, DOI 10.1121/1.398732
   Lim HH, 2008, REVIEW, P149
   Lim HH, 2008, HEARING RES, V242, P74, DOI 10.1016/j.heares.2008.02.003
   Lim HH, 2007, J NEUROSCI, V27, P13541, DOI 10.1523/JNEUROSCI.3123-07.2007
   Lim HH, 2007, J NEUROSCI, V27, P8733, DOI 10.1523/JNEUROSCI.5127-06.2007
   Lim HH, 2007, J NEUROPHYSIOL, V97, P1413, DOI 10.1152/jn.00384.2006
   Lim HH, 2015, HEARING RES, V322, P212, DOI 10.1016/j.heares.2015.01.006
   Lim Hubert H, 2009, Trends Amplif, V13, P149, DOI 10.1177/1084713809348372
   Liu LF, 2006, J NEUROPHYSIOL, V95, P1926, DOI 10.1152/jn.00497.2005
   Lloyd SKW, 2017, CLIN OTOLARYNGOL, V42, P1329, DOI 10.1111/coa.12882
   MALMIERCA MS, 1995, J COMP NEUROL, V357, P124, DOI 10.1002/cne.903570112
   Merchan M, 2005, NEUROSCIENCE, V136, P907, DOI 10.1016/j.neuroscience.2004.12.030
   MERZENICH MM, 1974, BRAIN RES, V77, P397, DOI 10.1016/0006-8993(74)90630-1
   Miocinovic S, 2009, EXP NEUROL, V216, P166, DOI 10.1016/j.expneurol.2008.11.024
   MITANI A, 1985, J COMP NEUROL, V235, P417, DOI 10.1002/cne.902350402
   Moerel M, 2015, SCI REP-UK, V5, DOI 10.1038/srep17048
   MOORE JK, 1987, HEARING RES, V29, P1, DOI 10.1016/0378-5955(87)90202-4
   Neuheiser A, 2010, JARO-J ASSOC RES OTO, V11, P689, DOI 10.1007/s10162-010-0229-0
   Newbold Carrie, 2014, Cochlear Implants Int, V15, P191, DOI 10.1179/1754762813Y.0000000050
   Nogueira W, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120148
   Otto SR, 2002, J NEUROSURG, V96, P1063, DOI 10.3171/jns.2002.96.6.1063
   Pages DS, 2016, J NEUROSCI, V36, P5071, DOI 10.1523/JNEUROSCI.3540-15.2016
   Peng KA, 2018, LARYNGOSCOPE, V128, P2163, DOI 10.1002/lary.27181
   Pfingst BE, 2011, J ACOUST SOC AM, V129, P3908, DOI 10.1121/1.3583543
   Polikov VS, 2005, J NEUROSCI METH, V148, P1, DOI 10.1016/j.jneumeth.2005.08.015
   Pollak GD, 2011, HEARING RES, V274, P27, DOI 10.1016/j.heares.2010.05.010
   Portfors CV, 2011, NEUROSCIENCE, V193, P429, DOI 10.1016/j.neuroscience.2011.07.025
   Quiroga RQ, 2004, NEURAL COMPUT, V16, P1661, DOI 10.1162/089976604774201631
   RANCK JB, 1975, BRAIN RES, V98, P417, DOI 10.1016/0006-8993(75)90364-9
   Richardson RT, 2017, EXPERT OPIN BIOL TH, V17, P213, DOI 10.1080/14712598.2017.1271870
   Rode T, 2013, FRONT NEURAL CIRCUIT, V7, DOI 10.3389/fncir.2013.00166
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Saldana E, 1996, J COMP NEUROL, V371, P15, DOI 10.1002/(SICI)1096-9861(19960715)371:1<15::AID-CNE2>3.0.CO;2-O
   Sanna M, 2012, OTOL NEUROTOL, V33, P154, DOI 10.1097/MAO.0b013e318241bc71
   Saoji AA, 2010, EAR HEARING, V31, P693, DOI 10.1097/AUD.0b013e3181e1d15e
   Schierholz I, 2017, HUM BRAIN MAPP, V38, P2206, DOI 10.1002/hbm.23515
   Schmidt C, 2012, IEEE T BIO-MED ENG, V59, P1583, DOI 10.1109/TBME.2012.2189885
   SCHREINER CE, 1988, J NEUROPHYSIOL, V60, P1823
   Schreiner CE, 1997, NATURE, V388, P383, DOI 10.1038/41106
   Snyder RL, 2008, HEARING RES, V235, P23, DOI 10.1016/j.heares.2007.09.013
   STEINSCHNEIDER M, 1992, ELECTROEN CLIN NEURO, V84, P196, DOI 10.1016/0168-5597(92)90026-8
   Stiebler I, 1985, TONE THRESHOLD DISTR, V76, P65
   Straka MM, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/4/046021
   Straka MM, 2013, J NEUROPHYSIOL, V110, P1009, DOI 10.1152/jn.00022.2013
   van den Honert C, 2007, J ACOUST SOC AM, V121, P3703, DOI 10.1121/1.2722047
   WINER JA, 1995, J COMP NEUROL, V355, P317, DOI 10.1002/cne.903550302
   Yan J, 2002, EUR J NEUROSCI, V16, P119, DOI 10.1046/j.1460-9568.2002.02046.x
   Yan W, 1998, NAT NEUROSCI, V1, P54, DOI 10.1038/255
   Yazdan-Shahmorad A, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/4/046018
   Yousif N, 2007, EXPERT REV MED DEVIC, V4, P623, DOI 10.1586/17434440.4.5.623
   Yu X, 2005, NAT NEUROSCI, V8, P961, DOI 10.1038/nn1477
NR 78
TC 0
Z9 0
U1 0
U2 4
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 1935-861X
EI 1876-4754
J9 BRAIN STIMUL
JI Brain Stimul.
PD SEP-OCT
PY 2018
VL 11
IS 5
BP 1161
EP 1174
DI 10.1016/j.brs.2018.05.009
PG 14
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA GR2QP
UT WOS:000442423400024
PM 29853311
DA 2021-02-24
ER

PT J
AU Majorano, M
   Maes, M
   Morelli, M
   Bastianello, T
   Guerzoni, L
   Murri, A
   Cuda, D
AF Majorano, Marinella
   Maes, Marlies
   Morelli, Marika
   Bastianello, Tamara
   Guerzoni, Letizia
   Murri, Alessandra
   Cuda, Domenico
TI Socio-emotional adjustment of adolescents with cochlear implants:
   Loneliness, emotional autonomy, self-concept, and emotional experience
   at the hospital
SO JOURNAL OF CHILD HEALTH CARE
LA English
DT Article
DE Adolescents; cochlear implants; emotional experience at the hospital;
   loneliness; self-concept; well-being
ID SPEECH-PERCEPTION; HEARING PEOPLE; CHILDREN; LIFE; DEAF; AGE;
   PERFORMANCE; LANGUAGE; IDENTITY; QUALITY
AB Recent studies have reported contrasting results in the socio-emotional adjustment of Italian adolescents with cochlear implants (CIs). The aim of the present study is to explore the relationship between the socio-emotional adjustment of adolescents with CIs, the quality of their hospital stay, and their age at CI activation. The participants were 29 adolescents with CIs (CI group) and 29 typically developing adolescents (TD group). The Emotional Autonomy Scale, the Loneliness and Aloneness Scale for Children and Adolescents, and the Multidimensional Self-Concept Scale were administered to each participant. The emotional experience reported during the hospital stay was considered for each participant in the CI group. The adolescents with CIs displayed significantly higher levels of loneliness and lower levels of aversion toward aloneness than the TD group participants. Adolescents who had received the CI in preschool displayed a higher level of physical self-concept than adolescents who had received it later. The adolescents' emotional experiences at the hospital were reported to be quite complex and related to their relationships with parents. In summary, the findings point to a specific type of fragility in socio-emotional adjustmentfocused on loneliness/alonenessrather than a general one.
C1 [Majorano, Marinella; Morelli, Marika; Bastianello, Tamara] Univ Verona, Dept Human Sci, Via S Francesco 22, I-37129 Verona, Italy.
   [Maes, Marlies] Katholieke Univ Leuven, Sch Psychol & Dev, Leuven, Belgium.
   [Guerzoni, Letizia; Murri, Alessandra; Cuda, Domenico] Guglielmo da Saliceto Hosp, Emilia Romagna, Italy.
RP Majorano, M (corresponding author), Univ Verona, Dept Human Sci, Via S Francesco 22, I-37129 Verona, Italy.
EM marinella.majorano@univr.it
RI Maes, Marlies/I-6822-2018; murri, alessandra/M-4104-2019
OI Maes, Marlies/0000-0002-1710-5728; murri, alessandra/0000-0002-5958-8086
CR Bailly D, 2003, ENCEPHALE, V29, P329
   Bat-Chava Y, 2014, CHILD CARE HLTH DEV, V40, P870, DOI 10.1111/cch.12102
   Bergamini L, 2003, TEST TMA VALUTAZIONE, P91
   Beyers W, 2005, EUR J PSYCHOL ASSESS, V21, P147, DOI 10.1027/1015-5759.21.3.147
   Blos P., 1979, ADOLESCENCE PASSAGE
   Bracken BA., 1992, MULTIDIMENSIONAL SEL
   Cacioppo S, 2015, PERSPECT PSYCHOL SCI, V10, P238, DOI 10.1177/1745691615570616
   Carney Terri, 2003, J Child Health Care, V7, P27, DOI 10.1177/1367493503007001674
   Celli C, 2014, AUDIOLOGIA PROTESICA, P299
   Corsano P, 2015, CHILD CARE HLTH DEV, V41, P1066, DOI 10.1111/cch.12239
   Corsano P, 2012, J CHILD HEALTH CARE, V1, P1
   Corsano P, 2006, ADOLESCENCE, V41, P341
   Coyne I, 2012, J CHILD HEALTH CARE, V16, P293, DOI 10.1177/1367493512443905
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Faber CE, 2000, ACTA OTO-LARYNGOL, P151, DOI 10.1080/000164800454251
   Goossens L, 2009, PERS INDIV DIFFER, V47, P890, DOI 10.1016/j.paid.2009.07.011
   Hintermair M, 2008, J DEAF STUD DEAF EDU, V13, P278, DOI 10.1093/deafed/enm054
   Kouwenberg M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052174
   Laursen B, 1997, INT J BEHAV DEV, V21, P747, DOI 10.1080/016502597384659
   Le Maner-Idrissi G, 2008, DEV MED CHILD NEUROL, V50, P796, DOI 10.1111/j.1469-8749.2008.03054.x
   Leigh IW, 2009, J DEAF STUD DEAF EDU, V14, P244, DOI 10.1093/deafed/enn038
   Maes M, 2017, J PEDIATR PSYCHOL, V42, P622, DOI 10.1093/jpepsy/jsx046
   Maes M, 2016, J YOUTH ADOLESCENCE, V45, P547, DOI 10.1007/s10964-015-0354-5
   Majorano M, 2017, J CHILD FAM STUD, V26, P690, DOI 10.1007/s10826-016-0591-6
   Majorano M, 2015, J CHILD FAM STUD, V24, P3436, DOI 10.1007/s10826-015-0145-3
   Mance Jennifer, 2012, Cochlear Implants Int, V13, P93, DOI 10.1179/1754762811Y.0000000017
   MARCOEN A, 1987, J YOUTH ADOLESCENCE, V16, P561, DOI 10.1007/BF02138821
   Meleddu M., 2002, B PSICOLOGIA APPL, V238, P43
   Melotti G., 2006, APPL PSYCHOL, V13, P237
   Moog Jean S, 2011, Ear Hear, V32, p75S, DOI 10.1097/AUD.0b013e3182014c76
   Most T, 2012, J DEAF STUD DEAF EDU, V17, P259, DOI 10.1093/deafed/enr049
   Musetti A, 2012, INT J PSYCHOANAL, V4, P43
   Preisler G, 2002, CHILD CARE HLTH DEV, V28, P403, DOI 10.1046/j.1365-2214.2002.00291.x
   Qualter P, 2015, PERSPECT PSYCHOL SCI, V10, P250, DOI 10.1177/1745691615568999
   Rich S, 2013, INT J PEDIATR OTORHI, V77, P1337, DOI 10.1016/j.ijporl.2013.05.029
   STEINBERG L, 1986, CHILD DEV, V57, P841, DOI 10.2307/1130361
   Szagun G, 2016, J CHILD LANG, V43, P505, DOI 10.1017/S0305000915000641
   Theunissen SCPM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094521
   Tomassini R, 1999, ECHI DAL SILENZIO AD
   Tomblin JB, 2008, J SPEECH LANG HEAR R, V51, P1353, DOI 10.1044/1092-4388(2008/07-0083)
   Vallarino MV, 2014, AUDIOLOGIA PROTESICA, P681
   Vanhalst J, 2012, J PSYCHOL, V146, P259, DOI 10.1080/00223980.2011.555433
   Warner-Czyz AD, 2015, TRENDS HEAR, V19, DOI 10.1177/2331216515572615
   Yu GL, 2005, PSYCHOL SCHOOLS, V42, P325, DOI 10.1002/pits.20083
   Yucel E, 2007, INT J PEDIATR OTORHI, V71, P1415, DOI 10.1016/j.ijporl.2007.05.015
   Zwolan TA, 2004, OTOL NEUROTOL, V25, P112, DOI 10.1097/00129492-200403000-00006
NR 46
TC 1
Z9 1
U1 0
U2 8
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1367-4935
EI 1741-2889
J9 J CHILD HEALTH CARE
JI J. Child Health Care
PD SEP
PY 2018
VL 22
IS 3
BP 359
EP 370
DI 10.1177/1367493518757065
PG 12
WC Nursing; Pediatrics
SC Nursing; Pediatrics
GA GR2IF
UT WOS:000442390000005
PM 29400078
DA 2021-02-24
ER

PT J
AU van de Ven, M
   Ernestus, M
AF van de Ven, Marco
   Ernestus, Mirjam
TI The role of segmental and durational cues in the processing of reduced
   words
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Acoustic reduction; word recognition; speech perception; gating;
   phonetic detail
ID RECOGNITION; SPEECH; CONSTRAINTS; CONTEXT; VOWELS; IDENTIFICATION;
   CONSONANTS; DELETION
AB In natural conversations, words are generally shorter and they often lack segments. It is unclear to what extent such durational and segmental reductions affect word recognition. The present study investigates to what extent reduction in the initial syllable hinders word comprehension, which types of segments listeners mostly rely on, and whether listeners use word duration as a cue in word recognition. We conducted three experiments in Dutch, in which we adapted the gating paradigm to study the comprehension of spontaneously uttered conversational speech by aligning the gates with the edges of consonant clusters or vowels. Participants heard the context and some segmental and/or durational information from reduced target words with unstressed initial syllables. The initial syllable varied in its degree of reduction, and in half of the stimuli the vowel was not clearly present. Participants gave too short answers if they were only provided with durational information from the target words, which shows that listeners are unaware of the reductions that can occur in spontaneous speech. More importantly, listeners required fewer segments to recognize target words if the vowel in the initial syllable was absent. This result strongly suggests that this vowel hardly plays a role in word comprehension, and that its presence may even delay this process. More important are the consonants and the stressed vowel.
C1 [van de Ven, Marco; Ernestus, Mirjam] Radboud Univ Nijmegen, Ctr Language Studies, POB 9104, NL-6500 HD Nijmegen, Netherlands.
   [van de Ven, Marco; Ernestus, Mirjam] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
RP van de Ven, M (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, POB 9104, NL-6500 HD Nijmegen, Netherlands.
EM Marco.vandeVen@pwo.ru.nl
RI Ernestus, Mirjam/E-4344-2010
CR BARD EG, 1988, PERCEPT PSYCHOPHYS, V44, P395, DOI 10.3758/BF03210424
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Brouwer S, 2012, Q J EXP PSYCHOL, V65, P2193, DOI 10.1080/17470218.2012.693109
   Bruno JL, 2007, J EXP CHILD PSYCHOL, V97, P183, DOI 10.1016/j.jecp.2007.01.005
   Cutler A, 1999, J ACOUST SOC AM, V105, P1877, DOI 10.1121/1.426724
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Drijvers L, 2016, BRAIN LANG, V153, P27, DOI 10.1016/j.bandl.2016.01.003
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   ERNESTUS M, 2000, VOICE ASSIMILATION S
   Ernestus M, 2011, J PHONETICS, V39, P253, DOI 10.1016/S0095-4470(11)00055-6
   Ernestus M, 2007, LANG COGNITIVE PROC, V22, P1, DOI 10.1080/01690960500268303
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Grosjean F, 1996, LANG COGNITIVE PROC, V11, P597, DOI 10.1080/016909696386999
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Janse E, 2011, J PHONETICS, V39, P330, DOI 10.1016/j.wocn.2011.03.005
   Johnson K, 2004, SPONTANEOUS SPEECH D, P29
   Kemps R, 2004, BRAIN LANG, V90, P117, DOI 10.1016/S0093-934X(03)00425-5
   Manuel S. Y., 1992, J ACOUST SOC AM, V91, P2388
   Mehler J, 2006, CORTEX, V42, P846, DOI 10.1016/S0010-9452(08)70427-1
   Nieuwland MS, 2006, J COGNITIVE NEUROSCI, V18, P1098, DOI 10.1162/jocn.2006.18.7.1098
   NOOTEBOOM SG, 1980, J ACOUST SOC AM, V67, P276, DOI 10.1121/1.383737
   Oostdijk N, 2002, LANG COMPUT, P105
   POLLACK I, 1964, J VERB LEARN VERB BE, V3, P79, DOI 10.1016/S0022-5371(64)80062-1
   POLS LCW, 1978, J ACOUST SOC AM, V64, P1333, DOI 10.1121/1.382100
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Schneider W., 2002, E PRIME USERS GUIDE
   Schuppler B, 2011, J PHONETICS, V39, P96, DOI 10.1016/j.wocn.2010.11.006
   Spinelli E, 2007, COGNITION, V104, P397, DOI 10.1016/j.cognition.2006.07.002
   Tucker BV, 2011, J PHONETICS, V39, P312, DOI 10.1016/j.wocn.2010.12.001
   TYLER LK, 1985, PERCEPT PSYCHOPHYS, V38, P217, DOI 10.3758/BF03207148
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   VAN DE VELDE HANS, 1996, LANG VAR CHANGE, V8, P149, DOI DOI 10.1017/S0954394500001125
   Van De Ven M., 2012, LAB PHONOLOGY, V3, P455, DOI [10.1515/lp-2012-0020, DOI 10.1515/LP-2012-0020]
   van de Ven M, 2011, MEM COGNITION, V39, P1301, DOI 10.3758/s13421-011-0103-2
   VANPETTEN C, 1990, MEM COGNITION, V18, P380, DOI 10.3758/BF03197127
   Warner N., 2007, P 16 INT C PHON SCI, P1949
   Warner N., 1998, THESIS
   Wurm LH, 2014, J MEM LANG, V72, P37, DOI 10.1016/j.jml.2013.12.003
   Zimmerer F, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00735
   Zimmerer F, 2014, J PHONETICS, V45, P64, DOI 10.1016/j.wocn.2014.03.006
   Zimmerer F, 2011, SPEECH COMMUN, V53, P941, DOI 10.1016/j.specom.2011.03.006
NR 44
TC 2
Z9 2
U1 0
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD SEP
PY 2018
VL 61
IS 3
BP 358
EP 383
DI 10.1177/0023830917727774
PG 26
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA GQ7PR
UT WOS:000441937100002
PM 28870139
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Faris, MM
   Best, CT
   Tyler, MD
AF Faris, Mona M.
   Best, Catherine T.
   Tyler, Michael D.
TI Discrimination of uncategorised non-native vowel contrasts is modulated
   by perceived overlap with native phonological categories
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Cross-language speech perception; Perceptual assimilation; Uncategorised
   assimilations; Perceived phonological overlap; Discrimination accuracy;
   Vowels
ID AMERICAN ENGLISH VOWELS; PERCEPTUAL ASSIMILATION; LISTENERS PERCEPTION;
   SPEECH-PERCEPTION; SPANISH LISTENERS; BRITISH ENGLISH; 2ND-LANGUAGE;
   LEARNERS; ADULTS; EXPERIENCE
AB Non-native vowels perceived as speech-like but not identified with a particular native (L1) vowel are assimilated as uncategorised, and have received very little empirical attention. According to the Perceptual Assimilation Model (PAM: Best, 1995), contrasts where one or both phones are uncategorised are Uncategorised-Categorised and Uncategorised-Uncategorised, respectively. We reasoned that discrimination accuracy for these assimilations should be influenced by perceived phonological overlap (i.e., overlap in the categorisations to L1 vowels), and predicted excellent discrimination for non-overlapping contrasts, followed by partially overlapping, and completely overlapping contrasts. To test those predictions, Australian English speakers discriminated between Danish monophthongal and diphthongal vowel contrasts that formed Uncategorised-Categorised and Uncategorised-Uncategorised assimilations, varying in the presence of overlap, in addition to Two-Category and Single-Category contrasts. The discrimination accuracy results supported our predictions. These findings have implications for PAM, and broader relevance to second-language learning models, as they allow for more precise discrimination predictions to be made based on assimilation type. (c) 2018 The Authors. Published by Elsevier Ltd.
C1 [Faris, Mona M.; Best, Catherine T.] Univ Western Sydney, MARCS Inst Brain Behav & Dev, Locked Bag 1797, Penrith, NSW 2751, Australia.
   [Tyler, Michael D.] Univ Western Sydney, Sch Social Sci & Psychol, Bankstown Campus,Locked Bag 1797, Penrith, NSW 2751, Australia.
RP Faris, MM (corresponding author), Univ Western Sydney, MARCS Inst Brain Behav & Dev, Locked Bag 1797, Penrith, NSW 2751, Australia.
EM m.faris@westernsydney.edu.au; c.best@westernsydney.edu.au;
   m.tyler@westemsydney.edu.au
RI Best, Catherine T/M-4547-2019; Tyler, Michael/B-2399-2013
OI Best, Catherine T/0000-0002-2447-2024; Faris, Mona/0000-0001-7707-1331;
   Tyler, Michael/0000-0003-1642-7941
CR Antoniou M, 2013, J ACOUST SOC AM, V133, P2397, DOI 10.1121/1.4792358
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T, 2007, LANGUAGE EXPERIENCE, DOI [10.1121/1.1332378, DOI 10.1121/1.1332378]
   Best C. T., 1994, DEV SPEECH PERCEPTIO, P167
   Best C. T, 2015, P 18 INT C PHON SCI
   Best CT, 2016, ECOL PSYCHOL, V28, P216, DOI 10.1080/10407413.2016.1230372
   Best CT, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1932
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Boersma P., 2005, PRAAT DOING PHONETIC
   Bohn O.-S, 2011, P 17 INT C PHON SCI, P336
   Bonatti L. L, PSYSCOPE 10 BUILD 57
   Bundgaard-Nielsen R. L, 2008, P INTERSPEECH 2008, P1177
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   Bundgaard-Nielsen RL, 2011, APPL PSYCHOLINGUIST, V32, P51, DOI 10.1017/S0142716410000287
   Cafford J. C, 2001, PRACTICAL INTRO PHON
   Cebrian J., 2010, P 6 INT S ACQ 2 LANG, P77
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   Cox F., 2007, J INT PHON ASSOC, V37, P341, DOI [10.1017/S0025100307003192, DOI 10.1017/S0025100307003192]
   Escudero P, 2011, J ACOUST SOC AM, V129, pEL1, DOI 10.1121/1.3525042
   Escudero P, 2010, J ACOUST SOC AM, V128, pEL254, DOI 10.1121/1.3488794
   Evans BG, 2018, J PHONETICS, V68, P15, DOI 10.1016/j.wocn.2018.01.002
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   GRONNUM N, 1998, J INT PHON ASSOC, V28, P99, DOI DOI 10.1017/S0025100300006290
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Halle PA, 1999, J PHONETICS, V27, P281, DOI 10.1006/jpho.1999.0097
   Harnsberger JD, 2001, J ACOUST SOC AM, V110, P489, DOI 10.1121/1.1371758
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Hojen A, 2006, J ACOUST SOC AM, V119, P3072, DOI 10.1121/1.2184289
   Kim D, 2018, J PHONETICS, V67, P1, DOI 10.1016/j.wocn.2017.11.003
   Ladefoged P, 2005, VOWELS CONSONANTS
   Levy ES, 2009, J ACOUST SOC AM, V126, P2670, DOI 10.1121/1.3224715
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   Patel TK, 2004, J EDUC PSYCHOL, V96, P785, DOI 10.1037/0022-0663.96.4.785
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   Fabra LR, 2012, J PHONETICS, V40, P491, DOI 10.1016/j.wocn.2012.01.001
   Sisinni B, 2009, P 10 ANN C INT SPEEC, P1679
   Strange W, 1998, J PHONETICS, V26, P311, DOI 10.1006/jpho.1998.0078
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, V36, P153, DOI DOI 10.1075/SIBIL.36.09STR
   Strange W, 2007, J ACOUST SOC AM, V122, P1111, DOI 10.1121/1.2749716
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
NR 48
TC 7
Z9 7
U1 1
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD SEP
PY 2018
VL 70
BP 1
EP 19
DI 10.1016/j.wocn.2018.05.003
PG 19
WC Linguistics; Language & Linguistics
SC Linguistics
GA GQ2JW
UT WOS:000441482300001
OA Other Gold
DA 2021-02-24
ER

PT J
AU Archer, SL
   Curtin, S
AF Archer, Stephanie L.
   Curtin, Suzanne
TI Fourteen-month-olds' sensitivity to acoustic salience in minimal pair
   word learning
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE First Language Acquisition; Word Learning; Speech Perception
ID SPEECH-PERCEPTION; PHONETIC DETAIL; INFANTS; ACQUISITION; CONTRASTS;
   CUES; REPRESENTATIONS; DISCRIMINATION; PHONOTACTICS; INFORMATION
AB During the first two years of life, infants concurrently refine native-language speech categories and word learning skills. However, in the Switch Task, 14-month-olds do not detect minimal contrasts in a novel object-word pairing (Stager & Werker, 1997). We investigate whether presenting infants with acoustically salient contrasts (liquids) facilitates success in the Switch Task. The first two experiments demonstrate that acoustic differences boost infants' detection of contrasts. However, infants cannot detect the contrast when the segments are digitally shortened. Thus, not all minimal contrasts are equally difficult, and the acoustic properties of a contrast matter in word learning.
C1 [Archer, Stephanie L.] Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
   [Curtin, Suzanne] Univ Calgary, Dept Psychol, Calgary, AB, Canada.
RP Archer, SL (corresponding author), Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
EM slarcher@ualberta.ca
OI Curtin, Suzanne/0000-0003-1509-7960
FU Social Sciences and Humanities Research Council of Canada (SSHRC)Social
   Sciences and Humanities Research Council of Canada (SSHRC)
FX This research was supported by a Social Sciences and Humanities Research
   Council of Canada (SSHRC) grant awarded to S. Curtin. We would like to
   thank Heather MacKenzie, Jennifer Ference, Erin Dodd, Melanie Khu,
   Jennifer Campbell, Patrick Mihalicz, the volunteer coders, and baby
   sitters at the Speech Development lab. We also thank the parents and
   infants who took part in our study.
CR Archer S, 2014, J COGN DEV, V15, P110, DOI 10.1080/15248372.2012.728544
   Archer SL, 2016, LANG LEARN DEV, V12, P60, DOI 10.1080/15475441.2014.979490
   Boersma P., 2010, PRAAT SYSTEM DOING P
   Cohen L. B., 2004, HABIT 10 NEW PROGRAM
   Curtin S, 2011, J CHILD LANG, V38, P904, DOI 10.1017/S0305000910000097
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Curtin S, 2009, DEVELOPMENTAL SCI, V12, P725, DOI 10.1111/j.1467-7687.2009.00814.x
   DELATTRE PC, 1955, J ACOUST SOC AM, V27, P769, DOI 10.1121/1.1908024
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Hollich G, 2002, PROC ANN BUCLD, P314
   Hollich G, 2005, SUPERCODER PROGRAM C
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lacerda F, 1994, J ACOUST SOC AM, V95, P3016
   Lacerda F., 1993, J ACOUST SOC AM, V93, P2372, DOI [DOI 10.1121/1.406120, 10.1121/1.406120]
   MacKenzie H, 2012, CHILD DEV, V83, P1129, DOI 10.1111/j.1467-8624.2012.01764.x
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P249, DOI 10.1111/j.1467-7687.2010.00975.x
   MacKenzie HK, 2014, DEV PSYCHOL, V50, P422, DOI 10.1037/a0033524
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Storkel HL, 2000, CLIN LINGUIST PHONET, V14, P407
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Thiessen ED, 2010, CHILD DEV, V81, P1287, DOI 10.1111/j.1467-8624.2010.01468.x
   Wang YY, 2015, LANG LEARN DEV, V11, P1, DOI 10.1080/15475441.2013.876270
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
   Zamuner TS, 2006, INFANCY, V10, P77, DOI 10.1207/s15327078in1001_5
NR 34
TC 3
Z9 3
U1 1
U2 4
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD SEP
PY 2018
VL 45
IS 5
BP 1198
EP 1211
DI 10.1017/S0305000917000617
PG 14
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA GP4RM
UT WOS:000440856900008
PM 29465335
DA 2021-02-24
ER

PT J
AU Sundara, M
   Ngon, C
   Skoruppa, K
   Feldman, NH
   Onario, GM
   Morgan, JL
   Peperkamp, S
AF Sundara, Megha
   Ngon, Celine
   Skoruppa, Katrin
   Feldman, Naomi H.
   Onario, Glenda Molina
   Morgan, James L.
   Peperkamp, Sharon
TI Young infants' discrimination of subtle phonetic contrasts
SO COGNITION
LA English
DT Article
DE Infant; Speech perception; Discrimination; Tamil; Filipino; English;
   French
ID NONNATIVE SPEECH CONTRASTS; LANGUAGE-EXPERIENCE; PERCEPTUAL
   REORGANIZATION; NASAL CONSONANTS; ADULTS; EXPOSURE; PLACE; TAMIL; CUES
AB It is generally accepted that infants initially discriminate native and non-native contrasts and that perceptual reorganization within the first year of life results in decreased discrimination of non-native contrasts, and improved discrimination of native contrasts. However, recent findings from Narayan, Werker, and Beddor (2010) surprisingly suggested that some acoustically subtle native-language contrasts might not be discriminated until the end of the first year of life. We first provide countervailing evidence that young English-learning infants can discriminate the Filipino contrast tested by Narayan et al. when tested in a more sensitive paradigm. Next, we show that young infants learning either English or French can also discriminate comparably subtle non-native contrasts from Tamil. These findings show that Narayan et al.'s null findings were due to methodological choices and indicate that young infants are sensitive to even subtle acoustic contrasts that cue phonetic distinctions cross-linguistically. Based on experimental results and acoustic analyses, we argue that instead of specific acoustic metrics, infant discrimination results themselves are the most informative about the salience of phonetic distinctions.
C1 [Sundara, Megha] Univ Calif Los Angeles, Dept Linguist, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
   [Ngon, Celine; Peperkamp, Sharon] PSL Res Univ, Lab Sci Cognit & Psycholinguist, CNRS, Dept Etud Cognit,EHESS,ENS, Paris, France.
   [Skoruppa, Katrin] Univ Neuchatel, Inst Language Sci & Commun, Neuchatel, Switzerland.
   [Feldman, Naomi H.] Univ Maryland, Dept Linguist, College Pk, MD USA.
   [Feldman, Naomi H.] Univ Maryland, UMIACS, College Pk, MD USA.
   [Onario, Glenda Molina; Morgan, James L.] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI USA.
   [Peperkamp, Sharon] Maternite Port Royal, AP HP, Paris, France.
RP Sundara, M (corresponding author), Univ Calif Los Angeles, Dept Linguist, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
EM megha.sundara@humnet.ucla.edu
RI peperkamp, sharon/V-6994-2017; Morgan, James L/A-9494-2012
OI peperkamp, sharon/0000-0001-5985-8878; Feldman,
   Naomi/0000-0001-9988-7497; Skoruppa, Katrin/0000-0002-5675-5993
FU NSFNational Science Foundation (NSF) [BCS-0951639, BCS-1320410]; Brown
   University Brain Science Program Fellowship; NIHUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USA
   [RO1-HD32005];  [ANR-10-LABX-0087];  [ANR-10-IDEX-0001-02]; 
   [ANR-13-APPR-0012]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH &HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD032005, R01HD032005, R01HD032005, R01HD032005, R01HD032005,
   R01HD032005, R01HD032005, R01HD032005, R01HD032005, R01HD032005,
   R01HD032005, R01HD032005] Funding Source: NIH RePORTER
FX We would like to thank Megan Blossom, Anne-Caroline Fievet, Robin
   Orfitelli and Lori Rolfe for help with infant recruitment and data
   collection; Caitlin Richter, Chijioke Okonkwo and Alexander Shushunov
   for testing adults; and Henry Tehrani for generating the MFCCs and PLPs.
   This research was supported by: NSF BCS-0951639 to MS; a Brown
   University Brain Science Program Fellowship and NSF BCS-1320410 to NHF;
   NIH RO1-HD32005 to JLM; ANR-10-LABX-0087 IEC; ANR-10-IDEX-0001-02 PSL*;
   and ANR-13-APPR-0012. Finally, we would like to thank Chandan Narayan
   for generously sharing his Filipino stimuli with us.
CR Anderson JL, 2003, LANG SPEECH, V46, P155, DOI 10.1177/00238309030460020601
   Aslin R. N., 1980, CHILD PHONOLOGY, V2, P67
   ASLIN RN, 1981, CHILD DEV, V52, P1135, DOI 10.1111/j.1467-8624.1981.tb03159.x
   Aslin RN, 2002, J ACOUST SOC AM, V112, P1257, DOI 10.1121/1.1501904
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beddor PS, 2009, LANGUAGE, V85, P785
   BERANEK LL, 1949, ACOUSTIC MEASUREMENT
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   BEST CT, 1995, ADV INFANCY RES, V9, P217
   BURNHAM DK, 1986, APPL PSYCHOLINGUIST, V7, P207, DOI 10.1017/S0142716400007542
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Cohen J, 1995, J ACOUST SOC AM, V97, P3246
   Cohen L.B, 2004, HABIT X NEW PROGRAM
   Dart S, 1991, UCLA WORKING PAPERS, V79
   Dart S. N., 1999, J INT PHON ASSOC, V29, P129
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Disner S, 1984, CAMBRIDGE STUDIES SP
   EILERS RE, 1977, J SPEECH HEAR RES, V20, P766, DOI 10.1044/jshr.2004.766
   EILERS RE, 1979, CHILD DEV, V50, P14
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   EIMAS PD, 1975, PERCEPT PSYCHOPHYS, V18, P341, DOI 10.3758/BF03211210
   EIMAS PD, 1974, PERCEPT PSYCHOPHYS, V16, P513, DOI 10.3758/BF03198580
   FANTZ RL, 1964, SCIENCE, V146, P668, DOI 10.1126/science.146.3644.668
   FANTZ RL, 1958, PSYCHOL REC, V8, P43, DOI 10.1007/BF03393306
   Feldman NH, 2013, COGNITION, V127, P427, DOI 10.1016/j.cognition.2013.02.007
   Hamann Silke, 2003, THESIS
   Harnsberger JD, 2001, J PHONETICS, V29, P303, DOI 10.1006/jpho.2001.0140
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Johnson K., 1997, J INT PHON ASSOC, V27, P1, DOI DOI 10.1017/S0025100300005387
   Jusczyk P. W., 1981, PERSPECTIVES STUDY S, P113
   JUSCZYK P. W., 1997, DISCOVERY SPOKEN LAN
   Kuhl P. K., 1998, J ACOUST SOC AM, V103, P2931, DOI DOI 10.1121/1.422159
   Kuhl P. K., 1985, MEASUREMENT AUDITION
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   LADEFOGED P, 1983, J PHONETICS, V11, P291, DOI 10.1016/S0095-4470(19)30828-9
   Lefcheck JS, 2016, METHODS ECOL EVOL, V7, P573, DOI 10.1111/2041-210X.12512
   LEVITT A, 1988, J EXP PSYCHOL HUMAN, V14, P361
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Mazuka R, 2014, DEV PSYCHOBIOL, V56, P192, DOI 10.1002/dev.21193
   Meints K., 2008, LINCOLN INFANT LAB P
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Narayanan S, 1999, J ACOUST SOC AM, V106, P1993, DOI 10.1121/1.427946
   Park AS, 2008, IEEE T AUDIO SPEECH, V16, P186, DOI 10.1109/TASL.2007.909282
   POLKA L, 1992, PERCEPT PSYCHOPHYS, V52, P37, DOI 10.3758/BF03206758
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   Rajaram S., 2000, TAMIL PHONETIC READE
   RAMASUBRAMANIAN N, 1971, LANG SPEECH, V14, P65, DOI 10.1177/002383097101400108
   Richter C., 2017, T ASS COMPUTATIONAL, V5, P425
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   STREETER LA, 1976, NATURE, V259, P39, DOI 10.1038/259039a0
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   Sundara M, 2011, J PHONETICS, V39, P505, DOI 10.1016/j.wocn.2010.08.006
   Tabain M, 2016, J ACOUST SOC AM, V139, P890, DOI 10.1121/1.4941659
   Tabain M, 2016, J ACOUST SOC AM, V139, P361, DOI 10.1121/1.4937751
   TREHUB SE, 1976, CHILD DEV, V47, P466, DOI 10.2307/1128803
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Tsushima T., 1994, EMERGENCE HUMAN COGN, V3, P57
   Werker J. F., 1998, PERCEPTUAL DEV VISUA, P389
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Werker JF, 1997, EARLY DEV PARENTING, V6, P171, DOI 10.1002/(SICI)1099-0917(199709/12)6:3/4<171::AID-EDP156>3.3.CO;2-8
NR 70
TC 5
Z9 5
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD SEP
PY 2018
VL 178
BP 57
EP 66
DI 10.1016/j.cognition.2018.05.009
PG 10
WC Psychology, Experimental
SC Psychology
GA GN8IF
UT WOS:000439402400006
PM 29777983
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Fisher, JM
   Dick, FK
   Levy, DF
   Wilson, SM
AF Fisher, Julia M.
   Dick, Frederic K.
   Levy, Deborah F.
   Wilson, Stephen M.
TI Neural representation of vowel formants in tonotopic auditory cortex
SO NEUROIMAGE
LA English
DT Article
DE Vowels; Formants; Tonotopy; Auditory cortex
ID ORDERLY CORTICAL REPRESENTATION; STEADY-STATE VOWELS; PHONOLOGICAL
   FEATURES; SPEECH-PERCEPTION; NATURAL SOUNDS; ORGANIZATION; EXTRACTION;
   CATEGORIES; ATTENTION; IDENTITY
AB Speech sounds are encoded by distributed patterns of activity in bilateral superior temporal cortex. However, it is unclear whether speech sounds are topographically represented in cortex, or which acoustic or phonetic dimensions might be spatially mapped. Here, using functional MRI, we investigated the potential spatial representation of vowels, which are largely distinguished from one another by the frequencies of their first and second formants, i.e. peaks in their frequency spectra. This allowed us to generate clear hypotheses about the representation of specific vowels in tonotopic regions of auditory cortex. We scanned participants as they listened to multiple natural tokens of the vowels [a] and [i], which we selected because their first and second formants overlap minimally. Formant-based regions of interest were defined for each vowel based on spectral analysis of the vowel stimuli and independently acquired tonotopic maps for each participant. We found that perception of [a] and [i] yielded differential activation of tonotopic regions corresponding to formants of [a] and [i], such that each vowel was associated with increased signal in tonotopic regions corresponding to its own formants. This pattern was observed in Heschl's gyrus and the superior temporal gyrus, in both hemispheres, and for both the first and second formants. Using linear discriminant analysis of mean signal change in formant-based regions of interest, the identity of untrained vowels was predicted with similar to 73% accuracy. Our findings show that cortical encoding of vowels is scaffolded on tonotopy, a fundamental organizing principle of auditory cortex that is not language-specific.
C1 [Fisher, Julia M.] Univ Arizona, Dept Linguist, Tucson, AZ USA.
   [Fisher, Julia M.] Univ Arizona, Stat Consulting Lab, Inst BIO5, Tucson, AZ USA.
   [Dick, Frederic K.] Univ London, Birkbeck Coll, Dept Psychol Sci, London, England.
   [Dick, Frederic K.] Birkbeck UCL Ctr Neuroimaging, London, England.
   [Dick, Frederic K.] UCL, Dept Expt Psychol, London, England.
   [Levy, Deborah F.; Wilson, Stephen M.] Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, 1215 21st Ave S,MCE 8310, Nashville, TN 37232 USA.
RP Wilson, SM (corresponding author), Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, 1215 21st Ave S,MCE 8310, Nashville, TN 37232 USA.
EM stephen.m.wilson@vanderbilt.edu
OI Wilson, Stephen/0000-0001-9884-2852; Dick, Frederic/0000-0002-2933-3912;
   Levy, Deborah/0000-0002-1389-2525
FU National Institute on Deafness and Other Communication Disorders at the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01 DC013270];
   National Science FoundationNational Science Foundation (NSF)
   [DGE-1746060]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC013270, R01DC013270,
   R01DC013270, R01DC013270, R01DC013270] Funding Source: NIH RePORTER
FX This research was supported in part by the National Institute on
   Deafness and Other Communication Disorders at the National Institutes of
   Health (grant number R01 DC013270) and the National Science Foundation
   (grant number DGE-1746060).
CR Allen EJ, 2018, NEUROIMAGE, V166, P60, DOI 10.1016/j.neuroimage.2017.10.050
   Allen EJ, 2017, J NEUROSCI, V37, P1284, DOI 10.1523/JNEUROSCI.2336-16.2016
   American Speech-Language-Hearing Association, 1997, GUID AUD SCREEN, DOI [10.1044/policy.GL1997-00199, DOI 10.1044/POLICY.GL1997-00199]
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bonte M, 2014, J NEUROSCI, V34, P4548, DOI 10.1523/JNEUROSCI.4339-13.2014
   Chan AM, 2014, CEREB CORTEX, V24, P2679, DOI 10.1093/cercor/bht127
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Da Costa S, 2013, J NEUROSCI, V33, P1858, DOI 10.1523/JNEUROSCI.4405-12.2013
   Da Costa S, 2011, J NEUROSCI, V31, P14067, DOI 10.1523/JNEUROSCI.2000-11.2011
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   De Martino F, 2015, CEREB CORTEX, V25, P3394, DOI 10.1093/cercor/bhu150
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Dick F, 2012, J NEUROSCI, V32, P16095, DOI 10.1523/JNEUROSCI.1712-12.2012
   Dick FK, 2017, J NEUROSCI, V37, P12187, DOI 10.1523/JNEUROSCI.1436-17.2017
   Diesch E, 1997, PSYCHOPHYSIOLOGY, V34, P501, DOI 10.1111/j.1469-8986.1997.tb01736.x
   Engineer CT, 2008, NAT NEUROSCI, V11, P603, DOI 10.1038/nn.2109
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Faraway J.J., 2016, EXTENDING LINEAR MOD
   Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Honey C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134078
   Humphries C, 2010, NEUROIMAGE, V50, P1202, DOI 10.1016/j.neuroimage.2010.01.046
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Makela AM, 2003, NEUROSCI LETT, V353, P111, DOI 10.1016/j.neulet.2003.09.021
   Manca AD, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01413
   Mesgarani N, 2008, J ACOUST SOC AM, V123, P899, DOI 10.1121/1.2816572
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Moerel M, 2015, NEUROIMAGE, V106, P161, DOI 10.1016/j.neuroimage.2014.11.044
   Moerel M, 2013, J NEUROSCI, V33, P11888, DOI 10.1523/JNEUROSCI.5306-12.2013
   Moerel M, 2012, J NEUROSCI, V32, P14205, DOI 10.1523/JNEUROSCI.1388-12.2012
   Moses DA, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/056004
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2003, COGNITIVE BRAIN RES, V15, P207, DOI 10.1016/S0926-6410(02)00193-3
   Obleser J, 2006, HUM BRAIN MAPP, V27, P562, DOI 10.1002/hbm.20201
   Obleser J, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00232
   Ohl FW, 1997, P NATL ACAD SCI USA, V94, P9440, DOI 10.1073/pnas.94.17.9440
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   POTTER RK, 1950, J ACOUST SOC AM, V22, P807, DOI 10.1121/1.1906694
   Qin L, 2008, J NEUROPHYSIOL, V99, P2305, DOI 10.1152/jn.01125.2007
   R Core Team, 2018, R LANG ENV STAT COMP
   Riecke L, 2017, CEREB CORTEX, V27, P3002, DOI 10.1093/cercor/bhw160
   SACHS MB, 1979, J ACOUST SOC AM, V66, P470, DOI 10.1121/1.383098
   Saenz M, 2014, HEARING RES, V307, P42, DOI 10.1016/j.heares.2013.07.016
   Santoro R, 2017, P NATL ACAD SCI USA, V114, P4799, DOI 10.1073/pnas.1617622114
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Scharinger M, 2011, J COGNITIVE NEUROSCI, V23, P3972, DOI 10.1162/jocn_a_00056
   SERENO MI, 1995, SCIENCE, V268, P889, DOI 10.1126/science.7754376
   Shestakova A, 2004, COGNITIVE BRAIN RES, V21, P342, DOI 10.1016/j.cogbrainres.2004.06.011
   STEINSCHNEIDER M, 1995, BRAIN RES, V674, P147, DOI 10.1016/0006-8993(95)00008-E
   Steinschneider M, 2011, HEARING RES, V271, P103, DOI 10.1016/j.heares.2010.04.008
   Striem-Amit E, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017832
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Talavage TM, 2004, J NEUROPHYSIOL, V91, P1282, DOI 10.1152/jn.01125.2002
   Versnel H, 1998, J ACOUST SOC AM, V103, P2502, DOI 10.1121/1.422771
   Walker KMM, 2011, J NEUROSCI, V31, P14565, DOI 10.1523/JNEUROSCI.2074-11.2011
   Wang XQ, 1995, J NEUROPHYSIOL, V74, P2685
   Woods DL, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005183
   Worsley KJ, 2002, NEUROIMAGE, V15, P1, DOI 10.1006/nimg.2001.0933
   Zhang QT, 2016, EUR J NEUROSCI, V43, P773, DOI 10.1111/ejn.13164
NR 70
TC 2
Z9 3
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD SEP
PY 2018
VL 178
BP 574
EP 582
DI 10.1016/j.neuroimage.2018.05.072
PG 9
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GM8IF
UT WOS:000438467800048
PM 29860083
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Singh, L
   Fu, CSL
   Seet, XH
   Tong, APY
   Wang, JL
   Best, CT
AF Singh, Leher
   Fu, Charlene S. L.
   Seet, Xian Hui
   Tong, Ashley P. Y.
   Wang, Joelle L.
   Best, Catherine T.
TI Developmental change in tone perception in Mandarin monolingual, English
   monolingual, and Mandarin-English bilingual infants: Divergences between
   monolingual and bilingual learners
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Bilingualism; Tone discrimination; Infants; Speech perception; Mandarin
   Chinese; Phonology
ID SPOKEN WORD RECOGNITION; SPEECH-PERCEPTION; LEXICAL TONE; 1ST YEAR;
   PHONETIC PERCEPTION; LANGUAGE INPUT; VOWEL LENGTH; DISCRIMINATION;
   INTONATION; PITCH
AB Most languages use lexical tone to discriminate the meanings of words. There has been recent interest in tracking the development of tone categories during infancy. These studies have focused largely on monolingual infants learning either a tone language or a non-tone language. It remains to be seen how bilingual infants learning one tone language (e.g., Mandarin) and one non-tone language (e.g., English) discriminate tones. Here, we examined infants' discrimination of two Mandarin tones pairs: one salient and one subtle. Discrimination was investigated in three groups: Mandarin-English bilinguals, English monolinguals, and Mandarin monolinguals at 6 months and 9 months of age in a cross-sectional design. Results demonstrated relatively strong Mandarin tone discrimination in Mandarin monolinguals, with salient tone discrimination at 6 months and both salient and subtle tone discrimination at 9 months. English monolinguals discriminated neither contrast at 6 months but discriminated the salient contrast at 9 months. Surprisingly, there was no evidence for tone discrimination in Mandarin-English bilingual infants. In a second experiment, 12- and 13-month-old Mandarin-English bilingual and English monolingual infants were tested to determine whether bilinguals would demonstrate tone sensitivity at a later age. Results revealed a lack of tone sensitivity at 12 or 13 months in bilingual infants, yet English monolingual infants were sensitive to both salient and subtle Mandarin tone contrasts at 12 or 13 months. Our findings provide evidence for age-related convergence in Mandarin tone discrimination in English and Mandarin monolingual infants and for a distinct pattern of tone discrimination in bilingual infants. Theoretical implications for phonetic category acquisition are discussed. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Singh, Leher; Fu, Charlene S. L.; Seet, Xian Hui; Tong, Ashley P. Y.; Wang, Joelle L.] Natl Univ Singapore, Dept Psychol, Singapore 117570, Singapore.
   [Best, Catherine T.] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
RP Singh, L (corresponding author), Natl Univ Singapore, Dept Psychol, Singapore 117570, Singapore.
EM leher.singh@gmail.com
RI Best, Catherine T/M-4547-2019
OI Best, Catherine T/0000-0002-2447-2024
FU Singapore Children's Society Research Grant; Ministry of Education Tier
   1 Academic Research Fund [FY2013-FRC2-009]
FX We are grateful for a Singapore Children's Society Research Grant
   awarded to C.S.L.F and for a Ministry of Education Tier 1 Academic
   Research Fund grant (FY2013-FRC2-009) awarded to L.S. We appreciate
   assistance from Felicia Poh for the recruitment of participants,
   Desirene Poon for the recording of stimuli, and Thilanga D.
   Wewalaarachchi for her comments on the manuscript.
CR Albareda-Castellot B, 2011, DEVELOPMENTAL SCI, V14, P395, DOI 10.1111/j.1467-7687.2010.00989.x
   Anawin L, 1998, INTONATION SYSTEMS S, P376
   Bauer R., 1997, MODERN CANTONESE PHO
   Best C.T., 1998, INFANT BEHAV DEV, V21, P295, DOI [10.1016/S0163, DOI 10.1016/S0163, DOI 10.1016/S0163-6383(98)91508-9]
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bosch L, 2003, P 15 INT C PHON SCI, P1987
   Bosch L, 2001, INFANCY, V2, P29, DOI 10.1207/S15327078IN0201_3
   Burnham D, 2007, LANGUAGE EXPERIENCE, P259
   Burnham D, 2017, 11 INT SEM SPEECH PR
   Burnham D, 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI 10.1017/S0142716414000496
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Byers-Heinlein K, 2017, P NATL ACAD SCI USA, V114, P9032, DOI 10.1073/pnas.1703220114
   Chen A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00297
   Christophe A, 2001, INFANCY, V2, P385, DOI 10.1207/S15327078IN0203_6
   Csibra G, 2016, DEV PSYCHOL, V52, P521, DOI 10.1037/dev0000083
   de Jong K, 2002, J PHONETICS, V30, P53, DOI 10.1006/jpho.2001.0151
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Ferjan Ramirez N, 2017, DEV SCI, DOI [10.1111idesc.12427, DOI 10.1111IDESC.12427.]
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   Garcia-Sierra A, 2011, J PHONETICS, V39, P546, DOI 10.1016/j.wocn.2011.07.002
   Gussenhoven Carlos, 2004, PHONOLOGY TONE INTON
   HO AT, 1977, PHONETICA, V34, P446, DOI 10.1159/000259916
   Homma Y, 1973, STUDY SOUNDS, V16, P347
   Kitamura C, 2003, INFANCY, V4, P85, DOI 10.1207/S15327078IN0401_5
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Liu LQ, 2016, INT J BILINGUAL, V20, P335, DOI 10.1177/1367006914566082
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Mattock K, 2010, DEVELOPMENTAL SCI, V13, P229, DOI 10.1111/j.1467-7687.2009.00891.x
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Mugitani R, 2009, DEV PSYCHOL, V45, P236, DOI 10.1037/a0014043
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Pell MD, 2001, J ACOUST SOC AM, V109, P1668, DOI 10.1121/1.1352088
   Pereira C, 1998, 5 INT C SPOK LANG PR, P927
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   Pierrehumbert J., 1988, JAPANESE TONE STRUCT
   Quam C, 2012, CHILD DEV, V83, P236, DOI 10.1111/j.1467-8624.2011.01700.x
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Shi RS, 2017, INFANCY, V22, P790, DOI 10.1111/infa.12191
   Singh L, 2017, CHILD DEV, DOI [10.1111/cdev.12852, DOI 10.1111/CDEV.12852.]
   Singh L, 2016, FRONT PSYCHOL, V7, DOI [10.3389/fpsyg.2016.00667, DOI 10.3389/FPSYG.2016.00667.]
   Singh L, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01563
   Singh L, 2016, J PHONETICS, V55, P109, DOI 10.1016/j.wocn.2015.12.005
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   Singh L, 2012, COGNITION, V124, P128, DOI 10.1016/j.cognition.2012.05.008
   Sundara M, 2008, COGNITION, V108, P232, DOI 10.1016/j.cognition.2007.12.013
   Sundara M, 2011, J PHONETICS, V39, P505, DOI 10.1016/j.wocn.2010.08.006
   Trainor LJ, 1998, INFANT BEHAV DEV, V21, P799, DOI 10.1016/S0163-6383(98)90047-9
   Tsao F.-M., 2017, FRONT PSYCHOL, V8, DOI [10.3389/fpsyg.2017.00558, DOI 10.3389/FPSYG.2017.00558.]
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Tyler MD, 2014, DEV PSYCHOBIOL, V56, P210, DOI 10.1002/dev.21195
   Uther M, 2007, SPEECH COMMUN, V49, P2, DOI 10.1016/j.specom.2006.10.003
   VANCE TJ, 1976, PHONETICA, V33, P368, DOI 10.1159/000259793
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wewalaarachchi TD, 2017, J EXP CHILD PSYCHOL, V159, P16, DOI 10.1016/j.jecp.2017.01.009
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE
   Yuan JH, 2004, 2004 International Symposium on Chinese Spoken Language Processing, Proceedings, P45
   Yuan JH, 2006, LECT NOTES COMPUT SC, V4274, P19
   Zeng X. L, 2004, P INT S TON ASP LANG, P235
NR 70
TC 3
Z9 3
U1 1
U2 13
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD SEP
PY 2018
VL 173
BP 59
EP 77
DI 10.1016/j.jecp.2018.03.012
PG 19
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GK7LM
UT WOS:000436385700005
PM 29677553
DA 2021-02-24
ER

PT J
AU Yamashiro, A
   Vouloumanos, A
AF Yamashiro, Amy
   Vouloumanos, Athena
TI How do infants and adults process communicative events in real time?
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Speech perception; Communication; Infant eye tracking; Real-time
   processing; Third-party interactions; Cognitive development
ID EYE-TRACKING; SPEECH; OBJECT; WORDS; CATEGORIZATION; UNDERSTAND;
   LANGUAGE; MODELS
AB Speech allows humans to communicate and to navigate the social world. By 12 months, infants recognize that speech elicits appropriate responses from others. However, it is unclear how infants process dynamic communicative scenes and how their processing abilities compare with those of adults. Do infants, like adults, process communicative events while the event is occurring or only after being presented with the outcome? We examined 12 month-olds' and adults' eye movements as they watched a Communicator grasp one (target) of two objects. During the test event, the Communicator could no longer reach the objects, so she spoke or coughed to a Listener, who selected either object. Infants' and adults' patterns of looking to the actors and objects revealed that both groups immediately evaluated the Communicator's speech, but not her cough, as communicative and recognized that the Listener should select the target object only when the Cominunicator spoke. Furthermore, infants and adults shifted their attention between the actors and the objects in very similar ways. This suggests that 12-month-olds can quickly process communicative events as they occur with adult-like accuracy. However, differences in looking reveal that 12-month-olds process slower than adults. This early developing processing ability may allow infants to learn language and acquire knowledge from communicative interactions. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yamashiro, Amy; Vouloumanos, Athena] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
RP Yamashiro, A (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM amy.yamashiro@nyu.edu
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   Development of the National Institutes of HealthUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD072018]; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD072018, R01HD072018, R01HD072018, R01HD072018,
   R01HD072018] Funding Source: NIH RePORTER
FX This research was supported by the Eunice Kennedy Shriver National
   Institute of Child Health and Human Development of the National
   Institutes of Health under Award R01HD072018. We thank members of the
   NYU Infant Cognition and Communication Lab, the parents and infants who
   participated, and Patrick Shrout for his assistance with analyses.
CR Akhtar N, 2001, CHILD DEV, V72, P416, DOI 10.1111/1467-8624.00287
   Aslin RN, 2007, DEVELOPMENTAL SCI, V10, P48, DOI 10.1111/j.1467-7687.2007.00563.x
   Augusti EM, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00161
   Baillargeon R, 2010, TRENDS COGN SCI, V14, P110, DOI 10.1016/j.tics.2009.12.006
   Beier JS, 2012, CHILD DEV, V83, P486, DOI 10.1111/j.1467-8624.2011.01702.x
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Brandone AC, 2014, DEVELOPMENTAL SCI, V17, P23, DOI 10.1111/desc.12095
   Cannon EN, 2012, DEVELOPMENTAL SCI, V15, P292, DOI 10.1111/j.1467-7687.2011.01127.x
   Cheung H, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046168
   Csibra G, 2011, PHILOS T R SOC B, V366, P1149, DOI 10.1098/rstb.2010.0319
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Cudeck R, 2002, PSYCHOL METHODS, V7, P41, DOI 10.1037/1082-989X.7.1.41
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630
   Falck-Ytter T, 2015, RES AUTISM SPECT DIS, V17, P78, DOI 10.1016/j.rasd.2015.06.007
   Fawcett C, 2013, DEVELOPMENTAL SCI, V16, P841, DOI 10.1111/desc.12074
   Ferry AL, 2010, CHILD DEV, V81, P472, DOI 10.1111/j.1467-8624.2009.01408.x
   Fitzmaurice G., 2011, APPL LONGITUDINAL AN
   Flanagan JR, 2003, NATURE, V424, P769, DOI 10.1038/nature01861
   Fulkerson AL, 2007, COGNITION, V105, P218, DOI 10.1016/j.cognition.2006.09.005
   Grayson D., 2004, Understanding Statistics, V3, P101, DOI 10.1207/s15328031us0302_3
   Gredeback G, 2015, CHILD DEV PERSPECT, V9, P79, DOI 10.1111/cdep.12109
   Gredeback G, 2010, SOC NEUROSCI-UK, V5, P441, DOI 10.1080/17470910903523327
   Gredeback G, 2010, COGNITION, V114, P197, DOI 10.1016/j.cognition.2009.09.004
   Grimm K, 2016, INT J BEHAV DEV, V40, P87, DOI 10.1177/0165025415580806
   Grosse G, 2010, DEV PSYCHOL, V46, P1710, DOI 10.1037/a0020727
   Hamlin J. K., 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.00563, DOI 10.3389/FPSYG.2014.01563]
   Krehm M, 2014, J COGN DEV, V15, P527, DOI 10.1080/15248372.2012.736112
   Langdon R, 2005, VIS COGN, V12, P1497, DOI 10.1080/13506280444000805
   Liszkowski U, 2008, COGNITION, V108, P732, DOI 10.1016/j.cognition.2008.06.013
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P249, DOI 10.1111/j.1467-7687.2010.00975.x
   Martin A, 2012, COGNITION, V123, P50, DOI 10.1016/j.cognition.2011.12.003
   Oakes LM, 2012, INFANCY, V17, P1, DOI 10.1111/j.1532-7078.2011.00101.x
   Oakes LM, 2010, INFANCY, V15, P1, DOI 10.1111/j.1532-7078.2010.00030.x
   R Core Team, 2013, R LANG ENV STAT COMP
   Rosander K, 2011, NEUROPSYCHOLOGIA, V49, P2911, DOI 10.1016/j.neuropsychologia.2011.06.018
   Schulze C, 2015, COGNITION, V136, P91, DOI 10.1016/j.cognition.2014.11.036
   Song HJ, 2008, COGNITION, V109, P295, DOI 10.1016/j.cognition.2008.08.008
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Thorgrimsson G. B, 2014, FRONTIERS PSYCHOL, V5, DOI [10.3389/fpsyg.2014.00321, DOI 10.3389FFPSYG.2014.00321]
   Thorgrimsson GB, 2015, INFANT BEHAV DEV, V39, P53, DOI 10.1016/j.infbeh.2015.02.002
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   Vouloumanos A, 2014, TRENDS COGN SCI, V18, P642, DOI 10.1016/j.tics.2014.10.001
   Vouloumanos A, 2014, DEVELOPMENTAL SCI, V17, P872, DOI 10.1111/desc.12170
   Vouloumanos A, 2012, P NATL ACAD SCI USA, V109, P12933, DOI 10.1073/pnas.1121057109
   Vouloumanos A, 2009, P NATL ACAD SCI USA, V106, P18867, DOI 10.1073/pnas.0906049106
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Woodward AL, 1998, COGNITION, V69, P1, DOI 10.1016/S0010-0277(98)00058-4
   Xu F, 2005, PSYCHOL SCI, V16, P372, DOI 10.1111/j.0956-7976.2005.01543.x
   Xu F, 2002, COGNITION, V85, P223, DOI 10.1016/S0010-0277(02)00109-9
NR 51
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD SEP
PY 2018
VL 173
BP 268
EP 283
DI 10.1016/j.jecp.2018.04.011
PG 16
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GK7LM
UT WOS:000436385700018
PM 29772454
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Gwilliams, L
   Linzen, T
   Poeppel, D
   Marantz, A
AF Gwilliams, Laura
   Linzen, Tal
   Poeppel, David
   Marantz, Alec
TI In Spoken Word Recognition, the Future Predicts the Past
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE auditory processing; lexical access; MEG; speech
ID VOICE ONSET TIME; SPEECH-PERCEPTION; PHONETIC CATEGORIZATION; SUBSEQUENT
   CONTEXT; MEG; RESTORATION; MODEL; FEATURES; FMRI; ARTICULATION
AB Speech is an inherently noisy and ambiguous signal. To fluently derive meaning, a listener must integrate contextual information to guide interpretations of the sensory input. Although many studies have demonstrated the influence of prior context on speech perception, the neural mechanisms supporting the integration of subsequent context remain unknown. Using MEG to record from human auditory cortex, we analyzed responses to spoken words with a varyingly ambiguous onset phoneme, the identity of which is later disambiguated at the lexical uniqueness point. Fifty participants (both male and female) were recruited across two MEG experiments. Our findings suggest that primary auditory cortex is sensitive to phonological ambiguity very early during processing at just 50 ms after onset. Subphonemic detail is preserved in auditory cortex over long timescales and re-evoked at subsequent phoneme positions. Commitments to phonological categories occur in parallel, resolving on the shorter timescale of similar to 450 ms. These findings provide evidence that future input determines the perception of earlier speech sounds by maintaining sensory features until they can be integrated with top-down lexical information.
C1 [Gwilliams, Laura; Poeppel, David; Marantz, Alec] NYU, Psychol Dept, 550 1St Ave, New York, NY 10003 USA.
   [Marantz, Alec] NYU, Dept Linguist, 550 1St Ave, New York, NY 10003 USA.
   [Gwilliams, Laura; Marantz, Alec] New York Univ Abu Dhabi, Abu Dhabi, Saadiyat Island, U Arab Emirates.
   [Linzen, Tal] Johns Hopkins Univ, Dept Cognit Sci, Baltimore, MD USA.
   [Poeppel, David] Max Planck Inst MPIEA, Dept Neurosci, D-60322 Frankfurt, Germany.
RP Gwilliams, L (corresponding author), NYU, Linguist Dept, 10 Washington Pl, New York, NY 10003 USA.
EM laura.gwilliams@nyu.edu
OI Linzen, Tal/0000-0003-0435-6912; Marantz, Alec/0000-0003-4805-2910;
   Poeppel, David/0000-0003-0184-163X; Gwilliams, Laura/0000-0002-9213-588X
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [ERC-2011-AdG 295810 BOOTPHON]; Agence Nationale pour la
   RechercheFrench National Research Agency (ANR) [ANR-10-IDEX-0001-02 PSL,
   ANR-10-LABX-0087 IEC]; National Institutes of HealthUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [2R01DC05660]; NYU Abu Dhabi (NYUAD) Institute [G1001]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC005660, R01DC005660, R01DC005660, R01DC005660,
   R01DC005660, R01DC005660, R01DC005660, R01DC005660, R01DC005660,
   R01DC005660, R01DC005660, R01DC005660, R01DC005660, R01DC005660,
   R01DC005660] Funding Source: NIH RePORTER
FX This work was supported by European Research Council (grant ERC-2011-AdG
   295810 BOOTPHON) and the Agence Nationale pour la Recherche (grants
   ANR-10-IDEX-0001-02 PSL and ANR-10-LABX-0087 IEC) to T.L.; the National
   Institutes of Health (Grant 2R01DC05660 to D.P.); and the NYU Abu Dhabi
   (NYUAD) Institute (Grant G1001 to A.M.). We thank Kyriaki Neophytou for
   her help with data collection and Lena Warnke for help with stimulus
   creation.
CR Ackermann H, 1999, COGNITIVE BRAIN RES, V7, P511, DOI 10.1016/S0926-6410(98)00054-8
   Adachi Y, 2001, IEEE T APPL SUPERCON, V11, P669, DOI 10.1109/77.919433
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bicknell K, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X15000734
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   BLUMSTEIN SE, 1977, J ACOUST SOC AM, V61, P1301, DOI 10.1121/1.381433
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Carpenter GA, 2016, ADAPTIVE RESONANCE T, P1
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   COLE RA, 1973, PERCEPT PSYCHOPHYS, V13, P153, DOI 10.3758/BF03207252
   CONNINE CM, 1991, J MEM LANG, V30, P234, DOI 10.1016/0749-596X(91)90005-5
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ettinger A, 2014, BRAIN LANG, V129, P14, DOI 10.1016/j.bandl.2013.11.004
   Gage N, 1998, BRAIN RES, V814, P236, DOI 10.1016/S0006-8993(98)01058-0
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gaskell MG, 2007, OXFORD HDB PSYCHOLIN, P55
   Gold JI, 2007, ANNU REV NEUROSCI, V30, P535, DOI 10.1146/annurev.neuro.29.051605.113038
   GORDON PC, 1993, COGNITIVE PSYCHOL, V25, P1, DOI 10.1006/cogp.1993.1001
   Gow D. W., 2007, LAB PHONOLOGY, V9, P173
   Gow DW, 2009, COGNITION, V110, P222, DOI 10.1016/j.cognition.2008.11.011
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027
   Grossberg S, 2011, J ACOUST SOC AM, V130, P440, DOI 10.1121/1.3589258
   Gwilliams L, 2018, NEUROPSYCHOLOGIA, V114, P77, DOI 10.1016/j.neuropsychologia.2018.04.015
   Gwilliams L, 2016, NEUROIMAGE, V132, P320, DOI 10.1016/j.neuroimage.2016.02.057
   Gwilliams L, 2015, BRAIN LANG, V147, P1, DOI 10.1016/j.bandl.2015.04.006
   Gwilliams L, 2018, P 8 WORKSH COGN MOD
   Gwilliams LE, 2015, J EXP PSYCHOL LEARN, V41, P1663, DOI 10.1037/xlm0000130
   HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686
   Heil P, 2004, CURR OPIN NEUROBIOL, V14, P461, DOI 10.1016/j.conb.2004.07.002
   Hertrich I, 2000, NEUROREPORT, V11, P4017, DOI 10.1097/00001756-200012180-00023
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Holmes AP, 1996, J CEREBR BLOOD F MET, V16, P7, DOI 10.1097/00004647-199601000-00002
   Kawahara H, 2008, IEEE INT C AC SPEECH
   Kawahara H, 2011, SADHANA-ACAD P ENG S, V36, P713, DOI 10.1007/s12046-011-0043-3
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MARTIN JG, 1981, J ACOUST SOC AM, V69, P559, DOI 10.1121/1.385484
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   MCQUEEN JM, 1991, J EXP PSYCHOL HUMAN, V17, P433, DOI 10.1037/0096-1523.17.2.433
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2003, NEUROIMAGE, V20, P1839, DOI 10.1016/j.neuroimage.2003.07.019
   Papanicolaou AC, 2003, NEUROIMAGE, V18, P448, DOI 10.1016/S1053-8119(02)00020-4
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   R Core Team, 2014, R LANG ENV STAT COMP
   Rogers JC, 2017, J COGNITIVE NEUROSCI, V29, P919, DOI 10.1162/jocn_a_01096
   SAMUEL AG, 1991, Q J EXP PSYCHOL-A, V43, P679, DOI 10.1080/14640749108400992
   SAMUEL AG, 1981, J EXP PSYCHOL HUMAN, V7, P1124, DOI 10.1037/0096-1523.7.5.1124
   Simos PG, 1998, COGNITIVE BRAIN RES, V7, P215, DOI 10.1016/S0926-6410(98)00037-8
   Steinschneider M, 1999, J NEUROPHYSIOL, V82, P2346
   STEINSCHNEIDER M, 1995, BRAIN LANG, V48, P326, DOI 10.1006/brln.1995.1015
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   Szostak CM, 2013, ATTEN PERCEPT PSYCHO, V75, P1533, DOI 10.3758/s13414-013-0492-3
   Tavabi K, 2007, EUR J NEUROSCI, V25, P3155, DOI 10.1111/j.1460-9568.2007.05572.x
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Wolff MJ, 2017, NAT NEUROSCI, V20, P864, DOI 10.1038/nn.4546
   Yuan J, 2008, PENN PHONETICS LAB F
NR 69
TC 11
Z9 11
U1 0
U2 12
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD AUG 29
PY 2018
VL 38
IS 35
BP 7585
EP 7599
DI 10.1523/JNEUROSCI.0065-18.2018
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA GR8SF
UT WOS:000442995700004
PM 30012695
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Zhao, TC
   Kuhl, PK
AF Zhao, T. Christina
   Kuhl, Patricia K.
TI Linguistic effect on speech perception observed at the brainstem
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE speech perception; brainstem response; linguistic experience; MEG/EEG
ID LANGUAGE PHONETIC PERCEPTION; CROSS-LANGUAGE; AUDITORY-SYSTEM; FETAL
   HEARING; EXPERIENCE; RESPONSES; DISCRIMINATION; CATEGORIZATION;
   ACQUISITION; POTENTIALS
AB Linguistic experience affects speech perception from early infancy, as previously evidenced by behavioral and brain measures. Current research focuses on whether linguistic effects on speech perception can be observed at an earlier stage in the neural processing of speech (i.e., auditory brainstem). Brainstem responses reflect rapid, automatic, and preattentive encoding of sounds. Positive experiential effects have been reported by examining the frequency-following response (FFR) component of the complex auditory brainstem response (cABR) in response to sustained high-energy periodic portions of speech sounds (vowels and lexical tones). The current study expands the existing literature by examining the cABR onset component in response to transient and low-energy portions of speech (consonants), employing simultaneous magnetoencephalography (MEG) in addition to electroencephalography (EEG), which provide complementary source information on cABR. Utilizing a cross-cultural design, we behaviorally measured perceptual responses to consonants in native Spanish-and English-speaking adults, in addition to cABR. Brain and behavioral relations were examined. Results replicated previous behavioral differences between language groups and further showed that individual consonant perception is strongly associated with EEG-cABR onset peak latency. MEG-cABR source analysis of the onset peaks complimented the EEG-cABR results by demonstrating subcortical sources for both peaks, with no group differences in peak locations. Current results demonstrate a brainstem-perception relation and show that the effects of linguistic experience on speech perception can be observed at the brainstem level.
C1 [Zhao, T. Christina; Kuhl, Patricia K.] Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
RP Kuhl, PK (corresponding author), Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
EM pkkuhl@u.washington.edu
FU Ready Mind Project
FX The manuscript has been greatly improved by comments from colleagues,
   including Dr. Samu Taulu (M/EEG methods) and Dr. Matthew Masapollo and
   Dr. Alexis Bosseler (speech perception). The research described here was
   supported by the Ready Mind Project as well as a generous contribution
   by Mr. Bard Richmond to the University of Washington Institute for
   Learning & Brain Sciences.
CR Abramson A. S., 1970, P 6 INT C PHON SCI, V196, P569
   ABRAMSON AS, 1972, HASKINS LAB STATUS R, V29, P15
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   BIRNHOLZ JC, 1983, SCIENCE, V222, P516, DOI 10.1126/science.6623091
   Boersma P., 2009, PRAAT DOING PHONETIC
   Bosseler AN, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00690
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Coffey EBJ, 2017, J NEUROSCI, V37, P830, DOI 10.1523/JNEUROSCI.1265-16.2016
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027
   Hay J. F, 2005, THESIS
   HEPPER PG, 1994, ARCH DIS CHILD-FETAL, V71, pF81, DOI 10.1136/fn.71.2.F81
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Intartaglia B, 2016, NEUROPSYCHOLOGIA, V89, P57, DOI 10.1016/j.neuropsychologia.2016.05.033
   JEWETT DL, 1970, SCIENCE, V167, P1517, DOI 10.1126/science.167.3924.1517
   Johnson KL, 2005, EAR HEARING, V26, P424, DOI 10.1097/01.aud.0000179687.71662.6e
   Kraus N, 2014, J NEUROSCI, V34, P11913, DOI 10.1523/JNEUROSCI.1881-14.2014
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Krishnaswamy P, 2017, P NATL ACAD SCI USA, V114, pE10465, DOI 10.1073/pnas.1705414114
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Larson E, 2018, IEEE T BIO-MED ENG, V65, P1002, DOI 10.1109/TBME.2017.2734641
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Macmillan N.A., 2008, DETECTION THEORY USE
   Mason JA, 1998, PEDIATRICS, V101, P221, DOI 10.1542/peds.101.2.221
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Moon C, 2013, ACTA PAEDIATR, V102, P156, DOI 10.1111/apa.12098
   Parkkonen L, 2009, HUM BRAIN MAPP, V30, P1772, DOI 10.1002/hbm.20788
   Partanen E, 2013, P NATL ACAD SCI USA, V110, P15145, DOI 10.1073/pnas.1302159110
   Ress D, 2000, NAT NEUROSCI, V3, P940
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Strange W, 1978, PERCEPTION EXPERIENC, V1, P129, DOI [DOI 10.1007/978-1-4684-2619-9_5, 10.1007/978-1-4684-2619-9_5]
   Suga N, 2003, NAT REV NEUROSCI, V4, P783, DOI 10.1038/nrn1222
   Suga N, 2008, J COMP PHYSIOL A, V194, P169, DOI 10.1007/s00359-007-0274-2
   Taulu S, 2005, J APPL PHYS, V97, DOI 10.1063/1.1935742
   Taulu S, 2009, HUM BRAIN MAPP, V30, P1524, DOI 10.1002/hbm.20627
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Xiao ZJ, 2002, NAT NEUROSCI, V5, P57, DOI 10.1038/nn786
NR 51
TC 10
Z9 10
U1 0
U2 8
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD AUG 28
PY 2018
VL 115
IS 35
BP 8716
EP 8721
DI 10.1073/pnas.1800186115
PG 6
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GR7ID
UT WOS:000442861600046
PM 30104356
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kim, S
   Mitterer, H
   Cho, T
AF Kim, Sahyang
   Mitterer, Holger
   Cho, Taehong
TI A time course of prosodic modulation in phonological inferencing: The
   case of Korean post-obstruent tensing
SO PLOS ONE
LA English
DT Article
ID SPEECH-PERCEPTION; ASSIMILATION; RECOGNITION; WORDS; BOUNDARIES;
   PROMINENCE; TRACKING; STOPS
AB Application of a phonological rule is often conditioned by prosodic structure, which may create a potential perceptual ambiguity, calling for phonological inferencing. Three eye-tracking experiments were conducted to examine how spoken word recognition may be modulated by the interaction between the prosodically-conditioned rule application and phonological inferencing. The rule examined was post-obstruent tensing (POT) in Korean, which changes a lax consonant into a tense after an obstruent only within a prosodic domain of Accentual Phrase (AP). Results of Experiments 1 and 2 revealed that, upon hearing a derived tense form, listeners indeed recovered its underlying (lax) form. The phonological inferencing effect, however, was observed only in the absence of its tense competitor which was acoustically matched with the auditory input. In Experiment 3, a prosodic cue to an AP boundary (which blocks POT) was created before the target using an F0 cue alone (i.e., without any temporal cues), and the phonological inferencing effect disappeared. This supports the view that phonological inferencing is modulated by listeners' online computation of prosodic structure (rather than through a low-level temporal normalization). Further analyses of the time course of eye movement suggested that the prosodic modulation effect occurred relatively later in the lexical processing. This implies that speech processing involves segmental processing in conjunction with prosodic structural analysis, and calls for further research on how prosodic information is processed along with segmental information in language-specific vs. universally applicable ways.
C1 [Kim, Sahyang] Hongik Univ, Dept English Educ, Seoul, South Korea.
   [Mitterer, Holger] Univ Malta, Dept Cognit Sci, Msida, Malta.
   [Cho, Taehong] Hanyang Univ, Hanyang Inst Phonet & Cognit Sci Language, Dept English Language & Literature, Seoul, South Korea.
RP Cho, T (corresponding author), Hanyang Univ, Hanyang Inst Phonet & Cognit Sci Language, Dept English Language & Literature, Seoul, South Korea.
EM tcho@hanyang.ac.kr
RI Mitterer, Holger/D-1908-2010
OI Mitterer, Holger/0000-0003-4318-0032; Cho, Taehong/0000-0002-8148-745X
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of KoreaNational Research Foundation of Korea
   [NRF-2016S1A5A2A01027109]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea
   (NRF-2016S1A5A2A01027109) awarded to SK. The funder had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.; This work was supported by the Ministry
   of Education of the Republic of Korea and the National Research
   Foundation of Korea (NRF-2016S1A5A2A01027109).
CR Abramson AS, 2017, J PHONETICS, V63, P75, DOI 10.1016/j.wocn.2017.05.002
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Beckman ME, 1996, LANG COGNITIVE PROC, V11, P17, DOI 10.1080/016909696387213
   Cho T, 2011, CONTINUUM COMPANION, P343
   Cho TH, 2007, J PHONETICS, V35, P210, DOI 10.1016/j.wocn.2006.03.003
   Cho T, 2009, J PHONETICS, V37, P466, DOI 10.1016/j.wocn.2009.08.001
   Cho TH, 2005, J PHONETICS, V33, P121, DOI 10.1016/j.wocn.2005.01.001
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Cho TH, 2001, J PHONETICS, V29, P155, DOI 10.1006/jpho.2001.0131
   Christophe A, 2004, J MEM LANG, V51, P523, DOI 10.1016/j.jml.2004.07.001
   Cutler A., 1987, Computer Speech and Language, V2, P133, DOI 10.1016/0885-2308(87)90004-0
   Davidson L, 2016, J PHONETICS, V54, P35, DOI 10.1016/j.wocn.2015.09.003
   de Jong K, 1998, J PHONETICS, V26, P283, DOI 10.1006/jpho.1998.0077
   Docherty G., 1992, PAPERS LABORATORY PH, P90, DOI DOI 10.1017/CBO9780511519918.005
   Gaskell MG, 2008, J EXP PSYCHOL HUMAN, V34, P1632, DOI 10.1037/a0011977
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gow D. W., 2007, LAB PHONOLOGY, V9, P173
   Gow DW, 2004, J MEM LANG, V51, P279, DOI 10.1016/j.jml.2004.05.004
   Gow DW, 2002, J EXP PSYCHOL HUMAN, V28, P163, DOI 10.1037//0096-1523.28.1.163
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Jun S.-A., 1998, PHONOLOGY, V15, P189, DOI DOI 10.1017/S0952675798003571
   Jun S.-A., 2005, PROSODIC TYPOLOGY PH, P201, DOI DOI 10.1093/ACPROF:OSO/9780199249633.003.0008
   Jun SA, 2000, TEXT SPEECH LANG TEC, V15, P209
   Katsika A, 2016, J PHONETICS, V55, P149, DOI 10.1016/j.wocn.2015.12.003
   Kim S, 2003, JAPANESE/KOREAN LINGUSITICS, VOL 11, P263
   Kim S, 2017, J ACOUST SOC AM, V142, pEL362, DOI 10.1121/1.5005132
   Kim S, 2013, J ACOUST SOC AM, V134, pEL19, DOI 10.1121/1.4807431
   Kim S, 2012, STUD SECOND LANG ACQ, V34, P415, DOI 10.1017/S0272263112000137
   Klatt D.H., 1975, J PHONETICS, V3, P129
   Kuzla C., 2010, LAB PHONOLOGY, P731
   Kuzla C, 2007, J PHONETICS, V35, P301, DOI 10.1016/j.wocn.2006.11.001
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   McQueen J. M., 1995, PHONOLOGY PHONETIC E, P61
   McQueen JM, 2007, Q J EXP PSYCHOL, V60, P661, DOI 10.1080/17470210601183890
   Mitterer H, 2006, COGNITIVE SCI, V30, P451, DOI 10.1207/s15516709cog0000_57
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   Mitterer H, 2013, J MEM LANG, V69, P59, DOI 10.1016/j.jml.2013.02.001
   Mitterer H, 2009, J EXP PSYCHOL HUMAN, V35, P244, DOI 10.1037/a0012730
   Nespor M, 1986, PROSODIC PHONOLOGY S
   Ohala J. J., 1995, PHONOLOGY PHONETIC E, V4, P41, DOI DOI 10.1017/CB09780511554315.004
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Tanner J, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.96
   Tyler MD, 2009, J ACOUST SOC AM, V126, P367, DOI 10.1121/1.3129127
   WIGHTMAN CW, 1992, J ACOUST SOC AM, V91, P1707, DOI 10.1121/1.402450
NR 48
TC 4
Z9 4
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 27
PY 2018
VL 13
IS 8
AR e0202912
DI 10.1371/journal.pone.0202912
PG 28
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GR6UK
UT WOS:000442804200031
PM 30148859
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Claes, AJ
   Van de Heyning, P
   Gilles, A
   Hofkens-Van den Brandt, A
   Van Rompaey, V
   Mertens, G
AF Claes, Annes J.
   Van de Heyning, Paul
   Gilles, Annick
   Hofkens-Van den Brandt, Anouk
   Van Rompaey, Vincent
   Mertens, Griet
TI Impaired Cognitive Functioning in Cochlear Implant Recipients Over the
   Age of 55 Years: A Cross-Sectional Study Using the Repeatable Battery
   for the Assessment of Neuropsychological Status for Hearing-Impaired
   Individuals (RBANS-H)
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cognition; cochlear implantation; RBANS-H; older adults; profound
   hearing loss; RBANS
ID OLDER-ADULTS; DECLINE; AIDS; EMERGENCE; DEMENTIA
AB Primary Objective: To compare cognitive functioning among experienced, unilateral cochlear implant (CI) recipients and normal-hearing (NH) controls by means of the Repeatable Battery for the Assessment of Neuropsychological Status for Hearing-impaired individuals (RBANS-H).
   Methods: Sixty-one post-lingually and bilaterally severely hearing-impaired CI recipients (median age: 71.0, range: 58.3 to 93.9 years) with at least 1 year of CI experience (median: 12.4, range: 1.1 to 18.6 years) and 81 NH control participants (median age: 69.9, range: 50.1 to 87.1 years) took part in this cross-sectional study. The RBANS-H was performed, as well as an audiometric assessment, including best-aided speech audiometry in quiet (monosyllabic words) and in noise (Leuven Intelligibility Sentences test).
   Results: The RBANS-H performances of the CI recipients (mean: 88.1 +/- 14.9) were significantly poorer than the those of the NH participants (mean: 100.5 +/- 13.2), with correction of age, sex, and education differences (general linear model: p = 0.001). The mean difference, corrected for the effects of these three demographic factors, was 8.8 (+/- 2.5) points. Additionally, in both groups, a significant correlation was established between overall cognition and speech perception, both in quiet and in noise, independently of age.
   Conclusion: Experienced, unilateral CI recipients present subnormal cognitive functioning, beyond the effect of age, sex and education. This has implications for auditory rehabilitation after CI and may highlight the need for additional cognitive rehabilitation in the long term after implantation. Long-term prospective and longitudinal investigations are imperative to improve our understanding of cognitive aging in severely hearing-impaired individuals receiving CIs and its association with CI outcomes.
C1 [Claes, Annes J.; Van de Heyning, Paul; Gilles, Annick; Hofkens-Van den Brandt, Anouk; Van Rompaey, Vincent; Mertens, Griet] Antwerp Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Antwerp, Belgium.
   [Claes, Annes J.; Van de Heyning, Paul; Gilles, Annick; Van Rompaey, Vincent; Mertens, Griet] Univ Antwerp, Expt Lab Translat Neurosci & Dentootolaryngol, Fac Med & Hlth Sci, Antwerp, Belgium.
   [Gilles, Annick] Univ Coll Ghent, Dept Human & Social Welf, Ghent, Belgium.
RP Claes, AJ (corresponding author), Antwerp Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Antwerp, Belgium.; Claes, AJ (corresponding author), Univ Antwerp, Expt Lab Translat Neurosci & Dentootolaryngol, Fac Med & Hlth Sci, Antwerp, Belgium.
EM annesclaes.uza@gmail.com
RI Mertens, Griet/M-3882-2016; Van Rompaey, Vincent/L-2450-2014
OI Mertens, Griet/0000-0001-8621-0292; Van Rompaey,
   Vincent/0000-0003-0912-7780
FU company MED-EL, Innsbruck (Austria)
FX The Antwerp University Hospital currently receives a research grant from
   the company MED-EL, Innsbruck (Austria).
CR Acar B, 2011, ARCH GERONTOL GERIAT, V52, P250, DOI 10.1016/j.archger.2010.04.013
   Amieva H, 2015, J AM GERIATR SOC, V63, P2099, DOI 10.1111/jgs.13649
   Appels BA, 2010, AM J ALZHEIMERS DIS, V25, P301, DOI 10.1177/1533317510367485
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   Baltes PB, 1997, PSYCHOL AGING, V12, P12, DOI 10.1037/0882-7974.12.1.12
   Barnes DE, 2011, LANCET NEUROL, V10, P819, DOI 10.1016/S1474-4422(11)70072-2
   Bush ALH, 2015, EAR HEARING, V36, P395, DOI 10.1097/AUD.0000000000000142
   Castiglione A, 2016, AUDIOL NEURO-OTOL, V21, P21, DOI 10.1159/000448350
   Choi AY, 2011, CLIN EXP OTORHINOLAR, V4, P72, DOI 10.3342/ceo.2011.4.2.72
   Claes AJ, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00512
   Cosetti MK, 2016, CLIN INTERV AGING, V11, P603, DOI 10.2147/CIA.S100255
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Gallacher J, 2012, NEUROLOGY, V79, P1583, DOI 10.1212/WNL.0b013e31826e263d
   Grantham DW, 2008, LARYNGOSCOPE, V118, P145, DOI 10.1097/MLG.0b013e31815661f9
   Gurgel RK, 2014, OTOL NEUROTOL, V35, P775, DOI 10.1097/MAO.0000000000000313
   Hua H, 2017, J SPEECH LANG HEAR R, V60, P2752, DOI 10.1044/2017_JSLHR-H-16-0276
   Karantzoulis S, 2013, ARCH CLIN NEUROPSYCH, V28, P837, DOI 10.1093/arclin/act057
   Kleine Punte A, 2013, Cochlear Implants Int, V14 Suppl 2, pS39, DOI 10.1179/1467010013Z.00000000098
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   LINDENBERGER U, 1994, PSYCHOL AGING, V9, P339, DOI 10.1037/0882-7974.9.3.339
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Piquado T, 2010, BRAIN RES, V1365, P48, DOI 10.1016/j.brainres.2010.09.070
   Quaranta N, 2014, AUDIOL NEURO-OTOL, V19, P10, DOI 10.1159/000371597
   Randolph C, 1998, J CLIN EXP NEUROPSYC, V20, P310, DOI 10.1076/jcen.20.3.310.823
   Randolph C, 1998, RBANS UPDATE REPEATA
   Roberts KL, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00039
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Sommers MS, 1997, J AM GERIATR SOC, V45, P633, DOI 10.1111/j.1532-5415.1997.tb03101.x
   van Hooren SAH, 2005, INT J AUDIOL, V44, P265, DOI 10.1080/14992020500060370
   van Wieringen A, 2008, INT J AUDIOL, V47, P348, DOI 10.1080/14992020801895144
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   Wouters J, 1994, LOGOPEDIE, V7, P28
NR 38
TC 13
Z9 13
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD AUG 24
PY 2018
VL 12
AR 580
DI 10.3389/fnins.2018.00580
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA GR5BX
UT WOS:000442641200001
PM 30197584
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Law, JM
   De Vos, A
   Vanderauwera, J
   Wouters, J
   Ghesquiere, P
   Vandermosten, M
AF Law, Jeremy M.
   De Vos, Astrid
   Vanderauwera, Jolijn
   Wouters, Jan
   Ghesquiere, Pol
   Vandermosten, Maaike
TI Grapheme-Phoneme Learning in an Unknown Orthography: A Study in Typical
   Reading and Dyslexic Children
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE dyslexia; literacy; phonological awareness; orthographic knowledge;
   letter-speech sound learning; grapheme-phoneme-correspondences;
   artificial script; children
ID DEVELOPMENTAL DYSLEXIA; FAMILIAL RISK; MORPHOLOGICAL AWARENESS;
   PHONOLOGICAL AWARENESS; SPEECH-PERCEPTION; CAUSAL LINK; DEFICITS;
   SOUNDS; ADULTS; ACQUISITION
AB In this study, we examined the learning of new grapheme-phoneme correspondences in individuals with and without dyslexia. Additionally, we investigated the relation between grapheme-phoneme learning and measures of phonological awareness, orthographic knowledge and rapid automatized naming, with a focus on the unique joint variance of grapheme-phoneme learning to word and non-word reading achievement. Training of grapheme-phoneme associations consisted of a 20-min training program in which eight novel letters (Hebrew) needed to be paired with speech sounds taken from the participant's native language (Dutch). Eighty-four third grade students, of whom 20 were diagnosed with dyslexia, participated in the training and testing. Our results indicate a reduced ability of dyslexic readers in applying newly learned grapheme-phoneme correspondences while reading words which consist of these novel letters. However, we did not observe a significant independent contribution of grapheme-phoneme learning to reading outcomes. Alternatively, results from the regression analysis indicate that failure to read may be due to differences in phonological and/or orthographic knowledge but not to differences in the grapheme-phoneme-conversion process itself.
C1 [Law, Jeremy M.] Univ Glasgow, Sch Interdisciplinary Studies, Glasgow, Lanark, Scotland.
   [Law, Jeremy M.; De Vos, Astrid; Vanderauwera, Jolijn; Ghesquiere, Pol] Katholieke Univ Leuven, Parenting & Special Educ Res Unit, Leuven, Belgium.
   [De Vos, Astrid; Vanderauwera, Jolijn; Wouters, Jan; Vandermosten, Maaike] Katholieke Univ Leuven, Lab Expt ORL, Leuven, Belgium.
RP Law, JM (corresponding author), Univ Glasgow, Sch Interdisciplinary Studies, Glasgow, Lanark, Scotland.; Law, JM (corresponding author), Katholieke Univ Leuven, Parenting & Special Educ Res Unit, Leuven, Belgium.
EM jeremy.law@glasgow.ac.uk
RI Ghesquiere, Pol/B-9226-2009; Vandermosten, Maaike/AAC-2979-2021;
   Wouters, Jan/D-1800-2015
OI Ghesquiere, Pol/0000-0001-9056-7550; Vandermosten,
   Maaike/0000-0002-9928-1580; Wouters, Jan/0000-0002-0093-698X; law,
   Jeremy/0000-0001-6075-2384
FU Maaike Vandermosten - Research Foundation Flanders (FWO)FWO; DBOF of the
   Research Council of KU Leuven (KU Leuven) [DBOF/12/014]; KU Leuven
   Research CouncilKU Leuven [OT/12/044]
FX This research was supported by postdoctoral grant of Maaike
   Vandermosten, funded by Research Foundation Flanders (FWO). Additional
   support was provided by the DBOF of the Research Council of KU Leuven
   (KU Leuven-DBOF/12/014) and KU Leuven Research Council OT/12/044.
CR Aravena S, 2018, J LEARN DISABIL-US, V51, P552, DOI 10.1177/0022219417715407
   Aravena S, 2013, J EXP CHILD PSYCHOL, V115, P691, DOI 10.1016/j.jecp.2013.03.009
   Bekebrede J, 2010, SCI STUD READ, V14, P183, DOI 10.1080/10888430903117500
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blomert L, 2009, 3DM DIFFERENTIAL DIA
   Blomert L, 2011, NEUROIMAGE, V57, P695, DOI 10.1016/j.neuroimage.2010.11.003
   Blomert L, 2010, DYSLEXIA, V16, P300, DOI 10.1002/dys.405
   Boets B, 2007, BRAIN LANG, V101, P19, DOI 10.1016/j.bandl.2006.06.009
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Boets B, 2010, BRIT J DEV PSYCHOL, V28, P5, DOI 10.1348/026151010X485223
   Boros M, 2016, NEUROIMAGE, V128, P316, DOI 10.1016/j.neuroimage.2016.01.014
   Brus B, 1999, MINUUT TEST VORM B E
   Castles A, 2004, COGNITION, V91, P77, DOI 10.1016/S0010-0277(03)00164-1
   Cavalli E, 2017, ANN DYSLEXIA, V67, P63, DOI 10.1007/s11881-016-0138-y
   Clayton FJ, 2018, SCI STUD READ, V22, P137, DOI 10.1080/10888438.2017.1390754
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Evers A., 2009, COTAN DOCUMENTATIE
   Froyen D, 2011, DEVELOPMENTAL SCI, V14, P635, DOI 10.1111/j.1467-7687.2010.01007.x
   Froyen DJW, 2009, J COGNITIVE NEUROSCI, V21, P567, DOI 10.1162/jocn.2009.21061
   Hair J. F., 1998, MULTIVARIATE DATA AN
   Hecht SA, 2001, J EXP CHILD PSYCHOL, V79, P192, DOI 10.1006/jecp.2000.2586
   Holloway I. D., 2013, CEREB CORTEX, V25, P1544, DOI DOI 10.1093/CERC0R/BHT347
   IBM Corp, 2011, IBM SPSS STAT WIND V
   Karipidis II, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24909-8
   Kort W., 2005, WISC 3 NL WECHSLER I
   Krishnan S, 2016, TRENDS COGN SCI, V20, P701, DOI 10.1016/j.tics.2016.06.012
   Law JM, 2018, APPL PSYCHOLINGUIST, V39, P483, DOI 10.1017/S0142716417000467
   Law JM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12453
   Law JM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00124
   Law JM, 2015, DYSLEXIA, V21, P254, DOI 10.1002/dys.1495
   Litt RA, 2014, J MEM LANG, V71, P71, DOI 10.1016/j.jml.2013.10.005
   Nash HM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12423
   Pennington BF, 2001, CHILD DEV, V72, P816, DOI 10.1111/1467-8624.00317
   Peterson RL, 2015, ANNU REV CLIN PSYCHO, V11, P283, DOI 10.1146/annurev-clinpsy-032814-112842
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Schmalz X, 2017, ANN DYSLEXIA, V67, P147, DOI 10.1007/s11881-016-0136-0
   Shaywitz BA, 2002, BIOL PSYCHIAT, V52, P101, DOI 10.1016/S0006-3223(02)01365-3
   Shaywitz BA, 2007, ANN NEUROL, V61, P363, DOI 10.1002/ana.21093
   Snowling M., 2000, DYSLEXIA
   Snowling MJ, 2016, PSYCHOL BULL, V142, P498, DOI 10.1037/bul0000037
   Tabachnick B. G., 2001, USING MULTIVARIATE S
   Thiebaut de Schotten M, 2014, CEREB CORTEX, V24, P989, DOI 10.1093/cercor/bhs383
   Torppa M, 2010, J LEARN DISABIL-US, V43, P308, DOI 10.1177/0022219410369096
   Turkeltaub PE, 2003, NAT NEUROSCI, V6, P767, DOI 10.1038/nn1065
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   van den Bos K.P., 1994, KLEPEL VORM A B TEST
   van den Bos KP, 2002, SCI STUD READ, V6, P25, DOI DOI 10.1207/S1532799XSSR0601_02
   Vandermosten M, 2019, SCI STUD READ, V23, P116, DOI 10.1080/10888438.2018.1473404
   Vanvooren S, 2017, RES DEV DISABIL, V70, P138, DOI 10.1016/j.ridd.2017.09.005
   Velvis M. H, 1998, THESIS
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
   Ziegler JC, 2010, DEVELOPMENTAL SCI, V13, pF8, DOI 10.1111/j.1467-7687.2010.00983.x
NR 55
TC 4
Z9 4
U1 0
U2 16
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD AUG 15
PY 2018
VL 9
AR 1393
DI 10.3389/fpsyg.2018.01393
PG 10
WC Psychology, Multidisciplinary
SC Psychology
GA GQ4IL
UT WOS:000441634300001
PM 30158886
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Proverbio, AM
   Raso, G
   Zani, A
AF Proverbio, Alice Mado
   Raso, Giulia
   Zani, Alberto
TI Electrophysiological Indexes of Incongruent Audiovisual Phonemic
   Processing: Unraveling the McGurk Effect
SO NEUROSCIENCE
LA English
DT Article
DE language; ERP; illusion; audiovisual; incongruence; MMN
ID MULTISENSORY SPEECH-PERCEPTION; MISMATCH NEGATIVITY;
   FUNCTIONAL-ORGANIZATION; VISUAL INFORMATION; TEMPORAL REGIONS; SEEING
   VOICES; HEARING LIPS; INTEGRATION; FMRI; ACTIVATION
AB In this study the timing of electromagnetic signals recorded during incongruent and congruent audiovisual (AV) stimulation in 14 Italian healthy volunteers was examined. In a previous study (Proverbio et al., 2016) we investigated the McGurk effect in the Italian language and found out which visual and auditory inputs provided the most compelling illusory effects (e.g., bilabial phonemes presented acoustically and paired with non-labials, especially alveolar-nasal and velar-occlusive phonemes). In this study EEG was recorded from 128 scalp sites while participants observed a female and a male actor uttering 288 syllables selected on the basis of the previous investigation (lasting approximately 600 ms) and responded to rare targets (/re/, /ri/, /ro/,/ru/). In half of the cases the AV information was incongruent, except for targets that were always congruent. A pMMN (phonological Mismatch Negativity) to incongruent AV stimuli was identified 500 ms after voice onset time. This automatic response indexed the detection of an incongruity between the labial and phonetic information. SwLORETA (Low-Resolution Electromagnetic Tomography) analysis applied to the difference voltage incongruent-congruent in the same time window revealed that the strongest sources of this activity were the right superior temporal (STG) and superior frontal gyri, which supports their involvement in AV integration. (C) 2018 IBRO. Published by Elsevier Ltd. All rights reserved.
C1 [Proverbio, Alice Mado; Raso, Giulia] Univ Milano Bicocca, Dept Psychol, Neuromi Ctr Neurosci, Milan, Italy.
   [Zani, Alberto] CNR, IBFM, Milan Res Area 3, Rome, Italy.
RP Proverbio, AM (corresponding author), Univ Milano Bicocca, Dept Psychol, Neuromi Ctr Neurosci, Milan, Italy.; Proverbio, AM (corresponding author), Univ Milano Bicocca, Dept Psychol, Piazza Ateneo Nuovo 1, I-20126 Milan, Italy.
EM mado.proverbio@unimib.it
RI Zani, Alberto/ABI-3498-2020; Zani, Alberto/ABG-8894-2020
OI Zani, Alberto/0000-0002-3906-7988; 
FU University of Milano-Bicocca [15,296 2016-ATE-0058]
FX This work was supported by 15,296 2016-ATE-0058 grant from University of
   Milano-Bicocca.
CR Alpert GF, 2008, J NEUROSCI, V28, P5344, DOI 10.1523/JNEUROSCI.5039-07.2008
   Baum SH, 2012, NEUROIMAGE, V62, P1825, DOI 10.1016/j.neuroimage.2012.05.034
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Bonda E, 1996, J NEUROSCI, V16, P3737
   Bonilha L, 2017, BRAIN, V140, P2370, DOI 10.1093/brain/awx169
   Bovo R, 2009, ACTA OTORHINOLARYNGO, V29, P203
   Buccino G, 2004, J COGNITIVE NEUROSCI, V16, P114, DOI 10.1162/089892904322755601
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1999, NEUROREPORT, V10, P2619, DOI 10.1097/00001756-199908200-00033
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Campbell R, 2001, COGNITIVE BRAIN RES, V12, P233, DOI 10.1016/S0926-6410(01)00054-4
   Cerri G, 2015, HUM BRAIN MAPP, V36, P1010, DOI 10.1002/hbm.22682
   Chen TH, 2004, PERCEPT PSYCHOPHYS, V66, P820, DOI 10.3758/BF03194976
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   CONNOLLY JF, 1992, BRAIN LANG, V43, P1, DOI 10.1016/0093-934X(92)90018-A
   CONNOLLY JF, 1995, ELECTROEN CLIN NEURO, V94, P276, DOI 10.1016/0013-4694(95)98479-R
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Czigler I, 2010, ADV CONSC RES, V78, P1, DOI 10.1075/aicr.78
   Desai R, 2008, J COGNITIVE NEUROSCI, V20, P1174, DOI 10.1162/jocn.2008.20081
   Elmer S, 2013, CORTEX, V49, P2812, DOI 10.1016/j.cortex.2013.03.007
   Engel GR, 1971, NATURE, V3, P234
   Eskelund K, 2015, NEUROPSYCHOLOGIA, V66, P48, DOI 10.1016/j.neuropsychologia.2014.10.021
   Ethofer T, 2013, NEUROIMAGE, V76, P45, DOI 10.1016/j.neuroimage.2013.02.064
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Gentilucci M, 2005, EXP BRAIN RES, V167, P66, DOI 10.1007/s00221-005-0008-z
   Green KP, 1997, J SPEECH LANG HEAR R, V40, P646, DOI 10.1044/jslhr.4003.646
   Grill-Spector K, 2004, NAT NEUROSCI, V7, P555, DOI 10.1038/nn1224
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hagan CC, 2009, P NATL ACAD SCI USA, V106, P20010, DOI 10.1073/pnas.0905792106
   Hasson U, 2007, NEURON, V56, P1116, DOI 10.1016/j.neuron.2007.09.037
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Kumar GV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01558
   Lam K, 1999, CLIN NEUROPHYSIOL, V110, P295, DOI 10.1016/S0168-5597(98)00059-8
   Liebenthal E, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00289
   Macaluso E, 2004, NEUROIMAGE, V21, P725, DOI 10.1016/j.neuroimage.2003.09.049
   Massaro D. W., 1998, PERCEIVING TALKING F, V1
   Matchin W, 2014, J COGNITIVE NEUROSCI, V26, P606, DOI 10.1162/jocn_a_00515
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MIDDELWEERD MJ, 1987, J ACOUST SOC AM, V82, P2145, DOI 10.1121/1.395659
   Moris Fernandez L, 2017, HUM BRAIN MAPP, V38, P1
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1995, EAR HEARING, V16, P6
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091
   Orr JM, 2009, CEREB CORTEX, V19, P703, DOI 10.1093/cercor/bhn119
   Palmero-Soler E, 2007, PHYS MED BIOL, V52, P1783, DOI 10.1088/0031-9155/52/7/002
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   PASCUALMARQUI RD, 1994, INT J PSYCHOPHYSIOL, V18, P49, DOI 10.1016/0167-8760(84)90014-X
   Pekkola J, 2006, NEUROIMAGE, V29, P797, DOI 10.1016/j.neuroimage.2005.09.069
   Picton TW, 2000, PSYCHOPHYSIOLOGY, V37, P127, DOI 10.1111/1469-8986.3720127
   Pratt H, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.407
   Proverbio AM, 2010, NEUROPSYCHOLOGY OF COMMUNICATION, P61
   Proverbio AM, 2017, NEUROSCIENCE, V346, P309, DOI 10.1016/j.neuroscience.2017.01.030
   Proverbio AM, 2014, SCI REP-UK, V4, DOI 10.1038/srep05866
   Proverbio AM, 2011, SCI REP-UK, V1, DOI 10.1038/srep00054
   Proverbio AM, 2016, SCI REP, V6, P30
   Puce A, 1998, J NEUROSCI, V18, P2188
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004
   Romero YR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00041
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Shams L, 2002, COGNITIVE BRAIN RES, V14, P147, DOI 10.1016/S0926-6410(02)00069-1
   Shao HY, 2017, NEUROIMAGE, V157, P129, DOI 10.1016/j.neuroimage.2017.05.061
   Skipper JI, 2006, ACTION TO LANGUAGE VIA THE MIRROR NEURON SYSTEM, P250, DOI 10.1017/CBO9780511541599.009
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stein E. B., 1993, MERGING SENSES
   Stekelenburg JJ, 2012, NEUROPSYCHOLOGIA, V50, P1425, DOI 10.1016/j.neuropsychologia.2012.02.027
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Wang YP, 2007, NEUROIMAGE, V35, P862, DOI 10.1016/j.neuroimage.2006.09.054
   Watson R, 2014, CORTEX, V50, P125, DOI 10.1016/j.cortex.2013.07.011
   Wegrzyn M, 2017, CORTEX, V96, P31, DOI 10.1016/j.cortex.2017.08.018
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Zampini M, 2005, PERCEPT PSYCHOPHYS, V67, P531, DOI 10.3758/BF03193329
   Zani A., 2003, COGNITIVE ELECTROPHY
   Zanow F, 2004, BRAIN TOPOGR, V16, P287
   Zerouali Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060128
NR 82
TC 7
Z9 7
U1 3
U2 12
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0306-4522
EI 1873-7544
J9 NEUROSCIENCE
JI Neuroscience
PD AUG 10
PY 2018
VL 385
BP 215
EP 226
DI 10.1016/j.neuroscience.2018.06.021
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA GM6VW
UT WOS:000438316600018
PM 29932985
DA 2021-02-24
ER

PT J
AU Holmes, E
   Kitterick, PT
   Summerfield, AQ
AF Holmes, Emma
   Kitterick, Padraig T.
   Summerfield, A. Quentin
TI Cueing listeners to attend to a target talker progressively improves
   word report as the duration of the cue-target interval lengthens to
   2,000 ms
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Attention: Selective; Audition; Speech perception
ID VISUALLY-GUIDED ATTENTION; HEARING-LOSS; SELECTIVE ATTENTION;
   RECEPTIVE-FIELDS; REACTION-TIME; SPEECH; SYNCHRONIZATION; OSCILLATIONS;
   INFORMATION; SUPPRESSION
AB Endogenous attention is typically studied by presenting instructive cues in advance of a target stimulus array. For endogenous visual attention, task performance improves as the duration of the cue-target interval increases up to 800 ms. Less is known about how endogenous auditory attention unfolds over time or the mechanisms by which an instructive cue presented in advance of an auditory array improves performance. The current experiment used five cue-target intervals (0, 250, 500, 1,000, and 2,000 ms) to compare four hypotheses for how preparatory attention develops over time in a multi-talker listening task. Young adults were cued to attend to a target talker who spoke in a mixture of three talkers. Visual cues indicated the target talker's spatial location or their gender. Participants directed attention to location and gender simultaneously ("objects") at all cue-target intervals. Participants were consistently faster and more accurate at reporting words spoken by the target talker when the cue-target interval was 2,000 ms than 0 ms. In addition, the latency of correct responses progressively shortened as the duration of the cue-target interval increased from 0 to 2,000 ms. These findings suggest that the mechanisms involved in preparatory auditory attention develop gradually over time, taking at least 2,000 ms to reach optimal configuration, yet providing cumulative improvements in speech intelligibility as the duration of the cue-target interval increases from 0 to 2,000 ms. These results demonstrate an improvement in performance for cue-target intervals longer than those that have been reported previously in the visual or auditory modalities.
C1 [Holmes, Emma; Summerfield, A. Quentin] Univ York, Dept Psychol, York, N Yorkshire, England.
   [Holmes, Emma] Western Univ, Brain & Mind Inst, Ctr Nat Sci, Room 120, London, ON N6A 5B7, Canada.
   [Kitterick, Padraig T.] NIHR Nottingham Hearing Biomed Res Unit, Nottingham, England.
   [Kitterick, Padraig T.] Univ Nottingham, Sch Med, Div Clin Neurosci, Nottingham, England.
   [Summerfield, A. Quentin] Univ York, Hull York Med Sch, York, N Yorkshire, England.
RP Holmes, E (corresponding author), Univ York, Dept Psychol, York, N Yorkshire, England.; Holmes, E (corresponding author), Western Univ, Brain & Mind Inst, Ctr Nat Sci, Room 120, London, ON N6A 5B7, Canada.
EM eholme5@uwo.ca
RI Holmes, Emma/H-8494-2019
OI Holmes, Emma/0000-0002-0314-6588; Kitterick, Padraig/0000-0001-8383-5318
FU Goodricke Appeal Fund
FX This work was supported by a studentship from the Goodricke Appeal Fund
   to EH.
CR Anton-Erxleben K, 2009, CEREB CORTEX, V19, P2466, DOI 10.1093/cercor/bhp002
   Best V, 2007, JARO-J ASSOC RES OTO, V8, P294, DOI 10.1007/s10162-007-0073-z
   Best V, 2009, JARO-J ASSOC RES OTO, V10, P142, DOI 10.1007/s10162-008-0146-7
   Brungart DS, 2007, PERCEPT PSYCHOPHYS, V69, P79, DOI 10.3758/BF03194455
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2002, J ACOUST SOC AM, V112, P2985, DOI 10.1121/1.1512703
   Chawla D, 1999, NAT NEUROSCI, V2, P671, DOI 10.1038/10230
   CHEAL ML, 1992, ACTA PSYCHOL, V81, P243, DOI 10.1016/0001-6918(92)90020-E
   Chennu S, 2013, J NEUROSCI, V33, P11194, DOI 10.1523/JNEUROSCI.0114-13.2013
   Clayton MS, 2015, TRENDS COGN SCI, V19, P188, DOI 10.1016/j.tics.2015.02.004
   Corbetta M, 2008, NEURON, V58, P306, DOI 10.1016/j.neuron.2008.04.017
   Darwin CJ, 2006, INT J AUDIOL, V45, pS20, DOI 10.1080/14992020600782592
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Duncan J, 2006, Q J EXP PSYCHOL, V59, P2, DOI 10.1080/17470210500260674
   Engel AK, 2001, TRENDS COGN SCI, V5, P16, DOI 10.1016/S1364-6613(00)01568-0
   Ericson MA, 2004, INT J AVIAT PSYCHOL, V14, P313, DOI 10.1207/s15327108ijap1403_6
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Fries P, 2001, SCIENCE, V291, P1560, DOI 10.1126/science.1055465
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Gazzaley A, 2005, J COGNITIVE NEUROSCI, V17, P507, DOI 10.1162/0898929053279522
   Giesbrecht B, 2006, BRAIN RES, V1080, P63, DOI 10.1016/j.brainres.2005.09.068
   Giesbrecht B, 2003, NEUROIMAGE, V19, P496, DOI 10.1016/S1053-8119(03)00162-9
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Hill KT, 2010, CEREB CORTEX, V20, P583, DOI 10.1093/cercor/bhp124
   Holmes E, 2017, HEARING RES, V350, P160, DOI 10.1016/j.heares.2017.05.005
   Holmes E, 2016, HEARING RES, V336, P83, DOI 10.1016/j.heares.2016.04.007
   Ihlefeld A, 2008, J ACOUST SOC AM, V124, P2224, DOI 10.1121/1.2973185
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Jonides J., 1981, ATTENTION PERFORM, P187, DOI DOI 10.1037/0096-1523.29.5.835
   Kidd G, 2005, J ACOUST SOC AM, V118, P3804, DOI 10.1121/1.2109187
   Kitterick PT, 2010, J ACOUST SOC AM, V127, P2498, DOI 10.1121/1.3327507
   Koch I, 2011, J EXP PSYCHOL HUMAN, V37, P1140, DOI 10.1037/a0022189
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Larson E, 2013, J ACOUST SOC AM, V134, pEL165, DOI 10.1121/1.4812439
   Lee AKC, 2013, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00190
   Lu ZL, 2009, VISION RES, V49, P1081, DOI 10.1016/j.visres.2008.05.021
   Lyon D. R., 1987, QUICKLY CAN ATTENTIO
   Makela AM, 2002, NEUROIMAGE, V17, P1300, DOI 10.1006/nimg.2002.1279
   Meiran N, 2000, COGNITIVE PSYCHOL, V41, P211, DOI 10.1006/cogp.2000.0736
   Monsell S, 2000, CONTROL OF COGNITIVE PROCESSES: ATTENTION AND PERFORMANCE XVIII, P3
   Moore T.J., 1981, AGARD C P
   Nishida S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00090
   O'Connell MN, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00655
   O'Connell MN, 2014, J NEUROSCI, V34, P16496, DOI 10.1523/JNEUROSCI.2055-14.2014
   POSNER MI, 1984, ATTENTION PERFORM, V10, P531
   Prinzmetal W, 2005, J EXP PSYCHOL GEN, V134, P73, DOI 10.1037/0096-3445.134.1.73
   Richards VM, 2004, J ACOUST SOC AM, V115, P289, DOI 10.1121/1.1631942
   Ristic J, 2006, Q J EXP PSYCHOL, V59, P1921, DOI 10.1080/17470210500416367
   ROCKSTROH B, 1993, ELECTROEN CLIN NEURO, V87, P235, DOI 10.1016/0013-4694(93)90023-O
   ROGERS RD, 1995, J EXP PSYCHOL GEN, V124, P207, DOI 10.1037/0096-3445.124.2.207
   RUCHKIN DS, 1977, PSYCHOPHYSIOLOGY, V14, P451, DOI 10.1111/j.1469-8986.1977.tb01311.x
   Salminen NH, 2012, NEUROSCIENTIST, V18, P602, DOI 10.1177/1073858411434209
   Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9
   Seidl KN, 2012, J NEUROSCI, V32, P11812, DOI 10.1523/JNEUROSCI.1693-12.2012
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   SHULMAN GL, 1979, J EXP PSYCHOL HUMAN, V5, P522, DOI 10.1037/0096-1523.5.3.522
   SINGER W, 1993, ANNU REV PHYSIOL, V55, P349, DOI 10.1146/annurev.ph.55.030193.002025
   Slagter HA, 2007, BRAIN RES, V1177, P90, DOI 10.1016/j.brainres.2007.07.097
   Spence C, 1998, PERCEPT PSYCHOPHYS, V60, P125, DOI 10.3758/BF03211923
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   Treue S, 1999, NATURE, V399, P575, DOI 10.1038/21176
   TSAL Y, 1983, J EXP PSYCHOL HUMAN, V9, P523, DOI 10.1037/0096-1523.9.4.523
   van Ede F, 2012, J NEUROSCI, V32, P10408, DOI 10.1523/JNEUROSCI.1337-12.2012
   Voisin J, 2006, J NEUROSCI, V26, P273, DOI 10.1523/JNEUROSCI.2967-05.2006
   WALTER WG, 1964, NATURE, V203, P380, DOI 10.1038/203380a0
   Weston PSJ, 2015, NEUROIMAGE, V105, P208, DOI 10.1016/j.neuroimage.2014.10.056
   Woldorff MG, 2004, J COGNITIVE NEUROSCI, V16, P149, DOI 10.1162/089892904322755638
   Womelsdorf T, 2006, NAT NEUROSCI, V9, P1156, DOI 10.1038/nn1748
   YAMAGUCHI S, 1994, BRAIN, V117, P553, DOI 10.1093/brain/117.3.553
NR 71
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD AUG
PY 2018
VL 80
IS 6
BP 1520
EP 1538
DI 10.3758/s13414-018-1531-x
PG 19
WC Psychology; Psychology, Experimental
SC Psychology
GA GN9DZ
UT WOS:000439488800017
PM 29696570
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Haukedal, CL
   Torkildsen, JV
   Lyxell, B
   Wie, OB
AF Haukedal, Christiane Lingas
   Torkildsen, Janne von Koss
   Lyxell, Bjorn
   Wie, Ona Bo
TI Parents' Perception of Health-Related Quality of Life in Children With
   Cochlear Implants: The Impact of Language Skills and Hearing
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID MENTAL-HEALTH; IMPAIRED CHILDREN; DEAF; ADOLESCENTS; OUTCOMES;
   RELIABILITY; PERFORMANCE; ABILITY; SPEECH; SELF
AB Purpose: The study compared how parents of children with cochlear implants (CIs) and parents of children with normal hearing perceive their children's health-related quality of life (HR-QOL).
   Method: The sample consisted of 186 Norwegian-speaking children in the age span of 5; 0-12; 11 (years; months): 106 children with CIs (53% boys, 47% girls) and 80 children with normal hearing (44% boys, 56% girls). No children had known additional disabilities affecting language, cognitive development, or HR-QOL. Parents completed the generic questionnaire Pediatric Quality of Life Inventory (Varni, Seid, & Kurtin, 2001), whereas children completed a test battery measuring different aspects of language and hearing.
   Results: Parents of children with CIs reported statistically significantly poorer HR-QOL in their children, on Pediatric Quality of Life Inventory total score and the subdomains social functioning and school functioning. Roughly 50% of parents of children with CIs reported HR-QOL levels (total score) within normal limits. No significant differences between groups emerged on the physical health and emotional functioning subscales. For the children in the group with CIs, better speech perception in everyday situations was associated with higher proxy-ratings of HR-QOL. Better spoken language skills were weakly to moderately associated with higher HR-QOL.
   Conclusions: The findings suggest that the social and school situation is not yet resolved satisfactorily for children with CIs. Habilitation focusing on spoken language skills and better sound environment may improve social interactions with peers and overall school functioning.
C1 [Haukedal, Christiane Lingas; Torkildsen, Janne von Koss; Wie, Ona Bo] Univ Oslo, Dept Special Needs Educ, Fac Educ Sci, Oslo, Norway.
   [Lyxell, Bjorn] Linkoping Univ, Dept Behav Sci & Learning, Linnaeus Ctr, Swedish Inst Disabil Res, Linkoping, Sweden.
   [Wie, Ona Bo] Oslo Univ Hosp, Dept Otorhinolaryngol, Div Surg & Clin Neurosci, Oslo, Norway.
RP Haukedal, CL (corresponding author), Univ Oslo, Dept Special Needs Educ, Fac Educ Sci, Oslo, Norway.
EM christiane.haukedal@isp.uio.no
FU Norwegian Directorate of Health; Oslo University Hospital; University of
   Oslo
FX This research was supported by the Norwegian Directorate of Health, Oslo
   University Hospital, and the University of Oslo. We wish to thank all
   the children and parents who participated in our study. We also want to
   thank the CI-team at Oslo University Hospital and the people who helped
   collecting the data for the study: Marit Enny Gismarvik, Asrun Valberg,
   and Ellen Brinchmann.
CR American Association on Intellectual and Developmental Disabilities, 2018, INT DIS DEF CLASS SY
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Anmyr L, 2011, INT J PEDIATR OTORHI, V75, P844, DOI 10.1016/j.ijporl.2011.03.023
   BERZON R, 1993, QUAL LIFE RES, V2, P367, DOI 10.1007/BF00422214
   Birman CS, 2012, OTOL NEUROTOL, V33, P1347, DOI 10.1097/MAO.0b013e31826939cc
   Blanchfield B B, 2001, J Am Acad Audiol, V12, P183
   Boons T, 2012, ARCH PEDIAT ADOL MED, V166, P28, DOI 10.1001/archpediatrics.2011.748
   CONRAD R, 1977, BRIT J EDUC PSYCHOL, V47, P138, DOI 10.1111/j.2044-8279.1977.tb02339.x
   De Giacomo A, 2013, INT J PEDIATR OTORHI, V77, P1975, DOI 10.1016/j.ijporl.2013.09.015
   Domellof E, 2014, QUAL LIFE RES, V23, P1877, DOI 10.1007/s11136-013-0613-4
   Duarte I., 2016, SPRINGERPLUS, V5, P1
   Duarte I, 2014, ACTA OTO-LARYNGOL, V134, P881, DOI 10.3109/00016489.2014.930968
   Dunn LM., 1997, BRIT PICTURE VOCABUL, V2
   EIDE AH, 2004, HORSELSHEMMEDE ARBEI
   Eiser C, 2007, ARCH DIS CHILD, V92, P348, DOI 10.1136/adc.2005.086405
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fayers P.M., 2007, QUALITY LIFE ASSESSM
   Fellinger J, 2005, SOC PSYCH PSYCH EPID, V40, P737, DOI 10.1007/s00127-005-0936-8
   Fellinger J, 2009, ACTA PSYCHIAT SCAND, V120, P153, DOI 10.1111/j.1600-0447.2009.01350.x
   Fellinger J, 2008, EUR CHILD ADOLES PSY, V17, P414, DOI 10.1007/s00787-008-0683-y
   Fellinger J, 2009, DEV MED CHILD NEUROL, V51, P635, DOI 10.1111/j.1469-8749.2008.03218.x
   Field A., 2013, DISCOVERING STAT USI
   Fulcher A, 2012, INT J PEDIATR OTORHI, V76, P1785, DOI 10.1016/j.ijporl.2012.09.001
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Geers AE, 2002, LANG SPEECH HEAR SER, V33, DOI 10.1044/0161-1461(2002/015)
   Hendar O., 2012, ELEVER MED HORSELSHE
   Hintermair M, 2011, J DEAF STUD DEAF EDU, V16, P254, DOI 10.1093/deafed/enq045
   Hoffmeister RJ, 2014, COGNITION, V132, P229, DOI 10.1016/j.cognition.2014.03.014
   Huber M, 2005, INT J PEDIATR OTORHI, V69, P1089, DOI 10.1016/j.ijporl.2005.02.018
   Huber M, 2008, INT J PEDIATR OTORHI, V72, P1393, DOI 10.1016/j.ijporl.2008.06.002
   Huber M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00953
   Huber M, 2011, INT J AUDIOL, V50, P146, DOI 10.3109/14992027.2010.533704
   Kirman A, 2013, INT J NURS PRACT, V19, P233, DOI 10.1111/ijn.12071
   Korver AMH, 2010, JAMA-J AM MED ASSOC, V304, P1701, DOI 10.1001/jama.2010.1501
   Kumar R, 2015, EAR HEARING, V36, P269, DOI 10.1097/AUD.0000000000000108
   KUYKEN W, 1995, SOC SCI MED, V41, P1403, DOI 10.1016/0277-9536(95)00112-k
   Kvam MH, 2007, J DEAF STUD DEAF EDU, V12, P1, DOI 10.1093/deafed/enl015
   Leigh G, 2015, J DEAF STUD DEAF EDU, V20, P331, DOI 10.1093/deafed/env028
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   Lin FR, 2006, INT J PEDIATR OTORHI, V70, P1695, DOI 10.1016/j.ijporl.2006.05.009
   Lofkvist U, 2014, INT J PEDIATR OTORHI, V78, P253, DOI 10.1016/j.ijporl.2013.11.017
   Lovett RES, 2010, ARCH DIS CHILD, V95, P107, DOI 10.1136/adc.2009.160325
   Loy B, 2010, OTOLARYNG HEAD NECK, V142, P247, DOI 10.1016/j.otohns.2009.10.045
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   Lyster S.-A. H., 2010, SPESIALPEDAGOGIKK, V9, P35
   Lyxell B, 2008, INT J AUDIOL, V47, pS47, DOI 10.1080/14992020802307370
   Manrique M, 2004, ACTA OTO-LARYNGOL, V124, P55, DOI 10.1080/03655230410017148
   Matza LS, 2004, VALUE HEALTH, V7, P79, DOI 10.1111/j.1524-4733.2004.71273.x
   Meserole RL, 2014, QUAL LIFE RES, V23, P721, DOI 10.1007/s11136-013-0509-3
   Morettin M, 2013, BRAZ J OTORHINOLAR, V79, P382, DOI 10.5935/1808-8694.20130066
   Myhrum M, 2016, EAR HEARING, V37, P80, DOI 10.1097/AUD.0000000000000224
   Necula V, 2013, INT J PEDIATR OTORHI, V77, P216, DOI 10.1016/j.ijporl.2012.10.026
   Oygarden J, 2009, THESIS
   Percy-Smith Lone, 2008, Cochlear Implants Int, V9, P199, DOI 10.1179/cim.2008.9.4.199
   Perez-Mora R, 2012, B-ENT, V8, P251
   Petrou S, 2007, PEDIATRICS, V120, P1044, DOI 10.1542/peds.2007-0159
   Rachakonda T, 2014, LARYNGOSCOPE, V124, P570, DOI 10.1002/lary.24336
   Rajendran V, 2010, ITAL J PEDIATR, V36, DOI 10.1186/1824-7288-36-75
   Raven J, 2004, COLOURED PROGR MATRI
   Raven J. C., 2008, STANDARD PROGR MATRI
   Razafimahefa-Raoelina T, 2016, EUR ANN OTORHINOLARY, V133, P31, DOI 10.1016/j.anorl.2015.10.002
   Reinfjell T, 2006, HEALTH QUAL LIFE OUT, V4, DOI 10.1186/1477-7525-4-61
   Roland L, 2016, OTOLARYNG HEAD NECK, V155, P208, DOI 10.1177/0194599816640485
   Saebo S. R., 2016, SPESIALPEDAGOGIKK, V4, P55
   Sahli S, 2009, INT J PEDIATR OTORHI, V73, P1774, DOI 10.1016/j.ijporl.2009.09.027
   Schick B, 2013, J DEAF STUD DEAF EDU, V18, P47, DOI 10.1093/deafed/ens039
   Schorr EA, 2009, J SPEECH LANG HEAR R, V52, P141, DOI 10.1044/1092-4388(2008/07-0213)
   Semel E. M., 2003, CLIN EVALUATION LANG
   Spencer LJ, 2012, J DEAF STUD DEAF EDU, V17, P483, DOI 10.1093/deafed/ens024
   Stacey PC, 2006, EAR HEARING, V27, P161, DOI 10.1097/01.aud.0000202353.37567.b4
   Stach B., 2010, CLIN AUDIOLOGY INTRO
   Szagun G, 2012, J SPEECH LANG HEAR R, V55, P1640, DOI 10.1044/1092-4388(2012/11-0119)
   Theunissen SCPM, 2015, EAR HEARING, V36, pe190, DOI 10.1097/AUD.0000000000000147
   Theunissen SCPM, 2012, LARYNGOSCOPE, V122, P654, DOI 10.1002/lary.22502
   Theunissen SCPM, 2011, INT J PEDIATR OTORHI, V75, P1313, DOI 10.1016/j.ijporl.2011.07.023
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Upton P, 2008, QUAL LIFE RES, V17, P895, DOI 10.1007/s11136-008-9350-5
   Van Eldik T, 2005, AM ANN DEAF, V150, P11, DOI 10.1353/aad.2005.0024
   van Wieringen A, 2015, HEARING RES, V322, P171, DOI 10.1016/j.heares.2014.09.002
   Varni JW, 2007, HEALTH QUAL LIFE OUT, V5, DOI 10.1186/1477-7525-5-2
   Varni JW, 2003, AMBUL PEDIATR, V3, P329, DOI 10.1367/1539-4409(2003)003<0329:TPAAPP>2.0.CO;2
   Varni JW, 2001, MED CARE, V39, P800, DOI 10.1097/00005650-200108000-00006
   Wake M, 2004, AMBUL PEDIATR, V4, P411, DOI 10.1367/A03-191R.1
   Wake M, 2004, EAR HEARING, V25, P1, DOI 10.1097/01.AUD.0000111262.12219.2F
   Warner-Czyz AD, 2009, INT J PEDIATR OTORHI, V73, P1423, DOI 10.1016/j.ijporl.2009.07.009
   Wie OB, 2010, INT J PEDIATR OTORHI, V74, P1258, DOI 10.1016/j.ijporl.2010.07.026
   Wie OB, 2007, INT J AUDIOL, V46, P232, DOI 10.1080/14992020601182891
   Woodcock K, 2008, INT J REHABIL RES, V31, P297, DOI 10.1097/MRR.0b013e3282fb7d4d
   World Health Organization, 1948, CONST WORLD HLTH ORG
   Zaidman-Zait A, 2017, EAR HEARING, V38, P399, DOI 10.1097/AUD.0000000000000410
NR 91
TC 8
Z9 8
U1 0
U2 6
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD AUG
PY 2018
VL 61
IS 8
DI 10.1044/2018_JSLHR-H-17-0278
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GU0YI
UT WOS:000444980200015
PM 30046806
OA Green Published
DA 2021-02-24
ER

PT J
AU Feng, L
   Oxenham, AJ
AF Feng, Lei
   Oxenham, Andrew J.
TI Auditory enhancement and the role of spectral resolution in
   normal-hearing listeners and cochlear-implant users
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID MASKED EXCITATION PATTERNS; SPATIAL TUNING CURVES; CHANNEL INTERACTION;
   ELECTRICAL-STIMULATION; ELECTRODE CONFIGURATION; SPEECH-PERCEPTION;
   MASKING; LOUDNESS; COMPONENTS; ADAPTATION
AB Detection of a target tone in a simultaneous multi-tone masker can be improved by preceding the stimulus with the masker alone. The mechanisms underlying this auditory enhancement effect may enable the efficient detection of new acoustic events and may help to produce perceptual constancy under varying acoustic conditions. Previous work in cochlear-implant (CI) users has suggested reduced or absent enhancement, due perhaps to poor spatial resolution in the cochlea. This study used a supra-threshold enhancement paradigm that in normal-hearing listeners results in large enhancement effects, exceeding 20 dB. Results from vocoder simulations using normal-hearing listeners showed that near-normal enhancement was observed if the simulated spread of excitation was limited to spectral slopes no shallower than 24 dB/oct. No significant enhancement was observed on average in CI users with their clinical monopolar stimulation strategy. The variability in enhancement between CI users, and between electrodes in a single CI user, could not be explained by the spread of excitation, as estimated from auditory nerve evoked potentials. Enhancement remained small, but did reach statistical significance, under the narrower partialtripolar stimulation strategy. The results suggest that enhancement may be at least partially restored by improvements in the spatial resolution of current CIs. (C) 2018 Acoustical Society of America.
C1 [Feng, Lei; Oxenham, Andrew J.] Univ Minnesota, Dept Psychol, N218 Elliott Hall,75 East River Pkwy, Minneapolis, MN 55455 USA.
RP Feng, L (corresponding author), Univ Minnesota, Dept Psychol, N218 Elliott Hall,75 East River Pkwy, Minneapolis, MN 55455 USA.
EM fengl@umn.edu
OI Oxenham, Andrew/0000-0002-9365-1157
FU National Institute of Health (NIDCD)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD) [R01
   DC012262]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC012262, R01DC012262,
   R01DC012262, R01DC012262, R01DC012262, R01DC012262, R01DC012262,
   R01DC012262, R01DC012262] Funding Source: NIH RePORTER
FX This research was supported by National Institute of Health (NIDCD Grant
   No. R01 DC012262). The authors thank Heather Kreft for assistance with
   subject recruitment and Dr. Michelle Hughes for advice on ECAP
   recordings. The authors also wish to extend thanks to the subjects who
   participated in this study.
CR Abbas PJ, 2004, AUDIOL NEURO-OTOL, V9, P203, DOI 10.1159/000078390
   Abbas PJ, 1999, EAR HEARING, V20, P45, DOI 10.1097/00003446-199902000-00005
   Anderson ES, 2011, J ACOUST SOC AM, V130, P364, DOI 10.1121/1.3589255
   Barlow H. B., 1961, SENS COMMUN, P217, DOI [10.7551/mitpress/9780262518420.003.0002, DOI 10.7551/MITPRESS/9780262518420.003.0013, 10.7551/mitpress/9780262518420.003.0013]
   Bierer JA, 2002, J NEUROPHYSIOL, V87, P478, DOI 10.1152/jn.00212.2001
   Bierer JA, 2015, TRENDS HEAR, V19, DOI 10.1177/2331216515569792
   Bierer JA, 2007, J ACOUST SOC AM, V121, P1642, DOI 10.1121/1.2436712
   Bierer JA, 2010, EAR HEARING, V31, P247, DOI 10.1097/AUD.0b013e3181c7daf4
   Bingabr M, 2008, HEARING RES, V241, P73, DOI 10.1016/j.heares.2008.04.012
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Byrne AJ, 2013, J ACOUST SOC AM, V134, P2631, DOI 10.1121/1.4820897
   Byrne AJ, 2011, J ACOUST SOC AM, V129, P2088, DOI 10.1121/1.3552880
   Carcagno S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067874
   Carcagno S, 2012, JARO-J ASSOC RES OTO, V13, P693, DOI 10.1007/s10162-012-0339-y
   Carlyon RP, 2007, JARO-J ASSOC RES OTO, V8, P119, DOI 10.1007/s10162-006-0068-1
   CARLYON RP, 1989, HEARING RES, V41, P223, DOI 10.1016/0378-5955(89)90014-2
   Chatterjee M, 2006, JARO-J ASSOC RES OTO, V7, P15, DOI 10.1007/s10162-005-0019-2
   Chatterjee M, 1998, J ACOUST SOC AM, V103, P2565, DOI 10.1121/1.422777
   Cohen LT, 2003, HEARING RES, V179, P72, DOI 10.1016/S0378-5955(03)00096-0
   Dean I, 2005, NAT NEUROSCI, V8, P1684, DOI 10.1038/nn1541
   Demany L, 2005, J ACOUST SOC AM, V117, P833, DOI 10.1121/1.1850209
   Erviti M, 2011, J ACOUST SOC AM, V129, P3837, DOI 10.1121/1.3589257
   Ewert S. D, 2013, I C AC AIA DAGA, P1326
   Feng L, 2015, J EXP PSYCHOL HUMAN, V41, P1696, DOI 10.1037/xhp0000115
   Finley CC, 2008, OTOL NEUROTOL, V29, P920, DOI 10.1097/MAO.0b013e318184f492
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Goupell MJ, 2012, J ACOUST SOC AM, V131, P1007, DOI 10.1121/1.3672650
   Gregg MK, 2012, NEUROIMAGE, V62, P113, DOI 10.1016/j.neuroimage.2012.04.057
   HARRIS DM, 1979, J NEUROPHYSIOL, V42, P1083
   Hartmann WM, 2006, J ACOUST SOC AM, V120, P2142, DOI 10.1121/1.2228476
   Henry BA, 2003, J ACOUST SOC AM, V113, P2861, DOI 10.1121/1.1561900
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Hughes ML, 2008, EAR HEARING, V29, P435, DOI 10.1097/AUD.0b013e31816a0d3d
   Hughes ML, 2009, J ACOUST SOC AM, V125, P247, DOI 10.1121/1.3035842
   Hughes ML, 2006, J ACOUST SOC AM, V119, P1538, DOI 10.1121/1.2164969
   Kawano A, 1998, ACTA OTO-LARYNGOL, V118, P313
   Ketten DR, 1998, ANN OTO RHINOL LARYN, V107, P1
   Kreft HA, 2017, JARO-J ASSOC RES OTO, V18, P483, DOI 10.1007/s10162-017-0618-8
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Landsberger DM, 2012, HEARING RES, V284, P16, DOI 10.1016/j.heares.2011.12.009
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Litvak LM, 2007, J ACOUST SOC AM, V122, P967, DOI 10.1121/1.2749414
   Lu T, 2011, J ACOUST SOC AM, V129, P3934, DOI 10.1121/1.3570948
   MacMillan NA, 1991, DETECTION THEORY USE
   Marrufo-Perez MI, 2018, J NEUROSCI, V38, P4138, DOI 10.1523/JNEUROSCI.0024-18.2018
   Mehta AH, 2017, JARO-J ASSOC RES OTO, V18, P789, DOI 10.1007/s10162-017-0632-x
   Nelson DA, 2011, J ACOUST SOC AM, V129, P3916, DOI 10.1121/1.3583503
   Oxenham AJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514553783
   Rabinowitz NC, 2011, NEURON, V70, P1178, DOI 10.1016/j.neuron.2011.04.030
   Richards VM, 2004, J ACOUST SOC AM, V116, P2278, DOI 10.1121/1.1784433
   SHANNON RV, 1983, HEARING RES, V12, P1, DOI 10.1016/0378-5955(83)90115-6
   Stevens Kenneth N., 2000, ACOUSTIC PHONETICS
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   SUMMERFIELD Q, 1987, J ACOUST SOC AM, V81, P700, DOI 10.1121/1.394838
   Viemeister N. F., 1980, PSYCHOPHYSICAL PHYSL, P190, DOI DOI 10.1007/978-94-009-9144-6_28
   Viemeister NF, 2013, ADV EXP MED BIOL, V787, P167, DOI 10.1007/978-1-4614-1590-9_19
   VIEMEISTER NF, 1982, J ACOUST SOC AM, V71, P1502, DOI 10.1121/1.387849
   Wang NY, 2016, JARO-J ASSOC RES OTO, V17, P383, DOI 10.1007/s10162-016-0563-y
   Wang NY, 2016, HEARING RES, V333, P150, DOI 10.1016/j.heares.2016.01.012
   Wang NY, 2015, JARO-J ASSOC RES OTO, V16, P535, DOI 10.1007/s10162-015-0523-y
   Wang NY, 2012, J ACOUST SOC AM, V131, pEL421, DOI 10.1121/1.4710838
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WRIGHT BA, 1993, J ACOUST SOC AM, V94, P72, DOI 10.1121/1.408215
NR 63
TC 7
Z9 7
U1 1
U2 7
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD AUG
PY 2018
VL 144
IS 2
BP 552
EP 566
DI 10.1121/1.5048414
PG 15
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GS4MV
UT WOS:000443620700014
PM 30180692
OA Green Published
DA 2021-02-24
ER

PT J
AU Stack, CMH
   James, A
   Watson, DG
AF Stack, Caoimhe M. Harrington
   James, Ariel N.
   Watson, Duane G.
TI A failure to replicate rapid syntactic adaptation in comprehension
SO MEMORY & COGNITION
LA English
DT Article
DE Sentence processing; Syntax; Adaptation; Replication
ID AMBIGUITY RESOLUTION; SPEECH-PERCEPTION; MECHANICAL TURK; EXPECTATION;
   CONSTRAINTS; PREDICTION; EXPERIENCE; REPETITION; SENTENCES; FEEDBACK
AB Language comprehension requires successfully navigating linguistic variability. One hypothesis for how listeners manage variability is that they rapidly update their expectations of likely linguistic events in new contexts. This process, called adaptation, allows listeners to better predict the upcoming linguistic input. In previous work, Fine, Jaeger, Farmer, and Qian (PLoS ONE, 8, e77661, 2013) found evidence for syntactic adaptation. Subjects repeatedly encountered sentences in which a verb was temporarily ambiguous between main verb (MV) and reduced relative clause (RC) interpretations. They found that subjects who had higher levels of exposure to the unexpected RC interpretation of the sentences had an easier time reading the RC sentences but a more difficult time reading the MV sentences. They concluded that syntactic adaptation occurs rapidly in unexpected structures and also results in difficulty with processing the previously expected alternative structures. This article presents two experiments. Experiment 1 was designed as a follow-up to Fine et al.'s study and failed to find evidence of adaptation. A power analysis of Fine et al.'s raw data revealed that a similar study would need double the items and four times the subjects to reach 95% power. In Experiment 2 we designed a close replication of Fine et al.'s experiment using these sample size guidelines. No evidence of rapid syntactic adaptation was found in this experiment. The failure to find evidence of adaptation in both experiments calls into question the robustness of the effect.
C1 [Stack, Caoimhe M. Harrington; Watson, Duane G.] Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [James, Ariel N.] Macalester Coll, St Paul, MN 55105 USA.
RP Stack, CMH (corresponding author), Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.
EM c.stack@vanderbilt.edu
RI James, Ariel/ABC-3770-2020
OI James, Ariel/0000-0003-2859-7796
FU James S. McDonnell Foundation
FX This research was supported by the James S. McDonnell Foundation. We
   thank Alex Fine and Florian Jaeger for providing the data from the
   original Fine et al. (2013) experiment, providing stimuli to use in the
   replication, and helpful comments on the results.
CR Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Browne W. J., 2009, GUIDE SAMPLE SIZE CA
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Buz E, 2016, J MEM LANG, V89, P68, DOI 10.1016/j.jml.2015.12.009
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Chang F, 2002, COGNITIVE SCI, V26, P609, DOI 10.1207/s15516709cog2605_3
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E
   Farmer T. A., 2014, P 36 ANN M COGN SCI, P2181
   FERREIRA F, 1986, J MEM LANG, V25, P348, DOI 10.1016/0749-596X(86)90006-9
   Fine A. B., 2011, P 33 ANN M COGN SCI, P925
   Fine AB, 2016, J EXP PSYCHOL LEARN, V42, P1362, DOI 10.1037/xlm0000236
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661
   Fine AB, 2013, COGNITIVE SCI, V37, P578, DOI 10.1111/cogs.12022
   Fraundorf SH, 2016, J MEM LANG, V91, P28, DOI 10.1016/j.jml.2016.05.006
   Garnsey SM, 1997, J MEM LANG, V37, P58, DOI 10.1006/jmla.1997.2512
   Gibson E, 2017, PSYCHOL SCI, V28, P703, DOI 10.1177/0956797617690277
   Jaeger T. F., 2008, P 29 ANN COGN SCI SO, P1061
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013
   Kleinschmidt D. F., 2012, P 34 ANN C COGN SCI, P599
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kurumada C., 2014, P 36 ANN M COGN SCI, P791
   Liu LD, 2018, COGNITION, V174, P55, DOI 10.1016/j.cognition.2018.01.003
   LOFTUS GR, 1978, MEM COGNITION, V6, P312, DOI 10.3758/BF03197461
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   MACDONALD MC, 1992, COGNITIVE PSYCHOL, V24, P56, DOI 10.1016/0010-0285(92)90003-K
   MIIKKULAINEN R, 1991, COGNITIVE SCI, V15, P343, DOI 10.1016/0364-0213(91)80002-M
   Myslin M, 2016, COGNITION, V147, P29, DOI 10.1016/j.cognition.2015.10.021
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   RAYNER K, 1983, J VERB LEARN VERB BE, V22, P358, DOI 10.1016/S0022-5371(83)90236-0
   Rohde DLT, 1999, COGNITION, V72, P67, DOI 10.1016/S0010-0277(99)00031-1
   Schnoebelen T, 2010, PSIHOLOGIJA, V43, P441, DOI 10.2298/PSI1004441S
   Snedeker J, 2004, COGNITIVE PSYCHOL, V49, P238, DOI 10.1016/j.cogpsych.2004.03.001
   TRUESWELL JC, 1994, PERSPECTIVES ON SENTENCE PROCESSING, P155
   TRUESWELL JC, 1994, J MEM LANG, V33, P285, DOI 10.1006/jmla.1994.1014
   Wells JB, 2009, COGNITIVE PSYCHOL, V58, P250, DOI 10.1016/j.cogpsych.2008.08.002
   Wittenberg E, 2017, J MEM LANG, V94, P254, DOI 10.1016/j.jml.2016.12.001
   Xiang M, 2015, LANG COGN NEUROSCI, V30, P648, DOI 10.1080/23273798.2014.995679
   Yildirim I., 2013, P 35 ANN C COGN SCI, P3835
NR 38
TC 16
Z9 16
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0090-502X
EI 1532-5946
J9 MEM COGNITION
JI Mem. Cogn.
PD AUG
PY 2018
VL 46
IS 6
BP 864
EP 877
DI 10.3758/s13421-018-0808-6
PG 14
WC Psychology, Experimental
SC Psychology
GA GO8EV
UT WOS:000440318700003
PM 29651687
OA Bronze
DA 2021-02-24
ER

PT J
AU Francisco, AA
   Takashima, A
   McQueen, JM
   van den Bunt, M
   Jesse, A
   Groen, MA
AF Francisco, Ana A.
   Takashima, Atsuko
   McQueen, James M.
   van den Bunt, Mark
   Jesse, Alexandra
   Groen, Margriet A.
TI Adult dyslexic readers benefit less from visual input during audiovisual
   speech processing: fMRI evidence
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE FMRI; Dyslexia; Audiovisual speech perception; Visual speech
ID SUPERIOR TEMPORAL SULCUS; HUMAN EXTRASTRIATE CORTEX; FUSIFORM FACE AREA;
   MULTISENSORY INTERACTIONS; OBJECT RECOGNITION; CORTICAL NETWORKS;
   WORKING-MEMORY; TALKING FACES; INTEGRATION; PERCEPTION
AB The aim of the present fMRI study was to investigate whether typical and dyslexic adult readers differed in the neural correlates of audiovisual speech processing. We tested for Blood Oxygen-Level Dependent (BOLD) activity differences between these two groups in a 1-back task, as they processed written (word, illegal consonant strings) and spoken (auditory, visual and audiovisual) stimuli. When processing written stimuli, dyslexic readers showed reduced activity in the supramarginal gyrus, a region suggested to play an important role in phonological processing, but only when they processed strings of consonants, not when they read words. During the speech perception tasks, dyslexic readers were only slower than typical readers in their behavioral responses in the visual speech condition. Additionally, dyslexic readers presented reduced neural activation in the auditory, the visual, and the audiovisual speech conditions. The groups also differed in terms of superadditivity, with dyslexic readers showing decreased neural activation in the regions of interest. An additional analysis focusing on vision related processing during the audiovisual condition showed diminished activation for the dyslexic readers in a fusiform gyrus cluster. Our results thus suggest that there are differences in audiovisual speech processing between dyslexic and normal readers. These differences might be explained by difficulties in processing the unisensory components of audiovisual speech, more specifically, dyslexic readers may benefit less from visual information during audiovisual speech processing than typical readers. Given that visual speech processing supports the development of phonological skills fundamental in reading, differences in processing of visual speech could contribute to differences in reading ability between typical and dyslexic readers.
C1 [Francisco, Ana A.; van den Bunt, Mark; Groen, Margriet A.] Radboud Univ Nijmegen, Behav Sci Inst, Postbus 9104, NL-6500 HE Nijmegen, Netherlands.
   [Takashima, Atsuko; McQueen, James M.] Radboud Univ Nijmegen, Max Planck Inst Psycholinguist, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Jesse, Alexandra] Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA 01003 USA.
   [Francisco, Ana A.] Albert Einstein Coll Med, Dept Pediat, Cognit Neurophysiol Lab, Van Etten Bldg,Room 1C-3B,1225 Morris Pk Ave, Bronx, NY 10461 USA.
RP Francisco, AA (corresponding author), Radboud Univ Nijmegen, Behav Sci Inst, Postbus 9104, NL-6500 HE Nijmegen, Netherlands.; Francisco, AA (corresponding author), Albert Einstein Coll Med, Dept Pediat, Cognit Neurophysiol Lab, Van Etten Bldg,Room 1C-3B,1225 Morris Pk Ave, Bronx, NY 10461 USA.
EM claraafrancisco@gmail.com; atsuko.takashima@donders.ru.nl;
   j.mcqueen@donders.ru.nl; m.vandenhunt@pwo.ru.nl; ajesse@psych.umass.edu;
   m.groen@pwo.ru.nl
RI Groen, Margriet/A-5087-2012
OI Groen, Margriet/0000-0002-6178-2937; Alves Francisco,
   Ana/0000-0003-4030-0297
FU Innovational Research Incentives Scheme Veni grant from the Netherlands
   Organisation for Scientific Research [275-89-017]
FX MAG was supported by an Innovational Research Incentives Scheme Veni
   grant (#275-89-017) from the Netherlands Organisation for Scientific
   Research. We thank Jose Marques, Marcel Zwiers, and Paul Gaalman for
   their technical support and all participants for their cooperation.
CR Baart M, 2012, ACTA PSYCHOL, V140, P91, DOI 10.1016/j.actpsy.2012.03.003
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barraclough NE, 2005, J COGNITIVE NEUROSCI, V17, P377, DOI 10.1162/0898929053279586
   Bates D., 2014, LME4 LINEAR MIXED EF
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Beauchamp MS, 2005, NEUROINFORMATICS, V3, P93, DOI 10.1385/NI:3:2:093
   Beauchamp MS, 2004, NAT NEUROSCI, V7, P1190, DOI 10.1038/nn1333
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Bekebrede J, 2010, SCI STUD READ, V14, P183, DOI 10.1080/10888430903117500
   Blank H, 2011, J NEUROSCI, V31, P12906, DOI 10.1523/JNEUROSCI.2091-11.2011
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Blomert L., 2006, PROTOCOL DYSLEXIE DI
   Blomert L, 2011, NEUROIMAGE, V57, P695, DOI 10.1016/j.neuroimage.2010.11.003
   Brett M., 2002, NEUROIMAGE, V16, pS497, DOI DOI 10.1016/S1053-8119(02)90013-3
   Brus BT., 1999, EEN MINUUT TEST VORM
   Bushara KO, 2001, J NEUROSCI, V21, P300, DOI 10.1523/JNEUROSCI.21-01-00300.2001
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1999, NEUROREPORT, V10, P2619, DOI 10.1097/00001756-199908200-00033
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Calvert GA, 2001, NEUROIMAGE, V14, P427, DOI 10.1006/nimg.2001.0812
   CAPLAN D, 1995, NEUROLOGY, V45, P293, DOI 10.1212/WNL.45.2.293
   Christopher ME, 2012, J EXP PSYCHOL GEN, V141, P470, DOI 10.1037/a0027375
   de Gelder B, 1998, BRAIN LANG, V64, P269, DOI 10.1006/brln.1998.1973
   De Pessemier P., 2009, TEST GEVORDERD LEZEN
   Deffke I, 2007, NEUROIMAGE, V35, P1495, DOI 10.1016/j.neuroimage.2007.01.034
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Ehri LC, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P3
   ELBRO C, 1994, ANN DYSLEXIA, V44, P205, DOI 10.1007/BF02648162
   Francisco AA, 2017, J SPEECH LANG HEAR R, V60, P144, DOI 10.1044/2016_JSLHR-H-15-0375
   Gabrieli JDE, 2009, SCIENCE, V325, P280, DOI 10.1126/science.1171999
   Giard MH, 1999, J COGNITIVE NEUROSCI, V11, P473, DOI 10.1162/089892999563544
   Grill-Spector K, 2004, NAT NEUROSCI, V7, P555, DOI 10.1038/nn1224
   Groen M. A, 2013, P INT C AUD VIS SPEE, P77
   Hahn N, 2014, NEUROSCI BIOBEHAV R, V47, P384, DOI 10.1016/j.neubiorev.2014.09.007
   Hairston WD, 2005, EXP BRAIN RES, V166, P474, DOI 10.1007/s00221-005-2387-6
   Hayasaka S, 2003, NEUROIMAGE, V20, P2343, DOI 10.1016/j.neuroimage.2003.08.003
   Hayes EA, 2003, NEUROSCI LETT, V351, P46, DOI 10.1016/S0304-3940(03)00971-6
   Helenius P, 1999, CEREB CORTEX, V9, P476, DOI 10.1093/cercor/9.5.476
   James T. W., 2012, FRONTIERS NEURAL BAS
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Karipidis II, 2017, HUM BRAIN MAPP, V38, P1038, DOI 10.1002/hbm.23437
   Kast M, 2011, BRAIN LANG, V119, P136, DOI 10.1016/j.bandl.2011.04.002
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Kronschnabel J, 2014, NEUROPSYCHOLOGIA, V62, P245, DOI 10.1016/j.neuropsychologia.2014.07.024
   Kyle FE, 2011, J DEAF STUD DEAF EDU, V16, P289, DOI 10.1093/deafed/enq069
   Laurienti PJ, 2005, EXP BRAIN RES, V166, P289, DOI 10.1007/s00221-005-2370-2
   Linkenkaer-Hansen K, 1998, NEUROSCI LETT, V253, P147, DOI 10.1016/S0304-3940(98)00586-2
   Macaluso E, 2000, SCIENCE, V289, P1206, DOI 10.1126/science.289.5482.1206
   Macaluso E, 2004, NEUROIMAGE, V21, P725, DOI 10.1016/j.neuroimage.2003.09.049
   Makris N, 2006, SCHIZOPHR RES, V83, P155, DOI 10.1016/j.schres.2005.11.020
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1
   Maldjian JA, 2004, NEUROIMAGE, V21, P450, DOI 10.1016/j.neuroimage.2003.09.032
   Martin A, 2016, HUM BRAIN MAPP, V37, P2676, DOI 10.1002/hbm.23202
   McCandliss BD, 2003, TRENDS COGN SCI, V7, P293, DOI 10.1016/S1364-6613(03)00134-7
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   MEREDITH MA, 1986, BRAIN RES, V365, P350
   Molholm S, 2004, CEREB CORTEX, V14, P452, DOI 10.1093/cercor/bhh007
   Monzalvo K, 2012, NEUROIMAGE, V61, P258, DOI 10.1016/j.neuroimage.2012.02.035
   Mottonen R, 2004, NEUROSCI LETT, V363, P112, DOI 10.1016/j.neulet.2004.03.076
   Norrix LW, 2006, J COMMUN DISORD, V39, P22, DOI 10.1016/j.jcomdis.2005.05.003
   OJEMANN G, 1989, J NEUROSURG, V71, P316, DOI 10.3171/jns.1989.71.3.0316
   Paulesu E, 1996, BRAIN, V119, P143, DOI 10.1093/brain/119.1.143
   Pekkola J, 2006, NEUROIMAGE, V29, P797, DOI 10.1016/j.neuroimage.2005.09.069
   Pekkola J, 2005, NEUROREPORT, V16, P125, DOI 10.1097/00001756-200502080-00010
   Penny W, 2003, RANDOM EFFECTS ANAL, P843
   Ramirez J, 2005, J ACOUST SOC AM, V118, P1122, DOI 10.1121/1.1940509
   Richards T, 2008, AM J NEURORADIOL, V29, P1134, DOI 10.3174/ajnr.A1007
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Russeler J, 2015, NEUROSCIENCE, V287, P55, DOI 10.1016/j.neuroscience.2014.12.023
   Rumsey JM, 1997, BRAIN, V120, P739, DOI 10.1093/brain/120.5.739
   Sadeh B, 2010, HUM BRAIN MAPP, V31, P1490, DOI 10.1002/hbm.20952
   Salmelin R, 1996, ANN NEUROL, V40, P157, DOI 10.1002/ana.410400206
   Sandak R, 2004, SCI STUD READ, V8, P273, DOI 10.1207/s1532799xssr0803_6
   Shaywitz SE, 2003, BIOL PSYCHIAT, V54, P25, DOI 10.1016/S0006-3223(02)01836-X
   Shaywitz SE, 1998, P NATL ACAD SCI USA, V95, P2636, DOI 10.1073/pnas.95.5.2636
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Stevenson RA, 2007, EXP BRAIN RES, V179, P85, DOI 10.1007/s00221-006-0770-6
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Swanson HL, 2006, J LEARN DISABIL-US, V39, P252
   Swanson HL, 2009, J LEARN DISABIL-US, V42, P260, DOI 10.1177/0022219409331958
   Szycik GR, 2009, HUM BRAIN MAPP, V30, P1990, DOI 10.1002/hbm.20640
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   van Bergen E, 2014, J ABNORM CHILD PSYCH, V42, P1187, DOI 10.1007/s10802-014-9858-9
   van Laarhoven T, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12504
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   von Kriegstein K, 2012, NEURAL BASEMULTISE, P683
   von Kriegstein K, 2008, P NATL ACAD SCI USA, V105, P6747, DOI 10.1073/pnas.0710826105
   Wallace M. T, 2014, CONSTRUCT MULTISENSO
   Werner S, 2010, CEREB CORTEX, V20, P1829, DOI 10.1093/cercor/bhp248
   Woll B, 2012, DEAF EDUC INT, V14, P16, DOI 10.1179/1557069X12Y.0000000001
   Woolrich MW, 2009, NEUROIMAGE, V45, pS173, DOI 10.1016/j.neuroimage.2008.10.055
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Wyk BCV, 2010, BRAIN COGNITION, V74, P97, DOI 10.1016/j.bandc.2010.07.002
   Ye Z, 2017, NEUROSCIENCE, V356, P1, DOI 10.1016/j.neuroscience.2017.05.017
NR 99
TC 3
Z9 3
U1 2
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD AUG
PY 2018
VL 117
BP 454
EP 471
DI 10.1016/j.neuropsychologia.2018.07.009
PG 18
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA HA8LL
UT WOS:000450540800047
PM 29990508
OA Green Published
DA 2021-02-24
ER

PT J
AU Colby, S
   Clayards, M
   Baum, S
AF Colby, Sarah
   Clayards, Meghan
   Baum, Shari
TI The Role of Lexical Status and Individual Differences for Perceptual
   Learning in Younger and Older Adults
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPOKEN WORD RECOGNITION; AGE-RELATED-CHANGES; SPEECH-PERCEPTION;
   SELECTIVE ADAPTATION; FEATURE-DETECTORS; LISTENERS; STIMULUS; CONTEXT;
   CATEGORIZATION; IDENTIFICATION
AB Purpose: This study examined whether older adults remain perceptually flexible when presented with ambiguities in speech in the absence of lexically disambiguating information. We expected older adults to show less perceptual learning when top-down information was not available. We also investigated whether individual differences in executive function predicted perceptual learning in older and younger adults.
   Method: Younger (n = 31) and older adults (n = 27) completed 2 perceptual learning tasks composed of a pretest, exposure, and posttest phase. Both learning tasks exposed participants to clear and ambiguous speech tokens, but crucially, the lexically guided learning task provided disambiguating lexical information whereas the distributional learning task did not. Participants also performed several cognitive tasks to investigate individual differences in working memory, vocabulary, and attention-switching control.
   Results: We found that perceptual learning is maintained in older adults, but that learning may be stronger in contexts where top-down information is available. Receptive vocabulary scores predicted learning across both age groups and in both learning tasks.
   Conclusions: Implicit learning is maintained with age across different learning conditions but remains stronger when lexically biasing information is available. We find that receptive vocabulary is relevant for learning in both types of learning tasks, suggesting the importance of vocabulary knowledge for adapting to ambiguities in speech.
C1 [Colby, Sarah; Clayards, Meghan; Baum, Shari] McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
   [Clayards, Meghan] McGill Univ, Dept Linguist, Montreal, PQ, Canada.
RP Colby, S (corresponding author), McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
EM sarah.colby@mail.mcgill.ca
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC) [435-2016-0747];
   Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
FX This work was supported by Social Sciences and Humanities Research
   Council of Canada Grant 435-2016-0747 to M. Clayards and a Natural
   Sciences and Engineering Research Council of Canada discovery grant to
   S. Baum. The authors would like to thank Victoria Poulton for her help
   in collecting data.
CR Adank P, 2010, PSYCHOL AGING, V25, P736, DOI 10.1037/a0020054
   Baese-Berk M., 2015, P 18 INT C PHON SCI, V0460, P1
   Baum SR, 2003, SPEECH COMMUN, V39, P231, DOI 10.1016/S0167-6393(02)00028-6
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Boersma P., 2014, PRAAT DOING PHONETIC
   Chladkova K, 2017, J EXP PSYCHOL HUMAN, V43, P414, DOI 10.1037/xhp0000333
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Dunn L.M., 1997, PPVT 3 PEABODY PICTU
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Golomb JD, 2007, J ACOUST SOC AM, V121, P1701, DOI 10.1121/1.2436635
   Guediche S, 2016, J EXP PSYCHOL HUMAN, V42, P1048, DOI 10.1037/xhp0000196
   Helfer KS, 2016, J ACOUST SOC AM, V140, P3844, DOI 10.1121/1.4967297
   Helfer KS, 2016, J ACOUST SOC AM, V140, pEL371, DOI 10.1121/1.4966586
   Helfer KS, 2014, J ACOUST SOC AM, V136, P748, DOI 10.1121/1.4887463
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Ishida M, 2016, COGNITION, V151, P68, DOI 10.1016/j.cognition.2016.03.008
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Kleinschmidt D. F., 2015, INFERRING LISTENERS, DOI [10.13140/ RG. 2.1.3803.4405., DOI 10.13140/RG.2.1.3803.4405, 10.13140/RG.2.1.3803.4405]
   Kleinschmidt DF, 2016, PSYCHON B REV, V23, P678, DOI 10.3758/s13423-015-0943-z
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   Mattys SL, 2014, PSYCHOL AGING, V29, P150, DOI 10.1037/a0035387
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Maye J, 2000, PROC ANN BUCLD, P522
   McAuliffe M, 2016, J ACOUST SOC AM, V140, P1727, DOI 10.1121/1.4962529
   McQueen JM, 2006, LANG SPEECH, V49, P101, DOI 10.1177/00238309060490010601
   Midford R, 2005, AGING NEUROPSYCHOL C, V12, P359, DOI 10.1080/13825580500246894
   Mueller S. T., 2011, PEBL DIGIT SPAN TEST
   Mueller ST, 2014, J NEUROSCI METH, V222, P250, DOI 10.1016/j.jneumeth.2013.10.024
   Neger TM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00628
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Park DC, 2009, ANNU REV PSYCHOL, V60, P173, DOI 10.1146/annurev.psych.59.103006.093656
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Piper BJ, 2012, BEHAV RES METHODS, V44, P110, DOI 10.3758/s13428-011-0096-6
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Reuter-Lorenz PA, 2014, NEUROPSYCHOL REV, V24, P355, DOI 10.1007/s11065-014-9270-9
   Revill KP, 2012, PSYCHOL AGING, V27, P80, DOI 10.1037/a0024113
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Scharenborg O, 2015, ATTEN PERCEPT PSYCHO, V77, P493, DOI 10.3758/s13414-014-0792-2
   Scharenborg O, 2013, ATTEN PERCEPT PSYCHO, V75, P525, DOI 10.3758/s13414-013-0422-4
   Schreiber E., 2013, P M AC, V19, DOI [10.1121/ 1.4801082, DOI 10.1121/1.4801082, 10.1121/1.4801082]
   Schvartz KC, 2008, J ACOUST SOC AM, V124, P3972, DOI 10.1121/1.2997434
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   Voelcker-Rehage C, 2008, EUR REV AGING PHYS A, V5, P5, DOI 10.1007/s11556-008-0030-9
   WILSON M, 1988, BEHAV RES METH INSTR, V20, P6, DOI 10.3758/BF03202594
NR 52
TC 4
Z9 4
U1 0
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD AUG
PY 2018
VL 61
IS 8
BP 1
EP 20
DI 10.1044/2018_JSLHR-S-17-0392
PG 20
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GU0YI
UT WOS:000444980200001
PM 30003232
DA 2021-02-24
ER

PT J
AU Dorn, K
   Weinert, S
   Falck-Ytter, T
AF Dorn, Katharina
   Weinert, Sabine
   Falck-Ytter, Terje
TI Watch and listen - A cross-cultural study of audio-visual-matching
   behavior in 4.5-month-old infants in German and Swedish talking faces
SO INFANT BEHAVIOR & DEVELOPMENT
LA English
DT Article
DE Speech perception; Audio-visual matching; Phonological/phonetic cues;
   Cross-cultural study; Eye-tracking
ID INTERSENSORY REDUNDANCY GUIDES; LANGUAGE DISCRIMINATION; AUDIOVISUAL
   SPEECH; LINGUISTIC RHYTHM; PERCEPTION; ATTENTION; RECOGNITION;
   ACQUISITION; COGNITION; VOICE
AB Investigating infants' ability to match visual and auditory speech segments presented sequentially allows us to understand more about the type of information they encode in each domain, as well as their ability to relate the information. One previous study found that 4.5- month-old infants' preference for visual French or German speech depended on whether they had previously heard the respective language, suggesting a remarkable ability to encode and relate audio-visual speech cues and to use these to guide their looking behavior. However, French and German differ in their prosody, meaning that perhaps, the infants did not base their matching on phonological or phonetic cues, but on prosody patterns. The present study aimed to address this issue by tracking the eye gaze of 4.5-month-old German and Swedish infants cross-culturally in an intersensory matching procedure, comparing German and Swedish, two same-rhythm-class languages differing in phonetic and phonological attributes but not in prosody. Looking times indicated that even when distinctive prosodic cues were eliminated, 4.5- month-olds were able to extract subtle language properties and sequentially match visual and heard fluent speech. This outcome was the same for different individual speakers for the two modalities, ruling out the possibility that the infants matched speech patterns specific to one individual. This study confirms a remarkably early emerging ability of infants to match auditory and visual information. The fact that the types of information were matched despite sequential presentation demonstrates that the information is retained in short term memory, and thus goes beyond purely perceptua - here-and-now processing.
C1 [Dorn, Katharina; Weinert, Sabine] Otto Friedrich Univ, Dept Dev Psychol, Bamberg, Germany.
   [Falck-Ytter, Terje] Uppsala Univ, Dept Psychol, Uppsala, Sweden.
RP Dorn, K (corresponding author), Otto Friedrich Univ, Dept Dev Psychol, Bamberg, Germany.
EM katharina.dorn@uni-bamberg.de
OI Weinert, Sabine/0000-0002-8341-9821
FU program IPID4all - German Academic Exchange Service; Federal Ministry of
   Education and ResearchFederal Ministry of Education & Research (BMBF)
FX This research received a specific grant from the funding program
   IPID4all - promoted by the German Academic Exchange Service and funded
   by the Federal Ministry of Education and Research.
CR Abercombie D., 1967, ELEMENTS GEN PHONETI
   Asp F, 2015, INT J AUDIOL, V54, P77, DOI 10.3109/14992027.2014.973536
   Bahrick LE, 2000, DEV PSYCHOL, V36, P190, DOI 10.1037//0012-1649.36.2.190
   Bahrick LE, 2004, CURR DIR PSYCHOL SCI, V13, P99, DOI 10.1111/j.0963-7214.2004.00283.x
   Beckman M. E., 1992, SPEECH PERCEPTION PR, P457
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Christophe A, 1998, DEVELOPMENTAL SCI, V1, P215, DOI 10.1111/1467-7687.00033
   Colombo J, 2001, ANNU REV PSYCHOL, V52, P337, DOI 10.1146/annurev.psych.52.1.337
   Colombo J., 2010, INFANT PERCEPTION CO
   Courage ML, 2006, CHILD DEV, V77, P680, DOI 10.1111/j.1467-8624.2006.00897.x
   Dauer R. M., 1983, J PHONETICS
   de Diego-Balaguer R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00044
   DODD B, 1979, COGNITIVE PSYCHOL, V11, P478, DOI 10.1016/0010-0285(79)90021-5
   DODD B, 1988, VOLTA REV, V90, P45
   FANT G, 1991, J PHONETICS, V19, P351, DOI 10.1016/S0095-4470(19)30327-4
   Fant G., 1989, STL QPSR, V2, P1
   Grabe E, 2002, PHONOL PHONET, V4-1, P515
   Kubicek C, 2018, INFANT CHILD DEV, V27, DOI 10.1002/icd.2084
   Kubicek C, 2014, INFANT BEHAV DEV, V37, P644, DOI 10.1016/j.infbeh.2014.08.010
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   KUHL PK, 1984, INFANT BEHAV DEV, V7, P361, DOI 10.1016/S0163-6383(84)80050-8
   Lewkowicz DJ, 2015, J EXP CHILD PSYCHOL, V130, P147, DOI 10.1016/j.jecp.2014.10.006
   Lewkowicz DJ, 2013, INT J BEHAV DEV, V37, P90, DOI 10.1177/0165025412467582
   Lindqvist C., 2007, SCHWEDISCHE PHONETIK
   Lofkvist U, 2014, INT J PEDIATR OTORHI, V78, P253, DOI 10.1016/j.ijporl.2013.11.017
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Mondloch C., 1996, P 12 M INT SOC PSYCH, P107
   Munhall K.G., 2004, HDB MULTISENSORY PRO, P177
   Murray MM, 2016, TRENDS NEUROSCI, V39, P567, DOI 10.1016/j.tins.2016.05.003
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2003, SPEECH COMMUN, V41, P233, DOI 10.1016/S0167-6393(02)00106-1
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Pike Kenneth, 1945, INTONATION AM ENGLIS
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Risberg A., 1978, STL QPSR, V4, P1
   Sai FZ, 2005, INFANT CHILD DEV, V14, P29, DOI 10.1002/icd.376
   Scott LS, 2007, CURR DIR PSYCHOL SCI, V16, P197, DOI 10.1111/j.1467-8721.2007.00503.x
   Soto-Faraco S, 2007, PERCEPT PSYCHOPHYS, V69, P218, DOI 10.3758/BF03193744
   Streri A, 2013, INT J BEHAV DEV, V37, P79, DOI 10.1177/0165025412465361
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 49
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0163-6383
EI 1879-0453
J9 INFANT BEHAV DEV
JI Infant Behav. Dev.
PD AUG
PY 2018
VL 52
BP 121
EP 129
DI 10.1016/j.infbeh.2018.05.003
PG 9
WC Psychology, Developmental
SC Psychology
GA GT6YR
UT WOS:000444667300014
PM 30007216
DA 2021-02-24
ER

PT J
AU Mosnier, I
   Vanier, A
   Bonnard, D
   Lina-Granade, G
   Truy, E
   Bordure, P
   Godey, B
   Marx, M
   Lescanne, E
   Venail, F
   Poncet, C
   Sterkers, O
   Belmin, J
AF Mosnier, Isabelle
   Vanier, Antoine
   Bonnard, Damien
   Lina-Granade, Genevieve
   Truy, Eric
   Bordure, Philippe
   Godey, Benoit
   Marx, Mathieu
   Lescanne, Emmanuel
   Venail, Frederic
   Poncet, Christine
   Sterkers, Olivier
   Belmin, Joel
TI Long-Term Cognitive Prognosis of Profoundly Deaf Older Adults After
   Hearing Rehabilitation Using Cochlear Implants
SO JOURNAL OF THE AMERICAN GERIATRICS SOCIETY
LA English
DT Article
DE hearing loss; elderly; cognitive decline; rehabilitation; speech
   perception
ID ALZHEIMERS ASSOCIATION WORKGROUPS; QUALITY-OF-LIFE; AUDITORY
   REHABILITATION; DIAGNOSTIC GUIDELINES; NATIONAL INSTITUTE; INCIDENT
   DEMENTIA; DECLINE; HEALTH; IMPAIRMENT; AIDS
AB ObjectivesTo analyze long-term cognitive status and function after cochlear implantation in profoundly deaf individuals.
   DesignProspective observational longitudinal study.
   SettingTen academic medical centers referent for cochlear implantation.
   ParticipantsIndividuals aged 65 and older who qualified for cochlear implantation (N=70).
   MeasurementsCognitive tests were administered before cochlear implantation and 1 and 5 or more years after cochlear implantation. Evaluation consisted of 6 tests assessing attention, memory, orientation, executive function, mental flexibility, and fluency. Cognitive status was determined as normal, mild cognitive impairment (MCI), or dementia. Speech perception in quiet and noisy conditions was assessed using disyllabic words, and quality of life was assessed using the Nijmegen Cochlear Implant Questionnaire.
   ResultsMean follow-up was 6.8 years (range 5.5-8.5 years). Speech perception scores and quality of life remained stable from 1 to 7 years after cochlear implantation. Of 31 participants (45%) with MCI before cochlear implantation, 2 (6%) developed dementia during follow-up, 19 (61%) remained stable, and 10 (32%) returned to normal cognition. None of the 38 with normal cognition developed dementia during follow-up, although 12 (32%) developed MCI.
   ConclusionMCI is highly prevalent in older adults with profound hearing loss. Nevertheless, we observed a low rate of progression to dementia, and cognitive function improved in some individuals with MCI at baseline. These results highlight that cochlear implantation should be strongly considered in profoundly deaf individuals, even those with MCI, who may have a specific subtype of MCI, with a possible positive effect of hearing rehabilitation on neurocognitive functioning.
C1 [Mosnier, Isabelle; Sterkers, Olivier] Sorbonne Univ, INSERM, Unite Rehabil Chirurg Miniinvas & Robotisee Audit, Paris, France.
   [Mosnier, Isabelle; Sterkers, Olivier] GHU Pitie Salpetriere, AP HP, Serv ORL, Otol Implants Auditifs & Chirurg Base Crane, Paris, France.
   [Vanier, Antoine] Sorbonne Univ, Dept Sante Publ, Paris, France.
   [Vanier, Antoine] GHU Pitie Salpetriere, AP HP, Dept Biostat Sant Publ & Informat Med, Paris, France.
   [Bonnard, Damien; Lina-Granade, Genevieve] Lyon Neurosci Res Ctr, Brain Dynam & Cognit Team, CRNL, INSERM U1028,CNRS UMR5292, F-69000 Lyon, France.
   [Truy, Eric] Hop Pellegrin, Serv ORL, Bordeaux, France.
   [Truy, Eric] Hop Edouard Herriot, Serv ORL, Lyon, France.
   [Bordure, Philippe] Hop Hotel Dieu, Serv ORL, Nantes, France.
   [Godey, Benoit] Hop Pontchaillou, Serv ORL, Rennes, France.
   [Marx, Mathieu] Hop Purpan, Serv ORL, Toulouse, France.
   [Lescanne, Emmanuel] Hop Bretonneau, Serv ORL, Tours, France.
   [Venail, Frederic] Hop Gui de Chauliac, Serv ORL, Montpellier, France.
   [Poncet, Christine] Hop Rothschild, AP HP, Serv ORL, Paris, France.
   [Belmin, Joel] Sorbonne Univ, Hop Charles Foix, AP HP, Serv Geriatrie, Ivry, France.
   [Belmin, Joel] Sorbonne Univ, Hop Charles Foix, AP HP, Ivry, France.
RP Mosnier, I (corresponding author), GH Pitie Salpetriere, Unite Otol Implants Auditifs & Chirurg Base Crane, Batiment Castaigne,47-83 Blvd Hop, F-75651 Paris 13, France.
EM isabelle.mosnier@aphp.fr
RI Venail, Frederic/AAG-5682-2020; Belmin, Joel/V-9995-2019
OI Belmin, Joel/0000-0003-1630-9582; Vanier, Antoine/0000-0001-6033-9282
FU Medel Funding Source: Medline; Advanced Bionics Funding Source: Medline;
   Cochlear Funding Source: Medline; Oticon Medical Funding Source:
   Medline; Cochlear France (Toulouse, France) Funding Source: Medline;
   Vibrant Medel Hearing Technology (Sofia Antipolis, France) Funding
   Source: Medline; Oticon Medical/Neurelec (Vallauris, France) Funding
   Source: Medline; Advanced Bionics AG (Stafa, Switzerland) Funding
   Source: Medline
CR Albers MW, 2015, ALZHEIMERS DEMENT, V11, P70, DOI 10.1016/j.jalz.2014.04.514
   Albert MS, 2011, ALZHEIMERS DEMENT, V7, P270, DOI 10.1016/j.jalz.2011.03.008
   Amieva H, 2015, J AM GERIATR SOC, V63, P2099, DOI 10.1111/jgs.13649
   Castiglione A, 2016, AUDIOL NEURO-OTOL, V21, P21, DOI 10.1159/000448350
   Choi JS, 2016, JAMA OTOLARYNGOL, V142, P652, DOI 10.1001/jamaoto.2016.0700
   Clark JH, 2012, J AM GERIATR SOC, V60, P1936, DOI 10.1111/j.1532-5415.2012.04150.x
   Contrera KJ, 2017, LARYNGOSCOPE, V127, P1885, DOI 10.1002/lary.26424
   Davies HR, 2017, J AM GERIATR SOC, V65, P2074, DOI 10.1111/jgs.14986
   Davis A, 2016, GERONTOLOGIST, V56, pS256, DOI 10.1093/geront/gnw033
   Dawes P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119616
   Deal JA, 2017, J GERONTOL A-BIOL, V72, P703, DOI 10.1093/gerona/glw069
   Delogu F, 2009, MEMORY, V17, P655, DOI 10.1080/09658210902998054
   Dillon MT, 2013, JAMA OTOLARYNGOL, V139, P279, DOI 10.1001/jamaoto.2013.1814
   Gallacher J, 2012, NEUROLOGY, V79, P1583, DOI 10.1212/WNL.0b013e31826e263d
   Gates GA, 2011, ARCH OTOLARYNGOL, V137, P390, DOI 10.1001/archoto.2011.28
   Gauthier S, 2006, LANCET, V367, P1262, DOI 10.1016/S0140-6736(06)68542-5
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Kluger A, 1999, J GERIATR PSYCH NEUR, V12, P168, DOI 10.1177/089198879901200402
   Kral A, 2016, LANCET NEUROL, V15, P610, DOI 10.1016/S1474-4422(16)00034-X
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, ARCH INTERN MED, V171, P1851, DOI 10.1001/archinternmed.2011.506
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Lin VYW, 2017, LARYNGOSCOPE, V127, pS4, DOI 10.1002/lary.26590
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   McKhann GM, 2011, ALZHEIMERS DEMENT, V7, P263, DOI 10.1016/j.jalz.2011.03.005
   Mick P, 2016, EAR HEARING, V37, pE194, DOI 10.1097/AUD.0000000000000267
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   Mosnier I, 2014, AUDIOL NEURO-OTOL, V19, P15, DOI 10.1159/000371599
   Olze H, 2012, LARYNGOSCOPE, V122, P196, DOI 10.1002/lary.22356
   Panza F, 2015, NAT REV NEUROL, V11
   Quaranta N, 2014, AUDIOL NEURO-OTOL, V19, P10, DOI 10.1159/000371597
   Shankar A, 2013, PSYCHOSOM MED, V75, P161, DOI 10.1097/PSY.0b013e31827f09cd
   SINHA UK, 1993, NEUROLOGY, V43, P779, DOI 10.1212/WNL.43.4.779
   Taljaard DS, 2016, CLIN OTOLARYNGOL, V41, P718, DOI 10.1111/coa.12607
NR 35
TC 19
Z9 20
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0002-8614
EI 1532-5415
J9 J AM GERIATR SOC
JI J. Am. Geriatr. Soc.
PD AUG
PY 2018
VL 66
IS 8
BP 1553
EP 1561
DI 10.1111/jgs.15445
PG 9
WC Geriatrics & Gerontology; Gerontology
SC Geriatrics & Gerontology
GA GT1KL
UT WOS:000444228500016
PM 30091185
DA 2021-02-24
ER

PT J
AU Drouin, JR
   Theodore, RM
AF Drouin, Julia R.
   Theodore, Rachel M.
TI Lexically guided perceptual learning is robust to task-based changes in
   listening strategy
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID TALKER VARIABILITY; SPEECH-PERCEPTION; SPEAKING RATE; ENGLISH;
   RECOGNITION; ADAPTATION; CATEGORIES; MEMORY
AB Listeners use lexical information to resolve ambiguity in the speech signal, resulting in the restructuring of speech sound categories. Recent findings suggest that lexically guided perceptual learning is attenuated when listeners use a perception-focused listening strategy (that directs attention towards surface variation) compared to when listeners use a comprehension-focused listening strategy (that directs attention towards higher-level linguistic information). However, previous investigations used the word position of the ambiguity to manipulate listening strategy, raising the possibility that attenuated learning reflected decreased strength of lexical recruitment instead of a perception-oriented listening strategy. The current work tests this hypothesis. Listeners completed an exposure phase followed by a test phase. During exposure, listeners heard an ambiguous fricative embedded in word-medial lexical contexts that supported realization of the ambiguity as /integral/. At test, listeners categorized members of an /asi/-/a integral i/ continuum. Listening strategy was manipulated via exposure task (experiment 1) and explicit acknowledgement of the ambiguity (experiment 2). Compared to control participants, listeners who were exposed to the ambiguity showed more /integral/ responses at the test; critically, the magnitude of learning did not differ across listening strategy conditions. These results suggest that given sufficient lexical context, lexically guided perceptual learning is robust to task-based changes in listening strategy. (C) 2018 Acoustical Society of America.
C1 [Drouin, Julia R.; Theodore, Rachel M.] Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,Unit 1085, Storrs, CT 06269 USA.
   [Drouin, Julia R.] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, 337 Mansfield Rd, Storrs, CT 06269 USA.
RP Theodore, RM (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,Unit 1085, Storrs, CT 06269 USA.
EM rachel.theodore@uconn.edu
FU Connecticut Institute for the Brain and Cognitive Sciences; NIH
   NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R21DC016141]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R21DC016141, R21DC016141, R21DC016141] Funding Source: NIH RePORTER
FX This research was supported by a seed grant from the Connecticut
   Institute for the Brain and Cognitive Sciences and by NIH NIDCD grant
   R21DC016141 to R.M.T. The views expressed here reflect those of the
   authors and not the NIH or the NIDCD. We extend gratitude to Nicholas
   Monto for helpful comments on an earlier version of this manuscript. We
   also extend gratitude to Jacqueline Ose for assistance with data
   collection.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   CRAIK FIM, 1975, J EXP PSYCHOL GEN, V104, P268, DOI 10.1037/0096-3445.104.3.268
   Drouin JR, 2016, J ACOUST SOC AM, V140, pEL307, DOI 10.1121/1.4964468
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   FOX RA, 1984, J EXP PSYCHOL HUMAN, V10, P526, DOI 10.1037/0096-1523.10.4.526
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Jesse A, 2011, PSYCHON B REV, V18, P943, DOI 10.3758/s13423-011-0129-2
   Johnson MA, 2013, LANG COGNITIVE PROC, V28, P1439, DOI 10.1080/01690965.2012.717632
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kuznetsova A., 2015, R PACKAGE VERSION
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   McAuliffe M, 2016, J ACOUST SOC AM, V140, P1727, DOI 10.1121/1.4962529
   McQueen JM, 2006, LANG SPEECH, V49, P101, DOI 10.1177/00238309060490010601
   Mitterer H, 2013, COGNITION, V129, P356, DOI 10.1016/j.cognition.2013.07.011
   Myers EB, 2014, J MEM LANG, V76, P80, DOI 10.1016/j.jml.2014.06.007
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   PISONI DB, 1993, SPEECH COMMUN, V13, P109, DOI 10.1016/0167-6393(93)90063-Q
   Pitt MA, 2006, J EXP PSYCHOL HUMAN, V32, P1120, DOI 10.1037/0096-1523.32.5.1120
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   Samuel AG, 2016, COGNITIVE PSYCHOL, V88, P88, DOI 10.1016/j.cogpsych.2016.06.007
   Scharenborg O, 2015, ATTEN PERCEPT PSYCHO, V77, P493, DOI 10.3758/s13414-014-0792-2
   Sjerps MJ, 2010, J EXP PSYCHOL HUMAN, V36, P195, DOI 10.1037/a0016803
   SOMMERS MS, 1994, J ACOUST SOC AM, V96, P1314, DOI 10.1121/1.411453
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Theodore RM, 2015, J ACOUST SOC AM, V138, P1068, DOI 10.1121/1.4927489
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Werker JF, 2007, COGNITION, V103, P147, DOI 10.1016/j.cognition.2006.03.006
   Werker JF, 2012, CURR DIR PSYCHOL SCI, V21, P221, DOI 10.1177/0963721412449459
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Xie X, 2017, J EXP PSYCHOL HUMAN, V43, P206, DOI 10.1037/xhp0000285
   Zhang XJ, 2014, J EXP PSYCHOL HUMAN, V40, P200, DOI 10.1037/a0033182
NR 42
TC 3
Z9 3
U1 1
U2 9
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD AUG
PY 2018
VL 144
IS 2
BP 1089
EP 1099
DI 10.1121/1.5047672
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GS4MV
UT WOS:000443620700059
PM 30180678
OA Green Published
DA 2021-02-24
ER

PT J
AU Franken, MK
   Acheson, DJ
   McQueen, JM
   Hagoort, P
   Eisner, F
AF Franken, Matthias K.
   Acheson, Daniel J.
   McQueen, James M.
   Hagoort, Peter
   Eisner, Frank
TI Opposing and following responses in sensorimotor speech control: Why
   responses go both ways
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Speech production; Auditory feedback; Speech perception; Pitch
ID VOICE PITCH; FEEDBACK; REFLEX; F-0
AB When talking, speakers continuously monitor and use the auditory feedback of their own voice to control and inform speech production processes. When speakers are provided with auditory feedback that is perturbed in real time, most of them compensate for this by opposing the feedback perturbation. But some responses follow the perturbation. In the present study, we investigated whether the state of the speech production system at perturbation onset may determine what type of response (opposing or following) is made. The results suggest that whether a perturbation-related response is opposing or following depends on ongoing fluctuations of the production system: The system initially responds by doing the opposite of what it was doing. This effect and the nontrivial proportion of following responses suggest that current production models are inadequate: They need to account for why responses to unexpected sensory feedback depend on the production system's state at the time of perturbation.
C1 [Franken, Matthias K.; Acheson, Daniel J.; Hagoort, Peter] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Donders Ctr Cognit Neuroimaging, Nijmegen, Netherlands.
   [Franken, Matthias K.; Acheson, Daniel J.; McQueen, James M.; Hagoort, Peter] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Franken, Matthias K.] Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.
   [McQueen, James M.; Eisner, Frank] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Donders Ctr Cognit, Nijmegen, Netherlands.
RP Franken, MK (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Donders Ctr Cognit Neuroimaging, Nijmegen, Netherlands.; Franken, MK (corresponding author), Max Planck Inst Psycholinguist, Nijmegen, Netherlands.; Franken, MK (corresponding author), Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.
EM matthias.franken@ugent.be
RI Franken, Matthias/J-2169-2019; Eisner, Frank/M-8606-2013
OI Franken, Matthias/0000-0002-6133-8756; Eisner, Frank/0000-0002-7484-8608
FU Dutch Science Foundation (NWO)Netherlands Organization for Scientific
   Research (NWO); NWONetherlands Organization for Scientific Research
   (NWO)
FX F.E. was funded by the Gravitation program Language in Interaction from
   the Dutch Science Foundation (NWO). M.K.F. was funded by the Research
   Talent program of the NWO.
CR Akagi M., 2000, P INTERSPEECH, P458
   Akagi M., 1998, P 5 INT C SPOK LANG, P1519
   Behroozmand R, 2012, J ACOUST SOC AM, V132, P2468, DOI 10.1121/1.4746984
   Boersma P., 2013, PRAAT DOING PHONETIC
   Burnett TA, 1998, J ACOUST SOC AM, V103, P3153, DOI 10.1121/1.423073
   Cai S., 2008, PROCEEDINGS OF THE 8, P65
   Ford JM, 2005, INT J PSYCHOPHYSIOL, V57, P143, DOI 10.1016/j.ijpsycho.2005.03.002
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Hain TC, 2000, EXP BRAIN RES, V130, P133, DOI 10.1007/s002219900237
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Larson CR, 2007, J ACOUST SOC AM, V121, P2862, DOI 10.1121/1.2715657
   Liu HJ, 2007, J ACOUST SOC AM, V122, P3671, DOI 10.1121/1.2800254
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Neuhoff J. G., 2002, P 2002 INT C AUD DIS
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013
   Siegel S., 1988, NONPARAMETRIC STAT B
   van Gelder T, 1998, BEHAV BRAIN SCI, V21, P615, DOI 10.1017/S0140525X98001733
   Wolpert DM, 2000, NAT NEUROSCI, V3, P1212, DOI 10.1038/81497
NR 20
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD AUG
PY 2018
VL 25
IS 4
BP 1458
EP 1467
DI 10.3758/s13423-018-1494-x
PG 10
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA GO9XP
UT WOS:000440461800022
PM 29869027
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Sammler, D
   Cunitz, K
   Gierhan, SME
   Anwander, A
   Adermann, J
   Meixensberger, J
   Friederici, AD
AF Sammler, Daniela
   Cunitz, Katrin
   Gierhan, Sarah M. E.
   Anwander, Alfred
   Adermann, Jens
   Meixensberger, Juergen
   Friederici, Angela D.
TI White matter pathways for prosodic structure building: A case study
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Language; Prosody; Voice; Pitch; DTI; Auditory pathways; Arcuate
   fascicle; Dorsal stream; Corpus callosum
ID HEMISPHERIC-SPECIALIZATION; AUDITORY-LANGUAGE; SPEECH-PERCEPTION;
   VENTRAL PATHWAYS; SYNTACTIC STRUCTURE; LINGUISTIC PROSODY; EMOTIONAL
   PROSODY; DTI TRACTOGRAPHY; CORPUS-CALLOSUM; DORSAL
AB The relevance of left dorsal and ventral fiber pathways for syntactic and semantic comprehension is well established, while pathways for prosody are little explored. The present study examined linguistic prosodic structure building in a patient whose right arcuate/superior longitudinal fascicles and posterior corpus callosum were transiently compromised by a vasogenic peritumoral edema. Compared to ten matched healthy controls, the patient's ability to detect irregular prosodic structure significantly improved between pre- and post-surgical assessment. This recovery was accompanied by an increase in average fractional anisotropy (FA) in right dorsal and posterior transcallosal fiber tracts. Neither general cognitive abilities nor (non-prosodic) syntactic comprehension nor FA in right ventral and left dorsal fiber tracts showed a similar pre-post increase. Together, these findings suggest a contribution of right dorsal and inter-hemispheric pathways to prosody perception, including the right-dorsal tracking and structuring of prosodic pitch contours that is transcallosally informed by concurrent syntactic information.
C1 [Sammler, Daniela] Max Planck Inst Human Cognit & Brain Sci, Otto Hahn Grp Neural Bases Intonat Speech & Mus, Stephanstr 1a, D-04103 Leipzig, Germany.
   [Sammler, Daniela; Cunitz, Katrin; Gierhan, Sarah M. E.; Anwander, Alfred; Friederici, Angela D.] Max Planck Inst Human Cognit & Brain Sci, Dept Neuropsychol, Stephanstr 1a, D-04103 Leipzig, Germany.
   [Cunitz, Katrin] Univ Hosp Ulm, Dept Child & Adolescent Psychiat & Psychol, Steinhovelstr 5, D-89075 Ulm, Germany.
   [Gierhan, Sarah M. E.; Friederici, Angela D.] Humboldt Univ, Berlin Sch Mind & Brain, Unter Linden 6, D-10099 Berlin, Germany.
   [Adermann, Jens; Meixensberger, Juergen] Univ Hosp Leipzig, Clin & Policlin Neurosurg, Liebigstr 20, D-04103 Leipzig, Germany.
RP Sammler, D (corresponding author), Max Planck Inst Human Cognit & Brain Sci, Stephanstr 1a, D-04103 Leipzig, Germany.
EM sammler@cbs.mpg.de
RI Cunitz, Katrin/AAS-8176-2020; Sammler, Daniela/V-9044-2019; Anwander,
   Alfred/B-5874-2011
OI Cunitz, Katrin/0000-0001-5530-8190; Sammler,
   Daniela/0000-0001-7458-0229; Anwander, Alfred/0000-0002-4861-4808
FU Max Planck SocietyMax Planck Society
FX We thank Johanna Reichert and Katharina Fath for help with testing
   healthy controls. This research was funded by the Max Planck Society.
CR Baum SR, 1999, APHASIOLOGY, V13, P581, DOI 10.1080/026870399401957
   Belyk M, 2014, SOC COGN AFFECT NEUR, V9, P1395, DOI 10.1093/scan/nst124
   Bizzi A, 2012, CORTEX, V48, P255, DOI 10.1016/j.cortex.2011.11.015
   BLUMSTEIN S, 1974, Cortex, V10, P146
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008
   Bornkessel-Schlesewsky I, 2013, BRAIN LANG, V125, P60, DOI 10.1016/j.bandl.2013.01.010
   BRICKENKAMP R, 1994, TEST D2
   Bruck C, 2011, PHYS LIFE REV, V8, P383, DOI 10.1016/j.plrev.2011.10.002
   Buxo-Lugo A, 2016, J MEM LANG, V90, P1, DOI 10.1016/j.jml.2016.03.001
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Chen JL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00009
   Cole J, 2015, LANG COGN NEUROSCI, V30, P1, DOI 10.1080/23273798.2014.963130
   Cole J, 2010, LANG COGNITIVE PROC, V25, P1141, DOI 10.1080/01690960903525507
   Cooper W. E., 1980, SYNTAX SPEECH
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   D'Ausilio A, 2011, BRAIN LANG, V118, P9, DOI 10.1016/j.bandl.2011.02.007
   den Ouden DB, 2016, Q J EXP PSYCHOL, V69, P926, DOI 10.1080/17470218.2015.1028416
   Domahs U, 2013, BRAIN LANG, V125, P272, DOI 10.1016/j.bandl.2013.02.012
   Duffau H, 2008, NEUROPSYCHOLOGIA, V46, P3197, DOI 10.1016/j.neuropsychologia.2008.07.017
   Eckstein K, 2006, J COGNITIVE NEUROSCI, V18, P1696, DOI 10.1162/jocn.2006.18.10.1696
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Fernandez-Miranda J, 2015, BRAIN STRUCT FUNCT, V220, P1665, DOI 10.1007/s00429-014-0751-7
   Forkel SJ, 2014, BRAIN, V137, P2027, DOI 10.1093/brain/awu113
   Fridriksson J., 2018, BRAIN
   Friederici AD, 2004, BRAIN LANG, V89, P267, DOI 10.1016/S0093-934X(03)00351-1
   Friederici AD, 2007, NEURON, V53, P135, DOI 10.1016/j.neuron.2006.11.020
   Friederici AD, 2013, CURR OPIN NEUROBIOL, V23, P250, DOI 10.1016/j.conb.2012.10.002
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Fruhholz S, 2015, NEUROIMAGE, V109, P27, DOI 10.1016/j.neuroimage.2015.01.016
   Fruehholz S, 2013, NEUROSCI BIOBEHAV R, V37, P2847, DOI 10.1016/j.neubiorev.2013.10.007
   Gandour J, 2004, NEUROIMAGE, V23, P344, DOI 10.1016/j.neuroimage.2004.06.004
   Geiser E, 2008, J COGNITIVE NEUROSCI, V20, P541, DOI 10.1162/jocn.2008.20029
   Gierhan S. M. E., 2012, INFORM 2012, P1102
   Gierhan S. M. E., 2013, MPI SERIES, V144
   Gierhan SME, 2013, BRAIN LANG, V127, P205, DOI 10.1016/j.bandl.2012.11.002
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Glasser MF, 2008, CEREB CORTEX, V18, P2471, DOI 10.1093/cercor/bhn011
   Griffiths JD, 2013, CEREB CORTEX, V23, P139, DOI 10.1093/cercor/bhr386
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hellbernd N, 2016, J MEM LANG, V88, P70, DOI 10.1016/j.jml.2016.01.001
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hofer S, 2006, NEUROIMAGE, V32, P989, DOI 10.1016/j.neuroimage.2006.05.044
   Horn W., 1983, LEISTUNGSPRIIFSYSTEM
   Houde JF, 2015, CURR OPIN NEUROBIOL, V33, P174, DOI 10.1016/j.conb.2015.04.006
   Huang H, 2005, NEUROIMAGE, V26, P195, DOI 10.1016/j.neuroimage.2005.01.019
   Ischebeck AK, 2008, CEREB CORTEX, V18, P541, DOI 10.1093/cercor/bhm083
   Jamison HL, 2006, CEREB CORTEX, V16, P1266, DOI 10.1093/cercor/bhj068
   Johnsrude IS, 2000, BRAIN, V123, P155, DOI 10.1093/brain/123.1.155
   Kellmeyer P, 2013, BRAIN LANG, V127, P241, DOI 10.1016/j.bandl.2013.09.011
   Koelsch S, 2005, CURR OPIN NEUROBIOL, V15, P207, DOI 10.1016/j.conb.2005.03.005
   Kotz SA, 2011, LANG LINGUIST COMPAS, V5, P108, DOI 10.1111/j.1749-818x.2010.00267.x
   Krawczyk DC, 2012, BRAIN RES, V1428, P13, DOI 10.1016/j.brainres.2010.11.080
   Kreiner H, 2014, BRAIN LANG, V137, P91, DOI 10.1016/j.bandl.2014.08.004
   Kreitewolf J, 2014, NEUROIMAGE, V102, P332, DOI 10.1016/j.neuroimage.2014.07.038
   Kummerer D, 2013, BRAIN, V136, P619, DOI 10.1093/brain/aws354
   Kyong JS, 2014, J COGNITIVE NEUROSCI, V26, P1748, DOI 10.1162/jocn_a_00583
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   Lazar M, 2003, HUM BRAIN MAPP, V18, P306, DOI 10.1002/hbm.10102
   Lehiste Ilse, 1973, GLOSSA, V7, P107, DOI DOI 10.1121/1.1982702
   Loui P, 2009, J NEUROSCI, V29, P10215, DOI 10.1523/JNEUROSCI.1701-09.2009
   Makris N, 2009, BRAIN STRUCT FUNCT, V213, P343, DOI 10.1007/s00429-008-0199-8
   Mauchly JW, 1940, ANN MATH STAT, V11, P204, DOI 10.1214/aoms/1177731915
   McGettigan C, 2012, TRENDS COGN SCI, V16, P269, DOI 10.1016/j.tics.2012.04.006
   Meixensberger J, 2005, ACTA NEUROCHIR, V147, P952
   Merrill J, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00076
   Meyer L, 2014, NEUROPSYCHOLOGIA, V61, P190, DOI 10.1016/j.neuropsychologia.2014.06.014
   Meyer M, 2004, BRAIN LANG, V89, P277, DOI 10.1016/S0093-934X(03)00350-X
   Meyer M, 2002, HUM BRAIN MAPP, V17, P73, DOI 10.1002/hbm.10042
   Mori S., 2007, INTRO DIFFUSION TENS
   Nespor Marina, 1986, PROSODIC PHONOLOGY
   Nishizaki T, 1999, BRIT J NEUROSURG, V13, P52, DOI 10.1080/02688699944186
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008
   Parker GJM, 2005, NEUROIMAGE, V24, P656, DOI 10.1016/j.neuroimage.2004.08.047
   Paulmann S., 2016, NEUROBIOLOGY LANGUAG, P1109
   Peretz I, 2016, TRENDS COGN SCI, V20, P857, DOI 10.1016/j.tics.2016.09.002
   Perkins JM, 1996, APHASIOLOGY, V10, P343, DOI 10.1080/02687039608248416
   Perrone-Bertolotti M, 2013, HUM BRAIN MAPP, V34, P2574, DOI 10.1002/hbm.22090
   Peschke C, 2012, NEUROIMAGE, V59, P788, DOI 10.1016/j.neuroimage.2011.07.025
   Pierrehumbert J., 1990, INTENTIONS COMMUNICA
   Plante E, 2002, NEUROIMAGE, V17, P401, DOI 10.1006/nimg.2002.1182
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Powell HWR, 2006, NEUROIMAGE, V32, P388, DOI 10.1016/j.neuroimage.2006.03.011
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rockhill J, 2007, NEUROSURG FOCUS, V23, pEl, DOI DOI 10.3171/FOC-07/10/E1
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Sammler D, 2010, BRAIN, V133, P2643, DOI 10.1093/brain/awq231
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schlaug G, 2009, ANN NY ACAD SCI, V1169, P385, DOI 10.1111/j.1749-6632.2009.04587.x
   Schonwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   SELKIRK ELISABETH, 1996, HDB PHONOLOGICAL THE, P550
   Selkirk Elizabeth, 1984, PHONOLOGY SYNTAX REL
   SHIPLEYBROWN F, 1988, BRAIN LANG, V33, P16, DOI 10.1016/0093-934X(88)90051-X
   Shokri-Kojori E, 2012, SCI REP-UK, V2, DOI 10.1038/srep00411
   Skeide MA, 2016, CEREB CORTEX, V26, P2127, DOI 10.1093/cercor/bhv042
   Snedeker J, 2003, J MEM LANG, V48, P103, DOI 10.1016/S0749-596X(02)00519-3
   Steinmann S, 2012, J NEUROLINGUIST, V25, P1, DOI 10.1016/j.jneuroling.2011.07.003
   Stokum JA, 2016, J CEREBR BLOOD F MET, V36, P513, DOI 10.1177/0271678X15617172
   Strelnikov KN, 2006, NEUROIMAGE, V29, P1127, DOI 10.1016/j.neuroimage.2005.08.021
   Tang C, 2017, SCIENCE, V357, P797, DOI 10.1126/science.aam8577
   Thiebaut de Schotten M, 2011, NAT NEUROSCI, V14, P1245, DOI 10.1038/nn.2905
   Thiebaut de Schotten M, 2011, NEUROIMAGE, V54, P49, DOI 10.1016/j.neuroimage.2010.07.055
   Thorndike R. M., 2013, MEASUREMENT EVALUATI
   van Lancker D., 1980, PAP LINGUIST, V13, P201, DOI [10.1080/08351818009370498, DOI 10.1080/08351818009370498]
   Vassal M, 2010, J NEUROSURG, V113, P1251, DOI 10.3171/2010.6.JNS10719
   Wagner M, 2010, LANG COGNITIVE PROC, V25, P905, DOI 10.1080/01690961003589492
   Watson CE, 2012, NEUROIMAGE, V59, P2831, DOI 10.1016/j.neuroimage.2011.09.030
   Watson D, 2004, LANG COGNITIVE PROC, V19, P713, DOI 10.1080/01690960444000070
   Wechsler D, 1987, WECHSLER MEMORY SCAL
   Wildgruber D, 2006, PROG BRAIN RES, V156, P249, DOI 10.1016/S0079-6123(06)56013-3
   Wildgruber D, 2009, INT J SPEECH-LANG PA, V11, P277, DOI DOI 10.1080/17549500902943043
   Wilson SM, 2011, NEURON, V72, P397, DOI 10.1016/j.neuron.2011.09.014
   Witteman J, 2012, NEUROPSYCHOLOGIA, V50, P2752, DOI 10.1016/j.neuropsychologia.2012.07.026
   Witteman J, 2011, NEUROPSYCHOLOGIA, V49, P3722, DOI 10.1016/j.neuropsychologia.2011.09.028
   Zarate JM, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00237
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 121
TC 6
Z9 6
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD AUG
PY 2018
VL 183
BP 1
EP 10
DI 10.1016/j.bandl.2018.05.001
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA GP4XN
UT WOS:000440875800001
PM 29758365
DA 2021-02-24
ER

PT J
AU Vollmer, M
AF Vollmer, Maike
TI Neural Processing of Acoustic and Electric Interaural Time Differences
   in Normal-Hearing Gerbils
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE binaural hearing; cochlear implant; inferior colliculus; interaural time
   difference; lateral lemniscus; temporal processing
ID BILATERAL COCHLEAR IMPLANTS; MEDIAL SUPERIOR OLIVE; LOW-FREQUENCY
   NEURONS; STIMULATED AUDITORY-NERVE; CATS INFERIOR COLLICULUS;
   SINGLE-FIBER RESPONSES; SOUND LOCALIZATION; BINAURAL INTERACTION;
   UNANESTHETIZED RABBIT; INTENSITY DIFFERENCES
AB Bilateral cochlear implants (CIs) provide benefits for speech perception in noise and directional hearing, but users typically show poor sensitivity to interaural time differences (ITDs). Possible explanations for this deficit are deafness-induced degradations in neural ITD sensitivity, between-ear mismatches in electrode positions or activation sites, or differences in binaural brain circuits activated by electric versus acoustic stimulation. To identify potential limitations of electric ITD coding in the normal-hearing system, responses of single neurons in the dorsal nucleus of the lateral lemniscus and in the inferior colliculus to ITDs of electric (biphasic pulses) and acoustic (noise, clicks, chirps, and tones) stimuli were recorded in normal-hearing gerbils of either sex. To maintain acoustic sensitivity, electric stimuli were delivered to the round window. ITD tuning metrics (e.g., best ITD) and ITD discrimination thresholds for electric versus transient acoustic stimuli (clicks, chirps) obtained from the same neurons were not significantly correlated. Across populations of neurons with similar characteristic frequencies, however, ITD tuning metrics and ITD discrimination thresholds were similar for electric and acoustic stimuli and largely independent of the spectrotemporal properties of the acoustic stimuli when measured in the central range of ITDs. The similarity of acoustic and electric ITD coding on the population level in animals with normal hearing experience suggests that poorer ITD sensitivity in bilateral CI users compared with normalhearing listeners is likely due to deprivation-induced changes in neural ITD coding rather than to differences in the binaural brain circuits involved in the processing of electric and acoustic ITDs.
C1 [Vollmer, Maike] Univ Hosp Wuerzburg, Comprehens Hearing Ctr, D-97080 Wurzburg, Germany.
   [Vollmer, Maike] Otto Von Guericke Univ, Univ Hosp Magdeburg, Dept Otolaryngol Head & Neck Surg, Leipziger Str 44, D-39120 Magdeburg, Germany.
   [Vollmer, Maike] Leibniz Inst Neurobiol, Ctr Learning & Memory Res, D-39118 Magdeburg, Germany.
RP Vollmer, M (corresponding author), Otto Von Guericke Univ, Univ Hosp Magdeburg, Dept Otolaryngol Head & Neck Surg, Leipziger Str 44, D-39120 Magdeburg, Germany.
EM maike.vollmer@med.ovgu.de
FU Deutsche Forschungsgemeinschaft (Priority Program 1608 "Ultrafast and
   Temporally Precise Information Processing: Normal and Dysfunctional
   Hearing") [VO 640/2-1, VO 640/2-2]; Interdisciplinary Center for
   Clinical Research [N-100]
FX This work was supported by the Deutsche Forschungsgemeinschaft (Priority
   Program 1608 "Ultrafast and Temporally Precise Information Processing:
   Normal and Dysfunctional Hearing", Grants VO 640/2-1 and VO 640/2-2 to
   M.V.) and the Interdisciplinary Center for Clinical Research (Grant
   N-100 to M.V.). I thank Otto Gleich and Peter Heil for valuable comments
   on the manuscript, Armin Wiegner and Tristan Bremer for programming and
   hardware support, Martin Kempe for help with ABR recordings, Barbara
   Kellner for assistance with histological preparations, and Rainer
   Brandtner for laboratory animal care. Cochlear implants were provided by
   MedEl (Innsbruck, Austria).
CR Aronoff JM, 2010, J ACOUST SOC AM, V127, pEL87, DOI 10.1121/1.3298451
   Batra R, 1997, J NEUROPHYSIOL, V78, P1222
   Belliveau LAC, 2014, J NEUROSCI, V34, P16796, DOI 10.1523/JNEUROSCI.2432-14.2014
   Bender KJ, 2011, NEUROPHARMACOLOGY, V60, P774, DOI 10.1016/j.neuropharm.2010.12.021
   BENEVENTO LA, 1970, BRAIN RES, V17, P387, DOI 10.1016/0006-8993(70)90248-9
   Bourk TR, 1976, THESIS
   Brand A, 2002, NATURE, V417, P543, DOI 10.1038/417543a
   BRUNSOBECHTOLD JK, 1981, J COMP NEUROL, V197, P705, DOI 10.1002/cne.901970410
   Burkard R, 2006, BRAIN RES, V1091, P27, DOI 10.1016/j.brainres.2006.02.132
   CAIRD D, 1987, EXP BRAIN RES, V68, P379
   CARNEY LH, 1988, J NEUROPHYSIOL, V60, P1653
   CARNEY LH, 1989, J NEUROPHYSIOL, V62, P144
   Chung Y, 2016, J NEUROSCI, V36, P5520, DOI 10.1523/JNEUROSCI.3795-15.2016
   Day ML, 2011, J NEUROPHYSIOL, V106, P1985, DOI 10.1152/jn.00131.2011
   Devore S, 2009, NEURON, V62, P123, DOI 10.1016/j.neuron.2009.02.018
   DYNES SBC, 1992, HEARING RES, V58, P79, DOI 10.1016/0378-5955(92)90011-B
   Earl BR, 2012, J ACOUST SOC AM, V131, P337, DOI 10.1121/1.3664052
   Fitzpatrick DC, 2000, J NEUROSCI, V20, P1605
   GEISLER CD, 1969, J NEUROPHYSIOL, V32, P960
   GLENDENNING KK, 1983, J NEUROSCI, V3, P1521
   GODFREY DA, 1975, J COMP NEUROL, V162, P247, DOI 10.1002/cne.901620206
   GODFREY DA, 1975, J COMP NEUROL, V162, P269, DOI 10.1002/cne.901620207
   GOLDBERG JM, 1969, J NEUROPHYSIOL, V32, P613
   Grothe B, 2014, FRONT NEURAL CIRCUIT, V8, DOI 10.3389/fncir.2014.00116
   Guinan JJ, 2005, J ACOUST SOC AM, V118, P2421, DOI 10.1121/1.2017899
   Hamzavi J, 2006, ACTA OTO-LARYNGOL, V126, P1182, DOI 10.1080/00016480600672683
   Hancock KE, 2004, J NEUROSCI, V24, P7110, DOI 10.1523/JNEUROSCI.0762-04.2004
   Hancock KE, 2013, JARO-J ASSOC RES OTO, V14, P393, DOI 10.1007/s10162-013-0380-5
   Hancock KE, 2010, J NEUROSCI, V30, P14068, DOI 10.1523/JNEUROSCI.3213-10.2010
   HARTMANN R, 1984, HEARING RES, V13, P47, DOI 10.1016/0378-5955(84)90094-7
   He SM, 2012, EAR HEARING, V33, P57, DOI 10.1097/AUD.0b013e31822519ef
   Heil P, 2015, CELL TISSUE RES, V361, P129, DOI 10.1007/s00441-015-2177-9
   Hu H.M, 2015, TRENDS HEAR, V19
   Hutson KA, 2018, ASS RES OTOLARYNGOL, V41, P28
   Javel E, 2000, HEARING RES, V140, P45, DOI 10.1016/S0378-5955(99)00186-0
   JEFFRESS LA, 1948, J COMP PHYSIOL PSYCH, V41, P35, DOI 10.1037/h0061495
   Jercog PE, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000406
   Joris PX, 2006, P NATL ACAD SCI USA, V103, P12917, DOI 10.1073/pnas.0601396103
   Joris PX, 1998, J NEUROPHYSIOL, V79, P253
   Joshi SN, 2017, JARO-J ASSOC RES OTO, V18, P323, DOI 10.1007/s10162-016-0608-2
   Kan A, 2015, HEARING RES, V322, P127, DOI 10.1016/j.heares.2014.08.005
   Kan A, 2013, J ACOUST SOC AM, V134, P2923, DOI 10.1121/1.4820889
   Kiang NYS, 1973, BASIC MECHANISMS HEA, P455
   KIANG NYS, 1975, NERVOUS SYSTEM, P81
   Kiang NYS, 1965, MIT RESMONOGR, V65
   Krumbholz K, 2000, J ACOUST SOC AM, V108, P1170, DOI 10.1121/1.1287843
   KUWADA S, 1987, J NEUROPHYSIOL, V57, P1338
   Kuwada S, 2006, J NEUROPHYSIOL, V95, P1309, DOI 10.1152/jn.00901.2005
   Laback B, 2015, HEARING RES, V322, P138, DOI 10.1016/j.heares.2014.10.004
   Landsberger DM, 2016, EAR HEARING, V37, pE149, DOI 10.1097/AUD.0000000000000250
   Landsberger DM, 2014, J ACOUST SOC AM, V135, pEL75, DOI 10.1121/1.4862875
   LEAKE PA, 1995, HEARING RES, V82, P65
   Litovsky R, 2006, EAR HEARING, V27, P714, DOI 10.1097/01.aud.0000246816.50820.42
   Litovsky RY, 2010, J ACOUST SOC AM, V127, P400, DOI 10.1121/1.3257546
   LUSTED HS, 1984, J ACOUST SOC AM, V76, P449, DOI 10.1121/1.391586
   Macherey O, 2011, JARO-J ASSOC RES OTO, V12, P233, DOI 10.1007/s10162-010-0248-x
   Macpherson EA, 2002, J ACOUST SOC AM, V111, P2219, DOI 10.1121/1.1471898
   Majdak P, 2006, J ACOUST SOC AM, V120, P2190, DOI 10.1121/1.2258390
   MAKI K, 2003, ASS RES OT ABSTR, V26, P89
   McAlpine D, 1998, J NEUROSCI, V18, P6026
   McAlpine D, 2003, TRENDS NEUROSCI, V26, P347, DOI 10.1016/S0166-2236(03)00140-1
   McAlpine D, 2001, NAT NEUROSCI, V4, P396, DOI 10.1038/86049
   McKay CM, 1999, J ACOUST SOC AM, V105, P347, DOI 10.1121/1.424553
   Middlebrooks JC, 2010, J NEUROSCI, V30, P1937, DOI 10.1523/JNEUROSCI.4949-09.2010
   Miller CA, 1999, HEARING RES, V130, P197, DOI 10.1016/S0378-5955(99)00012-X
   Miller CA, 2006, JARO-J ASSOC RES OTO, V7, P195, DOI 10.1007/s10162-006-0036-9
   Moxon E. C., 1971, THESIS
   Pecka M, 2008, J NEUROSCI, V28, P6914, DOI 10.1523/JNEUROSCI.1660-08.2008
   PFEIFFER RR, 1972, J ACOUST SOC AM, V52, P1669, DOI 10.1121/1.1913301
   PFEIFFER RR, 1966, EXP BRAIN RES, V1, P220
   Plauska A, 2017, J NEUROSCI, V37, P7278, DOI 10.1523/JNEUROSCI.0233-17.2017
   Ricketts TA, 2006, EAR HEARING, V27, P763, DOI 10.1097/01.aud.0000240814.27151.b9
   SAKITT B, 1973, NATURE, V241, P133, DOI 10.1038/241133a0
   Sato M, 2016, J NEUROSCI, V36, P54, DOI 10.1523/JNEUROSCI.2968-15.2016
   Schatzer R, 2014, HEARING RES, V309, P26, DOI 10.1016/j.heares.2013.11.003
   Seeber BU, 2008, J ACOUST SOC AM, V123, P1030, DOI 10.1121/1.2821965
   Seidl AH, 2005, J NEUROPHYSIOL, V94, P1028, DOI 10.1152/jn.01143.2004
   SHAMMA SA, 1989, J ACOUST SOC AM, V86, P989, DOI 10.1121/1.398734
   Shepherd RK, 1999, HEARING RES, V130, P171, DOI 10.1016/S0378-5955(99)00011-8
   Siveke I, 2006, J NEUROPHYSIOL, V96, P1425, DOI 10.1152/jn.00713.2005
   Smith ZM, 2007, J NEUROSCI, V27, P6740, DOI 10.1523/JNEUROSCI.0052-07.2007
   SPITZER MW, 1995, J NEUROPHYSIOL, V73, P1668
   Stahl P, 2016, J ACOUST SOC AM, V139, P1578, DOI 10.1121/1.4944564
   Stange A, 2013, NAT NEUROSCI, V16, P1840, DOI 10.1038/nn.3548
   Stecker GC, 2005, PLOS BIOL, V3, P520, DOI 10.1371/journal.pbio.0030078
   Takesian AE, 2009, FUTUR NEUROL, V4, P331, DOI 10.2217/FNL.09.5
   Tillein J, 2010, CEREB CORTEX, V20, P492, DOI 10.1093/cercor/bhp222
   Undurraga JA, 2016, JARO-J ASSOC RES OTO, V17, P591, DOI 10.1007/s10162-016-0584-6
   van Hoesel RJM, 2012, HEARING RES, V288, P100, DOI 10.1016/j.heares.2011.11.014
   VANDENHONERT C, 1984, HEARING RES, V14, P225, DOI 10.1016/0378-5955(84)90052-2
   Vollmer M, 2008, ASS RES OTOLARYNGOL, V31, P298
   Wiegner A, 2016, J NEUROSCI METH, V273, P40, DOI 10.1016/j.jneumeth.2016.08.006
   WIGHTMAN FL, 1992, J ACOUST SOC AM, V91, P1648, DOI 10.1121/1.402445
   YIN TCT, 1987, J NEUROPHYSIOL, V58, P562
   YIN TCT, 1990, J NEUROPHYSIOL, V64, P465
   YIN TCT, 1986, J NEUROPHYSIOL, V55, P280
   YIN TCT, 1983, J NEUROPHYSIOL, V50, P1000
   YIN TCT, 1983, J NEUROPHYSIOL, V50, P1020
NR 98
TC 4
Z9 4
U1 0
U2 6
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
J9 J NEUROSCI
JI J. Neurosci.
PD AUG 1
PY 2018
VL 38
IS 31
BP 6949
EP 6966
DI 10.1523/JNEUROSCI.3328-17.2018
PG 18
WC Neurosciences
SC Neurosciences & Neurology
GA GP1CV
UT WOS:000440551400012
PM 29959238
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU McMurray, B
   Danelz, A
   Rigler, H
   Seedorff, M
AF McMurray, Bob
   Danelz, Ani
   Rigler, Hannah
   Seedorff, Michael
TI Speech Categorization Develops Slowly Through Adolescence
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE speech perception; real-time processing; eye-tracking; development;
   adolescence
ID SPOKEN-WORD RECOGNITION; WITHIN-CATEGORY VARIATION; INFANT-DIRECTED
   SPEECH; LEXICAL ACCESS; INDIVIDUAL-DIFFERENCES; LANGUAGE IMPAIRMENT;
   DISTRIBUTIONAL INFORMATION; PERCEPTUAL REORGANIZATION; PHONOLOGICAL
   AWARENESS; VOICING CATEGORIES
AB The development oi the ability to categorize speech sounds is often viewed as occurring primarily during infancy via perceptual learning mechanisms. However, a number of studies suggest that even after infancy, children's categories become more categorical and well defined through about age 12. We investigated the cognitive changes that may be lesponsible for such development using a visual world paradigm experiment based on (McMurray, Tanenhaus, & Aslin, 2002). Children from 3 age groups (7-8, 12-13, and 17-18 years) heard a token from either a b/p oi s/f continua spanning 2 words (beach/peach, ship/sip) and selected its referent from a screen containing 4 pictures of potential lexical candidates. Eye movements to each object were monitored as a measure of how strongly children were committing to each candidate as perception unfolds in real-time. Results showed an ongoing sharpening of speech categories through 18, which was particularly apparent during the early stages of real-time perception. When analysis targeted to specifically within-category sensitivity to continuous detail, children exhibited increasingly gradient categories over development, suggesting that increasing sensitivity to fine-grained detail in the signal enables these more discrete categorizations. Together these suggest that speech development is a protracted process in which children's increasing sensitivity to within-category detail in the signal enables increasingly sharp phonetic categories.
C1 [McMurray, Bob] Univ Iowa, Dept Psychol & Brain Sci, Dept Commun Sci & Disorders, Dept Linguist, Ia City, IA 52245 USA.
   [McMurray, Bob] Univ Iowa, Dept Otolaryngol, Ia City, IA 52245 USA.
   [Danelz, Ani] Univ Iowa, Dept Commun Sci & Disorders, Ia City, IA 52245 USA.
   [Rigler, Hannah] Univ Iowa, Dept Psychol, Ia City, IA 52245 USA.
   [Seedorff, Michael] Univ Iowa, Dept Biostat, Ia City, IA 52245 USA.
RP McMurray, B (corresponding author), Univ Iowa, Dept Psychol & Brain Sci, 1 SSH, Ia City, IA 52245 USA.
EM bob-mcmurray@uiowa.edu
OI McMurray, Bob/0000-0002-6532-284X
FU [DC0008089];  [DC000242]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC008089, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   R01DC008089, P50DC000242, P50DC000242, R01DC008089, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, R01DC008089,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, R01DC008089, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, R01DC008089, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242] Funding Source: NIH RePORTER
FX This project was supported by DC0008089 awarded to Bob McMurray and
   DC000242 awarded to Bob McMurray and Bruce Gantz. We thank Ashley
   Farris-Trimble for consultation on the design of the study and for
   generating stimuli and Tyler Ellis and Claire Goodwin for assistance
   with data collection.
CR ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Benjamini Y., 1985, J ROYAL STAT SOC B, V57, P289
   BERNSTEIN LE, 1983, J PHONETICS, V11, P383, DOI 10.1016/S0095-4470(19)30837-X
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Bishop DVM, 2004, PSYCHOL BULL, V130, P858, DOI 10.1037/0033-2909.130.6.858
   Bus AG, 1999, J EDUC PSYCHOL, V91, P403, DOI 10.1037/0022-0663.91.3.403
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Coady JA, 2007, J SPEECH LANG HEAR R, V50, P41, DOI 10.1044/1092-4388(2007/004)
   Cristia A, 2014, J CHILD LANG, V41, P913, DOI 10.1017/S0305000912000669
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   de Boer B, 2003, ACOUST RES LETT ONL, V4, P129, DOI 10.1121/1.1613311
   Dich N, 2013, LINGUA, V133, P213, DOI 10.1016/j.lingua.2013.04.010
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   Dollaghan C, 1998, APPL PSYCHOLINGUIST, V19, P193, DOI 10.1017/S0142716400010031
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   Ehri LC, 2001, READ RES QUART, V36, P250, DOI 10.1598/RRQ.36.3.2
   EILERS RE, 1975, J SPEECH HEAR RES, V18, P158, DOI 10.1044/jshr.1801.158
   Farris-Trimble A, 2013, J SPEECH LANG HEAR R, V56, P1328, DOI 10.1044/1092-4388(2012/12-0145)
   Feldman NH, 2013, PSYCHOL REV, V120, P751, DOI 10.1037/a0034245
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Galle M., 2014, THESIS
   Galle M. E., 2018, WHAT ARE YOU WAITING
   Galle ME, 2014, PSYCHON B REV, V21, P884, DOI 10.3758/s13423-013-0569-y
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   Hart B., 1995, MEANINGFUL DIFFERENC
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   HEALY AF, 1982, J EXP PSYCHOL HUMAN, V8, P68, DOI 10.1037/0096-1523.8.1.68
   Ishida M, 2016, COGNITION, V151, P68, DOI 10.1016/j.cognition.2016.03.008
   JUSCZYK PW, 1993, J PHONETICS, V21, P3, DOI 10.1016/S0095-4470(19)31319-1
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1979, J ACOUST SOC AM, V66, P1668, DOI 10.1121/1.383639
   Law F, 2017, APPL PSYCHOLINGUIST, V38, P89, DOI 10.1017/S0142716416000126
   Luce R.D., 1959, INDIVIDUAL CHOICE BE
   Mainela-Arnold E, 2008, J SPEECH LANG HEAR R, V51, P381, DOI 10.1044/1092-4388(2008/028)
   MarslenWilson W, 1996, J EXP PSYCHOL HUMAN, V22, P1376, DOI 10.1037/0096-1523.22.6.1376
   Martin A, 2015, PSYCHOL SCI, V26, P341, DOI 10.1177/0956797614562453
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McArthur GM, 2004, COGN NEUROPSYCHOL, V21, P79, DOI 10.1080/02643290342000087
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B., 2012, OXFORD HDB LAB PHONO, P369
   McMurray B, 2017, NONLINEAR CURVEFITTI
   McMurray B, 2016, EAR HEARING, V37, pe37, DOI 10.1097/AUD.0000000000000207
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   Miller JL, 1997, PHONETICA, V54, P121, DOI 10.1159/000262217
   Miller JL, 1996, PERCEPT PSYCHOPHYS, V58, P1157, DOI 10.3758/BF03207549
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nearey T. M., 1986, EXPT PHONOLOGY, P141
   Nittrouer S, 2004, J ACOUST SOC AM, V115, P1777, DOI 10.1121/1.1651192
   NITTROUER S, 1992, J PHONETICS, V20, P351, DOI 10.1016/S0095-4470(19)30639-4
   Nittrouer S, 1997, J ACOUST SOC AM, V101, P2253, DOI 10.1121/1.418207
   Nittrouer S, 2002, J ACOUST SOC AM, V112, P711, DOI 10.1121/1.1496082
   Parrila R, 2004, SCI STUD READ, V8, P3, DOI 10.1207/s1532799xssr0801_2
   Rigler H, 2015, DEV PSYCHOL, V51, P1690, DOI 10.1037/dev0000044
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Sadagopan N, 2008, J SPEECH LANG HEAR R, V51, P1138, DOI 10.1044/1092-4388(2008/06-0222)
   Sekerina IA, 2007, J EXP CHILD PSYCHOL, V98, P20, DOI 10.1016/j.jecp.2007.04.005
   Semel E., 2006, CELF 4 CLIN EVALUATI
   Slawinski EB, 1998, J PHONETICS, V26, P27, DOI 10.1006/jpho.1997.0057
   Spivey M, 2007, CONTINUITY MIND
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   THIBODEAU LM, 1979, J PHONETICS, V7, P375, DOI 10.1016/S0095-4470(19)31071-X
   Thiessen ED, 2016, J MEM LANG, V88, P117, DOI 10.1016/j.jml.2016.01.003
   Torgesen J. K., 1997, SCI STUD READ, V1, P161, DOI DOI 10.1207/S1532799XSSR0102_4
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Utman JA, 2000, PERCEPT PSYCHOPHYS, V62, P1297, DOI 10.3758/BF03212131
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
   Wechsler D., 2011, WECHSLER ABBREVIATED
   WELSH MC, 1988, DEV NEUROPSYCHOL, V4, P199, DOI 10.1080/87565648809540405
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1993, J PHONETICS, V21, P83, DOI 10.1016/S0095-4470(19)31322-1
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Zangl R, 2005, J COGN DEV, V6, P179, DOI 10.1207/s15327647jcd0602_2
NR 91
TC 10
Z9 10
U1 1
U2 14
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD AUG
PY 2018
VL 54
IS 8
BP 1472
EP 1491
DI 10.1037/dev0000542
PG 20
WC Psychology, Developmental
SC Psychology
GA GO3TI
UT WOS:000439918200007
PM 29952600
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Ipser, A
   Karlinski, M
   Freeman, ED
AF Ipser, Alberta
   Karlinski, Maayan
   Freeman, Elliot D.
TI Correlation of Individual Differences in Audiovisual Asynchrony Across
   Stimuli and Tasks: New Constraints on Temporal Renormalization Theory
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE individual differences; multisensory integration; perceptual timing;
   speech perception
ID MULTISENSORY INTEGRATION; SYNCHRONY PERCEPTION; SIMULTANEITY; SPEECH;
   ORDER; SOUND; TIME; RECALIBRATION; JUDGMENT; VENTRILOQUISM
AB Sight and sound are out of synch in different people by different amounts for different tasks. But surprisingly, different concurrent measures of perceptual asynchrony correlate negatively (Freeman et al., 2013). Thus, if vision subjectively leads audition in one individual, the same individual might show a visual lag in other measures of audiovisual integration (e.g., McGurk illusion, Stream-Bounce illusion). This curious negative correlation was first observed between explicit temporal order judgments and implicit phoneme identification tasks, performed concurrently as a dual task, using incongruent McGurk stimuli. Here we used a new set of explicit and implicit tasks and congruent stimuli, to test whether this negative correlation persists across testing sessions, and whether it might be an artifact of using specific incongruent stimuli. None of these manipulations eliminated the negative correlation between explicit and implicit measures. This supports the generalizability and validity of the phenomenon, and offers new theoretical insights into its explanation. Our previously proposed "temporal renormalization" theory assumes that the timings of sensory events registered within the brain's different multimodal subnetworks are each perceived relative to a representation of the typical average timing of such events across the wider network. Our new data suggest that this representation is stable and generic, rather than dependent on specific stimuli or task contexts, and that it may be acquired through experience with a variety of simultaneous stimuli. Our results also add further evidence that speech comprehension may be improved in some individuals by artificially delaying voices relative to lip-movements.
C1 [Ipser, Alberta; Karlinski, Maayan; Freeman, Elliot D.] City Univ London, Dept Psychol, Northampton Sq, London EC1V 0HB, England.
   [Ipser, Alberta] Univ Sussex, Dept Psychol, Brighton, E Sussex, England.
RP Freeman, ED (corresponding author), City Univ London, Dept Psychol, Northampton Sq, London EC1V 0HB, England.
EM elliot.freeman@city.ac.uk
OI Freeman, Elliot/0000-0001-7234-824X
FU British Academy/Leverhulme Grant [SG151380]
FX We thank Leima Gheran and Mayara de Paula for assistance with data
   collection. This research was supported by a British Academy/Leverhulme
   Grant SG151380.
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Dennett D, 1995, BEHAV BRAIN SCI, V15, P1, DOI [10.1017/S0140525X02330061, DOI 10.1017/S0140525X02330061]
   EFRON R, 1963, BRAIN, V86, P261, DOI 10.1093/brain/86.2.261
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Freeman E, 2008, CURR BIOL, V18, P1262, DOI 10.1016/j.cub.2008.07.066
   Freeman ED, 2013, CORTEX, V49, P2875, DOI 10.1016/j.cortex.2013.03.006
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Grabot L, 2017, PSYCHOL SCI, V28, P670, DOI 10.1177/0956797616689369
   Hairston WD, 2005, EXP BRAIN RES, V166, P474, DOI 10.1007/s00221-005-2387-6
   HALLIDAY AM, 1964, Q J EXP PSYCHOL, V16, P35, DOI 10.1080/17470216408416344
   Hanson JVM, 2008, EXP BRAIN RES, V185, P347, DOI 10.1007/s00221-008-1282-3
   Harris L. R., 2008, ISSUES SPACE TIME PE, P232
   Ipser A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46413
   Ivry RB, 2004, CURR OPIN NEUROBIOL, V14, P225, DOI 10.1016/j.conb.2004.03.013
   Keetels M, 2012, NEURAL BASES MULTISE, P1
   King AJ, 2005, CURR BIOL, V15, pR339, DOI 10.1016/j.cub.2005.04.022
   Kopinska A, 2004, PERCEPTION, V33, P1049, DOI 10.1068/p5169
   Love SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054798
   Machulla TK, 2016, J EXP PSYCHOL HUMAN, V42, P1026, DOI 10.1037/xhp0000191
   Maier JX, 2011, J EXP PSYCHOL HUMAN, V37, P245, DOI 10.1037/a0019952
   Martin B, 2013, NEUROPSYCHOLOGIA, V51, P358, DOI 10.1016/j.neuropsychologia.2012.07.002
   Mauk MD, 2004, ANNU REV NEUROSCI, V27, P307, DOI 10.1146/annurev.neuro.27.070203.144247
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miyazaki M, 2006, NAT NEUROSCI, V9, P875, DOI 10.1038/nn1712
   Mollon JD, 1996, NATURE, V380, P101, DOI 10.1038/380101a0
   Morein-Zamir S, 2003, COGNITIVE BRAIN RES, V17, P154, DOI 10.1016/S0926-6410(03)00089-2
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Petrini K, 2010, J VISION, V10, DOI 10.1167/10.5.2
   Popple E, 1988, MINDWORKS TIME CONSC
   Scharnowski F, 2013, TRENDS COGN SCI, V17, P51, DOI 10.1016/j.tics.2012.12.005
   Schneider KA, 2003, COGNITIVE PSYCHOL, V47, P333, DOI 10.1016/S0010-0285(03)00035-5
   Sekuler R, 1997, NATURE, V385, P308, DOI 10.1038/385308a0
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   Soto-Faraco S, 2007, NEUROREPORT, V18, P347, DOI 10.1097/WNR.0b013e32801776f9
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   Sternberg S., 1973, ATTENTION PERFORM, VIV, P629
   Stone JV, 2001, P ROY SOC B-BIOL SCI, V268, P31, DOI 10.1098/rspb.2000.1326
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   TREISMAN M, 1963, PSYCHOL MONOGR, V77, P1, DOI 10.1037/h0093864
   van Eijk RLJ, 2008, PERCEPT PSYCHOPHYS, V70, P955, DOI 10.3758/PP.70.6.955
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vatakis A, 2008, EXP BRAIN RES, V185, P521, DOI 10.1007/s00221-007-1168-9
   Vatakis A, 2007, PERCEPT PSYCHOPHYS, V69, P744, DOI 10.3758/BF03193776
   Vlaming MSMG, 2014, EAR HEARING, V35, P667, DOI 10.1097/AUD.0000000000000073
   Vroomen J, 2004, J EXP PSYCHOL HUMAN, V30, P513, DOI 10.1037/0096-1523.30.3.513
   Vroomen J, 2011, COGNITION, V118, P75, DOI 10.1016/j.cognition.2010.10.002
   Yamamoto S, 2012, PLOS ONE, V7
   Yarrow K, 2011, CONSCIOUS COGN, V20, P1518, DOI 10.1016/j.concog.2011.07.003
   Yuan XY, 2014, NEUROSCI LETT, V569, P148, DOI 10.1016/j.neulet.2014.03.057
   Zeki S, 1998, P ROY SOC B-BIOL SCI, V265, P1583, DOI 10.1098/rspb.1998.0475
NR 52
TC 4
Z9 4
U1 1
U2 7
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD AUG
PY 2018
VL 44
IS 8
BP 1283
EP 1293
DI 10.1037/xhp0000535
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA GO3VB
UT WOS:000439924500011
PM 29733674
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Viebahn, MC
   Luce, PA
AF Viebahn, Malte C.
   Luce, Paul A.
TI Increased exposure and phonetic context help listeners recognize
   allophonic variants
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech reduction; Spoken word recognition; Allophonic variation;
   Flapping
ID SPOKEN WORD RECOGNITION; REDUCED PRONUNCIATION VARIANTS;
   SPEECH-PERCEPTION; FOREIGN ACCENT; LEXICAL ACCESS; TIME-COURSE;
   REPRESENTATION; ACTIVATION; COMPREHENSION; FORMS
AB This study examines the influence of increased exposure and phonetic context on the recognition of words that are produced with nasal flaps in American English (e.g., the word center produced as cenner). Previous work has shown that despite their high frequency of occurrence, words produced with nasal flaps are recognized more slowly and less accurately compared with canonical pronunciation variants produced with /nt/, which occur less frequently. We conducted two experiments in order to investigate how exposure and phonetic context influence this reported processing disadvantage for flapped variants. Experiment 1 demonstrated that the time to recognize flapped variants presented in isolation decreased over the course of the experiment, while accuracy increased. Experiment 2 replicated this finding and showed further that flapped variants that were presented in a casually produced sentence context were recognized faster compared with flapped variants presented in a carefully produced sentence context. Interestingly, the effect of context emerged only in late responses and was present only for flapped but not for canonical variants. Our results thus show that increased exposure and phonetic context help listeners recognize allophonic variants. This finding provides further support for the notion that listeners are flexible and adapt to phonetic variation in speech.
C1 [Viebahn, Malte C.] Univ Leipzig, Dept Psychol, Neumarkt 9-19, D-04109 Leipzig, Germany.
   [Luce, Paul A.] SUNY Buffalo, Dept Psychol, Buffalo, NY USA.
RP Viebahn, MC (corresponding author), Univ Leipzig, Dept Psychol, Neumarkt 9-19, D-04109 Leipzig, Germany.
EM malte.viebahn@uni-leipzig.de
CR Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Arai M, 2013, LANG COGNITIVE PROC, V28, P525, DOI 10.1080/01690965.2012.658072
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen RH, 2010, INT J PSYCHOL RES, V3, P12
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2005, FITTING LINEAR MIXED, V5, P27, DOI DOI 10.1159/000323281
   Brouwer S, 2012, LANG COGNITIVE PROC, V27, P539, DOI 10.1080/01690965.2011.555268
   Brunelliere A, 2013, BRAIN LANG, V125, P82, DOI 10.1016/j.bandl.2013.01.007
   Burki A, 2018, LANG COGN NEUROSCI, V33, P494, DOI 10.1080/23273798.2017.1388412
   Burki A, 2010, J MEM LANG, V62, P421, DOI 10.1016/j.jml.2010.01.002
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clarke-Davidson CM, 2008, PERCEPT PSYCHOPHYS, V70, P604, DOI 10.3758/PP.70.4.604
   Cluff M. S., 1990, J ACOUST SOC AM, V87, pS125, DOI [DOI 10.1121/1.2027912, 10.1121/1.2027912]
   Coenen E, 2001, LANG COGNITIVE PROC, V16, P535, DOI 10.1080/01690960143000155
   COHEN J, 1993, BEHAV RES METH INSTR, V25, P257, DOI 10.3758/BF03204507
   Connine CM, 2009, J MEM LANG, V61, P412, DOI 10.1016/j.jml.2009.07.003
   CUTLER A., 1998, P 5 INT C SPOK LANG, P2783
   Cutler A, 2012, NATIVE LISTENING
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498
   DeLong KA, 2008, PSYCHOPHYSIOLOGY, V45, pS9
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   Ernestus M, 2011, J PHONETICS, V39, P253, DOI 10.1016/S0095-4470(11)00055-6
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Gaskell MG, 1998, J EXP PSYCHOL HUMAN, V24, P380, DOI 10.1037/0096-1523.24.2.380
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Grainger J, 2005, Q J EXP PSYCHOL-A, V58, P981, DOI 10.1080/02724980443000386
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Ito A, 2018, J MEM LANG, V98, P1, DOI 10.1016/j.jml.2017.09.002
   Johnson K, 2004, SPONTANEOUS SPEECH D, P29
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362
   KLATT DH, 1989, LEXICAL REPRESENTATI, P169
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Ladefoged P., 2000, COURSE PHONETICS
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Luce PA, 1998, PERCEPT PSYCHOPHYS, V60, P484, DOI 10.3758/BF03206868
   Luce PA, 2005, BLACKW HBK LINGUIST, P591
   Magnuson JS, 2008, COGNITION, V108, P866, DOI 10.1016/j.cognition.2008.06.005
   Marr D., 1982, VISION
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   McLennan CT, 2003, J EXP PSYCHOL LEARN, V29, P539, DOI 10.1037/0278-7393.29.4.539
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Mitterer H, 2006, J PHONETICS, V34, P73, DOI 10.1016/j.wocn.2005.03.003
   Mitterer H, 2015, J MEM LANG, V85, P116, DOI 10.1016/j.jml.2015.08.005
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Mitterer H, 2009, J EXP PSYCHOL HUMAN, V35, P244, DOI 10.1037/a0012730
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Papesh MH, 2016, J EXP PSYCHOL GEN, V145, P314, DOI 10.1037/xge0000135
   Patterson D, 2003, PHONETICA, V60, P47, DOI 10.1159/000070454
   Perre L, 2009, BRAIN RES, V1275, P73, DOI 10.1016/j.brainres.2009.04.018
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Pitt MA, 2009, J EXP PSYCHOL HUMAN, V35, P896, DOI 10.1037/a0013160
   R Development Core Team, 2007, R LANG ENV STAT COMP
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   SEIDENBERG MS, 1979, J EXP PSYCHOL-HUM L, V5, P546, DOI 10.1037/0278-7393.5.6.546
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Sumner M, 2013, J ACOUST SOC AM, V134, pEL26, DOI 10.1121/1.4807432
   Taft M, 2008, J MEM LANG, V58, P366, DOI 10.1016/j.jml.2007.11.002
   Tuinman A, 2014, LANG SPEECH, V57, P68, DOI 10.1177/0023830913479106
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   van de Ven M, 2011, MEM COGNITION, V39, P1301, DOI 10.3758/s13421-011-0103-2
   Viebahn MC, 2017, J COGNITIVE NEUROSCI, V29, P1132, DOI 10.1162/jocn_a_01095
   Viebahn MC, 2015, J EXP PSYCHOL LEARN, V41, P1684, DOI 10.1037/a0039326
   Witteman MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P537, DOI 10.3758/s13414-012-0404-y
NR 70
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD AUG
PY 2018
VL 80
IS 6
BP 1539
EP 1558
DI 10.3758/s13414-018-1525-8
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA GN9DZ
UT WOS:000439488800018
PM 29691765
OA Bronze
DA 2021-02-24
ER

PT J
AU McLaughlin, DJ
   Baese-Berk, MM
   Bent, T
   Borrie, SA
   Van Engen, KJ
AF McLaughlin, Drew J.
   Baese-Berk, Melissa M.
   Bent, Tessa
   Borrie, Stephanie A.
   Van Engen, Kristin J.
TI Coping with adversity: Individual differences in the perception of noisy
   and accented speech
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Working memory; Inhibition
ID DYSARTHRIC SPEECH; FOREIGN-ACCENT; RECOGNITION; MEMORY; ADULTS; RHYTHM;
   AGE; INTELLIGIBILITY; COMPREHENSION; SEGMENTATION
AB During speech communication, both environmental noise and nonnative accents can create adverse conditions for the listener. Individuals recruit additional cognitive, linguistic, and/or perceptual resources when faced with such challenges. Furthermore, listeners vary in their ability to understand speech in adverse conditions. In the present study, we compared individuals' receptive vocabulary, inhibition, rhythm perception, and working memory with transcription accuracy (i.e., intelligibility scores) for four adverse listening conditions: native speech in speech-shaped noise, native speech with a single-talker masker, nonnative-accented speech in quiet, and nonnative-accented speech in speech-shaped noise. The results showed that intelligibility scores for similar types of adverse listening conditions (i.e., with the same environmental noise or nonnative-accented speech) significantly correlated with one another. Furthermore, receptive vocabulary positively predicted performance globally across adverse listening conditions, and working memory positively predicted performance for the nonnative-accented speech conditions. Taken together, these results indicate that some cognitive resources may be recruited for all adverse listening conditions, while specific additional resources may be engaged when people are faced with certain types of listening challenges.
C1 [McLaughlin, Drew J.; Baese-Berk, Melissa M.] Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
   [McLaughlin, Drew J.; Van Engen, Kristin J.] Washington Univ, Dept Psychol & Brain Sci, St Louis, MO 63130 USA.
   [Bent, Tessa] Indiana Univ, Dept Speech & Hearing Sci, Bloomington, IN 47405 USA.
   [Borrie, Stephanie A.] Utah State Univ, Dept Communicat Disorders & Deaf Educ, Logan, UT 84322 USA.
RP McLaughlin, DJ (corresponding author), Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.; McLaughlin, DJ (corresponding author), Washington Univ, Dept Psychol & Brain Sci, St Louis, MO 63130 USA.
EM drewjmclaughlin@wustl.edu
OI Borrie, Stephanie/0000-0002-2336-0071; Van Engen,
   Kristin/0000-0001-9069-5464
FU Office of the Vice President for Research and Innovation at the
   University of Oregon; University of Oregon Faculty Research Award
FX This work was partially funded by an undergraduate fellowship awarded to
   D.J.M. by the Office of the Vice President for Research and Innovation
   at the University of Oregon, and by a University of Oregon Faculty
   Research Award given to M.M.B.-B.
CR Adank P, 2012, NEUROPSYCHOLOGIA, V50, P77, DOI 10.1016/j.neuropsychologia.2011.10.024
   Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Benichov J, 2012, EAR HEARING, V33, P262, DOI 10.1097/AUD.0b013e31822f680f
   Bent T, 2016, J ACOUST SOC AM, V140, P3775, DOI 10.1121/1.4966677
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005
   Borrie SA, 2017, J ACOUST SOC AM, V141, P4660, DOI 10.1121/1.4986746
   Borrie SA, 2017, J SPEECH LANG HEAR R, V60, P561, DOI 10.1044/2016_JSLHR-S-16-0094
   Borrie SA, 2012, LANG COGNITIVE PROC, V27, P1039, DOI 10.1080/01690965.2011.610596
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   CUTLER A, 1988, J EXP PSYCHOL HUMAN, V14, P113, DOI 10.1037/0096-1523.14.1.113
   CUTLER A, 1992, J MEM LANG, V31, P218, DOI 10.1016/0749-596X(92)90012-M
   Davidson L, 2011, J EXP PSYCHOL HUMAN, V37, P270, DOI 10.1037/a0020988
   Dunn LM, 2007, PPVT 4 PEABODY PICTU
   Francis AL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00263
   Fullgrabe C, 2016, ADV EXP MED BIOL, V894, P29, DOI 10.1007/978-3-319-25474-6_4
   Gilbert JL, 2013, J AM ACAD AUDIOL, V24, P26, DOI 10.3766/jaaa.24.1.4
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Janse E, 2012, AGING NEUROPSYCHOL C, V19, P741, DOI 10.1080/13825585.2011.652590
   Janse E, 2012, Q J EXP PSYCHOL, V65, P1563, DOI 10.1080/17470218.2012.658822
   Liss JM, 1998, J ACOUST SOC AM, V104, P2457, DOI 10.1121/1.423753
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McAuliffe MJ, 2013, J ACOUST SOC AM, V134, P1358, DOI 10.1121/1.4812764
   Miettinen I, 2011, BRAIN RES, V1367, P298, DOI 10.1016/j.brainres.2010.10.037
   Miles J., 2005, ENCY STAT BEHAV SCI, DOI [10.1002/0470013192.bsa683., DOI 10.1002/0470013192.BSA683, 10.1002/0470013192.bsa683]
   Mueller ST, 2014, J NEUROSCI METH, V222, P250, DOI 10.1016/j.jneumeth.2013.10.024
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Ronnberg J, 2003, INT J AUDIOL, V42, pS68
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   SMITH MR, 1989, J SPEECH HEAR RES, V32, P912, DOI 10.1044/jshr.3204.912
   Smith SL, 2016, EAR HEARING, V37, pE360, DOI 10.1097/AUD.0000000000000329
   Song XD, 2017, J ACOUST SOC AM, V141, P2513, DOI 10.1121/1.4979594
   Song XYD, 2015, EAR HEARING, V36, pE326, DOI 10.1097/AUD.0000000000000186
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Tamati TN, 2013, J AM ACAD AUDIOL, V24, P616, DOI 10.3766/jaaa.24.7.10
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Van Engen KJ, 2012, LANG COGNITIVE PROC, V27, P1089, DOI 10.1080/01690965.2012.654644
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004
   White L., 2007, SEGMENTAL PROSODIC I, P237
   Wightman FL, 2010, J ACOUST SOC AM, V128, P270, DOI 10.1121/1.3436536
NR 47
TC 11
Z9 11
U1 0
U2 11
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD AUG
PY 2018
VL 80
IS 6
BP 1559
EP 1570
DI 10.3758/s13414-018-1537-4
PG 12
WC Psychology; Psychology, Experimental
SC Psychology
GA GN9DZ
UT WOS:000439488800019
PM 29740795
OA Bronze
DA 2021-02-24
ER

PT J
AU Boudelaa, S
AF Boudelaa, Sami
TI Non-Selective Lexical Access in Late Arabic-English Bilinguals: Evidence
   from Gating
SO JOURNAL OF PSYCHOLINGUISTIC RESEARCH
LA English
DT Article
DE Arabic-English bilingualism; Cross-language acoustic-phonetic
   similarities; Gating
ID SPOKEN-WORD RECOGNITION; LANGUAGE SPEECH-PERCEPTION; NATIVE-LANGUAGE;
   REPRESENTATION; 2ND-LANGUAGE; ACQUISITION; MEMORY; INTERFERENCE;
   DECISION; AGE
AB Previous research suggests that late bilinguals who speak typologically distant languages are the least likely to show evidence of non-selective lexical access processes. This study puts this claim to test by using the gating task to determine whether words beginning with speech sounds that are phonetically similar in Arabic and English (e.g., [b,d,m,n]) give rise to selective or non-selective lexical access processes in late Arabic-English bilinguals. The results show that an acoustic-phonetic input (e.g., [b']) that is consistent with words in Arabic (e.g., [b'drun] "moon") and English (e.g., [b'd] "bad") activates lexical representations in both languages of the bilingual. This non-selective activation holds equally well for mixed lists with words from both Arabic and English and blocked lists consisting only of Arabic or English words. These results suggest that non-selective lexical access processes are the default mechanism even in late bilinguals of typologically distant languages.
C1 [Boudelaa, Sami] United Arab Emirates Univ, Dept Linguist, Al Ain 15551, U Arab Emirates.
   [Boudelaa, Sami] Univ Cambridge, Dept Psychol, Cambridge, England.
RP Boudelaa, S (corresponding author), United Arab Emirates Univ, Dept Linguist, Al Ain 15551, U Arab Emirates.; Boudelaa, S (corresponding author), Univ Cambridge, Dept Psychol, Cambridge, England.
EM s.boudelaa@uaeu.ac.ae
OI Boudelaa, Sami/0000-0002-1870-7202
FU UAEU-FHSS [G00001813, G00002367]
FX The research was funded by the following UAEU-FHSS Grant G00001813 and
   G00002367. The author would like thank an anonymous reviewer for their
   helpful suggestions.
CR Albert M.L., 1978, BILINGUAL BRAIN NEUR
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Baker W, 2005, LANG SPEECH, V48, P1, DOI 10.1177/00238309050480010101
   BALOTA DA, 1984, J EXP PSYCHOL HUMAN, V10, P340, DOI 10.1037/0096-1523.10.3.340
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Boudelaa S, 2010, BEHAV RES METHODS, V42, P481, DOI 10.3758/BRM.42.2.481
   CARAMAZZA A, 1980, CAN J PSYCHOL, V34, P77, DOI 10.1037/h0081016
   CHUMBLEY JI, 1984, MEM COGNITION, V12, P590, DOI 10.3758/BF03213348
   Costa A, 2000, J EXP PSYCHOL LEARN, V26, P1283, DOI 10.1037//0278-7393.26.5.1283
   Costa A, 2006, BILING-LANG COGN, V9, P137, DOI 10.1017/S1366728906002495
   COTTON S, 1984, PERCEPT PSYCHOPHYS, V35, P41, DOI 10.3758/BF03205923
   CRAIG CH, 1993, J SPEECH HEAR RES, V36, P832, DOI 10.1044/jshr.3604.832
   de Sousa LB, 2015, REV ESTUD LING, V23, P335
   DEGROOT AMB, 1991, J MEM LANG, V30, P90, DOI 10.1016/0749-596X(91)90012-9
   Dijkstra T, 1998, PSYCHOL BELG, V38, P177
   Dijkstra T, 2002, BILING-LANG COGN, V5, P175, DOI 10.1017/S1366728902003012
   DURGUNOGLU AY, 1987, J MEM LANG, V26, P377, DOI 10.1016/0749-596X(87)90097-0
   Duyck W, 2008, Q J EXP PSYCHOL, V61, P1281, DOI 10.1080/17470210802000679
   Elman JL., 1996, RETHINKING INNATENES
   Embarki Mohamed, 2013, OXFORD HDB ARABIC LI, P23
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FRAUENFELDER UH, 1987, COGNITION, V25, P1, DOI 10.1016/0010-0277(87)90002-3
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Ghazeli Salem, 1977, THESIS
   Gollan TH, 2011, PSYCHOL SCI, V22, P1155, DOI 10.1177/0956797611417002
   Gollan TH, 2011, J EXP PSYCHOL GEN, V140, P186, DOI 10.1037/a0022256
   GRAINGER J, 1987, Q J EXP PSYCHOL-A, V39, P295, DOI 10.1080/14640748708401788
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Grosjean F., 2012, PSYCHOLINGUISTICS BI
   Grosjean F. M. J., 1988, LANG COGNITIVE PROC, V3, P233, DOI DOI 10.1080/01690968808402089
   Grosjean Francois, 1986, LANGUAGE PROCESSING, P145
   Guion SG, 2003, PHONETICA, V60, P98, DOI 10.1159/000071449
   Heredia R. R., 2013, FDN BILINGUAL MEMORY
   Kaushanskaya M, 2007, LANG LEARN, V57, P119, DOI 10.1111/j.1467-9922.2007.00401.x
   KINTSCH W, 1970, J VERB LEARN VERB BE, V9, P405, DOI 10.1016/S0022-5371(70)80080-9
   KOLERS PA, 1966, J VERB LEARN VERB BE, V5, P314, DOI 10.1016/S0022-5371(66)80037-3
   Kroll J.F., 2009, HDB BILINGUALISM PSY
   KROLL JF, 1994, J MEM LANG, V33, P149, DOI 10.1006/jmla.1994.1008
   Kuhl P, 2008, ANNU REV NEUROSCI, V31, P511, DOI 10.1146/annurev.neuro.30.051606.094321
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Ladefoged P., 1962, ELEMENTS ACOUSTIC PH
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lenneberg EH, 1967, HOSP PRACT, V2, P59, DOI [DOI 10.1080/21548331.1967.11707799, 10.1080/21548331.1967.11707799]
   Levelt WJ, 1989, SPEAKING INTENTION A
   Lewy N, 2015, THESIS
   Lewy N., 2008, STUDYING BILINGUALS, P201
   MACNAMARA J, 1971, J VERB LEARN VERB BE, V10, P480, DOI 10.1016/S0022-5371(71)80018-X
   MACNAMARA J, 1967, J SOC ISSUES, V23, P58, DOI 10.1111/j.1540-4560.1967.tb00576.x
   Marshall NB, 1996, J SPEECH HEAR RES, V39, P724, DOI 10.1044/jshr.3904.724
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   Martin CD, 2012, BRAIN LANG, V120, P61, DOI 10.1016/j.bandl.2011.10.003
   Morales L, 2016, BILING-LANG COGN, V19, P294, DOI 10.1017/S1366728915000176
   Paradis M., 1977, STUDIES NEUROLINGUIS, P65
   Penfield W, 1959, SPEECH BRAIN MECH
   Roberts M., 2002, APHASIOLOGY, V16, P635, DOI DOI 10.1080/02687030244000220
   SCARBOROUGH DL, 1984, J VERB LEARN VERB BE, V23, P84, DOI 10.1016/S0022-5371(84)90519-X
   SCHMIDT AM, 1995, PHONETICA, V52, P41, DOI 10.1159/000262028
   SEIDENBERG MS, 1990, PSYCHOL REV, V97, P447, DOI 10.1037/0033-295X.97.3.447
   Silverberg S, 2004, J MEM LANG, V51, P381, DOI 10.1016/j.jml.2004.05.003
   Simmonds AJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00166
   SOARES C, 1984, MEM COGNITION, V12, P380, DOI 10.3758/BF03198298
   TenThije JD, 2007, HAMB STUD MULTILING, V6, P1
   TYLER LK, 1985, PERCEPT PSYCHOPHYS, V38, P217, DOI 10.3758/BF03207148
   Van Hell J. G., 1998, BILING-LANG COGN, V1, P193, DOI [10.1017/S1366728998000352, DOI 10.1017/S1366728998000352]
   van Hell JG, 2002, PSYCHON B REV, V9, P780, DOI 10.3758/BF03196335
   WARREN P, 1987, PERCEPT PSYCHOPHYS, V41, P262, DOI 10.3758/BF03208224
   WEINREICH U, 1957, WORD, V13, P1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
NR 70
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0090-6905
EI 1573-6555
J9 J PSYCHOLINGUIST RES
JI J. Psycholinguist. Res.
PD AUG
PY 2018
VL 47
IS 4
BP 913
EP 930
DI 10.1007/s10936-018-9564-9
PG 18
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA GM9AR
UT WOS:000438533400010
PM 29417453
DA 2021-02-24
ER

PT J
AU Larraza, S
   Best, CT
AF Larraza, Saioa
   Best, Catherine T.
TI Differences in phonetic-to-lexical perceptual mapping of L1 and L2
   regional accents
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE regional accents; L2 versus L1; speech perception; spoken word
   recognition; perceptual adjustment to accent variation
ID INCOMPLETE NEUTRALIZATION; SPEECH; ENGLISH; ACQUISITION; LANGUAGE;
   REPRESENTATION; ADAPTATION; CONTRASTS; AGE
AB This study investigates how second language (L2) listeners match an unexpected accented form to their stored form of a word. The phonetic-to-lexical mapping for L2 as compared to L1 regional varieties was examined with early and late Italian-L2 speakers who were all L1-Australian English speakers. AXB discrimination and lexical decision tasks were conducted in both languages, using unfamiliar regional accents that minimize (near-merge) consonant contrasts maintained in their own L1-L2 accents. Results reveal that in the L2, early bilinguals' recognition of accented variants depended on their discrimination capacity. Late bilinguals, for whom the accented variants were not represented in their L2 lexicon, instead mapped standard and accented exemplars to the same lexical representations (i.e., dual mapping: Samuel & Larraza, 2015). By comparison, both groups showed the same broad accommodation to L1 accented variants. Results suggest qualitatively different yet similarly effective phonetic-to-lexical mapping strategies both for L2 versus L1 regional accents.
C1 [Larraza, Saioa] CNRS UMR 8158, Lab Psychol Percept, Paris, France.
   [Best, Catherine T.] Western Sydney Univ, MARCS Inst, Penrith, NSW, Australia.
   [Best, Catherine T.] Western Sydney Univ, Sch Humanities & Commun Arts, Penrith, NSW, Australia.
RP Larraza, S (corresponding author), Univ Paris 05, CNRS UMR 8158, Lab Psychol Percept, 45 Rue St Peres, F-75006 Paris, France.
EM saioa.larraza@parisdescartes.fr
RI Best, Catherine T/M-4547-2019
OI Best, Catherine T/0000-0002-2447-2024; LARRAZA ARNANZ,
   SAIOA/0000-0002-2248-5112
FU BCBL-Basque Center on Cognition, Brain and Language; MINECO from the
   Spanish Ministry of Economics and Competitiveness [PSI2010-17781]; MARCS
   Institute, University of Western Sydney, Australia
FX This study was partially funded by BCBL-Basque Center on Cognition,
   Brain and Language, by MINECO Grant PSI2010-17781 to Arthur Samuel from
   the Spanish Ministry of Economics and Competitiveness and by visiting
   PhD student support from MARCS Institute, University of Western Sydney,
   Australia, where the study was conducted. We give special thanks to
   Arthur Samuel, Anne Cutler, Jason Shaw, Bruno di Biase, Donald Derrick
   and Tonya Agostini for their valuable comments and help with the
   stimuli, and in general the BCBL and the MARCS Institute for the
   kindness and cooperation showed during the development of this project.
CR Baayen H., 1995, THE CELEX DATABASE
   Baayen H., 2012, OXFORD HDB LAB PHONO, P668
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bates D, 2013, LINEAR MIXED EFFECTS
   Best C. T., 2015, PHONETICS PHONOLOGY, P3, DOI [10.1075/cilt.335.01bes, DOI 10.1075/CILT.335.01BES]
   Best C. T., 1995, SPEECH PERCEPTION LI, P167
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Broersma M., 2002, P 7 INT C SPOK LANG, P261
   Broersma M, 2008, SYSTEM, V36, P22, DOI 10.1016/j.system.2007.11.003
   Bundgaard-Nielsen R. L., 2015, PLOS ONE, V10, P1
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   Diehm Erin, 1997, OHIO STATE WORKING P, V50, P11
   Dixon P, 2008, J MEM LANG, V59, P447, DOI 10.1016/j.jml.2007.11.004
   Dufour S., 2013, J PSYCHOLINGUISTIC R, V42, P1774
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   Faber A., 1995, LANG VAR CHANGE, V7, P35, DOI DOI 10.1017/S0954394500000892
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 1992, INTELLIGIBILITY SPEE, P157, DOI DOI 10.1075/SSPCL.1.06FLE
   FLEGE JE, 1987, SPEECH COMMUN, V6, P185, DOI 10.1016/0167-6393(87)90025-2
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2009, J PSYCHOLINGUIST RES, V38, P379, DOI 10.1007/s10936-008-9097-8
   FOURAKIS M, 1984, PHONETICA, V41, P140, DOI 10.1159/000261720
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   HAZAN VL, 1993, LANG SPEECH, V36, P17, DOI 10.1177/002383099303600102
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Labov W., 1991, LANG VAR CHANGE, V3, P33, DOI [10.1017/S0954394500000442, DOI 10.1017/S0954394500000442]
   Larraza S, 2017, Q J EXP PSYCHOL, V70, P92, DOI 10.1080/17470218.2015.1124896
   Larraza S, 2016, J EXP PSYCHOL LEARN, V42, P1774, DOI 10.1037/xlm0000252
   Laudanna A., 1995, 3 GIORNATE INT, VI, P103
   Loporcaro M., 1996, TRENDS LINGUISTICS S, V92, P153
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   R Development Core Team, 2012, R LANG ENV STAT COMP
   Samuel AG, 2015, J MEM LANG, V81, P51, DOI 10.1016/j.jml.2015.01.003
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   Sebastian-Galles N, 2006, J COGNITIVE NEUROSCI, V18, P1277, DOI 10.1162/jocn.2006.18.8.1277
   Silverberg S, 2004, J MEM LANG, V51, P381, DOI 10.1016/j.jml.2004.05.003
   Sumner M, 2005, J MEM LANG, V52, P322, DOI 10.1016/j.jml.2004.11.004
   Sumner M, 2011, COGNITION, V119, P131, DOI 10.1016/j.cognition.2010.10.018
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Tuinman A, 2012, J MEM LANG, V66, P530, DOI 10.1016/j.jml.2012.02.001
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
NR 52
TC 1
Z9 1
U1 0
U2 6
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD AUG
PY 2018
VL 21
IS 4
SI SI
BP 805
EP 825
DI 10.1017/S1366728917000323
PG 21
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA GM7NQ
UT WOS:000438376000010
DA 2021-02-24
ER

PT J
AU Mollahosseini, A
   Abdollahi, H
   Sweeny, TD
   Cole, R
   Mahoor, MH
AF Mollahosseini, Ali
   Abdollahi, Hojjat
   Sweeny, Timothy D.
   Cole, Ron
   Mahoor, Mohammad H.
TI Role of embodiment and presence in human perception of robots' facial
   cues
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES
LA English
DT Article
DE Social robot; Embodiment; Physical presence; Retro-projected robots
ID SOCIALLY INTELLIGENT AGENTS; PHYSICALLY PRESENT; SPEECH-PERCEPTION;
   FACE; DESIGN; EYES; ART
AB Both robotic and virtual agents could one day be equipped with social abilities necessary for effective and natural interaction with human beings. Although virtual agents are relatively inexpensive and flexible, they lack the physical embodiment present in robotic agents. Surprisingly, the role of embodiment and physical presence for enriching human-robot-interaction is still unclear. This paper explores how these unique features of robotic agents influence three major elements of human-robot face-to-face communication, namely the perception of visual speech, facial expression, and eye-gaze. We used a quantitative approach to disentangle the role of embodiment from the physical presence of a social robot, called Ryan, with three different agents (robot, telepresent robot, and virtual agent), as well as with an actual human. We used a robot with a retro-projected face for this study, since the same animation from a virtual agent could be projected to this robotic face, thus allowing comparison of the virtual agent's animation behaviors with both telepresent and the physically present robotic agents. The results of our studies indicate that the eye gaze and certain facial expressions are perceived more accurately when the embodied agent is physically present than when it is displayed on a 2D screen either as a telepresent or a virtual agent. Conversely, we find no evidence that either the embodiment or the presence of the robot improves the perception of visual speech, regardless of syntactic or semantic cues. Comparison of our findings with previous studies also indicates that the role of embodiment and presence should not be generalized without considering the limitations of the embodied agents.
C1 [Mollahosseini, Ali; Abdollahi, Hojjat; Mahoor, Mohammad H.] Univ Denver, Daniel Felix Ritchie Sch Engn & Comp Sci, Denver, CO 80208 USA.
   [Cole, Ron] Boulder Learning Inc, Boulder, CO 80301 USA.
   [Sweeny, Timothy D.] Univ Denver, Dept Psychol, Denver, CO 80208 USA.
RP Mahoor, MH (corresponding author), Univ Denver, Daniel Felix Ritchie Sch Engn & Comp Sci, Denver, CO 80208 USA.
EM ali.mollahosseini@du.edu; habdolla@du.edu; Timothy.Sweeny@du.edu;
   rcole@boulderlearning.com; mmahoor@du.edu
OI Abdollahi, Hojjat/0000-0002-0233-7737
FU NSFNational Science Foundation (NSF) [IIS-1111568, CNS-1427872]; DU
   Professional Research Opportunity for Faculty (PROF) grant
FX This work is partially supported by the NSF grants IIS-1111568 and
   CNS-1427872 and a DU Professional Research Opportunity for Faculty
   (PROF) grant. The 3D animation system used to control the Ryan model was
   developed jointly by Boulder Learning Inc.
   (http://www.boulderlearning.com) and the Computer Vision and Social
   Robotics Laboratory at the University of Denver.
CR Al Moubayed Samer, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P114, DOI 10.1007/978-3-642-34584-5_9
   Al Moubayed S, 2013, INT J HUM ROBOT, V10, DOI 10.1142/S0219843613500059
   Al Moubayed Samer, 2012, P 4 WORKSH EYE GAZ I, P3
   Al-Moubayed S., 2012, ACM T INTERACTIVE IN, V1
   Allison T, 2000, TRENDS COGN SCI, V4, P267, DOI 10.1016/S1364-6613(00)01501-1
   ANSTIS SM, 1969, AM J PSYCHOL, V82, P474, DOI 10.2307/1420441
   Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7
   BARONCOHEN S, 1995, BRIT J DEV PSYCHOL, V13, P379, DOI 10.1111/j.2044-835X.1995.tb00687.x
   Bartneck C., 2004, P DES EM, P32
   Bartneck C, 2007, LECT NOTES COMPUT SC, V4550, P20
   Becker-Asano C., 2011, 2011 IEEE WORKSH AFF, P1, DOI [DOI 10.1109/WACI.2011.5953147, 10.1109/WACI.2011.5953147]
   Beer J. M., 2011, UNDERSTANDING ROBOT, P1
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Biocca F., 1997, J COMPUT-MEDIAT COMM, P3, DOI [DOI 10.1111/J.1083-6101.1997.TB00070.X, 10.1111/j.1083-6101.1997.tb00070.x]
   Bolanos D, 2012, IEEE W SP LANG TECH, P354, DOI 10.1109/SLT.2012.6424249
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Breazeal C., 2005, Interactions, V12, P19, DOI 10.1145/1052438.1052455
   BREAZEAL C, 2000, SOCIABLE MACHINES EX
   Bruce A, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4138, DOI 10.1109/ROBOT.2002.1014396
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Chen YC, 2012, CONSCIOUS COGN, V21, P1703, DOI 10.1016/j.concog.2012.10.001
   CLINE MG, 1967, AM J PSYCHOL, V80, P41, DOI 10.2307/1420539
   Cohen J., 1977, SOCIAL ROBOTICS
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297
   Dautenhahn K, 2001, IEEE T SYST MAN CY A, V31, P345, DOI 10.1109/TSMCA.2001.952709
   Dautenhahn K, 1998, APPL ARTIF INTELL, V12, P573, DOI 10.1080/088395198117550
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   Delaunay F, 2010, ACMIEEE INT CONF HUM, P39, DOI 10.1109/HRI.2010.5453271
   Ekman P., 1978, FACIAL ACTION CODING
   ELLIOTT LL, 1995, J SPEECH HEAR RES, V38, P1363, DOI 10.1044/jshr.3806.1363
   Emery NJ, 2000, NEUROSCI BIOBEHAV R, V24, P581, DOI 10.1016/S0149-7634(00)00025-7
   Friesen W., 1983, EMFACS7 EMOTIO UNPUB
   Fujimura R, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P3860, DOI 10.1109/IROS.2010.5649116
   Goffman E, 1963, BEHAV PUBLIC PLACE
   Guizzo E, 2010, WORLD ROBOT POPULATI, P14
   Hartholt A, 2009, LECT NOTES ARTIF INT, V5773, P500
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   IDC, 2016, INT DAT CORP IDC PRE
   Imai M, 2002, IEEE ROMAN 2002, PROCEEDINGS, P411, DOI 10.1109/ROMAN.2002.1045657
   IPA, 1999, HDB INT PHON ASS GUI
   Itier RJ, 2009, NEUROSCI BIOBEHAV R, V33, P843, DOI 10.1016/j.neubiorev.2009.02.004
   Ju W, 2010, LECT NOTES COMPUT SC, V6137, P40, DOI 10.1007/978-3-642-13226-1_6
   Kajita S., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2000, DOI 10.1109/IROS.2011.6048357
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Katsyri J, 2008, INT J HUM-COMPUT ST, V66, P233, DOI 10.1016/j.ijhcs.2007.10.001
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   KENDON A, 1975, ORG BEHAV FACE TO FA
   Kidd C. D., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3559
   Kiesler S, 2008, SOC COGNITION, V26, P169, DOI 10.1521/soco.2008.26.2.169
   Kluttz NL, 2009, VISION RES, V49, P1979, DOI 10.1016/j.visres.2009.05.013
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Kose-Bagci H, 2009, ADV ROBOTICS, V23, P1951, DOI 10.1163/016918609X12518783330360
   Langton SRH, 2004, PERCEPT PSYCHOPHYS, V66, P752, DOI 10.3758/BF03194970
   Lazzeri N., 2015, FRONT BIOENG BIOTECH, V3
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Lester JC, 1999, APPL ARTIF INTELL, V13, P383, DOI 10.1080/088395199117324
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Lin CY, 2013, IEEE INT CONF ROBOT, P4316, DOI 10.1109/ICRA.2013.6631188
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI [DOI 10.1109/CVPRW.2010.5543262, 10.1109/CVPRW.2010.5543262]
   Ma JY, 2004, VISUAL COMPUT, V20, P86, DOI 10.1007/s00371-003-0234-y
   MARUYAMA K, 1984, Tohoku Psychologica Folia, V43, P150
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Misawa K, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P394, DOI 10.1145/2254556.2254632
   Mollahosseini A, 2014, IEEE-RAS INT C HUMAN, P1098, DOI 10.1109/HUMANOIDS.2014.7041505
   Mutlu B., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P61
   Nishio S., 2007, GEMINOID TELEOPERATE
   Oh KG, 2010, 2010 IEEE RO-MAN, P620, DOI 10.1109/ROMAN.2010.5598656
   Otsuka Y, 2014, J EXP PSYCHOL HUMAN, V40, P1425, DOI 10.1037/a0036151
   Ouni S., 2003, P 15 INT C PHON SCI, P286
   Pateromichelakis N, 2014, IEEE INT C INT ROBOT, P1374, DOI 10.1109/IROS.2014.6942736
   PERRETT DI, 1985, PROC R SOC SER B-BIO, V223, P293, DOI 10.1098/rspb.1985.0003
   Pfeifer R., 1999, UNDERSTANDING INTELL
   RC Luo, 2011, IECON, P171, DOI 10.1109/IECON.2011.6119307
   Ruhland K., 2014, EUROGRAPHICS STATE A, P69
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Siciliano C., 2003, AVSP 2003, P205
   Sweeny TD, 2017, VISION RES, V131, P67, DOI 10.1016/j.visres.2016.10.014
   Sweeny TD, 2012, VISION RES, V64, P26, DOI 10.1016/j.visres.2012.05.008
   Sweeny TD, 2012, COGNITION, V124, P194, DOI 10.1016/j.cognition.2012.04.009
   Todorovic D, 2006, VISION RES, V46, P3549, DOI 10.1016/j.visres.2006.04.011
   Vala M., 2007, P 6 INT JOINT C AUT, V5, P271
   Van Breemen A, 2004, P SHAPP HUM ROB INT, P143
   Wainer Joshua, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P872
   WALKER JH, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P85
   Wollaston WH, 1824, PHILOS T ROY SOC LON, V114, P247, DOI DOI 10.1098/RSTL.1824.0016
   Yoshikawa Y., 2006, ROBOTICS SCI SYSTEMS
   Zhao SY, 2003, PRESENCE-VIRTUAL AUG, V12, P445, DOI 10.1162/105474603322761261
NR 88
TC 9
Z9 9
U1 1
U2 19
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 1071-5819
EI 1095-9300
J9 INT J HUM-COMPUT ST
JI Int. J. Hum.-Comput. Stud.
PD AUG
PY 2018
VL 116
BP 25
EP 39
DI 10.1016/j.ijhcs.2018.04.005
PG 15
WC Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary
SC Computer Science; Engineering; Psychology
GA GL1SA
UT WOS:000436887100003
DA 2021-02-24
ER

PT J
AU Weatherhead, D
   White, KS
AF Weatherhead, Drew
   White, Katherine S.
TI And then I saw her race: Race-based expectations affect infants' word
   processing
SO COGNITION
LA English
DT Article
DE Speech perception; Infant word recognition; Infant social cognition;
   Sociolinguistic variation; Accent processing
ID SPEECH-PERCEPTION; 6-MONTH-OLD INFANTS; TODDLERS; ACCENT; FACE;
   IDENTIFICATION; ADAPTATION; RECOGNIZE; CONTRAST; CHILDREN
AB How do our expectations about speakers shape speech perception? Adults' speech perception is influenced by social properties of the speaker (e.g., race). When in development do these influences begin? In the current study, 16-month-olds heard familiar words produced in their native accent (e.g., "dog") and in an unfamiliar accent involving a vowel shift (e.g., "dag"), in the context of an image of either a same-race speaker or an other race speaker. Infants' interpretation of the words depended on the speaker's race. For the same-race speaker, infants only recognized words produced in the familiar accent; for the other-race speaker, infants recognized both versions of the words. Two additional experiments showed that infants only recognized an other-race speaker's atypical pronunciations when they differed systematically from the native accent. These results provide the first evidence that expectations driven by unspoken properties of speakers, such as race, influence infants' speech processing.
C1 [Weatherhead, Drew; White, Katherine S.] Univ Waterloo, Dept Psychol, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
RP Weatherhead, D (corresponding author), Univ Waterloo, Dept Psychol, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
EM deweathe@uwaterloo.ca
OI Weatherhead, Drew/0000-0002-3649-2030
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
FX The authors would like to thank Carolyn Baer, Jasmine Taylor, and Luxsi
   Sribaskaran for providing stimuli, the research assistants who helped
   with coding the data, and all of the families and infants who
   participated. This work was funded by an operating grant from the
   Natural Sciences and Engineering Research Council of Canada awarded to
   K.S.W.
CR Anzures G, 2010, DEVELOPMENTAL SCI, V13, P553, DOI 10.1111/j.1467-7687.2009.00900.x
   AU TKF, 1990, CHILD DEV, V61, P1474, DOI 10.2307/1130757
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Bar-Haim Y, 2006, PSYCHOL SCI, V17, P159, DOI 10.1111/j.1467-9280.2006.01679.x
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Bion RAH, 2013, COGNITION, V126, P39, DOI 10.1016/j.cognition.2012.08.008
   CLARK EV, 1990, J CHILD LANG, V17, P417, DOI 10.1017/S0305000900013842
   Clark EV, 2007, NEW DIR CHILD ADOLES, V115, P11, DOI 10.1002/cad.179
   COHEN J, 1993, BEHAV RES METH INSTR, V25, P257, DOI 10.3758/BF03204507
   Dale PS, 1996, BEHAV RES METH INS C, V28, P125, DOI 10.3758/BF03203646
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   GOLINKOFF RM, 1994, J CHILD LANG, V21, P125, DOI 10.1017/S0305000900008692
   Halberda J, 2003, COGNITION, V87, pB23, DOI 10.1016/S0010-0277(02)00186-5
   Hay J, 2007, ANNU REV ANTHROPOL, V36, P89, DOI 10.1146/annurev.anthro.34.081804.120633
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Kang O., 2009, J LANGUAGE SOCIAL PS
   Kang O, 2014, TRENDS APPL LINGUIST, V10, P239
   Kelly DJ, 2007, PSYCHOL SCI, V18, P1084, DOI 10.1111/j.1467-9280.2007.02029.x
   Kelly DJ, 2009, J EXP CHILD PSYCHOL, V104, P105, DOI 10.1016/j.jecp.2009.01.006
   Kelly DJ, 2005, DEVELOPMENTAL SCI, V8, pF31, DOI 10.1111/j.1467-7687.2005.0434a.x
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhlmeier V, 2003, PSYCHOL SCI, V14, P402, DOI 10.1111/1467-9280.01454
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Markman E.M., 1989, CATEGORIZATION NAMIN
   MARKMAN EM, 1990, COGNITIVE SCI, V14, P57, DOI 10.1016/0364-0213(90)90026-S
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   Merriman W. E., 1989, MONOGRAPHS SOC RES C, V54
   Mulak KE, 2013, CHILD DEV, V84, P2064, DOI 10.1111/cdev.12087
   Munson B, 2006, J ACOUST SOC AM, V119, P2427, DOI 10.1121/1.2173521
   Niedzielski N., 1996, U PENNSYLVANIA WORKI, V3, P7
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Schmale R, 2015, DEVELOPMENTAL SCI, V18, P664, DOI 10.1111/desc.12244
   Schmale R, 2012, DEVELOPMENTAL SCI, V15, P732, DOI 10.1111/j.1467-7687.2012.01175.x
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   Spokes A. C., 2016, FRONT PSYCHOL, V440, P1, DOI [10.3389/fpsyg.2016.00440, DOI 10.3389/FPSYG.2016.00440.]
   Spokes AC, 2017, COGNITION, V159, P102, DOI 10.1016/j.cognition.2016.11.008
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Uttley L, 2013, INT J BEHAV DEV, V37, P84, DOI 10.1177/0165025412467583
   van Heugten M, 2015, LANG LEARN DEV, V11, P41, DOI 10.1080/15475441.2013.879636
   van Heugten M, 2014, J EXP PSYCHOL GEN, V143, P340, DOI 10.1037/a0032192
   Vouloumanos A, 2009, P NATL ACAD SCI USA, V106, P18867, DOI 10.1073/pnas.0906049106
   Weatherhead D, 2016, LANG LEARN DEV, V12, P92, DOI 10.1080/15475441.2015.1024835
   Wheeler A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018621
   White KS, 2008, J MEM LANG, V59, P114, DOI 10.1016/j.jml.2008.03.001
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
NR 51
TC 7
Z9 6
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD AUG
PY 2018
VL 177
BP 87
EP 97
DI 10.1016/j.cognition.2018.04.004
PG 11
WC Psychology, Experimental
SC Psychology
GA GJ1XS
UT WOS:000435061800011
PM 29656014
DA 2021-02-24
ER

PT J
AU de Boisferon, AH
   Tift, AH
   Minar, NJ
   Lewkowicz, DJ
AF de Boisferon, Anne Hillairet
   Tift, Amy H.
   Minar, Nicholas J.
   Lewkowicz, David J.
TI The redeployment of attention to the mouth of a talking face during the
   second year of life
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Selective attention; Infants; Speech perception; Eye-tracking;
   Audiovisual speech; Vocabulary
ID INFANT-DIRECTED SPEECH; LANGUAGE-DEVELOPMENT; JOINT ATTENTION;
   INDIVIDUAL-DIFFERENCES; SELECTIVE ATTENTION; WORD SEGMENTATION; VISUAL
   SPEECH; PERCEPTION; DISCRIMINATION; RECOGNITION
AB Previous studies have found that when monolingual infants are exposed to a talking face speaking in a native language, 8- and 10-month-olds attend more to the talker's mouth, whereas 12-month-olds no longer do so. It has been hypothesized that the attentional focus on the talker's mouth at 8 and 10 months of age reflects reliance on the highly salient audiovisual (AV) speech cues for the acquisition of basic speech forms and that the subsequent decline of attention to the mouth by 12 months of age reflects the emergence of basic native speech expertise. Here, we investigated whether infants may redeploy their attention to the mouth once they fully enter the word-learning phase. To test this possibility, we recorded eye gaze in monolingual English-learning 14- and 18-month-olds while they saw and heard a talker producing an English or Spanish utterance in either an infant-directed (ID) or adult-directed (AD) manner. Results indicated that the 14 month-olds attended more to the talker's mouth than to the eyes when exposed to the ID utterance and that the 18-month-olds attended more to the talker's mouth when exposed to the ID and the AD utterance. These results show that infants redeploy their attention to a talker's mouth when they enter the word acquisition phase and suggest that infants rely on the greater perceptual salience of redundant AV speech cues to acquire their lexicon. (C) 2018 Elsevier Inc. All rights reserved.
C1 [de Boisferon, Anne Hillairet; Tift, Amy H.] Florida Atlantic Univ, Dept Psychol, Boca Raton, FL 33314 USA.
   [de Boisferon, Anne Hillairet; Tift, Amy H.] Florida Atlantic Univ, High Sch Res Program, Boca Raton, FL 33314 USA.
   [Minar, Nicholas J.] Rutgers Robert Wood Johnson Med Sch, Inst Study Child Dev, New Brunswick, NJ 08901 USA.
   [Lewkowicz, David J.] Northeastern Univ, Dept Commun Sci & Disorders, Boston, MA 02115 USA.
RP Lewkowicz, DJ (corresponding author), Northeastern Univ, Dept Commun Sci & Disorders, Boston, MA 02115 USA.
EM d.lewkowicz@northeastern.edu
RI de Boisferon, Anne Hillairet/H-4655-2019
OI de Boisferon, Anne Hillairet/0000-0002-7304-6291
FU EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD057116,
   R01HD057116, R01HD057116, R01HD057116] Funding Source: NIH RePORTER;
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH &HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD057116]
   Funding Source: NIH RePORTER; NICHD NIH HHSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01 HD057116] Funding Source: Medline
CR Altvater-Mackensen N, 2016, NEUROIMAGE, V133, P14, DOI 10.1016/j.neuroimage.2016.02.061
   Bahrick L.E., 2012, MULTISENSORY DEV, P183, DOI DOI 10.1093/ACPROF:OSO/9780199586059.003.0008
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Barenholtz E, 2014, PSYCHON B REV, V21, P1346, DOI 10.3758/s13423-014-0612-7
   Chawarska K, 2012, J CHILD PSYCHOL PSYC, V53, P903, DOI 10.1111/j.1469-7610.2012.02538.x
   Corkum V, 1995, JOINT ATTENTION ITS, P61
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Fenson L., 1994, MONOGRAPHS SOC RES C, V59
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Goldstein MH, 2003, P NATL ACAD SCI USA, V100, P8030, DOI 10.1073/pnas.1332441100
   Goldstein MH, 2008, PSYCHOL SCI, V19, P515, DOI 10.1111/j.1467-9280.2008.02117.x
   Havy M, 2017, CHILD DEV, V88, P2043, DOI 10.1111/cdev.12715
   Hillairet de Boisferon A., 2016, DEVELOPMENTAL SCI, DOI [10.1111/clesc.12381, DOI 10.1111/CLESC.12381]
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Lansing IR, 2003, PERCEPT PSYCHOPHYS, V65, P536, DOI 10.3758/BF03194581
   Lewkowicz DJ, 2014, DEV PSYCHOBIOL, V56, P292, DOI 10.1002/dev.21197
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   Lusk LG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00052
   Ma WY, 2011, LANG LEARN DEV, V7, P185, DOI 10.1080/15475441.2011.579839
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Merin N, 2007, J AUTISM DEV DISORD, V37, P108, DOI 10.1007/s10803-006-0342-4
   Morales M, 2000, J APPL DEV PSYCHOL, V21, P283, DOI 10.1016/S0193-3973(99)00040-4
   Mundy P, 1998, INFANT BEHAV DEV, V21, P469, DOI 10.1016/S0163-6383(98)90020-0
   Musacchia G, 2009, HEARING RES, V258, P72, DOI 10.1016/j.heares.2009.06.018
   NELSON K, 1974, PSYCHOL REV, V81, P267, DOI 10.1037/h0036592
   NELSON K, 1981, DEV PSYCHOL, V17, P170, DOI 10.1037/0012-1649.17.2.170
   Oller DK, 2013, P NATL ACAD SCI USA, V110, P6318, DOI 10.1073/pnas.1300337110
   PAPOUSEK M, 1990, INFANT BEHAV DEV, V13, P539, DOI 10.1016/0163-6383(90)90022-Z
   Partan S, 1999, SCIENCE, V283, P1272, DOI 10.1126/science.283.5406.1272
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Ramirez-Esparza N, 2014, DEVELOPMENTAL SCI, V17, P880, DOI 10.1111/desc.12172
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Richardson JTE, 2011, EDUC RES REV-NETH, V6, P135, DOI 10.1016/j.edurev.2010.12.001
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Rowe C, 1999, ANIM BEHAV, V58, P921, DOI 10.1006/anbe.1999.1242
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Singh L, 2009, INFANCY, V14, P654, DOI 10.1080/15250000903263973
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   Thelen A, 2015, COGNITION, V138, P148, DOI 10.1016/j.cognition.2015.02.003
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   TOMASELLO M, 1986, CHILD DEV, V57, P1454, DOI 10.1111/j.1467-8624.1986.tb00470.x
   Trainor LJ, 2002, PSYCHON B REV, V9, P335, DOI 10.3758/BF03196290
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vo MLH, 2012, J VISION, V12, DOI 10.1167/12.13.3
   von Kriegstein K, 2006, PLOS BIOL, V4, P1809, DOI 10.1371/journal.pbio.0040326
   Wallace MT, 2001, J NEUROSCI, V21, P8886, DOI 10.1523/JNEUROSCI.21-22-08886.2001
   Werker J. F., 2004, WEAVING LEXICON, P79
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 59
TC 12
Z9 12
U1 2
U2 19
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD AUG
PY 2018
VL 172
BP 189
EP 200
DI 10.1016/j.jecp.2018.03.009
PG 12
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GF4MT
UT WOS:000431937700012
PM 29627481
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Butera, IM
   Stevenson, RA
   Mangus, BD
   Woynaroski, TG
   Gifford, RH
   Wallace, MT
AF Butera, Iliza M.
   Stevenson, Ryan A.
   Mangus, Brannon D.
   Woynaroski, Tiffany G.
   Gifford, Rene H.
   Wallace, Mark T.
TI Audiovisual Temporal Processing in Postlingually Deafened Adults with
   Cochlear Implants
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEECH-PERCEPTION; VISUAL SPEECH; MULTISENSORY INTEGRATION; ASYNCHRONY
   DETECTION; AUDITORY DETECTION; ORDER JUDGMENT; BINDING WINDOW; HEARING;
   CHILDREN; ACUITY
AB For many cochlear implant (CI) users, visual cues are vitally important for interpreting the impoverished auditory speech information that an implant conveys. Although the temporal relationship between auditory and visual stimuli is crucial for how this information is integrated, audiovisual temporal processing in CI users is poorly understood. In this study, we tested unisensory (auditory alone, visual alone) and multisensory (audiovisual) temporal processing in postlingually deafened CI users (n = 48) and normal-hearing controls (n = 54) using simultaneity judgment (SJ) and temporal order judgment (TOJ) tasks. We varied the timing onsets between the auditory and visual components of either a syllable/viseme or a simple flash/beep pairing, and participants indicated either which stimulus appeared first (TOJ) or if the pair occurred simultaneously (SJ). Results indicate that temporal binding windows-the interval within which stimuli are likely to be perceptually 'bound'-are not significantly different between groups for either speech or non-speech stimuli. However, the point of subjective simultaneity for speech was less visually leading in CI users, who interestingly, also had improved visual-only TOJ thresholds. Further signal detection analysis suggests that this SJ shift may be due to greater visual bias within the CI group, perhaps reflecting heightened attentional allocation to visual cues.
C1 [Butera, Iliza M.; Woynaroski, Tiffany G.; Gifford, Rene H.; Wallace, Mark T.] Vanderbilt Univ, Vanderbilt Brain Inst, Nashville, TN 37235 USA.
   [Stevenson, Ryan A.] Univ Western Ontario, Dept Psychol, London, ON, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
   [Mangus, Brannon D.] Murfreesboro Med Clin, Murfreesboro, TN USA.
   [Mangus, Brannon D.] Surgictr, Murfreesboro, TN USA.
   [Woynaroski, Tiffany G.; Gifford, Rene H.; Wallace, Mark T.] Vanderbilt Univ, Dept Hearing & Speech Sci, Nashville, TN USA.
   [Woynaroski, Tiffany G.; Gifford, Rene H.; Wallace, Mark T.] Vanderbilt Univ, Med Ctr, Vanderbilt Kennedy Ctr, Nashville, TN USA.
RP Butera, IM (corresponding author), Vanderbilt Univ, Vanderbilt Brain Inst, Nashville, TN 37235 USA.
EM ilizabutera@gmail.com
OI Gifford, Rene/0000-0001-6662-3436; Wallace, Mark/0000-0002-0166-906X
FU CTSA from the National Center for Advancing Translational SciencesUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Center for Advancing Translational
   Sciences (NCATS) [KL2TR000446]; EKS NICHD [U54HD083211]; NSERCNatural
   Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2017-04656]; SSHRCSocial Sciences and Humanities Research Council
   of Canada (SSHRC) [435-2017-0936]; University of Western Ontario Faculty
   Development Research Fund; NIH NIEHSUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Environmental Health Sciences (NIEHS) [T32 MH064913];
   National Institutes of Deafness and Communication DisordersUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [5F31DC015956]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF
   CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH Eunice
   Kennedy Shriver National Institute of Child Health & Human Development
   (NICHD) [U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211] Funding Source: NIH RePORTER;
   NATIONAL CENTER FOR ADVANCING TRANSLATIONAL SCIENCESUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Center for Advancing Translational Sciences (NCATS)
   [KL2TR002245, KL2TR000446, KL2TR002245, KL2TR000446, KL2TR002245,
   KL2TR002245, KL2TR000446, KL2TR000446, KL2TR000446] Funding Source: NIH
   RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute of Mental Health (NIMH) [T32MH064913, T32MH064913,
   T32MH064913, T32MH064913, T32MH064913, T32MH064913, T32MH064913,
   T32MH064913, T32MH064913, T32MH064913, T32MH064913, T32MH064913,
   T32MH064913, T32MH064913, T32MH064913, T32MH064913, T32MH064913,
   T32MH064913, T32MH064913] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [F31DC015956, F31DC015956, F31DC015956] Funding Source: NIH
   RePORTER
FX We thank Juliane Kreuger, Kelly Jahn, and Sterling Sheffield for their
   assistance with data collection, and acknowledge that this work was
   supported in part by CTSA award No. KL2TR000446 (T.G.W) from the
   National Center for Advancing Translational Sciences, the EKS NICHD
   award No. U54HD083211 (T.G.W. & M.T.W), an NSERC Discovery Grant No.
   RGPIN-2017-04656 (R.A.S), a SSHRC Insight Grant No. 435-2017-0936
   (R.A.S), the University of Western Ontario Faculty Development Research
   Fund (R.A.S), grant number T32 MH064913 (I.M.B.) from NIH NIEHS, and by
   the National Institutes of Deafness and Communication Disorders award
   No. 5F31DC015956 (I.M.B.). Its contents are solely the responsibility of
   the authors and do not necessarily represent the official views of any
   of these funding sources.
CR Baskent D, 2011, EAR HEARING, V32, P582, DOI 10.1097/AUD.0b013e31820fca23
   Bergeson TR, 2005, EAR HEARING, V26, P149, DOI 10.1097/00003446-200504000-00004
   Boenke LT, 2009, EXP BRAIN RES, V198, P233, DOI 10.1007/s00221-009-1917-z
   Burr D, 2006, PROG BRAIN RES, V155, P243, DOI 10.1016/S0079-6123(06)55014-9
   Busby PA, 1999, J ACOUST SOC AM, V105, P1841, DOI 10.1121/1.426721
   De Niear MA, 2018, NEUROBIOL LEARN MEM, V147, P9, DOI 10.1016/j.nlm.2017.10.016
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Eijk R. L. J., 2008, PERCEPT PSYCHOPHYS, V70, P955
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Freeman ED, 2013, CORTEX, V49, P2875, DOI 10.1016/j.cortex.2013.03.006
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   Gifford RH, 2008, AUDIOL NEURO-OTOL, V13, P193, DOI 10.1159/000113510
   Gifford RH, 2014, AUDIOL NEURO-OTOL, V19, P57, DOI 10.1159/000355700
   Gilley PM, 2010, RESTOR NEUROL NEUROS, V28, P207, DOI 10.3233/RNN-2010-0525
   Gori M, 2017, NEUROPSYCHOLOGIA, V99, P350, DOI 10.1016/j.neuropsychologia.2017.03.025
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Hay-McCutcheon MJ, 2009, INT J AUDIOL, V48, P321, DOI 10.1080/14992020802644871
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Hillock-Dunn A, 2012, DEVELOPMENTAL SCI, V15, P688, DOI 10.1111/j.1467-7687.2012.01171.x
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Huyse A, 2013, EAR HEARING, V34, P110, DOI 10.1097/AUD.0b013e3182670993
   Ipser A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46413
   IRWIN RJ, 1985, CHILD DEV, V56, P614
   Jahn KN, 2017, EAR HEARING, V38, P236, DOI 10.1097/AUD.0000000000000379
   Kaiser AR, 2003, J SPEECH LANG HEAR R, V46, P390, DOI 10.1044/1092-4388(2003/032)
   Kleiner M, 2007, PERCEPTION, V36, P14
   Krekelberg B, 2001, TRENDS NEUROSCI, V24, P335, DOI 10.1016/S0166-2236(00)01795-1
   Lachs L, 2001, EAR HEARING, V22, P236, DOI 10.1097/00003446-200106000-00007
   Love SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054798
   Lovelace CT, 2003, COGNITIVE BRAIN RES, V17, P447, DOI 10.1016/S0926-6410(03)00160-5
   Macmillan N, 2004, DETECTION THEORY USE
   Massaro DW, 1999, J SPEECH LANG HEAR R, V42, P21, DOI 10.1044/jslhr.4201.21
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Moody-Antonio S, 2005, OTOL NEUROTOL, V26, P649, DOI 10.1097/01.mao.0000178124.13118.76
   Moutoussis K, 1997, P ROY SOC B-BIOL SCI, V264, P393, DOI 10.1098/rspb.1997.0056
   Nava E, 2008, EXP BRAIN RES, V190, P179, DOI 10.1007/s00221-008-1459-9
   PARASNIS I, 1985, BRAIN COGNITION, V4, P313, DOI 10.1016/0278-2626(85)90024-7
   Powers AR, 2016, SCI REP-UK, V6, DOI 10.1038/srep23374
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Schneider KA, 2003, COGNITIVE PSYCHOL, V47, P333, DOI 10.1016/S0010-0285(03)00035-5
   Schorr EA, 2005, P NATL ACAD SCI USA, V102, P18748, DOI 10.1073/pnas.0508862102
   Schreitmuller S., 2017, EAR HEAR
   SHANNON RV, 1989, J ACOUST SOC AM, V85, P2587, DOI 10.1121/1.397753
   Skottun BC, 2010, NEUROPSYCHOLOGIA, V48, P2226, DOI 10.1016/j.neuropsychologia.2010.04.013
   Spence C, 2010, CONSCIOUS COGN, V19, P364, DOI 10.1016/j.concog.2009.12.001
   Stein BE, 1996, J COGNITIVE NEUROSCI, V8, P497, DOI 10.1162/jocn.1996.8.6.497
   Stevenson R. A., 2017, J EXP PSYCHOL HUM PE
   Stevenson RA, 2017, EAR HEARING, V38, P521, DOI 10.1097/AUD.0000000000000435
   Stevenson RA, 2017, SCHIZOPHR RES, V179, P97, DOI 10.1016/j.schres.2016.09.035
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tremblay C, 2010, RESTOR NEUROL NEUROS, V28, P283, DOI 10.3233/RNN-2010-0498
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Tyler RS, 1997, OTOLARYNG HEAD NECK, V117, P180, DOI 10.1016/S0194-5998(97)70172-4
   van Dam LCJ, 2014, SENSORY INTEGRATION AND THE UNITY OF CONSCIOUSNESS, P209
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vatakis A, 2006, NEUROSCI LETT, V393, P40, DOI 10.1016/j.neulet.2005.09.032
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Zampini M, 2005, NEUROSCI LETT, V381, P217, DOI 10.1016/j.neulet.2005.01.085
NR 64
TC 3
Z9 3
U1 0
U2 2
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUL 27
PY 2018
VL 8
AR 11345
DI 10.1038/s41598-018-29598-x
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GO4HC
UT WOS:000439965200038
PM 30054512
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Poltrock, S
   Chen, H
   Kwok, C
   Cheung, H
   Nazzi, T
AF Poltrock, Silvana
   Chen, Hui
   Kwok, Celia
   Cheung, Hintat
   Nazzi, Thierry
TI Adult Learning of Novel Words in a Non-native Language: Consonants,
   Vowels, and Tones
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE word learning; minimal pairs; non-native speech perception; tones;
   adults
ID LEXICAL TONE; PERCEPTUAL REORGANIZATION; LINGUISTIC EXPERIENCE; PHONETIC
   PERCEPTION; SPEECH CONTRASTS; 1ST YEAR; BIAS; ENGLISH; FRENCH;
   DISCRIMINATION
AB While words are distinguished primarily by consonants and vowels in many languages, tones are also used in the majority of the world's languages to cue lexical contrasts. However, studies on novel word learning have largely concentrated on consonants and vowels. To shed more light on the use of tonal information in novel word learning and its relationship with the development of phonological categories, the present study explored how adults' ability to learn minimal pair pseudowords in a tone language is modulated by their native phonological knowledge. Twenty-four adult speakers of three languages were tested: Cantonese, Mandarin, and French. Eye-tracking was used to record eye movements of these learners, while they were watching animated cartoons in Cantonese. On each trial, adults had to learn two new label-object associations, while the labels differed minimally by a consonant, a vowel, or a tone. Learning would therefore attest to participants' ability to use phonological information to distinguish the paired words. Results first revealed that adult learners in each language group performed better than chance in all conditions. Moreover, compared to native Cantonese adults, both Mandarin-and French-speaking adults performed worse on all three contrasts. In addition, French adults were worse on tones when compared to Mandarin adults. Lastly, no advantage for consonantal information in native lexical processing was found for Cantonese-speaking adults as predicted by the "division of labor" proposal, thus confirming crosslinguistic differences in consonant/vowel weight between speakers of tonal vs. non-tonal languages. These findings establish rapid novel word learning in a non-native language (long-term learning will have to be further assessed), modulated by native phonological knowledge. The implications of the findings of this adult study for further infant word learning studies are discussed.
C1 [Poltrock, Silvana; Chen, Hui; Nazzi, Thierry] Univ Paris 05, Sorbonne Paris Cite, Paris, France.
   [Poltrock, Silvana; Chen, Hui; Nazzi, Thierry] CNRS, Lab Psychol Percept, Paris, France.
   [Poltrock, Silvana] Univ Potsdam, Dept Linguist, Potsdam, Germany.
   [Kwok, Celia; Cheung, Hintat] Educ Univ Hong Kong, Dept Linguist & Modern Language Studies, Tai Po, Hong Kong, Peoples R China.
RP Poltrock, S; Nazzi, T (corresponding author), Univ Paris 05, Sorbonne Paris Cite, Paris, France.; Poltrock, S; Nazzi, T (corresponding author), CNRS, Lab Psychol Percept, Paris, France.; Poltrock, S (corresponding author), Univ Potsdam, Dept Linguist, Potsdam, Germany.
EM poltrocks@gmail.com; thierry.nazzi@parisdescartes.fr
OI Nazzi, Thierry/0000-0002-4378-3661; CHEUNG, Hin Tat/0000-0002-5266-5296
FU  [ANR-13-BSH2-0004];  [ANR-15-CE28-0011]
FX This work was partly funded by ANR-13-BSH2-0004 to TN, and
   ANR-15-CE28-0011 to TN and HC. We would like to thank the participants
   for their time, and Sylvie Margules for help running the experiment.
CR Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bauer R., 1997, MODERN CANTONESE PHO
   Benavides-Varela S, 2012, P NATL ACAD SCI USA, V109, P17908, DOI 10.1073/pnas.1205413109
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Birdsong D, 2001, J MEM LANG, V44, P235, DOI 10.1006/jmla.2000.2750
   Boll-Avetisyan N, 2016, BILING-LANG COGN, V19, P971, DOI 10.1017/S1366728915000425
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   Cabrera L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01290
   Carreiras M, 2009, CEREB CORTEX, V19, P2659, DOI 10.1093/cercor/bhp019
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Cheng RL, 1966, J LINGUIST, V2, P135, DOI 10.1017/S0022226700001444
   Cooper A, 2013, J ACOUST SOC AM, V134, pEL133, DOI 10.1121/1.4812435
   Cooper A, 2012, J ACOUST SOC AM, V131, P4756, DOI 10.1121/1.4714355
   Creel SC, 2006, J MEM LANG, V54, P1, DOI 10.1016/j.jml.2005.09.003
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   DeLancey S., 2009, WORLDS MAJOR LANGUAG, P693
   Delle Luche C, 2014, J MEM LANG, V72, P1, DOI 10.1016/j.jml.2013.12.001
   Dink J. W, 2015, EYETRACKINGR R LIB E
   Dittinger E, 2016, J COGNITIVE NEUROSCI, V28, P1584, DOI 10.1162/jocn_a_00997
   Duanmu S., 2000, PHONOLOGY STANDARD C
   Dupoux E, 2008, COGNITION, V106, P682, DOI 10.1016/j.cognition.2007.04.001
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Floccia C, 2014, J CHILD LANG, V41, P1085, DOI 10.1017/S0305000913000287
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Gandour J, 2000, J COGNITIVE NEUROSCI, V12, P207, DOI 10.1162/089892900561841
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   Gomez DM, 2018, LANG SPEECH, V61, P84, DOI 10.1177/0023830917706529
   Gong H. C., 1980, B I HIST PHILOLOGY, V51, P455
   Gonzalez-Gomez N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059601
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Harrison P. A., 1999, THESIS
   Harrison P. A., 1998, UCL WORKING PAPERS P, V10, P33
   HASHIMOTO A, 1972, PHONOLOGY CANTONESE
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Hochmann JR, 2018, INFANCY, V23, P136, DOI 10.1111/infa.12203
   Hochmann JR, 2011, DEVELOPMENTAL SCI, V14, P1445, DOI 10.1111/j.1467-7687.2011.01089.x
   Hojen A, 2016, DEVELOPMENTAL SCI, V19, P41, DOI 10.1111/desc.12286
   Howie J.M., 1976, ACOUSTICAL STUDIES M
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Li F. - K., 1937, J CHINESE LINGUISTIC, P59
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Nazzi T, 2016, CURR DIR PSYCHOL SCI, V25, P291, DOI 10.1177/0963721416655786
   Nazzi T, 2009, J EXP CHILD PSYCHOL, V102, P522, DOI 10.1016/j.jecp.2008.05.003
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   New B, 2014, LANG COGN NEUROSCI, V29, P147, DOI 10.1080/01690965.2012.735678
   New B, 2008, PSYCHOL SCI, V19, P1223, DOI 10.1111/j.1467-9280.2008.02228.x
   Nishibayashi LL, 2016, COGNITION, V155, P188, DOI 10.1016/j.cognition.2016.07.003
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Poltrock S, 2015, J EXP CHILD PSYCHOL, V131, P135, DOI 10.1016/j.jecp.2014.11.011
   R Core Team, 2017, R LANG ENV STAT COMP
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   So C. K., 2010, P INT 2010 SAT WORKS
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   So CK, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1120
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Toro JM, 2008, PSYCHOL SCI, V19, P137, DOI 10.1111/j.1467-9280.2008.02059.x
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   vanOoijen B, 1996, MEM COGNITION, V24, P573, DOI 10.3758/BF03201084
   Wang W. S. - Y., 1963, POLA, V6, P1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE
NR 78
TC 7
Z9 7
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 24
PY 2018
VL 9
AR 1211
DI 10.3389/fpsyg.2018.01211
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA GO0JI
UT WOS:000439612800002
PM 30087631
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Yu, F
   Li, H
   Zhou, XQ
   Tang, XL
   Galvin, JJ
   Fu, QJ
   Yuan, W
AF Yu, Fei
   Li, Hai
   Zhou, Xiaoqing
   Tang, XiaoLin
   Galvin, John J., III
   Fu, Qian-Jie
   Yuan, Wei
TI Effects of Training on Lateralization for Simulations of Cochlear
   Implants and Single-Sided Deafness
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE cochlear implants; single-sided deafness; localization; lateralization;
   insertion depth
ID SOUND SOURCE LOCALIZATION; MELODIC CONTOUR IDENTIFICATION; BINAURAL
   INTERACTION COMPONENT; LEVEL DIFFERENCE CUES; UNILATERAL DEAFNESS;
   INTERAURAL TIME; HEARING-LOSS; SPEECH-PERCEPTION; INSERTION DEPTH;
   IN-NOISE
AB While cochlear implantation has benefitted many patients with single-sided deafness (SSD), there is great variability in cochlear implant (CI) outcomes and binaural performance remains poorer than that of normal-hearing (NH) listeners. Differences in sound quality across ears-temporal fine structure (TFS) information with acoustic hearing vs. coarse spectro-temporal envelope information with electric hearing-may limit integration of acoustic and electric patterns. Binaural performance may also be limited by inter-aural mismatch between the acoustic input frequency and the place of stimulation in the cochlea. SSD CI patients must learn to accommodate these differences between acoustic and electric stimulation to maximize binaural performance. It is possible that training may increase and/or accelerate accommodation and further improve binaural performance. In this study, we evaluated lateralization training in NH subjects listening to broad simulations of SSD CI signal processing. A 16-channel vocoder was used to simulate the coarse spectro-temporal cues available with electric hearing; the degree of inter-aural mismatch was varied by adjusting the simulated insertion depth (SID) to be 25 mm (SID25), 22 mm (SID22) and 19 mm (SID19) from the base of the cochlea. Lateralization was measured using headphones and head-related transfer functions (HRTFs). Baseline lateralization was measured for unprocessed speech (UN) delivered to the left ear to simulate SSD and for binaural performance with the acoustic ear combined with the 16-channel vocoders (UN+SID25, UN+SID22 and UN+SID19). After completing baseline measurements, subjects completed six lateralization training exercises with the UN+SID22 condition, after which performance was re-measured for all baseline conditions. Post-training performance was significantly better than baseline for all conditions (p < 0.05 in all cases), with no significant difference in training benefits among conditions. Given that there was no significant difference between the SSD and the SSD CI conditions before or after training, the results suggest that NH listeners were unable to integrate TFS and coarse spectro-temporal cues across ears for lateralization, and that inter-aural mismatch played a secondary role at best. While lateralization training may benefit SSD CI patients, the training may largely improve spectral analysis with the acoustic ear alone, rather than improve integration of acoustic and electric hearing.
C1 [Yu, Fei; Li, Hai; Zhou, Xiaoqing; Tang, XiaoLin; Yuan, Wei] Third Mil Med Univ, Southwest Hosp, Dept Otolaryngol, Chongqing, Peoples R China.
   [Galvin, John J., III] House Ear Res Inst, Los Angeles, CA USA.
   [Fu, Qian-Jie] Univ Calif Los Angeles, David Geffen Sch Med, Dept Head & Neck Surg, Los Angeles, CA 90095 USA.
RP Yuan, W (corresponding author), Third Mil Med Univ, Southwest Hosp, Dept Otolaryngol, Chongqing, Peoples R China.; Fu, QJ (corresponding author), Univ Calif Los Angeles, David Geffen Sch Med, Dept Head & Neck Surg, Los Angeles, CA 90095 USA.
EM qfu@mednet.ucla.edu; weyuan175@sina.com
OI Fu, Qian-Jie/0000-0003-3494-7633
FU Chongqing Science and Technology Commission of the people's livelihood
   special funding [cstc2016shmszx130058]; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [81470694, 81271080]; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01-DC004792];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC004792, R01DC004792, R01DC004792,
   R01DC004792, R01DC004792, R01DC004792, R01DC004792, R01DC004792,
   R01DC004792, R01DC004792, R01DC004792, R01DC004792, R01DC004792,
   R01DC004792, R01DC004792, R01DC004792, R01DC004792, R01DC004792] Funding
   Source: NIH RePORTER
FX This work was supported by the Chongqing Science and Technology
   Commission of the people's livelihood special funding under Grant No.
   cstc2016shmszx130058, National Natural Science Foundation of China under
   grant No. 81470694 and 81271080, and by NIH grant R01-DC004792.
CR Arndt S, 2011, OTOL NEUROTOL, V32, P39, DOI 10.1097/MAO.0b013e3181fcf271
   Aronoff JM, 2011, EAR HEARING, V32, P468, DOI 10.1097/AUD.0b013e31820dd3f0
   Aronoff JM, 2010, J ACOUST SOC AM, V127, pEL87, DOI 10.1121/1.3298451
   Blauert J., 1997, SPATIAL HEARING PSYC, P36
   Chan JCY, 2008, INT J AUDIOL, V47, P296, DOI 10.1080/14992020802075407
   Dillon MT, 2017, EAR HEARING, V38, P611, DOI 10.1097/AUD.0000000000000430
   Dorman MF, 2017, OTOL NEUROTOL, V38, pE268, DOI 10.1097/MAO.0000000000001449
   Dorman MF, 2016, AUDIOL NEURO-OTOL, V21, P127, DOI 10.1159/000444740
   Dorman MF, 2015, AUDIOL NEURO-OTOL, V20, P183, DOI 10.1159/000375394
   Eapen RJ, 2009, OTOL NEUROTOL, V30, P153, DOI 10.1097/MAO.0b013e3181925025
   Faulkner Andrew, 2006, Audiol Neurootol, V11 Suppl 1, P21, DOI 10.1159/000095610
   Feinkohl A, 2013, BEHAV BRAIN RES, V256, P669, DOI 10.1016/j.bbr.2013.08.038
   Firszt JB, 2012, OTOL NEUROTOL, V33, P1339, DOI 10.1097/MAO.0b013e318268d52d
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Fu Qian-Jie, 2004, Cochlear Implants Int, V5 Suppl 1, P84, DOI 10.1179/cim.2004.5.Supplement-1.84
   Fu QJ, 2015, J SPEECH LANG HEAR R, V58, P163, DOI 10.1044/2014_JSLHR-H-14-0127
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Fu QJ, 2002, J ACOUST SOC AM, V112, P1664, DOI 10.1121/1.1502901
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Galvin John J. III, 2012, Seminars in Hearing, V33, P399, DOI 10.1055/s-0032-1329227
   Gartrell BC, 2014, OTOL NEUROTOL, V35, P1525, DOI 10.1097/MAO.0000000000000437
   Goupell MJ, 2013, J ACOUST SOC AM, V133, P2272, DOI 10.1121/1.4792936
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   Hansen MR, 2013, OTOL NEUROTOL, V34, P1681, DOI 10.1097/MAO.0000000000000102
   Hu HM, 2016, ADV EXP MED BIOL, V894, P57, DOI 10.1007/978-3-319-25474-6_7
   Kamal SM, 2012, CURR OPIN OTOLARYNGO, V20, P393, DOI 10.1097/MOO.0b013e328357a613
   Kan A, 2015, EAR HEARING, V36, pE62, DOI 10.1097/AUD.0000000000000135
   Liu YW, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518813802
   Long CJ, 2003, J ACOUST SOC AM, V114, P1565, DOI 10.1121/1.1603765
   Mertens G, 2016, CLIN OTOLARYNGOL, V41, P511, DOI 10.1111/coa.12555
   Mertens G, 2017, EAR HEARING, V38, P117, DOI 10.1097/AUD.0000000000000359
   Oba SI, 2011, EAR HEARING, V32, P573, DOI 10.1097/AUD.0b013e31820fc821
   PERROTT DR, 1987, J ACOUST SOC AM, V82, P1637, DOI 10.1121/1.395155
   Poon BB, 2009, J ACOUST SOC AM, V126, P806, DOI 10.1121/1.3158821
   Reiss LAJ, 2008, OTOL NEUROTOL, V29, P160, DOI 10.1097/mao.0b013e31815aedf4
   Reiss LAJ, 2007, JARO-J ASSOC RES OTO, V8, P241, DOI 10.1007/s10162-007-0077-8
   Reiss LAJ, 2015, EAR HEARING, V36, pE23, DOI 10.1097/AUD.0000000000000114
   Reiss LAJ, 2012, AUDIOL NEURO-OTOL, V17, P357, DOI 10.1159/000341165
   Reiss LAJ, 2011, EAR HEARING, V32, P536, DOI 10.1097/AUD.0b013e31820c81b0
   Rosen S, 1999, J ACOUST SOC AM, V106, P3629, DOI 10.1121/1.428215
   Shinn-Cunningham B, 2000, PERCEPT PSYCHOPHYS, V62, P33, DOI 10.3758/BF03212059
   Stacey PC, 2008, J SPEECH LANG HEAR R, V51, P526, DOI 10.1044/1092-4388(2008/038)
   Stacey PC, 2007, J ACOUST SOC AM, V121, P2923, DOI 10.1121/1.2713668
   Stacey PC, 2010, INT J AUDIOL, V49, P347, DOI 10.3109/14992020903397838
   Svirsky MA, 2004, ACTA OTO-LARYNGOL, V124, P381, DOI 10.1080/00016480310000593
   Svirsky MA, 2015, ACTA OTO-LARYNGOL, V135, P354, DOI 10.3109/00016489.2014.1002052
   Tavora-Vieira D, 2013, LARYNGOSCOPE, V123, P1251, DOI 10.1002/lary.23764
   THURLOW WR, 1967, J ACOUST SOC AM, V42, P480, DOI 10.1121/1.1910604
   Tokita J, 2014, CURR OPIN OTOLARYNGO, V22, P353, DOI 10.1097/MOO.0000000000000080
   Tyler RS, 2010, J AM ACAD AUDIOL, V21, P390, DOI 10.3766/jaaa.21.6.4
   van Zon A, 2015, OTOL NEUROTOL, V36, P209, DOI 10.1097/MAO.0000000000000681
   Vermeire K, 2015, HEARING RES, V326, P8, DOI 10.1016/j.heares.2015.03.011
   Vermeire K, 2009, AUDIOL NEURO-OTOL, V14, P163, DOI 10.1159/000171478
   Yost WA, 2013, J ACOUST SOC AM, V133, P2876, DOI 10.1121/1.4799803
   Zhang F., 2018, 2018 MWM ASS RES OT, P208
   Zhang F, 2008, J AM ACAD AUDIOL, V19, P82, DOI 10.3766/jaaa.19.1.7
   Zhou XQ, 2017, INT J AUDIOL, V56, pS41, DOI 10.1080/14992027.2016.1197426
NR 59
TC 1
Z9 1
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD JUL 17
PY 2018
VL 12
AR 287
DI 10.3389/fnhum.2018.00287
PG 10
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA GN4MU
UT WOS:000439000400003
PM 30065641
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Shaw, JA
   Best, CT
   Docherty, G
   Evans, BG
   Foulkes, P
   Hay, J
   Mulak, KE
AF Shaw, Jason A.
   Best, Catherine T.
   Docherty, Gerard
   Evans, Bronwen G.
   Foulkes, Paul
   Hay, Jennifer
   Mulak, Karen E.
TI Resilience of English vowel perception across regional accent variation
SO LABORATORY PHONOLOGY
LA English
DT Article
DE vowel perception; sociophonetic variation; English accents; perceptual
   learning; Perceptual Assimilation Model
ID TRAINING JAPANESE LISTENERS; SPEECH-PERCEPTION; PHONETIC CONVERGENCE;
   TALKER VARIABILITY; ADAPTATION; ASSIMILATION; DISCRIMINATION;
   NORMALIZATION; ACQUISITION; ASYMMETRIES
AB In two categorization experiments using phonotactically legal nonce words, we tested Australian English listeners' perception of all vowels in their own accent as well as in four less familiar regional varieties of English which differ in how their vowel realizations diverge from Australian English: London, Yorkshire, Newcastle (UK), and New Zealand. Results of Experiment 1 indicated that amongst the vowel differences described in sociophonetic studies and attested in our stimulus materials, only a small subset caused greater perceptual difficulty for Australian listeners than for the corresponding Australian English vowels. We discuss this perceptual tolerance for vowel variation in terms of how perceptual assimilation of phonetic details into abstract vowel categories may contribute to recognizing words across variable pronunciations. Experiment 2 determined whether short-term multi-talker exposure would facilitate accent adaptation, particularly for those vowels that proved more difficult to categorize in Experiment 1. For each accent separately, participants listened to a pre-test passage in the nonce word accent but told by novel talkers before completing the same task as in Experiment 1. In contrast to previous studies showing rapid adaptation to talker-specific variation, our listeners' subsequent vowel assimilations were largely unaffected by exposure to other talkers' accent-specific variation.
C1 [Shaw, Jason A.; Best, Catherine T.; Mulak, Karen E.] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
   [Shaw, Jason A.] Yale Univ, Dept Linguist, New Haven, CT 06510 USA.
   [Docherty, Gerard] Griffith Univ, Arts Educ & Law, Brisbane, Qld 4111, Australia.
   [Evans, Bronwen G.] UCL, Dept Speech Hearing & Phonet Sci, London WC1E 6BT, England.
   [Foulkes, Paul] Univ York, Language & Linguist Sci, York YO10 5DD, N Yorkshire, England.
   [Hay, Jennifer] Univ Canterbury, New Zealand Inst Language Brain & Behav, Private Bag 4800, Christchurch 8140, New Zealand.
   [Mulak, Karen E.] Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20740 USA.
RP Shaw, JA (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.; Shaw, JA (corresponding author), Yale Univ, Dept Linguist, New Haven, CT 06510 USA.
EM jason.shaw@yale.edu
RI Best, Catherine T/M-4547-2019
OI Best, Catherine T/0000-0002-2447-2024; Shaw, Jason/0000-0002-5285-5049
FU Australian Research CouncilAustralian Research Council [DP120104596]
FX We would like to thank participants in this study and several research
   assistants who contributed to the collection of the data reported
   here-in New Zealand: Ksenia Gnevsheva, Mike Peek, Alia Hope-Wilson,
   Nathan Taylor, and Vicky Watson; in Northern England: Jalal Al-Tamimi,
   Sophie Wood, Vince Hughes, Amanda Cardoso, Hannah How, Justin Lo, Ella
   Jeffries, and James Tompkinson; in London: Anita Wagner, Katharine Mair,
   and Gisela Tome Lourido; in Sydney: Sarah Wright, Sara Fenwick, and Mark
   Lathouwers. The exposure passage was written by Meg Mundell. We thank
   audiences at the 18th International Congress of Phonetic Sciences in
   Glasgow, the 15th Interspeech conference in Dresden, the workshop on
   Sociophonetic Variability in the English Varieties of Australia in
   Brisbane, and the workshop of the Role of Predictability in Shaping
   Human Language Sound Patterns in Sydney, where aspects of this research
   were presented. The project was supported by Australian Research Council
   grant DP120104596.
CR Adank P, 2004, J ACOUST SOC AM, V116, P3099, DOI 10.1121/1.1795335
   Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Bates D, 2014, R PACKAGE VERSION, V1, pe4
   Bayard D., 2001, J SOCIOLING, V5, P22, DOI [10.1111/1467-9481.00136, DOI 10.1111/1467-9481.00136]
   BELL A, 1997, ENGL WORLD-WIDE, V18, P243, DOI DOI 10.1075/EWW.18.2.05BEL
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T., 2015, PHONETICS PHONOLOGY, P3, DOI [10.1075/cilt.335.01bes, DOI 10.1075/CILT.335.01BES]
   Best C. T, 2015, P 18 INT C PHON SCI
   Best CT, 2013, INTERSPEECH, P2127
   Best CT, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1932
   Best CT, 2010, J PHONETICS, V38, P109, DOI 10.1016/j.wocn.2009.09.001
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Billington R, 2011, AUST J LINGUIST, V31, P275, DOI 10.1080/07268602.2011.598628
   Bloomfield L, 1926, LANGUAGE, V2, P153, DOI 10.2307/408741
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Browman CP., 1989, PHONOLOGY, V6, P201, DOI [10.1017/S0952675700001019, DOI 10.1017/S0952675700001019]
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   CARLSON R, 1979, J ACOUST SOC AM, V65, pS6, DOI 10.1121/1.2017398
   Chodroff E, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0047
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clapper CG, 2016, J PHONETICS, V58, P87, DOI 10.1016/j.wocn.2016.06.002
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clopper CG, 2004, LANG SPEECH, V47, P207, DOI 10.1177/00238309040470030101
   Cox F., 2007, J INT PHON ASSOC, V37, P341, DOI [10.1017/S0025100307003192, DOI 10.1017/S0025100307003192]
   Cox F., 2006, AUST J LINGUIST, V26, P147, DOI DOI 10.1080/07268600600885494
   Cox F, 2014, AUST J LINGUIST, V34, P50, DOI 10.1080/07268602.2014.875455
   Cox F, 2012, STUD ENGL LANG, P294
   Cutler A., 2010, LAB PHONOLOGY, V10, P91
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL277, DOI 10.1121/1.3632043
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2009, J PSYCHOLINGUIST RES, V38, P379, DOI 10.1007/s10936-008-9097-8
   Fox S, 2015, NEW COCKNEY NEW ETHN
   GARRETT P, 2005, MULTILINGUA, V24, P211, DOI DOI 10.1515/MULT.2005.24.3.211
   Goldinger S. D., 2007, P OFC NFOEC 2007 AN, P1
   Haddican B, 2013, LANG VAR CHANGE, V25, P371, DOI 10.1017/S0954394513000197
   Hall Kathleen Currie, 2009, THESIS
   Harrington J, 2000, NATURE, V408, P927, DOI 10.1038/35050160
   Hay J., 2008, NZ ENGLISH, DOI [10.3366/edinburgh/9780748625291.001.0001, DOI 10.3366/EDINBURGH/9780748625291.001.0001]
   Hockett Charles F., 1966, WORD, V23, P320, DOI [10.1080/00437956.1967.11435484., DOI 10.1080/00437956.1967.11435484]
   Hofmeister P, 2013, LANG COGNITIVE PROC, V28, P48, DOI 10.1080/01690965.2011.572401
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Kerswill P, 2008, LANG VAR CHANGE, V20, P451, DOI 10.1017/S0954394508000148
   Kim Midam, 2011, Lab Phonol, V2, P125
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   Menard S, 2010, LOGISTIC REGRESSION, DOI [10.4135/9781483348964, DOI 10.4135/9781483348964]
   Moore B, 2008, SPEAKING OUR LANGUAG
   Munson B, 2004, J SPEECH LANG HEAR R, V47, P1048, DOI 10.1044/1092-4388(2004/078)
   Niedzielski Nancy A., 2000, FOLK LINGUISTICS, DOI [10.1515/9783110803389, DOI 10.1515/9783110803389]
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nycz J, 2013, ENGL LANG LINGUIST, V17, P325, DOI 10.1017/S1360674313000051
   Pardo JS, 2012, J PHONETICS, V40, P190, DOI 10.1016/j.wocn.2011.10.001
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   PISONI DB, 1975, MEM COGNITION, V3, P7, DOI 10.3758/BF03198202
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   PRZEDLACKA J, 2001, STUDIA ANGLICA POSNA, V36, P35
   Recasens D, 2015, J INT PHON ASSOC, V45, P115, DOI 10.1017/S0025100315000080
   Repp BH., 1984, SPEECH LANG ADV BASI, V10, P243, DOI DOI 10.1016/B978-0-12-608610-2.50012-1
   Rosner B. S., 1994, VOWEL PERCEPTION PRO, DOI [10.1093/acprof:oso/9780198521389.001.0001, DOI 10.1093/ACPROF:OSO/9780198521389.001.0001]
   Ryfa J, 2013, WORLD ENGLISH, VI, P31
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Schwartz JL, 2005, SPEECH COMMUN, V45, P425, DOI 10.1016/j.specom.2004.12.001
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Shaw J. A., 2016, LABPHON, V15
   Shaw J. A., 2014, P 14 AUSTR INT C SPE, P72
   Shaw JA, 2019, LANG SPEECH, V62, P80, DOI 10.1177/0023830917737331
   Shaw JA, 2013, LAB PHONOL, V4, P159, DOI 10.1515/lp-2013-0007
   Skoruppa K, 2011, COGNITIVE SCI, V35, P348, DOI 10.1111/j.1551-6709.2010.01152.x
   Smolensky P, 2014, COGNITIVE SCI, V38, P1102, DOI 10.1111/cogs.12047
   Sonderegger M, 2017, LANGUAGE, V93, P598, DOI 10.1353/lan.2017.0038
   Stuart-Smith J, 2013, LANGUAGE, V89, P501, DOI 10.1353/lan.2013.0041
   Sumner M, 2011, COGNITION, V119, P131, DOI 10.1016/j.cognition.2010.10.018
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Szakay A, 2016, J PHONETICS, V59, P92, DOI 10.1016/j.wocn.2016.09.005
   Tamminga M, 2016, LINGUIST VAR, V16, P300, DOI 10.1075/lv.16.2.06tam
   Tollfree Laura, 1999, URBAN VOICES ACCENT, P163
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   vanOoijen B, 1996, MEM COGNITION, V24, P573, DOI 10.3758/BF03201084
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
   Watt D., 1999, URBAN VOICES ACCENT, P25
   Watt Dominic, 2003, J INT PHON ASSOC, V33, P267, DOI DOI 10.1017/S0025100303001397
   WEATHERALL A, 1998, TE REO, V41, P153
   Wells John C., 1982, ACCENTS ENGLISH, DOI [10.1017/CBO9780511611759, DOI 10.1017/CBO9780511611759]
   Williams Ann, 1999, URBAN VOICES ACCENT, P141
   Ying J, 2013, INTERSPEECH, P2107
NR 106
TC 6
Z9 6
U1 0
U2 5
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD JUL 17
PY 2018
VL 9
IS 1
AR 11
DI 10.5334/labphon.87
PG 36
WC Linguistics; Language & Linguistics
SC Linguistics
GA GQ2HY
UT WOS:000441475400001
OA DOAJ Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Di Liberto, GM
   Peter, V
   Kalashnikova, M
   Goswami, U
   Burnham, D
   Lalor, EC
AF Di Liberto, Giovanni M.
   Peter, Varghese
   Kalashnikova, Marina
   Goswami, Usha
   Burnham, Denis
   Lalor, Edmund C.
TI Atypical cortical entrainment to speech in the right hemisphere
   underpins phonemic deficits in dyslexia
SO NEUROIMAGE
LA English
DT Article
DE Cortical tracking; Language impairment; Natural speech; EEG;
   Neuromarker; Objective measure
ID DEVELOPMENTAL DYSLEXIA; AUDITORY-CORTEX; CHILDREN; ENVELOPE;
   MODULATIONS; ADOLESCENTS; ASYMMETRY; PATTERNS; LANGUAGE; READERS
AB Developmental dyslexia is a multifaceted disorder of learning primarily manifested by difficulties in reading, spelling, and phonological processing. Neural studies suggest that phonological difficulties may reflect impairments in fundamental cortical oscillatory mechanisms. Here we examine cortical mechanisms in children (6-12 years of age) with or without dyslexia (utilising both age-and reading-level-matched controls) using electroencephalography (EEG). EEG data were recorded as participants listened to an audio-story. Novel electrophysiological measures of phonemic processing were derived by quantifying how well the EEG responses tracked phonetic features of speech. Our results provide, for the first time, evidence for impaired low-frequency cortical tracking to phonetic features during natural speech perception in dyslexia. Atypical phonological tracking was focused on the right hemisphere, and correlated with traditional psychometric measures of phonological skills used in diagnostic dyslexia assessments. Accordingly, the novel indices developed here may provide objective metrics to investigate language development and language impairment across languages.
C1 [Di Liberto, Giovanni M.; Lalor, Edmund C.] Trinity Coll Dublin, Trinity Coll Inst Neurosci, Sch Engn, Trinity Ctr Bioengn, Dublin 2, Ireland.
   [Di Liberto, Giovanni M.] CNRS, Lab Syst Perceptifs, UMR 8248, Paris, France.
   [Di Liberto, Giovanni M.] PSL Res Univ, Ecole Natl Super, Dept Etud Cognit, Paris, France.
   [Peter, Varghese; Kalashnikova, Marina; Burnham, Denis] Univ Western Sydney, MARCS Inst Brain Behav & Dev, Locked Bag 1957, Penrith, NSW, Australia.
   [Peter, Varghese] Macquarie Univ, Dept Linguist, N Ryde, NSW 2109, Australia.
   [Goswami, Usha] Univ Cambridge, Dept Psychol, Ctr Neurosci Educ, Cambridge, England.
   [Lalor, Edmund C.] Univ Rochester, Dept Biomed Engn, Rochester, NY USA.
   [Lalor, Edmund C.] Univ Rochester, Dept Neurosci, Rochester, NY USA.
RP Peter, V (corresponding author), Univ Western Sydney, MARCS Inst Brain Behav & Dev, Locked Bag 1957, Penrith, NSW, Australia.; Di Liberto, GM (corresponding author), Lab Syst Perceptifs, 29 Rue Ulm, F-75005 Paris, France.
EM diliberg@tcd.ie; varghese.peter@mq.edu.au
RI Kalashnikova, Marina/B-6590-2019; Di Liberto, Giovanni/AAT-8865-2020;
   Burnham, Denis/L-3742-2019
OI Kalashnikova, Marina/0000-0002-7924-8687; Di Liberto,
   Giovanni/0000-0002-7361-0980; Burnham, Denis/0000-0002-1980-3458; Peter,
   Varghese/0000-0002-4007-507X; Goswami, Usha/0000-0001-7858-2336; Lalor,
   Edmund/0000-0002-2498-6631
FU Irish Research Council Government of Ireland Postgraduate
   ScholarshipIrish Research Council for Science, Engineering and
   Technology [GOIPG/2013/1249]; Australian Research Council Discovery
   ProjectAustralian Research Council [DP110105123]
FX This study was supported by an Irish Research Council Government of
   Ireland Postgraduate Scholarship (GOIPG/2013/1249) awarded to the first
   and sixth authors and an Australian Research Council Discovery Project
   grant (DP110105123) awarded to the fourth and fifth authors.
CR Abrams DA, 2009, J NEUROSCI, V29, P7686, DOI 10.1523/JNEUROSCI.5242-08.2009
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Baker SF, 2007, INT J LAW PSYCHIAT, V30, P492, DOI 10.1016/j.ijlp.2007.09.010
   Benjamini Y, 2001, ANN STAT, V29, P1165
   Bishop D., 2003, CHILDRENS COMMUNICAT
   Bishop DVM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0035851
   Brooks M. Y., 2014, SCH DISABILITY STATU
   Clark KA, 2014, BRAIN, V137, P3136, DOI 10.1093/brain/awu229
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Cutini S, 2016, NEUROIMAGE, V143, P40, DOI 10.1016/j.neuroimage.2016.08.012
   Daniel SS, 2006, J LEARN DISABIL-US, V39, P507, DOI 10.1177/00222194060390060301
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto GM, 2017, HEARING RES, V348, P70, DOI 10.1016/j.heares.2017.02.015
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00481
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2013, CURR OPIN NEUROBIOL, V23, P37, DOI 10.1016/j.conb.2012.09.003
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gori S, 2015, J VISION, V15, DOI [10.1167/15.1.8, 10.1167/15.12.195]
   Gorman K., 2011, CANADIAN ACOUSTICS, V39, P192
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2013, LAB PHONOL, V4, P67, DOI 10.1515/lp-2013-0004
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   GREENWOOD D, 1961, J ACOUST SOC AM, V33, P484, DOI 10.1121/1.1908699
   Heim S, 2003, EUR J NEUROSCI, V17, P1715, DOI 10.1046/j.1460-9568.2003.02596.x
   Jones G, 2015, COGNITION, V144, P1, DOI 10.1016/j.cognition.2015.07.009
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   Lehongre K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00454
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Leong V, 2014, HEARING RES, V308, P141, DOI 10.1016/j.heares.2013.07.015
   Lizarazu M, 2015, HUM BRAIN MAPP, V36, P4986, DOI 10.1002/hbm.22986
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   McArthur G M, 2001, Dyslexia, V7, P150
   McNulty MA, 2003, J LEARN DISABIL-US, V36, P363, DOI 10.1177/00222194030360040701
   Miller-Shaul S, 2005, DYSLEXIA, V11, P132, DOI 10.1002/dys.290
   Molinaro N, 2016, HUM BRAIN MAPP, V37, P2767, DOI 10.1002/hbm.23206
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Peter V, 2016, DEV COGN NEUROS-NETH, V19, P152, DOI 10.1016/j.dcn.2016.03.006
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Power AJ, 2016, BRAIN LANG, V160, P1, DOI 10.1016/j.bandl.2016.06.006
   Power AJ, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00777
   Richlan F, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00120
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   SABORNIE EJ, 1994, LEARN DISABILITY Q, V17, P268, DOI 10.2307/1511124
   Schulte-Korne G, 2010, CLIN NEUROPHYSIOL, V121, P1794, DOI 10.1016/j.clinph.2010.04.028
   Semel E, 2006, CLIN EVALUATION LANG
   Snowling M., 2000, DYSLEXIA
   Swanson J. M., 1992, SCH BASED ASSESSMENT
   Torgesen JK, 2012, TOWRE TEST WORD READ
   Valdois S, 2004, DYSLEXIA, V10, P339, DOI 10.1002/dys.284
   Vanvooren S, 2014, J NEUROSCI, V34, P1523, DOI 10.1523/JNEUROSCI.3209-13.2014
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Wagner R. K., 2013, COMPREHENSIVE TEST P
   Wiener J, 2002, J ABNORM CHILD PSYCH, V30, P127, DOI 10.1023/A:1014701215315
NR 58
TC 28
Z9 28
U1 2
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD JUL 15
PY 2018
VL 175
BP 70
EP 79
DI 10.1016/j.neuroimage.2018.03.072
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GG8LO
UT WOS:000432949000007
PM 29609008
DA 2021-02-24
ER

PT J
AU Rosemann, S
   Thiel, CM
AF Rosemann, Stephanie
   Thiel, Christiane M.
TI Audio-visual speech processing in age-related hearing loss: Stronger
   integration and increased frontal lobe recruitment
SO NEUROIMAGE
LA English
DT Article
DE Aging; Hearing loss; Audio-visual speech; McGurk effect; Listening
   effort; Functional MRI
ID CROSS-MODAL REORGANIZATION; IMPLANTED DEAF PATIENTS; OLDER-ADULTS;
   AUDITORY-CORTEX; CORTICAL ACTIVITY; WORKING-MEMORY; BRAIN-REGIONS;
   PERCEPTION; LANGUAGE; RECOGNITION
AB Hearing loss is associated with difficulties in understanding speech, especially under adverse listening conditions. In these situations, seeing the speaker improves speech intelligibility in hearing-impaired participants. On the neuronal level, previous research has shown cross-modal plastic reorganization in the auditory cortex following hearing loss leading to altered processing of auditory, visual and audio-visual information. However, how reduced auditory input effects audio-visual speech perception in hearing-impaired subjects is largely unknown. We here investigated the impact of mild to moderate age-related hearing loss on processing audio-visual speech using functional magnetic resonance imaging. Normal-hearing and hearing-impaired participants performed two audiovisual speech integration tasks: a sentence detection task inside the scanner and the McGurk illusion outside the scanner. Both tasks consisted of congruent and incongruent audio-visual conditions, as well as auditory-only and visual-only conditions. We found a significantly stronger McGurk illusion in the hearing-impaired participants, which indicates stronger audio-visual integration. Neurally, hearing loss was associated with an increased recruitment of frontal brain areas when processing incongruent audio-visual, auditory and also visual speech stimuli, which may reflect the increased effort to perform the task. Hearing loss modulated both the audio-visual integration strength measured with the McGurk illusion and brain activation in frontal areas in the sentence task, showing stronger integration and higher brain activation with increasing hearing loss. Incongruent compared to congruent audio-visual speech revealed an opposite brain activation pattern in left ventral postcentral gyrus in both groups, with higher activation in hearing-impaired participants in the incongruent condition. Our results indicate that already mild to moderate hearing loss impacts audio-visual speech processing accompanied by changes in brain activation particularly involving frontal areas. These changes are modulated by the extent of hearing loss.
C1 [Rosemann, Stephanie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Dept Med & Hlth Sci, Dept Psychol, Biol Psychol, Oldenburg, Germany.
   [Rosemann, Stephanie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
RP Rosemann, S (corresponding author), Carl von Ossietzky Univ Oldenburg, Dept Psychol, Biol Psychol, Ammerlander Herrstr 114, Oldenburg, Germany.
EM Stephanie.rosemann@uni-oldenburg.de
OI Rosemann, Stephanie/0000-0003-2598-0538
FU German Research Foundation (Deutsche Forschungsgemeinschaft, DFG;
   Cluster of Excellence DFG 1077 "Hearing4all")German Research Foundation
   (DFG); Neuroimaging Unit of the Carl von Ossietzky Universitat Oldenburg
   - German Research Foundation [3T MRI INST 184/152-1 FUGG]
FX This work was funded by the German Research Foundation (Deutsche
   Forschungsgemeinschaft, DFG; Cluster of Excellence DFG 1077
   "Hearing4all") and supported by the Neuroimaging Unit of the Carl von
   Ossietzky Universitat Oldenburg funded by grants from the German
   Research Foundation (3T MRI INST 184/152-1 FUGG).
CR Allman BL, 2009, P NATL ACAD SCI USA, V106, P5925, DOI 10.1073/pnas.0809483106
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Arehart KH, 2013, EAR HEARING, V34, P251, DOI 10.1097/AUD.0b013e318271aa5e
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Bedny M, 2011, P NATL ACAD SCI USA, V108, P4429, DOI 10.1073/pnas.1014818108
   Behroozmand R, 2015, NEUROIMAGE, V109, P418, DOI 10.1016/j.neuroimage.2015.01.040
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Benuzzi F, 2008, J NEUROSCI, V28, P923, DOI 10.1523/JNEUROSCI.4012-07.2008
   Berding G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128743
   Bishop CW, 2009, J COGNITIVE NEUROSCI, V21, P1790, DOI 10.1162/jocn.2009.21118
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Champoux F, 2009, NEUROPSYCHOLOGIA, V47, P17, DOI 10.1016/j.neuropsychologia.2008.08.028
   Chen L, 2016, CAN RESPIR J, V2016, DOI 10.1155/2016/9092871
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Driver J, 2008, NEURON, V57, P11, DOI 10.1016/j.neuron.2007.12.013
   Durston S, 2003, NEUROIMAGE, V20, P2135, DOI 10.1016/j.neuroimage.2003.08.004
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   Erickson LC, 2014, HUM BRAIN MAPP, V35, P5587, DOI 10.1002/hbm.22572
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Frtusova JB, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00490
   Gabrieli JDE, 1998, P NATL ACAD SCI USA, V95, P906, DOI 10.1073/pnas.95.3.906
   Geiser E, 2008, J COGNITIVE NEUROSCI, V20, P541, DOI 10.1162/jocn.2008.20029
   Grabski K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049117
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Harris KC, 2009, J NEUROSCI, V29, P6078, DOI 10.1523/JNEUROSCI.0412-09.2009
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   Hisanaga S, 2016, SCI REP-UK, V6, DOI 10.1038/srep35265
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Irwin J., 2017, LINGUIST COMPASS, V11, P77, DOI [10.1111/lnc3.12237, DOI 10.1111/LNC3.12237]
   Job A, 2012, BRAIN BEHAV, V2, P187, DOI 10.1002/brb3.21
   Job A, 2011, HUM BRAIN MAPP, V32, P744, DOI 10.1002/hbm.21063
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Kareken DA, 2004, NEUROIMAGE, V22, P456, DOI 10.1016/j.neuroimage.2004.01.008
   Kemmerer D, 2012, CORTEX, V48, P826, DOI 10.1016/j.cortex.2010.11.001
   Kim MB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148466
   Krick CM, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00049
   Lambertz N, 2005, COGNITIVE BRAIN RES, V25, P884, DOI 10.1016/j.cogbrainres.2005.09.010
   Lazard DS, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14872
   Lee HJ, 2007, BRAIN, V130, P2929, DOI 10.1093/brain/awm230
   Lee YS, 2016, HEARING RES, V333, P108, DOI 10.1016/j.heares.2015.12.008
   Lin FR, 2012, JAMA-J AM MED ASSOC, V307, P1147, DOI 10.1001/jama.2012.321
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lomber SG, 2010, NAT NEUROSCI, V13, P1421, DOI 10.1038/nn.2653
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Menon V, 2010, BRAIN STRUCT FUNCT, V214, P655, DOI 10.1007/s00429-010-0262-0
   Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758
   Meredith MA, 2012, NEUROSCIENCE, V214, P136, DOI 10.1016/j.neuroscience.2012.04.001
   Moradi S., 2016, COMP GATED AUDIO VIS, V20, P1, DOI [10.1177/2331216516653355, DOI 10.1177/2331216516653355]
   Moradi S, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514545406
   Musacchia G, 2009, EAR HEARING, V30, P505, DOI 10.1097/AUD.0b013e3181a7f5b7
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nee DE, 2007, COGN AFFECT BEHAV NE, V7, P1, DOI 10.3758/CABN.7.1.1
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Puschmann S, 2017, CORTEX, V86, P109, DOI 10.1016/j.cortex.2016.10.014
   Puschmann S, 2014, HEARING RES, V316, P28, DOI 10.1016/j.heares.2014.07.005
   Rettenbach R, 1999, J COGNITIVE NEUROSCI, V11, P560, DOI 10.1162/089892999563616
   Reuter-Lorenz PA, 2008, CURR DIR PSYCHOL SCI, V17, P177, DOI 10.1111/j.1467-8721.2008.00570.x
   Roberts KL, 2008, J COGNITIVE NEUROSCI, V20, P1063, DOI 10.1162/jocn.2008.20074
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, J SPEECH LANG HEAR R, V54, P705, DOI 10.1044/1092-4388(2010/09-0088)
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Schierholz I, 2015, HEARING RES, V328, P133, DOI 10.1016/j.heares.2015.08.009
   Schulte M., 2015, 18 JAHRESTAGUNG DTSC
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Song JJ, 2015, BRAIN STRUCT FUNCT, V220, P1109, DOI 10.1007/s00429-013-0704-6
   Sorqvist P, 2010, MEMORY, V18, P310, DOI 10.1080/09658211003601530
   Souza P, 2015, INT J AUDIOL, V54, P705, DOI 10.3109/14992027.2015.1043062
   Spielberg JM, 2015, P NATL ACAD SCI USA, V112, P10020, DOI 10.1073/pnas.1500048112
   Stevenson RA, 2018, J EXP PSYCHOL HUMAN, V44, P106, DOI 10.1037/xhp0000424
   Strelnikov K, 2015, EUR J NEUROSCI, V41, P677, DOI 10.1111/ejn.12827
   Stropahl M, 2017, NEUROIMAGE-CLIN, V16, P514, DOI 10.1016/j.nicl.2017.09.001
   Stropahl M, 2017, PSYCHON B REV, V24, P863, DOI 10.3758/s13423-016-1148-9
   Stropahl M, 2015, NEUROIMAGE, V121, P159, DOI 10.1016/j.neuroimage.2015.07.062
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Thiel CM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00473
   Tian X, 2016, CORTEX, V77, P1, DOI 10.1016/j.cortex.2016.01.002
   Tremblay C, 2010, RESTOR NEUROL NEUROS, V28, P283, DOI 10.3233/RNN-2010-0498
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Tyler LK, 2010, CEREB CORTEX, V20, P352, DOI 10.1093/cercor/bhp105
   Uslar VN, 2013, J ACOUST SOC AM, V134, P3039, DOI 10.1121/1.4818760
   Vaden KI, 2015, J NEUROSCI, V35, P3929, DOI 10.1523/JNEUROSCI.2908-14.2015
   Vaden KI, 2013, J NEUROSCI, V33, P18979, DOI 10.1523/JNEUROSCI.1417-13.2013
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   von Gablenz P, 2015, HNO, V63, P195, DOI 10.1007/s00106-014-2949-7
   Wagener K, 1999, Z AUDIOL, V38, P86
   Wagener K, 1999, Z AUDIOL, V38, P44
   Wagener K., 1999, Z AUDIOL, V38, P4
   WHO-World Health Organization, 2001, GRAD HEAR IMP
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   WINGFIELD A, 1995, J GERONTOL B-PSYCHOL, V50, pP257, DOI 10.1093/geronb/50B.5.P257
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
NR 110
TC 21
Z9 21
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD JUL 15
PY 2018
VL 175
BP 425
EP 437
DI 10.1016/j.neuroimage.2018.04.023
PG 13
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GG8LO
UT WOS:000432949000035
PM 29655940
DA 2021-02-24
ER

PT J
AU Nan, Y
   Liu, L
   Geiser, E
   Shu, H
   Gong, CC
   Dong, Q
   Gabrieli, JDE
   Desimone, R
AF Nan, Yun
   Liu, Li
   Geiser, Eveline
   Shu, Hua
   Gong, Chen Chen
   Dong, Qi
   Gabrieli, John D. E.
   Desimone, Robert
TI Piano training enhances the neural processing of pitch and improves
   speech perception in Mandarin-speaking children
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE music; piano; reading; education
ID EVENT-RELATED POTENTIALS; MISMATCH RESPONSES; LEXICAL TONE;
   AUDITORY-DISCRIMINATION; BRAIN PLASTICITY; LANGUAGE IMPAIRMENT; MUSIC;
   EXPERIENCE; ACQUISITION; NEGATIVITY
AB Musical training confers advantages in speech-sound processing, which could play an important role in early childhood education. To understand the mechanisms of this effect, we used event-related potential and behavioral measures in a longitudinal design. Seventy-four Mandarin-speaking children aged 4-5 y old were pseudorandomly assigned to piano training, reading training, or a no-contact control group. Six months of piano training improved behavioral auditory word discrimination in general as well as word discrimination based on vowels compared with the controls. The reading group yielded similar trends. However, the piano group demonstrated unique advantages over the reading and control groups in consonant-based word discrimination and in enhanced positive mismatch responses (pMMRs) to lexical tone and musical pitch changes. The improved word discrimination based on consonants correlated with the enhancements in musical pitch pMMRs among the children in the piano group. In contrast, all three groups improved equally on general cognitive measures, including tests of IQ, working memory, and attention. The results suggest strengthened common sound processing across domains as an important mechanism underlying the benefits of musical training on language processing. In addition, although we failed to find far-transfer effects of musical training to general cognition, the near-transfer effects to speech perception establish the potential for musical training to help children improve their language skills. Piano training was not inferior to reading training on direct tests of language function, and it even seemed superior to reading training in enhancing consonant discrimination.
C1 [Nan, Yun; Liu, Li; Shu, Hua; Dong, Qi] Beijing Normal Univ, McGovern Inst Brain Res, State Key Lab Cognit Neurosci & Learning, IDG, Beijing 100875, Peoples R China.
   [Geiser, Eveline; Gong, Chen Chen; Gabrieli, John D. E.; Desimone, Robert] MIT, McGovern Inst Brain Res, Cambridge, MA 02139 USA.
   [Geiser, Eveline] Univ Lausanne, Univ Hosp Ctr, Lab Invest Neurophysiol, Neuropsychol & Neurorehabilitat Serv, CH-1011 Lausanne, Switzerland.
   [Geiser, Eveline] Univ Lausanne, Univ Hosp Ctr, Lab Invest Neurophysiol, Radiodiagnost Serv, CH-1011 Lausanne, Switzerland.
   [Gabrieli, John D. E.] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA.
RP Nan, Y (corresponding author), Beijing Normal Univ, McGovern Inst Brain Res, State Key Lab Cognit Neurosci & Learning, IDG, Beijing 100875, Peoples R China.; Desimone, R (corresponding author), MIT, McGovern Inst Brain Res, Cambridge, MA 02139 USA.
EM nany@bnu.edu.cn; desimone@mit.edu
RI Gabrieli, John/AAJ-2869-2020
FU 973 ProgramNational Basic Research Program of China [2014CB846103];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31471066, 31521063, 31571155, 31221003]; 111
   ProjectMinistry of Education, China - 111 Project [B07008]; Beijing
   Municipal Science and Technology CommissionBeijing Municipal Science &
   Technology Commission [Z151100003915122]; InterDiscipline Research Funds
   of Beijing Normal University; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   [2017XTCX04, 2015KJJCB28]
FX This work was supported by 973 Program Grant 2014CB846103; National
   Natural Science Foundation of China Grants 31471066, 31521063, 31571155,
   and 31221003; 111 Project Grant B07008; Beijing Municipal Science and
   Technology Commission Grant Z151100003915122; the InterDiscipline
   Research Funds of Beijing Normal University; and Fundamental Research
   Funds for the Central Universities Grant 2017XTCX04 and 2015KJJCB28.
CR Anderson R. C., 2002, CHINESE CHILDRENS RE, P131, DOI DOI 10.1007/978-1-4615-0859-5_7
   Barnett SM, 2002, PSYCHOL BULL, V128, P612, DOI 10.1037//0033-2909.128.4.612
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bishop DVM, 2011, DEVELOPMENTAL SCI, V14, P402, DOI 10.1111/j.1467-7687.2010.00990.x
   Bishop DVM, 2010, J NEUROSCI, V30, P15578, DOI 10.1523/JNEUROSCI.2217-10.2010
   Blood AJ, 2001, P NATL ACAD SCI USA, V98, P11818, DOI 10.1073/pnas.191355898
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Conard NJ, 2009, NATURE, V460, P737, DOI 10.1038/nature08169
   Davids N, 2011, NEUROPSYCHOLOGIA, V49, P19, DOI 10.1016/j.neuropsychologia.2010.11.001
   Dege F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Gong Y. X., 1986, PSYCHOL SCI, V2, P23
   Halliday LF, 2014, J NEURODEV DISORD, V6, DOI 10.1186/1866-1955-6-21
   He C, 2009, EUR J NEUROSCI, V29, P861, DOI 10.1111/j.1460-9568.2009.06625.x
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Holdaway D., 1979, FDN LITERACY
   Hovel H, 2015, PEDIATR RES, V77, P570, DOI 10.1038/pr.2015.7
   Hua Z, 2000, J CHILD LANG, V27, P3, DOI 10.1017/S030500099900402X
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Kraus N, 2017, NEUROSCIENTIST, V23, P287, DOI 10.1177/1073858416653593
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Mahajan Y, 2015, NEUROSCI LETT, V587, P102, DOI 10.1016/j.neulet.2014.12.041
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Nan Y, 2013, HUM BRAIN MAPP, V34, P2045, DOI 10.1002/hbm.22046
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   Norman-Haignere S, 2015, NEURON, V88, P1281, DOI 10.1016/j.neuron.2015.11.035
   Patel A. D., 2008, MUSIC LANGUAGE BRAIN
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Penhune VB, 2011, CORTEX, V47, P1126, DOI 10.1016/j.cortex.2011.05.010
   Putkinen V, 2013, EUR J NEUROSCI, V37, P654, DOI 10.1111/ejn.12049
   Putkinen V, 2014, DEVELOPMENTAL SCI, V17, P282, DOI 10.1111/desc.12109
   Salimpoor VN, 2011, NAT NEUROSCI, V14, P257, DOI 10.1038/nn.2726
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   Searcy YM, 2004, AM J MENT RETARD, V109, P231, DOI 10.1352/0895-8017(2004)109<231:TRBAAI>2.0.CO;2
   SEMLITSCH HV, 1986, PSYCHOPHYSIOLOGY, V23, P695, DOI 10.1111/j.1469-8986.1986.tb00696.x
   Shafer VL, 2010, EAR HEARING, V31, P735, DOI 10.1097/AUD.0b013e3181e5d1a7
   Shestakova A, 2003, CLIN NEUROPHYSIOL, V114, P1507, DOI 10.1016/S1388-2457(03)00134-2
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   Storkel HL, 2009, J CHILD LANG, V36, P291, DOI 10.1017/S030500090800891X
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Tang W, 2016, NEUROPSYCHOLOGIA, V91, P247, DOI 10.1016/j.neuropsychologia.2016.08.003
   Tierney A, 2013, PROG BRAIN RES, V207, P209, DOI 10.1016/B978-0-444-63327-9.00008-4
   Tierney AT, 2015, P NATL ACAD SCI USA, V112, P10062, DOI 10.1073/pnas.1505114112
   Wan CY, 2010, NEUROSCIENTIST, V16, P566, DOI 10.1177/1073858410377805
   Weiss MW, 2015, J NEUROSCI, V35, P1687, DOI 10.1523/JNEUROSCI.3680-14.2015
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Zuk J, 2017, J EXP PSYCHOL GEN, V146, P495, DOI 10.1037/xge0000281
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 58
TC 17
Z9 19
U1 3
U2 37
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD JUL 10
PY 2018
VL 115
IS 28
BP E6630
EP E6639
DI 10.1073/pnas.1808412115
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GM3ZE
UT WOS:000438050900030
PM 29941577
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Choi, JE
   Seok, JM
   Ahn, J
   Ji, YS
   Lee, KM
   Hong, SH
   Choi, BO
   Moon, IJ
AF Choi, Ji Eun
   Seok, Jin Myoung
   Ahn, Jungmin
   Ji, Yoon Sang
   Lee, Kyung Myun
   Hong, Sung Hwa
   Choi, Byung-Ok
   Moon, Il Joon
TI Hidden hearing loss in patients with Charcot-Marie-Tooth disease type 1A
SO SCIENTIFIC REPORTS
LA English
DT Article
ID AUDITORY NEUROPATHY; MODULATION DETECTION; CHILDREN; DUPLICATION;
   MECHANISM; FAMILY; NOISE; SCORE
AB The aim of this study was to investigate hidden hearing loss in patients with Charcot-Marie-Tooth disease type 1 A (CMT1A), a common inherited demyelinating neuropathy. By using pure-tone audiometry, 43 patients with CMT1A and 60 healthy controls with normal sound detection abilities were enrolled. Speech perception in quiet and noisy backgrounds, spectral ripple discrimination (SRD), and temporal modulation detection (TMD) were measured. Although CMT1A patients and healthy controls had similar pure-tone thresholds and speech perception scores in a quiet background, CMT1A patients had significantly (p < 0.05) decreased speech perception ability in a noisy background compared to controls. CMT1A patients showed significantly decreased temporal and spectral resolution (both p < 0.05). Also, auditory temporal processing of CMT1A patients was correlated with speech perception in a noisy background (r = 0.447, p < 0.01) and median motor conduction velocity (r = 0.335, p < 0.05). Therefore, we assumed that demyelination of auditory nerve in CMT1A causes defective cochlear neurotransmission, which reduces temporal resolution and speech perception in a noisy background. Because the temporal resolution test was well correlated with the degree of demyelination in auditory and peripheral motor nerves, temporal resolution testing could be performed as an additional marker for CMT1A.
C1 [Choi, Ji Eun] Dankook Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Cheonan, South Korea.
   [Seok, Jin Myoung] Soonchunhyang Univ, Coll Med, Cheonan Hosp, Dept Neurol, Cheonan, South Korea.
   [Ahn, Jungmin; Moon, Il Joon] Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
   [Ji, Yoon Sang] Samsung Med Ctr, Hearing Res Lab, Chang Won, South Korea.
   [Lee, Kyung Myun] Korea Adv Inst Sci & Technol, Sch Humanities & Social Sci, Chang Won, South Korea.
   [Hong, Sung Hwa] Sungkyunkwan Univ, Sch Med, Samsung Changwon Hosp, Dept Otorhinolaryngol Head & Neck Surg, Chang Won, South Korea.
   [Choi, Byung-Ok] Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Neurol, Seoul, South Korea.
RP Moon, IJ (corresponding author), Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.; Choi, BO (corresponding author), Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Neurol, Seoul, South Korea.
EM bochoi77@hanmail.net; moonij@skku.edu
RI Choi, Ji Eun/I-5707-2015
OI Choi, Ji Eun/0000-0001-8105-813X
FU Korean Health Technology R&D Project, Ministry of Health Welfare
   [HI14C3484, HI15C1560, HI16C0426]; NRF - MSIP [NRF-2017R1A2B2004699];
   National Institute of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01NS094388];
   NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKEUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Neurological Disorders & Stroke (NINDS)
   [R01NS094388, R01NS094388, R01NS094388, R01NS094388, R01NS094388]
   Funding Source: NIH RePORTER
FX We would like to thank all subjects who participated in this study and
   our colleagues at Hearing Research Lab in Samsung Medical Center for
   performing the auditory tests. This work was supported by grants from
   the Korean Health Technology R&D Project, Ministry of Health & Welfare
   (HI14C3484, HI15C1560, and HI16C0426) and by NRF grants funded by MSIP
   (NRF-2017R1A2B2004699) and the National Institute of Health
   (R01NS094388).
CR Birouk N, 1997, BRAIN, V120, P813, DOI 10.1093/brain/120.5.813
   Brown W. F., 2002, PATHOPHYSIOLOGY COND, P56
   CARHART R, 1959, J SPEECH HEAR DISORD, V24, P330, DOI 10.1044/jshd.2404.330
   Chalak S, 2013, J CLIN DIAGN RES, V7, P2677, DOI 10.7860/JCDR/2013/6768.3730
   Choi JE, 2016, SCI REP-UK, V6, DOI 10.1038/srep35235
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   Haberlova J, 2010, PEDIATR NEUROL, V43, P407, DOI 10.1016/j.pediatrneurol.2010.06.004
   Kovach MJ, 2002, AM J MED GENET, V108, P295, DOI 10.1002/ajmg.10223
   Lee JH, 2007, J CLIN NEUROL, V3, P101, DOI 10.3988/jcn.2007.3.2.101
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Moon SK, 2008, INT J AUDIOL, V47, P375, DOI 10.1080/14992020701882457
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P2320, DOI 10.1121/1.417941
   Piscosquito G, 2015, EUR J NEUROL, V22, P1556, DOI 10.1111/ene.12783
   Plack CJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514550621
   RAGLAN E, 1987, ACTA OTO-LARYNGOL, V103, P50, DOI 10.3109/00016488709134697
   Rance G, 2004, EAR HEARING, V25, P34, DOI 10.1097/01.AUD.0000111259.59690.B8
   Rance G, 2012, NEUROSCIENCE, V226, P227, DOI 10.1016/j.neuroscience.2012.08.054
   Rance G, 2012, BRAIN, V135, P1412, DOI 10.1093/brain/aws085
   ROA BB, 1993, NEW ENGL J MED, V329, P96, DOI 10.1056/NEJM199307083290205
   Schaette R, 2011, J NEUROSCI, V31, P13452, DOI 10.1523/JNEUROSCI.2156-11.2011
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   Shim HJ, 2014, OTOL NEUROTOL, V35, P1345, DOI 10.1097/MAO.0000000000000323
   Shy ME, 2005, NEUROLOGY, V64, P1209, DOI 10.1212/01.WNL.0000156517.00615.A3
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   Starr A., 2001, PATHOPHYSIOLOGY AUDI, P76
   VENTRY IM, 1982, EAR HEARING, V3, P128, DOI 10.1097/00003446-198205000-00006
   Wan GQ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14487
   Wang S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129710
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Won JH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140920
   Won JH, 2011, J ACOUST SOC AM, V130, P376, DOI 10.1121/1.3592521
   Zeng FG, 1999, NEUROREPORT, V10, P3429, DOI 10.1097/00001756-199911080-00031
NR 32
TC 4
Z9 4
U1 0
U2 1
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUL 9
PY 2018
VL 8
AR 10335
DI 10.1038/s41598-018-28501-y
PG 8
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GM1LV
UT WOS:000437830200031
PM 29985472
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Blank, H
   Spangenberg, M
   Davis, MH
AF Blank, Helen
   Spangenberg, Marlene
   Davis, Matthew H.
TI Neural Prediction Errors Distinguish Perception and Misperception of
   Speech
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE fMRI; misperception; predictive coding; prior expectations;
   representational similarity analysis; speech perception
ID PRIOR KNOWLEDGE; HEARING-LOSS; RECOGNITION; REPRESENTATIONS;
   ORGANIZATION; INFORMATION; CORTEX; OSCILLATIONS; REPETITION; BRAIN
AB Humans use prior expectations to improve perception, especially of sensory signals that are degraded or ambiguous. However, if sensory input deviates from prior expectations, then correct perception depends on adjusting or rejecting prior expectations. Failure to adjust or reject the prior leads to perceptual illusions, especially if there is partial overlap (and thus partial mismatch) between expectations and input. With speech, "slips of the ear" occur when expectations lead to misperception. For instance, an entomologist might be more susceptible to hear "The ants are my friends" for "The answer, my friend" (in the Bob Dylan song Blowing in the Wind). Here, we contrast two mechanisms by which prior expectations may lead to misperception of degraded speech. First, clear representations of the common sounds in the prior and input (i.e., expected sounds) may lead to incorrect confirmation of the prior. Second, insufficient representations of sounds that deviate between prior and input (i.e., prediction errors) could lead to deception. We used crossmodal predictions from written words that partially match degraded speech to compare neural responses when male and female human listeners were deceived into accepting the prior or correctly reject it. Combined behavioral and multivariate representational similarity analysis of fMRI data show that veridical perception of degraded speech is signaled by representations of prediction error in the left superior temporal sulcus. Instead of using top-down processes to support perception of expected sensory input, our findings suggest that the strength of neural prediction error representations distinguishes correct perception and misperception.
C1 [Blank, Helen; Spangenberg, Marlene; Davis, Matthew H.] Univ Cambridge, Med Res Council, Cognit & Brain Sci Unit, Cambridge CB2 7E, England.
   [Blank, Helen] Univ Med Ctr Hamburg, Dept Syst Neurosci, Eppendorf Martinistr 52, D-20248 Hamburg, Germany.
   [Spangenberg, Marlene] Univ Oxford, Dept Expt Psychol, Oxford OX1 3PH, England.
RP Blank, H (corresponding author), Univ Med Ctr Hamburg, Dept Syst Neurosci, Eppendorf Martinistr 52, D-20248 Hamburg, Germany.
EM hblank@uke.de
OI , Helen/0000-0002-5824-0811; Davis, Matt/0000-0003-2239-0778;
   Spangenberg, Marlene/0000-0002-2549-3476
FU UK Medical Research CouncilUK Research & Innovation (UKRI)Medical
   Research Council UK (MRC) [RG91365/SUAG/008]; European Union Horizon
   2020 Programme (Marie Curie Fellowship) [703635]
FX This work was supported by the UK Medical Research Council (Grant
   RG91365/SUAG/008 to M.H.D.) and the European Union Horizon 2020
   Programme (Marie Curie Fellowship 703635 to H.B.). We thank Yaara Erez,
   Jenni Rodd, Ediz Sohoglu, and Arnold Ziesche for valuable comments on a
   previous version of this manuscript and Helen Lloyd and Steve Eldridge
   for assistance in radiography.
CR Aitchison L, 2017, CURR OPIN NEUROBIOL, V46, P219, DOI 10.1016/j.conb.2017.08.010
   Alderson-Day B, 2017, BRAIN, V140, P2475, DOI 10.1093/brain/awx206
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Billig AJ, 2013, CURR BIOL, V23, P1585, DOI 10.1016/j.cub.2013.06.042
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577
   Blank H, 2013, NEUROIMAGE, V65, P109, DOI 10.1016/j.neuroimage.2012.09.047
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Bond Z., 1999, SLIPS EAR ERRORS PER
   Bond ZS, 2005, BLACKW HBK LINGUIST, P290, DOI 10.1002/9780470757024.ch12
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Cusack R, 2015, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00090
   Dalton DS, 2003, GERONTOLOGIST, V43, P661, DOI 10.1093/geront/43.5.661
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Fletcher PC, 2009, NAT REV NEUROSCI, V10, P48, DOI 10.1038/nrn2536
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gregory R., 1997, EYE BRAIN PSYCHOL SE
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   Henson RNA, 2003, PROG NEUROBIOL, V70, P53, DOI 10.1016/S0301-0082(03)00086-8
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   Kok P, 2012, NEURON, V75, P265, DOI 10.1016/j.neuron.2012.04.034
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Misaki M, 2010, NEUROIMAGE, V53, P103, DOI 10.1016/j.neuroimage.2010.05.051
   Moore DR, 2009, NAT NEUROSCI, V12, P686, DOI 10.1038/nn.2326
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477
   Murray SO, 2004, NEURAL NETWORKS, V17, P695, DOI 10.1016/j.neunet.2004.03.010
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Nili H, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003553
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rogersa CS, 2015, J ACOUST SOC AM, V138, pEL26, DOI 10.1121/1.4922363
   Roth TN, 2011, EUR ARCH OTO-RHINO-L, V268, P1101, DOI 10.1007/s00405-011-1597-8
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Summerfield C, 2008, NAT NEUROSCI, V11, P1004, DOI 10.1038/nn.2163
   Teufel C, 2015, P NATL ACAD SCI USA, V112, P13401, DOI 10.1073/pnas.1503916112
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Zoefel B, 2017, LANG COGN NEUROSCI, V32, P910, DOI 10.1080/23273798.2016.1247970
NR 48
TC 4
Z9 4
U1 0
U2 5
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD JUL 4
PY 2018
VL 38
IS 27
BP 6076
EP 6089
DI 10.1523/JNEUROSCI.3258-17.2018
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA GM7NL
UT WOS:000438375200005
PM 29891730
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Wu, C
   Zheng, YJ
   Li, JH
   She, SL
   Peng, HJ
   Li, L
AF Wu, Chao
   Zheng, Yingjun
   Li, Juanhua
   She, Shenglin
   Peng, Hongjun
   Li, Liang
TI Cortical Gray Matter Loss, Augmented Vulnerability to Speech-on-Speech
   Masking, and Delusion in People With Schizophrenia
SO FRONTIERS IN PSYCHIATRY
LA English
DT Article
DE schizophrenia; speech perception; informational masking; delusion;
   gray-matter volume
ID PERCEIVED SPATIAL SEPARATION; PRESENTED LIPREADING CUES; SUPERIOR
   TEMPORAL GYRUS; VOXEL-BASED MORPHOMETRY; NEGATIVE SYNDROME SCALE;
   1ST-EPISODE SCHIZOPHRENIA; FUNCTIONAL CONNECTIVITY; INFORMATIONAL
   MASKING; THOUGHT-DISORDER; LISTENING CONDITIONS
AB People with schizophrenia exhibit impairments in target-speech recognition (TSR) against multiple-talker-induced informational speech masking. Up to date, the underlying neural mechanisms and its relationships with psychotic symptoms remain largely unknown. This study aimed to investigate whether the schizophrenia-associated TSR impairment contribute to certain psychotic symptoms by sharing underlying alternations in cortical gray-matter volume (GMV) with the psychotic symptoms. Participants with schizophrenia (N = 34) and their matched healthy controls (N = 29) were tested for TSR against a two-talker-speech masker. Psychotic symptoms of participants with schizophrenia were evaluated using the Positive and Negative Syndrome Scale. The regional GMV across various cortical regions was assessed using the voxel-based morphometry. The results of partial-correlation and mediation analyses showed that in participants with schizophrenia, the TSR was negatively correlated with the delusion severity, but positively with the GMV in the bilateral superior/middle temporal cortex, bilateral insular, left medial orbital frontal gyrus, left Rolandic operculum, left mid-cingulate cortex, left posterior fusiform, and left cerebellum. Moreover, the association between GMV and delusion was based on the mediating role played by the TSR performance. Thus, in people with schizophrenia, both delusions and the augmented vulnerability of TSR to informational masking are associated with each other and share the underlying cortical GMV reduction, suggesting that the origin of delusion in schizophrenia may be related to disorganized or limited informational processing (e.g., the incapability of adequately filtering information from multiple sources at the perceptual level). The TSR impairment can be a potential marker for predicting delusion severity.
C1 [Wu, Chao] Beijing Normal Univ, Fac Psychol, Beijing, Peoples R China.
   [Zheng, Yingjun; Li, Juanhua; She, Shenglin; Peng, Hongjun] Guangzhou Med Univ, Guangzhou Brain Hosp, Guangzhou, Guangdong, Peoples R China.
   [Li, Liang] Peking Univ, Beijing Key Lab Behav & Mental Hlth, Sch Psychol & Cognit Sci, Key Lab Machine Percept,Minist Educ, Beijing, Peoples R China.
   [Li, Liang] Capital Med Univ, Beijing Inst Brain Disorder, Beijing, Peoples R China.
RP Li, L (corresponding author), Peking Univ, Beijing Key Lab Behav & Mental Hlth, Sch Psychol & Cognit Sci, Key Lab Machine Percept,Minist Educ, Beijing, Peoples R China.; Li, L (corresponding author), Capital Med Univ, Beijing Inst Brain Disorder, Beijing, Peoples R China.
EM liangli@pku.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81601168, 81671334, 31771252]; China
   Postdoctoral Science Foundation Special Program [2016T90050]; Beijing
   Municipal Science & Tech CommissionBeijing Municipal Science &
   Technology Commission [Z161100002616017]
FX This work was supported by the National Natural Science Foundation of
   China (81601168, 81671334, 31771252), the China Postdoctoral Science
   Foundation Special Program (2016T90050), and the Beijing Municipal
   Science & Tech Commission (Z161100002616017).
CR Arnsten AFT, 2012, NEURON, V76, P223, DOI 10.1016/j.neuron.2012.08.038
   Asami T, 2012, NEUROIMAGE, V59, P986, DOI 10.1016/j.neuroimage.2011.08.066
   Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Blakemore SJ, 2003, NEUROPSYCHOLOGIA, V41, P1058, DOI 10.1016/S0028-3932(02)00313-5
   Braff DL, 1999, AM J PSYCHIAT, V156, P596
   Chambon V, 2008, BRAIN, V131, P962, DOI 10.1093/brain/awn032
   Douaud G, 2007, BRAIN, V130, P2375, DOI 10.1093/brain/awm184
   First M. B., 1996, STRUCTURED CLIN INTE
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Furth KE, 2013, FRONT CELL NEUROSCI, V7, DOI 10.3389/fncel.2013.00102
   Gong QY, 2016, AM J PSYCHIAT, V173, P232, DOI 10.1176/appi.ajp.2015.15050641
   Gottesman II, 2003, AM J PSYCHIAT, V160, P636, DOI 10.1176/appi.ajp.160.4.636
   GRILLON C, 1990, ARCH GEN PSYCHIAT, V47, P171
   Harvey PD, 1998, AM J PSYCHIAT, V155, P1080, DOI 10.1176/ajp.155.8.1080
   Heinz A, 2010, SCHIZOPHRENIA BULL, V36, P472, DOI 10.1093/schbul/sbq031
   Honea R, 2005, AM J PSYCHIAT, V162, P2233, DOI 10.1176/appi.ajp.162.12.2233
   Indefrey P, 2001, P NATL ACAD SCI USA, V98, P5933, DOI 10.1073/pnas.101118098
   Ischebeck AK, 2008, CEREB CORTEX, V18, P541, DOI 10.1093/cercor/bhm083
   Johnston PJ, 2010, SCHIZOPHRENIA BULL, V36, P680, DOI 10.1093/schbul/sbn136
   Kasai K, 2003, AM J PSYCHIAT, V160, P156, DOI 10.1176/appi.ajp.160.1.156
   KAY SR, 1987, SCHIZOPHRENIA BULL, V13, P261, DOI 10.1093/schbul/13.2.261
   Khan A, 2011, BMC PSYCHIATRY, V11, DOI 10.1186/1471-244X-11-178
   Kumari V, 2010, SCHIZOPHRENIA BULL, V36, P740, DOI 10.1093/schbul/sbn148
   LAWSON JS, 1964, BRIT J PSYCHIAT, V110, P375, DOI 10.1192/bjp.110.466.375
   Li JH, 2017, NEUROSCIENCE, V359, P248, DOI 10.1016/j.neuroscience.2017.06.043
   Lui S, 2009, AM J PSYCHIAT, V166, P196, DOI 10.1176/appi.ajp.2008.08020183
   Mass R, 2000, SCHIZOPHRENIA BULL, V26, P167, DOI 10.1093/oxfordjournals.schbul.a033437
   Mesulam MM, 2014, NAT REV NEUROL, V10, P554, DOI 10.1038/nrneurol.2014.159
   Moran ME, 2014, INT J DEV NEUROSCI, V32, P58, DOI 10.1016/j.ijdevneu.2013.05.010
   Nakamura M, 2008, BRAIN, V131, P180, DOI 10.1093/brain/awm265
   Nakamura M, 2007, BIOL PSYCHIAT, V62, P773, DOI 10.1016/j.biopsych.2007.03.030
   Oak JN, 2000, EUR J PHARMACOL, V405, P303, DOI 10.1016/S0014-2999(00)00562-8
   Opris I, 2014, BRAIN, V137, P1863, DOI 10.1093/brain/awt359
   Padmanabhan JL, 2015, SCHIZOPHRENIA BULL, V41, P154, DOI 10.1093/schbul/sbu075
   Palaniyappan L, 2012, J PSYCHIATR NEUROSCI, V37, P17, DOI 10.1503/jpn.100176
   Pankow A, 2016, SCHIZOPHRENIA BULL, V42, P67, DOI 10.1093/schbul/sbv098
   Pankow A, 2012, NEUROPSYCHOBIOLOGY, V66, P33, DOI 10.1159/000337132
   Preacher KJ, 2008, BEHAV RES METHODS, V40, P879, DOI 10.3758/BRM.40.3.879
   Qu TS, 2009, IEEE T AUDIO SPEECH, V17, P1124, DOI 10.1109/TASL.2009.2020532
   Rozycki M, 2018, SCHIZOPHRENIA BULL, V44, P1035, DOI 10.1093/schbul/sbx137
   Satterthwaite TD, 2016, JAMA PSYCHIAT, V73, P515, DOI 10.1001/jamapsychiatry.2015.3463
   Schacht JP, 2016, PHARMACOGENOMICS J, V16, P430, DOI 10.1038/tpj.2016.43
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Scott SK, 2013, HEARING RES, V303, P58, DOI 10.1016/j.heares.2013.05.001
   Scott SK, 2009, J ACOUST SOC AM, V125, P1737, DOI 10.1121/1.3050255
   Sigmundsson T, 2001, AM J PSYCHIAT, V158, P234, DOI 10.1176/appi.ajp.158.2.234
   Song J, 2015, NEUROPSYCH DIS TREAT, V11, DOI 10.2147/NDT.S80438
   Sugimori E, 2014, PSYCHOL SCI, V25, P403, DOI 10.1177/0956797613505776
   Sumner PJ, 2018, NEUROSCI BIOBEHAV R, V84, P299, DOI 10.1016/j.neubiorev.2017.08.017
   Suzuki M, 2005, BRAIN, V128, P2109, DOI 10.1093/brain/awh554
   Sweet RA, 2003, NEUROPSYCHOPHARMACOL, V28, P599, DOI 10.1038/sj.npp.1300120
   Voruganti LNP, 1997, CAN J PSYCHIAT, V42, P1066, DOI 10.1177/070674379704201008
   Wang D, 2015, TRANSL PSYCHIAT, V5, DOI 10.1038/tp.2015.69
   Wensing T, 2017, HUM BRAIN MAPP, V38, P4946, DOI 10.1002/hbm.23706
   Woods SW, 2003, J CLIN PSYCHIAT, V64, P663, DOI 10.4088/JCP.v64n0607
   Wright IC, 2000, AM J PSYCHIAT, V157, P16, DOI 10.1176/ajp.157.1.16
   Writed I, 1991, WRIT MATH SYST DOING
   Wu BJ, 2015, SCHIZOPHR RES, V169, P489, DOI 10.1016/j.schres.2015.09.011
   Wu C, 2017, PSYCHOL MED, V47, P837, DOI 10.1017/S0033291716002816
   Wu C, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00107
   Wu C, 2013, SCHIZOPHR RES, V150, P594, DOI 10.1016/j.schres.2013.08.017
   Wu C, 2013, J ACOUST SOC AM, V133, pEL281, DOI 10.1121/1.4794933
   Wu C, 2012, SCHIZOPHR RES, V134, P33, DOI 10.1016/j.schres.2011.09.019
   Wu XH, 2005, HEARING RES, V199, P1, DOI 10.1016/j.heares.2004.03.010
   Xie ZL, 2015, NEUROPSYCHOLOGIA, V67, P121, DOI 10.1016/j.neuropsychologia.2014.12.013
   Zheng Y, 2016, PSYCHOL MED, V46, P477, DOI 10.1017/S0033291715001828
NR 67
TC 1
Z9 1
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-0640
J9 FRONT PSYCHIATRY
JI Front. Psychiatry
PD JUL 4
PY 2018
VL 9
AR 287
DI 10.3389/fpsyt.2018.00287
PG 11
WC Psychiatry
SC Psychiatry
GA GL6LL
UT WOS:000437297500001
PM 30022955
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Stevenson, RA
   Segers, M
   Ncube, BL
   Black, KR
   Bebko, JM
   Ferber, S
   Barense, MD
AF Stevenson, Ryan A.
   Segers, Magali
   Ncube, Busisiwe L.
   Black, Karen R.
   Bebko, James M.
   Ferber, Susanne
   Barense, Morgan D.
TI The cascading influence of multisensory processing on speech perception
   in autism
SO AUTISM
LA English
DT Article
DE audiovisual; autism spectrum disorder; multisensory; sensory
   integration; speech perception; temporal processing
ID SENSORY OVER-RESPONSIVITY; SUPERIOR TEMPORAL SULCUS; AUDIOVISUAL SPEECH;
   SPECTRUM DISORDERS; YOUNG-CHILDREN; SYNCHRONY DETECTION; FUNCTIONING
   AUTISM; BINDING WINDOW; INTEGRATION; ANXIETY
AB It has been recently theorized that atypical sensory processing in autism relates to difficulties in social communication. Through a series of tasks concurrently assessing multisensory temporal processes, multisensory integration and speech perception in 76 children with and without autism, we provide the first behavioral evidence of such a link. Temporal processing abilities in children with autism contributed to impairments in speech perception. This relationship was significantly mediated by their abilities to integrate social information across auditory and visual modalities. These data describe the cascading impact of sensory abilities in autism, whereby temporal processing impacts multisensory information of social information, which, in turn, contributes to deficits in speech perception. These relationships were found to be specific to autism, specific to multisensory but not unisensory integration, and specific to the processing of social information.
C1 [Stevenson, Ryan A.] Univ Western Ontario, London, ON, Canada.
   [Segers, Magali; Ncube, Busisiwe L.; Bebko, James M.] York Univ, N York, ON, Canada.
   [Black, Karen R.; Ferber, Susanne; Barense, Morgan D.] Univ Toronto, Toronto, ON, Canada.
   [Ferber, Susanne; Barense, Morgan D.] Rotman Res Inst Baycrest, Toronto, ON, Canada.
RP Stevenson, RA (corresponding author), Univ Western Ontario, Nat Sci Ctr, Brain & Mind Inst, London, ON N6A 5B7, Canada.
EM rsteve28@uwo.ca
RI Black, Karen R./AAD-1427-2019
OI Black, Karen R./0000-0002-7601-3700
FU Social Sciences and Humanities Research Counsel of Canada [R5502A07];
   Natural Sciences and Engineering Research Counsel of Canada Discovery
   Grant; University of Western Ontario's Faculty Development Research
   Fund; Autism Research Training Program; Kay Sansom Scholarship from the
   Ontario Association on Developmental Disabilities, a University of
   Toronto Excellence Award-Natural Sciences and Engineering; University of
   Toronto Undergraduate Research Award; NSERC grantNatural Sciences and
   Engineering Research Council of Canada (NSERC) [216203-13]; Canadian
   Institutes of Health Research (CIHR) grantCanadian Institutes of Health
   Research (CIHR) [106436]; James S McDonnell Foundation; NSERC Discovery
   grantNatural Sciences and Engineering Research Council of Canada
   (NSERC); CIHR Emerging Team GrantCanadian Institutes of Health Research
   (CIHR)
FX R.A.S. was funded through the Social Sciences and Humanities Research
   Counsel of Canada Insight Grant R5502A07, the Natural Sciences and
   Engineering Research Counsel of Canada Discovery Grant, the University
   of Western Ontario's Faculty Development Research Fund, and the Autism
   Research Training Program (http://www.traininautism.com/). K.R.B. was
   funded through the Kay Sansom Scholarship from the Ontario Association
   on Developmental Disabilities, a University of Toronto Excellence
   Award-Natural Sciences and Engineering, and the University of Toronto
   Undergraduate Research Award. S.F. was funded through NSERC grant
   216203-13 and Canadian Institutes of Health Research (CIHR) grant
   106436. M. D. B. was funded through a Scholar Award from the James S
   McDonnell Foundation and an NSERC Discovery grant and accelerator
   supplement. J. M. B. was funded through a CIHR Emerging Team Grant.
CR American Psychiatric Association [APA], 2013, DIAGNOSTIC STAT MANU, V5th
   Autim Self Advocacy Network (ASAN), 2016, ID 1 LANG
   Baranek GT, 2006, J CHILD PSYCHOL PSYC, V47, P591, DOI 10.1111/j.1469-7610.2005.01546.x
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   BARONCOHEN S, 1989, BRIT J DISORD COMMUN, V24, P199
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Baum SH, 2015, JOVE-J VIS EXP, V98
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Black KR, LINKING ANXIET UNPUB
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brock J, 2002, DEV PSYCHOPATHOL, V14, P209, DOI 10.1017/S0954579402002018
   Burnette CP, 2005, J AUTISM DEV DISORD, V35, P63, DOI 10.1007/s10803-004-1035-5
   Calvert GA, 2004, J PHYSIOL-PARIS, V98, P191, DOI 10.1016/j.jphysparis.2004.03.018
   Cheung OS, 2008, J EXP PSYCHOL HUMAN, V34, P1327, DOI 10.1037/a0011752
   Collignon O, 2013, CORTEX, V49, P1704, DOI 10.1016/j.cortex.2012.06.001
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   Corbett BA, 2009, PSYCHIAT RES, V166, P210, DOI 10.1016/j.psychres.2008.02.005
   Dawson G, 2000, J AUTISM DEV DISORD, V30, P415, DOI 10.1023/A:1005547422749
   de Boer-Schellekens L, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00008
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   De Gelder B, 1991, EUROPEAN J COGNITIVE, V3, P69, DOI DOI 10.1080/09541449108406220
   DiLavore P. C., 2012, AUTISM DIAGNOSTIC OB
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Foxe JJ, 2013, CEREB CORTEX, V25, P98
   Fraser S, 2010, J SPEECH LANG HEAR R, V53, P18, DOI 10.1044/1092-4388(2009/08-0140)
   FRITH U, 1994, COGNITION, V50, P115, DOI 10.1016/0010-0277(94)90024-8
   Gauthier I, 2009, VISION RES, V49, P470, DOI 10.1016/j.visres.2008.12.007
   Glod M, 2015, REV J AUTISM DEV DIS, V2, P199, DOI 10.1007/s40489-015-0047-8
   Green SA, 2012, J AUTISM DEV DISORD, V42, P1112, DOI 10.1007/s10803-011-1361-3
   Green SA, 2010, J AUTISM DEV DISORD, V40, P1495, DOI 10.1007/s10803-010-1007-x
   Grossman RB, 2015, AUTISM RES, V8, P307, DOI 10.1002/aur.1447
   Grossman RB, 2009, J CHILD PSYCHOL PSYC, V50, P491, DOI 10.1111/j.1469-7610.2008.02002.x
   Happe F, 1999, TRENDS COGN SCI, V3, P216, DOI 10.1016/S1364-6613(99)01318-2
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Kanner L, 1943, NERV CHILD, V2, P217
   Kasari C, 1997, J AUTISM DEV DISORD, V27, P39, DOI 10.1023/A:1025869105208
   Keane BP, 2010, RES AUTISM SPECT DIS, V4, P276, DOI 10.1016/j.rasd.2009.09.015
   Keetels M, 2005, EXP BRAIN RES, V167, P635, DOI 10.1007/s00221-005-0067-1
   Kenny L, 2016, AUTISM, V20, P442, DOI 10.1177/1362361315588200
   Kern JK, 2007, AUTISM, V11, P123, DOI 10.1177/1362361307075702
   Kientz MA, 1997, AM J OCCUP THER, V51, P530, DOI 10.5014/ajot.51.7.530
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lachs L, 1998, RES SPOKEN LANGUAGE, V22, P377
   LECOUTEUR A, 1989, J AUTISM DEV DISORD, V19, P363, DOI 10.1007/BF02212936
   Lidstone J, 2014, RES AUTISM SPECT DIS, V8, P82, DOI 10.1016/j.rasd.2013.10.001
   Lord C, 1995, J CHILD PSYCHOL PSYC, V36, P1365, DOI 10.1111/j.1469-7610.1995.tb01669.x
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Macaluso E, 2004, NEUROIMAGE, V21, P725, DOI 10.1016/j.neuroimage.2003.09.049
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1992, EXP BRAIN RES, V88, P181, DOI 10.1007/BF02259139
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   MEREDITH MA, 1986, BRAIN RES, V365, P350
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P131
   Mottron L, 2003, J CHILD PSYCHOL PSYC, V44, P904, DOI 10.1111/1469-7610.00174
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   Nishimura M, 2008, VIS COGN, V16, P859, DOI 10.1080/13506280701538514
   Noel JP, 2017, AUTISM RES, V10, P121, DOI 10.1002/aur.1633
   ONeill M, 1997, J AUTISM DEV DISORD, V27, P283, DOI 10.1023/A:1025850431170
   OZONOFF S, 1991, J CHILD PSYCHOL PSYC, V32, P1081, DOI 10.1111/j.1469-7610.1991.tb00351.x
   Patten Elena, 2014, Autism Res Treat, V2014, P678346, DOI 10.1155/2014/678346
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pellicano E, 2012, TRENDS COGN SCI, V16, P504, DOI 10.1016/j.tics.2012.08.009
   Plaisted K, 1999, J CHILD PSYCHOL PSYC, V40, P733, DOI 10.1111/1469-7610.00489
   Powers AR, 2012, J NEUROSCI, V32, P6263, DOI 10.1523/JNEUROSCI.6138-11.2012
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Preacher KJ, 2004, BEHAV RES METH INS C, V36, P717, DOI 10.3758/BF03206553
   Quinto L, 2010, ATTEN PERCEPT PSYCHO, V72, P1450, DOI 10.3758/APP.72.6.1450
   Rogers SJ, 2003, J AUTISM DEV DISORD, V33, P631, DOI 10.1023/B:JADD.0000006000.38991.a7
   Royal DW, 2009, EXP BRAIN RES, V198, P127, DOI 10.1007/s00221-009-1772-y
   Samson F, 2006, J AUTISM DEV DISORD, V36, P65, DOI 10.1007/s10803-005-0043-4
   Schall S, 2009, EXP BRAIN RES, V198, P137, DOI 10.1007/s00221-009-1867-5
   Schlesinger JJ, 2014, ANESTH ANALG, V118, P1249, DOI 10.1213/ANE.0000000000000222
   Senkowski D, 2007, NEUROPSYCHOLOGIA, V45, P561, DOI 10.1016/j.neuropsychologia.2006.01.013
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Sheffert S.M., 1996, RES SPOKEN LANGUAGE, P578
   Sinclair J, 1999, WHY I DISLIKE PERSON
   Sinha P, 2014, P NATL ACAD SCI USA, V111, P15220, DOI 10.1073/pnas.1416797111
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   STEVENS SS, 1946, SCIENCE, V103, P677, DOI 10.1126/science.103.2684.677
   Stevenson RA, 2007, EXP BRAIN RES, V179, P85, DOI 10.1007/s00221-006-0770-6
   Stevenson RA, 2017, AUTISM RES, V10, P1280, DOI 10.1002/aur.1776
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2018, J AUTISM DEV DISORD, V48, P1382, DOI 10.1007/s10803-016-2711-y
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2014, BRAIN TOPOGR, V27, P707, DOI 10.1007/s10548-014-0365-7
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stevenson RA, 2013, EXP BRAIN RES, V227, P249, DOI 10.1007/s00221-013-3507-3
   Stevenson RA, 2013, EXP BRAIN RES, V225, P479, DOI 10.1007/s00221-012-3387-y
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Stevenson RA, 2012, BRAIN TOPOGR, V25, P308, DOI 10.1007/s10548-012-0220-7
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Stevenson RA, 2009, EXP BRAIN RES, V198, P183, DOI 10.1007/s00221-009-1783-8
   Stevenson RA, 2009, NEUROIMAGE, V44, P1210, DOI 10.1016/j.neuroimage.2008.09.034
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Talay-Ongan A., 2000, INT J DISABIL DEV ED, V47, P201, DOI DOI 10.1080/713671112
   Teunisse JP, 2003, BRAIN COGNITION, V52, P285, DOI 10.1016/S0278-2626(03)00042-3
   van Atteveldt NM, 2007, CEREB CORTEX, V17, P962, DOI 10.1093/cercor/bhl007
   van Boxtel JJA, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00217
   van der Smagt MJ, 2007, J AUTISM DEV DISORD, V37, P2014, DOI 10.1007/s10803-006-0346-0
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Wallace MT, 2004, EXP BRAIN RES, V158, P252, DOI 10.1007/s00221-004-1899-9
   Watling RL, 2001, AM J OCCUP THER, V55, P416, DOI 10.5014/ajot.55.4.416
   Wechsler D, 2011, WASI 2 WECHSLER ABBR
   Williams JHG, 2004, RES DEV DISABIL, V25, P559, DOI 10.1016/j.ridd.2004.01.008
   Wing L, 2002, MENT RETARD DEV D R, V8, P151, DOI 10.1002/mrdd.10029
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   YOUNG AW, 1987, PERCEPTION, V16, P747, DOI 10.1068/p160747
   Zampini M, 2005, PERCEPT PSYCHOPHYS, V67, P531, DOI 10.3758/BF03193329
NR 119
TC 33
Z9 33
U1 1
U2 27
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1362-3613
EI 1461-7005
J9 AUTISM
JI Autism
PD JUL
PY 2018
VL 22
IS 5
BP 609
EP 624
DI 10.1177/1362361317704413
PG 16
WC Psychology, Developmental
SC Psychology
GA GM9GR
UT WOS:000438555100010
PM 28506185
DA 2021-02-24
ER

PT J
AU Yu, LD
   Wang, SP
   Huang, D
   Wu, XY
   Zhang, Y
AF Yu, Luodi
   Wang, Suiping
   Huang, Dan
   Wu, Xueyuan
   Zhang, Yang
TI Role of inter-trial phase coherence in atypical auditory evoked
   potentials to speech and nonspeech stimuli in children with autism
SO CLINICAL NEUROPHYSIOLOGY
LA English
DT Article
DE Auditory processing; Speech perception; Auditory evoked potential;
   Inter-trial phase coherence; Autism
ID EVENT-RELATED POTENTIALS; SPECTRUM DISORDERS; CORTICAL OSCILLATIONS;
   MISMATCH NEGATIVITY; THETA OSCILLATIONS; GAMMA OSCILLATIONS;
   YOUNG-CHILDREN; HUMAN BRAIN; RESPONSES; LANGUAGE
AB Objective: This autism study investigated how inter-trial phase coherence (ITPC) drives abnormalities in auditory evoked potential (AEP) responses for speech and nonspeech stimuli.
   Methods: Auditory P1-N2 responses and ITPCs in the theta band (4-7 Hz) for pure tones and words were assessed with EEG data from 15 school-age children with autism and 16 age-matched typically developing (TD) controls.
   Results: The autism group showed enhanced PI and reduced N2 for both speech and nonspeech stimuli in comparison with the TD group. Group differences were also found with enhanced theta ITPC for PI followed by ITPC reduction for N2 in the autism group. The ITPC values were significant predictors of PI and N2 amplitudes in both groups.
   Conclusions: Abnormal trial-to-trial phase synchrony plays an important role in AEP atypicalities in children with autism. ITPC-driven enhancement as well as attenuation in different AEP components may coexist, depending on the stage of information processing.
   Significance: It is necessary to examine the time course of auditory evoked potentials and the corresponding inter-trial coherence of neural oscillatory activities to better understand hyper- and hypo- sensitive responses in autism, which has important implications for sensory based treatment. (C) 2018 International Federation of Clinical Neurophysiology. Published by Elsevier B.V. All rights reserved.
C1 [Yu, Luodi; Wang, Suiping] South China Normal Univ, Sch Psychol, Guangzhou 510631, Guangdong, Peoples R China.
   [Yu, Luodi; Zhang, Yang] Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
   [Huang, Dan; Wu, Xueyuan] Guangzhou Cana Sch, Guangzhou Rehabil & Res Ctr Children Autism, Guangzhou 510540, Guangdong, Peoples R China.
   [Zhang, Yang] Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN 55455 USA.
RP Wang, SP (corresponding author), South China Normal Univ, Sch Psychol, Guangzhou 510631, Guangdong, Peoples R China.; Zhang, Y (corresponding author), Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
EM wangsuiping@m.scnu.edu.cn; zhanglab@umn.edu
RI Zhang, Yang/Q-1780-2015
OI Zhang, Yang/0000-0001-6777-3487
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [NSFC 31571136]; Key Project of National Social Science
   Foundation of China [15AZD048]; Key Project of National Natural Science
   Foundation of Guangdong Province [2014A030311016]; NSFC overseas
   collaboration grant of the University of Minnesota [31728009]; Grand
   Challenges Exploratory Research Award of the University of
   MinnesotaUniversity of Minnesota System; CLA Brain Imaging Research
   Award of the University of Minnesota
FX This work was supported by grants from the Natural Science Foundation of
   China (NSFC 31571136), Key Project of National Social Science Foundation
   of China (15AZD048), Key Project of National Natural Science Foundation
   of Guangdong Province (2014A030311016) to SW, and grants from the NSFC
   overseas collaboration grant (31728009), the Grand Challenges
   Exploratory Research Award, and CLA Brain Imaging Research Award of the
   University of Minnesota to YZ. We thank the participants and their
   families for their support, and Yang Fan, Xiaoyun Wu, Kai Fan for their
   assistance.
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   American Psychiatric Association, 1994, DIAGN STAT MAN MENT, V4th
   Barry RJ, 2003, INT J PSYCHOPHYSIOL, V47, P187, DOI 10.1016/S0167-8760(02)00151-4
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bruneau N, 2003, INT J PSYCHOPHYSIOL, V51, P17, DOI 10.1016/S0167-8760(03)00149-1
   Buard I, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00742
   BUCHWALD JS, 1992, ELECTROEN CLIN NEURO, V84, P164, DOI 10.1016/0168-5597(92)90021-3
   Cardy JEO, 2008, INT J PSYCHOPHYSIOL, V68, P170, DOI 10.1016/j.ijpsycho.2007.10.015
   Ceponiene R, 1998, EVOKED POTENTIAL, V108, P345, DOI 10.1016/S0168-5597(97)00081-6
   Ceponiene R, 2008, CLIN NEUROPHYSIOL, V119, P1560, DOI 10.1016/j.clinph.2008.03.005
   Ceponiene R, 2005, PSYCHOPHYSIOLOGY, V42, P391, DOI 10.1111/j.1469-8986.2005.00305.x
   Ceponiene R, 2003, P NATL ACAD SCI USA, V100, P5567, DOI 10.1073/pnas.0835631100
   Ceponiene R, 2009, BRAIN LANG, V110, P107, DOI 10.1016/j.bandl.2009.04.003
   Ceponiene R, 2002, CLIN NEUROPHYSIOL, V113, P870, DOI 10.1016/S1388-2457(02)00078-0
   Ceponiene R, 2001, INT J NEUROSCI, V109, P245
   Cunningham J, 2000, EAR HEARING, V21, P554, DOI 10.1097/00003446-200012000-00003
   Dawson M, 2007, PSYCHOL SCI, V18, P657, DOI 10.1111/j.1467-9280.2007.01954.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Donkers FCL, 2015, J AUTISM DEV DISORD, V45, P506, DOI 10.1007/s10803-013-1948-y
   Edgar JC, 2015, MOL AUTISM, V6, DOI 10.1186/s13229-015-0065-5
   Edgar JC, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00417
   Edgar JC, 2015, J AUTISM DEV DISORD, V45, P395, DOI 10.1007/s10803-013-1904-x
   Edwards E, 2009, J NEUROPHYSIOL, V102, P377, DOI 10.1152/jn.90954.2008
   Eggermont JJ, 1997, ACTA OTO-LARYNGOL, V117, P161, DOI 10.3109/00016489709117760
   Ferri R, 2003, CLIN NEUROPHYSIOL, V114, P1671, DOI 10.1016/S1388-2457(03)00153-6
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Gage NM, 2003, NEUROREPORT, V14, P2047, DOI 10.1097/00001756-200311140-00008
   Gandal MJ, 2010, BIOL PSYCHIAT, V68, P1100, DOI 10.1016/j.biopsych.2010.09.031
   Gilliam J.E., 2006, GILLIAM AUTISM RATIN, V2nd ed
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gomot M, 2011, J AUTISM DEV DISORD, V41, P705, DOI 10.1007/s10803-010-1091-y
   Grunwald T, 2003, BIOL PSYCHIAT, V53, P511, DOI 10.1016/S0006-3223(02)01673-6
   Gueorguieva R, 2004, ARCH GEN PSYCHIAT, V61, P310, DOI 10.1001/archpsyc.61.3.310
   Haigh SM, 2018, EUR J NEUROSCI, V47, P602, DOI 10.1111/ejn.13601
   Hegarty JP, 2018, PROG NEURO-PSYCHOPH, V81, P153, DOI 10.1016/j.pnpbp.2017.09.016
   Huang D, 2018, EUR J NEUROSCI, V47, P662, DOI 10.1111/ejn.13657
   Isler JR, 2010, CLIN NEUROPHYSIOL, V121, P2035, DOI 10.1016/j.clinph.2010.05.004
   Jochaut D, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3339/fnhum.2015.00171, 10.3389/fnhum.2015.00171]
   Karhu J, 1997, NEUROREPORT, V8, P1327, DOI 10.1097/00001756-199704140-00002
   Khan S, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00255
   Klimesch W, 2007, NEUROSCI BIOBEHAV R, V31, P1003, DOI 10.1016/j.neubiorev.2007.03.005
   Koerner TK, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7030026
   Koerner TK, 2016, HEARING RES, V339, P40, DOI 10.1016/j.heares.2016.06.001
   Koerner TK, 2015, HEARING RES, V328, P113, DOI 10.1016/j.heares.2015.08.002
   Kujala T, 2013, NEUROSCI BIOBEHAV R, V37, P697, DOI 10.1016/j.neubiorev.2013.01.006
   Lepisto T, 2005, BRAIN RES, V1066, P147, DOI 10.1016/j.brainres.2005.10.052
   Lord C., 2001, AUTISM DIAGNOSTIC OB
   Malekmohammadi M, 2015, CEREB CORTEX, V25, P1618, DOI 10.1093/cercor/bht358
   Milne E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00051
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   Mottron L, 2017, EUR CHILD ADOLES PSY, V26, P815, DOI 10.1007/s00787-017-0955-5
   Mottron L, 2013, NEUROSCI BIOBEHAV R, V37, P209, DOI 10.1016/j.neubiorev.2012.11.016
   Orekhova EV, 2009, CLIN NEUROPHYSIOL, V120, P520, DOI 10.1016/j.clinph.2008.12.034
   Orekhova EV, 2008, NEUROSCI LETT, V434, P218, DOI 10.1016/j.neulet.2008.01.066
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Pratt H., 2011, OXFORD HDB EVENT REL, P89, DOI [10.1093/oxfordhb/9780195374148.013.0050, DOI 10.1093/OXFORDHB/9780195374148.013.0050]
   Radicevic Z, 2008, EXP BRAIN RES, V184, P529, DOI 10.1007/s00221-007-1119-5
   Raven J, 1998, OXFORD PSYCHOL
   Roberts TPL, 2013, BRAIN RES, V1537, P79, DOI 10.1016/j.brainres.2013.09.011
   Roberts TPL, 2010, AUTISM RES, V3, P8, DOI 10.1002/aur.111
   Roberts TPL, 2009, NEUROREPORT, V20, P1586, DOI 10.1097/WNR.0b013e3283306854
   Samson F, 2006, J AUTISM DEV DISORD, V36, P65, DOI 10.1007/s10803-005-0043-4
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Sharma A, 1997, EVOKED POTENTIAL, V104, P540, DOI 10.1016/S0168-5597(97)00050-6
   Simon DM, 2016, NEUROSCI BIOBEHAV R, V68, P848, DOI 10.1016/j.neubiorev.2016.07.016
   Smith IC, 2015, J AUTISM DEV DISORD, V45, P2541, DOI 10.1007/s10803-015-2423-8
   Sun LM, 2012, J NEUROSCI, V32, P9563, DOI 10.1523/JNEUROSCI.1073-12.2012
   van Noordt S, 2017, RES AUTISM SPECT DIS, V37, P1, DOI 10.1016/j.rasd.2017.01.011
   Wang XY, 2017, SCI REP-UK, V7, P1, DOI 10.1038/srep43254
   Wechsler D., 2003, WECHSLER INTELLIGENC
   Whitehouse AJO, 2008, DEVELOPMENTAL SCI, V11, P516, DOI 10.1111/j.1467-7687.2008.00697.x
   Winer JA, 2005, TRENDS NEUROSCI, V28, P255, DOI 10.1016/j.tins.2005.03.009
   You RS, 2017, RES DEV DISABIL, V61, P158, DOI 10.1016/j.ridd.2016.12.009
   Yu LD, 2015, J AUTISM DEV DISORD, V45, P3656, DOI 10.1007/s10803-015-2510-x
   Zhang Y, 2011, DEVELOPMENTAL SCI, V14, P566, DOI 10.1111/j.1467-7687.2010.01004.x
NR 77
TC 3
Z9 3
U1 5
U2 17
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 1388-2457
EI 1872-8952
J9 CLIN NEUROPHYSIOL
JI Clin. Neurophysiol.
PD JUL
PY 2018
VL 129
IS 7
BP 1374
EP 1382
DI 10.1016/j.clinph.2018.04.599
PG 9
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA GH2LL
UT WOS:000433233300006
PM 29729592
DA 2021-02-24
ER

PT J
AU Guevara-Rukoz, A
   Cristia, A
   Ludusan, B
   Thiolliere, R
   Martin, A
   Mazuka, R
   Dupoux, E
AF Guevara-Rukoz, Adriana
   Cristia, Alejandrina
   Ludusan, Bogdan
   Thiolliere, Roland
   Martin, Andrew
   Mazuka, Reiko
   Dupoux, Emmanuel
TI Are Words Easier to Learn From Infant- Than Adult-Directed Speech? A
   Quantitative Corpus-Based Investigation
SO COGNITIVE SCIENCE
LA English
DT Article
DE Speech perception; Psycholinguistics; Language development; Word
   learning; Infant-directed speech; Hyperspeech
ID TALKER VARIABILITY; MOTHERS SPEECH; CROSS-LANGUAGE; BABY TALK; JAPANESE;
   PERCEPTION; CATEGORIES; LEARNABILITY; RECOGNITION; ASSOCIATION
AB We investigate whether infant-directed speech (IDS) could facilitate word form learning when compared to adult-directed speech (ADS). To study this, we examine the distribution of word forms at two levels, acoustic and phonological, using a large database of spontaneous speech in Japanese. At the acoustic level we show that, as has been documented before for phonemes, the realizations of words are more variable and less discriminable in IDS than in ADS. At the phonological level, we find an effect in the opposite direction: The IDS lexicon contains more distinctive words (such as onomatopoeias) than the ADS counterpart. Combining the acoustic and phonological metrics together in a global discriminability score reveals that the bigger separation of lexical categories in the phonological space does not compensate for the opposite effect observed at the acoustic level. As a result, IDS word forms are still globally less discriminable than ADS word forms, even though the effect is numerically small. We discuss the implication of these findings for the view that the functional role of IDS is to improve language learnability.
C1 [Guevara-Rukoz, Adriana; Cristia, Alejandrina; Ludusan, Bogdan; Thiolliere, Roland; Dupoux, Emmanuel] CNRS, ENS, EHESS, PSL,Lab Sci Cognit & Psycholinguist, Paris, France.
   [Mazuka, Reiko] RIKEN, Brain Sci Inst, Lab Language Dev, Wako, Saitama, Japan.
   [Martin, Andrew] Konan Univ, Fac Letters, Dept English Literature & Language, Kobe, Hyogo, Japan.
   [Mazuka, Reiko] Duke Univ, Dept Psychol & Neurosci, Durham, NC 27706 USA.
RP Guevara-Rukoz, A (corresponding author), Lab Sci Cognit & Psycholinguist, 29 Rue Ulm, F-75005 Paris, France.
EM adriana.guevara.rukoz@ens.fr
RI Mazuka, Reiko/N-7400-2015; Cristia, Alejandrina/H-2768-2019
OI Cristia, Alejandrina/0000-0003-2979-4556
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [ERC-2011-AdG-295810 BOOTPHON]; Agence Nationale de la
   RechercheFrench National Research Agency (ANR)European Commission
   [ANR-2010-BLAN-1901-1 BOOTLANG, ANR-14-CE30-0003 MechELex,
   ANR-10-IDEX-0001-02 PSL*, ANR-10-LABX-0087 IEC]; James S. McDonnell
   Foundation; Fondation de FranceFondation de France; Japan Society for
   the Promotion of ScienceMinistry of Education, Culture, Sports, Science
   and Technology, Japan (MEXT)Japan Society for the Promotion of Science
   [24520446]; Canon Foundation in EuropeCanon Foundation
FX This work was supported by the European Research Council (Grant
   ERC-2011-AdG-295810 BOOTPHON), the Agence Nationale de la Recherche
   (Grants ANR-2010-BLAN-1901-1 BOOTLANG, ANR-14-CE30-0003 MechELex,
   ANR-10-IDEX-0001-02 PSL*, and ANR-10-LABX-0087 IEC), the James S.
   McDonnell Foundation, the Fondation de France, the Japan Society for the
   Promotion of Science (Kakenhi Grant 24520446, to A. Martin), and the
   Canon Foundation in Europe. We thank Bob McMurray and two anonymous
   reviewers for helpful feedback.
CR Antetomaso S., 2016, P 41 ANN BOST U C LA, P32
   Aslin RN, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P117
   Beckman ME, 2000, CHILD DEV, V71, P240, DOI 10.1111/1467-8624.00139
   Beckman ME, 2007, LAB PHONOLOGY, P241
   Benders T, 2013, INFANT BEHAV DEV, V36, P847, DOI 10.1016/j.infbeh.2013.09.001
   Bergmann C., 2016, P 38 ANN M COGN SCI, P1331
   Bergmann C, 2017, INTERSPEECH, P2103, DOI 10.21437/Interspeech.2017-1443
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   Cristia A, 2014, J CHILD LANG, V41, P913, DOI 10.1017/S0305000912000669
   Csibra G, 2006, ATTENTION PERFORM, P249
   Dautriche I, 2017, COGNITION, V163, P128, DOI 10.1016/j.cognition.2017.02.001
   de Boer B, 2003, ACOUST RES LETT ONL, V4, P129, DOI 10.1121/1.1613311
   Dilley LC, 2014, J CHILD LANG, V41, P155, DOI 10.1017/S0305000912000670
   Dupoux E, 2018, COGNITION, V173, P43, DOI 10.1016/j.cognition.2017.11.008
   Endress AD, 2007, COGNITION, V105, P577, DOI 10.1016/j.cognition.2006.12.014
   Endress AD, 2009, TRENDS COGN SCI, V13, P348, DOI 10.1016/j.tics.2009.05.005
   Englund KT, 2005, J PSYCHOLINGUIST RES, V34, P259, DOI 10.1007/s10936-005-3640-7
   Fais L, 2010, J CHILD LANG, V37, P319, DOI 10.1017/S0305000909009556
   Feldman N. H., 2009, P 31 ANN C COGN SCI, P2208
   FERGUSON CA, 1964, AM ANTHROPOL, V66, P103, DOI 10.1525/aa.1964.66.suppl_3.02a00060
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   FERNALD A, 1993, CHILD DEV, V64, P637
   Fernald A, 2000, PHONETICA, V57, P242, DOI 10.1159/000028477
   Fourtassi A., 2014, P 18 C COMP NAT LANG, P191
   Golinkoff RM, 2015, CURR DIR PSYCHOL SCI, V24, P339, DOI 10.1177/0963721415595345
   Greenwood CR, 2011, COMM DISORD Q, V32, P83, DOI 10.1177/1525740110367826
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296
   Hayashi A., 1999, P 14 INT C PHON SCI, P2177
   Henning A, 2005, INFANT BEHAV DEV, V28, P519, DOI 10.1016/j.infbeh.2005.06.001
   Iba M., 2000, LANGUAGE CULTURE J I, V4, P45
   Igarashi Y, 2013, J ACOUST SOC AM, V134, P1283, DOI 10.1121/1.4812755
   Imai M, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0298
   Imai M, 2008, COGNITION, V109, P54, DOI 10.1016/j.cognition.2008.07.015
   Johnson EK, 2013, J ACOUST SOC AM, V134, pEL534, DOI 10.1121/1.4828977
   JUSCZYK PW, 1990, COGNITIVE DEV, V5, P265, DOI 10.1016/0885-2014(90)90018-O
   Kalashnikova M, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170306
   Kantartzis K, 2011, COGNITIVE SCI, V35, P575, DOI 10.1111/j.1551-6709.2010.01169.x
   KAYE K, 1980, J CHILD LANG, V7, P489, DOI 10.1017/S0305000900002804
   Kirchhoff K, 2005, J ACOUST SOC AM, V117, P2238, DOI 10.1121/1.1869172
   KOHONEN T, 1988, COMPUTER, V21, P11, DOI 10.1109/2.28
   KUHL PK, 1993, J PHONETICS, V21, P125
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Lahey M, 2014, LANG LEARN DEV, V10, P308, DOI 10.1080/15475441.2013.860813
   Lake BM, 2009, IEEE T AUTON MENT DE, V1, P35, DOI 10.1109/TAMD.2009.2021703
   Larsen E, 2017, INTERSPEECH, P2198, DOI 10.21437/Interspeech.2017-937
   Leben William R., 1973, THESIS
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   Lindblom B., 1992, PHONOLOGICAL DEV MOD, V131, P163
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Ludusan B., 2015, C EMP METH NAT LANG, P93
   Ludusan B, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P178, DOI 10.18653/v1/P17-2028
   Ludusan B, 2016, J ACOUST SOC AM, V140, P1239, DOI 10.1121/1.4960576
   Martin A, 2016, COGNITION, V156, P52, DOI 10.1016/j.cognition.2016.07.015
   Martin A, 2015, PSYCHOL SCI, V26, P341, DOI 10.1177/0956797614562453
   Martin A, 2014, COGNITION, V132, P216, DOI 10.1016/j.cognition.2014.04.003
   Martin A, 2013, COGNITIVE SCI, V37, P103, DOI 10.1111/j.1551-6709.2012.01267.x
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Mazuka R., 2006, IEIC TECHNICAL REPOR, V106, P11
   Mazuka R., 2008, ORIGINS LANGUAGE, P39
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Miyazaki M, 2013, P 35 ANN C COGN SCI, P3080
   Miyazawa K, 2017, COGNITION, V166, P84, DOI 10.1016/j.cognition.2017.05.003
   Moore B.C., 2012, INTRO PSYCHOL HEARIN
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Newport E, 1977, TALKING CHILDREN LAN
   Ngon C, 2013, DEVELOPMENTAL SCI, V16, P24, DOI 10.1111/j.1467-7687.2012.01189.x
   Ota M, 2018, J CHILD LANG, V45, P204, DOI 10.1017/S0305000916000660
   Ota M, 2016, LANG LEARN DEV, V12, P380, DOI 10.1080/15475441.2016.1165100
   PAPOUSEK M, 1991, APPL PSYCHOLINGUIST, V12, P481, DOI 10.1017/S0142716400005889
   PHILLIPS JR, 1973, CHILD DEV, V44, P182
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   RATNER NB, 1984, J CHILD LANG, V11, P557, DOI 10.1017/S030500090000595X
   Reilly JS, 1996, J CHILD LANG, V23, P219, DOI 10.1017/S0305000900010163
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Ryalls BO, 1997, DEV PSYCHOL, V33, P441, DOI 10.1037/0012-1649.33.3.441
   Sagisaka Y., 1990, ICSLP90, P1089
   Saji N, 2013, ONOMATOPE KENKYU NO, P151
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Schatz T, 2013, INTERSPEECH 2013, P1781
   Schatz T., 2016, THESIS
   Soderstrom M, 2007, DEV REV, V27, P501, DOI 10.1016/j.dr.2007.06.002
   Soderstrom M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080646
   Trueswell JC, 2016, COGNITION, V148, P117, DOI 10.1016/j.cognition.2015.11.002
   Tsuji S, 2014, J CHILD LANG, V41, P1276, DOI 10.1017/S0305000913000469
   Uther M, 2007, SPEECH COMMUN, V49, P2, DOI 10.1016/j.specom.2006.10.003
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Varadarajan B., 2008, P 46 ANN M ASS COMP, P165, DOI DOI 10.3115/1557690.1557736
   Versteegh M, 2016, PROCEDIA COMPUT SCI, V81, P67, DOI 10.1016/j.procs.2016.04.031
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
NR 94
TC 3
Z9 3
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD JUL
PY 2018
VL 42
IS 5
BP 1586
EP 1617
DI 10.1111/cogs.12616
PG 32
WC Psychology, Experimental
SC Psychology
GA GN9HH
UT WOS:000439502700007
PM 29851142
OA Bronze
DA 2021-02-24
ER

PT J
AU Alain, C
   Du, Y
   Bernstein, LJ
   Barten, T
   Banai, K
AF Alain, Claude
   Du, Yi
   Bernstein, Lori J.
   Barten, Thijs
   Banai, Karen
TI Listening under difficult conditions: An activation likelihood
   estimation meta-analysis
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE auditory; listening effort; prefrontal cortex; speech
ID SPOKEN LANGUAGE COMPREHENSION; POSITRON-EMISSION-TOMOGRAPHY; SOUND
   OBJECT REPRESENTATIONS; INFERIOR FRONTAL-CORTEX; HUMAN AUDITORY-SYSTEM;
   OLDER-ADULTS EXPEND; EVENT-RELATED FMRI; SPEECH-PERCEPTION; SEMANTIC
   AMBIGUITY; WORKING-MEMORY
AB The brain networks supporting speech identification and comprehension under difficult listening conditions are not well specified. The networks hypothesized to underlie effortful listening include regions responsible for executive control. We conducted meta-analyses of auditory neuroimaging studies to determine whether a common activation pattern of the frontal lobe supports effortful listening under different speech manipulations. Fifty-three functional neuroimaging studies investigating speech perception were divided into three independent Activation Likelihood Estimate analyses based on the type of speech manipulation paradigm used: Speech-in-noise (SIN, 16 studies, involving 224 participants); spectrally degraded speech using filtering techniques (15 studies involving 270 participants); and linguistic complexity (i.e., levels of syntactic, lexical and semantic intricacy/density, 22 studies, involving 348 participants). Meta-analysis of the SIN studies revealed higher effort was associated with activation in left inferior frontal gyrus (IFG), left inferior parietal lobule, and right insula. Studies using spectrally degraded speech demonstrated increased activation of the insula bilaterally and the left superior temporal gyrus (STG). Studies manipulating linguistic complexity showed activation in the left IFG, right middle frontal gyrus, left middle temporal gyrus and bilateral STG. Planned contrasts revealed left IFG activation in linguistic complexity studies, which differed from activation patterns observed in SIN or spectral degradation studies. Although there were no significant overlap in prefrontal activation across these three speech manipulation paradigms, SIN and spectral degradation showed overlapping regions in left and right insula. These findings provide evidence that there is regional specialization within the left IFG and differential executive networks underlie effortful listening.
C1 [Alain, Claude; Barten, Thijs] Baycrest Hlth Ctr, Rotman Res Inst, Toronto, ON, Canada.
   [Alain, Claude] Univ Toronto, Dept Psychol, Toronto, ON, Canada.
   [Du, Yi] Chinese Acad Sci, Inst Psychol, CAS Key Lab Behav Sci, Beijing, Peoples R China.
   [Bernstein, Lori J.] Univ Hlth Network, Princess Margaret Canc Ctr, Dept Support Care, Toronto, ON, Canada.
   [Bernstein, Lori J.] Univ Toronto, Dept Psychiat, Toronto, ON, Canada.
   [Banai, Karen] Univ Haifa, Dept Commun Sci & Disorders, Haifa, Israel.
RP Alain, C (corresponding author), Rotman Res Inst Baycrest, 3560 Bathurst St, Toronto, ON M6A 2E1, Canada.
EM calain@research.baycrest.org
RI Banai, Karen/J-1448-2019; Barten, Thijs/AAD-4184-2019; Du,
   Yi/R-3858-2016
OI Banai, Karen/0000-0002-2990-0470; Bernstein, Lori/0000-0002-2479-3223
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP 106619]; Natural Sciences and Engineering Research
   Council of Canada (NSERC)Natural Sciences and Engineering Research
   Council of Canada (NSERC)
FX This research was supported by grants from the Canadian Institutes of
   Health Research (MOP 106619) and the Natural Sciences and Engineering
   Research Council of Canada (NSERC) to CA.
CR Adank P, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00558
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Adank P, 2012, NEUROPSYCHOLOGIA, V50, P77, DOI 10.1016/j.neuropsychologia.2011.10.024
   Alain C, 2001, P NATL ACAD SCI USA, V98, P12301, DOI 10.1073/pnas.211209098
   Alain C, 2005, J COGNITIVE NEUROSCI, V17, P811, DOI 10.1162/0898929053747621
   Alain C, 2004, PSYCHOL AGING, V19, P125, DOI 10.1037/0882-7974.19.1.125
   Alain C, 2008, J COGNITIVE NEUROSCI, V20, P285, DOI 10.1162/jocn.2008.20014
   Alain C, 2008, CURR OPIN OTOLARYNGO, V16, P485, DOI 10.1097/MOO.0b013e32830e2096
   Andrews G, 2006, MEM COGNITION, V34, P1325, DOI 10.3758/BF03193275
   Backer KC, 2015, J NEUROSCI, V35, P1307, DOI 10.1523/JNEUROSCI.1487-14.2015
   Backer KC, 2014, PSYCHOL RES-PSYCH FO, V78, P439, DOI 10.1007/s00426-013-0531-7
   Backer KC, 2012, J EXP PSYCHOL HUMAN, V38, P1554, DOI 10.1037/a0027858
   Badre D, 2005, NEURON, V47, P907, DOI 10.1016/j.neuron.2005.07.023
   Badre D, 2008, TRENDS COGN SCI, V12, P193, DOI 10.1016/j.tics.2008.02.004
   Bee N. S., 2014, J SAINS KESIHAT MALA, V12, P23
   Bekinschtein TA, 2011, J NEUROSCI, V31, P9665, DOI 10.1523/JNEUROSCI.5058-10.2011
   Bhargava P, 2012, J ACOUST SOC AM, V131, pEL87, DOI 10.1121/1.3670000
   Bilenko NY, 2009, J COGNITIVE NEUROSCI, V21, P960, DOI 10.1162/jocn.2009.21073
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Buchsbaum B, 2005, BRAIN LANG, V95, P265, DOI 10.1016/j.bandl.2005.01.009
   Buchweitz A, 2014, BRAIN LANG, V139, P49, DOI 10.1016/j.bandl.2014.09.010
   Cabeza R, 2002, NEUROIMAGE, V17, P1394, DOI 10.1006/nimg.2002.1280
   Caplan D, 1999, NEUROIMAGE, V9, P343, DOI 10.1006/nimg.1998.0412
   Cox RW, 2012, NEUROIMAGE, V62, P743, DOI 10.1016/j.neuroimage.2011.08.056
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Davis MH, 2007, P NATL ACAD SCI USA, V104, P16032, DOI 10.1073/pnas.0701309104
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Davis MH, 2003, J NEUROSCI, V23, P3423
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Eckert MA, 2008, JARO-J ASSOC RES OTO, V9, P252, DOI 10.1007/s10162-008-0113-3
   Eckert MA, 2009, HUM BRAIN MAPP, V30, P2530, DOI 10.1002/hbm.20688
   Eickhoff SB, 2017, HUM BRAIN MAPP, V38, P7, DOI 10.1002/hbm.23342
   Eickhoff SB, 2016, NEUROIMAGE, V137, P70, DOI 10.1016/j.neuroimage.2016.04.072
   Eickhoff SB, 2012, NEUROIMAGE, V59, P2349, DOI 10.1016/j.neuroimage.2011.09.017
   Eickhoff SB, 2009, HUM BRAIN MAPP, V30, P2907, DOI 10.1002/hbm.20718
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   Evans S, 2016, J COGNITIVE NEUROSCI, V28, P483, DOI 10.1162/jocn_a_00913
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Friederici AD, 2006, CEREB CORTEX, V16, P1709, DOI 10.1093/cercor/bhj106
   Friederici AD, 2010, HUM BRAIN MAPP, V31, P448, DOI 10.1002/hbm.20878
   Gosselin PA, 2011, INT J AUDIOL, V50, P786, DOI 10.3109/14992027.2011.599870
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   Grady CL, 2008, CEREB CORTEX, V18, P189, DOI 10.1093/cercor/bhm045
   Grindrod CM, 2008, BRAIN RES, V1229, P167, DOI 10.1016/j.brainres.2008.07.017
   Guediche S, 2013, J COGNITIVE NEUROSCI, V25, P706, DOI 10.1162/jocn_a_00351
   Guerreiro MJS, 2016, J NEUROSCI, V36, P1620, DOI 10.1523/JNEUROSCI.2559-15.2016
   Herrmann B, 2012, HUM BRAIN MAPP, V33, P584, DOI 10.1002/hbm.21235
   Hervais-Adelman A, 2014, BRAIN LANG, V132, P1, DOI 10.1016/j.bandl.2014.01.009
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   Hesling I, 2005, NEUROIMAGE, V24, P937, DOI 10.1016/j.neuroimage.2004.11.003
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   Kahneman D., 1973, ATTENTION EFFORT
   Koelewijn T, 2012, EAR HEARING, V33, P291, DOI 10.1097/AUD.0b013e3182310019
   Kuchinsky SE, 2016, EXP AGING RES, V42, P64, DOI 10.1080/0361073X.2016.1108712
   Kuhn S, 2013, SOC COGN AFFECT NEUR, V8, P688, DOI 10.1093/scan/nss047
   Kyong JS, 2014, J COGNITIVE NEUROSCI, V26, P1748, DOI 10.1162/jocn_a_00583
   Lancaster JL, 2007, HUM BRAIN MAPP, V28, P1194, DOI 10.1002/hbm.20345
   Lee YS, 2016, HEARING RES, V333, P108, DOI 10.1016/j.heares.2015.12.008
   Lopes TM, 2016, NEUROPSYCHOLOGIA, V81, P140, DOI 10.1016/j.neuropsychologia.2015.12.020
   Love T, 2006, CORTEX, V42, P577, DOI 10.1016/S0010-9452(08)70396-4
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Meltzer JA, 2010, CEREB CORTEX, V20, P1853, DOI 10.1093/cercor/bhp249
   Merrill J, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00076
   Meyer M, 2004, BRAIN LANG, V89, P277, DOI 10.1016/S0093-934X(03)00350-X
   Meyer M, 2002, HUM BRAIN MAPP, V17, P73, DOI 10.1002/hbm.10042
   Nichols T, 2005, NEUROIMAGE, V25, P653, DOI 10.1016/j.neuroimage.2004.12.005
   Obleser J, 2011, NEUROIMAGE, V56, P2310, DOI 10.1016/j.neuroimage.2011.03.035
   Peelle JE, 2004, BRAIN LANG, V91, P315, DOI 10.1016/j.bandl.2004.05.007
   Peelle JE, 2010, NEUROIMAGE, V52, P1410, DOI 10.1016/j.neuroimage.2010.05.015
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rissman J, 2003, J COGNITIVE NEUROSCI, V15, P1160, DOI 10.1162/089892903322598120
   Rodd JM, 2015, BRAIN LANG, V141, P89, DOI 10.1016/j.bandl.2014.11.012
   Rodd JM, 2010, BRAIN LANG, V115, P182, DOI 10.1016/j.bandl.2010.07.005
   Rodd JM, 2010, NEUROPSYCHOLOGIA, V48, P1324, DOI 10.1016/j.neuropsychologia.2009.12.035
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Ronnberg J, 2016, INT J AUDIOL, V55, P623, DOI 10.1080/14992027.2016.1219775
   Ruff I, 2008, BRAIN LANG, V105, P41, DOI 10.1016/j.bandl.2008.01.003
   Salvi RJ, 2002, HEARING RES, V170, P96, DOI 10.1016/S0378-5955(02)00386-6
   Samson Y, 2001, REV NEUROL-FRANCE, V157, P837
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Scott SK, 2006, J ACOUST SOC AM, V120, P1075, DOI 10.1121/1.2216725
   Sehm B, 2013, J NEUROSCI, V33, P15868, DOI 10.1523/JNEUROSCI.5466-12.2013
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Sequeira SD, 2010, LATERALITY, V15, P577, DOI 10.1080/13576500903045082
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sharp DJ, 2010, HUM BRAIN MAPP, V31, P365, DOI 10.1002/hbm.20871
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Takeichi H, 2010, NEUROIMAGE, V49, P2697, DOI 10.1016/j.neuroimage.2009.10.063
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Tuennerhoff J, 2016, NEUROIMAGE, V124, P641, DOI 10.1016/j.neuroimage.2015.09.004
   Turkeltaub PE, 2012, HUM BRAIN MAPP, V33, P1, DOI 10.1002/hbm.21186
   Tyler LK, 2011, BRAIN, V134, P415, DOI 10.1093/brain/awq369
   Vaden KI, 2015, J NEUROSCI, V35, P3929, DOI 10.1523/JNEUROSCI.2908-14.2015
   Vaden KI, 2013, J NEUROSCI, V33, P18979, DOI 10.1523/JNEUROSCI.1417-13.2013
   Vaden KI, 2011, NEUROPSYCHOLOGIA, V49, P3563, DOI 10.1016/j.neuropsychologia.2011.09.008
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Vitello S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00530
   Westbrook A, 2015, COGN AFFECT BEHAV NE, V15, P395, DOI 10.3758/s13415-015-0334-y
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035
   Wong PCM, 2008, J SPEECH LANG HEAR R, V51, P1026, DOI 10.1044/1092-4388(2008/075)
   Wong PCM, 2009, ANN NY ACAD SCI, V1169, P157, DOI 10.1111/j.1749-6632.2009.04548.x
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Wright BA, 2010, J NEUROSCI, V30, P11635, DOI 10.1523/JNEUROSCI.1441-10.2010
   Xia MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068910
   Zekveld AA, 2014, NEUROIMAGE, V101, P76, DOI 10.1016/j.neuroimage.2014.06.069
   Zekveld AA, 2012, BRAIN LANG, V122, P103, DOI 10.1016/j.bandl.2012.05.006
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
NR 116
TC 18
Z9 18
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD JUL
PY 2018
VL 39
IS 7
BP 2695
EP 2709
DI 10.1002/hbm.24031
PG 15
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GL9TM
UT WOS:000437682100001
PM 29536592
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Bergmann, C
   Cristia, A
AF Bergmann, Christina
   Cristia, Alejandrina
TI Environmental Influences on Infants' Native Vowel Discrimination: The
   Case of Talker Number in Daily Life
SO INFANCY
LA English
DT Article
ID SPEECH-PERCEPTION; 2-MONTH-OLD INFANTS; LANGUAGE INPUT; INFORMATION;
   ACQUISITION; WORDS; RECOGNITION; VARIABILITY; SENSITIVITY; CATEGORIES
AB Both quality and quantity of speech from the primary caregiver have been found to impact language development. A third aspect of the input has been largely ignored: the number of talkers who provide input. Some infants spend most of their waking time with only one person; others hear many different talkers. Even if the very same words are spoken the same number of times, the pronunciations can be more variable when several talkers pronounce them. Is language acquisition affected by the number of people who provide input? To shed light on the possible link between how many people provide input in daily life and infants' native vowel discrimination, three age groups were tested: 4-month-olds (before attunement to native vowels), 6-month-olds (at the cusp of native vowel attunement) and 12-month-olds (well attuned to the native vowel system). No relationship was found between talker number and native vowel discrimination skills in 4- and 6-month-olds, who are overall able to discriminate the vowel contrast. At 12months, we observe a small positive relationship, but further analyses reveal that the data are also compatible with the null hypothesis of no relationship. Implications in the context of infant language acquisition and cognitive development are discussed.
C1 [Bergmann, Christina; Cristia, Alejandrina] PSL Res Univ, CNRS, EHESS, LSCP,Dept Etud Cognit,ENS, Paris, France.
   [Bergmann, Christina] Max Planck Inst Psycholinguist, Language Dev Dept, POB 310, NL-6500 AH Nijmegen, Netherlands.
RP Bergmann, C (corresponding author), Max Planck Inst Psycholinguist, Language Dev Dept, POB 310, NL-6500 AH Nijmegen, Netherlands.
EM chbergma@gmail.com
RI Bergmann, Christina/J-2765-2014; Cristia, Alejandrina/H-2768-2019
OI Bergmann, Christina/0000-0003-2656-9070; Cristia,
   Alejandrina/0000-0003-2979-4556
FU Fondation Pierre-Gilles de Gennes; H2020 European Research Council
   [Marie Skl odowska-Curie grant] [660911]; Agence Nationale de la
   RechercheFrench National Research Agency (ANR)European Commission
   [ANR-2010-BLAN-1901-1 BOOTLANG, ANR-14-CE30-0003 MechELex,
   ANR-10-IDEX-0001-02 PSL*, ANR-10-LABX-0087 IEC]; Fondation de
   FranceFondation de France
FX The present work was supported by the Fondation Pierre-Gilles de Gennes,
   the H2020 European Research Council [Marie Skl odowska-Curie grant No
   660911; and E-2011-AdG 295810 BOOTPHON], the Agence Nationale de la
   Recherche [ANR-2010-BLAN-1901-1 BOOTLANG, ANR-14-CE30-0003 MechELex,
   ANR-10-IDEX-0001-02 PSL*, ANR-10-LABX-0087 IEC], and the Fondation de
   France. The funding agencies had no role in study design; the
   collection, analysis, and interpretation of data; the writing of the
   report; and the decision to submit the article for publication.
CR Altvater-Mackensen N, 2015, CHILD DEV, V86, P362, DOI 10.1111/cdev.12320
   Bergelson E., WHAT DO N AM B UNPUB
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Bergmann C., 2016, P 38 ANN M COGN SCI, P1331
   Bergmann C., 2015, INDIVIDUAL DIFFERENC, V3, P57
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Cristia A, 2016, INFANCY, V21, P648, DOI 10.1111/infa.12127
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Cristia A, 2011, J ACOUST SOC AM, V129, P3271, DOI 10.1121/1.3562562
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Dehaene-Lambertz G, 2001, NEUROREPORT, V12, P3155, DOI 10.1097/00001756-200110080-00034
   Elsner M., 2013, P C EMP METH NAT LAN, P42
   Fagan JF, 2007, INTELLIGENCE, V35, P225, DOI 10.1016/j.intell.2006.07.007
   Feldman NH, 2013, PSYCHOL REV, V120, P751, DOI 10.1037/a0034245
   Fox J., 2011, R COMPANION APPL REG
   Gendrot C., 2005, VARIATIONS, V2, P2
   Gogate LJ, 2009, J EXP PSYCHOL HUMAN, V35, P508, DOI 10.1037/a0013623
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Houston DM, 2007, INFANCY, V12, P119, DOI 10.1111/j.1532-7078.2007.tb00237.x
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   HUTTENLOCHER J, 1991, DEV PSYCHOL, V27, P236, DOI 10.1037/0012-1649.27.2.236
   JASP Team, 2016, JASP VERS 0 7 5 5
   JUSCZYK PW, 1992, COGNITION, V43, P253, DOI 10.1016/0010-0277(92)90014-9
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Koorathota S., 2016, INT C INF STUD
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   KUHL PK, 1979, J ACOUST SOC AM, V66, P1668, DOI 10.1121/1.383639
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   MANDEL DR, 1995, PSYCHOL SCI, V6, P314, DOI 10.1111/j.1467-9280.1995.tb00517.x
   Mani N, 2008, DEVELOPMENTAL SCI, V11, P53, DOI 10.1111/j.1467-7687.2007.00645.x
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Meints K., 2008, LINCOLN INFANT LAB P
   Melvin SA, 2017, INFANCY, V22, P42, DOI 10.1111/infa.12145
   Morey R. D., 2015, BAYESFACTOR COMPUTAT
   Mulak KE, 2013, CHILD DEV, V84, P2064, DOI 10.1111/cdev.12087
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Polka L, 2014, PSYCHOL SCI, V25, P1448, DOI 10.1177/0956797614533571
   Pons F, 2012, CHILD DEV, V83, P965, DOI 10.1111/j.1467-8624.2012.01740.x
   R Core Team, 2016, R LANG ENV STAT COMP
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Schmale R, 2015, DEVELOPMENTAL SCI, V18, P664, DOI 10.1111/desc.12244
   Seidl A, 2014, LANG LEARN DEV, V10, P297, DOI 10.1080/15475441.2013.858575
   Seidl A, 2014, LANG LEARN, V64, P165, DOI 10.1111/lang.12059
   Shneidman LA, 2013, J CHILD LANG, V40, P672, DOI 10.1017/S0305000912000141
   Shneidman LA, 2012, DEVELOPMENTAL SCI, V15, P659, DOI 10.1111/j.1467-7687.2012.01168.x
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tsuji S, 2017, INTERSPEECH, P2108, DOI 10.21437/Interspeech.2017-1468
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   van Heugten M, 2012, J SPEECH LANG HEAR R, V55, P554, DOI 10.1044/1092-4388(2011/10-0347)
   Wagenmakers EJ, 2016, CURR DIR PSYCHOL SCI, V25, P169, DOI 10.1177/0963721416643289
   Wetzels R, 2012, PSYCHON B REV, V19, P1057, DOI 10.3758/s13423-012-0295-x
   Yeung HH, 2014, COGNITION, V132, P151, DOI 10.1016/j.cognition.2014.04.001
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
   YOUNGER BA, 1986, CHILD DEV, V57, P803, DOI 10.2307/1130356
NR 59
TC 1
Z9 1
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD JUL-AUG
PY 2018
VL 23
IS 4
BP 484
EP 501
DI 10.1111/infa.12232
PG 18
WC Psychology, Developmental
SC Psychology
GA GI2SO
UT WOS:000434222400001
DA 2021-02-24
ER

PT J
AU Werker, JF
AF Werker, Janet F.
TI Perceptual beginnings to language acquisition
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
DE infancy; language acquisition; multisensory; phonetic development;
   speech perception
ID DEVELOPMENTAL SPEECH-PERCEPTION; ENGLISH-LEARNING INFANTS;
   NATIVE-LANGUAGE; 1ST YEAR; PHONETIC PERCEPTION; BILINGUAL INFANTS;
   VISUAL SPEECH; DISTRIBUTIONAL INFORMATION; LINGUISTIC EXPERIENCE;
   14-MONTH-OLD INFANTS
AB In this article, I present a selective review of research on speech perception development and its relation to reference, word learning, and other aspects of language acquisition, focusing on the empirical and theoretical contributions that have come from my laboratory over the years. Discussed are the biases infants have at birth for processing speech, the mechanisms by which universal speech perception becomes attuned to the properties of the native language, and the extent to which changing speech perception sensitivities contribute to language learning. These issues are reviewed from the perspective of both monolingual and bilingual learning infants. Two foci will distinguish this from my previous reviews: first and foremost is the extent to which contrastive meaning and referential intent are not just shaped by, but also shape, changing speech perception sensitivities, and second is the extent to which infant speech perception is multisensory and its implications for both theory and methodology.
C1 [Werker, Janet F.] Univ British Columbia, Vancouver, BC, Canada.
RP Werker, JF (corresponding author), Univ British Columbia, Dept Psychol, 2136 West Mall, Vancouver, BC V6T 1Z4, Canada.
EM jwerker@psych.ubc.ca
OI Werker, Janet F./0000-0002-1168-9013
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC);
   NSERCNatural Sciences and Engineering Research Council of Canada
   (NSERC); Canada Research ChairNatural Resources CanadaCanadian Forest
   ServiceCanada Research Chairs; Canadian Institutes for Advanced Research
   Fellowship
FX Preparation of this paper, and the research from my laboratory described
   therein, was supported by grants from SSHRC and NSERC, and by my Canada
   Research Chair and Canadian Institutes for Advanced Research Fellowship.
   Special thanks to Savannah Nijeboer for editing and for creating the
   figures, and to Dr. Padmapriya Kandhadai for editing advice.
CR Albareda-Castellot B, 2011, DEVELOPMENTAL SCI, V14, P395, DOI 10.1111/j.1467-7687.2010.00989.x
   Archer S, 2014, J COGN DEV, V15, P110, DOI 10.1080/15248372.2012.728544
   Baker SA, 2006, LANG LEARN DEV, V2, P147, DOI 10.1207/s15473341lld0203_1
   Beckman ME, 2000, CHILD DEV, V71, P240, DOI 10.1111/1467-8624.00139
   Begus K, 2016, P NATL ACAD SCI USA, V113, P12397, DOI 10.1073/pnas.1603261113
   Bergelson E., YOUNG INFANTS WORD C
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Bernard C., 2012, FRONT PSYCHOL, V3, P85
   Bernhardt B. M., 2007, FIRST LANG, V27, P315, DOI DOI 10.1177/0142723707081652
   Best C. T., 1997, J EXPT PSYCHOL HUMAN, V14, P345
   BEST Catherine T, 1994, DEV SPEECH PERCEPTIO
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Brown C., 1997, FOCUS PHONOLOGICAL A
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Byers-Heinlein K, 2010, PSYCHOL SCI, V21, P343, DOI 10.1177/0956797609360758
   Choi D., DOES EARLY MOTOR DEV
   Coulon M, 2013, INFANCY, V18, P782, DOI 10.1111/infa.12001
   Cristia A, 2011, J PHONETICS, V39, P388, DOI 10.1016/j.wocn.2011.02.004
   Curtin S., 2007, OXFORD HDB PSYCHOLIN
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   de la Cruz Pavia I., 2016, C PAVIA AMLAP16 ARCH
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Dehaene-Lambertz G, 2004, J COGNITIVE NEUROSCI, V16, P1375, DOI 10.1162/0898929042304714
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P449, DOI 10.1162/089892900562264
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Fais L., 2012, LAB PHONOLOGY, V3, P91, DOI DOI 10.1515/lp-2012-0007
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Fennell CT, 2007, CHILD DEV, V78, P1510, DOI 10.1111/j.1467-8624.2007.01080.x
   Fennell CT, 2012, INFANCY, V17, P339, DOI 10.1111/j.1532-7078.2011.00080.x
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   FENSON L, 1994, MONOGR SOC RES CHILD, V59, pR5
   Ferguson B, 2016, COGNITION, V146, P185, DOI 10.1016/j.cognition.2015.09.020
   Ferry AL, 2013, P NATL ACAD SCI USA, V110, P15231, DOI 10.1073/pnas.1221166110
   Friedrich M, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12357
   Gervain J, 2008, COGNITIVE PSYCHOL, V57, P56, DOI 10.1016/j.cogpsych.2007.12.001
   Gervain J, 2016, NEUROIMAGE, V133, P144, DOI 10.1016/j.neuroimage.2016.03.001
   Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Guellai B., 2014, FRONT PSYCHOL, V5, P1
   Havy M, 2017, CHILD DEV, V88, P2043, DOI 10.1111/cdev.12715
   Hayes-Harb R., 2007, SECOND LANG RES, V23, P1
   Heitner RM, 2004, PHILOS PSYCHOL, V17, P45, DOI 10.1080/0951508042000202372
   Hensch TK, 2005, NAT REV NEUROSCI, V6, P877, DOI 10.1038/nrn1787
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   JUSCZYK PW, 1993, J PHONETICS, V21, P3, DOI 10.1016/S0095-4470(19)31319-1
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Kavanagh J. F., 1980, CHILD PHONOLOGY, V2
   Kemp N, 2017, APPL PSYCHOLINGUIST, V38, P289, DOI 10.1017/S0142716416000199
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   KUHL PK, 1993, J PHONETICS, V21, P125
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   LAWRENCE DH, 1949, J EXP PSYCHOL, V39, P770, DOI 10.1037/h0058097
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P399
   MANDEL DR, 1995, PSYCHOL SCI, V6, P314, DOI 10.1111/j.1467-9280.1995.tb00517.x
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   Martin A, 2012, COGNITION, V123, P50, DOI 10.1016/j.cognition.2011.12.003
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Mattock K, 2010, DEVELOPMENTAL SCI, V13, P229, DOI 10.1111/j.1467-7687.2009.00891.x
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Gomez DM, 2014, P NATL ACAD SCI USA, V111, P5837, DOI 10.1073/pnas.1318261111
   May L., 2011, FRONT PSYCHOL, V2, P19
   May L., 2017, DEVELOPMENTAL SCI
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2001, PROC ANN BUCLD, P480
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Meltzoff A. N., 2016, ZERO 3 J, V36, P2
   Minagawa-Kawai Y, 2011, CEREB CORTEX, V21, P254, DOI 10.1093/cercor/bhq082
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Moon C, 2013, ACTA PAEDIATR, V102, P156, DOI 10.1111/apa.12098
   Mugitani R, 2009, DEV PSYCHOL, V45, P236, DOI 10.1037/a0014043
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Palmer SB, 2012, CHILD DEV, V83, P543, DOI 10.1111/j.1467-8624.2011.01715.x
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Perszyk DR, 2016, COGNITION, V153, P175, DOI 10.1016/j.cognition.2016.05.004
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   Pi Casaus G., 2015, COMMUNICATION
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sansavini A, 1997, DEV PSYCHOL, V33, P3, DOI 10.1037/0012-1649.33.1.3
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Shi RS, 1999, COGNITION, V72, pB11, DOI 10.1016/S0010-0277(99)00047-5
   Shi R, 2008, DEVELOPMENTAL SCI, V11, P407, DOI 10.1111/j.1467-7687.2008.00685.x
   Shi RS, 2010, INFANCY, V15, P517, DOI 10.1111/j.1532-7078.2009.00022.x
   Shultz S., 2014, DEVELOPMENTAL SCI, V72, P1
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Skoruppa K, 2009, DEVELOPMENTAL SCI, V12, P914, DOI 10.1111/j.1467-7687.2009.00835.x
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   STREETER LA, 1976, NATURE, V259, P39, DOI 10.1038/259039a0
   Sundara M, 2008, COGNITION, V108, P232, DOI 10.1016/j.cognition.2007.12.013
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2007, COGNITIVE PSYCHOL, V54, P99, DOI 10.1016/j.cogpsych.2006.05.001
   Swingley D, 2007, DEV PSYCHOL, V43, P454, DOI 10.1037/0012-1649.43.2.454
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Takesian AE, 2013, PROG BRAIN RES, V207, P3, DOI 10.1016/B978-0-444-63327-9.00001-1
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Ter Schure S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00525
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Thiessen ED, 2013, PSYCHOL BULL, V139, P792, DOI 10.1037/a0030801
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   Trubetskoy N., 1969, PRINCIPLES PHONOLOGY
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Vouloumanos A, 2012, P NATL ACAD SCI USA, V109, P12933, DOI 10.1073/pnas.1121057109
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   Vouloumanos A, 2009, P NATL ACAD SCI USA, V106, P18867, DOI 10.1073/pnas.0906049106
   Waxman S. R., 2004, WEAVING LEXICON
   Weatherhead D, 2017, COGNITION, V160, P103, DOI 10.1016/j.cognition.2017.01.002
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Weikum WM, 2012, P NATL ACAD SCI USA, V109, P17221, DOI 10.1073/pnas.1121263109
   Werker J. F., 2004, WEAVING LEXICON, P79
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Werker JF, 2012, CURR DIR PSYCHOL SCI, V21, P221, DOI 10.1177/0963721412449459
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   WERKER JF, 1989, AM SCI, V77, P54
   Wojcik E., 2017, OXFORD RES ENCY PSYC, DOI [10. 1093/acrefore/9780190236557. 013. 56, DOI 10.1093/ACREFORE/9780190236557.013.56]
   Wu R, 2011, DEV PSYCHOL, V47, P1220, DOI 10.1037/a0024023
   Xu F., 2016, CORE KNOWLEDGE CONCE
   Yeung H. H., 2005, THESIS
   Yeung HH, 2014, CHILD DEV, V85, P1036, DOI 10.1111/cdev.12185
   Yeung HH, 2014, COGNITION, V132, P151, DOI 10.1016/j.cognition.2014.04.001
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
NR 162
TC 10
Z9 10
U1 0
U2 21
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD JUL
PY 2018
VL 39
IS 4
BP 703
EP 728
DI 10.1017/S0142716418000152
PG 26
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA GT1ML
UT WOS:000444234700001
OA Bronze
DA 2021-02-24
ER

PT J
AU Ocklenburg, S
   Friedrich, P
   Fraenz, C
   Schluter, C
   Beste, C
   Gunturkun, O
   Genc, E
AF Ocklenburg, Sebastian
   Friedrich, Patrick
   Fraenz, Christoph
   Schlueter, Caroline
   Beste, Christian
   Gunturkun, Onur
   Genc, Erhan
TI Neurite architecture of the planum temporale predicts neurophysiological
   processing of auditory speech
SO SCIENCE ADVANCES
LA English
DT Article
ID SURFACE-BASED ANALYSIS; HUMAN BRAIN; LANGUAGE LATERALIZATION;
   ELECTROMAGNETIC TOMOGRAPHY; DIFFUSION MRI; IN-VIVO; CORTEX; ASYMMETRIES;
   RESOLUTION; DISTRIBUTIONS
AB The left hemispheric advantage in speech perception is reflected in faster neurophysiological processing. On the basis of postmortem data, it has been suggested that asymmetries in the organization of the intrinsic microcircuitry of the posterior temporal lobe may produce this leftward timing advantage. However, whether this hypothetical structure-function relationship exists in vivo has never been empirically validated. To test this assumption, we used in vivo neurite orientation dispersion and density imaging to quantify microcircuitry in terms of axon and dendrite complexity of the left and right planum temporale in 98 individuals. We found that a higher density of dendrites and axons in the temporal speech area is associated with faster neurophysiological processing of auditory speech, as reflected by electroencephalography. Our results imply that a higher density and higher number of synaptic contacts in the left posterior temporal lobe increase temporal precision and decrease latency of neurophysiological processes in this brain region.
C1 [Ocklenburg, Sebastian; Friedrich, Patrick; Fraenz, Christoph; Schlueter, Caroline; Gunturkun, Onur; Genc, Erhan] Ruhr Univ Bochum, Inst Cognit Neurosci, Biopsychol, Dept Psychol, Univ Str 150, D-44780 Bochum, Germany.
   [Beste, Christian] Tech Univ Dresden, Fac Med, Dept Child & Adolescent Psychiat, Cognit Neurophysiol, Fetscherstr 74, D-01307 Dresden, Germany.
RP Ocklenburg, S (corresponding author), Ruhr Univ Bochum, Inst Cognit Neurosci, Biopsychol, Dept Psychol, Univ Str 150, D-44780 Bochum, Germany.
EM sebastian.ocklenburg@rub.de
RI Friedrich, Patrick/Y-1778-2019; Ocklenburg, Sebastian/O-5867-2017;
   Schluter, Caroline/E-4000-2019; Genc, Erhan/T-9376-2018
OI Friedrich, Patrick/0000-0001-5120-5880; Ocklenburg,
   Sebastian/0000-0001-5882-3200; Genc, Erhan/0000-0001-6514-5479;
   Gunturkun, Onur/0000-0003-4173-5233
FU Deutsche Forschungsgemeinschaft (DFG)German Research Foundation (DFG)
   [Gu227/16-1, BE4045/26-1, GE2777/2-1]; DFGGerman Research Foundation
   (DFG)European Commission [SFB 1280]; Mercur Foundation [An-2015-0044]
FX This work was supported by Deutsche Forschungsgemeinschaft (DFG) grant
   nos. Gu227/16-1, BE4045/26-1, and GE2777/2-1; DFG SFB 1280 project A03;
   and Mercur Foundation grant no. An-2015-0044.
CR Alonso-Nanclares L, 2008, P NATL ACAD SCI USA, V105, P14615, DOI 10.1073/pnas.0803652105
   Anderson B, 1999, NEUROPSY NEUROPSY BE, V12, P247
   Beste C, 2016, BRAIN STRUCT FUNCT, V221, P2487, DOI 10.1007/s00429-015-1051-6
   Catani M., 2012, ATLAS HUMAN BRAIN CO
   Concha ML, 2012, NAT REV NEUROSCI, V13, P832, DOI 10.1038/nrn3371
   Corballis MC, 2012, PROG BRAIN RES, V195, P103, DOI 10.1016/B978-0-444-53860-4.00006-4
   Daducci A, 2015, NEUROIMAGE, V105, P32, DOI 10.1016/j.neuroimage.2014.10.026
   De Martino F, 2015, P NATL ACAD SCI USA, V112, P16036, DOI 10.1073/pnas.1507552112
   Destexhe A, 2003, NAT REV NEUROSCI, V4, P739, DOI 10.1038/nrn1198
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Dippel G, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7587
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Friedrich P, 2017, NEUROIMAGE, V163, P310, DOI 10.1016/j.neuroimage.2017.09.048
   Froeling M, 2017, MAGN RESON MED, V77, P1797, DOI 10.1002/mrm.26259
   GALABURDA AM, 1978, SCIENCE, V199, P852, DOI 10.1126/science.341314
   Galuske RAW, 2000, SCIENCE, V289, P1946, DOI 10.1126/science.289.5486.1946
   GESCHWIND N, 1968, SCIENCE, V161, P186, DOI 10.1126/science.161.3837.186
   Greve DN, 2013, J COGNITIVE NEUROSCI, V25, P1477, DOI 10.1162/jocn_a_00405
   Grossi G, 2010, BIOL PSYCHOL, V85, P124, DOI 10.1016/j.biopsycho.2010.06.003
   Grussu F, 2017, ANN CLIN TRANSL NEUR, V4, P663, DOI 10.1002/acn3.445
   Herrmann CS, 2001, NEUROSCI BIOBEHAV R, V25, P465, DOI 10.1016/S0149-7634(01)00027-6
   Horn L, 1930, Z GESAMTE NEUROLOGIE, V130, P678
   Hugdahl K, 2000, ACTA PSYCHOL, V105, P211, DOI 10.1016/S0001-6918(00)00062-7
   Jespersen SN, 2010, NEUROIMAGE, V49, P205, DOI 10.1016/j.neuroimage.2009.08.053
   Jespersen SN, 2012, IEEE T MED IMAGING, V31, P16, DOI 10.1109/TMI.2011.2162099
   Kleinnijenhuis M., 2013, P 19 ANN M OHBM, P3815
   Kleinnijenhuis M., 2014, IMAGING FIBRES BRAIN
   Mazoyer B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101165
   Mazziotta J, 2001, PHILOS T R SOC B, V356, P1293, DOI 10.1098/rstb.2001.0915
   Ocklenburg S, 2016, REV NEUROSCIENCE, V27, P465, DOI 10.1515/revneuro-2015-0052
   Ocklenburg S, 2011, BEHAV BRAIN RES, V225, P284, DOI 10.1016/j.bbr.2011.07.042
   Olbrich S, 2009, NEUROIMAGE, V45, P319, DOI 10.1016/j.neuroimage.2008.11.014
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   PASCUALMARQUI RD, 1994, INT J PSYCHOPHYSIOL, V18, P49, DOI 10.1016/0167-8760(84)90014-X
   Poulet JFA, 2008, NATURE, V454, P881, DOI 10.1038/nature07150
   Salkoff DB, 2015, J NEUROSCI, V35, P10236, DOI 10.1523/JNEUROSCI.0828-15.2015
   Sekihara K, 2005, NEUROIMAGE, V25, P1056, DOI 10.1016/j.neuroimage.2004.11.051
   SELDON HL, 1981, BRAIN RES, V229, P277, DOI 10.1016/0006-8993(81)90994-X
   SELDON HL, 1982, BRAIN RES, V249, P211, DOI 10.1016/0006-8993(82)90055-5
   SELDON HL, 1981, BRAIN RES, V229, P295, DOI 10.1016/0006-8993(81)90995-1
   SELDON HL, 1985, ASSOCIATION AUDITORY, P273
   Sepehrband F, 2016, NMR BIOMED, V29, P293, DOI 10.1002/nbm.3462
   Shapleske J, 1999, BRAIN RES REV, V29, P26, DOI 10.1016/S0165-0173(98)00047-2
   Spironelli C, 2009, BIOL PSYCHOL, V80, P35, DOI 10.1016/j.biopsycho.2008.01.012
   Tournier JD, 2007, NEUROIMAGE, V35, P1459, DOI 10.1016/j.neuroimage.2007.02.016
   Tzourio-Mazoyer N, 2017, CORTEX, V86, P314, DOI 10.1016/j.cortex.2016.05.013
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zhang H, 2012, NEUROIMAGE, V61, P1000, DOI 10.1016/j.neuroimage.2012.03.072
NR 49
TC 17
Z9 17
U1 0
U2 1
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2375-2548
J9 SCI ADV
JI Sci. Adv.
PD JUL
PY 2018
VL 4
IS 7
AR eaar6830
DI 10.1126/sciadv.aar6830
PG 8
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GS0IN
UT WOS:000443176100025
PM 30009258
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Moreno-Torres, I
   Madrid-Canovas, S
AF Moreno-Torres, Ignacio
   Madrid-Canovas, Sonia
TI Recognition of Spanish consonants in 8-talker babble by children with
   cochlear implants, and by children and adults with normal hearing
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; NOISE; IDENTIFICATION; CONFUSIONS; TRANSITIONS;
   FEATURES; CUES
AB This paper presents the results of closed-set recognition task for 80 Spanish consonant-vowel sounds in 8-talker babble. Three groups of subjects participated in the study: a group of children using cochlear implants (CIs; age range: 7-13), an age-matched group of children with normal hearing (NH), and a group of adults with NH. The speech-to-noise ratios at which the participants recognized 33% of the target consonants were +7.8 dB, -3dB, and -6dB, respectively. In order to clarify the qualitative differences between the groups, groups were matched for the percentage of recognized syllables. As compared with the two groups with NH, the children with CIs: (1) produced few "I do not know" responses; (2) frequently selected the voiced stops (i.e., /b, d, g/) and the most energetic consonants (i.e., /I, r, j, s, tf/); (3) showed no vowel context effects; and (4) had a robust voicing bias. As compared with the adults with NH, both groups of children showed a fronting bias in place of articulation errors. The factors underlying these error patterns are discussed. (C) 2018 Author(s). All article content, except where otherwise noted, is licensed under a Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0
C1 [Moreno-Torres, Ignacio] Univ Malaga, Dept Filol Espanola, Campus Teatinos S-N, E-29071 Malaga, Spain.
   [Madrid-Canovas, Sonia] Univ Murcia, Dept Lengua Espanola & Linguist Gen, Campus La Merced, E-30001 Murcia, Spain.
RP Moreno-Torres, I (corresponding author), Univ Malaga, Dept Filol Espanola, Campus Teatinos S-N, E-29071 Malaga, Spain.
EM imoreno@uma.es
RI Moreno-Torres, Ignacio/H-2598-2015
FU project DENSIC (El Desarrollo del Nino Sordo con Implante Coclear) -
   Spanish Ministerio de Economia y Competitividad [FFI2015-68498-P
   MINECO/FEDER]
FX This study was funded by the project DENSIC (El Desarrollo del Nino
   Sordo con Implante Coclear) awarded by the Spanish Ministerio de
   Economia y Competitividad (FFI2015-68498-P MINECO/FEDER) to the first
   author.
CR Albala M. J., 1995, REV FILOL ESPAN, V85, P1
   Alexander JM, 2008, J ACOUST SOC AM, V123, P386, DOI 10.1121/1.2817617
   ALLEN P, 1992, J SPEECH HEAR RES, V35, P222, DOI 10.1044/jshr.3501.222
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bosch L., 2004, EVALUACION FONOLOGIC
   Bouton S, 2012, J SPEECH LANG HEAR R, V55, P139, DOI 10.1044/1092-4388(2011/10-0330)
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Chun H, 2015, J AUDIOL OTOL, V19, P144, DOI 10.7874/jao.2015.19.3.144
   DUBNO JR, 1981, J ACOUST SOC AM, V69, P249, DOI 10.1121/1.385345
   Feijoo S, 1998, J ACOUST SOC AM, V103, P2933
   Gerrits E., 2001, THESIS
   Giezen MR, 2010, J SPEECH LANG HEAR R, V53, P1440, DOI 10.1044/1092-4388(2010/09-0252)
   Gurlekian J. A., 1987, J ACOUST SOC AM, V82, pS119
   Hawkins S, 2010, J PHONETICS, V38, P60, DOI 10.1016/j.wocn.2009.02.001
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Hedrick M, 2011, INT J AUDIOL, V50, P540, DOI 10.3109/14992027.2010.549515
   Hnath-Chisolm TE, 1998, J SPEECH LANG HEAR R, V41, P94, DOI 10.1044/jslhr.4101.94
   Iglehart F, 2016, AM J AUDIOL, V25, P100, DOI 10.1044/2016_AJA-15-0064
   Johnson CE, 2000, J SPEECH LANG HEAR R, V43, P144, DOI 10.1044/jslhr.4301.144
   Mayo C, 2004, J ACOUST SOC AM, V115, P3184, DOI 10.1121/1.1738838
   Mayo C., 2016, P SPEECH PROS 2016 M, P553
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Moreno-Torres I, 2017, J ACOUST SOC AM, V141, P3079, DOI 10.1121/1.4982251
   Moreno-Torres I, 2014, J NEUROLINGUIST, V31, P1, DOI 10.1016/j.jneuroling.2014.04.002
   Munson B, 2005, J ACOUST SOC AM, V118, P2607, DOI 10.1121/1.2005887
   Nittrouer S, 2004, J ACOUST SOC AM, V115, P1777, DOI 10.1121/1.1651192
   Nittrouer S, 1998, J SPEECH LANG HEAR R, V41, P809, DOI 10.1044/jslhr.4104.809
   Nittrouer S, 2014, J COMMUN DISORD, V52, P111, DOI 10.1016/j.jcomdis.2014.09.003
   Qazi OUR, 2013, HEARING RES, V299, P79, DOI 10.1016/j.heares.2013.01.018
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   Sroka JJ, 2005, SPEECH COMMUN, V45, P401, DOI 10.1016/j.specom.2004.11.009
   Sussman JE, 2001, J ACOUST SOC AM, V109, P1173, DOI 10.1121/1.1349428
   TYEMURRAY N, 1995, J SPEECH HEAR RES, V38, P327, DOI 10.1044/jshr.3802.327
   Van Zyl M, 2013, J COMMUN DISORD, V46, P449, DOI 10.1016/j.jcomdis.2013.09.002
   WANG MD, 1973, J ACOUST SOC AM, V54, P1248, DOI 10.1121/1.1914417
   Woods DL, 2010, J ACOUST SOC AM, V127, P1609, DOI 10.1121/1.3293005
NR 38
TC 1
Z9 1
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2018
VL 144
IS 1
BP 69
EP 80
DI 10.1121/1.5044416
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GP4EJ
UT WOS:000440810900021
PM 30075641
OA Other Gold
DA 2021-02-24
ER

PT J
AU Thorin, J
   Sadakata, M
   Desain, P
   McQueen, JM
AF Thorin, Jana
   Sadakata, Makiko
   Desain, Peter
   McQueen, James M.
TI Perception and production in interaction during non-native speech
   category learning
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID TRAINING JAPANESE LISTENERS; R-VERTICAL-BAR; ENGLISH VOWELS; COGNITIVE
   LOAD; VARIABILITY; SPEAKERS; RECOGNITION; LEARNERS; DEPENDS; SOUNDS
AB Establishing non-native phoneme categories can be a notoriously difficult endeavour-in both speech perception and speech production. This study asks how these two domains interact in the course of this learning process. It investigates the effect of perceptual learning and related production practice of a challenging non-native category on the perception and/or production of that category. A four-day perceptual training protocol on the British English /ae/-/epsilon/ vowel contrast was combined with either related or unrelated production practice. After feedback on perceptual categorisation of the contrast, native Dutch participants in the related production group (N = 19) pronounced the trial's correct answer, while participants in the unrelated production group (N = 19) pronounced similar but phonologically unrelated words. Comparison of pre- and post-tests showed significant improvement over the course of training in both perception and production, but no differences between the groups were found. The lack of an effect of production practice is discussed in the light of previous, competing results and models of second-language speech perception and production. This study confirms that, even in the context of related production practice, perceptual training boosts production learning. (C) 2018 Acoustical Society of America.
C1 [Thorin, Jana; Sadakata, Makiko; Desain, Peter; McQueen, James M.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Ctr Cognit, Montessorilaan 3, NL-6500 HE Nijmegen, Netherlands.
   [Sadakata, Makiko] Univ Amsterdam, Inst Log Language & Computat, Amsterdam, Netherlands.
   [McQueen, James M.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
RP Thorin, J (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Ctr Cognit, Montessorilaan 3, NL-6500 HE Nijmegen, Netherlands.
EM j.thorin@donders.ru.nl
RI Desain, Peter/D-1267-2012; McQueen, James M./B-2212-2010; Krutwig,
   Jana/Q-8581-2018
OI McQueen, James M./0000-0003-3734-6286; 
FU Language in Interaction Consortium
FX This research was supported by a Ph.D. grant of the Language in
   Interaction Consortium (https://www.languageininteraction.nl/) to J.T.
   Special thanks go to Philip van den Broek for his technical support,
   Matthias Franken for his work on the ASR system, as well as Malin
   Mangersnes, Mariia Naumovets, Dennis Uhrig, Inez Wijnands, Josh Ring,
   and Eliana Garcia-Cossio for their help with data collection. We thank
   three reviewers for their constructive feedback.
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Baese-Berk MM, 2016, J MEM LANG, V89, P23, DOI 10.1016/j.jml.2015.10.008
   Baese-Berk MM, 2010, THESIS
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Broersma M., 2002, P 7 INT C SPOK LANG, P261
   Broersma M. E., 2005, PHONETIC LEXICAL PRO
   Brunner J, 2011, J SPEECH LANG HEAR R, V54, P727, DOI 10.1044/1092-4388(2010/09-0256)
   de Jong K, 2009, J PHONETICS, V37, P357, DOI 10.1016/j.wocn.2009.06.001
   Deterding David, 1997, J INT PHON ASSOC, V27, P47, DOI [DOI 10.1017/S0025100300005417, 10.1017/S0025100300005417]
   Escudero P, 2008, J PHONETICS, V36, P345, DOI 10.1016/j.wocn.2007.11.002
   Flege J. E., 1995, SPEECH PERCEPTION LI, P239
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Franken MK, 2017, J ACOUST SOC AM, V142, P2007, DOI 10.1121/1.5006899
   Gerrits E, 2004, PERCEPT PSYCHOPHYS, V66, P363, DOI 10.3758/BF03194885
   Hattori K., 2008, J ACOUST SOC AM, V123, P3327, DOI [10.1121/1.2933826, DOI 10.1121/1.2933826]
   Herd W, 2013, J ACOUST SOC AM, V133, P4247, DOI 10.1121/1.4802902
   Hirata Y., 2004, Computer Assisted Language Learning, V17, P357, DOI 10.1080/0958822042000319629
   Hu W, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162876
   Huensch A, 2015, J PHONETICS, V52, P105, DOI 10.1016/j.wocn.2015.06.007
   Inceoglu S, 2016, APPL PSYCHOLINGUIST, V37, P1175, DOI 10.1017/S0142716415000533
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Kartushina N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01246
   Kawahara H, 2011, SADHANA-ACAD P ENG S, V36, P713, DOI 10.1007/s12046-011-0043-3
   Kittredge AK, 2016, J MEM LANG, V89, P8, DOI 10.1016/j.jml.2015.08.001
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Lambacher SG, 2005, APPL PSYCHOLINGUIST, V26, P227, DOI 10.1017/S0142716405050150
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Lopez-Soto T., 2009, P MTGS ACOUST, V6
   Lu S, 2015, BRAIN RES, V1624, P28, DOI 10.1016/j.brainres.2015.07.014
   MacMillan NA, 1991, DETECTION THEORY USE
   Mattys SL, 2014, PSYCHON B REV, V21, P748, DOI 10.3758/s13423-013-0544-7
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Mitterer H, 2017, ATTEN PERCEPT PSYCHO, V79, P344, DOI 10.3758/s13414-016-1195-3
   Munro M. J., 2004, SYSTEM, V32, P539, DOI DOI 10.1016/J.SYSTEM.2004.09.011
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   Rato A., 2014, CONCORDIA WORKING PA, V5, P529
   Sadakata M, 2013, J ACOUST SOC AM, V134, P1324, DOI 10.1121/1.4812767
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Wanrooij K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109806
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Wong J. W. S., 2013, C 14 ANN C INT SPEEC, P1
   Ylinen S, 2010, J COGNITIVE NEUROSCI, V22, P1319, DOI 10.1162/jocn.2009.21272
   Young S, 2009, HTK BOOK
NR 53
TC 2
Z9 2
U1 1
U2 6
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2018
VL 144
IS 1
BP 92
EP 103
DI 10.1121/1.5044415
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GP4EJ
UT WOS:000440810900023
PM 30075662
OA Green Published
DA 2021-02-24
ER

PT J
AU Bologna, WJ
   Vaden, KI
   Ahlstrom, JB
   Dubno, JR
AF Bologna, William J.
   Vaden, Kenneth I., Jr.
   Ahlstrom, Jayne B.
   Dubno, Judy R.
TI Age effects on perceptual organization of speech: Contributions of
   glimpsing, phonemic restoration, and speech segregation
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID MINI-MENTAL-STATE; HEARING-LOSS; OLDER-ADULTS; INTERRUPTED SPEECH;
   INDIVIDUAL-DIFFERENCES; WORKING-MEMORY; RECOGNITION PERFORMANCE;
   RECEPTION THRESHOLD; MODULATED NOISE; BOTTOM-UP
AB In realistic listening environments, speech perception requires grouping together audible fragments of speech, filling in missing information, and segregating the glimpsed target from the background. The purpose of this study was to determine the extent to which age-related difficulties with these tasks can be explained by declines in glimpsing, phonemic restoration, and/or speech segregation. Younger and older adults with normal hearing listened to sentences interrupted with silence or envelope-modulated noise, presented either in quiet or with a competing talker. Older adults were poorer than younger adults at recognizing keywords based on short glimpses but benefited more when envelope-modulated noise filled silent intervals. Recognition declined with a competing talker but this effect did not interact with age. Results of cognitive tasks indicated that faster processing speed and better visual-linguistic closure were predictive of better speech understanding. Taken together, these results suggest that age-related declines in speech recognition may be partially explained by difficulty grouping short glimpses of speech into a coherent message.
C1 [Bologna, William J.; Vaden, Kenneth I., Jr.; Ahlstrom, Jayne B.; Dubno, Judy R.] Med Univ South Carolina, Dept Otolaryngol Head & Neck Surg, 135 Rutledge Ave,MSC 550, Charleston, SC 29425 USA.
   [Bologna, William J.] Vet Affairs Portland Hlth Care Syst, Natl Ctr Rehabilitat Auditory Res, Dept Vet Affairs, 3710 Southwest US Vet Hosp Rd,P5-NCRA, Portland, OR 97239 USA.
RP Bologna, WJ (corresponding author), Med Univ South Carolina, Dept Otolaryngol Head & Neck Surg, 135 Rutledge Ave,MSC 550, Charleston, SC 29425 USA.; Bologna, WJ (corresponding author), Vet Affairs Portland Hlth Care Syst, Natl Ctr Rehabilitat Auditory Res, Dept Vet Affairs, 3710 Southwest US Vet Hosp Rd,P5-NCRA, Portland, OR 97239 USA.
EM William.Bologna@va.gov
RI Vaden, Kenneth/AAB-8387-2019
OI Vaden, Kenneth/0000-0002-3621-2043
FU National Institutes of Health/National Institute on Deafness and Other
   Communication Disorders (NIH/NIDCD)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD) [R01
   DC00184, P50 DC00422]; American Academy of Audiology Foundation
   [017727]; South Carolina Clinical and Translational Research (SCTR)
   Institute; Medical University of South Carolina, through NIH [UL1
   TR000062]; Research Facilities Improvement Program from the National
   Center for Research Resources, NIH [C06 RR14516]; NATIONAL CENTER FOR
   ADVANCING TRANSLATIONAL SCIENCESUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Center for Advancing Translational Sciences (NCATS) [UL1TR000062,
   UL1TR000062, UL1TR000062, UL1TR000062] Funding Source: NIH RePORTER;
   NATIONAL CENTER FOR RESEARCH RESOURCESUnited States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Center for Research Resources (NCRR) [C06RR014516] Funding Source: NIH
   RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   R01DC000184, R01DC000184, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, R01DC000184,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, R01DC000184, R01DC000184,
   R01DC000184, P50DC000422, R01DC000184, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, R01DC000184, P50DC000422, P50DC000422, P50DC000422,
   R01DC000184, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   R01DC000184, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   R01DC000184, R01DC000184, P50DC000422, P50DC000422, P50DC000422,
   R01DC000184, P50DC000422, P50DC000422, R01DC000184, R01DC000184,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, R01DC000184,
   P50DC000422, R01DC000184, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, R01DC000184, P50DC000422,
   R01DC000184, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, R01DC000184, P50DC000422,
   R01DC000184, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   R01DC000184, R01DC000184, P50DC000422, P50DC000422, R01DC000184,
   P50DC000422, P50DC000422, R01DC000184, P50DC000422, P50DC000422,
   P50DC000422, R01DC000184, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, R01DC000184,
   P50DC000422, P50DC000422, P50DC000422, P50DC000422, R01DC000184,
   P50DC000422, P50DC000422, P50DC000422, R01DC000184, P50DC000422] Funding
   Source: NIH RePORTER
FX This work was supported (in part) by research Grant Nos. R01 DC00184 and
   P50 DC00422 from the National Institutes of Health/National Institute on
   Deafness and Other Communication Disorders (NIH/NIDCD), Grant No. 017727
   from the American Academy of Audiology Foundation, and the South
   Carolina Clinical and Translational Research (SCTR) Institute, with an
   academic home at the Medical University of South Carolina, through NIH
   Grant No. UL1 TR000062. This investigation was conducted in a facility
   constructed with support from Research Facilities Improvement Program
   Grant No. C06 RR14516 from the National Center for Research Resources,
   NIH. This work was completed as part of the dissertation by W.J.B. to
   fulfill the requirement for Ph.D. at the University of Maryland. The
   authors would like to thank University of Maryland dissertation
   committee members Monita Chatterjee, Sandra Gordon-Salant, Rochelle
   Newman, and Jonathan Simon for their advice and support on this work,
   Lois Matthews for her assistance with participant recruitment, Larry
   Humes for providing the English version of the TRT, and the Associate
   Editor, two anonymous reviewers, and Michelle Molis for comments on an
   earlier version of this manuscript.
CR ANSI, 2010, S362010 ANSIASA
   BALTES PB, 1993, GERONTOLOGIST, V33, P580, DOI 10.1093/geront/33.5.580
   BASHFORD JA, 1988, J ACOUST SOC AM, V84, P1635, DOI 10.1121/1.397178
   Bashford JA, 1996, PERCEPT PSYCHOPHYS, V58, P342, DOI 10.3758/BF03206810
   BASHFORD JA, 1987, PERCEPT PSYCHOPHYS, V42, P114, DOI 10.3758/BF03210499
   Baskent D, 2010, J ACOUST SOC AM, V128, pE169, DOI 10.1121/1.3475794
   Baskent D, 2010, HEARING RES, V260, P54, DOI 10.1016/j.heares.2009.11.007
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Ben-David BM, 2012, HEARING RES, V290, P55, DOI 10.1016/j.heares.2012.04.022
   Benard MR, 2014, J ACOUST SOC AM, V135, pEL88, DOI 10.1121/1.4862879
   Bregman A.S., 1990, AUDITORY SCENE ANAL, P1
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   CLARK HH, 1973, J VERB LEARN VERB BE, V12, P335, DOI 10.1016/S0022-5371(73)80014-3
   CLUFF MS, 1990, J EXP PSYCHOL HUMAN, V16, P551, DOI 10.1037/0096-1523.16.3.551
   COLE RA, 1980, J VERB LEARN VERB BE, V19, P297, DOI 10.1016/S0022-5371(80)90239-X
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   DeCaro R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00236
   DIRKS DD, 1986, J ACOUST SOC AM, V80, P82, DOI 10.1121/1.394086
   Dubno JR, 2003, J ACOUST SOC AM, V113, P2084, DOI 10.1121/1.1555611
   Dubno JR, 2002, J ACOUST SOC AM, V111, P2897, DOI 10.1121/1.1480421
   Durlach NI, 2003, J ACOUST SOC AM, V113, P2984, DOI 10.1121/1.1570435
   EISENBERG LS, 1995, J SPEECH HEAR RES, V38, P222, DOI 10.1044/jshr.3801.222
   Ezzatian P, 2015, EAR HEARING, V36, P482, DOI 10.1097/AUD.0000000000000139
   FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247
   Fitzgibbons P J, 1996, J Am Acad Audiol, V7, P183
   FITZGIBBONS PJ, 1987, J ACOUST SOC AM, V81, P133, DOI 10.1121/1.395022
   FITZGIBBONS PJ, 1994, J SPEECH HEAR RES, V37, P662, DOI 10.1044/jshr.3703.662
   Fitzgibbons PJ, 1995, J ACOUST SOC AM, V98, P3140, DOI 10.1121/1.413803
   Fitzgibbons PJ, 2001, J ACOUST SOC AM, V109, P2955, DOI 10.1121/1.1371760
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Garofolo J. S., 1993, DARPA TIMIT ACOUSTIC
   George ELJ, 2007, J ACOUST SOC AM, V121, P2362, DOI 10.1121/1.2642072
   Gilbert G, 2007, J ACOUST SOC AM, V122, P1336, DOI 10.1121/1.2756161
   Gilbert JL, 2013, J AM ACAD AUDIOL, V24, P26, DOI 10.3766/jaaa.24.1.4
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Helfer KS, 2009, J ACOUST SOC AM, V125, P447, DOI 10.1121/1.3035837
   Hinkle D.E., 2003, APPL STAT BEHAV SCI, V5th
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Humes LE, 2016, FRONT SYST NEUROSCI, V10, DOI 10.3389/fnsys.2016.00091
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   HUMES LE, 1994, J SPEECH HEAR RES, V37, P465, DOI 10.1044/jshr.3702.465
   Jaekel BN, 2018, J ACOUST SOC AM, V143, P84, DOI 10.1121/1.5016968
   Jin SH, 2006, J ACOUST SOC AM, V119, P3097, DOI 10.1121/1.2188688
   Jin SH, 2010, J ACOUST SOC AM, V128, P881, DOI 10.1121/1.3458851
   Kidd G, 2005, J ACOUST SOC AM, V118, P3804, DOI 10.1121/1.2109187
   Kidd GR, 2012, J ACOUST SOC AM, V131, P1434, DOI 10.1121/1.3675975
   Krull V, 2013, EAR HEARING, V34, pE14, DOI 10.1097/AUD.0b013e31826d0c27
   Kwon B. J., 2012, TOKEN VERSION 1 36
   Lee JH, 2012, J ACOUST SOC AM, V132, P1700, DOI 10.1121/1.4740482
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Molis MR, 2015, J SPEECH LANG HEAR R, V58, P481, DOI 10.1044/2015_JSLHR-H-14-0098
   MOORE B C J, 1990, British Journal of Audiology, V24, P131, DOI 10.3109/03005369009077854
   Moore BCJ, 2003, J PHONETICS, V31, P563, DOI 10.1016/S0095-4470(03)00011-1
   MURDOCK BB, 1968, J EXP PSYCHOL, V76, P1, DOI 10.1037/h0025694
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   POWERS GL, 1977, J ACOUST SOC AM, V61, P195, DOI 10.1121/1.381255
   R Development Core Team, 2016, R LANG ENV STAT COMP
   Rajan R, 2008, NEUROSCIENCE, V154, P784, DOI 10.1016/j.neuroscience.2008.03.067
   Ronnberg J., 1990, EUROPEAN J COGNITIVE, V2, P253, DOI [10.1080/09541449008406207, DOI 10.1080/09541449008406207]
   Saija JD, 2014, JARO-J ASSOC RES OTO, V15, P139, DOI 10.1007/s10162-013-0422-z
   Salthouse TA, 2000, BIOL PSYCHOL, V54, P35, DOI 10.1016/S0301-0511(00)00052-1
   Shafiro V, 2016, J ACOUST SOC AM, V139, P455, DOI 10.1121/1.4939891
   Shafiro V, 2015, J ACOUST SOC AM, V137, P745, DOI 10.1121/1.4906275
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Shinn-Cunningham BG, 2008, J ACOUST SOC AM, V123, P295, DOI 10.1121/1.2804701
   Simpson AN, 2013, OTOLARYNG HEAD NECK, V148, P664, DOI 10.1177/0194599812473936
   Srinivasan S, 2005, SPEECH COMMUN, V45, P63, DOI 10.1016/j.specom.2004.09.002
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   SURPRENANT AM, 1993, Q J EXP PSYCHOL-A, V46, P193, DOI 10.1080/14640749308401044
   TAKAHASHI GA, 1992, J SPEECH HEAR RES, V35, P1410, DOI 10.1044/jshr.3506.1410
   Tiffin J, 1948, J APPL PSYCHOL, V32, P234, DOI 10.1037/h0061266
   TOMBAUGH TN, 1992, J AM GERIATR SOC, V40, P922, DOI 10.1111/j.1532-5415.1992.tb01992.x
   Trenerry M.R., 1989, STROOP NEUROPSYCHOLO
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   Vaden K., 2009, IRVINE PHONOTACTIC O
   Verhaeghen P, 2003, PSYCHOL AGING, V18, P332, DOI 10.1037/0882-7974.18.2.332
   VERSCHUURE J, 1983, PERCEPT PSYCHOPHYS, V33, P232, DOI 10.3758/BF03202859
   Versfeld NJ, 2000, J ACOUST SOC AM, V107, P1671, DOI 10.1121/1.428451
   Vitevitch MS, 1999, BRAIN LANG, V68, P306, DOI 10.1006/brln.1999.2116
   Wang X, 2010, J ACOUST SOC AM, V128, P2100, DOI 10.1121/1.3483733
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Zekveld AA, 2007, J SPEECH LANG HEAR R, V50, P576, DOI 10.1044/1092-4388(2007/040)
NR 90
TC 6
Z9 6
U1 1
U2 8
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2018
VL 144
IS 1
BP 267
EP 281
DI 10.1121/1.5044397
PG 15
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GP4EJ
UT WOS:000440810900038
PM 30075693
OA Green Published
DA 2021-02-24
ER

PT J
AU Brown, KS
   Allopenna, PD
   Hunt, WR
   Steiner, R
   Saltzman, E
   McRae, K
   Magnuson, JS
AF Brown, Kevin S.
   Allopenna, Paul D.
   Hunt, William R.
   Steiner, Rachael
   Saltzman, Elliot
   McRae, Ken
   Magnuson, James S.
TI Universal Features in Phonological Neighbor Networks
SO ENTROPY
LA English
DT Article
DE networks; neighborhood activation model; phonology; phonological
   neighbor network
ID SPOKEN WORD RECOGNITION; LANGUAGE EVOLUTION; ACTIVATION MODEL; FILM
   SUBTITLES; SPEECH; PERCEPTION; LEXICONS; ENGLISH; SPANISH; TRACE
AB Human speech perception involves transforming a countinuous acoustic signal into discrete linguistically meaningful units (phonemes) while simultaneously causing a listener to activate words that are similar to the spoken utterance and to each other. The Neighborhood Activation Model posits that phonological neighbors (two forms [words] that differ by one phoneme) compete significantly for recognition as a spoken word is heard. This definition of phonological similarity can be extended to an entire corpus of forms to produce a phonological neighbor network (PNN). We study PNNs for five languages: English, Spanish, French, Dutch, and German. Consistent with previous work, we find that the PNNs share a consistent set of topological features. Using an approach that generates random lexicons with increasing levels of phonological realism, we show that even random forms with minimal relationship to any real language, combined with only the empirical distribution of language-specific phonological form lengths, are sufficient to produce the topological properties observed in the real language PNNs. The resulting pseudo-PNNs are insensitive to the level of lingustic realism in the random lexicons but quite sensitive to the shape of the form length distribution. We therefore conclude that universal features seen across multiple languages are really string universals, not language universals, and arise primarily due to limitations in the kinds of networks generated by the one-step neighbor definition. Taken together, our results indicate that caution is warranted when linking the dynamics of human spoken word recognition to the topological properties of PNNs, and that the investigation of alternative similarity metrics for phonological forms should be a priority.
C1 [Brown, Kevin S.; Hunt, William R.] Univ Connecticut, Dept Biomed Engn, Storrs, CT 06269 USA.
   [Brown, Kevin S.] Univ Connecticut, Dept Phys, Storrs, CT 06269 USA.
   [Brown, Kevin S.] Univ Connecticut, Inst Syst Genom, Storrs, CT 06269 USA.
   [Brown, Kevin S.; Magnuson, James S.] Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
   [Allopenna, Paul D.; Steiner, Rachael; Magnuson, James S.] Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
   [Saltzman, Elliot] Boston Univ, Dept Phys Therapy & Athlet Training, Boston, MA 02215 USA.
   [McRae, Ken] Univ Western Ontario, Dept Psychol, London, ON N6A 5C2, Canada.
   [McRae, Ken] Univ Western Ontario, Brain Mind Inst, London, ON N6A 5C2, Canada.
RP Brown, KS (corresponding author), Univ Connecticut, Dept Biomed Engn, Storrs, CT 06269 USA.; Brown, KS (corresponding author), Univ Connecticut, Dept Phys, Storrs, CT 06269 USA.; Brown, KS (corresponding author), Univ Connecticut, Inst Syst Genom, Storrs, CT 06269 USA.; Brown, KS (corresponding author), Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
EM kevin.s.brown@uconn.edu; paul.allopenna@uconn.edu;
   william.hunt@uconn.edu; rachael.steiner@uconn.edu; esaltz@bu.edu;
   kenm@uwo.ca; james.magnuson@uconn.edu
OI Magnuson, James/0000-0003-0158-2367; Brown, Kevin/0000-0003-2959-2401
FU Connecticut Institute for Brain and Cognitive Sciences (CT IBaCS)
FX We acknowledge the seed grant program from the Connecticut Institute for
   Brain and Cognitive Sciences (CT IBaCS) for supporting this work.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Arbesman S, 2010, INT J BIFURCAT CHAOS, V20, P679, DOI 10.1142/S021812741002596X
   Arbesman S, 2010, ENTROPY-SWITZ, V12, P327, DOI 10.3390/e12030327
   Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Brysbaert M, 2011, EXP PSYCHOL, V58, P412, DOI 10.1027/1618-3169/a000123
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Cancho RFI, 2003, P NATL ACAD SCI USA, V100, P788, DOI 10.1073/pnas.0335980100
   Chan KY, 2010, COGNITIVE SCI, V34, P685, DOI 10.1111/j.1551-6709.2010.01100.x
   Chan KY, 2009, J EXP PSYCHOL HUMAN, V35, P1934, DOI 10.1037/a0016902
   Christiansen MH, 2003, TRENDS COGN SCI, V7, P300, DOI 10.1016/S1364-6613(03)00136-0
   Clauset A, 2009, SIAM REV, V51, P661, DOI 10.1137/070710111
   Cuetos F, 2011, PSICOLOGICA, V32, P133
   Fowler C., 2012, CAMBRIDGE HDB PSYCHO, P3
   Francis W. N., 1982, FREQUENCY ANAL ENGLI
   Gruenenfelder TM, 2009, J SPEECH LANG HEAR R, V52, P596, DOI 10.1044/1092-4388(2009/08-0004)
   Hannagan T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00563
   Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577
   Iyengar SRS, 2012, TOP COGN SCI, V4, P121, DOI 10.1111/j.1756-8765.2011.01178.x
   Kello CT, 2009, PHONOL PHONET, V16, P171, DOI 10.1515/9783110223958.171
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643
   LANDAUER TK, 1973, J VERB LEARN VERB BE, V12, P119, DOI 10.1016/S0022-5371(73)80001-5
   Luce P.A, 1986, RES SPEECH PERCEPTIO
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Magnuson J. S., 2013, OXFORD HDB COGNITIVE, P412, DOI DOI 10.1093/OXFORDHB/9780195376746.013.0027
   Marian V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043230
   MARSLENWILSON W, 1993, COGNITIVE MODELS OF SPEECH PROCESSING: THE SECOND SPERLONGA MEETING, P187
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375
   New B, 2004, BEHAV RES METH INS C, V36, P516, DOI 10.3758/BF03195598
   Newman MEJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.026126
   Plotkin JB, 2000, J THEOR BIOL, V205, P147, DOI 10.1006/jtbi.2000.2053
   POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419
   Siew CSQ, 2017, PSYCHON B REV, V24, P496, DOI 10.3758/s13423-016-1103-9
   SIMON HA, 1955, BIOMETRIKA, V42, P425
   Stella M, 2016, SPRINGER PR COMPLEX, P219, DOI 10.1007/978-3-319-29228-1_19
   Stella M, 2015, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2015/05/P05006
   Steyvers M, 2005, COGNITIVE SCI, V29, P41, DOI 10.1207/s15516709cog2901_3
   Vitevitch MS, 2008, J SPEECH LANG HEAR R, V51, P408, DOI 10.1044/1092-4388(2008/030)
   Vitevitch MS, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00369
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
NR 41
TC 1
Z9 1
U1 0
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD JUL
PY 2018
VL 20
IS 7
AR 526
DI 10.3390/e20070526
PG 23
WC Physics, Multidisciplinary
SC Physics
GA GO4WD
UT WOS:000440017100046
PM 33265615
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Swingley, D
   Alarcon, C
AF Swingley, Daniel
   Alarcon, Claudia
TI Lexical Learning May Contribute to Phonetic Learning in Infants: A
   Corpus Analysis of Maternal Spanish
SO COGNITIVE SCIENCE
LA English
DT Article
DE Language; Phonetics; Categorization; Perception; Lexicon; Infancy
ID SPEECH-PERCEPTION; DIRECTED SPEECH; DISTRIBUTIONAL INFORMATION;
   LANGUAGE-DEVELOPMENT; CATEGORIES INSIGHTS; WORD COMPREHENSION; VOWEL
   CATEGORIES; DISCRIMINATION; VOCABULARY; CONTRASTS
AB In their first year, infants begin to learn the speech sounds of their language. This process is typically modeled as an unsupervised clustering problem in which phonetically similar speech-sound tokens are grouped into phonetic categories by infants using their domain-general inference abilities. We argue here that maternal speech is too phonetically variable for this account to be plausible, and we provide phonetic evidence from Spanish showing that infant-directed Spanish vowels are more readily clustered over word types than over vowel tokens. The results suggest that infants' early adaptation to native-language phonetics depends on their word-form lexicon, implicating a much wider range of potential sources of influence on infants' developmental trajectories in language learning.
C1 [Swingley, Daniel; Alarcon, Claudia] Univ Penn, Dept Psychol, 425 S Univ Ave, Philadelphia, PA 19104 USA.
RP Swingley, D (corresponding author), Univ Penn, Dept Psychol, 425 S Univ Ave, Philadelphia, PA 19104 USA.
EM swingley@psych.upenn.edu
RI Swingley, Daniel/AAH-3230-2019
OI Swingley, Daniel/0000-0002-2891-0175
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01-HD049681]
FX This work was supported by NIH grant R01-HD049681 to D. Swingley.
   Portions of the research reported here were presented at the Workshop on
   Infant Speech Perception (Bilbao) in 2017. Some of the initial
   annotations were done by Madeline Schnur and Juan Cabrera when they were
   undergraduates at Penn. We thank Susana Lopez Ornat for making her
   corpus available via the CHILDES database.
CR Adriaans F, 2017, J ACOUST SOC AM, V141, P3070, DOI 10.1121/1.4982246
   Bergelson E, 2015, LANG LEARN DEV, V11, P369, DOI 10.1080/15475441.2014.979387
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Best C.T., 1998, INFANT BEHAV DEV, V21, P295, DOI [10.1016/S0163, DOI 10.1016/S0163, DOI 10.1016/S0163-6383(98)91508-9]
   Bloom P., 2000, CHILDREN LEARN MEANI
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Brent MR, 2001, COGNITION, V81, pB33, DOI 10.1016/S0010-0277(01)00122-6
   Burnham EB, 2015, J SPEECH LANG HEAR R, V58, P241, DOI 10.1044/2015_JSLHR-S-13-0205
   Cartmill EA, 2013, P NATL ACAD SCI USA, V110, P11278, DOI 10.1073/pnas.1309518110
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Cristia A, 2014, J CHILD LANG, V41, P913, DOI 10.1017/S0305000912000669
   Cristia A, 2011, J PHONETICS, V39, P388, DOI 10.1016/j.wocn.2011.02.004
   Cristia A, 2011, J ACOUST SOC AM, V129, P3271, DOI 10.1121/1.3562562
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   Dillon B, 2013, COGNITIVE SCI, V37, P344, DOI 10.1111/cogs.12008
   Duda RO, 1973, PATTERN CLASSIFICATI
   EIMAS PD, 1980, SCIENCE, V209, P1140, DOI 10.1126/science.7403875
   Englund KT, 2005, J PSYCHOLINGUIST RES, V34, P259, DOI 10.1007/s10936-005-3640-7
   Feldman NH, 2013, PSYCHOL REV, V120, P751, DOI 10.1037/a0034245
   Feldman NH, 2013, COGNITION, V127, P427, DOI 10.1016/j.cognition.2013.02.007
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Garrett S., 1997, CALLHOME SPANISH LEX
   Goudbeek M, 2009, J EXP PSYCHOL HUMAN, V35, P1913, DOI 10.1037/a0015781
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Horst JS, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00149
   Huttenlocher J, 2010, COGNITIVE PSYCHOL, V61, P343, DOI 10.1016/j.cogpsych.2010.08.002
   Johnson EK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083546
   Jones C, 2012, LANG LEARN, V62, P1052, DOI 10.1111/j.1467-9922.2012.00725.x
   Jusczyk PW, 1997, SCIENCE, V277, P1984, DOI 10.1126/science.277.5334.1984
   Kalashnikova M, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170306
   Kuhl P. K., 1992, DEV PSYCHOACOUSTICS, P293, DOI DOI 10.1037/10119-012
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Labov W., 2005, ATLAS N AM ENGLISH P
   Lacerda F., 1995, P 13 INT C PHON SCI, V2, P140
   Lew-Williams C, 2011, DEVELOPMENTAL SCI, V14, P1323, DOI 10.1111/j.1467-7687.2011.01079.x
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   Lopez Ornat S., 1994, ADQUISICION LENGUA E
   MacWhinney B., 2000, CHILDES PROJECT TOOL
   Martin A, 2015, PSYCHOL SCI, V26, P341, DOI 10.1177/0956797614562453
   Martin A, 2013, COGNITIVE SCI, V37, P103, DOI 10.1111/j.1551-6709.2012.01267.x
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Miyazawa K, 2017, COGNITION, V166, P84, DOI 10.1016/j.cognition.2017.05.003
   Narayan C., 2013, ORIGINS SOUND CHANGE, P128
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   R Core Team, 2015, R LANG ENV STAT COMP
   Redington M, 1998, COGNITIVE SCI, V22, P425, DOI 10.1016/S0364-0213(99)80046-9
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Singh L, 2009, INFANCY, V14, P654, DOI 10.1080/15250000903263973
   STERN DN, 1983, J CHILD LANG, V10, P1, DOI 10.1017/S0305000900005092
   Sundberg U, 1999, PHONETICA, V56, P186, DOI 10.1159/000028450
   Swingley D, 2005, COGNITIVE PSYCHOL, V50, P86, DOI 10.1016/j.cogpsych.2004.06.001
   Swingley D., 2006, 15 BIENN C INF STUD
   Swingley D, 2018, CHILD DEV, V89, P1247, DOI 10.1111/cdev.12731
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Tamis-LeMonda CS, 2014, CURR DIR PSYCHOL SCI, V23, P121, DOI 10.1177/0963721414522813
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   Tomasello M, 2001, BEHAV BRAIN SCI, V24, P1119, DOI 10.1017/S0140525X01390131
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
   Young S.J., 2006, HTK BOOK VERSION 3 4
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
NR 74
TC 3
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD JUL
PY 2018
VL 42
IS 5
BP 1618
EP 1641
DI 10.1111/cogs.12620
PG 24
WC Psychology, Experimental
SC Psychology
GA GN9HH
UT WOS:000439502700008
PM 29785714
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU Singh, L
AF Singh, Leher
TI Bilingual Infants Demonstrate Advantages in Learning Words in a Third
   Language
SO CHILD DEVELOPMENT
LA English
DT Article
ID NONNATIVE CONSONANT CONTRASTS; SPEECH-PERCEPTION; DEVELOPMENTAL-CHANGES;
   PHONETIC DETAIL; CROSS-LANGUAGE; LEXICAL ACCESS; 1ST YEAR; TONE;
   GESTURES; BRAIN
AB Prior research suggests that bilingualism may endow infants with greater phonological flexibility. This study investigated whether this flexibility facilitates word learning in additional languages (n=96). Experiment 1 compared 18- to 20-month-old monolingual (English) and bilingual (English/Mandarin) infants on their ability to learn words distinguished by click consonants from a Southern African language, Ndebele. English-Mandarin bilingual infants were sensitive to Ndebele click contrasts, but monolingual English infants were not. In Experiments 2a and 2b, we investigated whether enhanced bilingual sensitivity extended to analogous nonlinguistic labels: hand claps and finger snaps. Although discriminated by infants, neither group distinguished words labeled by hand claps and finger snaps. Results suggest that bilingual infants' sustained openness to non native contrast may facilitate the uptake of words in distant languages.
C1 [Singh, Leher] Natl Univ Singapore, Singapore, Singapore.
RP Singh, L (corresponding author), Natl Univ Singapore, Dept Psychol, AS 4,03-40,9 Arts Link, Singapore 117570, Singapore.
EM psyls@nus.edu.sg
CR Aguilar E. F., 2015, THESIS
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT, 1999, PSYCHOL SCI, V10, P65, DOI 10.1111/1467-9280.00108
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bialystok E, 2012, HDB BILINGUALISM MUL, V2, P624, DOI DOI 10.1002/9781118332382.CH25
   Bialystok E, 2008, J EXP PSYCHOL LEARN, V34, P859, DOI 10.1037/0278-7393.34.4.859
   Bialystok E, 2012, TRENDS COGN SCI, V16, P240, DOI 10.1016/j.tics.2012.03.001
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Byers-Heinlein K, 2014, DEV PSYCHOBIOL, V56, P274, DOI 10.1002/dev.21167
   Byers-Heinlein K, 2013, BILING-LANG COGN, V16, P198, DOI 10.1017/S1366728912000417
   Chen A, 2016, INFANT CHILD DEV, V25, P426, DOI 10.1002/icd.1944
   Conboy BT, 2011, DEVELOPMENTAL SCI, V14, P242, DOI 10.1111/j.1467-7687.2010.00973.x
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Curtin S, 2010, J EXP CHILD PSYCHOL, V105, P376, DOI 10.1016/j.jecp.2009.12.004
   DEMUTH K, 2007, INT GUIDE SPEECH ACQ
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Fennell CT, 2007, CHILD DEV, V78, P1510, DOI 10.1111/j.1467-8624.2007.01080.x
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   Garcia-Sierra A, 2011, J PHONETICS, V39, P546, DOI 10.1016/j.wocn.2011.07.002
   Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430
   Graham SA, 2007, DEV PSYCHOL, V43, P1111, DOI 10.1037/0012-1649.43.5.1111
   GROSJEAN F, 1989, BRAIN LANG, V36, P3, DOI 10.1016/0093-934X(89)90048-5
   Gussenhoven Carlos, 2004, PHONOLOGY TONE INTON
   Hao ML, 2008, BEHAV RES METHODS, V40, P728, DOI 10.3758/BRM.40.3.728
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   Holt R., 2015, AUSTR LING SOC SYDN
   Ivanova I, 2008, ACTA PSYCHOL, V127, P277, DOI 10.1016/j.actpsy.2007.06.003
   Kaushanskaya M, 2007, LANG LEARN, V57, P119, DOI 10.1111/j.1467-9922.2007.00401.x
   Kaushanskaya M, 2009, PSYCHON B REV, V16, P705, DOI 10.3758/PBR.16.4.705
   Kovacs AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   Kovelman I, 2011, NEUROREPORT, V22, P947, DOI 10.1097/WNR.0b013e32834cdc26
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Kroll J.F., 2002, SECOND LANG RES, V18, P137, DOI DOI 10.1191/0267658302SR2010A
   Kuhl P. K, 2011, HUMAN NEUROPLASTICIT, P33
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Maddieson Ian, 2003, BANTU LANGUAGES, V4, P15
   Rojas JAM, 2010, ACTA ACUST UNITED AC, V96, P1069, DOI 10.3813/AAA.918368
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   MOWRER DE, 1991, CLIN LINGUIST PHONET, V5, P139, DOI 10.3109/02699209108985510
   Namy LL, 2004, J COGN DEV, V5, P37, DOI 10.1207/s15327647jcd0501_3
   Namy LL, 2000, J COGN DEV, V1, P405, DOI 10.1207/S15327647JCD0104_03
   Namy LL, 2001, INFANCY, V2, P73, DOI 10.1207/S15327078IN0201_5
   Oakes L. M., 2015, HABIT 2 UNPUB
   PAPAGNO C, 1995, Q J EXP PSYCHOL-A, V48, P98, DOI 10.1080/14640749508401378
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Ramirez NF, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12427
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   SERVICE E, 1992, Q J EXP PSYCHOL-A, V45, P21, DOI 10.1080/14640749208401314
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Suanda SH, 2013, LANG LEARN DEV, V9, P50, DOI 10.1080/15475441.2012.723189
   Suanda SH, 2013, INFANCY, V18, P276, DOI 10.1111/j.1532-7078.2012.00131.x
   Thomas-Vilakati Kimberly, 2010, COPRODUCTION COARTIC
   Tonelli A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156654
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Vukatana E, 2016, J CHILD LANG, V43, P1400, DOI 10.1017/S0305000915000707
   Werker J., 2013, OXFORD HDB DEV PSYCH, P909
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   Wewalaarachchi TD, 2017, J EXP CHILD PSYCHOL, V159, P16, DOI 10.1016/j.jecp.2017.01.009
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   2008, COGNITION, V106, P833
NR 77
TC 18
Z9 18
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0009-3920
EI 1467-8624
J9 CHILD DEV
JI Child Dev.
PD JUL-AUG
PY 2018
VL 89
IS 4
BP e397
EP e413
DI 10.1111/cdev.12852
PG 17
WC Psychology, Educational; Psychology, Developmental
SC Psychology
GA GN0JF
UT WOS:000438649100007
PM 28556913
DA 2021-02-24
ER

PT J
AU Kwok, EYL
   Joanisse, MF
   Archibald, LMD
   Cardy, JO
AF Kwok, Elaine Y. L.
   Joanisse, Marc F.
   Archibald, Lisa M. D.
   Cardy, Janis Oram
TI Immature Auditory Evoked Potentials in Children With Moderate-Severe
   Developmental Language Disorder
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID EVENT-RELATED POTENTIALS; IMPAIRED CHILDREN; SPEECH-PERCEPTION;
   MATURATION; IMPAIRMENTS; RESPONSES; PEOPLE; LATERALIZATION; ACQUISITION;
   TOPOGRAPHY
AB Purpose: Immature auditory processing has been proposed to underlie language impairments in children with developmental language disorder (DLD; also known as specific language impairment). Using newly available normative auditory evoked potential (AEP) waveforms, we estimated AEP maturity in individual children with DLD and explored whether this maturational index was related to their language abilities.
   Method: AEPs were elicited by 225 trials of a 490-Hz pure tone. Using intraclass correlation and our previously established normative AEP waveforms of 7- to 10-year-old children with typical development, we estimated the age equivalent of the AEPs (AEP-age) from 21 children with DLD. The relation between AEP maturity and language was explored through regression analysis.
   Results: AEP-age predicted 31 % of the variance in the language abilities of children with DLD. The AEP-age of children with mild DLD was similar to their chronological age, whereas children with moderate-severe DLD showed, on average, a 1.3-year delay in their neural responses. AEP-age predicted receptive, but not expressive, language performance.
   Conclusion: Maturation in auditory neural responses is a significant predictor of language ability, particularly in children with moderate-severe DLD.
C1 [Kwok, Elaine Y. L.; Archibald, Lisa M. D.; Cardy, Janis Oram] Univ Western Ontario, Sch Commun Sci & Disorders, London, ON, Canada.
   [Kwok, Elaine Y. L.] Univ Western Ontario, Grad Program Hlth & Rehabil Sci, London, ON, Canada.
   [Joanisse, Marc F.; Archibald, Lisa M. D.; Cardy, Janis Oram] Univ Western Ontario, Dept Psychol, London, ON, Canada.
   [Joanisse, Marc F.] Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
RP Cardy, JO (corresponding author), Univ Western Ontario, Sch Commun Sci & Disorders, London, ON, Canada.; Cardy, JO (corresponding author), Univ Western Ontario, Dept Psychol, London, ON, Canada.
EM janis.cardy@uwo.ca
RI Cardy, Janis Oram/AAF-4147-2019; Joanisse, Marc/B-5772-2015
OI Cardy, Janis Oram/0000-0002-7170-6145; Joanisse,
   Marc/0000-0002-6352-291X; Kwok, Elaine/0000-0002-4893-2574
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [418406-2012, 371201-2009]; Scottish Rite Charitable Foundation of
   Canada Research Grant
FX This research was supported by the Natural Sciences and Engineering
   Research Council of Canada Discovery Grant 418406-2012 to Janis Oram
   Cardy and 371201-2009 to Lisa M.D. Archibald and a Scottish Rite
   Charitable Foundation of Canada Research Grant to Janis Oram Cardy. The
   authors thank the children and parents for their participation and
   Margot Stothers, Heather Brown, Rachael Smyth, Jillian Spratt, Jessica
   Boehm, Charity McCarthy, Jackson Wilson, Asha Shelton, and Katherine
   Harder for their assistance with data collection.
CR Alloway TP, 2004, J EXP CHILD PSYCHOL, V87, P85, DOI 10.1016/j.jecp.2003.10.002
   Archibald LMD, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077463
   Archibald LMD, 2012, DEV COGN NEUROS-NETH, V2, P139, DOI 10.1016/j.dcn.2011.07.003
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Bishop D. V. M., 2004, DEVELOPMENTAL SCI, V7, P11, DOI DOI 10.1111/J.1467-7687.2004.00356.X
   Bishop DVM, 2007, DEVELOPMENTAL SCI, V10, P576, DOI 10.1111/j.1467-7687.2007.00620.x
   Bishop DVM, 2017, J CHILD PSYCHOL PSYC, V58, P1068, DOI 10.1111/jcpp.12721
   Bishop DVM, 2013, SCIENCE, V340, DOI 10.1126/science.1230531
   Bishop DVM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018993
   BISHOP DVM, 1987, DEV MED CHILD NEUROL, V29, P442
   Bishop DVM, 2005, CORTEX, V41, P327, DOI 10.1016/S0010-9452(08)70270-3
   Cardy JEO, 2008, INT J PSYCHOPHYSIOL, V68, P170, DOI 10.1016/j.ijpsycho.2007.10.015
   Cardy JEO, 2005, NEUROREPORT, V16, P329, DOI 10.1097/00001756-200503150-00005
   Ceponiene R, 2009, BRAIN LANG, V110, P107, DOI 10.1016/j.bandl.2009.04.003
   Ceponiene R, 2002, CLIN NEUROPHYSIOL, V113, P870, DOI 10.1016/S1388-2457(02)00078-0
   Choudhury N, 2011, CLIN NEUROPHYSIOL, V122, P320, DOI 10.1016/j.clinph.2010.05.035
   Conti-Ramsden G, 2001, J CHILD PSYCHOL PSYC, V42, P741, DOI 10.1111/1469-7610.00770
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   de Guibert C, 2011, BRAIN, V134, P3044, DOI 10.1093/brain/awr141
   DeThorne LS, 2004, AM J SPEECH-LANG PAT, V13, P275, DOI 10.1044/1058-0360(2004/029)
   Duffy FH, 2013, BMC NEUROL, V13, DOI 10.1186/1471-2377-13-12
   Eggermont JJ, 2003, ACTA OTO-LARYNGOL, V123, P249, DOI 10.1080/0036554021000028098
   Eggermont JJ, 2002, AUDIOL NEURO-OTOL, V7, P71, DOI 10.1159/000057656
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hugdahl K, 2004, J SPEECH LANG HEAR R, V47, P162, DOI 10.1044/1092-4388(2004/014)
   Joanisse MF, 2004, CURR DIR PSYCHOL SCI, V13, P156, DOI 10.1111/j.0963-7214.2004.00297.x
   Kwok EYL, 2018, EUR J NEUROSCI, V47, P69, DOI 10.1111/ejn.13785
   Leonard LB, 2014, CHILDREN WITH SPECIFIC LANGUAGE IMPAIRMENT, 2ND EDITION, P1
   LIEGEOISCHAUVEL C, 1994, ELECTROEN CLIN NEURO, V92, P204, DOI 10.1016/0168-5597(94)90064-7
   LINCOLN AJ, 1995, J AUTISM DEV DISORD, V25, P521, DOI 10.1007/BF02178298
   McArthur G, 2009, DEVELOPMENTAL SCI, V12, P768, DOI 10.1111/j.1467-7687.2008.00804.x
   McArthur GM, 2005, BRAIN LANG, V94, P260, DOI 10.1016/j.bandl.2005.01.002
   McArthur GM, 2004, J SPEECH LANG HEAR R, V47, P527, DOI 10.1044/1092-4388(2004/041)
   McArthur GM, 2004, COGN NEUROPSYCHOL, V21, P79, DOI 10.1080/02643290342000087
   Minagawa-Kawai Y, 2011, DEV COGN NEUROS-NETH, V1, P217, DOI 10.1016/j.dcn.2011.03.005
   Moore JK, 2002, ANN OTO RHINOL LARYN, V111, P7
   NEVILLE HJ, 1993, J COGNITIVE NEUROSCI, V5, P235, DOI 10.1162/jocn.1993.5.2.235
   Ors Marianne, 2002, Eur J Paediatr Neurol, V6, P47, DOI 10.1053/ejpn.2001.0541
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Reilly S, 2014, INT J LANG COMM DIS, V49, P416, DOI 10.1111/1460-6984.12102
   Rice ML, 1998, J SPEECH LANG HEAR R, V41, P1412, DOI 10.1044/jslhr.4106.1412
   RUBIN H, 1990, CAN J PSYCHOL, V44, P483, DOI 10.1037/h0084269
   Rutter M., 2003, SOCIAL COMMUNICATION
   Semel E. M., 2003, CLIN EVALUATION LANG
   SMITHLOCK KM, 1993, HASKINS LAB STATUS R, V114, P113
   Spaulding TJ, 2006, LANG SPEECH HEAR SER, V37, P61, DOI 10.1044/0161-1461(2006/007)
   Sussman E, 2008, HEARING RES, V236, P61, DOI 10.1016/j.heares.2007.12.001
   Takeshita K, 2002, CLIN NEUROPHYSIOL, V113, P1470, DOI 10.1016/S1388-2457(02)00202-X
   Tallal P., 2000, SPEECH LANGUAGE IMPA, P131
   TonnquistUhlen I, 1996, EAR HEARING, V17, P314, DOI 10.1097/00003446-199608000-00003
   Uwer R, 2002, DEV MED CHILD NEUROL, V44, P527
   Warrier C, 2009, J NEUROSCI, V29, P61, DOI 10.1523/JNEUROSCI.3489-08.2009
   Wechler D., 1999, WECHSLER ABBREVIATED
   Wible B, 2005, BRAIN, V128, P417, DOI 10.1093/brain/awh367
   Wright B. A., 2002, P 25 ANN M ASS RES O, V25, P19
NR 55
TC 4
Z9 4
U1 1
U2 5
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUL
PY 2018
VL 61
IS 7
BP 1718
EP 1730
DI 10.1044/2018_JSLHR-L-17-0420
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GN0RQ
UT WOS:000438683200013
PM 29974119
DA 2021-02-24
ER

PT J
AU Berry, GM
   Ernestus, M
AF Berry, Grant M.
   Ernestus, Mirjam
TI Phonetic alignment in English as a lingua franca: Coming together while
   splitting apart
SO SECOND LANGUAGE RESEARCH
LA English
DT Article
DE conversational speech; English as a lingua franca; phonetic alignment;
   speech production; style-shifting; vowel contrasts
ID SPEECH-PERCEPTION; INTERLINGUAL IDENTIFICATION; ACOUSTIC DESCRIPTION;
   COGNITIVE CONTROL; INHIBITORY SKILL; VOWEL CONTRAST; SPANISH;
   ADAPTATION; ACCOMMODATION; EXPERIENCE
AB This study investigates the plasticity of phonological boundaries during discourse in a lingua franca. We tracked the production of 34 Spanish learners of English conversing with two Dutch confederates in English across two speech styles, focusing on incremental changes in two key English vowel contrasts with differential effects of cross-linguistic influence (/i/-/?/ and /epsilon/-/ae/). Results indicate that Spaniards align with Dutch confederates, quickly merging /epsilon/ and /ae/ and gradually separating their merged /i/-/?/ category, rather than adopting native-like English production. We found greater merger in informal speech overall. We also found an interaction with time for the /i/-/?/ contrast, indicating that the merged /i/ and /?/ categories gradually separate in informal speech; this effect was not found for /epsilon/-/ae/. Finally, proficiency modulates alignment: the most proficient speakers separate /i/-/?/ and merge /epsilon/-/ae/ more than other speakers. We interpret phonetic alignment as a complex, dynamic phenomenon influenced by proficiency in discourse language and speaking style, and whose effects may unfold rapidly or gradually depending on the phonological category investigated.
C1 [Berry, Grant M.] Penn State Univ, University Pk, PA 16802 USA.
   [Ernestus, Mirjam] Radboud Univ Nijmegen, Nijmegen, Netherlands.
RP Berry, GM (corresponding author), Penn State Univ, Dept Spanish Italian & Portuguese, 442 Burrowes Bldg, University Pk, PA 16802 USA.
EM grantberry@psu.edu
OI Berry, Grant M./0000-0002-4376-4305
FU NSF Partnerships in International Research and Education grant [OISE
   0968369]; VICI grant from the NWO [277-70-010]; ERC Starting
   GrantEuropean Research Council (ERC) [284108]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article:
   Collaboration between authors was facilitated by an NSF Partnerships in
   International Research and Education grant (OISE 0968369) to Judith F
   Kroll, Paola E Dussias, and Janet van Hell. The second author was
   supported by a VICI grant (#277-70-010) from the NWO and an ERC Starting
   Grant (#284108).
CR Adank P, 2004, J ACOUST SOC AM, V116, P3099, DOI 10.1121/1.1795335
   Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Adank P, 2007, J ACOUST SOC AM, V121, P1130, DOI 10.1121/1.2409492
   Amengual M, 2015, PHONETICA, V72, P207, DOI 10.1159/000439406
   Archila-Suerte P, 2012, BILING-LANG COGN, V15, P190, DOI 10.1017/S1366728911000125
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen RH, 2015, REPSYCHLING DATA SET, V0
   Babel M, 2013, FRONT PSYCHOL, V4, P321
   Babel M, 2012, LANG SPEECH, V55, P231, DOI 10.1177/0023830911417695
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Baese-Berk MM, 2013, JASA EXPRESS LETT J, V133, P174, DOI DOI 10.1121/1
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barrios S, 2016, J ACOUSTICAL SOC AM, V129
   Bates D., 2015, PARSIMONIOUS MIXED M
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Berry GM, 2016, LINGUIST VANGUARD, V2, P85
   Biber D, 2006, CORPORA, V1, P1, DOI 10.3366/cor.2006.1.1.1
   Biber D, 2012, CORPUS LINGUIST LING, V8, P9, DOI 10.1515/cllt-2012-0002
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Booij G., 1995, PHONOLOGY DUTCH
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   BRADLOW AR, 1995, J ACOUST SOC AM, V97, P1916, DOI 10.1121/1.412064
   Branigan HP, 2000, COGNITION, V75, pB13, DOI 10.1016/S0010-0277(99)00081-5
   Braver TS, 2012, TRENDS COGN SCI, V16, P106, DOI 10.1016/j.tics.2011.12.010
   Braver TS, 2002, NEUROSCI BIOBEHAV R, V26, P809, DOI 10.1016/S0149-7634(02)00067-2
   Burgos P, 2013, P INT 2013 LYON FRAN, V2013, P2385
   Campbell L., 2013, HIST LINGUISTICS INT
   Casillas JV, 2015, PHONETICA, V72, P182, DOI 10.1159/000431101
   Chang CB, 2013, J PHONETICS, V41, P520, DOI 10.1016/j.wocn.2013.09.006
   Chang CB, 2012, J ACOUST SOC AM, V132, P2700, DOI 10.1121/1.4747615
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Clopper CG, 2014, LAB PHONOL, V5, P69, DOI 10.1515/lp-2014-0004
   Costa A, 2008, LANG COGNITIVE PROC, V23, P528, DOI 10.1080/01690960801920545
   Council of Europe, 2001, COMM EUR FRAM REF LA
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   De Looze C, 2014, SPEECH COMMUN, V58, P11, DOI 10.1016/j.specom.2013.10.002
   Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914
   Elston-Guttler KE, 2005, J COGNITIVE NEUROSCI, V17, P1593, DOI 10.1162/089892905774597245
   Erriestus M, 2015, J PHONETICS, V48, P60, DOI 10.1016/j.wocn.2014.08.001
   Escudero P, 2012, J PHONETICS, V40, P280, DOI 10.1016/j.wocn.2011.11.004
   Escudero P, 2011, J ACOUST SOC AM, V129, pEL1, DOI 10.1121/1.3525042
   Escudero P, 2010, J ACOUST SOC AM, V128, pEL254, DOI 10.1121/1.3488794
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   FLEGE JE, 1991, Q J EXP PSYCHOL-A, V43, P701, DOI 10.1080/14640749108400993
   Friedman NP, 2004, J EXP PSYCHOL GEN, V133, P101, DOI 10.1037/0096-3445.133.1.101
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Giacomino L, 2012, LINGUISTIC PORTFOLIO, V1
   Giles H., 1991, CONTEXTS ACCOMMODATI, P1, DOI [10.1017/CBO9780511663673.001, DOI 10.1017/CBO9780511663673.001]
   Gussenhoven C., 1992, J INT PHON ASSOC, V22, P45, DOI [DOI 10.1017/S002510030000459X, 10.1017/S002510030000459X]
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hwane J, 2015, J MEM LANG, V81, P72, DOI 10.1016/j.jml.2015.01.001
   Jacobs CL, 2015, J MEM LANG, V84, P37, DOI 10.1016/j.jml.2015.05.004
   Jesse A, 2011, PSYCHON B REV, V18, P943, DOI 10.3758/s13423-011-0129-2
   Kim Midam, 2011, Lab Phonol, V2, P125
   Kittredge AK, 2016, J MEM LANG, V89, P8, DOI 10.1016/j.jml.2015.08.001
   Kondaurova MV, 2008, J ACOUST SOC AM, V124, P3959, DOI 10.1121/1.2999341
   Kouwenhoven H, 2018, CORPUS LINGUIST LING, V14, P35, DOI 10.1515/cllt-2013-0054
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Labov W, 2013, LANGUAGE, V89, P30
   Labov W, 2011, J SOCIOLING, V15, P431, DOI 10.1111/j.1467-9841.2011.00504.x
   Lev-Ari S, 2014, J PHONETICS, V47, P36, DOI 10.1016/j.wocn.2014.09.001
   Lev-Ari S, 2013, J PHONETICS, V41, P320, DOI 10.1016/j.wocn.2013.06.002
   LEVELT WJM, 1983, COGNITION, V14, P41, DOI 10.1016/0010-0277(83)90026-4
   Levey S, 2004, CONT ISSUES COMMUNIC, V31, P162
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   MacKenzie L, 2013, NEW WAYS ANAL VARIAT, V42
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Martinez-Celdran Eugenio, 2003, J INT PHON ASSOC, V33, P255, DOI DOI 10.1017/S0025100303001373
   Mattys SL, 2015, J ACOUST SOC AM, V137, P1464, DOI 10.1121/1.4913507
   Mattys SL, 2014, PSYCHON B REV, V21, P748, DOI 10.3758/s13423-013-0544-7
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Moreno EM, 2008, J NEUROLINGUIST, V21, P477, DOI 10.1016/j.jneuroling.2008.01.003
   Namy LL, 2002, J LANG SOC PSYCHOL, V21, P422, DOI 10.1177/026192702237958
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nycz Jennifer, 2013, J ACOUST SOC AM, V20, P1
   OLSON CL, 1976, PSYCHOL BULL, V83, P579, DOI 10.1037/0033-2909.83.4.579
   Pardo J, 2001, THESIS
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   PILLAI KCS, 1955, ANN MATH STAT, V26, P117, DOI 10.1214/aoms/1177728599
   Pillai KCS, 1954, I STAT MIMEOGRAPH SE, V88
   R Core Team, 2016, R LANG ENV STAT COMP
   Rosenfelder I, 2014, PROGRAM SUITE V1 2 2
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Serafini EJ, 2016, STUD SECOND LANG ACQ, V38, P607, DOI 10.1017/S0272263115000327
   Sharifzadeh HR, 2012, J VOICE, V26, pE49, DOI 10.1016/j.jvoice.2010.12.002
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Sidaras S.K., 2011, THESIS
   Simon E, 2012, LANG SCI, V34, P269, DOI 10.1016/j.langsci.2011.10.002
   Simonet M, 2014, J PHONETICS, V43, P26, DOI 10.1016/j.wocn.2014.01.004
   Thompson GL, 2012, VIAL-VIGO INT J APPL, V9, P107
   Trofimovich P, 2014, BILING-LANG COGN, V17, P822, DOI 10.1017/S1366728913000801
   Trudgill P, 1986, DIALECTS CONTACT LAN
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Wang HY, 2006, AVT PUBL, V23, P237
   Weber A, 2014, J PHONETICS, V46, P34, DOI 10.1016/j.wocn.2014.05.002
   Weinreich U., 1968, LANGUAGES CONTACT FI
   White EJ, 2017, BILING-LANG COGN, V20, P162, DOI 10.1017/S1366728915000620
   Wilson I, 2014, J SPEECH LANG HEAR R, V57, P361, DOI 10.1044/2013_JSLHR-S-12-0345
   Witteman MJ, 2015, LANG SPEECH, V58, P168, DOI 10.1177/0023830914528102
NR 111
TC 0
Z9 0
U1 0
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0267-6583
EI 1477-0326
J9 SECOND LANG RES
JI Second Lang. Res.
PD JUL
PY 2018
VL 34
IS 3
BP 343
EP 370
DI 10.1177/0267658317737348
PG 28
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GM4JP
UT WOS:000438086100003
DA 2021-02-24
ER

PT J
AU Magimairaj, BM
   Nagaraj, NK
AF Magimairaj, Beula M.
   Nagaraj, Naveen K.
TI Working Memory and Auditory Processing in School-Age Children
SO LANGUAGE SPEECH AND HEARING SERVICES IN SCHOOLS
LA English
DT Article
ID INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION; LANGUAGE IMPAIRMENT;
   LISTENING DIFFICULTIES; OLDER-ADULTS; DISORDER APD; HEARING-LOSS; NOISE;
   ATTENTION; CAPACITY
AB Purpose: Our goal is to present the relationships between working memory (WM) and auditory processing abilities in school-age children.
   Review and Discussion: We begin with an overview of auditory processing, the conceptualization of auditory processing disorder, and the assessment of auditory processing abilities in children. Next, we describe a model of WM and a model of auditory processing followed by their comparison. Evidence for the relationships between WM and auditory processing abilities in school-age children follows. Specifically, we present evidence for the association (or lack thereof) between WM/attention and auditory processing test performance.
   Clinical Implications: In conclusion, we describe a new framework for understanding auditory processing abilities in children based on integrated evidence from cognitive science, hearing science, and language science. We also discuss clinical implications in children that could inform future research.
C1 [Magimairaj, Beula M.] Univ Cent Arkansas, Cognit & Language Lab, Commun Sci & Disorders, Conway, AR 72035 USA.
   [Nagaraj, Naveen K.] Univ Arkansas Med Sci, Cognit Hearing Sci Lab, Audiol & Speech Pathol, Little Rock, AR 72205 USA.
   [Nagaraj, Naveen K.] Univ Arkansas, Little Rock, AR 72204 USA.
RP Magimairaj, BM (corresponding author), Univ Cent Arkansas, Cognit & Language Lab, Commun Sci & Disorders, Conway, AR 72035 USA.
EM bmagimairaj@uca.edu
FU Hearing Health Foundation's Emerging Research Grant; University of
   Arkansas for Medical Sciences
FX A Hearing Health Foundation's Emerging Research Grant to the authors and
   a Medical Research Endowment Grant from the University of Arkansas for
   Medical Sciences to the second author funded the authors' studies cited
   in this article.
CR Abrams D., 2015, HDB CLIN AUDIOLOGY, P527
   Ahmmed AU, 2014, EAR HEARING, V35, P295, DOI 10.1097/01.aud.0000441034.02052.0a
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Alloway TP., 2007, AUTOMATED WORKING ME
   American Academy of Audiology, 2010, AM AC AUD CLIN PRACT
   American Educational Research Association; American Psychological Association; National Council on Measurement in Education, 2014, STAND ED PSYCH TEST
   American Speech-Language-Hearing Association, 2005, CENTR AUD PROC ROL A
   Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI 10.1016/S0079-7421(08)60422-3
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Banai K., 2014, HDB CENTRAL AUDITORY, P191
   Barrouillet P, 2010, PSYCHOL BELG, V50, P353, DOI 10.5334/pb-50-3-4-353
   Barrouillet P, 2009, DEV PSYCHOL, V45, P477, DOI 10.1037/a0014615
   Barry JG, 2015, EAR HEARING, V36, pE300, DOI 10.1097/AUD.0000000000000180
   Bellis T J, 1999, J Am Acad Audiol, V10, P319
   Bellis Teri James, 2002, Seminars in Hearing, V23, P287, DOI 10.1055/s-2002-35877
   Benard MR, 2014, J ACOUST SOC AM, V135, pEL88, DOI 10.1121/1.4862879
   Bishop D., 2003, CHILDRENS COMMUNICAT
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   Cameron S, 2016, J AM ACAD AUDIOL, V27, P470, DOI 10.3766/jaaa.15085
   Cameron S, 2016, J AM ACAD AUDIOL, V27, P458, DOI 10.3766/jaaa.15084
   Cameron Sharon, 2015, Seminars in Hearing, V36, P216, DOI 10.1055/s-0035-1564457
   Cameron S, 2008, J AM ACAD AUDIOL, V19, P377, DOI 10.3766/jaaa.19.5.2
   Camos V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00900
   Camos V, 2011, DEV PSYCHOL, V47, P898, DOI 10.1037/a0023193
   Chermak G D, 1999, J Am Acad Audiol, V10, P289
   Conway ARA, 2005, PSYCHON B REV, V12, P769, DOI 10.3758/BF03196772
   Cowan N, 2005, COGNITIVE PSYCHOL, V51, P42, DOI 10.1016/j.cogpsych.2004.12.001
   Cowan N, 2017, ADV CHILD DEV BEHAV, V52, P81, DOI 10.1016/bs.acdb.2016.12.001
   Dawes P, 2009, INT J LANG COMM DIS, V44, P440, DOI 10.1080/13682820902929073
   Dillon H, 2012, J AM ACAD AUDIOL, V23, P97, DOI 10.3766/jaaa.23.2.4
   Domitz D M, 2000, Am J Audiol, V9, P101, DOI 10.1044/1059-0889(2000/012)
   Eggermont J., 2014, HDB CENTRAL AUDITORY, P59
   Eisenberg LS, 2000, J ACOUST SOC AM, V107, P2704, DOI 10.1121/1.428656
   Emanuel DC, 2011, AM J AUDIOL, V20, P48, DOI 10.1044/1059-0889(2011/10-0019)
   Engle RW, 2002, CURR DIR PSYCHOL SCI, V11, P19, DOI 10.1111/1467-8721.00160
   Etymotic Research, 2005, BKB SIN SPEECH IN NO
   Ferguson MA, 2011, J SPEECH LANG HEAR R, V54, P211, DOI 10.1044/1092-4388(2010/09-0167)
   Ferre Jeanane M., 2002, Seminars in Hearing, V23, P319, DOI 10.1055/s-2002-35880
   Fey ME, 2011, LANG SPEECH HEAR SER, V42, P246, DOI 10.1044/0161-1461(2010/10-0013)
   First M. B., 2013, DSM 5 HDB DIFFERENTI
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Gaillard V, 2011, J EXP CHILD PSYCHOL, V110, P469, DOI 10.1016/j.jecp.2011.05.004
   Gathercole SE, 1999, TRENDS COGN SCI, V3, P410, DOI 10.1016/S1364-6613(99)01388-1
   GEFFNER D., 2010, AUDITORY SKILLS ASSE
   Gillarn RB, 2008, J SPEECH LANG HEAR R, V51, P97, DOI 10.1044/1092-4388(2008/007)
   Gyldenkaerne P, 2014, J AM ACAD AUDIOL, V25, P676, DOI 10.3766/jaaa.25.7.6
   Halliday LF, 2012, J SPEECH LANG HEAR R, V55, P168, DOI 10.1044/1092-4388(2011/09-0213)
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Hornickel J, 2011, BEHAV BRAIN RES, V216, P597, DOI 10.1016/j.bbr.2010.08.051
   Hugdahl K, 2009, SCAND J PSYCHOL, V50, P11, DOI 10.1111/j.1467-9450.2008.00676.x
   Jarrold C, 2006, NEUROSCIENCE, V139, P39, DOI 10.1016/j.neuroscience.2005.07.002
   Jerger J, 2000, J Am Acad Audiol, V11, P467
   JERGER J, 1998, SEMINARS HEARING, V19, P395, DOI DOI 10.1055/S-0028-1082986
   Jones PR, 2015, DEV PSYCHOL, V51, P353, DOI 10.1037/a0038570
   Kamhi AG, 2011, LANG SPEECH HEAR SER, V42, P265, DOI 10.1044/0161-1461(2010/10-0004)
   KATZ J, 1963, ANN OTO RHINOL LARYN, V72, P908, DOI 10.1177/000348946307200405
   KATZ J, 1962, J AUD RES, V2, P327
   KATZ J, 1968, J SPEECH HEAR DISORD, V33, P132, DOI 10.1044/jshd.3302.132
   Katz J., 2001, CENTRAL TEST BATTERY
   Katz J, 1992, CENTRAL AUDITORY PRO, P81
   Katz J., 1973, THE SSW TEST MANUAL
   Keith R, 2000, RANDOM GAP DETECTION
   Keith R.W., 2009, SCAN 3 C TESTS AUDIT
   Keith R. W., 1986, SCAN SCREENING TEST
   KIMURA D, 1961, CAN J PSYCHOLOGY, V15, P156, DOI 10.1037/h0083218
   KRAUS N, 1995, J COGNITIVE NEUROSCI, V7, P25, DOI 10.1162/jocn.1995.7.1.25
   Kraus N., 2013, AUDITORY PROCESSING
   Kraus N, 2015, TRENDS COGN SCI, V19, P642, DOI 10.1016/j.tics.2015.08.017
   Kraus N, 2012, ANN NY ACAD SCI, V1252, P100, DOI 10.1111/j.1749-6632.2012.06463.x
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Leonard LB, 2013, J SPEECH LANG HEAR R, V56, P577, DOI 10.1044/1092-4388(2012/11-0254)
   Lepine R, 2005, PSYCHON B REV, V12, P165, DOI 10.3758/BF03196363
   Magimairaj BM, 2018, J SPEECH LANG HEAR R, V61, P1294, DOI 10.1044/2018_JSLHR-H-17-0312
   Magimairaj BM, 2012, ACTA PSYCHOL, V140, P196, DOI 10.1016/j.actpsy.2012.05.004
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McCreery RW, 2017, INT J AUDIOL, V56, P306, DOI 10.1080/14992027.2016.1266703
   Medwetsky L, 2011, LANG SPEECH HEAR SER, V42, P286, DOI 10.1044/0161-1461(2011/10-0036)
   Merzenich MM, 1996, SCIENCE, V271, P77, DOI 10.1126/science.271.5245.77
   Miller G.A., 1960, PLANS STRUCTURE BEHA
   Moore DR, 2015, INT J PSYCHOPHYSIOL, V95, P125, DOI 10.1016/j.ijpsycho.2014.07.006
   Moore DR, 2013, INT J AUDIOL, V52, P3, DOI 10.3109/14992027.2012.723143
   Moore DR, 2012, J COMMUN DISORD, V45, P411, DOI 10.1016/j.jcomdis.2012.06.006
   Moore DR, 2010, PEDIATRICS, V126, pE382, DOI 10.1542/peds.2009-2826
   Murphy CFB, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135422
   Musiek F E, 1994, Am J Audiol, V3, P23, DOI 10.1044/1059-0889.0303.23
   MUSIEK FE, 1983, EAR HEARING, V4, P79, DOI 10.1097/00003446-198303000-00002
   Myklebust H, 1954, AUDITORY DISORDERS C
   Nagaraj NK, 2017, J ACOUST SOC AM, V142, P3756, DOI 10.1121/1.5018429
   Nagaraj NK, 2017, J SPEECH LANG HEAR R, V60, P2949, DOI 10.1044/2017_JSLHR-H-17-0022
   Nittrouer S, 2013, INT J AUDIOL, V52, P513, DOI 10.3109/14992027.2013.792957
   NORMAN DA, 1980, CONSCIOUSNESS SELF R
   Osman H, 2014, J SPEECH LANG HEAR R, V57, P1503, DOI 10.1044/2014_JSLHR-H-13-0286
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Pennington BF, 2009, ANNU REV PSYCHOL, V60, P283, DOI 10.1146/annurev.psych.60.110707.163548
   Riccio CA, 2005, CHILD NEUROPSYCHOL, V11, P363, DOI 10.1080/09297040490916956
   RICCIO CA, 1994, J AM ACAD CHILD PSY, V33, P849, DOI 10.1097/00004583-199407000-00011
   Richard G. J., 2013, AUDITORY PROCESSING, P283
   Richard GJ, 2006, DIFFERENTIAL SCREENI
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rosen S, 2010, INT J PEDIATR OTORHI, V74, P594, DOI 10.1016/j.ijporl.2010.02.021
   Schmithorst VJ, 2013, NEUROIMAGE-CLIN, V3, P8, DOI 10.1016/j.nicl.2013.06.016
   Sharma M, 2009, J SPEECH LANG HEAR R, V52, P706, DOI 10.1044/1092-4388(2008/07-0226)
   Sheft S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134330
   Shipstead Z, 2012, J APPL RES MEM COGN, V1, P185, DOI 10.1016/j.jarmac.2012.06.003
   Smith SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01394
   Smoski W. J., 1998, CHILDRENS AUDITORY P
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Sullivan JR, 2015, J SPEECH LANG HEAR R, V58, P1043, DOI 10.1044/2015_JSLHR-H-14-0204
   Sutcliffe PA, 2006, J SPEECH LANG HEAR R, V49, P1072, DOI 10.1044/1092-4388(2006/076)
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   Tallal P, 2006, TRENDS NEUROSCI, V29, P382, DOI 10.1016/j.tins.2006.06.003
   Tillery K. L., 2015, HDB CLIN AUDIOLOGY, P545
   Tillery KL, 2000, J SPEECH LANG HEAR R, V43, P893, DOI 10.1044/jslhr.4304.893
   Tomlin D, 2015, EAR HEARING, V36, P527, DOI 10.1097/AUD.0000000000000172
   Unsworth N, 2007, PSYCHOL REV, V114, P104, DOI 10.1037/0033-295X.114.1.104
   Weihing J, 2012, INT J AUDIOL, V51, P405, DOI 10.3109/14992027.2012.658970
   Wilson WJ, 2011, J SPEECH LANG HEAR R, V54, P278, DOI 10.1044/1092-4388(2010/09-0273)
   Woodcock R. W., 2001, WOODCOCK JOHNSON 3 T
   Zhao TC, 2016, P NATL ACAD SCI USA, V113, P5212, DOI 10.1073/pnas.1603984113
NR 125
TC 6
Z9 6
U1 1
U2 11
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 0161-1461
EI 1558-9129
J9 LANG SPEECH HEAR SER
JI Lang. Speech Hear. Serv. Sch.
PD JUL
PY 2018
VL 49
IS 3
BP 409
EP 423
DI 10.1044/2018_LSHSS-17-0099
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GM3EO
UT WOS:000437982200006
PM 29978209
DA 2021-02-24
ER

PT J
AU Masapollo, M
   Polka, L
   Menard, L
   Franklin, L
   Tiede, M
   Morgan, J
AF Masapollo, Matthew
   Polka, Linda
   Menard, Lucie
   Franklin, Lauren
   Tiede, Mark
   Morgan, James
TI Asymmetries in Unimodal Visual Vowel Perception: The Roles of
   Oral-Facial Kinematics, Orientation, and Configuration
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE visual speech perception; natural referent vowel framework; focal
   vowels; eye-tracking; point-light stimuli
ID AUDIOVISUAL SPEECH-PERCEPTION; LINGUISTIC EXPERIENCE; UNIVERSAL BIAS;
   GAZE BEHAVIOR; HEARING LIPS; VOCAL-TRACT; INFANTS; FACES; SENSITIVITY;
   DISPLAYS
AB Masapollo, Polka, and Menard (2017) recently reported a robust directional asymmetry in unimodal visual vowel perception: Adult perceivers discriminate a change from an English /u/ viseme to a French /u/ viseme significantly better than a change in the reverse direction. This asymmetry replicates a frequent pattern found in unimodal auditory vowel perception that points to a universal bias favoring more extreme vocalic articulations, which lead to acoustic signals with increased formant convergence. In the present article, the authors report 5 experiments designed to investigate whether this asymmetry in the visual realm reflects a speech-specific or general processing bias. They successfully replicated the directional effect using Masapollo et al.'s dynamically articulating faces but failed to replicate the effect when the faces were shown under static conditions. Asymmetries also emerged during discrimination of canonically oriented point-light stimuli that retained the kinematics and configuration of the articulating mouth. In contrast, no asymmetries emerged during discrimination if rotated point-light stimuli or Lissajou patterns that retained the kinematics, but not the canonical orientation or spatial configuration, of the labial gestures. These findings suggest that the perceptual processes underlying asymmetries in unimodal visual vowel discrimination are sensitive to speech-specific motion and configural properties and raise foundational questions concerning the role of specialized and general processes in vowel perception.
C1 [Masapollo, Matthew; Franklin, Lauren; Morgan, James] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
   [Masapollo, Matthew; Polka, Linda] McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
   [Polka, Linda; Menard, Lucie] Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Menard, Lucie] Univ Quebec, Dept Linguist, Montreal, PQ, Canada.
   [Tiede, Mark] Haskins Labs Inc, New Haven, CT USA.
RP Masapollo, M (corresponding author), Boston Univ, Ctr Computat Neurosci & Neural Technol, 677 Beacon St, Boston, MA 02215 USA.
EM mmasapol@bu.edu
RI Morgan, James L/A-9494-2012
OI Polka, Linda/0000-0003-4761-9057
FU NSERCNatural Sciences and Engineering Research Council of Canada (NSERC)
   [105397, 312395]; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [5-27025]; EUNICE
   KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD068501,
   R01HD068501, R01HD068501, R01HD068501, R01HD068501] Funding Source: NIH
   RePORTER
FX The research reported here was supported in part by NSERC Grant 105397
   to Linda Polka, NSERC Grant 312395 to Lucie Menard, and NIH Grant
   5-27025 to James Morgan. We are grateful to Alexina Hicks, Angela Chang,
   Fiona Higgins (McGill University), Lori Rolfe, Ellen Macaruso, and Leah
   Mann (Brown University) for assistance with subject recruitment and
   data-collection, and Laureline Arnaud and Pamela Trudeau-Fisette
   (University of Quebec at Montreal) for their help with stimulus
   preparation. I thank Alexina Hicks, who served as the model speaker in
   Masapollo, Polka, and Menard (2017) and the present study. Finally, this
   work benefited from helpful discussions with, or comments from Sheila
   Blumstein, Frank Guenther, Carol Fowler, Julia Irwin, and Douglas
   Whalen.
CR Best C. T., 1981, AM J PSYCHOL, V74, P17
   Best CT, 2016, ECOL PSYCHOL, V28, P216, DOI 10.1080/10407413.2016.1230372
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brancazio L, 2006, LANG SPEECH, V49, P21, DOI 10.1177/00238309060490010301
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   COWAN N, 1986, J ACOUST SOC AM, V79, P500, DOI 10.1121/1.393537
   ESCUDERO P, 2003, P 15 INT C PHON SCI, P861
   Everdell IT, 2007, PERCEPTION, V36, P1535, DOI 10.1068/p5852
   Fowler C. A., 2004, HDB MULTISENSORY PRO, P189
   FOWLER CA, 1990, J ACOUST SOC AM, V88, P1236, DOI 10.1121/1.399701
   FOWLER CA, 1990, J EXP PSYCHOL HUMAN, V16, P742, DOI 10.1037/0096-1523.16.4.742
   GILMORE GC, 1979, PERCEPT PSYCHOPHYS, V25, P425, DOI 10.3758/BF03199852
   Green JR, 2010, J SPEECH LANG HEAR R, V53, P1529, DOI 10.1044/1092-4388(2010/09-0005)
   GRIER JB, 1971, PSYCHOL BULL, V75, P424, DOI 10.1037/h0031246
   Guellai B, 2016, J EXP PSYCHOL HUMAN, V42, P1275, DOI 10.1037/xhp0000208
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Irwin JR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00397
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Jordan TR, 1997, J EXP PSYCHOL HUMAN, V23, P388, DOI 10.1037/0096-1523.23.2.388
   Kalashnikova M, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170306
   Kent R.D, 2002, ACOUSTIC ANAL SPEECH
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lucero JC, 2005, J ACOUST SOC AM, V118, P405, DOI 10.1121/1.1928807
   Lucero JC, 1999, J ACOUST SOC AM, V106, P2834, DOI 10.1121/1.428108
   MacLeod AAN, 2009, J PHONETICS, V37, P374, DOI 10.1016/j.wocn.2009.07.001
   MacMillan N. A., 2005, DETECTION THEORY USE
   MANN VA, 1986, COGNITION, V24, P169, DOI 10.1016/S0010-0277(86)80001-4
   Masapollo M, 2017, COGNITION, V166, P358, DOI 10.1016/j.cognition.2017.06.001
   Masapollo M, 2017, J ACOUST SOC AM, V141, P2857, DOI 10.1121/1.4981006
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Munhall K.G., 2004, HDB MULTISENSORY PRO, P177
   Munhall KG, 2002, NEUROREPORT, V13, P1793, DOI 10.1097/00001756-200210070-00020
   Noiray A, 2011, J ACOUST SOC AM, V129, P340, DOI 10.1121/1.3518452
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   R Core Team, 2017, R LANGUAGE ENV STAT
   Rosenblum L. D., 1998, ADV PSYCHOL SPEECHRE, P61
   Rosenblum LD, 2005, BLACKW HBK LINGUIST, P51, DOI 10.1002/9780470757024.ch3
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Rosenblum LD, 2000, J EXP PSYCHOL HUMAN, V26, P806, DOI 10.1037//0096-1523.26.2.806
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Schwartz JL, 2005, SPEECH COMMUN, V45, P425, DOI 10.1016/j.specom.2004.12.001
   SCHWARTZ JL, 1989, SPEECH COMMUN, V8, P235, DOI 10.1016/0167-6393(89)90004-6
   Shochi T., 2009, INT C AUD VIS SPEECH
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Sundara M, 2001, NEUROREPORT, V12, P1341, DOI 10.1097/00001756-200105250-00010
   Tsuji S, 2017, INTERSPEECH, P2108, DOI 10.21437/Interspeech.2017-1468
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Vatikiotis-Bateson E., 1996, SPEECHREADING HUMANS, P221, DOI DOI 10.1007/978-3-662-13015-5_16
   VatikiotisBateson E, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1485, DOI 10.1109/ICSLP.1996.607897
   Venezia JH, 2016, NEUROIMAGE, V126, P196, DOI 10.1016/j.neuroimage.2015.11.038
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 72
TC 3
Z9 4
U1 0
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD JUL
PY 2018
VL 44
IS 7
BP 1103
EP 1118
DI 10.1037/xhp0000518
PG 16
WC Psychology; Psychology, Experimental
SC Psychology
GA GM1OU
UT WOS:000437839600009
PM 29517257
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Goldblat, E
   Most, T
AF Goldblat, Ester
   Most, Tova
TI Cultural Identity of Young Deaf Adults with Cochlear Implants in
   Comparison to Deaf without Cochlear Implants and Hard-of-Hearing Young
   Adults
SO JOURNAL OF DEAF STUDIES AND DEAF EDUCATION
LA English
DT Article
ID SPEECH-PERCEPTION; EDUCATIONAL-EXPERIENCES; CHILDREN; ADOLESCENTS;
   ACCULTURATION; PEOPLE; SCHOOL; INTELLIGIBILITY; COMMUNICATION;
   PERFORMANCE
AB This study examined the relationships between cultural identity, severity of hearing loss (HL), and the use of a cochlear implant (CI). One hundred and forty-one adolescents and young adults divided into three groups (deaf with CI, deaf without CI, and hard-of-hearing (HH)) and 134 parents participated. Adolescents and young adults completed questionnaires on cultural identity (hearing, Deaf, marginal, bicultural-hearing, and bicultural-deaf) and communication proficiencies (hearing, spoken language, and sign language). Parents completed a speech quality questionnaire. Deaf participants without CI and those with CI differed in all identities except marginal identity. CI users and HH participants had similar identities except for a stronger bicultural-deaf identity among CI users. Three clusters of participants evolved: participants with a dominant bicultural-deaf identity, participants with a dominant bicultural-hearing identity and participants without a formed cultural identity. Adolescents and young adults who were proficient in one of the modes of communication developed well-established bicultural identities. Adolescents and young adults who were not proficient in one of the modes of communication did not develop a distinguished cultural identity. These results suggest that communication proficiencies are crucial for developing defined identities.
C1 [Goldblat, Ester; Most, Tova] Tel Aviv Univ, Tel Aviv, Israel.
RP Goldblat, E (corresponding author), POB 118, IL-7194500 Halamish, Israel.
EM stgoldblat@gmail.com
CR ANDERSON JC, 1988, PSYCHOL BULL, V103, P411, DOI 10.1037/0033-2909.103.3.411
   Bat-Chava Y, 2000, AM ANN DEAF, V145, P420, DOI 10.1353/aad.2012.0176
   Bat-Chava Y., 2001, J DEAF STUD DEAF EDU, V6, P186, DOI [10.1093/deafed/6.3.186, DOI 10.1093/DEAFED/6.3.186]
   Baudonck N, 2010, INT J PEDIATR OTORHI, V74, P310, DOI [10.1016/ijporl.201.08.011, DOI 10.1016/IJPORL.201.08.011]
   Baudonck N, 2010, INT J PEDIATR OTORHI, V74, P416, DOI 10.1016/j.ijporl.2010.01.017
   Beadreault P, 2006, THESIS
   Berlin C. I, 2009, HDB CLIN AUDIOLOGY, P529
   Black Jane, 2011, Cochlear Implants Int, V12, P67, DOI 10.1179/146701010X486417
   Byrnes LJ, 2001, AM ANN DEAF, V146, P409, DOI 10.1353/aad.2012.0212
   Cote JE, 1996, J ADOLESCENCE, V19, P417, DOI 10.1006/jado.1996.0040
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   El-Hakim H, 2001, INT J PEDIATR OTORHI, V59, P187, DOI 10.1016/S0165-5876(01)00481-5
   Eriks-Brophy A, 2012, VOLTA REV, V112, P5, DOI 10.17955/tvr.112.1.694
   Fischer LC, 2001, J COUNS PSYCHOL, V48, P355, DOI 10.1037/0022-0167.48.3.355
   Fitzpatrick Elizabeth M, 2012, Cochlear Implants Int, V13, P5, DOI 10.1179/146701011X12950038111611
   Gantz BJ, 2000, ANN OTO RHINOL LARYN, V109, P33
   Giezen MR, 2010, J SPEECH LANG HEAR R, V53, P1440, DOI 10.1044/1092-4388(2010/09-0252)
   Glickman N. S, 1993, THESIS
   GLICKMAN NS, 1993, REHABIL PSYCHOL, V38, P275, DOI 10.1037/0090-5550.38.4.275
   Grotevant H. D., 1987, J ADOLESCENT RES, V2, P203, DOI [DOI 10.1177/074355488723003, 10.1177/074355488723003]
   Harrison RV, 2005, DEV PSYCHOBIOL, V46, P252, DOI 10.1002/dev.20052
   Hauser P. C., 2006, NEURODEVELOPMENTAL D, P119
   Hilton K, 2013, J DEAF STUD DEAF EDU, V18, P513, DOI 10.1093/deafed/ent025
   Hintermair M, 2005, J DEAF STUD DEAF EDU, V10, P184, DOI 10.1093/deafed/eni018
   Hintermair M, 2008, J DEAF STUD DEAF EDU, V13, P278, DOI 10.1093/deafed/enm054
   Holcomb TK, 1997, AM ANN DEAF, V142, P89, DOI 10.1353/aad.2012.0728
   Israelite N., 2002, J DEAF STUD DEAF EDU, V7, P134, DOI DOI 10.1093/DEAFED/7.2.134
   Kent B, 2006, J DEAF STUD DEAF EDU, V11, P461, DOI 10.1093/deafed/enj044
   Kishon-Rabin L, 2002, ANN OTO RHINOL LARYN, V111, P85
   Kobosko Joanna, 2010, Cochlear Implants Int, V11 Suppl 1, P319, DOI 10.1179/146701010X12671177989552
   Law ZWY, 2006, J SPEECH LANG HEAR R, V49, P1342, DOI 10.1044/1092-4388(2006/096)
   Lederberg AR, 2013, DEV PSYCHOL, V49, P15, DOI 10.1037/a0029558
   Leigh I, 1998, J Deaf Stud Deaf Educ, V3, P329
   Leigh IW, 2009, J DEAF STUD DEAF EDU, V14, P244, DOI 10.1093/deafed/enn038
   Leigh IW, 2009, LENS DEAF IDENTITIES
   Martin D, 2011, J DEAF STUD DEAF EDU, V16, P108, DOI 10.1093/deafed/enq037
   McIlroy G, 2011, J DEAF STUD DEAF EDU, V16, P494, DOI 10.1093/deafed/enr017
   Meadow-Orlans K. P., 2003, PARENTS THEIR DEAF C
   Meyer TA, 2000, ANN OTO RHINOL LARYN, V109, P49
   Mildner V, 2006, CLIN LINGUIST PHONET, V20, P219, DOI 10.1080/02699200400027031
   Mitchell Ross, 2004, SIGN LANGUAGE STUDIE, V4, P138, DOI DOI 10.1353/SLS.2004.0005
   Moog J. S, 2011, EAR HEARING, V32, P755, DOI [10.1097/AUD.0b013e3182104c76, DOI 10.1097/AUD.0B013E3182104C76]
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P495, DOI 10.1093/deafed/enm015
   Most T, 2007, DEAF EDUC INT, V9, P68, DOI 10.1002/dei.207
   Murray JB, 2007, OTJR-OCCUP PART HEAL, V27, P113, DOI 10.1177/153944920702700305
   Najarian CG, 2008, DISABIL SOC, V23, P117, DOI 10.1080/09687590701841141
   Nikolaraizi M, 2006, J DEAF STUD DEAF EDU, V11, P477, DOI 10.1093/deafed/enl003
   O'Donoghue GM, 1999, EAR HEARING, V20, P419, DOI 10.1097/00003446-199910000-00005
   Obasi C, 2008, J DEAF STUD DEAF EDU, V13, P455, DOI 10.1093/deafed/enn008
   Oh SH, 2003, ACTA OTO-LARYNGOL, V123, P148, DOI 10.1080/0036554021000028111
   Olson A. D, 2006, ASHA LEADER, V11, P18, DOI [10.1044/leader.FTR1.11132006/5, DOI 10.1044/LEADER.FTR1.11132006/5]
   Plaut A, 2007, HIST ED SETTINGS STU, P53
   Pulsifer MB, 2003, ARCH PEDIAT ADOL MED, V157, P552, DOI 10.1001/archpedi.157.6.552
   Punch R, 2007, J DEAF STUD DEAF EDU, V12, P504, DOI 10.1093/deafed/enm011
   Rich S, 2013, INT J PEDIATR OTORHI, V77, P1337, DOI 10.1016/j.ijporl.2013.05.029
   Sari H, 2005, DEAF EDUC INT, V7, P206, DOI 10.1002/dei.9
   Schwartz SJ, 2011, J COUNS PSYCHOL, V58, P27, DOI 10.1037/a0021356
   Schwartz SJ, 2010, AM PSYCHOL, V65, P237, DOI 10.1037/a0019330
   Schwartz SJ, 2007, CULT DIVERS ETHN MIN, V13, P364, DOI 10.1037/1099-9809.13.4.364
   Schwartz SJ, 2008, SOC PERSONAL PSYCHOL, V2, P635, DOI 10.1111/j.1751-9004.2008.00077.x
   Schwartz SJ, 2006, HUM DEV, V49, P1, DOI 10.1159/000090300
   Silman S, 1991, AUDITORY DIAGNOSIS P, P10
   Smiler K, 2007, J DEAF STUD DEAF EDU, V12, P93, DOI 10.1093/deafed/enl023
   Spahn Claudia, 2004, Cochlear Implants Int, V5, P13, DOI 10.1002/cii.120
   Spencer LJ, 2012, J DEAF STUD DEAF EDU, V17, P483, DOI 10.1093/deafed/ens024
   Spencer P. E., 2011, OXFORD HDB DEAF STUD, P452, DOI DOI 10.1093/0XF0RDHB/9780199750986.013.0032
   Tavakol M, 2011, INT J MED EDUC, V2, P53, DOI 10.5116/ijme.4dfb.8dfd
   Taylor G, 1999, DISABIL SOC, V14, P369, DOI 10.1080/09687599926208
   Thibodeau L, 2010, Z GANZHEITL TIERMED, V31, P47, DOI 10.1055/s-0029-1246324
   Thoutenhoofd E, 2006, J DEAF STUD DEAF EDU, V11, P171, DOI 10.1093/deafed/enj029
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   Van Lierde KM, 2005, INT J AUDIOL, V44, P452, DOI 10.1080/14992020500189146
   Wald RL, 2000, ANN OTO RHINOL LARYN, V109, P87
   Warner-Czyz Andrea D, 2013, Cochlear Implants Int, V14, P266, DOI 10.1179/1754762812Y.0000000021
   Wheeler A, 2007, J DEAF STUD DEAF EDU, V12, P303, DOI 10.1093/deafed/enm018
   Woolfe T., 2001, DEAFNESS ED INT, V3, P80, DOI [10.1002/dei.100, DOI 10.1002/DEI.100]
NR 76
TC 3
Z9 4
U1 3
U2 14
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1081-4159
EI 1465-7325
J9 J DEAF STUD DEAF EDU
JI J. Deaf Stud. Deaf Educ.
PD JUL
PY 2018
VL 23
IS 3
BP 228
EP 239
DI 10.1093/deafed/eny007
PG 12
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA GL5BG
UT WOS:000437176600005
PM 29562365
OA Bronze
DA 2021-02-24
ER

PT J
AU Eisenberg, LS
   Ganguly, DH
   Martinez, AS
   Fisher, LM
   Winter, ME
   Glater, JL
   Schrader, DK
   Loggins, J
   Wilkinson, EP
AF Eisenberg, Laurie S.
   Ganguly, Dianne Hammes
   Martinez, Amy S.
   Fisher, Laurel M.
   Winter, Margaret E.
   Glater, Jamie L.
   Schrader, Debra K.
   Loggins, Janice
   Wilkinson, Eric P.
CA Los Angeles Pediatric ABI Team
TI Early Communication Development of Children with Auditory Brainstem
   Implants
SO JOURNAL OF DEAF STUDIES AND DEAF EDUCATION
LA English
DT Article
ID HEARING-IMPAIRED CHILDREN; SET SPEECH RECOGNITION; COCHLEAR
   IMPLANTATION; LANGUAGE-DEVELOPMENT; NERVE APLASIA; SPOKEN WORD;
   OUTCOMES; INTELLIGIBILITY; PERCEPTION; INFANTS
AB The auditory brainstem implant (ABI) is an auditory sensory device that is surgically placed on the cochlear nucleus of the brainstem for individuals who are deaf but unable to benefit from a cochlear implant (CI) due to anatomical abnormalities of the cochlea and/or eighth nerve, specific disease processes, or temporal bone fractures. In the United States, the Food and Drug Administration has authorized a Phase I clinical trial to determine safety and feasibility of the ABI in up to 10 eligible young children who are deaf and either derived no benefit from the CI or were anatomically unable to receive a CI. In this paper, we describe the study protocol and the children who have enrolled in the study thus far. In addition, we report the scores on speech perception, speech production, and language (spoken and signed) for five children with 1-3 years of assessment post-ABI activation. To date, the results indicate that spoken communication skills are slow to develop and that visual communication remains essential for post-ABI intervention.
C1 [Eisenberg, Laurie S.; Ganguly, Dianne Hammes; Martinez, Amy S.; Fisher, Laurel M.; Winter, Margaret E.; Glater, Jamie L.; Schrader, Debra K.; Loggins, Janice; Wilkinson, Eric P.; Los Angeles Pediatric ABI Team] Univ Southern Calif, Keck Sch Med, Los Angeles, CA USA.
RP Eisenberg, LS (corresponding author), Caruso Family Ctr Childhood Commun, 806 W Adams Blvd, Los Angeles, CA 90007 USA.
EM laurie.eisenberg@med.usc.edu
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [U01DC013031];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [U01DC013031] Funding Source: NIH
   RePORTER
FX This work is supported by the National Institute on Deafness and Other
   Communication Disorders of the National Institutes of Health
   [U01DC013031]. The ABI devices are donated by Cochlear Americas. This
   study is conducted under IDE G120194, University of Southern California,
   ClinicalTrials.gov: NCT02102256.
CR Aaron K. A, 2016, CLIN MANAGEMENT CHIL, P69
   Barnard JM, 2015, OTOL NEUROTOL, V36, P985, DOI 10.1097/MAO.0000000000000723
   Beraneck M, 2014, DEV AUDITORY VESTIBU, P449, DOI DOI 10.1016/B978-0-12-408088-1.00015-4
   BERLINER KI, 1989, EAR HEARING, V10, P237, DOI 10.1097/00003446-198908000-00005
   Birman CS, 2016, OTOL NEUROTOL, V37, P438, DOI 10.1097/MAO.0000000000000997
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Brown C, 1999, ANN OTO RHINOL LARYN, V108, P110
   Buchman CA, 2011, LARYNGOSCOPE, V121, P1979, DOI 10.1002/lary.22032
   Colletti L, 2014, AUDIOL NEURO-OTOL, V19, P386, DOI 10.1159/000363684
   Colletti V, 2005, OTOLARYNG HEAD NECK, V133, P126, DOI 10.1016/j.otohns.2005.03.022
   Colletti V, 2002, OTOL NEUROTOL, V23, P682, DOI 10.1097/00129492-200209000-00014
   Cruz I, 2012, OTOL NEUROTOL, V33, P751, DOI 10.1097/MAO.0b013e3182595309
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   EDGERTON BJ, 1982, ANN OTO RHINOL LARYN, V91, P117
   Eisenberg LS, 2012, J AM ACAD AUDIOL, V23, P412, DOI 10.3766/jaaa.23.6.4
   Fagan MK, 2015, J EXP CHILD PSYCHOL, V137, P125, DOI 10.1016/j.jecp.2015.04.005
   Fisher LM, 2015, THER INNOV REGUL SCI, V49, P659, DOI 10.1177/2168479015599559
   Flipsen P, 2006, J COMMUN DISORD, V39, P93, DOI 10.1016/j.jcomdis.2005.11.001
   GEERS AE, 1988, AM J OTOL, V9, P169
   Geers AE, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-3489
   Giezen MR, 2014, J DEAF STUD DEAF EDU, V19, P107, DOI 10.1093/deafed/ent040
   Iverson JM, 2010, J CHILD LANG, V37, P229, DOI 10.1017/S0305000909990432
   JERGER S, 1980, INT J PEDIATR OTORHI, V2, P217, DOI 10.1016/0165-5876(80)90047-6
   Johnson K. C, 2016, CLIN MANAGEMENT CHIL, P737
   Kaplan AB, 2015, INT J PEDIATR OTORHI, V79, P310, DOI 10.1016/j.ijporl.2014.11.023
   Karasik LB, 2011, CHILD DEV, V82, P1199, DOI 10.1111/j.1467-8624.2011.01595.x
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   Moeller MP, 2007, EAR HEARING, V28, P605, DOI 10.1097/AUD.0b013e31812564ab
   Moog J.S., 1990, EARLY SPEECH PERCEPT
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Noij KS, 2015, OTOLARYNG HEAD NECK, V153, P739, DOI 10.1177/0194599815596929
   Paden E, 1992, IDENTIFYING EARLY PH
   Puram SV, 2016, OTOLARYNG HEAD NECK, V155, P133, DOI 10.1177/0194599816637599
   ROBBINS AM, 1991, AM J OTOL, V12, P144
   Sennaroglu L, 2016, OTOL NEUROTOL, V37, P865, DOI 10.1097/MAO.0000000000001050
   Shannon RV, 2015, HEARING RES, V322, P57, DOI 10.1016/j.heares.2014.11.003
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Teagle HFB, 2018, EAR HEARING, V39, P326, DOI 10.1097/AUD.0000000000000501
   Thielemeir M A, 1985, Ear Hear, V6, p27S, DOI 10.1097/00003446-198505001-00007
   Trammell J, 1981, TEST AUDITORY COMPRE
   Wilkinson EP, 2017, OTOL NEUROTOL, V38, P212, DOI 10.1097/MAO.0000000000001287
   Young NM, 2012, INT J PEDIATR OTORHI, V76, P1442, DOI 10.1016/j.ijporl.2012.06.019
   Zimmerman I. L., 2011, PRESCHOOL LANGUAGE S
   Zimmerman-Phillips S, 2000, ANN OTO RHINOL LARYN, V109, P42
NR 44
TC 7
Z9 7
U1 0
U2 6
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1081-4159
EI 1465-7325
J9 J DEAF STUD DEAF EDU
JI J. Deaf Stud. Deaf Educ.
PD JUL
PY 2018
VL 23
IS 3
BP 249
EP 260
DI 10.1093/deafed/eny010
PG 12
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA GL5BG
UT WOS:000437176600007
PM 29718280
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Adank, P
   Nuttall, H
   Bekkering, H
   Maegherman, G
AF Adank, Patti
   Nuttall, Helen
   Bekkering, Harold
   Maegherman, Gwijde
TI Effects of stimulus response compatibility on covert imitation of vowels
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Speech production; Multisensory processing
ID SPEECH DISTORTION; PERCEPTION; DISCRIMINATION; EXCITABILITY; CONSONANTS;
   FEATURES
AB When we observe someone else speaking, we tend to automatically activate the corresponding speech motor patterns. When listening, we therefore covertly imitate the observed speech. Simulation theories of speech perception propose that covert imitation of speech motor patterns supports speech perception. Covert imitation of speech has been studied with interference paradigms, including the stimulus-response compatibility paradigm (SRC). The SRC paradigm measures covert imitation by comparing articulation of a prompt following exposure to a distracter. Responses tend to be faster for congruent than for incongruent distracters; thus, showing evidence of covert imitation. Simulation accounts propose a key role for covert imitation in speech perception. However, covert imitation has thus far only been demonstrated for a select class of speech sounds, namely consonants, and it is unclear whether covert imitation extends to vowels. We aimed to demonstrate that covert imitation effects as measured with the SRC paradigm extend to vowels, in two experiments. We examined whether covert imitation occurs for vowels in a consonant-vowel-consonant context in visual, audio, and audiovisual modalities. We presented the prompt at four time points to examine how covert imitation varied over the distracter's duration. The results of both experiments clearly demonstrated covert imitation effects for vowels, thus supporting simulation theories of speech perception. Covert imitation was not affected by stimulus modality and was maximal for later time points.
C1 [Adank, Patti; Nuttall, Helen; Maegherman, Gwijde] UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
   [Nuttall, Helen] Univ Lancaster, Dept Psychol, Lancaster LA1 4YF, England.
   [Bekkering, Harold] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Adank, P (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
EM p.adank@ucl.ac.uk
OI Maegherman, Gwijde/0000-0002-1068-5897; Nuttall,
   Helen/0000-0001-8497-5603
FU BIAL FoundationBial Foundation [267/14]
FX This work was supported by the BIAL Foundation under Grant No. 267/14 to
   P.A. We thank Dan Kennedy-Higgins and Flavia Bojescu for assistance in
   data collection.
CR Adank P, 2017, LANG COGN NEUROSCI, V32, P900, DOI 10.1080/23273798.2016.1257816
   Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Baayen R. H., 2008, DATA SETS FUNCTIONS
   Boatman D, 1997, CORTEX, V33, P83, DOI 10.1016/S0010-9452(97)80006-8
   BOATMAN DF, 1994, J NEUROLINGUIST, V8, P225, DOI 10.1016/0911-6044(94)90028-0
   BOERSMA P, 2003, PRAAT DOING PHONETIC
   Brass M, 2000, BRAIN COGNITION, V44, P124, DOI 10.1006/brcg.2000.1225
   Buccino G, 2004, J COGNITIVE NEUROSCI, V16, P114, DOI 10.1162/089892904322755601
   Caramazza A, 2000, NATURE, V403, P428, DOI 10.1038/35000206
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Galantucci B, 2009, ATTEN PERCEPT PSYCHO, V71, P1138, DOI 10.3758/APP.71.5.1138
   Gerrits E, 2004, PERCEPT PSYCHOPHYS, V66, P363, DOI 10.3758/BF03194885
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Heyes C, 2011, PSYCHOL BULL, V137, P463, DOI 10.1037/a0022288
   Jarick M, 2009, EXP BRAIN RES, V195, P175, DOI 10.1007/s00221-009-1765-x
   Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8
   Kerzel D, 2000, J EXP PSYCHOL HUMAN, V26, P634, DOI 10.1037//0096-1523.26.2.634
   LIBERMAN AM, 1981, PERCEPT PSYCHOPHYS, V30, P133, DOI 10.3758/BF03204471
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Nuttall HE, 2017, NEUROPSYCHOLOGIA, V94, P13, DOI 10.1016/j.neuropsychologia.2016.11.016
   Nuttall HE, 2016, NEUROIMAGE, V128, P218, DOI 10.1016/j.neuroimage.2015.12.038
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Roon KD, 2015, PSYCHON B REV, V22, P242, DOI 10.3758/s13423-014-0666-6
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Seifritz E, 2002, SCIENCE, V297, P1706, DOI 10.1126/science.1074355
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Traunmuller H, 2007, J PHONETICS, V35, P244, DOI 10.1016/j.wocn.2006.03.002
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Whalen DH, 1996, PERCEPT PSYCHOPHYS, V58, P857, DOI 10.3758/BF03205488
   Wilson M, 2005, PSYCHOL BULL, V131, P460, DOI 10.1037/0033-2909.131.3.460
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
NR 35
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JUL
PY 2018
VL 80
IS 5
BP 1290
EP 1299
DI 10.3758/s13414-018-1501-3
PG 10
WC Psychology; Psychology, Experimental
SC Psychology
GA GL7VA
UT WOS:000437412400023
PM 29536418
OA Green Published, Other Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Stilp, CE
   Assgari, AA
AF Stilp, Christian E.
   Assgari, Ashley A.
TI Perceptual sensitivity to spectral properties of earlier sounds during
   speech categorization
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Perceptual categorization and identification; Psychoacoustics; Speech
   perception
ID VOWEL IDENTIFICATION; AUDITORY ENHANCEMENT; NORMAL-HEARING; CONTRAST;
   COMPENSATION; CONTEXT; CALIBRATION; PEAKS
AB Speech perception is heavily influenced by surrounding sounds. When spectral properties differ between earlier (context) and later (target) sounds, this can produce spectral contrast effects (SCEs) that bias perception of later sounds. For example, when context sounds have more energy in low-F-1 frequency regions, listeners report more high-F-1 responses to a target vowel, and vice versa. SCEs have been reported using various approaches for a wide range of stimuli, but most often, large spectral peaks were added to the context to bias speech categorization. This obscures the lower limit of perceptual sensitivity to spectral properties of earlier sounds, i.e., when SCEs begin to bias speech categorization. Listeners categorized vowels (/E<feminine ordinal indicator>/-/E >/, Experiment 1) or consonants (/d/-/g/, Experiment 2) following a context sentence with little spectral amplification (+1 to +4 dB) in frequency regions known to produce SCEs. In both experiments, +3 and +4 dB amplification in key frequency regions of the context produced SCEs, but lesser amplification was insufficient to bias performance. This establishes a lower limit of perceptual sensitivity where spectral differences across sounds can bias subsequent speech categorization. These results are consistent with proposed adaptation-based mechanisms that potentially underlie SCEs in auditory perception.
   Recent sounds can change what speech sounds we hear later. This can occur when the average frequency composition of earlier sounds differs from that of later sounds, biasing how they are perceived. These "spectral contrast effects" are widely observed when sounds' frequency compositions differ substantially. We reveal the lower limit of these effects, as +3 dB amplification of key frequency regions in earlier sounds was enough to bias categorization of the following vowel or consonant sound. Speech categorization being biased by very small spectral differences across sounds suggests that spectral contrast effects occur frequently in everyday speech perception.
C1 [Stilp, Christian E.; Assgari, Ashley A.] Univ Louisville, Dept Psychol & Brain Sci, 317 Life Sci Bldg, Louisville, KY 40292 USA.
RP Stilp, CE (corresponding author), Univ Louisville, Dept Psychol & Brain Sci, 317 Life Sci Bldg, Louisville, KY 40292 USA.
EM christian.stilp@louisville.edu
CR Alexander JM, 2010, J ACOUST SOC AM, V128, P3597, DOI 10.1121/1.3500693
   Assgari A. A., 2016, J ACOUST SOC AM, V139, P2124
   Assgari AA, 2015, J ACOUST SOC AM, V138, P3023, DOI 10.1121/1.4934559
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Boersma P., 2014, PRAAT DOING PHONETIC
   Byrne AJ, 2011, J ACOUST SOC AM, V129, P2088, DOI 10.1121/1.3552880
   Carcagno S, 2012, JARO-J ASSOC RES OTO, V13, P693, DOI 10.1007/s10162-012-0339-y
   Delgutte B., 1996, P AUD BAS SPEECH PER
   Delgutte B., 1996, HDB PHONETIC SCI, P507
   Garofolo J, 1990, PB91505065 NIST
   Green D. M., 1988, PROFILE ANAL AUDITOR
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2002, HEARING RES, V167, P156, DOI 10.1016/S0378-5955(02)00383-0
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   LEA AP, 1994, PERCEPT PSYCHOPHYS, V56, P379, DOI 10.3758/BF03206730
   LEEK MR, 1987, J ACOUST SOC AM, V81, P148, DOI 10.1121/1.395024
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   LINDBLOM BE, 1967, J ACOUST SOC AM, V42, P830, DOI 10.1121/1.1910655
   Loizou PC, 2001, J ACOUST SOC AM, V110, P1619, DOI 10.1121/1.1388004
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Nelson PC, 2010, J NEUROSCI, V30, P6577, DOI 10.1523/JNEUROSCI.0277-10.2010
   R Development Core Team, 2016, R LANG ENV STAT COMP
   Sjerps MJ, 2018, J EXP PSYCHOL HUMAN, V44, P914, DOI 10.1037/xhp0000504
   Sjerps MJ, 2015, J EXP PSYCHOL HUMAN, V41, P710, DOI 10.1037/a0039028
   Sjerps MJ, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P394
   Sjerps MJ, 2013, J PHONETICS, V41, P145, DOI 10.1016/j.wocn.2013.01.005
   Sjerps MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P576, DOI 10.3758/s13414-012-0408-7
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Stephens JDW, 2011, SPEECH COMMUN, V53, P877, DOI 10.1016/j.specom.2011.02.007
   Stilp C. E., 2016, P M AC, V26, DOI [10.1121/2.0000233, DOI 10.1121/2.0000233]
   Stilp CE, 2017, J ACOUST SOC AM, V141, pEL153, DOI 10.1121/1.4974769
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Stilp CE, 2014, J ACOUST SOC AM, V136, pEL383, DOI 10.1121/1.4898741
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   SUMMERFIELD Q, 1984, PERCEPT PSYCHOPHYS, V35, P203, DOI 10.3758/BF03205933
   SUMMERFIELD Q, 1987, J ACOUST SOC AM, V81, P700, DOI 10.1121/1.394838
   VIEMEISTER NF, 1982, J ACOUST SOC AM, V71, P1502, DOI 10.1121/1.387849
   von Bekesy G., 1967, SENSORY PERCEPTION
   WARREN RM, 1985, PSYCHOL REV, V92, P574, DOI 10.1037/0033-295X.92.4.574
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WATKINS AJ, 1994, J ACOUST SOC AM, V96, P1263, DOI 10.1121/1.410275
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P3749, DOI 10.1121/1.414981
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
NR 49
TC 8
Z9 8
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JUL
PY 2018
VL 80
IS 5
BP 1300
EP 1310
DI 10.3758/s13414-018-1488-9
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA GL7VA
UT WOS:000437412400024
PM 29492759
OA Bronze
DA 2021-02-24
ER

PT J
AU Misic, B
   Betzel, RF
   Griffa, A
   de Reus, MA
   He, Y
   Zuo, XN
   van den Heuvel, MP
   Hagmann, P
   Sporns, O
   Zatorre, RJ
AF Misic, Bratislav
   Betzel, Richard F.
   Griffa, Alessandra
   de Reus, Marcel A.
   He, Ye
   Zuo, Xi-Nian
   van den Heuvel, Martijn P.
   Hagmann, Patric
   Sporns, Olaf
   Zatorre, Robert J.
TI Network-Based Asymmetry of the Human Auditory System
SO CEREBRAL CORTEX
LA English
DT Article
DE auditory; connectome; network; spreading
ID HUMAN CONNECTOME; HUMAN BRAIN; HEMISPHERIC-SPECIALIZATION;
   SPEECH-PERCEPTION; LANGUAGE PATHWAYS; DIFFUSION MRI; CORTEX;
   LATERALIZATION; DISTRIBUTIONS; TRACTOGRAPHY
AB Converging evidence from activation, connectivity, and stimulation studies suggests that auditory brain networks are lateralized. Here we show that these findings can be at least partly explained by the asymmetric network embedding of the primary auditory cortices. Using diffusion-weighted imaging in 3 independent datasets, we investigate the propensity for left and right auditory cortex to communicate with other brain areas by quantifying the centrality of the auditory network across a spectrum of communication mechanisms, from shortest path communication to diffusive spreading. Across all datasets, we find that the right auditory cortex is better integrated in the connectome, facilitating more efficient communication with other areas, with much of the asymmetry driven by differences in communication pathways to the opposite hemisphere. Critically, the primacy of the right auditory cortex emerges only when communication is conceptualized as a diffusive process, taking advantage of more than just the topologically shortest paths in the network. Altogether, these results highlight how the network configuration and embedding of a particular region may contribute to its functional lateralization.
C1 [Misic, Bratislav; Zatorre, Robert J.] McGill Univ, Montreal Neurol Inst, Montreal, PQ H3A 2B4, Canada.
   [Betzel, Richard F.] Univ Penn, Dept Bioengn, Philadelphia, PA 19104 USA.
   [Griffa, Alessandra; Hagmann, Patric] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS5 5, CH-1015 Lausanne, Switzerland.
   [Griffa, Alessandra; Hagmann, Patric] CHU Vaudois, Dept Radiol, CH-1011 Lausanne, Switzerland.
   [de Reus, Marcel A.; van den Heuvel, Martijn P.] UMC Utrecht, Brain Ctr Rudolf Magnus, NL-3584 CX Utrecht, Netherlands.
   [He, Ye; Zuo, Xi-Nian] Inst Psychol, CAS Key Lab Behav Sci, Beijing 100101, Peoples R China.
   [He, Ye; Sporns, Olaf] Indiana Univ, Dept Psychol & Brain Sci, Bloomington, IN 47405 USA.
RP Misic, B (corresponding author), McGill Univ, Montreal Neurol Inst, McConnell Brain Imaging Ctr, 3801 Rue Univ, Montreal, PQ H3A 2B4, Canada.; Zatorre, RJ (corresponding author), McGill Univ, Montreal Neurol Inst, 3801 Rue Univ, Montreal, PQ H3A 2B4, Canada.
EM bratislav.misic@mcgill.ca; robert.zatorre@mcgill.ca
RI Zuo, Xi-Nian/A-7273-2009; Sporns, Olaf/A-1667-2010
OI Zuo, Xi-Nian/0000-0001-9110-585X; Sporns, Olaf/0000-0001-7265-4036;
   Griffa, Alessandra/0000-0003-1923-1653
FU Canada First Research Excellence Fund; Natural Sciences and Engineering
   Research Council of Canada (NSERC)Natural Sciences and Engineering
   Research Council of Canada (NSERC) [017-04265]; Fonds de recherche du
   Quebec, SanteFonds de la Recherche en Sante du Quebec; Canadian
   Institutes of Health ResearchCanadian Institutes of Health Research
   (CIHR); Canada Fund for InnovationCanada Foundation for Innovation;
   National Basic Research (973) ProgramNational Basic Research Program of
   China [2015CB351702]; Natural Science Foundation of China (NSFC)National
   Natural Science Foundation of China (NSFC) [81471740]; Beijing Municipal
   Science and Tech Commission [Z161100002616023]; Major Project of
   National Social Science Foundation of China [14ZDB161]; NSFC Major Joint
   Fund for International Cooperation and Exchange [81220108014]
FX This research was undertaken thanks in part to funding from the Canada
   First Research Excellence Fund, awarded to McGill University for the
   Healthy Brains for Healthy LIves initiative. B.M. acknowledges support
   from the Natural Sciences and Engineering Research Council of Canada
   (NSERC Discovery Grant RGPIN #017-04265) and from the Fonds de recherche
   du Quebec, Sante. R.Z. is supported by funding from the Canadian
   Institutes of Health Research and the Canada Fund for Innovation. X.N.Z.
   was supported by grants from the National Basic Research (973) Program
   (2015CB351702), the Natural Science Foundation of China (NSFC 81471740),
   Beijing Municipal Science and Tech Commission (Z161100002616023), and
   the Major Project of National Social Science Foundation of China
   (14ZDB161). X.N.Z. and O.S. are members of an international
   collaboration team supported by the NSFC Major Joint Fund for
   International Cooperation and Exchange (81220108014).
CR Andoh J, 2015, J NEUROSCI, V35, P14602, DOI 10.1523/JNEUROSCI.2333-15.2015
   Andoh J, 2013, NEUROIMAGE, V79, P162, DOI 10.1016/j.neuroimage.2013.04.078
   Andreotti J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115503
   Avena-Koenigsberger A, 2018, NAT REV NEUROSCI, V19, P17, DOI 10.1038/nrn.2017.149
   Avena-Koenigsberger A, 2017, BRAIN STRUCT FUNCT, V222, P603, DOI 10.1007/s00429-016-1238-5
   Betzel RF, 2017, NEUROIMAGE, V160, P73, DOI 10.1016/j.neuroimage.2016.11.006
   Betzel RF, 2016, SCI REP-UK, V6, DOI 10.1038/srep30770
   Betzel RF, 2016, NEUROIMAGE, V124, P1054, DOI 10.1016/j.neuroimage.2015.09.041
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   BRADSHAW JL, 1981, BEHAV BRAIN SCI, V4, P51, DOI 10.1017/S0140525X00007548
   Cammoun L, 2015, BRAIN STRUCT FUNCT, V220, P3537, DOI 10.1007/s00429-014-0872-z
   Cammoun L, 2012, J NEUROSCI METH, V203, P386, DOI 10.1016/j.jneumeth.2011.09.031
   Catani M, 2007, P NATL ACAD SCI USA, V104, P17163, DOI 10.1073/pnas.0702116104
   Cha K, 2016, CEREB CORTEX, V26, P211, DOI 10.1093/cercor/bhu193
   Cocchi L, 2016, ELIFE, V5, DOI 10.7554/eLife.15252
   Cole MW, 2016, NAT NEUROSCI, V19, P1718, DOI 10.1038/nn.4406
   Corballis MC, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01021
   Crofts JJ, 2011, NEUROIMAGE, V54, P161, DOI 10.1016/j.neuroimage.2010.08.032
   Crofts JJ, 2009, J R SOC INTERFACE, V6, P411, DOI 10.1098/rsif.2008.0484
   de Reus MA, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00647
   de Reus MA, 2013, NEUROIMAGE, V70, P402, DOI 10.1016/j.neuroimage.2012.12.066
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Estrada E, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.036111
   Fornito A., 2016, FUNDAMENTALS BRAIN N
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Goni J, 2014, P NATL ACAD SCI USA, V111, P833, DOI 10.1073/pnas.1315529111
   Good CD, 2001, NEUROIMAGE, V14, P685, DOI 10.1006/nimg.2001.0857
   Gotts SJ, 2013, P NATL ACAD SCI USA, V110, pE3435, DOI 10.1073/pnas.1302581110
   Graham DJ, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00044
   GRANOVETTER M, 1978, AM J SOCIOL, V83, P1420, DOI 10.1086/226707
   Grayson DS, 2016, NEURON, V91, P453, DOI 10.1016/j.neuron.2016.06.005
   Gu S, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9414
   Hutsler J, 2003, TRENDS NEUROSCI, V26, P429, DOI 10.1016/S0166-2236(03)00198-X
   Iturria-Medina Y, 2011, CEREB CORTEX, V21, P56, DOI 10.1093/cercor/bhq058
   Jones DK, 2013, NEUROIMAGE, V73, P239, DOI 10.1016/j.neuroimage.2012.06.081
   Kaiser Marcus, 2010, Front Neuroinform, V4, P8, DOI 10.3389/fninf.2010.00008
   Lichtman JW, 2011, SCIENCE, V334, P618, DOI 10.1126/science.1209168
   Liu HS, 2009, P NATL ACAD SCI USA, V106, P20499, DOI 10.1073/pnas.0908073106
   Maier-Hein KH, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01285-x
   Marie D, 2015, BRAIN STRUCT FUNCT, V220, P729, DOI 10.1007/s00429-013-0680-x
   Meyer M, 2014, CEREB CORTEX, V24, P2541, DOI 10.1093/cercor/bht094
   Misic B, 2016, CEREB CORTEX, V26, P3285, DOI 10.1093/cercor/bhw089
   Misic B, 2015, NEURON, V86, P1518, DOI 10.1016/j.neuron.2015.05.035
   Misic B, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003982
   Misic B, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003427
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   Nematzadeh A, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.088701
   Nooner KB, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00152
   O'Dea R, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0016
   Parker GJM, 2005, NEUROIMAGE, V24, P656, DOI 10.1016/j.neuroimage.2004.08.047
   Penhune VB, 1996, CEREB CORTEX, V6, P661, DOI 10.1093/cercor/6.5.661
   RINGO JL, 1994, CEREB CORTEX, V4, P331, DOI 10.1093/cercor/4.4.331
   Roberts JA, 2017, NEUROIMAGE, V145, P118, DOI 10.1016/j.neuroimage.2016.09.053
   Schneider P, 2005, NAT NEUROSCI, V8, P1241, DOI 10.1038/nn1530
   SELDON HL, 1981, BRAIN RES, V229, P277, DOI 10.1016/0006-8993(81)90994-X
   SELDON HL, 1982, BRAIN RES, V249, P211, DOI 10.1016/0006-8993(82)90055-5
   SELDON HL, 1981, BRAIN RES, V229, P295, DOI 10.1016/0006-8993(81)90995-1
   SEMMES J, 1968, NEUROPSYCHOLOGIA, V6, P11, DOI 10.1016/0028-3932(68)90035-3
   Spiegler A, 2016, ENEURO, V3, DOI 10.1523/ENEURO.0068-16.2016
   Thiebaut de Schotten M, 2011, NEUROIMAGE, V54, P49, DOI 10.1016/j.neuroimage.2010.07.055
   Thomas C, 2014, P NATL ACAD SCI USA, V111, P16574, DOI 10.1073/pnas.1405672111
   Tomasi D, 2012, HUM BRAIN MAPP, V33, P849, DOI 10.1002/hbm.21252
   Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041
   Watts DJ, 2002, P NATL ACAD SCI USA, V99, P5766, DOI 10.1073/pnas.082090499
   WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269
   Yeh FC, 2010, IEEE T MED IMAGING, V29, P1626, DOI 10.1109/TMI.2010.2045126
   Zalesky A, 2016, NEUROIMAGE, V142, P397, DOI 10.1016/j.neuroimage.2016.06.035
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 70
TC 13
Z9 13
U1 1
U2 11
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD JUL
PY 2018
VL 28
IS 7
BP 2655
EP 2664
DI 10.1093/cercor/bhy101
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA GL4XX
UT WOS:000437165800035
PM 29722805
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bressmann, T
   Radovanovic, B
   Harper, S
   Klaiman, P
   Fisher, D
   Kulkarni, GV
AF Bressmann, Tim
   Radovanovic, Bojana
   Harper, Susan
   Klaiman, Paula
   Fisher, David
   Kulkarni, Gajanan V.
TI Production of Two Nasal Sounds by Speakers With Cleft Palate
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
LA English
DT Article
DE aerodynamics; speech development; speech disorders; speech perception;
   speech production
ID COMPENSATORY ARTICULATIONS; SPEECH; CHILDREN; CONTACT; ADULTS;
   INDIVIDUALS; ADOLESCENTS; PATTERNS; VOWELS
AB Many speakers with cleft palate develop atypical consonant productions, especially for pressure consonants such as plosives, fricatives, and affricates. The present study investigated the nature of nasal sound errors. The participants were eight female and three male speakers with cleft palate between the ages of 6 to 20. Speakers were audio-recorded, and midsagittal tongue movement was captured with ultrasound. The speakers repeated vowel-consonant-vowel with the vowels /u/, and /eta/. the alveolar and velar nasal consonants /alpha/, /i/and /u/. The productions were reviewed by three listeners. The participants showed a variety of different placement errors and insertions of plosives, as well as liquid productions. There was considerable error variability between and within speakers, often related to the different vowel contexts. Three speakers co-produced click sounds. The study demonstrated the wide variety of sound errors that some speakers with cleft palate may demonstrate for nasal sounds. Nasal sounds, ideally in different vowel contexts, should be included in articulation screenings for speakers with cleft palate, perhaps more than is currently the case.
C1 [Bressmann, Tim; Radovanovic, Bojana; Harper, Susan] Univ Toronto, Dept Speech Language Pathol, 160-500 Univ Ave, Toronto, ON M5G 1V7, Canada.
   [Klaiman, Paula] Hosp Sick Children, Dept Plast Surg, Toronto, ON, Canada.
   [Fisher, David] Hosp Sick Children, Cleft Lip & Palate Program, Toronto, ON, Canada.
   [Kulkarni, Gajanan V.] Univ Toronto, Fac Dent, Toronto, ON, Canada.
RP Bressmann, T (corresponding author), Univ Toronto, Dept Speech Language Pathol, 160-500 Univ Ave, Toronto, ON M5G 1V7, Canada.
EM tim.bressmann@utoronto.ca
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [485680]
FX This research was funded by the Canadian Institutes of Health Research
   (operating grant fund number 485680). The authors would like to thank
   Ms. Christina Khaouli-Tannous and Ms. Liya Khait for their help with the
   recordings.
CR Cheng HY, 2007, J SPEECH LANG HEAR R, V50, P375, DOI 10.1044/1092-4388(2007/027)
   COLE RA, 1979, J ACOUST SOC AM, V65, pS81, DOI 10.1121/1.2017457
   Gibbon F, 2005, FOLIA PHONIATR LOGO, V57, P181, DOI 10.1159/000085186
   Gibbon F, 2004, CLIN LINGUIST PHONET, V18, P285, DOI 10.1080/02699200410001663362
   Gibbon F, 2008, CLEFT PALATE-CRAN J, V45, P381, DOI 10.1597/06-232.1
   Gooch JL, 2001, CLEFT PALATE-CRAN J, V38, P59, DOI 10.1597/1545-1569(2001)038<0059:ROLTOC>2.0.CO;2
   Harding A, 1998, INT J LANG COMM DIS, V33, P329
   Howard SJ, 2002, CLIN LINGUIST PHONET, V16, P371, DOI 10.1080/02699200210135893
   Kent R. D., 1996, AM J SPEECH LANG PAT, V5, P7, DOI [DOI 10.1044/1058-0360.0503.07, 10.1044/1058- 0360.0503.07]
   Kummer AW, 2008, CLEFT PALATE CRANIOF
   Lewis KE, 2000, CLEFT PALATE-CRAN J, V37, P584, DOI 10.1597/1545-1569(2000)037<0584:TEOVON>2.0.CO;2
   McLeod S, 2006, CLIN LINGUIST PHONET, V20, P99, DOI 10.1080/02699200400026496
   MCWILLIAMS BJ, 1958, J SPEECH HEAR RES, V1, P68, DOI 10.1044/jshr.0101.68
   Peterson-Falzone SJ, 2001, CLEFT PALATE SPEECH
   PETERSONFALZONE S, 2006, TREATING CLEFT PALAT
   Philips B J, 1969, Cleft Palate J, V6, P245
   Rastadmehr O, 2008, HEAD NECK-J SCI SPEC, V30, P718, DOI 10.1002/hed.20772
   Rogers Henry, 2000, SOUNDS LANGUAGE
   SPRIESTERSBACH DC, 1956, J SPEECH HEAR DISORD, V21, P436, DOI 10.1044/jshd.2104.436
   TROST JE, 1981, CLEFT PALATE J, V18, P193
   Van Demark D R, 1969, Cleft Palate J, V6, P254
   WARREN DW, 1986, CLEFT PALATE J, V23, P251
NR 22
TC 2
Z9 2
U1 0
U2 1
PU ALLIANCE COMMUNICATIONS GROUP DIVISION ALLEN PRESS
PI LAWRENCE
PA 810 EAST 10TH STREET, LAWRENCE, KS 66044 USA
SN 1055-6656
EI 1545-1569
J9 CLEFT PALATE-CRAN J
JI Cleft Palate-Craniofac. J.
PD JUL
PY 2018
VL 55
IS 6
BP 876
EP 882
DI 10.1597/16-096
PG 7
WC Dentistry, Oral Surgery & Medicine; Surgery
SC Dentistry, Oral Surgery & Medicine; Surgery
GA GK9RH
UT WOS:000436589200012
PM 28033025
DA 2021-02-24
ER

PT J
AU Spevack, SC
   Falandays, JB
   Batzloff, B
   Spivey, MJ
AF Spevack, Samuel C.
   Falandays, J. Benjamin
   Batzloff, Brandon
   Spivey, Michael J.
TI Interactivity of language
SO LANGUAGE AND LINGUISTICS COMPASS
LA English
DT Article
ID SYNTACTIC AMBIGUITY RESOLUTION; ONLINE SENTENCE COMPREHENSION; SPOKEN
   WORD-RECOGNITION; EYE-MOVEMENTS; LEXICAL AMBIGUITY; SPEECH-PERCEPTION;
   INTERPERSONAL SYNCHRONY; VISUAL CONTEXT; TIME-COURSE; COORDINATION
AB In previous decades, the language sciences made important advances by dividing language into its different information formats, such as phonetics, semantics, and syntax. Such division generally implied that language processing is divorced from context. In more recent decades, however, important advances in the language sciences have been made in understanding how linguistic information interacts with context. These contextual influences stem from a broad range of sources. They include linguistic and non-linguistic processes within and between individuals. This brief review touches on experimental results from both behavioral and neural measures, and from both individuals processing prepared linguistic stimuli and dyads sharing unscripted conversation. Overall, the findings generally support a view of language processing that must somehow allow for the different information formats of language to retain their unique labels but also accommodate the fact that they frequently interact and overlap with other, even non-linguistic, formats of information.
C1 [Spevack, Samuel C.; Falandays, J. Benjamin; Batzloff, Brandon; Spivey, Michael J.] Univ Calif, Cognit & Informat Sci, Merced, CA 95343 USA.
RP Spivey, MJ (corresponding author), Univ Calif, Cognit & Informat Sci, Merced, CA 95343 USA.
EM spivey@ucmerced.edu
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   ALTMANN G, 1988, COGNITION, V30, P191, DOI 10.1016/0010-0277(88)90020-0
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004
   Anderson SE, 2011, ACTA PSYCHOL, V137, P181, DOI 10.1016/j.actpsy.2010.09.008
   Arnold JE, 2000, COGNITION, V76, pB13, DOI 10.1016/S0010-0277(00)00073-1
   Athreya DN, 2014, EXP BRAIN RES, V232, P2741, DOI 10.1007/s00221-014-3957-2
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Beckner C, 2009, LANG LEARN, V59, P1
   Borrie SA, 2014, J SPEECH LANG HEAR R, V57, P815, DOI 10.1044/2014_JSLHR-S-13-0149
   Budiu R, 2004, COGNITIVE SCI, V28, P1, DOI 10.1016/j.cogsci.2003.10.001
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Capra F., 2014, SYSTEMS VIEW LIFE UN
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Clark H.H., 1992, ARENAS LANGUAGE USE
   Clark HH, 2005, DISCOURSE STUD, V7, P507, DOI 10.1177/1461445605054404
   Clark HH, 2004, J MEM LANG, V50, P62, DOI 10.1016/j.jml.2003.08.004
   Clark HH, 2002, COGNITION, V84, P73, DOI 10.1016/S0010-0277(02)00017-3
   CONNINE CM, 1987, J MEM LANG, V26, P527, DOI 10.1016/0749-596X(87)90138-0
   D'Ausilio A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0418
   Dale R, 2005, J EXP THEOR ARTIF IN, V17, P317, DOI 10.1080/09528130500283766
   Dale R, 2006, LANG LEARN, V56, P391, DOI 10.1111/j.1467-9922.2006.00372.x
   Dale R, 2013, PSYCHOL LEARN MOTIV, V59, P43, DOI 10.1016/B978-0-12-407187-2.00002-2
   Damasio AR, 1989, NEURAL COMPUT, V1, P123, DOI 10.1162/neco.1989.1.1.123
   Dias JW, 2016, ATTEN PERCEPT PSYCHO, V78, P317, DOI 10.3758/s13414-015-0982-6
   Dikker S, 2014, J NEUROSCI, V34, P6267, DOI 10.1523/JNEUROSCI.3796-13.2014
   Duran ND, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00140
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547
   ELMAN JL, 1988, J MEM LANG, V27, P143, DOI 10.1016/0749-596X(88)90071-X
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Falandays J. B., LANGUAGE COGNITION N
   Farmer TA, 2007, COGNITIVE SCI, V31, P889, DOI 10.1080/03640210701530797
   Farmer TA, 2006, P NATL ACAD SCI USA, V103, P12203, DOI 10.1073/pnas.0602173103
   Fusaroli R, 2016, COGNITIVE SCI, V40, P145, DOI 10.1111/cogs.12251
   Fusaroli R, 2012, PSYCHOL SCI, V23, P931, DOI 10.1177/0956797612436816
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Galati A, 2010, J MEM LANG, V62, P35, DOI 10.1016/j.jml.2009.09.002
   Gallotti M, 2013, TRENDS COGN SCI, V17, P160, DOI 10.1016/j.tics.2013.02.002
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313
   Gordon CL, 2017, NEUROSCI LETT, V651, P232, DOI 10.1016/j.neulet.2017.05.021
   Gow DW, 2016, LANG COGN NEUROSCI, V31, P841, DOI 10.1080/23273798.2015.1029498
   Hanna JE, 2007, J MEM LANG, V57, P596, DOI 10.1016/j.jml.2007.01.008
   Hauk O, 2004, NEURON, V41, P301, DOI 10.1016/S0896-6273(03)00838-9
   Hauk O, 2017, LANG COGN NEUROSCI, V32, P533, DOI 10.1080/23273798.2017.1297842
   Holt LL, 2002, HEARING RES, V167, P156, DOI 10.1016/S0378-5955(02)00383-0
   Hove MJ, 2009, SOC COGNITION, V27, P949, DOI 10.1521/soco.2009.27.6.949
   Huettig F, 2004, ON-LINE STUDY OF SENTENCE COMPREHENSION, P187
   Ilmberger J, 2001, BRAIN LANG, V76, P111, DOI 10.1006/brln.2000.2415
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Kaiser E, 2008, LANG COGNITIVE PROC, V23, P709, DOI 10.1080/01690960701771220
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x
   KAWAMOTO AH, 1993, J MEM LANG, V32, P474, DOI 10.1006/jmla.1993.1026
   Kelso J. A. S., 1984, AM J PHYSIOL-REG I, V15, pR1000, DOI [DOI 10.1152/AJPREGU.1984.246.6.R1000, DOI 10.1152/ajpregu.1984.246.6.R1000]
   Knoeferle P, 2006, COGNITIVE SCI, V30, P481, DOI 10.1207/s15516709cog0000_65
   Knoeferle P, 2016, LANG LINGUIST COMPAS, V10, P66, DOI 10.1111/lnc3.12177
   Konvalinka I, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00215
   Kuhlen AK, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00266
   Lakin JL, 2003, J NONVERBAL BEHAV, V27, P145, DOI 10.1023/A:1025389814290
   Lam KJY, 2017, LANG COGN NEUROSCI, V32, P590, DOI 10.1080/23273798.2016.1164323
   Laughlin R. B., 2005, DIFFERENT UNIVERSE R
   Lee CL, 2009, J MEM LANG, V61, P538, DOI 10.1016/j.jml.2009.08.003
   Lewis AG, 2017, LANG COGN NEUROSCI, V32, P601, DOI 10.1080/23273798.2016.1211300
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Louwerse MM, 2012, COGNITIVE SCI, V36, P1404, DOI 10.1111/j.1551-6709.2012.01269.x
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   Magnuson JS, 2003, COGNITIVE SCI, V27, P285, DOI 10.1016/S0364-0213(03)00004-1
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McMurray B, 2003, J PSYCHOLINGUIST RES, V32, P77, DOI 10.1023/A:1021937116271
   McRae K, 1998, J MEM LANG, V38, P283, DOI 10.1006/jmla.1997.2543
   Mcrae K, 2009, LANG LINGUIST COMPAS, V3, P1417, DOI 10.1111/j.1749-818x.2009.00174.x
   Menenti L, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00185
   Meyer AM, 2007, BRAIN RES, V1183, P91, DOI 10.1016/j.brainres.2007.09.007
   Miles LK, 2010, EUR J SOC PSYCHOL, V40, P52, DOI 10.1002/ejsp.721
   Miller RM, 2013, ATTEN PERCEPT PSYCHO, V75, P1817, DOI 10.3758/s13414-013-0517-y
   Miller RM, 2010, ATTEN PERCEPT PSYCHO, V72, P1614, DOI 10.3758/APP.72.6.1614
   Montague PR, 2002, NEUROIMAGE, V16, P1159, DOI 10.1006/nimg.2002.1150
   Nieuwland MS, 2006, J COGNITIVE NEUROSCI, V18, P1098, DOI 10.1162/jocn.2006.18.7.1098
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Onnis L, 2012, INFORMATION, V3, P124, DOI 10.3390/info3010124
   Paxton A, 2013, Q J EXP PSYCHOL, V66, P2092, DOI 10.1080/17470218.2013.853089
   Perez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04464-4
   Pickering MJ, 2008, PSYCHOL BULL, V134, P427, DOI 10.1037/0033-2909.134.3.427
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Pulvermuller F, 2005, EUR J NEUROSCI, V21, P793, DOI 10.1111/j.1460-9568.2005.03900.x
   Rayner K, 2010, WIRES COGN SCI, V1, P787, DOI 10.1002/wcs.68
   Richardson DC, 2007, PSYCHOL SCI, V18, P407, DOI 10.1111/j.1467-9280.2007.01914.x
   Richardson DC, 2009, COGNITIVE SCI, V33, P1468, DOI 10.1111/j.1551-6709.2009.01057.x
   Richardson DC, 2003, COGNITIVE SCI, V27, P767, DOI 10.1016/S0364-0213(03)00064-8
   Richardson DC, 2005, COGNITIVE SCI, V29, P1045, DOI 10.1207/s15516709cog0000_29
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Roepstorff A, 2004, PSYCHOL RES-PSYCH FO, V68, P189, DOI 10.1007/s00426-003-0155-4
   Rommers J, 2017, LANG COGN NEUROSCI, V32, P576, DOI 10.1080/23273798.2016.1183799
   Samuel AG, 2003, J MEM LANG, V48, P416, DOI 10.1016/S0749-596X(02)00514-4
   Sato M, 2010, SPEECH COMMUN, V52, P533, DOI 10.1016/j.specom.2009.12.004
   SCHMIDT RC, 1990, J EXP PSYCHOL HUMAN, V16, P227, DOI 10.1037/0096-1523.16.2.227
   Schoot L, 2016, NEUROSCI BIOBEHAV R, V68, P454, DOI 10.1016/j.neubiorev.2016.06.009
   Segaert K, 2012, CEREB CORTEX, V22, P1662, DOI 10.1093/cercor/bhr249
   SEIDENBERG MS, 1982, COGNITIVE PSYCHOL, V14, P489, DOI 10.1016/0010-0285(82)90017-2
   Shockley K, 2003, J EXP PSYCHOL HUMAN, V29, P326, DOI 10.1037/0096-1523.29.2.326
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Shockley K, 2007, J EXP PSYCHOL HUMAN, V33, P201, DOI 10.1037/0096-1523.33.1.201
   SIMPSON GB, 1991, J MEM LANG, V30, P627, DOI 10.1016/0749-596X(91)90029-J
   Smolensky P, 2014, COGNITIVE SCI, V38, P1102, DOI 10.1111/cogs.12047
   Spiegelhalder K, 2014, BEHAV BRAIN RES, V258, P75, DOI 10.1016/j.bbr.2013.10.015
   Spivey M., 2012, CAMBRIDGE HDB PSYCHO
   Spivey M. J., 2016, VISUALLY SITUATED LA, P1
   Spivey MJ, 2016, LANG COGN NEUROSCI, V31, P856, DOI 10.1080/23273798.2016.1140788
   Spivey MJ, 2013, ECOL PSYCHOL, V25, P233, DOI 10.1080/10407413.2013.810475
   Spivey MJ, 2005, P NATL ACAD SCI USA, V102, P10393, DOI 10.1073/pnas.0503903102
   Spivey MJ, 2002, COGNITIVE PSYCHOL, V45, P447, DOI 10.1016/S0010-0285(02)00503-0
   Spivey MJ, 1998, J EXP PSYCHOL LEARN, V24, P1521, DOI 10.1037/0278-7393.24.6.1521
   Staub A, 2011, J EXP PSYCHOL GEN, V140, P407, DOI 10.1037/a0023517
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107
   SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4
   TABOSSI P, 1988, J MEM LANG, V27, P324, DOI 10.1016/0749-596X(88)90058-7
   Tanenhaus M. K., 1995, HDB COGNITION PERCEP, P217
   TANENHAUS MK, 1979, J VERB LEARN VERB BE, V18, P427, DOI 10.1016/S0022-5371(79)90237-8
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   TANENHAUS MK, 1987, COGNITION, V25, P213, DOI 10.1016/0010-0277(87)90010-2
   TANENHAUS MK, 2000, ARCHITECTURES MECH L, P90
   Thompson-Schill SL, 1997, P NATL ACAD SCI USA, V94, P14792, DOI 10.1073/pnas.94.26.14792
   Tolins J, 2014, J PRAGMATICS, V70, P152, DOI 10.1016/j.pragma.2014.06.006
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   TRUESWELL JC, 1993, J EXP PSYCHOL LEARN, V19, P528, DOI 10.1037/0278-7393.19.3.528
   TRUESWELL JC, 1994, J MEM LANG, V33, P285, DOI 10.1006/jmla.1994.1014
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   van Berkum JJA, 1999, J MEM LANG, V41, P147, DOI 10.1006/jmla.1999.2641
   VANORDEN GC, 1990, PSYCHOL REV, V97, P488, DOI 10.1037/0033-295X.97.4.488
   Vigliocco G, 2004, COGNITIVE PSYCHOL, V48, P422, DOI 10.1016/j.cogpsych.2003.09.001
   Vu H, 1998, MEM COGNITION, V26, P979, DOI 10.3758/BF03201178
   Yee E, 2011, J EXP PSYCHOL GEN, V140, P348, DOI 10.1037/a0022840
   Zwaan RA, 2002, PSYCHOL SCI, V13, P168, DOI 10.1111/1467-9280.00430
NR 136
TC 3
Z9 3
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1749-818X
J9 LANG LINGUIST COMPAS
JI Lang. Linguist. Compass
PD JUL
PY 2018
VL 12
IS 7
AR e12282
DI 10.1111/lnc3.12282
PG 18
WC Language & Linguistics
SC Linguistics
GA GL2HQ
UT WOS:000436940700001
DA 2021-02-24
ER

PT J
AU Baart, M
   Vroomen, J
AF Baart, Martijn
   Vroomen, Jean
TI Recalibration of vocal affect by a dynamic face
SO EXPERIMENTAL BRAIN RESEARCH
LA English
DT Article
DE Emotion perception; Cross-modal learning; Audiovisual integration;
   Adaptation
ID SELECTIVE ADAPTATION; SPEECH-PERCEPTION; EMOTIONS; RECOGNITION;
   EXPRESSION; IDENTIFICATION; REPRESENTATION; INTEGRATION; EXPOSURE;
   BINDING
AB Perception of vocal affect is influenced by the concurrent sight of an emotional face. We demonstrate that the sight of an emotional face also can induce recalibration of vocal affect. Participants were exposed to videos of a 'happy' or 'fearful' face in combination with a slightly incongruous sentence with ambiguous prosody. After this exposure, ambiguous test sentences were rated as more 'happy' when the exposure phase contained 'happy' instead of 'fearful' faces. This auditory shift likely reflects recalibration that is induced by error minimization of the inter-sensory discrepancy. In line with this view, when the prosody of the exposure sentence was non-ambiguous and congruent with the face (without audiovisual discrepancy), aftereffects went in the opposite direction, likely reflecting adaptation. Our results demonstrate, for the first time, that perception of vocal affect is flexible and can be recalibrated by slightly discrepant visual information.
C1 [Baart, Martijn; Vroomen, Jean] Tilburg Univ, Dept Cognit Neuropsychol, POB 90153, NL-5000 LE Tilburg, Netherlands.
   [Baart, Martijn] Basque Ctr Cognit Brain & Language, BCBL, Donostia San Sebastian, Spain.
RP Baart, M; Vroomen, J (corresponding author), Tilburg Univ, Dept Cognit Neuropsychol, POB 90153, NL-5000 LE Tilburg, Netherlands.; Baart, M (corresponding author), Basque Ctr Cognit Brain & Language, BCBL, Donostia San Sebastian, Spain.
EM m.baart@tilburguniversity.edu; j.vroomen@tilburguniversity.edu
RI Vroomen, Jean/K-1033-2013; Baart, Martijn/L-2910-2013
OI Vroomen, Jean/0000-0001-5923-5988; Baart, Martijn/0000-0002-5015-4265
FU Netherlands Organization for Scientific Research (NWO: VENI
   Grant)Netherlands Organization for Scientific Research (NWO)
   [275-89-027]
FX MB was supported by The Netherlands Organization for Scientific Research
   (NWO: VENI Grant 275-89-027).
CR Baart M, 2010, EXP BRAIN RES, V203, P575, DOI 10.1007/s00221-010-2264-9
   BEIER EG, 1972, J CONSULT CLIN PSYCH, V39, P166, DOI 10.1037/h0033170
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Bestelmeyer PEG, 2010, VIS COGN, V18, P255, DOI 10.1080/13506280802708024
   Bestelmeyer PEG, 2010, COGNITION, V117, P217, DOI 10.1016/j.cognition.2010.08.008
   Birkholz P, 2015, J ACOUST SOC AM, V137, P1503, DOI 10.1121/1.4906836
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3
   Calder AJ, 2000, NAT NEUROSCI, V3, P1077, DOI 10.1038/80586
   Darwin C., 1872, EXPRESSION EMOTIONS
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   DIEHL RL, 1980, J EXP PSYCHOL HUMAN, V6, P24, DOI 10.1037/0096-1523.6.1.24
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ethofer T, 2006, HUM BRAIN MAPP, V27, P707, DOI 10.1002/hbm.20212
   Focker J, 2011, ACTA PSYCHOL, V137, P36, DOI 10.1016/j.actpsy.2011.02.004
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   Hagan CC, 2009, P NATL ACAD SCI USA, V106, P20010, DOI 10.1073/pnas.0905792106
   Huber DE, 2008, J EXP PSYCHOL GEN, V137, P324, DOI 10.1037/0096-3445.137.2.324
   Iwase M, 2002, NEUROIMAGE, V17, P758, DOI 10.1006/nimg.2002.1225
   Kilian-Hutten N, 2011, NEUROIMAGE, V57, P1601, DOI 10.1016/j.neuroimage.2011.05.043
   Klasen M, 2011, J NEUROSCI, V31, P13635, DOI 10.1523/JNEUROSCI.2833-11.2011
   Kleischmidt D, 2011, P COGN MOD COMP LING, P10
   Muller VI, 2011, NEUROIMAGE, V54, P2257, DOI 10.1016/j.neuroimage.2010.10.047
   Pourtois G, 2000, NEUROREPORT, V11, P1329, DOI 10.1097/00001756-200004270-00036
   Pye A, 2015, COGNITION, V134, P245, DOI 10.1016/j.cognition.2014.11.001
   RADEAU M, 1974, Q J EXP PSYCHOL, V26, P63, DOI 10.1080/14640747408400388
   Reiman EM, 1997, AM J PSYCHIAT, V154, P918
   ROBERTS M, 1981, PERCEPT PSYCHOPHYS, V30, P309, DOI 10.3758/BF03206144
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Scott SK, 1997, NATURE, V385, P254, DOI 10.1038/385254a0
   Scott SK, 2010, HBK BEHAV NEUROSCI, V19, P187, DOI 10.1016/B978-0-12-374593-4.00019-X
   Skuk VG, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081691
   Vroomen J, 2004, COGNITIVE BRAIN RES, V22, P32, DOI 10.1016/j.cogbrainres.2004.07.003
   Vroomen J, 1993, P 3 EUR C SPEECH COM, V93
   Vroomen J., 2012, NEURAL BASEMULTISE, P363, DOI DOI 10.1201/9781439812174-24
   Vroomen J, 2001, COGN AFFECT BEHAV NE, V1, P382, DOI 10.3758/CABN.1.4.382
   Walther C, 2013, CORTEX, V49, P1963, DOI 10.1016/j.cortex.2012.08.012
   Welch R., 1986, HDB PERCEPTION HUMAN, V1, P21
NR 43
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0014-4819
EI 1432-1106
J9 EXP BRAIN RES
JI Exp. Brain Res.
PD JUL
PY 2018
VL 236
IS 7
BP 1911
EP 1918
DI 10.1007/s00221-018-5270-y
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA GK0FI
UT WOS:000435783300007
PM 29696314
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Jesse, A
   Bartoli, M
AF Jesse, Alexandra
   Bartoli, Michael
TI Learning to recognize unfamiliar talkers: Listeners rapidly form
   representations of facial dynamic signatures
SO COGNITION
LA English
DT Article
DE Face perception; Audiovisual speech perception; Talker identification
ID SUPERIOR TEMPORAL SULCUS; VISUAL SPEECH-PERCEPTION; POINT-LIGHT
   DISPLAYS; FACE-RECOGNITION; MOVING FACES; AUDIOVISUAL SPEECH; BIOLOGICAL
   MOTION; HUMAN BRAIN; CROSSMODAL BINDING; PERSON RECOGNITION
AB Seeing the motion of a talking face can be sufficient to recognize personally highly familiar speakers, suggesting that dynamic facial information is stored in long-term representations for familiar speakers. In the present study, we tested whether talking-related facial dynamic information can guide the learning of unfamiliar speakers. Participants were asked to identify speakers from configuration-normalized point-light displays showing only the biological motion that speakers produced while saying short sentences. During an initial learning phase, feedback was given. During test, listeners identified speakers from point-light displays of the training sentences and of new sentences. Listeners learned to identify two speakers, and four speakers in another experiment, from visual dynamic information alone. Learning was evident already after very little exposure. Furthermore, listeners formed abstract representations of visual dynamic signatures that allowed them to recognize speakers at test even from new linguistic materials. Control experiments showed that any potentially remaining static information in the point-light displays was not sufficient to guide learning and that listeners learned to recognize the identity, rather than the sex, of the speakers, as learning was also found when speakers were of the same sex. Overall, these results demonstrate that listeners can learn to identify unfamiliar speakers from the motion they produce during talking. Listeners thus establish abstract representations of the talking-related dynamic facial motion signatures of unfamiliar speakers already from limited exposure.
C1 [Jesse, Alexandra; Bartoli, Michael] Univ Massachusetts, Dept Psychol & Brain Sci, 135 Hicks Way, Amherst, MA 01003 USA.
RP Jesse, A (corresponding author), Univ Massachusetts, Dept Psychol & Brain Sci, 135 Hicks Way, Amherst, MA 01003 USA.
EM ajesse@psych.umass.edu
CR Allison T, 2000, TRENDS COGN SCI, V4, P267, DOI 10.1016/S1364-6613(00)01501-1
   Andics A, 2010, NEUROIMAGE, V52, P1528, DOI 10.1016/j.neuroimage.2010.05.048
   Barsics C, 2014, PSYCHOL BELG, V54, P244, DOI 10.5334/pb.ap
   Barsics C, 2012, J COGN PSYCHOL, V24, P789, DOI 10.1080/20445911.2012.692672
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037/0096-1523.4.3.373
   Bate S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00770
   Beauchamp MS, 2003, J COGNITIVE NEUROSCI, V15, P991, DOI 10.1162/089892903770007380
   Belin P, 2003, NEUROREPORT, V14, P2105, DOI 10.1097/00001756-200311140-00019
   Belin P, 2002, COGNITIVE BRAIN RES, V13, P17, DOI 10.1016/S0926-6410(01)00084-2
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2011, BRIT J PSYCHOL, V102, P711, DOI 10.1111/j.2044-8295.2011.02041.x
   Bennetts RJ, 2013, PERCEPTION, V42, P950, DOI 10.1068/p7446
   Bernstein M, 2015, NEUROSCI BIOBEHAV R, V55, P536, DOI 10.1016/j.neubiorev.2015.06.010
   BERRY D S, 1991, Ecological Psychology, V3, P349, DOI 10.1207/s15326969eco0304_3
   BERRY DS, 1990, J PERS SOC PSYCHOL, V58, P1004, DOI 10.1037/0022-3514.58.6.1004
   Blank H, 2011, J NEUROSCI, V31, P12906, DOI 10.1523/JNEUROSCI.2091-11.2011
   Bonda E, 1996, J NEUROSCI, V16, P3737
   Bonner L, 2003, VIS COGN, V10, P527, DOI 10.1080/13506280244000168
   BRICKER PD, 1976, CONT ISSUES EXPT PHO, P295
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   Bruce V., 1988, PRACTICAL ASPECTS ME, V1, P169
   Calder AJ, 2005, NAT REV NEUROSCI, V6, P641, DOI 10.1038/nrn1724
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1999, NEUROREPORT, V10, P2619, DOI 10.1097/00001756-199908200-00033
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Christie F, 1998, MEM COGNITION, V26, P780, DOI 10.3758/BF03211397
   Costello A.B., 2005, PRACTICAL ASSESSMENT, V10, P1, DOI DOI 10.4135/9781412995627.D8
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   ELLIS HD, 1979, PERCEPTION, V8, P431, DOI 10.1068/p080431
   Fellowes JM, 1997, PERCEPT PSYCHOPHYS, V59, P839, DOI 10.3758/BF03205502
   Foley E, 2012, J COGNITIVE NEUROSCI, V24, P507, DOI 10.1162/jocn_a_00120
   Fox CJ, 2009, HUM BRAIN MAPP, V30, P1637, DOI 10.1002/hbm.20630
   Girges C, 2015, Q J EXP PSYCHOL, V68, P1832, DOI 10.1080/17470218.2014.993664
   Grossman E, 2000, J COGNITIVE NEUROSCI, V12, P711, DOI 10.1162/089892900562417
   Grossmann T, 2010, NEURON, V65, P852, DOI 10.1016/j.neuron.2010.03.001
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Heald SLM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00698
   Hecker M H, 1971, ASHA Monogr, V16, P1
   Hein G, 2008, J COGNITIVE NEUROSCI, V20, P2125, DOI 10.1162/jocn.2008.20148
   Hill H, 2003, PERCEPTION, V32, P561, DOI 10.1068/p3435
   Howard RJ, 1996, CURR BIOL, V6, P1015, DOI 10.1016/S0960-9822(02)00646-2
   Jacobs A, 2004, J EXP PSYCHOL HUMAN, V30, P822, DOI 10.1037/0096-1523.30.5.822
   Jesse A., 2018, DATA LEARNING RECONG
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Johnston RA, 2009, MEMORY, V17, P577, DOI 10.1080/09658210902976969
   Kamachi M, 2003, CURR BIOL, V13, P1709, DOI 10.1016/j.cub.2003.09.005
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Knight B, 1997, VIS COGN, V4, P265, DOI 10.1080/713756764
   Krauss RM, 2002, J EXP SOC PSYCHOL, V38, P618, DOI 10.1016/S0022-1031(02)00510-3
   Lachs L, 2004, ECOL PSYCHOL, V16, P159, DOI 10.1207/s15326969eco1603_1
   Lachs L, 2004, J ACOUST SOC AM, V116, P507, DOI 10.1121/1.1757454
   Lahnakoski JM, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00233
   Lander K, 1999, MEM COGNITION, V27, P974, DOI 10.3758/BF03201228
   Lander K, 2005, VIS COGN, V12, P429, DOI 10.1080/13506280444000382
   Lander K, 2004, NEUROCASE, V10, P462, DOI 10.1080/13554790490900761
   Lander K, 2004, MEM COGNITION, V32, P640, DOI 10.3758/BF03195855
   Lander K, 2003, VIS COGN, V10, P897, DOI 10.1080/13506280344000149
   Lander K, 2001, APPL COGNITIVE PSYCH, V15, P101, DOI 10.1002/1099-0720(200101/02)15:1<101::AID-ACP697>3.0.CO;2-7
   Lander K, 2000, ECOL PSYCHOL, V12, P259, DOI 10.1207/S15326969ECO1204_01
   Lander K, 2007, Q J EXP PSYCHOL, V60, P519, DOI 10.1080/17470210601117559
   LEGGE GE, 1984, J EXP PSYCHOL LEARN, V10, P298
   Loebach JL, 2008, J ACOUST SOC AM, V124, P552, DOI 10.1121/1.2931948
   Longmore CA, 2013, NEUROPSYCHOLOGIA, V51, P864, DOI 10.1016/j.neuropsychologia.2013.01.022
   Loula F, 2005, J EXP PSYCHOL HUMAN, V31, P210, DOI 10.1037/0096-1523.31.1.210
   Lumley T, 2004, LEAPS REGRESSION SUB
   Macaluso E, 2004, NEUROIMAGE, V21, P725, DOI 10.1016/j.neuroimage.2003.09.049
   MALONE DR, 1982, J NEUROL NEUROSUR PS, V45, P820, DOI 10.1136/jnnp.45.9.820
   Massaro D. W., 1998, PERCEIVING TALKING F
   Massaro D. W., 2007, OXFORD HDB PSYCHOLIN, P19, DOI [10.1093/oxfordhb/9780198568971.013.0002, DOI 10.1093/0XF0RDHB/9780198568971.013.0002]
   Mavica LW, 2013, J EXP PSYCHOL HUMAN, V39, P307, DOI 10.1037/a0030945
   Nakamura K, 2001, NEUROPSYCHOLOGIA, V39, P1047, DOI 10.1016/S0028-3932(01)00037-9
   Natu V, 2011, BRIT J PSYCHOL, V102, P726, DOI 10.1111/j.2044-8295.2011.02053.x
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3
   Pitcher D, 2011, NEUROIMAGE, V56, P2356, DOI 10.1016/j.neuroimage.2011.03.067
   R Core Team, 2016, R LANG ENV STAT COMP
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Remez RE, 2007, J ACOUST SOC AM, V122, P3688, DOI 10.1121/1.2799903
   Riedel P, 2015, CORTEX, V68, P86, DOI 10.1016/j.cortex.2014.11.016
   Roark DA, 2006, PERCEPTION, V35, P761, DOI 10.1068/p5503
   Rosenblum LD, 2007, PERCEPTION, V36, P157, DOI 10.1068/p5613
   Rosenblum LD, 2006, PERCEPT PSYCHOPHYS, V68, P84, DOI 10.3758/BF03193658
   Rosenblum LD, 2002, PERCEPT PSYCHOPHYS, V64, P220, DOI 10.3758/BF03195788
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Rossion B, 2001, J COGNITIVE NEUROSCI, V13, P1019, DOI 10.1162/089892901753165917
   Schall S, 2013, NEUROIMAGE, V77, P237, DOI 10.1016/j.neuroimage.2013.03.043
   Schultz J, 2009, EXP BRAIN RES, V194, P465, DOI 10.1007/s00221-009-1721-9
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Sheffert SM, 2004, PERCEPT PSYCHOPHYS, V66, P352, DOI 10.3758/BF03194884
   Sheffert SM, 2002, J EXP PSYCHOL HUMAN, V28, P1447, DOI 10.1037//0096-1523.28.6.1447
   Shultz S, 2012, J COGNITIVE NEUROSCI, V24, P1224, DOI 10.1162/jocn_a_00208
   Skelton F, 2008, VIS COGN, V16, P419, DOI 10.1080/13506280701577496
   Smith HMJ, 2016, EVOL PSYCHOL-US, V14, DOI 10.1177/1474704916630317
   Summerfield Q., 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237
   Tabachnick B. G., 2012, USING MULTIAVARIATE
   Thomas SM, 2001, BEHAV RES METH INS C, V33, P59, DOI 10.3758/BF03195347
   Thornton IM, 1998, COGNITIVE NEUROPSYCH, V15, P535, DOI 10.1080/026432998381014
   Turk-Browne NB, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00176
   Vatikiotis-Bateson E., 1996, SPEECHREADING HUMANS, P221, DOI DOI 10.1007/978-3-662-13015-5_16
   von Kriegstein K, 2005, J COGNITIVE NEUROSCI, V17, P367, DOI 10.1162/0898929053279577
   von Kriegstein K, 2003, COGNITIVE BRAIN RES, V17, P48, DOI 10.1016/S0926-6410(03)00079-X
   von Kriegstein K, 2008, P NATL ACAD SCI USA, V105, P6747, DOI 10.1073/pnas.0710826105
   WALDEN BE, 1974, J SPEECH HEAR RES, V17, P270, DOI 10.1044/jshr.1702.270
   Watson R, 2014, CORTEX, V50, P125, DOI 10.1016/j.cortex.2013.07.011
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Yakel DA, 2000, PERCEPT PSYCHOPHYS, V62, P1405, DOI 10.3758/BF03212142
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   YOUNG AW, 1993, BRAIN, V116, P941, DOI 10.1093/brain/116.4.941
   Yovel G, 2016, TRENDS COGN SCI, V20, P383, DOI 10.1016/j.tics.2016.02.005
   Zake R, 2014, J NEUROSCI, V34, P10821, DOI 10.1523/JNEUROSCI.0581-14.2014
   Zhang H, 2009, NEUROSCI LETT, V454, P1, DOI 10.1016/j.neulet.2009.02.054
NR 118
TC 2
Z9 2
U1 2
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD JUL
PY 2018
VL 176
BP 195
EP 208
DI 10.1016/j.cognition.2018.03.018
PG 14
WC Psychology, Experimental
SC Psychology
GA GH7NY
UT WOS:000433641900015
PM 29604468
DA 2021-02-24
ER

PT J
AU Loucks, J
   Sommerville, J
AF Loucks, Jeff
   Sommerville, Jessica
TI Developmental Change in Action Perception: Is Motor Experience the
   Cause?
SO INFANCY
LA English
DT Article
ID SPEECH-PERCEPTION; BIOLOGICAL MOTION; OTHERS ACTIONS; 1ST YEAR; INFANTS;
   LANGUAGE; GRASP; DISCRIMINATION; TELEVISION; ADULTS
AB Human actions are complex stimuli containing several perceptual dimensions an observer could attend to. Research indicates that attention to the perceptual dimensions of action undergoes a process of perceptual narrowing between 4 and 10months, during which infants' attention to configural and temporal information in action decreases over time, while attention to hand information is maintained. This research explored whether infants' active experience with grasping is related to perceptual narrowing in action. Across two studies, we tested 6-month-old infants' attention to changes in these action dimensions and also assessed their grasping ability. Infants who were more proficient at grasping showed a pattern more consistent with perceptual narrowing (decreasing attention to configural and temporal information) relative to those less proficient at grasping, especially for attention to configural information. In addition, attention to hand information appears to undergo U-shaped development between 4 and 10months, as 6-month-olds did not recover attention to the hand change. These findings add to a growing body of research showing that infants' motor experience broadly influences their perception of others' action and may follow a complex developmental pathway that diverges from perceptual narrowing over the first year.
C1 [Loucks, Jeff] Univ Regina, Regina, SK, Canada.
   [Sommerville, Jessica] Univ Washington, Seattle, WA 98195 USA.
RP Loucks, J (corresponding author), Univ Regina, Psychol, 3737 Wascana Pkwy, Regina, SK S4S 0A2, Canada.
EM jeff.loucks@uregina.ca
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [K18OD008069]; NSERCNatural Sciences
   and Engineering Research Council of Canada (NSERC)
FX Neither of the authors have any conflict of interests. Thanks to the
   members of the Early Childhood Cognition Lab and the Early Cognitive
   Development Lab for their assistance in data collection. Special thanks
   to Natasha Nagel for collecting data on Study 2. Study 1 was supported
   by a grant from NIH (award #: K18OD008069) awarded to the second author,
   and Study 2 was supported by an NSERC Discovery grant awarded to the
   first author. We are especially grateful to all of the families in the
   Seattle and Regina areas who volunteered to participate: This research
   happened because of you.
CR Anderson DR, 2005, AM BEHAV SCI, V48, P505, DOI 10.1177/0002764204271506
   Baldwin D, 2005, DEVELOPMENT OF SOCIAL COGNITION AND COMMUNICATION, P117
   Baldwin DA, 2000, CURR DIR PSYCHOL SCI, V9, P40, DOI 10.1111/1467-8721.00057
   Barr R, 1999, CHILD DEV, V70, P1067, DOI 10.1111/1467-8624.00079
   Barr R, 2007, DEVELOPMENTAL SCI, V10, P910, DOI 10.1111/j.1467-7687.2007.00641.x
   Blakemore SJ, 2005, NEUROPSYCHOLOGIA, V43, P260, DOI 10.1016/j.neuropsychologia.2004.11.012
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brass M, 2001, ACTA PSYCHOL, V106, P3, DOI 10.1016/S0001-6918(00)00024-X
   Cannon EN, 2016, DEVELOPMENTAL SCI, V19, P50, DOI 10.1111/desc.12295
   Cannon EN, 2012, DEVELOPMENTAL SCI, V15, P35, DOI 10.1111/j.1467-7687.2011.01095.x
   Cashon CH, 2013, CHILD DEV, V84, P802, DOI 10.1111/cdev.12024
   Cashon CH, 2011, J COGN DEV, V12, P159, DOI 10.1080/15248372.2011.563483
   Chen LC, 2007, INFANT BEHAV DEV, V30, P16, DOI 10.1016/j.infbeh.2006.07.005
   Daum MM, 2011, J EXP CHILD PSYCHOL, V108, P810, DOI 10.1016/j.jecp.2010.10.003
   Dobkins KR, 2009, OPTOMETRY VISION SCI, V86, P583, DOI 10.1097/OPX.0b013e3181a72854
   Falck-Ytter T, 2006, NAT NEUROSCI, V9, P878, DOI 10.1038/nn1729
   Filippi CA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00019
   GIBSON EJ, 1988, ANNU REV PSYCHOL, V39, P1, DOI 10.1146/annurev.ps.39.020188.000245
   Gibson J., 1979, ECOLOGICAL APPROACH
   Grossman ED, 2001, VISION RES, V41, P1475, DOI 10.1016/S0042-6989(00)00317-5
   Hannon EE, 2005, P NATL ACAD SCI USA, V102, P12639, DOI 10.1073/pnas.0504254102
   HUTTENLOCHER PR, 1990, NEUROPSYCHOLOGIA, V28, P517, DOI 10.1016/0028-3932(90)90031-I
   Jarvelainen J, 2001, NEUROREPORT, V12, P3493
   Kanakogi Y, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1342
   Karl JM, 2014, EXP BRAIN RES, V232, P3301, DOI 10.1007/s00221-014-4013-y
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lewkowicz DJ, 2009, TRENDS COGN SCI, V13, P470, DOI 10.1016/j.tics.2009.08.004
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   Loucks J, 2016, PERCEPTION, V45, P1222, DOI 10.1177/0301006616652054
   Loucks J, 2013, J EXP CHILD PSYCHOL, V116, P856, DOI 10.1016/j.jecp.2013.08.001
   Loucks J, 2012, CHILD DEV, V83, P801, DOI 10.1111/j.1467-8624.2012.01735.x
   Loucks J, 2012, DEVELOPMENTAL SCI, V15, P123, DOI 10.1111/j.1467-7687.2011.01099.x
   Loucks J, 2011, PERCEPTION, V40, P1047, DOI 10.1068/p7084
   Loucks J, 2009, COGNITION, V111, P84, DOI 10.1016/j.cognition.2008.12.010
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Meltzoff A., 2010, HDB INFANT DEV, P345, DOI DOI 10.1002/9781444327564.CH11
   MORTON J, 1991, PSYCHOL REV, V98, P164, DOI 10.1037/0033-295X.98.2.164
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Oztop E, 2004, EXP BRAIN RES, V158, P480, DOI 10.1007/s00221-004-1914-1
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551
   Rosander K, 2011, NEUROPSYCHOLOGIA, V49, P2911, DOI 10.1016/j.neuropsychologia.2011.06.018
   Scott LS, 2007, CURR DIR PSYCHOL SCI, V16, P197, DOI 10.1111/j.1467-8721.2007.00503.x
   Scott LS, 2009, PSYCHOL SCI, V20, P676, DOI 10.1111/j.1467-9280.2009.02348.x
   Shimada S, 2006, NEUROIMAGE, V32, P930, DOI 10.1016/j.neuroimage.2006.03.044
   Sommerville JA, 2005, COGNITION, V96, pB1, DOI 10.1016/j.cognition.2004.07.004
   Sommerville JA, 2005, COGNITION, V95, P1, DOI 10.1016/j.cognition.2003.12.004
   Sommerville JA, 2008, DEV PSYCHOL, V44, P1249, DOI 10.1037/a0012296
   Southgate V, 2010, PSYCHOL SCI, V21, P355, DOI 10.1177/0956797610362058
   Thompson J, 2012, NEUROIMAGE, V59, P4, DOI 10.1016/j.neuroimage.2011.05.044
   VONHOFSTEN C, 1988, J EXP PSYCHOL HUMAN, V14, P610, DOI 10.1037/0096-1523.14.4.610
   VONHOFSTEN C, 1984, J EXP CHILD PSYCHOL, V38, P208, DOI 10.1016/0022-0965(84)90122-X
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Woodward AL, 1998, COGNITION, V69, P1, DOI 10.1016/S0010-0277(98)00058-4
   Woodward AL, 2002, COGNITIVE DEV, V17, P1061, DOI 10.1016/S0885-2014(02)00074-6
   Woodward AL, 2009, CURR DIR PSYCHOL SCI, V18, P53, DOI 10.1111/j.1467-8721.2009.01605.x
NR 57
TC 1
Z9 1
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD JUL-AUG
PY 2018
VL 23
IS 4
BP 519
EP 537
DI 10.1111/infa.12231
PG 19
WC Psychology, Developmental
SC Psychology
GA GI2SO
UT WOS:000434222400003
DA 2021-02-24
ER

PT J
AU Kashani, HB
   Sayadiyan, A
AF Kashani, Hamidreza Baradaran
   Sayadiyan, Abolghasem
TI Sequential use of spectral models to reduce deletion and insertion
   errors in vowel detection
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Vowel landmark detection; Temporal objective contour (TOC); Vowel
   deletion error; Consonant insertion error; Vowel insertion error
ID SPONTANEOUS SPEECH; ROBUST SPEECH; RECOGNITION; INFORMATION; UNITS
AB From both perspectives of speech production and speech perception, vowels as syllable nuclei can be considered as the most significant speech events. Detection of vowel events from a speech signal is usually performed by a two-step procedure. First, a temporal objective contour (TOC), as a time-varying measure of vowel similarity, is generated from the speech signal. Second, vowel landmarks, as the places of vowel events, are extracted by locating prominent peaks of the TOC.
   In this paper, by employing some spectral models in a sequential manner, we propose a new framework that directly addresses three possible errors in the vowel detection problem, namely vowel deletion, consonant insertion, and vowel insertion. The proposed framework consists of three main steps as follows. At the first step, two solutions are proposed to essentially reduce the initial vowel deletion error. The first solution is to use the peaks detected by a conventional energy-based TOC, but without utilizing TOC smoothing and peak thresholding processes. The peaks detected by a spectral-based TOC generated on the basis of GMM models are also put forward as the second solution for achieving a smaller vowel deletion error. At the second step, a two-class support vector machine (SVM) classifier is adopted to identify the consonant peaks from the vowel ones. Removing the peaks classified as consonants reduces the consonant insertion error. Finally, a two-class SVM classifier is proposed to classify the consecutive peaks detected within the same vowel from the others. The merging of the peaks classified as "same vowel" considerably reduces the vowel insertion error.
   Experiments are separately conducted on three standard speech corpora, namely FARSDAT, TIMIT and TFARSDAT. The effectiveness of the techniques proposed to reduce three types of detection errors is verified. The criteria of total error (as the summation of three detection errors) and F-measure, respectively result in about 9.7% and 95.1% for FARSDAT, 17.5% and 91.3% for TIMIT, and 19.6% and 90.2% for the TFARSDAT corpus. The evaluation results show that the proposed framework outperforms the existing well-known methods in terms of both total error and F-measure on both read and spontaneous speech corpora. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Kashani, Hamidreza Baradaran; Sayadiyan, Abolghasem] Amirkabir Univ Technol, Dept Elect Engn, POB 15875-4413,424 Hafez Ave, Tehran, Iran.
RP Sayadiyan, A (corresponding author), Amirkabir Univ Technol, Dept Elect Engn, POB 15875-4413,424 Hafez Ave, Tehran, Iran.
EM hr_baradaran@aut.ac.ir; eeas350@aut.ac.ir
CR Bartels CD, 2010, COMPUT SPEECH LANG, V24, P685, DOI 10.1016/j.csl.2009.11.001
   Bijankhan M., 1994, P 5 INT C SPEECH SCI, P826
   Bijankhan Mahmood, 2003, P EUROSPEECH 2003, P1525
   Brookes M., 1997, VOICEBOX SPEECH PROC, V47
   Cernak M, 2015, IEEE-ACM T AUDIO SPE, V23, P1019, DOI 10.1109/TASLP.2015.2418577
   Choueiter G. F., 2008, THESIS
   Chu SM, 2010, INT CONF ACOUST SPEE, P4306, DOI 10.1109/ICASSP.2010.5495656
   Dekens T, 2014, EUR SIGNAL PR CONF, P1252
   HOLMES JN, 1980, IEE PROC-F, V127, P53, DOI 10.1049/ip-f-1.1980.0010
   Huckvale M., 2008, SPEECH FILING SYSTEM
   International Phonetic Association, 1999, HDB INT PHON ASS GUI
   Jiao Y, 2015, IEEE-ACM T AUDIO SPE, V23, P1421, DOI 10.1109/TASLP.2015.2434213
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Khonglah BK, 2014, IND C INDICON 2014 A, P1
   Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928
   Landsiedel C, 2011, INT CONF ACOUST SPEE, P5256
   Li M, 2013, COMPUT SPEECH LANG, V27, P151, DOI 10.1016/j.csl.2012.01.008
   Makur A, 2001, IEEE T CIRCUITS-I, V48, P1086, DOI 10.1109/81.948436
   Nagarajan T, 2004, EURASIP J APPL SIG P, V2004, P2614, DOI 10.1155/S1110865704406210
   Narendra N. P., 2012, ACM T SPEECH LANG PR, V9, P1, DOI DOI 10.1145/2382434.2382435
   Ng RWM, 2013, IEEE T AUDIO SPEECH, V21, P1841, DOI 10.1109/TASL.2013.2260157
   Obin N, 2013, INT CONF ACOUST SPEE, P6699, DOI 10.1109/ICASSP.2013.6638958
   Prasanna SRM, 2011, IEEE T AUDIO SPEECH, V19, P2552, DOI 10.1109/TASL.2011.2155061
   Rao KS, 2010, COMPUT SPEECH LANG, V24, P474, DOI 10.1016/j.csl.2009.03.003
   Reddy VR, 2013, COMPUT SPEECH LANG, V27, P1105, DOI 10.1016/j.csl.2013.02.003
   Sadjadi SO, 2013, MSR IDENTITY TOOLBOX
   Samarah Y. A., 1977, ARRANGEMENT SEGMENTA
   STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162
   Tachbelie MY, 2014, SPEECH COMMUN, V56, P181, DOI 10.1016/j.specom.2013.01.008
   Thomas S., 2006, IEDM, P1, DOI DOI 10.1109/IEDM.2006.346877
   Veaux C., 2011, P INTERSPEECH, P2765
   Wang D, 2007, IEEE T AUDIO SPEECH, V15, P2190, DOI 10.1109/TASL.2007.905178
   Xie ZM, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1571
   Yadav J, 2016, CIRC SYST SIGNAL PR, V35, P139, DOI 10.1007/s00034-015-0051-3
   Yapanel UH, 2008, SPEECH COMMUN, V50, P142, DOI 10.1016/j.specom.2007.07.006
   Yarra C, 2016, SPEECH COMMUN, V78, P62, DOI 10.1016/j.specom.2016.01.004
   Yuan JH, 2010, INT CONF ACOUST SPEE, P4222, DOI 10.1109/ICASSP.2010.5495686
   Zeng XY, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P528
   ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7
NR 39
TC 0
Z9 0
U1 0
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD JUL
PY 2018
VL 50
BP 105
EP 125
DI 10.1016/j.csl.2017.12.008
PG 21
WC Computer Science, Artificial Intelligence
SC Computer Science
GA FZ3IB
UT WOS:000427479600006
DA 2021-02-24
ER

PT J
AU Karzon, R
   Narayanan, A
   Chen, L
   Lieu, JEC
   Hershey, T
AF Karzon, Roanne
   Narayanan, Anagha
   Chen, Ling
   Lieu, Judith E. C.
   Hershey, Tamara
TI Longitudinal hearing loss in Wolfram syndrome
SO ORPHANET JOURNAL OF RARE DISEASES
LA English
DT Article
DE Wolfram syndrome; Hearing loss; Speech intelligibility index
ID TYPE-1 DIABETES-MELLITUS; OPTIC ATROPHY; WFS1 GENE; SYNDROME FAMILIES;
   DIDMOAD SYNDROME; INTELLIGIBILITY INDEX; TRANSMEMBRANE PROTEIN;
   MUTATION; IMPAIRMENT; IDENTIFICATION
AB Background: Wolfram syndrome (WFS) is a rare autosomal recessive disease with clinical manifestations of diabetes mellitus (DM), diabetes insipidus (DI), optic nerve atrophy (OA) and sensorineural hearing loss (SNHL). Although SNHL is a key symptom of WFS, there is limited information on its natural history using standardized measures. Such information is important for clinical care and determining its use as an outcome measure in clinical trials.
   Methods: Standardized audiologic measures, including pure-tone testing, tympanometry, speech perception, and the unaided Speech Intelligibility Index (SII) were assessed in patients with confirmed WFS annually. Mixed model analyses were used to examine main effects of age, time or interactions for pure tone average (PTA), high frequency average (HFA) and SII.
   Results: Forty WFS patients were evaluated between 1 and 6 times. Mean age at initial enrollment was 13.5 years (SD = 5.6). Patients were classified as having normal hearing (n = 10), mild-to-severe (n = 24) or profound SNHL (n = 6). Mean age of diagnosis for SNHL was 8.3 years (SD = 5.1) with 75% prevalence. HFA worsened over time for both ears, and SII worsened over time in the worse ear, with greater decline in both measures in younger patients. Average estimated change over 1 year for all measures was in the subclinical range and power analyses suggest that 100 patients would be needed per group (treatment vs. placebo) to detect a 60% reduction in annual change of HFA over 3 years. If trials focused on just those patients with SNHL, power estimates suggest 55 patients per group would be sufficient.
   Conclusions: Most patients had a slow progressive SNHL emerging in late childhood. Change over time with standard audiologic tests (HFA, SII) was small and would not be detectable for at least 2 years in an individual. Relatively large sample sizes would be necessary to detect significant impact on hearing progression in a clinical trial. Hearing function should be monitored clinically in WFS to provide appropriate intervention. Because SNHL can occur very early in WFS, audiologists and otolaryngologists should be aware of and refer for later emerging symptoms.
C1 [Karzon, Roanne] St Louis Childrens Hosp, One Childrens Pl, St Louis, MO 63110 USA.
   [Karzon, Roanne] Washington Univ, Program Audiol & Commun Sci, Sch Med, St Louis, MO 63110 USA.
   [Narayanan, Anagha; Hershey, Tamara] Washington Univ, Dept Psychiat, Sch Med, 4525 Scott Ave,Campus Box 8134, St Louis, MO 63110 USA.
   [Chen, Ling] Washington Univ, Div Biostat, Sch Med, St Louis, MO 63110 USA.
   [Lieu, Judith E. C.] Washington Univ, Dept Otolaryngol Head & Neck Surg, Sch Med, St Louis, MO 63110 USA.
   [Hershey, Tamara] Washington Univ, Dept Radiol, Sch Med, 4525 Scott Ave,Campus Box 8134, St Louis, MO 63110 USA.
RP Hershey, T (corresponding author), Washington Univ, Dept Psychiat, Sch Med, 4525 Scott Ave,Campus Box 8134, St Louis, MO 63110 USA.; Hershey, T (corresponding author), Washington Univ, Dept Radiol, Sch Med, 4525 Scott Ave,Campus Box 8134, St Louis, MO 63110 USA.
EM tammy@wustl.edu
OI Hershey, Tamara/0000-0001-7549-0698
FU NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [HD070855];
   CTSAUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Center for Advancing
   Translational Sciences (NCATS) [UL1 RR024992]; Diabetes Research Center
   at Washington University [DK 020579]; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD070855] Funding Source: NIH RePORTER; NATIONAL
   CENTER FOR ADVANCING TRANSLATIONAL SCIENCESUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Center for Advancing Translational Sciences (NCATS)
   [UL1TR002345, UL1TR002345, UL1TR002345, UL1TR000448, UL1TR000448,
   UL1TR002345, UL1TR000448, UL1TR000448, UL1TR000448, UL1TR002345,
   UL1TR002345, UL1TR000448, UL1TR000448, UL1TR002345, UL1TR000448,
   UL1TR000448] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF
   DIABETES AND DIGESTIVE AND KIDNEY DISEASESUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK)
   [P30DK020579, P30DK020579, P30DK020579, P30DK020579, P30DK020579,
   P30DK020579, P30DK020579, P30DK020579, P30DK020579, P30DK020579,
   P30DK020579, P30DK020579, P30DK020579, P30DK020579, P30DK020579,
   P30DK020579, P30DK020579, P30DK020579, P30DK020579, P30DK020579,
   P30DK020579, P30DK020579, P30DK020579, P30DK020579, P30DK020579,
   P30DK020579, P30DK020579, P30DK020579, P30DK020579, P30DK020579,
   P30DK020579, P30DK020579, P30DK020579, P30DK020579, P30DK020579,
   P30DK020579] Funding Source: NIH RePORTER
FX Funded by NICHD (HD070855; Hershey, PI) and supported by the CTSA (UL1
   RR024992) and Diabetes Research Center (DK 020579) at Washington
   University.
CR Aloi C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029150
   American Speech Language Hearing Association, 2005, GUID MAN PUR TON THR
   Ansi A., 1997, NEW YORK AM NAT STAN, V19, P90
   Ariyasu D, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18020382
   Barrett TG, 1997, J MED GENET, V34, P838, DOI 10.1136/jmg.34.10.838
   BARRETT TG, 1995, LANCET, V346, P1458, DOI 10.1016/S0140-6736(95)92473-6
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Blanco-Aguirre ME, 2015, GENE, V566, P63, DOI 10.1016/j.gene.2015.04.040
   Bonnycastle LL, 2013, DIABETES, V62, P3943, DOI 10.2337/db13-0571
   Chaussenot A, 2015, CLIN GENET, V87, P430, DOI 10.1111/cge.12437
   Danielpur L, 2016, J CLIN ENDOCR METAB, V101, P3592, DOI 10.1210/jc.2016-2240
   de Heredia ML, 2013, GENET MED, V15, P497, DOI 10.1038/gim.2012.180
   Domenech E, 2004, CLIN GENET, V65, P463, DOI 10.1111/j.1399-0004.2004.00249.x
   Farmer A, 2013, BMC PEDIATR, V13, DOI 10.1186/1471-2431-13-130
   Ganie MA, 2009, J PEDIATR ENDOCR MET, V22, P3
   Giuliano Fabienne, 2005, Hum Mutat, V25, P99, DOI 10.1002/humu.9300
   GUNN T, 1976, J PEDIATR-US, V89, P565, DOI 10.1016/S0022-3476(76)80387-3
   Hansen L, 2005, EUR J HUM GENET, V13, P1275, DOI 10.1038/sj.ejhg.5201491
   Homa K, 2014, ENDOKRYNOL POL, V65, P398, DOI 10.5603/EP.2014.0055
   Hornsby B. W. Y., 2004, HEARING J, V57, P10
   Inoue H, 1998, NAT GENET, V20, P143, DOI 10.1038/2441
   Karzon RK, 2013, EAR HEARING, V34, P809, DOI 10.1097/AUD.0b013e3182944db7
   Killion M, 2010, HEAR J, V63, P10
   KINSLEY BT, 1995, DIABETES CARE, V18, P1566, DOI 10.2337/diacare.18.12.1566
   Kumar S, 2010, PEDIATR DIABETES, V11, P28, DOI 10.1111/j.1399-5448.2009.00518.x
   Leal Carolina, 2016, Cochlear Implants Int, V17 Suppl 1, P8, DOI 10.1080/14670100.2016.1151635
   Lieber DS, 2012, BMC MED GENET, V13, DOI 10.1186/1471-2350-13-3
   Lombardo F, 2005, J PEDIATR ENDOCR MET, V18, P1391
   Lombardo F, 2014, J ENDOCRINOL INVEST, V37, P195, DOI 10.1007/s40618-013-0039-4
   Marietti G, 1995, Minerva Pediatr, V47, P127
   Marshall BA, 2013, ORPHANET J RARE DIS, V8, DOI 10.1186/1750-1172-8-64
   Matsunaga K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106906
   Medlej R, 2004, J CLIN ENDOCR METAB, V89, P1656, DOI 10.1210/jc.2002-030015
   Mets RB, 2010, OPHTHALMIC GENET, V31, P227, DOI 10.3109/13816810.2010.516056
   Mozzillo E, 2014, BMC MED GENET, V15, DOI 10.1186/1471-2350-15-88
   Nashibi M, 2016, J CELL MOL ANESTH, V1, P126
   Paris LP, 2015, J DIABETES METAB, V6, DOI 10.4172/2155-6156.1000561
   Pennings RJE, 2004, AUDIOL NEURO-OTOL, V9, P51, DOI 10.1159/000074187
   Plantinga RF, 2008, ANN OTO RHINOL LARYN, V117, P494, DOI 10.1177/000348940811700704
   Rendtorff ND, 2011, AM J MED GENET A, V155A, P1298, DOI 10.1002/ajmg.a.33970
   Scollie SD, 2008, EAR HEARING, V29, P543, DOI 10.1097/AUD.0b013e3181734a02
   Simsek E, 2003, ACTA PAEDIATR, V92, P55
   Smith CJA, 2004, DIABETES CARE, V27, P2003, DOI 10.2337/diacare.27.8.2003
   Sobhani M, 2014, MOL BIOL REP, V41, P7499, DOI 10.1007/s11033-014-3642-3
   Stiles DJ, 2012, J SPEECH LANG HEAR R, V55, P764, DOI 10.1044/1092-4388(2011/10-0264)
   Stiles DJ, 2012, J SPEECH LANG HEAR R, V1, P7499
   Strom TM, 1998, HUM MOL GENET, V7, P2021, DOI 10.1093/hmg/7.13.2021
   Urano F, 2016, CURR DIABETES REP, V16, DOI 10.1007/s11892-015-0702-6
   Zalloua P, 2008, HUM MOL GENET, V17, P4012, DOI 10.1093/hmg/ddn304
NR 49
TC 7
Z9 9
U1 0
U2 2
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1750-1172
J9 ORPHANET J RARE DIS
JI Orphanet J. Rare Dis.
PD JUN 27
PY 2018
VL 13
AR 102
DI 10.1186/s13023-018-0852-0
PG 11
WC Genetics & Heredity; Medicine, Research & Experimental
SC Genetics & Heredity; Research & Experimental Medicine
GA GL2VH
UT WOS:000436983000001
PM 29945639
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Devaraju, DS
   Gnanateja, GN
   Kumar, UA
   Maruthy, S
AF Devaraju, Dhatri S.
   Gnanateja, G. Nike
   Kumar, U. Ajith
   Maruthy, Sandeep
TI Gender-bias in the sensory representation of infant cry
SO NEUROSCIENCE LETTERS
LA English
DT Article
DE Infant cry; Frequency following response; Gender difference
ID AUDITORY BRAIN-STEM; FREQUENCY-FOLLOWING RESPONSES; IN-NOISE PERCEPTION;
   MUSICAL EXPERIENCE; SEX-DIFFERENCES; HEAD SIZE; SELECTIVE ATTENTION;
   SPEECH-PERCEPTION; PITCH PATTERNS; DIFFERENTIATION
AB The auditory neural pathway in females appears to be more sensitive to the cry of an infant (De Pisapia et al., 2013; Messina et al., 2016). Cortical responses in females have shown a distinct advantage compared to males in the auditory processing of infant cry. Such gender-bias in the cortical responses might emanate either at higher levels of processing such as cognitive and emotional processing or at the lower level representation of stimulus features. We assessed for a difference if any, between the two genders, in the sensory representation of an infant's cry. We used frequency following responses (FFR) to assess the sensory representation of an infant cry. This was done in sixteen male and fifteen female non-parent adults. The FFR closely mimics the stimulus acoustics with fine temporal precision and is the measure of choice to assess the sensory encoding of sounds in the auditory system. We performed spectral analysis of the FFRs and compared the spectral magnitudes between males and females. We found significantly higher FFR spectral magnitudes in females compared to males. The gender differences found were not related to the confounding variables such as head size or differences in the volume-conducting media. By systematically controlling other influencing variables, we show that the bias in neural processing of infant cry in females emerges right at the sensory representation levels.
C1 [Devaraju, Dhatri S.; Gnanateja, G. Nike; Kumar, U. Ajith; Maruthy, Sandeep] All India Inst Speech & Hearing, Dept Audiol, Mysuru 570006, Karnataka, India.
RP Gnanateja, GN (corresponding author), All India Inst Speech & Hearing, Dept Audiol, Mysuru 570006, Karnataka, India.
EM dhatri2612@gmail.com; nikegnanateja@gmail.com; ajithkumar18@gmail.com;
   msandeepa@gmail.com
RI ; Gnanateja, G. Nike/M-1889-2013
OI Maruthy, Sandeep/0000-0003-0162-6702; Gnanateja, G.
   Nike/0000-0001-7949-1524; S Devaraju, Dhatri/0000-0001-6396-3021; Kumar,
   Ajith/0000-0002-1368-9834
FU AIISH Research Fellowship (Ph.D. fellowship -
   SH/ACA/Ph.D./Admission/2014-15)
FX The authors thank the Director AIISH for permitting to carry out the
   research work. Thanks are due to all the participants who volunteered
   for the study. GNG was funded by the AIISH Research Fellowship (Ph.D.
   fellowship - SH/ACA/Ph.D./Admission/2014-15) while this research work
   was being executed.
CR Abrams D. A., 2005, ASHA LEAD
   Ahadi M, 2014, AURIS NASUS LARYNX, V41, P239, DOI 10.1016/j.anl.2013.10.010
   Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004
   Anderson S, 2010, J NEUROSCI, V30, P4922, DOI 10.1523/JNEUROSCI.0107-10.2010
   [Anonymous], 2009, S3212004 ANSIASA
   [Anonymous], 2013, S311999 ANSIASA
   AOYAGI M, 1990, AUDIOLOGY, V29, P107
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   Chaste P, 2013, BIOL PSYCHIAT, V74, P576, DOI 10.1016/j.biopsych.2013.04.018
   Coffey EBJ, 2017, J NEUROSCI, V37, P830, DOI 10.1523/JNEUROSCI.1265-16.2016
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   De Pisapia N, 2013, NEUROREPORT, V24, P142, DOI 10.1097/WNR.0b013e32835df4fa
   DEMPSEY JJ, 1986, AUDIOLOGY, V25, P258
   Family Health International (Organization), 1985, NETW RES TRIANGLE PA, V7, P3
   GALBRAITH GC, 1995, INT J PSYCHOPHYSIOL, V19, P203, DOI 10.1016/0167-8760(95)00008-G
   Galbraith GC, 1998, NEUROREPORT, V9, P1889, DOI 10.1097/00001756-199806010-00041
   GALBRAITH GC, 1993, BIOL PSYCHOL, V37, P3, DOI 10.1016/0301-0511(93)90024-3
   Galbraith GC, 2000, NEUROSCI LETT, V292, P123, DOI 10.1016/S0304-3940(00)01436-1
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   Krishnan A, 2009, BRAIN LANG, V110, P135, DOI 10.1016/j.bandl.2009.03.005
   Krizman J, 2012, CLIN NEUROPHYSIOL, V123, P590, DOI 10.1016/j.clinph.2011.07.037
   Maruthy S, 2017, JARO-J ASSOC RES OTO, V18, P635, DOI 10.1007/s10162-017-0623-y
   Messina I., 2016, FRONT PSYCHOL, P6
   MICHALEWSKI HJ, 1980, ELECTROEN CLIN NEURO, V48, P351, DOI 10.1016/0013-4694(80)90271-0
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Parbery-Clark A, 2011, NEUROPSYCHOLOGIA, V49, P3338, DOI 10.1016/j.neuropsychologia.2011.08.007
   Skoe E, 2011, J NEUROSCI METH, V196, P308, DOI 10.1016/j.jneumeth.2011.01.020
   Skoe E, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013645
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   SMITH JC, 1975, ELECTROEN CLIN NEURO, V39, P465, DOI 10.1016/0013-4694(75)90047-4
   Song JH, 2012, CEREB CORTEX, V22, P1180, DOI 10.1093/cercor/bhr196
   Strait DL, 2009, ANN NY ACAD SCI, V1169, P209, DOI 10.1111/j.1749-6632.2009.04864.x
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Tomasevic L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185154
   TRUNE DR, 1988, HEARING RES, V32, P165, DOI 10.1016/0378-5955(88)90088-3
   Venuti P, 2012, RES DEV DISABIL, V33, P2255, DOI 10.1016/j.ridd.2012.06.011
   Wang JQ, 2010, NEUROSCI LETT, V469, P319, DOI 10.1016/j.neulet.2009.12.018
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   WORDEN FG, 1968, ELECTROEN CLIN NEURO, V25, P42, DOI 10.1016/0013-4694(68)90085-0
   Zanon M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00803
NR 41
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0304-3940
EI 1872-7972
J9 NEUROSCI LETT
JI Neurosci. Lett.
PD JUN 21
PY 2018
VL 678
BP 138
EP 143
DI 10.1016/j.neulet.2018.04.043
PG 6
WC Neurosciences
SC Neurosciences & Neurology
GA GI9ZE
UT WOS:000434903300021
PM 29729354
DA 2021-02-24
ER

PT J
AU Dai, BH
   Chen, CS
   Long, YH
   Zheng, LF
   Zhao, H
   Bai, XL
   Liu, WD
   Zhang, YX
   Liu, L
   Guo, TM
   Ding, GS
   Lu, CM
AF Dai, Bohan
   Chen, Chuansheng
   Long, Yuhang
   Zheng, Lifen
   Zhao, Hui
   Bai, Xialu
   Liu, Wenda
   Zhang, Yuxuan
   Liu, Li
   Guo, Taomei
   Ding, Guosheng
   Lu, Chunming
TI Neural mechanisms for selectively tuning in to the target speaker in a
   naturalistic noisy situation
SO NATURE COMMUNICATIONS
LA English
DT Article
ID COCKTAIL-PARTY; CORTICAL REPRESENTATION; PREFRONTAL CORTEX;
   SPEECH-PERCEPTION; ATTENDED SPEECH; SYNCHRONIZATION; COMMUNICATION;
   OSCILLATIONS; EMERGENCE; COHERENCE
AB The neural mechanism for selectively tuning in to a target speaker while tuning out the others in a multi-speaker situation (i.e., the cocktail-party effect) remains elusive. Here we addressed this issue by measuring brain activity simultaneously from a listener and from multiple speakers while they were involved in naturalistic conversations. Results consistently show selectively enhanced interpersonal neural synchronization (INS) between the listener and the attended speaker at left temporal-parietal junction, compared with that between the listener and the unattended speaker across different multi-speaker situations. Moreover, INS increases significantly prior to the occurrence of verbal responses, and even when the listener's brain activity precedes that of the speaker. The INS increase is independent of brain-to-speech synchronization in both the anatomical location and frequency range. These findings suggest that INS underlies the selective process in a multi-speaker situation through neural predictions at the content level but not the sensory level of speech.
C1 [Dai, Bohan; Long, Yuhang; Zheng, Lifen; Zhao, Hui; Bai, Xialu; Liu, Wenda; Zhang, Yuxuan; Liu, Li; Guo, Taomei; Ding, Guosheng; Lu, Chunming] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
   [Dai, Bohan; Long, Yuhang; Zheng, Lifen; Zhao, Hui; Bai, Xialu; Liu, Wenda; Zhang, Yuxuan; Liu, Li; Guo, Taomei; Ding, Guosheng; Lu, Chunming] Beijing Normal Univ, IDG McGovern Inst Brain Res, Beijing 100875, Peoples R China.
   [Dai, Bohan] Max Planck Inst Psycholinguist, NL-6525 XD Nijmegen, Netherlands.
   [Dai, Bohan] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, NL-6525 EN Nijmegen, Netherlands.
   [Chen, Chuansheng] Univ Calif Irvine, Dept Psychol & Social Behav, Irvine, CA 92697 USA.
RP Lu, CM (corresponding author), Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.; Lu, CM (corresponding author), Beijing Normal Univ, IDG McGovern Inst Brain Res, Beijing 100875, Peoples R China.
EM uchunming@bnu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31622030, 31411130158]; Fundamental Research
   Funds for the Central UniversitiesFundamental Research Funds for the
   Central Universities [2017EYT32, 2017XTCX04]; Open Research Fund of the
   State Key Laboratory of Cognitive Neuroscience and Learning [CNLYB1605,
   CNLZD1604]
FX This work was supported by National Natural Science Foundation of China
   (31622030 and 31411130158), the Fundamental Research Funds for the
   Central Universities (2017EYT32 and 2017XTCX04), and the Open Research
   Fund of the State Key Laboratory of Cognitive Neuroscience and Learning
   (CNLYB1605 and CNLZD1604).
CR Adolphs R, 2014, BRAIN, V137, P1572, DOI 10.1093/brain/awu108
   Auksztulewicz R, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2003143
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Chang C, 2010, NEUROIMAGE, V50, P81, DOI 10.1016/j.neuroimage.2009.12.011
   Chen JYE, 2015, NEUROIMAGE, V107, P207, DOI 10.1016/j.neuroimage.2014.12.012
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Comon P, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P1
   Corps RE, 2018, COGNITION, V175, P77, DOI 10.1016/j.cognition.2018.01.015
   Cui X, 2012, NEUROIMAGE, V59, P2430, DOI 10.1016/j.neuroimage.2011.09.003
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565
   Funane T, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3602853
   Ghinst MV, 2016, J NEUROSCI, V36, P1596, DOI 10.1523/JNEUROSCI.1730-15.2016
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gohel SR, 2015, BRAIN CONNECT, V5, P23, DOI 10.1089/brain.2013.0210
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grinsted A, 2004, NONLINEAR PROC GEOPH, V11, P561, DOI 10.5194/npg-11-561-2004
   Hasson U, 2015, TRENDS COGN SCI, V19, P304, DOI 10.1016/j.tics.2015.04.006
   Hoshi E, 2006, NEUROSCI RES, V54, P73, DOI 10.1016/j.neures.2005.10.013
   Hoshi Y, 2007, J BIOMED OPT, V12, DOI 10.1117/1.2804911
   Jiang J, 2015, P NATL ACAD SCI USA, V112, P4274, DOI 10.1073/pnas.1422930112
   Jiang J, 2012, J NEUROSCI, V32, P16064, DOI 10.1523/JNEUROSCI.2926-12.2012
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Konvalinka I, 2010, Q J EXP PSYCHOL, V63, P2220, DOI 10.1080/17470218.2010.497843
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lee AKC, 2014, HEARING RES, V307, P111, DOI 10.1016/j.heares.2013.06.010
   Liu YC, 2017, SCI REP-UK, V7, DOI 10.1038/srep43293
   Makeig S, 2004, TRENDS COGN SCI, V8, P204, DOI 10.1016/j.tics.2004.03.008
   McDermott JH, 2009, CURR BIOL, V19, pR1024, DOI 10.1016/j.cub.2009.09.005
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Montague PR, 2002, NEUROIMAGE, V16, P1159, DOI 10.1006/nimg.2002.1150
   Nozawa T, 2016, NEUROIMAGE, V133, P484, DOI 10.1016/j.neuroimage.2016.03.059
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Osaka N, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01811
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521
   Perez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04464-4
   Power AJ, 2012, EUR J NEUROSCI, V35, P1497, DOI 10.1111/j.1460-9568.2012.08060.x
   Raichle ME, 2011, BRAIN CONNECT, V1, P3, DOI 10.1089/brain.2011.0019
   Samson D, 2004, NAT NEUROSCI, V7, P499, DOI 10.1038/nn1223
   Santoro R, 2017, P NATL ACAD SCI USA, V114, P4799, DOI 10.1073/pnas.1617622114
   Scholkmann F, 2014, NEUROIMAGE, V85, P6, DOI 10.1016/j.neuroimage.2013.05.004
   SINGER W, 1995, ANNU REV NEUROSCI, V18, P555, DOI 10.1146/annurev.ne.18.030195.003011
   Smith SM, 2012, P NATL ACAD SCI USA, V109, P3131, DOI 10.1073/pnas.1121329109
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107
   Stolk A, 2014, P NATL ACAD SCI USA, V111, P18183, DOI 10.1073/pnas.1414886111
   Stolk A, 2013, P NATL ACAD SCI USA, V110, P14574, DOI 10.1073/pnas.1303170110
   Xia MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068910
NR 51
TC 29
Z9 29
U1 1
U2 22
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2041-1723
J9 NAT COMMUN
JI Nat. Commun.
PD JUN 19
PY 2018
VL 9
AR 2405
DI 10.1038/s41467-018-04819-z
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GJ7BD
UT WOS:000435538700006
PM 29921937
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hamilton, LS
   Edwards, E
   Chang, EF
AF Hamilton, Liberty S.
   Edwards, Erik
   Chang, Edward F.
TI A Spatial Map of Onset and Sustained Responses to Speech in the Human
   Superior Temporal Gyrus
SO CURRENT BIOLOGY
LA English
DT Article
ID HUMAN AUDITORY-CORTEX; NONNEGATIVE MATRIX FACTORIZATION; PRIMATE
   PREFRONTAL CORTEX; CORTICAL REPRESENTATION; DECISION-MAKING; NATURAL
   SOUNDS; MOTOR CORTEX; PERCEPTION; STIMULI; ORGANIZATION
AB To derive meaning from speech, we must extract multiple dimensions of concurrent information from incoming speech signals. That is, equally important to processing phonetic features is the detection of acoustic cues that give structure and context to the information we hear. How the brain organizes this information is unknown. Using data-driven computational methods on high-density intracranial recordings from 27 human participants, we reveal the functional distinction of neural responses to speech in the posterior superior temporal gyrus according to either onset or sustained response profiles. Though similar response types have been observed throughout the auditory system, we found novel evidence for a major spatial parcellation in which a distinct caudal zone detects acoustic onsets and a rostral-surround zone shows sustained, relatively delayed responses to ongoing speech stimuli. While posterior onset and anterior sustained responses are used substantially during natural speech perception, they are not limited to speech stimuli and are seen even for reversed or spectrally rotated speech. Single-electrode encoding of phonetic features in each zone depended upon whether the sound occurred at sentence onset, suggesting joint encoding of phonetic features and their temporal context. Onset responses in the caudal zone could accurately decode sentence and phrase onset boundaries, providing a potentially important internal mechanism for detecting temporal landmarks in speech and other natural sounds. These findings suggest that onset and sustained responses not only define the basic spatial organization of high-order auditory cortex but also have direct implications for how speech information is parsed in the cortex.
C1 [Hamilton, Liberty S.; Edwards, Erik; Chang, Edward F.] Univ Calif San Francisco, Dept Neurol Surg, 675 Nelson Rising Lane, San Francisco, CA 94158 USA.
   [Hamilton, Liberty S.; Edwards, Erik; Chang, Edward F.] Univ Calif San Francisco, Ctr Integrat Neurosci, 675 Nelson Rising Lane, San Francisco, CA 94158 USA.
   [Hamilton, Liberty S.] Univ Texas Austin, Dept Commun Sci & Disorders, Moody Coll Commun, 2504A Whitis Ave,Stop A1100, Austin, TX 78712 USA.
   [Hamilton, Liberty S.] Univ Texas Austin, Dell Med Sch, Dept Neurol, 1701 Trinity St, Austin, TX 78705 USA.
RP Chang, EF (corresponding author), Univ Calif San Francisco, Dept Neurol Surg, 675 Nelson Rising Lane, San Francisco, CA 94158 USA.; Chang, EF (corresponding author), Univ Calif San Francisco, Ctr Integrat Neurosci, 675 Nelson Rising Lane, San Francisco, CA 94158 USA.
EM edward.chang@ucsf.edu
RI Hamilton, Liberty/V-2542-2019
OI Hamilton, Liberty/0000-0003-0182-2500
FU NIH (National Institute on Deafness and Other Communication
   Disorders)United States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F32 DC014192-01, DP2-OD00862,
   R01-DC012379]; New York Stem Cell Foundation; McKnight Foundation; Shurl
   and Kay Curci Foundation; William K. Bowes Foundation; NVIDIA
   Corporation; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F32DC014192, F32DC014192,
   F32DC014192] Funding Source: NIH RePORTER
FX The authors would like to thank Christoph Schreiner, Keith Johnson,
   Michael Stryker, Brian Malone, Neal Fox, Yulia Oganian, and Matthew
   Leonard for helpful comments on the manuscript. This work was supported
   by grants from the NIH (F32 DC014192-01 Ruth L. Kirschstein postdoctoral
   fellowship from the National Institute on Deafness and Other
   Communication Disorders to L.S.H. and DP2-OD00862 and R01-DC012379 to
   E.F.C.). E.F.C. is a New York Stem Cell Foundation-Robertson
   Investigator. This research was also supported by The New York Stem Cell
   Foundation, The McKnight Foundation, The Shurl and Kay Curci Foundation,
   and The William K. Bowes Foundation. We gratefully acknowledge the
   support of NVIDIA Corporation with the donation of the Tesla K40 GPU
   used for this research.
CR Atencio CA, 2012, J NEUROPHYSIOL, V107, P2594, DOI 10.1152/jn.01025.2011
   Bendor D, 2007, NAT NEUROSCI, V10, P763, DOI 10.1038/nn1888
   Bertrand A, 2008, INT CONF ACOUST SPEE, P4713, DOI 10.1109/ICASSP.2008.4518709
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   BLESSER B, 1972, J SPEECH HEAR RES, V15, P5, DOI 10.1044/jshr.1501.05
   BOATMAN D, 1995, BRAIN LANG, V51, P269, DOI 10.1006/brln.1995.1061
   Bregman AS., 1994, AUDITORY SCENE ANAL
   Briggman KL, 2005, SCIENCE, V307, P896, DOI 10.1126/science.1103736
   Cant NB, 2007, J COMP NEUROL, V503, P432, DOI 10.1002/cne.21391
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Churchland MM, 2012, NATURE, V487, P51, DOI 10.1038/nature11129
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   Da Costa S, 2013, J NEUROSCI, V33, P1858, DOI 10.1523/JNEUROSCI.4405-12.2013
   David SV, 2013, J NEUROSCI, V33, P19154, DOI 10.1523/JNEUROSCI.2270-13.2013
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Ding C, 2008, COMPUT STAT DATA AN, V52, P3913, DOI 10.1016/j.csda.2008.01.011
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Edwards E, 2010, NEUROIMAGE, V50, P291, DOI 10.1016/j.neuroimage.2009.12.035
   Edwards E, 2009, J NEUROPHYSIOL, V102, P377, DOI 10.1152/jn.90954.2008
   Eggermont JJ, 2001, HEARING RES, V157, P1, DOI 10.1016/S0378-5955(01)00259-3
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Foffani G, 2004, J NEUROSCI METH, V135, P107, DOI 10.1016/j.jneumeth.2003.12.011
   Garofolo J., 1993, TIMIT ACOUSTIC PHONE
   Hamilton LS, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00062
   Harms MP, 2003, HUM BRAIN MAPP, V20, P168, DOI 10.1002/hbm.10136
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Honey CJ, 2012, NEURON, V76, P423, DOI 10.1016/j.neuron.2012.08.011
   Howard MA, 2000, J COMP NEUROL, V416, P79, DOI 10.1002/(SICI)1096-9861(20000103)416:1<79::AID-CNE6>3.0.CO;2-2
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Kaas JH, 2000, P NATL ACAD SCI USA, V97, P11793, DOI 10.1073/pnas.97.22.11793
   Kaas JH, 1999, NAT NEUROSCI, V2, P1045, DOI 10.1038/15967
   Kao JC, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8759
   Ladefoged Peter, 1975, COURSE PHONETICS
   Leaver AM, 2010, J NEUROSCI, V30, P7604, DOI 10.1523/JNEUROSCI.0296-10.2010
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Leonard MK, 2019, BRAIN LANG, V193, P58, DOI 10.1016/j.bandl.2016.06.001
   Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011
   Malone BJ, 2015, J NEUROPHYSIOL, V113, P2934, DOI 10.1152/jn.01054.2014
   Mazor O, 2005, NEURON, V48, P661, DOI 10.1016/j.neuron.2005.09.032
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Millman RE, 2015, J COGNITIVE NEUROSCI, V27, P533, DOI 10.1162/jocn_a_00719
   Moerel M, 2012, J NEUROSCI, V32, P14205, DOI 10.1523/JNEUROSCI.1388-12.2012
   Moses DA, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/056004
   Nearey TM, 2001, LANG COGNITIVE PROC, V16, P673, DOI 10.1080/01690960143000173
   Nourski KV, 2014, NEUROIMAGE, V101, P598, DOI 10.1016/j.neuroimage.2014.07.004
   Nourski KV, 2009, J NEUROSCI, V29, P15564, DOI 10.1523/JNEUROSCI.3065-09.2009
   O'Sullivan JA, 2015, J NEUROSCI, V35, P7256, DOI 10.1523/JNEUROSCI.4973-14.2015
   Ortega-Martorell S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047824
   Panzeri S, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0467
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Phillips DP, 2002, HEARING RES, V167, P192, DOI 10.1016/S0378-5955(02)00393-3
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Rauschecker Josef P, 2012, Front Evol Neurosci, V4, P7, DOI 10.3389/fnevo.2012.00007
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rauschecker JP, 1997, J COMP NEUROL, V382, P89
   Ray S, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1000610
   Romanski LM, 2009, ANNU REV NEUROSCI, V32, P315, DOI 10.1146/annurev.neuro.051508.135431
   Romanski LM, 1999, NAT NEUROSCI, V2, P1131, DOI 10.1038/16056
   Romanski LM, 2002, NAT NEUROSCI, V5, P15, DOI 10.1038/nn781
   Roux FE, 2015, CORTEX, V71, P398, DOI 10.1016/j.cortex.2015.07.001
   Saenz M, 2014, HEARING RES, V307, P42, DOI 10.1016/j.heares.2013.07.016
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Schnupp JWH, 2006, J NEUROSCI, V26, P4785, DOI 10.1523/JNEUROSCI.4330-05.2006
   Schonwiesner M, 2009, P NATL ACAD SCI USA, V106, P14611, DOI 10.1073/pnas.0907682106
   Schwartz J.-L., 1992, AUDITORY PROCESSING, P239
   Seifritz E, 2002, SCIENCE, V297, P1706, DOI 10.1126/science.1074355
   Shamma S, 2001, TRENDS COGN SCI, V5, P340, DOI 10.1016/S1364-6613(00)01704-6
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   Singh NC, 2003, J ACOUST SOC AM, V114, P3394, DOI 10.1121/1.1624067
   Slaney M., 1998, AUDITORY TOOLBOX VER
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   SUSSMAN HM, 1984, BRAIN LANG, V22, P167, DOI 10.1016/0093-934X(84)90087-7
   Theunissen FE, 2001, NETWORK-COMP NEURAL, V12, P289, DOI 10.1088/0954-898X/12/3/304
   Tsunada J, 2016, NAT NEUROSCI, V19, P135, DOI 10.1038/nn.4195
   Werner S, 2011, CEREB CORTEX, V21, P920, DOI 10.1093/cercor/bhq161
   Wessinger CM, 2001, J COGNITIVE NEUROSCI, V13, P1, DOI 10.1162/089892901564108
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
   Zheng Y, 2008, J NEUROSCI, V28, P14230, DOI 10.1523/JNEUROSCI.2882-08.2008
NR 84
TC 28
Z9 28
U1 0
U2 4
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD JUN 18
PY 2018
VL 28
IS 12
BP 1860
EP +
DI 10.1016/j.cub.2018.04.033
PG 16
WC Biochemistry & Molecular Biology; Biology; Cell Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA GK8GC
UT WOS:000436455700016
PM 29861132
OA Bronze
DA 2021-02-24
ER

PT J
AU Curtin, S
   Werker, JF
AF Curtin, Suzanne
   Werker, Janet F.
TI PRIMIR on Tone
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE PRIMIR; tone; speech perception; language acquisition; word learning;
   bilingualism; infancy
ID PERCEPTION; LANGUAGE
C1 [Curtin, Suzanne] Univ Calgary, Dept Psychol, Calgary, AB, Canada.
   [Werker, Janet F.] Univ British Columbia, Dept Psychol, Vancouver, BC, Canada.
RP Curtin, S (corresponding author), Univ Calgary, Dept Psychol, Calgary, AB, Canada.; Werker, JF (corresponding author), Univ British Columbia, Dept Psychol, Vancouver, BC, Canada.
EM scurtin@ucalgary.ca; jwerker@psych.ubc.ca
OI Curtin, Suzanne/0000-0003-1509-7960; Werker, Janet
   F./0000-0002-1168-9013
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC) [435-2017-0120,
   435-2014-0917]; Natural Sciences and Engineering Research Council of
   CanadaNatural Sciences and Engineering Research Council of Canada
   (NSERC)CGIAR [327319-2012]
FX The writing of this article was supporting by the Social Sciences and
   Humanities Research Council of Canada (grant 435-2017-0120 to SC and
   grant 435-2014-0917 to JW) and the Natural Sciences and Engineering
   Research Council of Canada (grant 327319-2012 to SC).
CR Curtin S., 2007, OXFORD HDB PSYCHOLIN, P579, DOI [DOI 10.1093/OXFORDHB/9780198568971.001.0001, 10.1093/ oxfordhb/9780198568971.013.0035.]
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
NR 7
TC 3
Z9 3
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 15
PY 2018
VL 9
AR 1007
DI 10.3389/fpsyg.2018.01007
PG 2
WC Psychology, Multidisciplinary
SC Psychology
GA GJ5HD
UT WOS:000435411200001
PM 29962996
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Herrmann, B
   Johnsrude, IS
AF Herrmann, Bjorn
   Johnsrude, Ingrid S.
TI Neural Signatures of the Processing of Temporal Patterns in Sound
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE electroencephalography; entrainment; neural synchronization; stimulus
   statistics; sustained activity; temporal regularity
ID STEADY-STATE RESPONSES; NEURONAL OSCILLATIONS; CORTICAL OSCILLATIONS;
   SUSTAINED POTENTIALS; SPEECH-PERCEPTION; AGING AFFECTS; ENTRAINMENT;
   MODULATION; ATTENTION; REPETITION
AB The ability to detect regularities in sound (i.e., recurring structure) is critical for effective perception, enabling, for example, change detection and prediction. Two seemingly unconnected lines of research concern the neural operations involved in processing regularities: one investigates how neural activity synchronizes with temporal regularities (e.g., frequency modulation; FM) in sounds, whereas the other focuses on increases in sustained activity during stimulation with repeating tone-frequency patterns. In three electroencephalography studies with male and female human participants, we investigated whether neural synchronization and sustained neural activity are dissociable, or whether they are functionally interdependent. Experiment I demonstrated that neural activity synchronizes with temporal regularity (FM) in sounds, and that sustained activity increases concomitantly. In Experiment II, phase coherence of FM in sounds was parametrically varied. Although neural synchronization was more sensitive to changes in FM coherence, such changes led to a systematic modulation of both neural synchronization and sustained activity, with magnitude increasing as coherence increased. In Experiment III, participants either performed a duration categorization task on the sounds, or a visual object tracking task to distract attention. Neural synchronization was observed regardless of task, whereas the sustained response was observed only when attention was on the auditory task, not under (visual) distraction. The results suggest that neural synchronization and sustained activity levels are functionally linked: both are sensitive to regularities in soun(d)s. However, neural synchronization might reflect a more sensory-driven response to regularity, compared with sustained activity which may be influenced by attentional, contextual, or other experiential factors.
C1 [Herrmann, Bjorn; Johnsrude, Ingrid S.] Univ Western Ontario, Brain & Mind Inst, London, ON N6A 3K7, Canada.
   [Johnsrude, Ingrid S.] Univ Western Ontario, Sch Commun Sci & Disorders, London, ON N6A 5B7, Canada.
RP Herrmann, B (corresponding author), Univ Western Ontario, Brain & Mind Inst, London, ON N6A 3K7, Canada.
EM herrmann.b@gmail.com
RI Herrmann, Bjorn/H-8000-2019; Johnsrude, Ingrid S/G-4694-2011
OI Herrmann, Bjorn/0000-0001-6362-3043; Johnsrude, Ingrid
   S/0000-0002-7810-1333
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP133450]; CFREF (Canada First Research Excellence
   Fund) BrainsCAN postdoctoral fellowship
FX This work was supported by the Canadian Institutes of Health Research
   (MOP133450 to I.S.J.), and the CFREF (Canada First Research Excellence
   Fund) BrainsCAN postdoctoral fellowship awarded to B.H. We thank
   Youngkyung Jung and Suvarna Moharir for their help during data
   acquisition.
CR Alvarez GA, 2007, J VISION, V7, DOI 10.1167/7.13.14
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Bakdash JZ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00456
   Baldeweg T, 2006, TRENDS COGN SCI, V10, P93, DOI 10.1016/j.tics.2006.01.010
   Barascud N, 2016, P NATL ACAD SCI USA, V113, pE616, DOI 10.1073/pnas.1508523113
   Barnes R, 2000, COGNITIVE PSYCHOL, V41, P254, DOI 10.1006/cogp.2000.0738
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Bendixen A, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00060
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Boettcher FA, 2002, HEARING RES, V165, P10, DOI 10.1016/S0378-5955(01)00398-7
   Cavanagh P, 2005, TRENDS COGN SCI, V9, P349, DOI 10.1016/j.tics.2005.05.009
   Costa-Faidella J, 2017, NEUROIMAGE, V159, P195, DOI 10.1016/j.neuroimage.2017.07.056
   DAVID E, 1969, PFLUG ARCH EUR J PHY, V309, P362, DOI 10.1007/BF00587759
   Davis MH, 2007, P NATL ACAD SCI USA, V104, P16032, DOI 10.1073/pnas.0701309104
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Doelling KB, 2015, P NATL ACAD SCI USA, V112, pE6233, DOI 10.1073/pnas.1508431112
   Elhilali M, 2009, PLOS BIOL, V7, DOI 10.1371/journal.pbio.1000129
   Garrido MI, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002999
   Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Heilbron M, 2017, NEUROSCIENCE, DOI [10.1016/j.neuroscience.Medline, DOI 10.1016/J.NEUROSCIENCE.MEDLINE]
   Henry MJ, 2014, TIMING TIME PERCEPTI, V2, P62, DOI DOI 10.1163/22134468-00002011
   Henry MJ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15801
   Henry MJ, 2014, P NATL ACAD SCI USA, V111, P14935, DOI 10.1073/pnas.1408741111
   Henry MJ, 2012, P NATL ACAD SCI USA, V109, P20095, DOI 10.1073/pnas.1213390109
   Herrmann B, 2018, J EXP PSYCHOL HUMAN, V44, P89, DOI 10.1037/xhp0000432
   Herrmann B, 2017, EUR J NEUROSCI, V45, P299, DOI 10.1111/ejn.13463
   Herrmann B, 2016, NEUROIMAGE, V124, P487, DOI 10.1016/j.neuroimage.2015.09.019
   Herrmann B, 2013, J NEUROSCI, V33, P15799, DOI 10.1523/JNEUROSCI.1434-13.2013
   Holmes E, 2018, JARO-J ASSOC RES OTO, V19, P83, DOI 10.1007/s10162-017-0641-9
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   JARVILEHTO T, 1978, BIOL PSYCHOL, V7, P1, DOI 10.1016/0301-0511(78)90038-8
   John MS, 2002, EAR HEARING, V23, P106, DOI 10.1097/00003446-200204000-00004
   John MS, 2001, AUDIOL NEURO-OTOL, V6, P12, DOI 10.1159/000046805
   Jones MR, 2002, PSYCHOL SCI, V13, P313, DOI 10.1111/1467-9280.00458
   Kayser SJ, 2015, J NEUROSCI, V35, P14691, DOI 10.1523/JNEUROSCI.2243-15.2015
   Keitel A, 2017, NEUROIMAGE, V147, P32, DOI 10.1016/j.neuroimage.2016.11.062
   KOHLER W, 1955, J CELL COMPAR PHYSL, V45, P25, DOI 10.1002/jcp.1030450403
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lakatos P, 2013, J NEUROSCI, V33, P11692, DOI 10.1523/JNEUROSCI.0010-13.2013
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   MacMillan N. A., 2005, DETECTION THEORY USE
   MAISTE A, 1989, EAR HEARING, V10, P153, DOI 10.1097/00003446-198906000-00003
   Makeig S, 1996, ADV NEURAL INFORM PR
   Masson MEJ, 2003, CAN J EXP PSYCHOL, V57, P203, DOI 10.1037/h0087426
   Masutomi K, 2016, J EXP PSYCHOL HUMAN, V42, P386, DOI 10.1037/xhp0000147
   McDermott JH, 2013, NAT NEUROSCI, V16, P493, DOI 10.1038/nn.3347
   Millman RE, 2017, J NEUROSCI, V37, P7727, DOI 10.1523/JNEUROSCI.2722-16.2017
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nobre AC, 2018, NAT REV NEUROSCI, V19, P34, DOI 10.1038/nrn.2017.141
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   PICTON TW, 1978, ELECTROEN CLIN NEURO, V45, P186, DOI 10.1016/0013-4694(78)90003-2
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Puvvada KC, 2017, J NEUROSCI, V37, P9189, DOI 10.1523/JNEUROSCI.0938-17.2017
   PYLYSHYN Z W, 1988, Spatial Vision, V3, P179, DOI 10.1163/156856888X00122
   Rosenthal R, 2003, PSYCHOL METHODS, V8, P492, DOI 10.1037/1082-989X.8.4.492
   Scholl BJ, 2009, COMPUTATION, COGNITION, AND PYLYSHYN, P49
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Schroger E, 2007, J PSYCHOPHYSIOL, V21, P138, DOI 10.1027/0269-8803.21.34.138
   Sohoglu E, 2016, ELIFE, V5, DOI 10.7554/eLife.19113
   Southwell R, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0105
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Sussman ES, 2007, PERCEPT PSYCHOPHYS, V69, P136, DOI 10.3758/BF03194460
   Sussman ES, 2017, J SPEECH LANG HEAR R, V60, P2989, DOI 10.1044/2017_JSLHR-H-17-0041
   Teki S, 2016, CEREB CORTEX, V26, P3669, DOI 10.1093/cercor/bhw173
   ten Oever S, 2017, J NEUROSCI, V37, P4903, DOI 10.1523/JNEUROSCI.3658-16.2017
   Tombu M, 2008, COGNITION, V108, P1, DOI 10.1016/j.cognition.2007.12.014
   Weise A, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.13063
   Whittingstall K, 2009, NEURON, V64, P281, DOI 10.1016/j.neuron.2009.08.016
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Xiang JJ, 2010, J NEUROSCI, V30, P12084, DOI 10.1523/JNEUROSCI.0827-10.2010
NR 79
TC 7
Z9 7
U1 2
U2 12
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
J9 J NEUROSCI
JI J. Neurosci.
PD JUN 13
PY 2018
VL 38
IS 24
BP 5466
EP 5477
DI 10.1523/JNEUROSCI.0346-18.2018
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA GJ5IB
UT WOS:000435413600003
PM 29773757
OA Bronze
DA 2021-02-24
ER

PT J
AU Shin, M
   Choi, Y
   Mazuka, R
AF Shin, Minha
   Choi, Youngon
   Mazuka, Reiko
TI Development of fricative sound perception in Korean infants: The role of
   language experience and infants' initial sensitivity
SO PLOS ONE
LA English
DT Article
ID ADULT-DIRECTED SPEECH; JAPANESE INFANTS; DISCRIMINATION; PATTERNS
AB In this paper, we report data on the development of Korean infants' perception of a rare fricative phoneme distinction. Korean fricative consonants have received much interest in the linguistic community due to the language's distinct categorization of sounds. Unlike many fricative contrasts utilized in most of the world's languages, Korean fricatives (/s*/-/s/) are all voiceless. Moreover, compared with other sound categories, fricatives have received very little attention in the speech perception development field and no studies thus far have examined Korean infants' development of native phonology in this domain. Using a visual habituation paradigm, we tested 4-6-month-old and 7-9-month-old Korean infants on their abilities to discriminate the Korean fricative pair in the [a] vowel context, /s*a/-/sa/, which can be distinguished based on acoustic cues, such as the durations of aspiration and frication noise. Korean infants older than 7 months were able to reliably discriminate the fricative pair but younger infants did not show clear signs of such discrimination. These results add to the growing evidence that there are native sound contrasts infants cannot discriminate early on without a certain amount of language exposure, providing further data to help delineate the specific nature of early perceptual capacity.
C1 [Shin, Minha; Choi, Youngon] Chung Ang Univ, Dept Psychol, Seoul, South Korea.
   [Mazuka, Reiko] RIKEN Ctr Brain Sci, Lab Language Dev, Tokyo, Japan.
   [Mazuka, Reiko] Duke Univ, Dept Psychol & Neurosci, Durham, NC USA.
RP Choi, Y (corresponding author), Chung Ang Univ, Dept Psychol, Seoul, South Korea.
EM yochoi@cau.ac.kr
RI Mazuka, Reiko/N-7400-2015
OI Choi, Youngon/0000-0002-0698-1511
FU Chung-Ang University Graduate Research Scholarship; Korean National
   Research FoundationNational Research Foundation of Korea
   [NRF-2014R1A1A2054072]; Japanese Society for Promotion of
   ScienceMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of Science [16H06319];
   Japanese Ministry of Education, Culture, Sports, Science and
   TechnologyMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT) [4903, 17H06382]
FX This research was supported by the Chung-Ang University Graduate
   Research Scholarship in 2018 to M. Shin, by a Korean National Research
   Foundation grant (NRF-2014R1A1A2054072) to Y. Choi, and by a Japanese
   Society for Promotion of Science Grant in-Aid for Scientific Research
   S(16H06319), Japanese Ministry of Education, Culture, Sports, Science
   and Technology Grant-in-Aid for Innovative Areas #4903 (17H06382) to R.
   Mazuka.
CR [Anonymous], 1991, EMERGENCE NATIVE LAN
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Chang C. B., 2007, KOREAN FRICATIVES PR, P20
   Chang CB, 2013, KOREAN LINGUIST, V15, P7, DOI 10.1075/kl.15.1.02cha
   Cheon H, 1998, DEV KOREAN S S NORMA
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Choi Y, 2017, INT C STUD CHILD LAN, P37
   EILERS RE, 1975, J SPEECH HEAR RES, V18, P158, DOI 10.1044/jshr.1801.158
   EILERS RE, 1977, J SPEECH HEAR RES, V20, P766, DOI 10.1044/jshr.2004.766
   EILERS RE, 1979, CHILD DEV, V50, P14
   EILERS RE, 1977, J ACOUST SOC AM, V61, P1321, DOI 10.1121/1.381435
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Hong G, 2002, KOREAN J COMMUNICATI, V7, P106
   Hoonhorst I, 2009, J EXP CHILD PSYCHOL, V104, P353, DOI 10.1016/j.jecp.2009.07.005
   Hyunkee Ahn，, 2009, [Korean Journal of English Language and Linguistics, 영어학], V9, P281
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kim M, 2011, J CHILD LANG, V38, P316, DOI 10.1017/S0305000909990353
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, DOI [10.1111/j.1467-7687.2006.00468.x/full, DOI 10.1111/J.1467-7687.2006.00468.X/FULL]
   LASKY RE, 1975, J EXP CHILD PSYCHOL, V20, P215, DOI 10.1016/0022-0965(75)90099-5
   Lee K, 1999, KOREAN LINGUIST, V10, P47
   Lee S, 2008, J CHILD LANG, V35, P591, DOI 10.1017/S0305000908008684
   Lee SAS, 2010, J CHILD LANG, V37, P767, DOI 10.1017/S0305000909009568
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Mazuka R, 2014, DEV PSYCHOBIOL, V56, P192, DOI 10.1002/dev.21193
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   Sato Y, 2012, DEV PSYCHOL, V48, P18, DOI 10.1037/a0025528
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Schneider W., 2012, E PRIME 2 0
   Shin J, 2004, SYSTEM OUR SPEECH BA
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Tsuji S, 2014, J CHILD LANG, V41, P1276, DOI 10.1017/S0305000913000469
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2012, CURR DIR PSYCHOL SCI, V21, P221, DOI 10.1177/0963721412449459
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yoon K., 1999, MID LING C
NR 41
TC 0
Z9 0
U1 1
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUN 13
PY 2018
VL 13
IS 6
AR e0199045
DI 10.1371/journal.pone.0199045
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GJ2HI
UT WOS:000435090700089
PM 29897999
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Glanz, O
   Derix, J
   Kaur, R
   Schulze-Bonhage, A
   Auer, P
   Aertsen, A
   Ball, T
AF Glanz, Olga (Ijina)
   Derix, Johanna
   Kaur, Rajbir
   Schulze-Bonhage, Andreas
   Auer, Peter
   Aertsen, Ad
   Ball, Tonio
TI Real-life speech production and perception have a shared
   premotor-cortical substrate
SO SCIENTIFIC REPORTS
LA English
DT Article
ID ELECTROCORTICOGRAPHIC GAMMA ACTIVITY; AUDIOVISUAL SPEECH; CORTEX; MOTOR;
   LANGUAGE; ORGANIZATION; AREAS; ACTIVATION; FMRI; STIMULATION
AB Motor-cognitive accounts assume that the articulatory cortex is involved in language comprehension, but previous studies may have observed such an involvement as an artefact of experimental procedures. Here, we employed electrocorticography (ECoG) during natural, non-experimental behavior combined with electrocortical stimulation mapping to study the neural basis of real-life human verbal communication. We took advantage of ECoG's ability to capture high-gamma activity (70-350 Hz) as a spatially and temporally precise index of cortical activation during unconstrained, naturalistic speech production and perception conditions. Our findings show that an electrostimulation-defined mouth motor region located in the superior ventral premotor cortex is consistently activated during both conditions. This region became active early relative to the onset of speech production and was recruited during speech perception regardless of acoustic background noise. Our study thus pinpoints a shared ventral premotor substrate for real-life speech production and perception with its basic properties.
C1 [Glanz, Olga (Ijina); Auer, Peter] Univ Freiburg, GRK Frequency Effects Language 1624, Freiburg, Germany.
   [Glanz, Olga (Ijina); Auer, Peter] Univ Freiburg, Dept German Linguist, Freiburg, Germany.
   [Glanz, Olga (Ijina); Derix, Johanna; Kaur, Rajbir; Ball, Tonio] Univ Freiburg, Hermann Paul Sch Linguist, Freiburg, Germany.
   [Glanz, Olga (Ijina); Derix, Johanna; Schulze-Bonhage, Andreas; Ball, Tonio] Univ Freiburg, Fac Med, Med Ctr, Dept Neurosurg,Translat Neurotechnol Lab, Freiburg, Germany.
   [Glanz, Olga (Ijina); Derix, Johanna] Univ Freiburg, BrainLinks BrainTools, Freiburg, Germany.
   [Glanz, Olga (Ijina); Derix, Johanna; Aertsen, Ad] Univ Freiburg, Fac Biol, Neurobiol & Biophys, Freiburg, Germany.
   [Kaur, Rajbir] Univ Cologne, Fac Med, Cologne, Germany.
   [Schulze-Bonhage, Andreas] Univ Freiburg, Fac Med, Med Ctr, Epilepsy Ctr,Dept Neurosurg, Freiburg, Germany.
   [Schulze-Bonhage, Andreas; Aertsen, Ad; Ball, Tonio] Univ Freiburg, Bernstein Ctr Freiburg, Freiburg, Germany.
RP Glanz, O (corresponding author), Univ Freiburg, GRK Frequency Effects Language 1624, Freiburg, Germany.; Glanz, O (corresponding author), Univ Freiburg, Dept German Linguist, Freiburg, Germany.; Glanz, O; Ball, T (corresponding author), Univ Freiburg, Hermann Paul Sch Linguist, Freiburg, Germany.; Glanz, O; Ball, T (corresponding author), Univ Freiburg, Fac Med, Med Ctr, Dept Neurosurg,Translat Neurotechnol Lab, Freiburg, Germany.; Glanz, O (corresponding author), Univ Freiburg, BrainLinks BrainTools, Freiburg, Germany.; Glanz, O (corresponding author), Univ Freiburg, Fac Biol, Neurobiol & Biophys, Freiburg, Germany.; Ball, T (corresponding author), Univ Freiburg, Bernstein Ctr Freiburg, Freiburg, Germany.
EM olga.glanz@uniklinik-freiburg.de; tonio.ball@uniklinik-freiburg.de
RI Schulze-Bonhage, Andreas/AAJ-3107-2020
OI Glanz, Olga/0000-0001-5420-3135
FU 'Frequency effects in language' (University of Freiburg) [DFG-GRK 1624];
   BrainLinks-BrainTools (DfG grant, University of Freiburg) [EXC1086];
   Baden-Wurttemberg Stiftung [NEU018]
FX We thank DFG-GRK 1624 'Frequency effects in language' (University of
   Freiburg), BrainLinks-BrainTools (DfG grant EXC1086, University of
   Freiburg) and the Baden-Wurttemberg Stiftung (grant NEU018) for
   financial support.
CR Ball T, 2009, NEUROIMAGE, V46, P708, DOI 10.1016/j.neuroimage.2009.02.028
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Callan DE, 2004, J COGNITIVE NEUROSCI, V16, P805, DOI 10.1162/089892904970771
   Campbell R, 2001, COGNITIVE BRAIN RES, V12, P233, DOI 10.1016/S0926-6410(01)00054-4
   Carota F, 2010, CEREB CORTEX, V20, P1891, DOI 10.1093/cercor/bhp255
   Crone NE, 2011, INT J PSYCHOPHYSIOL, V79, P9, DOI 10.1016/j.ijpsycho.2010.10.013
   Crone NE, 2001, CLIN NEUROPHYSIOL, V112, P565, DOI 10.1016/S1388-2457(00)00545-9
   Crone NE, 2001, NEUROLOGY, V57, P2045, DOI 10.1212/WNL.57.11.2045
   Crone NE, 1998, BRAIN, V121, P2301, DOI 10.1093/brain/121.12.2301
   Derix J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00383
   Derix J, 2012, FRONT HUM NEUROSCI, V6, P1, DOI 10.3389/fnhum.2012.00251
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Dubois C, 2012, NEUROPSYCHOLOGIA, V50, P1316, DOI 10.1016/j.neuropsychologia.2012.02.016
   Dufor O, 2009, NEUROIMAGE, V46, P241, DOI 10.1016/j.neuroimage.2009.01.035
   Eickhoff SB, 2007, CEREB CORTEX, V17, P1800, DOI 10.1093/cercor/bhl090
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Fowler CA, 2016, SPEECH MOTOR CONTROL, P1
   FOWLER CA, 1994, ENCY LANGUAGE LINGUI, P4199
   Fridriksson J, 2008, NEUROIMAGE, V41, P605, DOI 10.1016/j.neuroimage.2008.02.046
   Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402
   Geyer S, 1996, NATURE, V382, P805, DOI 10.1038/382805a0
   HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686
   Haruno M, 2001, NEURAL COMPUT, V13, P2201, DOI 10.1162/089976601750541778
   Hasson U, 2010, TRENDS COGN SCI, V14, P40, DOI 10.1016/j.tics.2009.10.011
   Heim S, 2008, NEUROIMAGE, V40, P1362, DOI 10.1016/j.neuroimage.2008.01.009
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   HOCHBERG Y, 1990, STAT MED, V9, P811, DOI 10.1002/sim.4780090710
   Iacoboni M, 2008, J PHYSIOL-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003
   Iljina O, 2017, BRAIN-COMPUT INTERFA, V4, P186, DOI 10.1080/2326263X.2017.1330611
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   Liberman A., 1962, P SP COMM SEM STOCKH
   Liberman A. M., 1967, MODELS PERCEPTION SP, P68
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Logothetis NK, 2008, NATURE, V453, P869, DOI 10.1038/nature06976
   Manning JR, 2009, J NEUROSCI, V29, P13613, DOI 10.1523/JNEUROSCI.2041-09.2009
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Menenti L, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00185
   Menenti L, 2011, PSYCHOL SCI, V22, P1173, DOI 10.1177/0956797611418347
   Miller K., 2005, COMMUNICATION THEORI
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Nourski KV, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00202
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Okada K, 2006, BRAIN LANG, V98, P112, DOI 10.1016/j.bandl.2006.04.006
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Pei XM, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/4/046028
   Penfield W, 1937, BRAIN, V60, P389, DOI 10.1093/brain/60.4.389
   Percival DB, 2000, CA ST PR MA
   Pistohl T, 2012, NEUROIMAGE, V59, P248, DOI 10.1016/j.neuroimage.2011.06.084
   Poeppel D, 2004, COGNITION, V92, P1, DOI 10.1016/j.cognition.2003.11.001
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Pulvermtiller F., 2003, NEUROSCIENCE LANGUAG
   Pulvermuller F., 2016, HDB NEUROBIOLOGY LAN, P311, DOI 10.1016/C2011-0-07351-9
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Ray S, 2008, CLIN NEUROPHYSIOL, V119, P116, DOI 10.1016/j.clinph.2007.09.136
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Rorden C, 2000, BEHAV NEUROL, V12, P191, DOI 10.1155/2000/421719
   Ruescher J, 2013, NEUROIMAGE, V81, P164, DOI 10.1016/j.neuroimage.2013.04.102
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Shimada K, 2015, NEUROSCIENCE, V300, P474, DOI 10.1016/j.neuroscience.2015.05.045
   Sinai A, 2005, BRAIN, V128, P1556, DOI 10.1093/brain/awh491
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Szenkovits G, 2012, NEUROPSYCHOLOGIA, V50, P1380, DOI 10.1016/j.neuropsychologia.2012.02.023
   Toga AW, 2006, NAT REV NEUROSCI, V7, P952, DOI 10.1038/nrn2012
   Towle VL, 2008, BRAIN, V131, P2013, DOI 10.1093/brain/awn147
   Tremblay P, 2011, NEUROIMAGE, V57, P1561, DOI 10.1016/j.neuroimage.2011.05.067
   Venezia JH, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00157
   WALKER MB, 1982, J SOC PSYCHOL, V117, P305, DOI 10.1080/00224545.1982.9713444
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wellmer J, 2009, EPILEPSIA, V50, P2267, DOI 10.1111/j.1528-1167.2009.02192.x
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
   Wilson SM, 2009, TRENDS COGN SCI, V13, P329, DOI 10.1016/j.tics.2009.06.001
NR 78
TC 9
Z9 9
U1 0
U2 6
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUN 11
PY 2018
VL 8
AR 8898
DI 10.1038/s41598-018-26801-x
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GI8MP
UT WOS:000434779300006
PM 29891885
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Marian, V
   Lam, TQ
   Hayakawa, S
   Dhar, S
AF Marian, Viorica
   Lam, Tuan Q.
   Hayakawa, Sayuri
   Dhar, Sumitrajit
TI Top-Down Cognitive and Linguistic Influences on the Suppression of
   Spontaneous Otoacoustic Emissions
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE otoacoustic emissions; individual differences; speech perception;
   bilingualism; cognitive control; executive function
ID CONTRALATERAL ACOUSTIC STIMULATION; PERIPHERAL AUDITORY ACTIVITY;
   SPEECH-PERCEPTION; WORKING-MEMORY; OLIVOCOCHLEAR REFLEX; NOISE; HUMANS;
   BILINGUALISM; EAR; ENHANCEMENT
AB Auditory sensation is often thought of as a bottom-up process, yet the brain exerts top-down control to affect how and what we hear. We report the discovery that the magnitude of top-down influence varies across individuals as a result of differences in linguistic background and executive function. Participants were 32 normal-hearing individuals (23 female) varying in language background (11 English monolinguals, 10 Korean-English late bilinguals, and 11 Korean-English early bilinguals), as well as cognitive abilities (working memory, cognitive control). To assess efferent control over inner ear function, participants were presented with speech-sounds (e.g., /ba/, /pa/) in one ear while spontaneous otoacoustic emissions (SOAEs) were measured in the contralateral ear. SOAEs are associated with the amplification of sound in the cochlea, and can be used as an index of top-down efferent activity. Individuals with bilingual experience and those with better cognitive control experienced larger reductions in the amplitude of SOAEs in response to speech stimuli, likely as a result of greater efferent suppression of amplification in the cochlea. This suppression may aid in the critical task of speech perception by minimizing the disruptive effects of noise. In contrast, individuals with better working memory exert less control over the cochlea, possibly due to a greater capacity to process complex stimuli at later stages. These findings demonstrate that even peripheral mechanics of auditory perception are shaped by top-down cognitive and linguistic influences.
C1 [Marian, Viorica; Hayakawa, Sayuri; Dhar, Sumitrajit] Northwestern Univ, Dept Commun Sci & Disorders, Evanston, IL 60208 USA.
   [Lam, Tuan Q.] Loyola Univ, Dept Psychol Sci, New Orleans, LA 70118 USA.
RP Marian, V (corresponding author), Northwestern Univ, Dept Commun Sci & Disorders, Evanston, IL 60208 USA.
EM v-marian@northwestern.edu
RI Dhar, Sumit/B-6319-2009; Hayakawa, Sayuri/AAE-6252-2020
OI Hayakawa, Sayuri/0000-0001-9863-1406; Dhar,
   Sumitrajit/0000-0002-4496-6355
FU NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD059858];
   NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [T32-DC009399-04]; EUNICE KENNEDY
   SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child
   Health & Human Development (NICHD) [R01HD059858, R01HD059858,
   R01HD059858, R01HD059858, R01HD059858, R01HD059858, R01HD059858] Funding
   Source: NIH RePORTER; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH &HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD059858, R01HD059858] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [T32DC009399, T32DC009399, T32DC009399, T32DC009399,
   T32DC009399] Funding Source: NIH RePORTER
FX This project was funded in part by grant NICHD R01HD059858 to VM and by
   training grant NIDCD T32-DC009399-04 to TL.
CR Bernaards CA, 2005, EDUC PSYCHOL MEAS, V65, P676, DOI DOI 10.1177/0013164404272507
   Bialystok E, 2004, PSYCHOL AGING, V19, P290, DOI 10.1037/0882-7974.19.2.290
   Bialystok E., 2001, BILINGUALISM DEV LAN
   Bialystok E, 2008, J EXP PSYCHOL LEARN, V34, P859, DOI 10.1037/0278-7393.34.4.859
   Blom E, 2014, J EXP CHILD PSYCHOL, V128, P105, DOI 10.1016/j.jecp.2014.06.007
   Blumenfeld HK, 2011, COGNITION, V118, P245, DOI 10.1016/j.cognition.2010.10.012
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Brashears Shanda M, 2003, J Am Acad Audiol, V14, P314
   Calvo N, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00265
   Cooper NP, 2006, J PHYSIOL-LONDON, V576, P49, DOI 10.1113/jphysiol.2006.114991
   Costa A, 2008, COGNITION, V106, P59, DOI 10.1016/j.cognition.2006.12.013
   de Abreu PMJE, 2011, MEMORY, V19, P529, DOI 10.1080/09658211.2011.590504
   Deeter R, 2009, J ACOUST SOC AM, V126, P2413, DOI 10.1121/1.3224716
   Gershon RC, 2013, NEUROLOGY, V80, pS2, DOI 10.1212/WNL.0b013e3182872e5f
   Gollan TH, 2008, J MEM LANG, V58, P787, DOI 10.1016/j.jml.2007.07.001
   Guinan JJ, 2006, EAR HEARING, V27, P589, DOI 10.1097/01.aud.0000240507.83072.e7
   Gunter TC, 2003, J COGNITIVE NEUROSCI, V15, P643, DOI 10.1162/jocn.2003.15.5.643
   HARRISON WA, 1993, J ACOUST SOC AM, V94, P2649, DOI 10.1121/1.407349
   KAWASE T, 1993, J NEUROPHYSIOL, V70, P2533
   Khalfa S, 2001, NEUROSCIENCE, V104, P347, DOI 10.1016/S0306-4522(01)00072-0
   Kumar UA, 2004, EAR HEARING, V25, P142, DOI 10.1097/01.AUD.0000120363.56591.E6
   LAVIE N, 1994, PERCEPT PSYCHOPHYS, V56, P183, DOI 10.3758/BF03213897
   Marian V., 2003, BILING-LANG COGN, V6, P97, DOI DOI 10.1017/S1366728903001068
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   MCFADDEN D, 1993, HEARING RES, V71, P208, DOI 10.1016/0378-5955(93)90036-Z
   MOTT JB, 1989, HEARING RES, V38, P229, DOI 10.1016/0378-5955(89)90068-3
   NAEVE SL, 1992, J ACOUST SOC AM, V91, P2091, DOI 10.1121/1.403695
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Perrot X, 2006, CEREB CORTEX, V16, P941, DOI 10.1093/cercor/bhj035
   Perrot X, 1999, NEUROSCI LETT, V262, P167, DOI 10.1016/S0304-3940(99)00044-0
   Perrot X, 2014, HEARING RES, V308, P27, DOI 10.1016/j.heares.2013.08.010
   R Core Team, 2016, R LANG ENV STAT COMP
   Revelle WR, 2017, PSYCH PROCEDURES PER
   Rodriguez-Fornells A, 2005, J COGNITIVE NEUROSCI, V17, P422, DOI 10.1162/0898929053279559
   Rudner M, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/869726
   SCHLOTH E, 1983, HEARING RES, V11, P285, DOI 10.1016/0378-5955(83)90063-1
   Schroeder SR, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4058620
   Sorqvist P, 2012, J COGNITIVE NEUROSCI, V24, P2147
   Strait D, 2011, MUSIC PERCEPT, V29, P133, DOI 10.1525/MP.2011.29.2.133
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   TALMADGE CL, 1993, HEARING RES, V71, P170, DOI 10.1016/0378-5955(93)90032-V
   Terreros G, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00134
   Thierry G, 2007, P NATL ACAD SCI USA, V104, P12530, DOI 10.1073/pnas.0609927104
   Weiss D, 2008, J AM ACAD AUDIOL, V19, P5, DOI 10.3766/jaaa.19.1.2
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Zhao W, 2012, J NEUROPHYSIOL, V108, P25, DOI 10.1152/jn.00051.2012
   Zhao W, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018725
   Zhao W, 2010, JARO-J ASSOC RES OTO, V11, P53, DOI 10.1007/s10162-009-0189-4
NR 52
TC 3
Z9 3
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JUN 8
PY 2018
VL 12
AR 378
DI 10.3389/fnins.2018.00378
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA GI7HJ
UT WOS:000434673100001
PM 29937708
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gabay, Y
   Holt, LL
AF Gabay, Yafit
   Holt, Lori L.
TI Short-term adaptation to sound statistics is unimpaired in developmental
   dyslexia
SO PLOS ONE
LA English
DT Article
ID SPEECH-PERCEPTION; NONLINGUISTIC SOUNDS; NONSPEECH SOUNDS; PRECEDING
   LIQUID; CONTEXT; CATEGORIZATION; DEFICIT; DISCRIMINATION; INFORMATION;
   LANGUAGE
AB Developmental dyslexia is presumed to arise from phonological impairments. Accordingly, people with dyslexia show speech perception deficits taken as indication of impoverished phonological representations. However, the nature of speech perception deficits in those with dyslexia remains elusive. Specifically, there is no agreement as to whether speech perception deficits arise from speech-specific processing impairments, or from general auditory impairments that might be either specific to temporal processing or more general. Recent studies show that general auditory referents such as Long Term Average Spectrum (LTAS, the distribution of acoustic energy across the duration of a sound sequence) affect speech perception. Here we examine the impact of preceding target sounds' LTAS on phoneme categorization to assess the nature of putative general auditory impairments associated with dyslexia. Dyslexic and typical listeners categorized speech targets varying perceptually from /ga/-/da/preceded by speech and nonspeech tone contexts varying. Results revealed a spectrally contrastive influence of the preceding context LTAS on speech categorization, with a larger magnitude effect for nonspeech compared to speech precursors. Importantly, there was no difference in the presence or magnitude of the effects across dyslexia and control groups. These results demonstrate an aspect of general auditory processing that is spared in dyslexia, available to support phonemic processing when speech is presented in context.
C1 [Gabay, Yafit] Univ Haifa, Dept Special Educ, Haifa, Israel.
   [Gabay, Yafit] Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, Haifa, Israel.
   [Holt, Lori L.] Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
RP Gabay, Y (corresponding author), Univ Haifa, Dept Special Educ, Haifa, Israel.; Gabay, Y (corresponding author), Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, Haifa, Israel.; Holt, LL (corresponding author), Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
EM ygabay@eciu.haifa.ac.il; loriholt@cmu.edu
RI Gabay, Yafit/P-8315-2019
OI Gabay, Yafit/0000-0002-7899-3044
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01DC004674];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC004674, R01DC004674, R01DC004674,
   R01DC004674, R01DC004674, R01DC004674, R01DC004674, R01DC004674,
   R01DC004674, R01DC004674, R01DC004674, R01DC004674, R01DC004674,
   R01DC004674] Funding Source: NIH RePORTER
FX The research was supported by a grant from the National Institutes of
   Health (R01DC004674) to LLH.; The authors thank Christi Gomez for her
   assistance. The research was supported by a grant from the National
   Institutes of Health (R01DC004674) to LLH. Correspondence may be
   addressed to LLH, loriholt@cmu.edu or YG, ygabay@eclu.haifa.acil.
CR Agus TR, 2014, J SPEECH LANG HEAR R, V57, P1069, DOI 10.1044/1092-4388(2013/13-0020)
   Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Aravamudhan R, 2008, J ACOUST SOC AM, V124, P1695, DOI 10.1121/1.2956482
   Association A.P. Association A.P., 2000, DSM 4 TR DIAGNOSTIC, V75, P78
   Banai K, 2018, LANG COGN NEUROSCI, V33, P321, DOI 10.1080/23273798.2017.1408851
   Beattie RL, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027893
   Blomert L, 2004, J SPEECH LANG HEAR R, V47, P1030, DOI 10.1044/1092-4388(2004/077)
   Brunswick N, 1999, BRAIN, V122, P1901, DOI 10.1093/brain/122.10.1901
   Demonet JF, 2004, LANCET, V363, P1451, DOI 10.1016/S0140-6736(04)16106-0
   Di Filippo G, 2008, DEV SCI, V11
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Gabay Y, 2015, NEUROPSYCHOLOGY, V29, P844, DOI 10.1037/neu0000194
   Gabay Y, 2015, J SPEECH LANG HEAR R, V58, P934, DOI 10.1044/2015_JSLHR-L-14-0324
   Gabay Y, 2012, NEUROPSYCHOLOGIA, V50, P2435, DOI 10.1016/j.neuropsychologia.2012.06.014
   Georgiou GK, 2018, ANN DYSLEXIA, P1, DOI [10.1007/s11881-018-0158-x, DOI 10.1007/S11881-018-0158-X]
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Holt LL, 2006, J ACOUST SOC AM, V119, P4016, DOI 10.1121/1.2195119
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Huang J, 2012, FRONTIERS PSYCHOL, V3
   Huang JY, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00010
   Huang JY, 2011, J ACOUST SOC AM, V129, P1145, DOI 10.1121/1.3543994
   Huang JY, 2009, J ACOUST SOC AM, V125, P3983, DOI 10.1121/1.3125342
   Hufnagle DG, 2013, J EXP CHILD PSYCHOL, V116, P728, DOI 10.1016/j.jecp.2013.05.008
   Jaffe-Dax S, 2018, ELIFE, V7, DOI 10.7554/eLife.30018
   Jaffe-Dax S, 2016, J VISION, V16, DOI 10.1167/16.9.10
   Jaffe-Dax S, 2015, J NEUROSCI, V35, P12116, DOI 10.1523/JNEUROSCI.1302-15.2015
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Lotto AJ, 2003, J ACOUST SOC AM, V113, P53, DOI 10.1121/1.1527959
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   McDermott JH, 2013, NAT NEUROSCI, V16, P493, DOI 10.1038/nn.3347
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Nicolson RI, 2007, TRENDS NEUROSCI, V30, P135, DOI 10.1016/j.tins.2007.02.003
   Nicolson RI, 2011, CORTEX, V47, P117, DOI 10.1016/j.cortex.2009.08.016
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Rashotte, 1999, TOWRE 2 TEST WORD RE
   Raven J-C, 1992, STANDARD PROGR MATRI, V1992, DOI [10.2466/pms.1992.74.3c.1193, DOI 10.2466/PMS.1992.74.3C.1193]
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Rosenholtz R, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00013
   Schneider W, 2002, GUIDE E PUS
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Torgesen J.K., 1999, TOWRE TEST WORD READ
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Vitela AD, 2015, J ACOUST SOC AM, V137, pEL65, DOI 10.1121/1.4903917
   Vitela AD, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00399
   Vitela AD, 2010, J ACOUST SOC AM, V128, P2349
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   Wade T, 2005, J ACOUST SOC AM, V118, P1701, DOI 10.1121/1.1984839
   Wechsler D., 1997, WAIS 3 WECHSLER ADUL
   Wijnen F, 2012, J SPEECH LANG HEAR R, V55, P1387, DOI 10.1044/1092-4388(2012/10-0302)
   Wilson AM, 2001, J LEARN DISABIL-US, V34, P394, DOI 10.1177/002221940103400501
   Wolf M., 2005, RAN RAS RAPID AUTOMA
   Woodcock R. W., 1998, WOODCOCK READING MAS
NR 66
TC 2
Z9 2
U1 0
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUN 7
PY 2018
VL 13
IS 6
AR e0198146
DI 10.1371/journal.pone.0198146
PG 16
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GI5BF
UT WOS:000434384900023
PM 29879142
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Szymaszek, A
   Dacewicz, A
   Urban, P
   Szelag, E
AF Szymaszek, Aneta
   Dacewicz, Anna
   Urban, Paulina
   Szelag, Elzbieta
TI Training in Temporal Information Processing Ameliorates Phonetic
   Identification
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE temporal information processing (TIP); specific language impairment
   (SLI); voice-onset-time; phonetic identification; temporal intervention;
   voicing contrast detection
ID ACOUSTICALLY MODIFIED SPEECH; COMPUTER-BASED INTERVENTION; RANDOMIZED
   CONTROLLED-TRIAL; LANGUAGE IMPAIRMENT; ORDER JUDGMENT; AUDITORY
   COMPREHENSION; DEVELOPMENTAL APHASIA; PSYCHOMETRIC FUNCTION; FAST
   FORWORD; PERCEPTION
AB Many studies revealed a link between temporal information processing (TIP) in a millisecond range and speech perception. Previous studies indicated a dysfunction in TIP accompanied by deficient phonemic hearing in children with specific language impairment (SLI). In this study we concentrate in SLI on phonetic identification, using the voice-onset-time (VOT) phenomenon in which TIP is built-in. VOT is crucial for speech perception, as stop consonants (like/t/vs./d/) may be distinguished by an acoustic difference in time between the onsets of the consonant (stop release burst) and the following vibration of vocal folds (voicing). In healthy subjects two categories (voiced and unvoiced) are determined using VOT task. The present study aimed at verifying whether children with SLI indicate a similar pattern of phonetic identification as their healthy peers and whether the intervention based on TIP results in improved performance on the VOT task. Children aged from 5 to 8 years (n = 47) were assigned into two groups: normal children without any language disability (NC, n = 20), and children with SLI (n = 27). In the latter group participants were randomly classified into two treatment subgroups, i.e., experimental temporal training (EG, n = 14) and control non-temporal training (CG, n = 13). The analyzed indicators of phonetic identification were: (1) the boundary location (alpha) determined as the VOT value corresponding to 50% voicing/unvoicing distinctions; (2) ranges of voiced/unvoiced categories; (3) the slope of identification curve (beta) reflecting the identification correctness; (4) percent of voiced distinctions within the applied VOT spectrum. The results indicated similar alpha values and similar ranges of voiced/unvoiced categories between SLI and NC. However, beta in SLI was significantly higher than that in NC. After the intervention, the significant improvement of b was observed only in EG. They achieved the level of performance comparable to that observed in NC. The training-related improvement in CG was non-significant. Furthermore, only in EG the beta values in post-test correlated with measures of TIP as well as with phonemic hearing obtained in our previous studies. These findings provide another evidence that TIP is omnipresent in language communication and reflected not only in phonemic hearing but also in phonetic identification.
C1 [Szymaszek, Aneta; Dacewicz, Anna; Urban, Paulina; Szelag, Elzbieta] Polish Acad Sci, Nencki Inst Expt Biol, Lab Neuropsychol, Warsaw, Poland.
RP Szymaszek, A (corresponding author), Polish Acad Sci, Nencki Inst Expt Biol, Lab Neuropsychol, Warsaw, Poland.
EM a.szymaszek@nencki.gov.pl
RI Szymaszek, Aneta/U-5474-2018; Szelag, Elzbieta/F-8959-2015
OI Szymaszek, Aneta/0000-0001-9786-1277; Szelag,
   Elzbieta/0000-0003-0245-4973; Urban, Paulina/0000-0001-6469-8776
FU National Centre for Research and Development, Poland
   [INNOTECH-K1/IN1/30/159041/NCBR/12]
FX The research was supported by the INNOTECH-K1/IN1/30/159041/NCBR/12
   grant from the National Centre for Research and Development, Poland.
CR ANSI, 2004, SPEC AUD
   Benasich AA, 2002, BEHAV BRAIN RES, V136, P31, DOI 10.1016/S0166-4328(02)00098-0
   Bishop DVM, 1999, J SPEECH LANG HEAR R, V42, P1295, DOI 10.1044/jslhr.4206.1295
   Chobert J, 2012, NEUROPSYCHOLOGIA, V50, P2044, DOI 10.1016/j.neuropsychologia.2012.05.004
   Cohen W, 2005, J SPEECH LANG HEAR R, V48, P715, DOI 10.1044/1092-4388(2005/049)
   Doellinger Michael, 2011, Open Neurol J, V5, P37, DOI 10.2174/1874205X01105010037
   EIMAS PD, 1991, MODULARITY AND THE MOTOR THEORY OF SPEECH PERCEPTION, P111
   Fink M, 2006, BRAIN LANG, V98, P1, DOI 10.1016/j.bandl.2005.12.005
   Fitch R Holly, 2003, Behav Cogn Neurosci Rev, V2, P155, DOI 10.1177/1534582303258736
   Gerrits E, 2009, J COMMUN DISORD, V42, P180, DOI 10.1016/j.jcomdis.2008.10.004
   Gillarn RB, 2008, J SPEECH LANG HEAR R, V51, P97, DOI 10.1044/1092-4388(2008/007)
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Given BK, 2008, BRAIN LANG, V106, P83, DOI 10.1016/j.bandl.2007.12.001
   Hoonhorst I, 2009, J EXP CHILD PSYCHOL, V104, P353, DOI 10.1016/j.jecp.2009.07.005
   King KA, 2008, CLIN NEUROPHYSIOL, V119, P2855, DOI 10.1016/j.clinph.2008.09.015
   LASKY RE, 1975, J EXP CHILD PSYCHOL, V20, P215, DOI 10.1016/0022-0965(75)90099-5
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   McArthur G M, 2001, Dyslexia, V7, P150
   Merzenich MM, 1996, SCIENCE, V271, P77, DOI 10.1126/science.271.5245.77
   MOLFESE DL, 1980, BRAIN LANG, V11, P285, DOI 10.1016/0093-934X(80)90129-7
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Oron A, 2015, INT J LANG COMM DIS, V50, P604, DOI 10.1111/1460-6984.12160
   Pahlke F., 2004, INFORM BIOMETRIE EPI, V35, P1
   Parbery-Clark A, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2011.12.015
   Poppel E, 1997, TRENDS COGN SCI, V1, P56, DOI 10.1016/S1364-6613(97)01008-5
   Poppel E, 2009, PHILOS T R SOC B, V364, P1887, DOI 10.1098/rstb.2009.0015
   Puzynski S, 2000, KLASYFIKACJA ZABURZE
   Rey V, 2002, BRAIN LANG, V80, P576, DOI 10.1006/brln.2001.2618
   Rojczyk A., 2010, TEMPORAL SPECTRAL PA
   Strasburger H, 2001, PERCEPT PSYCHOPHYS, V63, P1348, DOI 10.3758/BF03194547
   STREETER LA, 1976, NATURE, V259, P39, DOI 10.1038/259039a0
   SUSSMAN JE, 1993, J SPEECH HEAR RES, V36, P1286, DOI 10.1044/jshr.3606.1286
   SWISHER L, 1972, NEUROPSYCHOLOGIA, V10, P137, DOI 10.1016/0028-3932(72)90053-X
   Szelag E., 2016, DR NEURONOWSKI POMYS
   Szelag E., 2014, TEST BADANIA ROZUMIE
   Szelag E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01714
   Szelag E, 2014, J NEUROL SCI, V338, P77, DOI 10.1016/j.jns.2013.12.020
   Szustrowa T., 2003, MANUAL RAVENS PROGR
   Szymaszek A, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00098
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   TALLAL P, 1973, NATURE, V241, P468, DOI 10.1038/241468a0
   Tallal P, 1995, IRISH J PSYCHOL, V16, P194, DOI 10.1080/03033910.1995.10558057
   TALLAL P, 1975, J SPEECH HEAR DISORD, V40, P413, DOI 10.1044/jshd.4003.413
   TALLAL P, 1974, NEUROPSYCHOLOGIA, V12, P83, DOI 10.1016/0028-3932(74)90030-X
   Tarkowski Z., 2001, TEST SPRAWNOSCI JEZY
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Treutwein B, 1999, PERCEPT PSYCHOPHYS, V61, P87, DOI 10.3758/BF03211951
   TREUTWEIN B, 1995, VISION RES, V35, P2503, DOI 10.1016/0042-6989(95)00016-S
   Treutwein B, 1997, SPATIAL VISION, V11, P129
   Vandewalle E, 2012, RES DEV DISABIL, V33, P635, DOI 10.1016/j.ridd.2011.11.005
   von Steinbuchel N, 1999, NEUROSCI LETT, V264, P168, DOI 10.1016/S0304-3940(99)00204-9
   Werff KRV, 2011, EAR HEARING, V32, P168, DOI 10.1097/AUD.0b013e3181f534b5
   Wittmann M, 2004, ACTA NEUROBIOL EXP, V64, P341
   Wittmann M, 2004, NEUROREPORT, V15, P2401, DOI 10.1097/00001756-200410250-00020
   Zaehle T, 2004, EUR J NEUROSCI, V20, P2447, DOI 10.1111/j.1460-9568.2004.03687.x
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
   Ziegler JC, 2011, J EXP CHILD PSYCHOL, V110, P362, DOI 10.1016/j.jecp.2011.05.001
NR 57
TC 2
Z9 2
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD JUN 6
PY 2018
VL 12
AR 213
DI 10.3389/fnhum.2018.00213
PG 11
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA GI3XM
UT WOS:000434305400001
PM 29928195
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Giraudet, F
   Charles, P
   Mom, T
   Boespflug-Tanguy, O
   Durr, A
   Deltenre, P
   Avan, P
AF Giraudet, Fabrice
   Charles, Perrine
   Mom, Thierry
   Boespflug-Tanguy, Odile
   Durr, Alexandra
   Deltenre, Paul
   Avan, Paul
TI Rapid exhaustion of auditory neural conduction in a prototypical
   mitochondrial disease, Friedreich ataxia
SO CLINICAL NEUROPHYSIOLOGY
LA English
DT Article
DE Friedreich ataxia; Auditory brainstem; Conduction velocity;
   Neurodegeneration
ID SPEECH-PERCEPTION; INDIVIDUALS; ABNORMALITIES; CONSEQUENCES; ADAPTATION;
   NEUROPATHY
AB Objectives: In patients with Friedreich ataxia (FRDA), mitochondrial failure leads to impaired cellular energetics. Since many FRDA patients have impaired hearing in noise, we investigated the objective consequences on standard auditory brainstem-evoked responses (ABRs).
   Methods: In 37 FRDA patients, among whom 34 with abnormal standard ABRs, hearing sensitivity, speech-in-noise intelligibility and otoacoustic emissions were controlled. ABR recordings were split into four consecutive segments of the total time frame used for data collection, thus allowing the dynamics of ABR averaging to be observed.
   Results: Most ears showed features of an auditory neuropathy spectrum disorder with flattened ABRs and impaired speech-in-noise intelligibility contrasting with near-normal hearing sensitivity and normal preneural responses. Yet split-ABRs revealed short-lived wave patterns in 26 out of 68 ears with flattened standard ABRs (38%). While averaging went on, the pattern of waves shifted so that interwave latencies increased by 35% on average.
   Conclusions: In FRDA, the assumption of stationarity used for extracting standard ABRs is invalid. The preservation of early split-ABRs indicates no short-term dyssynchrony of action potentials. A large decrease in conduction velocity along auditory neurons occurs within seconds, attributed to fast energetic failure.
   Significance: This model of metabolic sensory neuropathy warns against exposure of metabolically-impaired patients to sustained auditory stimulation. (C) 2018 International Federation of Clinical Neurophysiology. Published by Elsevier B.V. All rights reserved.
C1 [Giraudet, Fabrice; Mom, Thierry; Avan, Paul] Univ Clermont Auvergne, UMR INSERM 1107, Lab Neurosensory Biophys, Clermont Ferrand, France.
   [Charles, Perrine; Durr, Alexandra] Grp Hosp Pitie Salpetriere, AP HP, Dept Genet, Paisley, Renfrew, Scotland.
   [Durr, Alexandra] UPMC Univ Paris VI, Sorbonne Univ, CNRS UMR7225, INSERM U1127,ICM,UMR S1127, Paris, France.
   [Boespflug-Tanguy, Odile] Robert Debre Univ Hosp, AP HP, Reference Ctr Rare Dis Leukodystrophies, Child Neurol & Metab Disorders Dept, Paris, France.
   [Boespflug-Tanguy, Odile] Paris Diderot Univ, Robert Debre Univ Hosp, Sorbonne Paris Cite, Inserm,UMR 1141,DHU PROTECT, Paris, France.
   [Deltenre, Paul] Univ Libre Bruxelles, CHU Brugmann, Brussels, Belgium.
   [Avan, Paul] Ctr Jean Perrin, Clermont Ferrand, France.
RP Avan, P (corresponding author), Sch Med, UMR INSERM 1107, Lab Neurosensory Biophys, 28 Pl Henri Dunant, F-63000 Clermont Ferrand, France.
EM paul.avan@udamail.fr
RI GIRAUDET, Fabrice/Y-2287-2019
OI GIRAUDET, Fabrice/0000-0001-7816-7503; MOM, Thierry/0000-0002-2229-2337
FU Association Francaise pour l'Ataxie de Friedreich (AFAF, France)
FX One of the authors (FG) received a grant from Association Francaise pour
   l'Ataxie de Friedreich (AFAF, France).
CR BAYLOR DA, 1969, J PHYSIOL-LONDON, V203, P555, DOI 10.1113/jphysiol.1969.sp008879
   Berlin CI, 2003, PEDIATR CLIN N AM, V50, P331, DOI 10.1016/S0031-3955(03)00031-2
   Cacace AT, 2011, AUDIOL NEURO-OTOL, V16, P398, DOI 10.1159/000323276
   Cone B, 2015, AM J AUDIOL, V24, P153, DOI 10.1044/2015_AJA-14-0021
   Delmaghani S, 2015, CELL, V163, P894, DOI 10.1016/j.cell.2015.10.023
   Durr A, 1996, NEW ENGL J MED, V335, P1169, DOI 10.1056/NEJM199610173351601
   Frewin Becky, 2013, Cochlear Implants Int, V14, P287, DOI 10.1179/1754762813Y.0000000029
   Gittis AH, 2010, J NEUROPHYSIOL, V104, P1625, DOI 10.1152/jn.00378.2010
   Hall J.W., 2007, NEW HDB AUDITORY EVO
   HAMMOND C, 1990, NEUROBIOLOGIE CELLUL
   Harrison RV, 2015, INT J PEDIATR OTORHI, V79, P1980, DOI 10.1016/j.ijporl.2015.10.006
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   JABBARI B, 1983, NEUROLOGY, V33, P1071, DOI 10.1212/WNL.33.8.1071
   JEWETT DL, 1971, BRAIN, V94, P681, DOI 10.1093/brain/94.4.681
   KEMP DT, 1978, J ACOUST SOC AM, V64, P1386, DOI 10.1121/1.382104
   Kraus N, 2000, JARO-J ASSOC RES OTO, V1, P33, DOI 10.1007/s101620010004
   Lodi R, 1999, P NATL ACAD SCI USA, V96, P11492, DOI 10.1073/pnas.96.20.11492
   Martelli A, 2012, DIS MODEL MECH, V5, P165, DOI 10.1242/dmm.008706
   Pandolfo M, 2008, ARCH NEUROL-CHICAGO, V65, P1296, DOI 10.1001/archneur.65.10.1296
   Rance G, 2012, NEUROSCIENCE, V226, P227, DOI 10.1016/j.neuroscience.2012.08.054
   Rance G, 2015, BRAIN, V138, DOI 10.1093/brain/awv270
   Rance G, 2012, J CHILD NEUROL, V27, P1197, DOI 10.1177/0883073812448963
   Rance G, 2010, AUDIOL NEURO-OTOL, V15, P229, DOI 10.1159/000255341
   Rance G, 2008, BRAIN, V131, P2002, DOI 10.1093/brain/awn104
   Rapin I, 2003, INT J PEDIATR OTORHI, V67, P707, DOI 10.1016/S0165-5876(03)00103-4
   Rotig A, 1997, NAT GENET, V17, P215, DOI 10.1038/ng1097-215
   Sangrey T, 2005, NEUROCOMPUTING, V65, P907, DOI 10.1016/j.neucom.2004.10.091
   Sininger YS, 2002, ANN OTO RHINOL LARYN, V111, P29, DOI 10.1177/00034894021110S506
   SPIEKER S, 1995, J NEUROL, V242, P517
   SPOENDLIN H, 1974, BRAIN, V97, P41, DOI 10.1093/brain/97.1.41
   SPOENDLIN H, 1989, HEARING RES, V43, P25, DOI 10.1016/0378-5955(89)90056-7
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   Trouillas P, 1997, J NEUROL SCI, V145, P205, DOI 10.1016/S0022-510X(96)00231-6
   VANASSE M, 1988, CAN J NEUROL SCI, V15, P292, DOI 10.1017/S0317167100027773
   WINTER IM, 1990, HEARING RES, V45, P191, DOI 10.1016/0378-5955(90)90120-E
   Woo J, 2009, IEEE T BIO-MED ENG, V56, P1348, DOI 10.1109/TBME.2008.2005782
   Wu CC, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000001073
   Wynne DP, 2013, BRAIN, V136, P1626, DOI 10.1093/brain/awt056
   Zeng FG, 2006, J SPEECH LANG HEAR R, V49, P367, DOI 10.1044/1092-4388(2006/029)
   Zeng FG, 2005, J NEUROPHYSIOL, V93, P3050, DOI 10.1152/jn.00985.2004
NR 40
TC 1
Z9 1
U1 0
U2 5
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 1388-2457
EI 1872-8952
J9 CLIN NEUROPHYSIOL
JI Clin. Neurophysiol.
PD JUN
PY 2018
VL 129
IS 6
BP 1121
EP 1129
DI 10.1016/j.clinph.2018.03.005
PG 9
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA GG5EE
UT WOS:000432717300003
PM 29625343
DA 2021-02-24
ER

PT J
AU Chow, I
AF Chow, Ivan
TI AN INVESTIGATION ON SYNTACTIC DISAMBIGUATION IN MANDARIN SPEECH
   PERCEPTION AND THE PHONOLOGICAL STATUS OF THE DISYLLABIC FOOT
SO JOURNAL OF CHINESE LINGUISTICS
LA English
DT Article
DE Modern Chinese; Syntactic disambiguation; Disyllabic Foot; Speech
   perception; Parsing
ID PROSODIC STRUCTURE; AMBIGUITY
AB In light of the high frequency of disyllabic words in modern Chinese and the "default" phonological status held by the disyllabic prosodic foot in speech production, we conducted a series of psycholinguistic experiments to determine whether the quantitative property of prosodic feet has a significant influence when parsing syntactically ambiguous utterances in speech perception. More specifically, without contextual or acoustic cues, would native Mandarin speakers be biased towards disyllabic structures when listening to six-syllable utterances that can be parsed into syntactically similar structures composed entirely of disyllabic or trisyllabic feet? Results indicate that, Mandarin speakers tend to parse ambiguous utterances initially into one of the two possible syntactic structures rather than simply recognizing them as ambiguous. Nonetheless, they do not favour disyllabic structures when lexical information regarding word meaning, syntactic function, usage frequency, etc. is available. However, when parsing sequences of six random digits where lexical and syntactic information is irrelevant, our results point to a clear preferential tendency towards disyllabic grouping. In other words, the quantitative property of prosodic feet plays a significant role in Mandarin speech parsing only when lexical and syntactic information is irrelevant or unavailable.
C1 [Chow, Ivan] Univ Toronto Mississauga, Dept Language Studies, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
RP Chow, I (corresponding author), Univ Toronto Mississauga, Dept Language Studies, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
EM ivan.chow@utoronto.ca
CR BEACH CM, 1991, J MEM LANG, V30, P644, DOI 10.1016/0749-596X(91)90030-N
   BERKOVITS R, 1994, LANG SPEECH, V37, P237, DOI 10.1177/002383099403700302
   BERKOVITS R, 1993, J PHONETICS, V21, P479, DOI 10.1016/S0095-4470(19)30231-1
   BOERSMA P., 2007, PRAAT COMPUTER SOFTW
   BRESNAN JW, 1971, LANGUAGE, V47, P257, DOI 10.2307/412081
   Chao Yuen Ren, 1968, GRAMMAR SPOKEN CHINE
   Chen Matthew Y., 2000, TONE SANDHI PATTERNS
   Chow I, 2005, J CHINESE LINGUIST, V33, P181
   CHOW I., 2003, THESIS
   COOPER W. E., 1981, SYNTAX SPEECH
   Crain S., 1985, NATURAL LANGUAGE PAR, P94, DOI [DOI 10.1017/CBO9780511597855.004, 10.1017/CBO9780511597855.004]
   Crain S., 1985, NATURAL LANGUAGE PAR, P320, DOI DOI 10.1017/CBO9780511597855.011
   Duanmu S., 2000, PHONOLOGY STANDARD C
   EDWARDS J, 1991, J ACOUST SOC AM, V89, P369, DOI 10.1121/1.400674
   FENG S., 2001, SHI JIE HAN YU JIAO, V55, P53
   Feng S, 1995, THESIS
   FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1
   GUSSENHOVEN C, 1992, J PHONETICS, V20, P283, DOI 10.1016/S0095-4470(19)30636-9
   Hayes B., 1989, RHYTHM METER PP, P201, DOI [10.1016/B978-0-12-409340-9.50013-9, DOI 10.1016/B978-0-12-409340-9.50013-9]
   Klatt D.H., 1975, J PHONETICS, V3, P129
   LADD DR, 1988, J ACOUST SOC AM, V84, P530, DOI 10.1121/1.396830
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   NAKATANI LH, 1981, PHONETICA, V38, P84, DOI 10.1159/000260016
   NICOL JL, 1993, J PSYCHOLINGUIST RES, V22, P207
   Shih Chilin, 1986, THESIS
   Speer SR, 1996, J PSYCHOLINGUIST RES, V25, P249, DOI 10.1007/BF01708573
   Swerts M, 1997, J ACOUST SOC AM, V101, P514, DOI 10.1121/1.418114
   Wagner Michael, 2005, THESIS
   Wang B, 2011, J PHONETICS, V39, P595, DOI 10.1016/j.wocn.2011.03.006
   White L, 2010, J PHONETICS, V38, P459, DOI 10.1016/j.wocn.2010.05.002
   WU J., 2001, HAN YU JIE LU XUE
   Xu Y, 1997, J PHONETICS, V25, P61, DOI 10.1006/jpho.1996.0034
   Xu Y., 2011, J SPEECH SCI, V1, P85
   Xu Y, 2009, J PHONETICS, V37, P502, DOI 10.1016/j.wocn.2009.08.003
   Zhang Ning, 1997, J EAST ASIAN LINGUIS, V6, P293, DOI 10.1023/A:1008232121848
NR 35
TC 0
Z9 0
U1 1
U2 4
PU JOURNAL CHINESE LINGUISTICS
PI NEW TERRITORIES
PA CHINESE UNIV HONG KONG, SHATIN, NEW TERRITORIES, HONG KONG 00000,
   PEOPLES R CHINA
SN 0091-3723
J9 J CHINESE LINGUIST
JI J. Chin. Linguist.
PD JUN
PY 2018
VL 46
IS 2
BP 269
EP 291
DI 10.1353/jcl.2018.0010
PG 23
WC Asian Studies; Linguistics; Language & Linguistics
SC Asian Studies; Linguistics
GA HC2WR
UT WOS:000451663100003
DA 2021-02-24
ER

PT J
AU He, D
   Lim, BP
   Yang, XS
   Hasegawa-Johnson, M
   Chen, DM
AF He, Di
   Lim, Boon Pang
   Yang, Xuesong
   Hasegawa-Johnson, Mark
   Chen, Deming
TI Acoustic landmarks contain more information about the phone string than
   other frames for automatic speech recognition with deep neural network
   acoustic model
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
AB Most mainstream automatic speech recognition (ASR) systems consider all feature frames equally important. However, acoustic landmark theory is based on a contradictory idea that some frames are more important than others. Acoustic landmark theory exploits quantal nonlinearities in the articulatory-acoustic and acoustic-perceptual relations to define landmark times at which the speech spectrum abruptly changes or reaches an extremum; frames overlapping landmarks have been demonstrated to be sufficient for speech perception. In this work, experiments are conducted on the TIMIT corpus, with both Gaussian mixture model (GMM) and deep neural network (DNN)-based ASR systems, and it is found that frames containing landmarks are more informative for ASR than others. It is discovered that altering the level of emphasis on landmarks by re-weighting acoustic likelihood tends to reduce the phone error rate (PER). Furthermore, by leveraging the landmark as a heuristic, one of the hybrid DNN frame dropping strategies maintained a PER within 0.44% of optimal when scoring less than half (45.8% to be precise) of the frames. This hybrid strategy outperforms other non-heuristic-based methods and demonstrate the potential of landmarks for reducing computation. (C) 2018 Acoustical Society of America.
C1 [He, Di; Chen, Deming] Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA.
   [Lim, Boon Pang] Novumind, Santa Clara, CA 95054 USA.
   [Yang, Xuesong; Hasegawa-Johnson, Mark] Univ Illinois, Beckman Inst, Urbana, IL 61801 USA.
RP He, D (corresponding author), Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA.
EM dihe2@illinois.edu
OI He, Di/0000-0001-5185-7408
CR Borys S., 2008, THESIS
   Chitturi R, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2354
   Choi J.-Y., 1999, THESIS, P1
   Chomsky N., 1968, SOUND PATTERN ENGLIS, P1
   CRESSIE NAC, 1986, BIOMETRICAL J, V28, P131, DOI 10.1002/bimj.4710280202
   Fletcher H, 1933, BELL SYST TECH J, V12, P377, DOI 10.1002/j.1538-7305.1933.tb00403.x
   FURUI S, 1986, J ACOUST SOC AM, V80, P1016, DOI 10.1121/1.393842
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530
   Garofalo, 1993, PRONUNCIATION S IS S
   Garofalo J. S., 1993, LINGUISTIC DATA CONS
   Gillick L., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P532, DOI 10.1109/ICASSP.1989.266481
   Hasegawa-Johnson M., 2000, INTERSPEECH, P133
   Hasegawa-Johnson Mark, 2005, Proc IEEE Int Conf Acoust Speech Signal Process, V1, P1213
   Hermansky H, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P255, DOI 10.1109/ASRU.2003.1318450
   Howitt A. W., 2000, P 6 INT C SPOK LANG, P628
   Iso-Sipila J., 2000, P 10 IEEE EUR SIGN P, P1
   Jakobson R., 1951, PRELIMINARIES SPEECH, P1
   Jansen A, 2008, INT CONF ACOUST SPEE, P4093, DOI 10.1109/ICASSP.2008.4518554
   Juneja A., 2004, THESIS
   Kirchhoff K, 2002, SPEECH COMMUN, V37, P303, DOI 10.1016/S0167-6393(01)00020-6
   Kirchhoff K., 1998, P ICSLP, P0873
   Kirchhoff K., 1999, THESIS
   Kong  Xiang, 2016, ARXIV161103533
   Lee C.-H., 2007, P INTERSPEECH, P1825
   Lee J. I., 2008, ACOUSTICS 08, V08, P2417
   Lee J.-W., 2011, 12 ANN C INT SPEECH, P1261
   Lee JW, 2012, J ACOUST SOC AM, V131, P1536, DOI 10.1121/1.3672706
   Lee K.-F., 1988, AUTOMATIC SPEECH REC, P1
   Lee S., 2008, ACOUSTICS 08, P2430
   Liu SA, 1996, J ACOUST SOC AM, V100, P3417, DOI 10.1121/1.416983
   Livescu K., 2007, P IEEE INT C AC SPEE, P621
   Lulich SM, 2010, J PHONETICS, V38, P20, DOI 10.1016/j.wocn.2008.10.006
   McGraw I, 2016, INT CONF ACOUST SPEE, P5955, DOI 10.1109/ICASSP.2016.7472820
   Metze F, 2005, THESIS
   Niyogi P, 1999, INT CONF ACOUST SPEE, P425, DOI 10.1109/ICASSP.1999.758153
   Nress A. B. e. a., 2011, P INT FLOR IT, P2301
   OHDE RN, 1994, J ACOUST SOC AM, V96, P1303, DOI 10.1121/1.410278
   OHMAN SEG, 1966, J ACOUST SOC AM, V39, P151, DOI 10.1121/1.1909864
   Qian K., 2016, PROC SPEECH PROSODY, P1114
   Quatieri T. F., 2008, DISCRETE TIME SPEECH, P1
   Sak H, 2014, INTERSPEECH, P338
   Stevens K.N., 1985, PHONETIC LINGUISTICS, P243
   Stevens K.N., 1972, HUMAN COMMUNICATION
   Stevens K. N., 2000, ACOUSTIC PHONETICS, P1
   Stevens Kenneth N., 1986, INVARIANCE VARIABILI, P426
   Stevens Kenneth N, 1992, P ICSLP, P499
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   Vanhoucke V, 2013, INT CONF ACOUST SPEE, P7582, DOI 10.1109/ICASSP.2013.6639137
   Vesely K., 2013, P INTERSPEECH, V2013, P2345
   Wang SZ, 2009, J ACOUST SOC AM, V126, P3268, DOI 10.1121/1.3257185
   Xie Z., 2006, P ANN C INT SPEECH C, P1327
   Xiong W., 2016, ARXIV16105256
NR 52
TC 4
Z9 4
U1 1
U2 7
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUN
PY 2018
VL 143
IS 6
BP 3207
EP 3219
DI 10.1121/1.5039837
PG 13
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GL3LI
UT WOS:000437036000016
PM 29960420
DA 2021-02-24
ER

PT J
AU Hay, J
   Drager, K
   Gibson, A
AF Hay, Jennifer
   Drager, Katie
   Gibson, Andy
TI HEARING R-SANDHI: THE ROLE OF PAST EXPERIENCE
SO LANGUAGE
LA English
DT Article
DE salience; listener expectations; r-sandhi; sociophonetics; phoneme
   monitoring; speech perception; rhoticity
ID PERCEPTION
AB We report on two phoneme-monitoring experiments that examine whether listeners from three regions are sensitive to the distribution of r-presence in linking and intrusive environments. The results provide evidence that sound perception is affected by a listener's experience-driven expectations: greater prior experience with a sound in a given context increases the likelihood of perceiving the sound in that context, regardless of whether the sound is present in the stimulus. For listeners with extremely limited prior exposure to a variant, the variant is especially salient and we also observe an experiment-internal effect of experience. We argue that our results support models that incorporate both word-specific and abstract probabilistic representations.*
C1 [Hay, Jennifer; Gibson, Andy] Univ Canterbury, Christchurch, New Zealand.
   [Drager, Katie] Univ Hawaii Manoa, Honolulu, HI 96822 USA.
RP Hay, J (corresponding author), Univ Canterbury, Christchurch, New Zealand.
EM jen.hay@canterbury.ac.nz; kdrager@hawaii.edu;
   andy.gibson@pg.canterbury.ac.nz
FU Royal Society of NZ Marsden Fund grant; Rutherford Discovery Grant;
   University of Canterbury internal grant; University of Canterbury
   Erskine Fellowship
FX These studies were funded by a Royal Society of NZ Marsden Fund grant, a
   Rutherford Discovery Grant, a University of Canterbury internal grant to
   the first author, and a University of Canterbury Erskine Fellowship to
   the second author. We would like to thank Amalia Arvaniti for allowing
   us use of the Phonetics Lab at UCSD. The coding of r for the corpus work
   described in 2.2 was completed by Danae McConnel, Amy Wilson, Karen
   Malcolm, Aaron Nolan, and Abby Walker, with supervision contributed by
   Margaret Maclagan. The Intermediate Archive recordings were collected by
   Rosemary Goodyear, Lesley Evans, and members of the Origins of New
   Zealand English (ONZE) team. The Canterbury Corpus data was collected by
   members of the NZ English class of the Linguistics Department,
   University of Canterbury. Work done by the ONZE project team in
   preparing data, making transcripts, and obtaining background information
   for the corpus is also acknowledged. The recording and analysis of the
   small elicitation task reported in 2.2 was conducted by Andrew Lang. We
   are very grateful to all editors and referees who provided detailed
   feedback on this article, including Adam Albright, Megan Crowhurst, Greg
   Carlson, Jim Scobbie, and Natasha Warner. We would also like to thank
   Jacq Jones for their valuable editorial assistance.
CR Awh E, 2012, TRENDS COGN SCI, V16, P437, DOI 10.1016/j.tics.2012.06.010
   Bartlett Christopher M., 2002, THESIS
   CHANG CHARLES B., 2013, J PHONETICS, DOI 10.1016/j.wocn.2013.09.006
   Cho T, 2011, J PSYCHOLINGUIST RES, V40, P253, DOI 10.1007/s10936-011-9168-0
   Connine CM, 1996, LANG COGNITIVE PROC, V11, P635
   Cutler A., 2010, LAB PHONOLOGY, V10, P91
   Cutler A, 2012, NATIVE LISTENING LAN
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Ernestus M, 2014, LINGUA, V142, P27, DOI 10.1016/j.lingua.2012.12.006
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Foulkes Paul, 1997, HIST EPISTEMOLOGIE L, V19, P73, DOI 10.3406/hel.1997.2573
   GIBSON ANDY, 2016, NZ ENGLISH J
   Goldinger S. D., 2007, 16 INT C PHON SCI, P49
   Goldinger Stephen D., 1997, TALKER VARIABILITY S, P33
   Gomez F. A, 2011, P 17 INT C PHON SCI, P1414
   Gordon E, 2007, CREATING AND DIGITIZING LANGUAGE CORPORA VOLUME 2: DIACHRONIC DATABASES, P82
   Harris John, 1994, ENGLISH SOUND STRUCT
   Hay J, 2005, LANGUAGE, V81, P799, DOI 10.1353/lan.2005.0175
   Hay J., 2010, READER SOCIOPHONETIC, P41
   Hay J, 2016, LANGUAGE, V92, P298, DOI 10.1353/lan.2016.0036
   Hay J, 2012, LINGUISTICS, V50, P745, DOI 10.1515/ling-2012-0023
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Ingram JCL, 1997, J PHONETICS, V25, P343, DOI 10.1006/jpho.1997.0048
   Jaeger TF, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01115
   Jarvis B. G., 2006, DIRECTRT VERSION 200
   JOHNSTON WILLIAM A., 1997, J EXPT PSYCHOL HUMAN, DOI 10.1037/0096-1523.23.3.622
   Kemps R, 2004, BRAIN LANG, V90, P117, DOI 10.1016/S0093-934X(03)00425-5
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   KRALJIC TANYA, 2005, COGNITIVE PSYCHOL, DOI 10.1016/j.cogpsych.2005.05.001
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   MAGNUSON JAMES S., 2003, COGNITIVE SCI, DOI 10.1207/s15516709cog2702_6
   MANN VA, 1981, J ACOUST SOC AM, V69, P548, DOI 10.1121/1.385483
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   MCCARTHY JOHN J., 1993, CANADIAN J LINGUISTI, DOI 10.1017/S0008413100014730
   McMahon April, 2000, LEXICAL PHONOLOGY HI
   Mitterer H, 2009, J EXP PSYCHOL HUMAN, V35, P244, DOI 10.1037/a0012730
   Monahan P. J., 2009, JAP KOR LING, V17, P391
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Orgun CO, 2001, NAT LANG LINGUIST TH, V19, P737, DOI 10.1023/A:1013313827798
   PAVLIK RADOSLAV, 2016, J PHONETICS, DOI 10.1016/j.wocn.2015.10.001
   Peperkamp Sharon, 2003, P 15 INT C PHON SCI, P367
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Soskuthy M, 2013, ENGL LANG LINGUIST, V17, P55, DOI 10.1017/S1360674312000329
   STEMBERGER JP, 1986, MEM COGNITION, V14, P17, DOI 10.3758/BF03209225
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   SUMMERFIELD CHRISTOPHER, 2009, TRENDS COGN SCI, DOI 10.1016/j.tics.2009.06.003
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   TAN YING YING, 2011, P 17 INT C PHON SCI, P1954
   Tuinman A, 2011, J ACOUST SOC AM, V130, P1643, DOI 10.1121/1.3619793
   Tuinman A, 2012, J MEM LANG, V66, P530, DOI 10.1016/j.jml.2012.02.001
   Tulving E, 1996, CEREB CORTEX, V6, P71, DOI 10.1093/cercor/6.1.71
   Uffmann C, 2007, LANG SCI, V29, P451, DOI 10.1016/j.langsci.2006.12.017
   Vitevitch MS, 1997, LANG SPEECH, V40, P47, DOI 10.1177/002383099704000103
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   WARNER NATASHA, 2001, J PHONETICS, DOI 10.1006/jpho.2001.0129
   Weber A, 2001, LANG SPEECH, V44, P95, DOI 10.1177/00238309010440010401
   WEBER ANDREA, 2002, LANG SPEECH, DOI 10.1177/00238309020450010201
   Wells J. C., 1982, ACCENTS ENGLISH
   Wurm LH, 1997, J MEM LANG, V36, P165, DOI 10.1006/jmla.1996.2482
NR 64
TC 4
Z9 4
U1 1
U2 2
PU LINGUISTIC SOC AMER
PI WASHINGTON
PA 1325 18TH ST NW, SUITE 211, WASHINGTON, DC 20036-6501 USA
SN 0097-8507
EI 1535-0665
J9 LANGUAGE
JI Language
PD JUN
PY 2018
VL 94
IS 2
BP 360
EP 404
DI 10.1353/lan.2018.0020
PG 45
WC Linguistics; Language & Linguistics
SC Linguistics
GA GN4SV
UT WOS:000439023700009
DA 2021-02-24
ER

PT J
AU Biau, E
   Fromont, LA
   Soto-Faraco, S
AF Biau, Emmanuel
   Fromont, Lauren A.
   Soto-Faraco, Salvador
TI Beat Gestures and Syntactic Parsing: An ERP Study
SO LANGUAGE LEARNING
LA English
DT Article
DE audiovisual speech; gestures; prosody; syntactic parsing; ERPs; P600
ID EVENT-RELATED POTENTIALS; SPEECH-PERCEPTION; SELECTIVE ATTENTION; HUMAN
   BRAIN; AUDIOVISUAL INTEGRATION; LANGUAGE COMPREHENSION; RELATIVE
   CLAUSES; WORD RECOGNITION; AUDITORY SPEECH; VISUAL PROSODY
AB We tested the prosodic hypothesis that the temporal alignment of a speaker's beat gestures in a sentence influences syntactic parsing by driving the listener's attention. Participants chose between two possible interpretations of relative-clause (RC) ambiguous sentences, while their electroencephalogram (EEG) was recorded. We manipulated the alignment of the beat within sentences where auditory prosody was removed. Behavioral performance showed no effect of beat placement on the sentences' interpretation, while event-related potentials (ERPs) revealed a positive shift of the signal in the windows corresponding to N100 and P200 components. Additionally, post hoc analyses of the ERPs time locked to the RC revealed a modulation of the P600 component as a function of gesture. These results suggest that beats modulate early processing of affiliate words in continuous speech and potentially have a global impact at the level of sentence-parsing components. We speculate that beats must be synergistic with auditory prosody to be fully consequential in behavior.
C1 [Biau, Emmanuel] Univ Maastricht, Maastricht, Netherlands.
   [Fromont, Lauren A.] Univ Montreal, Montreal, PQ, Canada.
   [Fromont, Lauren A.] Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Soto-Faraco, Salvador] Unive Pompeu Fabra, Barcelona, Spain.
   [Soto-Faraco, Salvador] Inst Catalana Recerca & Estudis Avancats, Barcelona, Spain.
RP Biau, E (corresponding author), Univ Maastricht, FPN NP & PP, POB 616, NL-6200 MD Maastricht, Netherlands.
EM emmanuel.biau@maastrichtuniversity.nl
OI biau, emmanuel/0000-0002-7631-9013
FU Ministerio de Economia y CompetitividadSpanish Government
   [PSI2016-75558-P]; AGAUR Generalitat de CatalunyaAgencia de Gestio
   D'Ajuts Universitaris de Recerca Agaur (AGAUR)Generalitat de Catalunya
   [2014SGR856]; European Research CouncilEuropean Research Council
   (ERC)European Commission [StG-2010 263145]; European UnionEuropean
   Commission [707727]
FX This research was supported by the Ministerio de Economia y
   Competitividad (PSI2016-75558-P), AGAUR Generalitat de Catalunya
   (2014SGR856), and the European Research Council (StG-2010 263145). EB
   was supported by a postdoctoral fellowship from the European Union's
   Horizon 2020 research and innovation programme, under the Marie
   Sklodowska-Curie grant agreement No. 707727.
CR Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Astheimer LB, 2009, BIOL PSYCHOL, V80, P23, DOI 10.1016/j.biopsycho.2008.01.015
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Biau E, 2016, NEUROIMAGE, V132, P129, DOI 10.1016/j.neuroimage.2016.02.018
   Biau E, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00527
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018
   Biau E, 2013, BRAIN LANG, V124, P143, DOI 10.1016/j.bandl.2012.10.008
   Boersma P, 2015, PRAAT DOING PHONETIC
   Brunelliere A, 2015, PSYCHOPHYSIOLOGY, V52, P46, DOI 10.1111/psyp.12285
   Brunelliere A, 2013, INT J PSYCHOPHYSIOL, V89, P136, DOI 10.1016/j.ijpsycho.2013.06.016
   Brunelliere A, 2013, BRAIN LANG, V125, P82, DOI 10.1016/j.bandl.2013.01.007
   Carreiras M, 2004, COGNITIVE BRAIN RES, V20, P98, DOI 10.1016/j.cogbrainres.2004.01.009
   Clifton C, 2002, LANG SPEECH, V45, P87, DOI 10.1177/00238309020450020101
   CUTLER A, 1988, J EXP PSYCHOL HUMAN, V14, P113, DOI 10.1037/0096-1523.14.1.113
   desla Cruz-Pavia I., 2010, INTERLINGUISTICA, V20, P1
   Dimitrova D, 2016, J COGNITIVE NEUROSCI, V28, P1255, DOI 10.1162/jocn_a_00963
   Duchon A, 2013, BEHAV RES METHODS, V45, P1246, DOI 10.3758/s13428-013-0326-1
   Esteve-Gibert N, 2014, SPEECH COMMUN, V57, P301, DOI 10.1016/j.specom.2013.06.006
   Fernandez Eva M., 2003, BILINGUAL SENTENCE P
   Frazier L, 2006, TRENDS COGN SCI, V10, P244, DOI 10.1016/j.tics.2006.04.002
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Fromont LA, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00096
   Gordon PC, 2012, LANG LINGUIST COMPAS, V6, P403, DOI 10.1002/lnc3.347
   Gratton G., 1989, J PSYCHOPHYSIOL, V3, P14
   Grillo N, 2014, COGNITION, V133, P156, DOI 10.1016/j.cognition.2014.05.019
   Guellai B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00700
   Haupt FS, 2008, J MEM LANG, V59, P54, DOI 10.1016/j.jml.2008.02.003
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Hirai M, 2003, NEUROSCI LETT, V344, P41, DOI 10.1016/S0304-3940(03)00413-0
   Holle H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00074
   Hubbard AL, 2009, HUM BRAIN MAPP, V30, P1028, DOI 10.1002/hbm.20565
   Jahshan C, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.303
   Kelly SD, 2004, BRAIN LANG, V89, P253, DOI 10.1016/S0093-934X(03)00335-3
   Kong LY, 2010, NEUROSCI LETT, V473, P37, DOI 10.1016/j.neulet.2010.02.014
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Krakowski AI, 2011, NEUROIMAGE, V56, P373, DOI 10.1016/j.neuroimage.2011.01.058
   Lehiste Ilse, 1973, GLOSSA, V7, P107, DOI DOI 10.1121/1.1982702
   Leonard T, 2011, LANG COGNITIVE PROC, V26, P1457, DOI 10.1080/01690965.2010.500218
   Marstaller L, 2014, J NEUROLINGUIST, V30, P69, DOI 10.1016/j.jneuroling.2014.04.003
   McNeill D., 1992, HAND MIND WHAT GESTU
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   NAATANEN R, 1982, PSYCHOL BULL, V92, P605
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Obleser J, 2006, CEREB CORTEX, V16, P1069, DOI 10.1093/cercor/bhj047
   OSTERHOUT L, 1992, J MEM LANG, V31, P785, DOI 10.1016/0749-596X(92)90039-Z
   PICTON TW, 1974, ELECTROEN CLIN NEURO, V36, P191, DOI 10.1016/0013-4694(74)90156-4
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Quene H, 2005, PHONETICA, V62, P1, DOI 10.1159/000087222
   Sanchez-Garcia C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025198
   Skipper JI, 2007, BRAIN LANG, V101, P260, DOI 10.1016/j.bandl.2007.02.008
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Talsma D, 2010, TRENDS COGN SCI, V14, P400, DOI 10.1016/j.tics.2010.06.008
   Treffner P, 2008, ECOL PSYCHOL, V20, P32, DOI 10.1080/10407410701766643
   van de Meerendonk N, 2010, J COGNITIVE NEUROSCI, V22, P67, DOI 10.1162/jocn.2008.21170
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Wang L, 2013, NEUROPSYCHOLOGIA, V51, P2847, DOI 10.1016/j.neuropsychologia.2013.09.027
NR 59
TC 3
Z9 3
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD JUN
PY 2018
VL 68
SU 1
SI SI
BP 102
EP 126
DI 10.1111/lang.12257
PG 25
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GI1RD
UT WOS:000434147300006
DA 2021-02-24
ER

PT J
AU Honeder, C
   Ahmadi, N
   Kramer, AM
   Zhu, C
   Saidov, N
   Arnoldner, C
AF Honeder, Clemens
   Ahmadi, Navid
   Kramer, Anne-Margarethe
   Zhu, Chengjing
   Saidov, Nodir
   Arnoldner, Christoph
TI Cochlear Implantation in the Guinea Pig
SO JOVE-JOURNAL OF VISUALIZED EXPERIMENTS
LA English
DT Article
DE Medicine; Issue 136; Guinea Pig; Cochlear Implantation; Animal Model;
   Hearing Loss; Electrophysiology; Hearing Preservation
ID HEARING-LOSS; FREQUENCY HEARING; RESIDUAL HEARING; MODEL; ARRAY;
   PRESERVATION; STIMULATION; SURGERY
AB Cochlear implants are highly efficient devices that can restore hearing in subjects with profound hearing loss. Due to improved speech perception outcomes, candidacy criteria have been expanded over the last few decades. This includes patients with substantial residual hearing that benefit from electrical and acoustical stimulation of the same ear, which makes hearing preservation during cochlear implantation an important issue. Electrode impedances and the related issue of energy consumption is another major research field, as progress in this area could pave the way for fully implantable auditory prostheses. To address these issues in a systematic way, adequate animal models are essential. Therefore, the goal of this protocol is to provide an animal model of cochlear implantation, which can be used to address various research questions. Due to its large tympanic bulla, which allows easy surgical access to the inner ear, as well as its hearing range which is relatively similar to the hearing range of humans, the guinea pig is a commonly used species in auditory research. Cochlear implantation in the guinea pig is performed via a retroauricular approach. Through the bullostomy a cochleostomy is drilled and the cochlear implant electrode is inserted into the scala tympani. This electrode can then be used for electrical stimulation, determination of electrode impedances and the measurement of compound action potentials of the auditory nerve. In addition to these applications, cochlear implant electrodes can also be used as drug delivery devices, if a topical delivery of pharmaceutical agents to the cells or fluids of the inner ear is intended.
C1 [Honeder, Clemens; Ahmadi, Navid; Zhu, Chengjing; Saidov, Nodir; Arnoldner, Christoph] Med Univ Vienna, Dept Otorhinolaryngol Head & Neck Surg, Vienna, Austria.
   [Kramer, Anne-Margarethe] Med Univ Vienna, Dept Biomed Res, Vienna, Austria.
RP Honeder, C (corresponding author), Med Univ Vienna, Dept Otorhinolaryngol Head & Neck Surg, Vienna, Austria.
EM clemens.honeder@meduniwien.ac.at
OI Ahmadi, Navid/0000-0003-3246-5905; Arnoldner,
   Christoph/0000-0003-0066-810X
FU Austrian Science Fund (FWF grant)Austrian Science Fund (FWF) [P
   24260-B19]; MED-EL Austria
FX The authors want to thank Sandra Peiritsch for the care of the animals
   and Noelani Peet for medical writing. The financial support by the
   Austrian Science Fund (FWF grant P 24260-B19) and MED-EL Austria is
   gratefully acknowledged.
CR Arnoldner C, 2010, ADV OTO-RHINO-LARYNG, V67, P116, DOI 10.1159/000262603
   Chang MY, 2017, OTOL NEUROTOL, V38, P962, DOI 10.1097/MAO.0000000000001453
   Ciorba A, 2012, CLIN INTERV AGING, V7, P159, DOI 10.2147/CIA.S26059
   DeMason C, 2012, EAR HEARING, V33, P534, DOI 10.1097/AUD.0b013e3182498c28
   Eshraghi AA, 2005, OTOL NEUROTOL, V26, P442, DOI 10.1097/01.mao.0000169791.53201.e1
   Eshraghi AA, 2003, LARYNGOSCOPE, V113, P415, DOI 10.1097/00005537-200303000-00005
   Eshraghi AA, 2017, ACTA OTO-LARYNGOL, V137, P384, DOI 10.1080/00016489.2016.1256499
   Heffner HE, 2007, J AM ASSOC LAB ANIM, V46, P20
   Honeder C., 2016, HEAR RES
   Honeder C, 2015, ACTA OTO-LARYNGOL, V135, P313, DOI 10.3109/00016489.2014.986758
   Jin Z, 2006, HEARING RES, V219, P74, DOI 10.1016/j.heares.2006.06.001
   Kral A, 2010, NEW ENGL J MED, V363, P1438, DOI 10.1056/NEJMra0911225
   Marx M, 2013, OTOL NEUROTOL, V34, pE76, DOI 10.1097/MAO.0b013e31829411b4
   Mistry N, 2014, HEARING RES, V312, P81, DOI 10.1016/j.heares.2014.03.005
   Moteki H, 2017, ACTA OTO-LARYNGOL, V137, P516, DOI 10.1080/00016489.2016.1252061
   Reiss LAJ, 2015, HEARING RES, V327, P163, DOI 10.1016/j.heares.2015.06.007
   Ris L, 1997, J PHYSIOL-LONDON, V500, P509, DOI 10.1113/jphysiol.1997.sp022037
   Stevens G, 2013, EUR J PUBLIC HEALTH, V23, P146, DOI 10.1093/eurpub/ckr176
   Van Beek-King JM, 2014, OTOL NEUROTOL, V35, pE45, DOI 10.1097/MAO.0000000000000186
   Wysocki J, 2005, HEARING RES, V199, P103, DOI 10.1016/j.heares.2004.08.008
NR 20
TC 4
Z9 4
U1 0
U2 1
PU JOURNAL OF VISUALIZED EXPERIMENTS
PI CAMBRIDGE
PA 1 ALEWIFE CENTER, STE 200, CAMBRIDGE, MA 02140 USA
SN 1940-087X
J9 JOVE-J VIS EXP
JI J. Vis. Exp.
PD JUN
PY 2018
IS 136
AR e56829
DI 10.3791/56829
PG 7
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GT7ZQ
UT WOS:000444752100020
PM 29985368
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Scheerer, NE
   Jones, JA
AF Scheerer, Nichole E.
   Jones, Jeffery A.
TI Detecting our own vocal errors: An event-related study of the thresholds
   for perceiving and compensating for vocal pitch errors
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Dual-stream theory; Auditory feedback; Speech production; Speech
   Perception; Frequency-altered feedback; Pitch-shift reflex; Response
   thresholds
ID AUDITORY-FEEDBACK; SPEECH PRODUCTION; VOICE; FREQUENCY; RESPONSES;
   CORTEX; PERCEPTION; MAGNITUDE; VOCALIZATION; ORGANIZATION
AB Previous studies suggest that a perception-action dissociation exists for the cortical processing of vocal pitch, because speakers compensate for small vocal errors without awareness. In this event-related potential (ERP) study, participants vocalized while hearing their productions either altered or unaltered in pitch, and reported whether their auditory feedback was altered. Pitch alterations as small as 10 cents resulted in compensatory vocal responses, while participants reported hearing perturbations that were 15 cents and larger. Similarly, P1 ERP responses were elicited by perturbations 15 cents and larger, while N1 responses followed a linear trend with increasing perturbation magnitudes, and P2 responses were elicited by perturbations 30 cents and larger. Although their thresholds differed, both motor and perceptual responses were elicited by small frequency altered feedback (FAF) perturbations. Previous reports of a perception-action dissociation may reflect differences in the magnitude of vocal error required to elicit a motor response, and for an individual to report a pitch change, rather than to detect a pitch change (as reflected by ERP responses).
C1 [Jones, Jeffery A.] Wilfrid Laurier Univ, Psychol Dept, Waterloo, ON N2L 4A6, Canada.
   Wilfrid Laurier Univ, Laurier Ctr Cognit Neurosci, Waterloo, ON, Canada.
RP Jones, JA (corresponding author), Wilfrid Laurier Univ, Psychol Dept, Waterloo, ON N2L 4A6, Canada.
EM jjones@wlu.ca
RI Scheerer, Nichole E./Y-5522-2019
FU Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) [283202]
FX This research was funded by a Natural Sciences and Engineering Research
   Council of Canada (NSERC) Discovery grant, funding reference number
   283202, awarded to Jeffery A. Jones. The authors declare they have no
   competing interests.
CR Beal DS, 2011, NEUROIMAGE, V54, P2994, DOI 10.1016/j.neuroimage.2010.11.026
   Behroozmand R, 2014, BRAIN COGNITION, V84, P97, DOI 10.1016/j.bandc.2013.11.007
   Behroozmand R, 2011, J COGNITIVE NEUROSCI, V23, P1205, DOI 10.1162/jocn.2010.21447
   Behroozmand R, 2009, CLIN NEUROPHYSIOL, V120, P1303, DOI 10.1016/j.clinph.2009.04.022
   Burnett TA, 1997, J VOICE, V11, P202, DOI 10.1016/S0892-1997(97)80079-3
   Burnett TA, 1998, J ACOUST SOC AM, V103, P3153, DOI 10.1121/1.423073
   Camacho A, 2007, J ACOUST SOC AM, V122, P2960, DOI [10.1121/1.2942550, DOI 10.1121/1.2942550]
   Chait M, 2004, NEUROREPORT, V15, P2455, DOI 10.1097/00001756-200411150-00004
   Chen ZC, 2012, BMC NEUROSCI, V13, DOI 10.1186/1471-2202-13-55
   Eliades SJ, 2008, NATURE, V453, P1102, DOI 10.1038/nature06910
   ELMAN JL, 1981, J ACOUST SOC AM, V70, P45, DOI 10.1121/1.386580
   Ferree TC, 2001, CLIN NEUROPHYSIOL, V112, P536, DOI 10.1016/S1388-2457(00)00533-2
   Ford JM, 2001, AM J PSYCHIAT, V158, P1914, DOI 10.1176/appi.ajp.158.11.1914
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Green D. M., 1966, SIGNAL DETECTION THE
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Hafke HZ, 2008, J ACOUST SOC AM, V123, P273, DOI 10.1121/1.2817357
   Hain TC, 2000, EXP BRAIN RES, V130, P133, DOI 10.1007/s002219900237
   Hawco CS, 2009, PSYCHOPHYSIOLOGY, V46, P1216, DOI 10.1111/j.1469-8986.2009.00875.x
   Hawco CS, 2009, BRAIN RES, V1276, P131, DOI 10.1016/j.brainres.2009.04.033
   Heinks-Maldonado TH, 2005, PSYCHOPHYSIOLOGY, V42, P180, DOI 10.1111/j.1469-8986.2005.00272.x
   Heinks-Maldonado TH, 2006, NEUROREPORT, V17, P1375, DOI 10.1097/01.wnr.0000233102.43526.e9
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Hutchins S, 2013, BRAIN LANG, V125, P106, DOI 10.1016/j.bandl.2013.01.011
   Korzyukov O, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041216
   Korzyukov O, 2012, INT J PSYCHOPHYSIOL, V83, P71, DOI 10.1016/j.ijpsycho.2011.10.006
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Liu HJ, 2007, J ACOUST SOC AM, V122, P3671, DOI 10.1121/1.2800254
   Liu HJ, 2011, CLIN NEUROPHYSIOL, V122, P951, DOI 10.1016/j.clinph.2010.08.010
   Loui P, 2008, CURR BIOL, V18, pR331, DOI 10.1016/j.cub.2008.02.045
   MacMillan NA, 1991, DETECTION THEORY USE
   Mishkin M., 1982, ANAL VISUAL BEHAV, P549
   Moore DR, 2002, BRIT MED BULL, V63, P171, DOI 10.1093/bmb/63.1.171
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nakagawa K, 2014, NEUROIMAGE, V86, P131, DOI 10.1016/j.neuroimage.2013.07.082
   Natke U, 2003, J ACOUST SOC AM, V113, P1587, DOI 10.1121/1.1543928
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Scheerer NE, 2013, NEUROSCIENCE, V240, P176, DOI 10.1016/j.neuroscience.2013.02.054
   Scheerer NE, 2014, EUR J NEUROSCI, V40, P3793, DOI 10.1111/ejn.12734
   Scheerer NE, 2013, EUR J NEUROSCI, V38, P3189, DOI 10.1111/ejn.12301
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Tumber AK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109968
   Williamson VJ, 2012, NEUROPSYCHOLOGIA, V50, P172, DOI 10.1016/j.neuropsychologia.2011.11.015
   WOLPAW JR, 1975, ELECTROEN CLIN NEURO, V39, P609, DOI 10.1016/0013-4694(75)90073-5
   WOODS DL, 1993, COGNITIVE BRAIN RES, V1, P227, DOI 10.1016/0926-6410(93)90007-R
   Wrzosek M, 2013, ARCH ACOUST, V38, P375, DOI 10.2478/aoa-2013-0044
NR 52
TC 9
Z9 10
U1 0
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD JUN
PY 2018
VL 114
BP 158
EP 167
DI 10.1016/j.neuropsychologia.2017.12.007
PG 10
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA GS6HE
UT WOS:000443791200016
PM 29221832
DA 2021-02-24
ER

PT J
AU Dittinger, E
   D'Imperio, M
   Besson, M
AF Dittinger, Eva
   D'Imperio, Mariapaola
   Besson, Mireille
TI Enhanced neural and behavioural processing of a nonnative phonemic
   contrast in professional musicians
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE event-related potentials; music training; N200; P300; syllabic
   categorisation
ID CATEGORICAL SPEECH-PERCEPTION; BRAIN-STEM; MUSICAL EXPERTISE;
   AUDITORY-CORTEX; LANGUAGE; CHILDREN; WORD; CATEGORIZATION; POTENTIALS;
   CONTEXT
AB Based on growing evidence suggesting that professional music training facilitates foreign language perception and learning, we examined the impact of musical expertise on the categorisation of syllables including phonemes that did (/p/, /b/) or did not (/p(h)/) belong to the French repertoire by analysing both behaviour (error rates and reaction times) and Event-Related brain Potentials (N200 and P300 components). Professional musicians and nonmusicians categorised syllables either as /ba/ or /pa/ (voicing task), or as /pa/ or /p(h)a/ with /p(h)/ being a nonnative phoneme for French speakers (aspiration task). In line with our hypotheses, results showed that musicians outperformed nonmusicians in the aspiration task but not in the voicing task. Moreover, the difference between the native (/p/) and the nonnative phoneme (/p(h)/), as reflected in N200 and P300 amplitudes, was larger in musicians than in nonmusicians in the aspiration task but not in the voicing task. These results show that behaviour and brain activity associated to nonnative phoneme perception are influenced by musical expertise and that these effects are task-dependent. The implications of these findings for current models of phoneme perception and for understanding the qualitative and quantitative differences found on the N200 and P300 components are discussed.
C1 [Dittinger, Eva; Besson, Mireille] CNRS, Marseille, France.
   [Dittinger, Eva; Besson, Mireille] Aix Marseille Univ, LNC, UMR 7291, Marseille, France.
   [Dittinger, Eva; D'Imperio, Mariapaola] CNRS, Aix En Provence, France.
   [Dittinger, Eva; D'Imperio, Mariapaola] Aix Marseille Univ, LPL, UMR 7309, Aix En Provence, France.
   [Dittinger, Eva] BLRI, Aix En Provence, France.
   [D'Imperio, Mariapaola] IUF, Paris, France.
RP Dittinger, E (corresponding author), Ctr St Charles, LNC, UMR 7291, Pole 3C,Case C,3 Pl Victor Hugo, F-13331 Marseille 3, France.
EM eva.dittinger@blri.fr
FU Institut Convergence ILCB [ANR-16-CONV-0002]; Labex BLRI
   [ANR-11-LABX-0036]
FX Institut Convergence ILCB, Grant/Award Number: ANR-16-CONV-0002; Labex
   BLRI, Grant/Award Number: ANR-11-LABX-0036
CR Asaridou SS, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00321
   Besson M, 2017, ROUTLEDGE COMPANION TO MUSIC COGNITION, P37
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Best C. T., 2007, SPEECH LEARNING ROLE
   Bidebnan GM, 2010, BRAIN RES, V1355, P112, DOI 10.1016/j.brainres.2010.07.100
   Bidelman GM, 2015, J NEUROSCI, V35, P1240, DOI 10.1523/JNEUROSCI.3292-14.2015
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Boersma P., 2011, PRAAT DOING PHONETIC
   Chobert J, 2013, BRAIN SCI, V3, P923, DOI 10.3390/brainsci3020923
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   CONNOLLY JF, 1992, BRAIN LANG, V43, P1, DOI 10.1016/0093-934X(92)90018-A
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Delogu F, 2010, EUR J COGN PSYCHOL, V22, P46, DOI 10.1080/09541440802708136
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Dittinger E, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00233
   Dittinger E, 2016, J COGNITIVE NEUROSCI, V28, P1584, DOI 10.1162/jocn_a_00997
   DONCHIN E, 1988, BEHAV BRAIN SCI, V11, P357, DOI 10.1017/S0140525X00058027
   Elmer S, 2012, CEREB CORTEX, V22, P650, DOI 10.1093/cercor/bhr142
   Friedman D, 2000, MICROSC RES TECHNIQ, V51, P6, DOI 10.1002/1097-0029(20001001)51:1<6::AID-JEMT2>3.0.CO;2-R
   Friedrich M, 2008, NEUROREPORT, V19, P1757, DOI 10.1097/WNR.0b013e328318f014
   Friston K, 2012, NEUROIMAGE, V61, P1300, DOI 10.1016/j.neuroimage.2012.04.018
   George EM, 2011, NEUROPSYCHOLOGIA, V49, P1083, DOI 10.1016/j.neuropsychologia.2011.02.001
   Gottfried T. L, 2007, LANGUAGE EXPERIENCE, P221, DOI DOI 10.1075/LLLT.17
   Intartaglia B, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12575-1
   Jancke L, 2009, RESTOR NEUROL NEUROS, V27, P521, DOI 10.3233/RNN-2009-0519
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Kluender KR, 1994, HDB PSYCHOLINGUISTIC, P173
   Korkman M., 1998, NEPSY DEV NEUROPSYCH
   Krampe RT, 1996, J EXP PSYCHOL GEN, V125, P331, DOI 10.1037/0096-3445.125.4.331
   Kuhnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Kujala T, 2007, BIOL PSYCHOL, V74, P1, DOI 10.1016/j.biopsycho.2006.06.001
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P294, DOI 10.1162/jocn.2010.21413
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Milovanov R, 2010, LEARN INDIVID DIFFER, V20, P56, DOI 10.1016/j.lindif.2009.11.003
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Munte TF, 2002, NAT REV NEUROSCI, V3, P473, DOI 10.1038/nrn843
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Patel Salil H, 2005, Int J Med Sci, V2, P147
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Raven J.C, 1962, COLOURED PROGR MATRI
   RITTER W, 1984, ANN NY ACAD SCI, V425, P24, DOI 10.1111/j.1749-6632.1984.tb23521.x
   Sadakata M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01318
   Sadakata M, 2013, J ACOUST SOC AM, V134, P1324, DOI 10.1121/1.4812767
   Sadakata M, 2011, ACTA PSYCHOL, V138, P1, DOI 10.1016/j.actpsy.2011.03.007
   Schon D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060
   Seppanen M, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00043
   Shahin A, 2003, J NEUROSCI, V23, P5545
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   Slevc LR, 2012, WIRES COGN SCI, V3, P483, DOI 10.1002/wcs.1186
   Strait DL, 2015, DEV COGN NEUROS-NETH, V12, P94, DOI 10.1016/j.dcn.2015.01.001
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Tervaniemi M, 2009, EUR J NEUROSCI, V30, P1636, DOI 10.1111/j.1460-9568.2009.06955.x
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Wang X, 2015, CONSCIOUS COGN, V36, P169, DOI 10.1016/j.concog.2015.06.014
   Wechsler D., 2003, WECHSLER INTELLIGENC
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
NR 65
TC 3
Z9 3
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD JUN
PY 2018
VL 47
IS 12
BP 1504
EP 1516
DI 10.1111/ejn.13939
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA GL4HX
UT WOS:000437112300007
PM 29753304
DA 2021-02-24
ER

PT J
AU Van Eeckhoutte, M
   Spirrov, D
   Francart, T
AF Van Eeckhoutte, Maaike
   Spirrov, Dimitar
   Francart, Tom
TI Comparison between adaptive and adjustment procedures for binaural
   loudness balancing
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID INTERAURAL LEVEL DIFFERENCES; COCHLEAR IMPLANT; ELECTRICAL-STIMULATION;
   IMPAIRED LISTENERS; SPEECH-PERCEPTION; HEARING-AID; FREQUENCY;
   DISCRIMINATION; PSYCHOACOUSTICS; LATERALIZATION
AB Binaural loudness balancing is performed in research and clinical practice when fitting bilateral hearing devices, and is particularly important for bimodal listeners, who have a bilateral combination of a hearing aid and a cochlear implant. In this study, two psychophysical binaural loudness balancing procedures were compared. Two experiments were carried out. In the first experiment, the effect of procedure (adaptive or adjustment) on the balanced loudness levels was investigated using noise band stimuli, of which some had a frequency shift to simulate bimodal hearing. In the second experiment, the adjustment procedure was extended. The effect of the starting level of the adjustment procedure was investigated and the two procedures were again compared for different reference levels and carrier frequencies. Fourteen normal hearing volunteers participated in the first experiment, and 38 in the second experiment. Although the final averaged loudness balanced levels of both procedures were similar, the adjustment procedure yielded smaller standard deviations across four test sessions. The results of experiment 2 demonstrated that in order to avoid bias, the adjustment procedure should be conducted twice, once starting from below and once from above the expected balanced loudness level. (C) 2018 Acoustical Society of America.
C1 [Van Eeckhoutte, Maaike; Spirrov, Dimitar; Francart, Tom] Katholieke Univ Leuven, ExpORL, Dept Neurosci, Leuven, Belgium.
RP Francart, T (corresponding author), Katholieke Univ Leuven, ExpORL, Dept Neurosci, Leuven, Belgium.
EM tom.francart@med.kuleuven.be
OI Spirrov, Dimitar/0000-0003-2072-4682; Van Eeckhoutte,
   Maaike/0000-0002-5612-5326
FU Agency for Innovation by Science and Technology in Flanders
   (IWT)Institute for the Promotion of Innovation by Science and Technology
   in Flanders (IWT) [131106]; Agency for Innovation by Science and
   Technology in Flanders; Cochlear Ltd (IWT Baekeland) [140748]
FX M.V.E. was supported by a Ph.D. grant for Strategic Basic Research by
   the Agency for Innovation by Science and Technology in Flanders (IWT,
   131106). D.S. was supported by the Agency for Innovation by Science and
   Technology in Flanders and Cochlear Ltd (IWT Baekeland, 140748). We also
   thank Dr. V. Best and the two anonymous reviewers for their constructive
   remarks to improve the manuscript. We are grateful to the participants
   who voluntarily participated in the experiments, and to I. Bernaerts, E.
   Meeussen, C. Simons, and J. Vanderydt for their help in collecting some
   of the data. The authors report no conflict of interest. We thank L. Van
   Deun for her comments on an earlier version of the manuscript. M.V.E.
   and D.S. contributed equally to this work and should be considered joint
   first authors.
CR Akeroyd MA, 2006, INT J AUDIOL, V45, pS25, DOI 10.1080/14992020600782626
   Aronoff JM, 2015, HEARING RES, V320, P24, DOI 10.1016/j.heares.2014.12.005
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   Ching T Y C, 2007, Trends Amplif, V11, P161, DOI 10.1177/1084713807304357
   Dorman MF, 2014, EAR HEARING, V35, P633, DOI 10.1097/AUD.0000000000000057
   Fitzgerald MB, 2015, EAR HEARING, V36, pE225, DOI 10.1097/AUD.0000000000000174
   Fletcher H, 1933, J ACOUST SOC AM, V5, P82, DOI 10.1121/1.1915637
   Francart T, 2008, J NEUROSCI METH, V172, P283, DOI 10.1016/j.jneumeth.2008.04.020
   Francart T, 2008, AUDIOL NEURO-OTOL, V13, P309, DOI 10.1159/000124279
   Francart T, 2007, J ACOUST SOC AM, V122, P2826, DOI 10.1121/1.2783130
   Francart T, 2013, EAR HEARING, V34, P685, DOI 10.1097/AUD.0b013e31829d14cb
   Guerit F, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514560590
   Hoth S, 2007, EUR ARCH OTO-RHINO-L, V264, P129, DOI 10.1007/s00405-006-0159-y
   Jansen S, 2013, EAR HEARING, V34, P773, DOI 10.1097/AUD.0b013e318297920b
   JESTEADT W, 1980, PERCEPT PSYCHOPHYS, V28, P85, DOI 10.3758/BF03204321
   JESTEADT W, 1977, J ACOUST SOC AM, V61, P169, DOI 10.1121/1.381278
   Lecluyse W, 2009, J ACOUST SOC AM, V126, P2570, DOI 10.1121/1.3238248
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   MILLS AW, 1960, J ACOUST SOC AM, V32, P132, DOI 10.1121/1.1907864
   Oetting D, 2014, HEARING RES, V316, P16, DOI 10.1016/j.heares.2014.07.003
   Peters JPM, 2016, HEARING RES, V342, P124, DOI 10.1016/j.heares.2016.10.009
   Reiss LAJ, 2016, JARO-J ASSOC RES OTO, V17, P341, DOI 10.1007/s10162-016-0570-z
   Salloum CAM, 2010, EAR HEARING, V31, P441, DOI 10.1097/AUD.0b013e3181d4f228
   Scollie SD, 2010, INT J AUDIOL, V49, pS26, DOI 10.3109/14992020903121159
   STEVENS SS, 1957, J EXP PSYCHOL, V54, P377, DOI 10.1037/h0043680
   Tan CT, 2017, J AM ACAD AUDIOL, V28, P187, DOI 10.3766/jaaa.15063
   Tyler RS, 2002, EAR HEARING, V23, P98, DOI 10.1097/00003446-200204000-00003
   van Wieringen A, 2001, EAR HEARING, V22, P528, DOI 10.1097/00003446-200112000-00008
   WIER CC, 1976, PERCEPT PSYCHOPHYS, V19, P75, DOI 10.3758/BF03199389
   Wilcox R., 2012, INTRO ROBUST ESTIMAT, P608
   YOST WA, 1988, J ACOUST SOC AM, V83, P1846, DOI 10.1121/1.396520
NR 31
TC 4
Z9 4
U1 1
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUN
PY 2018
VL 143
IS 6
BP 3720
EP 3729
DI 10.1121/1.5042522
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GL3LI
UT WOS:000437036000063
PM 29960470
OA Green Published
DA 2021-02-24
ER

PT J
AU Panouilleres, MTN
   Boyles, R
   Chesters, J
   Watkins, KE
   Mottonen, R
AF Panouilleres, Muriel T. N.
   Boyles, Rowan
   Chesters, Jennifer
   Watkins, Kate E.
   Moettoenen, Riikka
TI Facilitation of motor excitability during listening to spoken sentences
   is not modulated by noise or semantic coherence
SO CORTEX
LA English
DT Article
DE Articulatory motor cortex; Semantic context; Speech in noise; Speech
   perception; Transcranial magnetic stimulation
ID TRANSCRANIAL MAGNETIC STIMULATION; SPEECH-PERCEPTION; PREMOTOR CORTEX;
   COMPREHENSION; SOUNDS; REPRESENTATIONS; SYSTEM; TMS; CONNECTIVITY;
   ORGANIZATION
AB Comprehending speech can be particularly challenging in a noisy environment and in the absence of semantic context. It has been proposed that the articulatory motor system would be recruited especially in difficult listening conditions. However, it remains unknown how signal-to-noise ratio (SNR) and semantic context affect the recruitment of the articulatory motor system when listening to continuous speech. The aim of the present study was to address the hypothesis that involvement of the articulatory motor cortex increases when the intelligibility and clarity of the spoken sentences decreases, because of noise and the lack of semantic context. We applied Transcranial Magnetic Stimulation (TMS) to the lip and hand representations in the primary motor cortex and measured motor evoked potentials from the lip and hand muscles, respectively, to evaluate motor excitability when young adults listened to sentences. In Experiment 1, we found that the excitability of the lip motor cortex was facilitated during listening to both semantically anomalous and coherent sentences in noise relative to non-speech baselines, but neither SNR nor semantic context modulated the facilitation. In Experiment 2, we replicated these findings and found no difference in the excitability of the lip motor cortex between sentences in noise and clear sentences without noise. Thus, our results show that the articulatory motor cortex is involved in speech processing even in optimal and ecologically valid listening conditions and that its involvement is not modulated by the intelligibility and clarity of speech. (C) 2018 The Authors. Published by Elsevier Ltd.
C1 [Panouilleres, Muriel T. N.; Boyles, Rowan; Chesters, Jennifer; Watkins, Kate E.; Moettoenen, Riikka] Univ Oxford, Dept Expt Psychol, Oxford, England.
   [Panouilleres, Muriel T. N.; Boyles, Rowan; Chesters, Jennifer; Watkins, Kate E.; Moettoenen, Riikka] Univ Nottingham, Sch Psychol, Univ Pk, Nottingham NG7 2RD, England.
   [Moettoenen, Riikka] Univ Nottingham, Sch Psychol, Nottingham, England.
RP Mottonen, R (corresponding author), Univ Nottingham, Sch Psychol, Univ Pk, Nottingham NG7 2RD, England.
EM muriel.panouilleres@inserm.fr; rowan.boyles@nhs.net;
   jennifer.chesters@psy.ox.ac.uk; kate.watkins@psy.ox.ac.uk;
   Riikka.Mottonen@nottingham.ac.uk
RI Watkins, Kate E/A-6559-2012
OI Watkins, Kate E/0000-0002-2621-482X; Mottonen,
   Riikka/0000-0003-4533-4277; Panouilleres, Muriel/0000-0003-0264-2093
FU Wellcome TrustWellcome TrustEuropean Commission [WT091070AIA]; Medical
   Research Council, UKUK Research & Innovation (UKRI)Medical Research
   Council UK (MRC) [G1000566]; Medical Research CouncilUK Research &
   Innovation (UKRI)Medical Research Council UK (MRC) [G1000566] Funding
   Source: researchfish
FX We thank Dr. Matt Davis and Dr. Ingrid Johnsrude for the stimulus
   material. We are also grateful to the participants for contributing with
   their time and effort to this study. This study was funded by the
   Wellcome Trust (WT091070AIA) and Medical Research Council, UK
   (G1000566).
CR Adank P, 2017, LANG COGN NEUROSCI, V32, P900, DOI 10.1080/23273798.2016.1257816
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Adank P, 2010, NEUROIMAGE, V49, P1124, DOI 10.1016/j.neuroimage.2009.07.032
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Eckert MA, 2016, EAR HEARING, V37, p101S, DOI 10.1097/AUD.0000000000000300
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Londei A, 2010, HUM BRAIN MAPP, V31, P567, DOI 10.1002/hbm.20888
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   MILLER GA, 1963, J VERB LEARN VERB BE, V2, P217, DOI 10.1016/S0022-5371(63)80087-0
   Mottonen R, 2014, JOVE-J VIS EXP, DOI 10.3791/51665
   Mottonen R, 2014, J NEUROSCI, V34, P4064, DOI 10.1523/JNEUROSCI.2214-13.2014
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Mottonen R, 2012, APHASIOLOGY, V26, P1103, DOI 10.1080/02687038.2011.619515
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   Morillon B, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6255
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Murakami T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00446
   Murakami T, 2011, NEUROPSYCHOLOGIA, V49, P2045, DOI 10.1016/j.neuropsychologia.2011.03.034
   Nuttall HE, 2017, NEUROPSYCHOLOGIA, V94, P13, DOI 10.1016/j.neuropsychologia.2016.11.016
   Nuttall HE, 2016, NEUROIMAGE, V128, P218, DOI 10.1016/j.neuroimage.2015.12.038
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Panouilleres M., 2017, BIORXIV, DOI [10.1101/169235,169235, DOI 10.1101/169235,169235]
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schomers MR, 2015, CEREB CORTEX, V25, P3894, DOI 10.1093/cercor/bhu274
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Smalle EHM, 2015, CEREB CORTEX, V25, P3690, DOI 10.1093/cercor/bhu218
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Szenkovits G, 2012, NEUROPSYCHOLOGIA, V50, P1380, DOI 10.1016/j.neuropsychologia.2012.02.023
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2009, TRENDS COGN SCI, V13, P329, DOI 10.1016/j.tics.2009.06.001
NR 43
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER MASSON, CORPORATION OFFICE
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD JUN
PY 2018
VL 103
BP 44
EP 54
DI 10.1016/j.cortex.2018.02.007
PG 11
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA GK5MI
UT WOS:000436218800004
PM 29554541
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Sovilj-Nikic, S
   Sovilj-Nikic, I
   Markovic, M
AF Sovilj-Nikic, Sandra
   Sovilj-Nikic, Ivan
   Markovic, Maja
TI Meta Learning Approach to Phone Duration Modeling
SO TEHNICKI VJESNIK-TECHNICAL GAZETTE
LA English
DT Article
DE machine learning; meta learning algorithm; phone duration model;
   synthesized speech
ID NETWORKS
AB One of the essential prerequisites for achieving the naturalness of synthesized speech is the possibility of the automatic prediction of phone duration, due to the high importance of segmental duration in speech perception. In this paper we present a new phone duration prediction model for the Serbian language using meta learning approach. Based on the data obtained from the analysis of a large speech database, we used a feature set of 21 parameters describing phones and their contexts. These include attributes related to the segmental identity, manner of articulation (for consonants), attributes related to phonological context, such as segment types and voicing values of neighboring phones, presence or absence of lexical stress, morphological attributes, such as part-of-speech, and prosodic attributes, such as phonological word length, the position of the segment in the syllable, the position of the syllable in a word, the position of a word in a phrase, phrase break level, etc. Phone duration model obtained using meta learning algorithm outperformed the best individual model by approximately 2,0% and 1,7% in terms of the relative reduction of the root-meansquared error and the mean absolute error, respectively.
C1 [Sovilj-Nikic, Sandra] Iritel Ad Beograd, Batajnicki Put 23, Beorgad 11080, Serbia.
   [Sovilj-Nikic, Ivan] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
   [Markovic, Maja] Univ Novi Sad, Fac Philosophy, Dr Zorana Dindica 2, Novi Sad 21000, Serbia.
RP Sovilj-Nikic, S (corresponding author), Iritel Ad Beograd, Batajnicki Put 23, Beorgad 11080, Serbia.
EM sandrasn@eunet.rs; diomed17@gmail.com; majamarkovic@ff.uns.ac.rs
FU Ministry of Education, Science and Technological Development of the
   Republic of Serbia [III 43008, TR 35015, TR 32035]; CEEPUS project -
   Secretary of Science and Technological Development of the Autonomous
   Province of Vojvodina [CIII-RO-0058-07-1415]
FX This research was funded by the Ministry of Education, Science and
   Technological Development of the Republic of Serbia, within the projects
   III 43008, TR 35015 and TR 32035, and it is also the result of the
   cooperation within CEEPUS project CIII-RO-0058-07-1415 supported by
   Secretary of Science and Technological Development of the Autonomous
   Province of Vojvodina.
CR Batusek M. A., 2002, P SPEECH PROSODY, P167
   Breiman L, 1984, CLASSIFICATION REGRE
   Campbell W. N., 1992, THESIS
   Cosic P, 2011, TEH VJESN, V18, P479
   CRYSTAL TH, 1988, J ACOUST SOC AM, V83, P1553, DOI 10.1121/1.395911
   Frank E., 2016, WEKA WORKBENCH ONLIN
   Goubanova O, 2008, SPEECH COMMUN, V50, P301, DOI 10.1016/j.specom.2007.10.002
   Kaariainen M, 2004, J MACH LEARN RES, V5, P1107
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Lazaridis Alexandras, 2010, Journal of Computer Sciences, V6, P341, DOI 10.3844/jcssp.2010.341.349
   Lazaridis A., 2007, P SPECOM MOSC RUSS, P287
   Markovic M., 2009, P 19 ISTAL INT S THE, P305
   Norkevicius G, 2008, INFORMATICA-LITHUAN, V19, P271
   Ozturk O., 2005, THESIS
   Petrovic D., 2010, FONOLOGIJA SRPSKOG J
   Rao KS, 2007, COMPUT SPEECH LANG, V21, P282, DOI 10.1016/j.csl.2006.06.003
   Riley M., 1992, TALKING MACHINES THE, P265
   Secujski M., 2011, P INTERSPEECH 2011 F, P3157
   Secujski M., 2007, P SPECOM MOSC RUSS, P3
   Shabtai Noam, 2010, ADV SPEECH RECOGNITI, P141
   Sovilj-Nikic S, 2014, ELEKTRON ELEKTROTECH, V20, P77, DOI 10.5755/j01.eee.20.3.4090
   Sovilj-Nikic S., 2007, THESIS
   VANSANTEN JPH, 1992, SPEECH COMMUN, V11, P513, DOI 10.1016/0167-6393(92)90027-5
   Witten IH, 2016, DATA MINING PRACTICA
NR 24
TC 0
Z9 0
U1 0
U2 2
PU UNIV OSIJEK, TECH FAC
PI SLAVONSKI BROD
PA TRG IVANE BRLIC-MAZURANIC 2, SLAVONSKI BROD, HR-35000, CROATIA
SN 1330-3651
EI 1848-6339
J9 TEH VJESN
JI Teh. Vjesn.
PD JUN
PY 2018
VL 25
IS 3
BP 855
EP 860
DI 10.17559/TV-20171002122930
PG 6
WC Engineering, Multidisciplinary
SC Engineering
GA GL3MS
UT WOS:000437040900028
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Melguy, YV
AF Melguy, Yevgeniy Vasilyevich
TI Exploring the Bilingual Phonological Space: Early Bilinguals'
   Discrimination of Coronal Stop Contrasts
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech perception; discrimination; bilingual; multilingual; second
   language (L2); cross-linguistic; non-native; phonetic contrasts; Speech
   Learning Model; speech learning model; perceptual assimilation model;
   Perceptual Assimilation Model (PAM); PAM L2
ID VOICE ONSET TIME; NATIVE-LANGUAGE; PERCEPTUAL ASSIMILATION;
   SPEECH-PERCEPTION; JAPANESE ADULTS; ENGLISH; EXPERIENCE; LISTENERS;
   SPEAKERS; SPANISH
AB It is well known that the way monolingual listeners discriminate speech sounds is strongly influenced by their native (L1) sound system. Moreover, such perceptual constraints are not limited to monolinguals: multiple studies have found evidence of language-specificity in bilingual speech perception. However, the question of whether bilinguals have simultaneous access to both of their phonologies during non-native contrast discrimination has not been systematically examined. Namely, very few studies of bilinguals have specifically examined cases where a non-native contrast pair straddles the boundary between two sound systems, with one sound corresponding to a sound in the L1, and the other to a sound in the second language (L2), but with neither the L1 nor the L2 containing both. The current study aimed to do so by comparing the ability of early bilinguals to discriminate non-native phonetic contrasts consisting of sounds that exist in either their L1 or L2, but not in both. A forced-choice perception task compared two listener groupsSpanish-English bilinguals and English monolingualson their perception of Nepali dental-alveolar stop contrasts. Results showed that despite displaying some sensitivity to phonetic differences within each contrast pair, the bilingual group was unable to discriminate such cross-language contrasts significantly better than the monolingual English control group.
C1 [Melguy, Yevgeniy Vasilyevich] Univ Calif Berkeley, Berkeley, CA 94720 USA.
RP Melguy, YV (corresponding author), Univ Calif Berkeley, Dept Linguist, 1203 Dwinelle Hall 2650, Berkeley, CA 94720 USA.
EM ymelguy@berkeley.edu
CR Abramson A. S., 1965, P 5 INT C AC LIEG, V51
   Antoniou M, 2015, BILING-LANG COGN, V18, P683, DOI 10.1017/S1366728914000777
   Antoniou M, 2013, J ACOUST SOC AM, V133, P2397, DOI 10.1121/1.4792358
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Antoniou M, 2010, J PHONETICS, V38, P640, DOI 10.1016/j.wocn.2010.09.005
   Au TKF, 2008, J MEM LANG, V58, P998, DOI 10.1016/j.jml.2007.11.001
   Baker W, 2005, LANG SPEECH, V48, P1, DOI 10.1177/00238309050480010101
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T., 1992, HASKINS LABORATORIES, V109/110, P89
   Best C. T., 2003, P 15 INT C PHON SCI
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bohn O.-S., 2011, INT C PHONETIC SCI, P336
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bundgaard-Nielsen RL, 2012, LAB PHONOL, V3, P133, DOI DOI 10.1515/LP-2012-0009
   BURKICOHEN J, 1989, LANG SPEECH, V32, P355
   Calderon J., 1996, THESIS
   Carlson MT, 2016, BILING-LANG COGN, V19, P939, DOI 10.1017/S1366728915000334
   Chang CB, 2016, BILING-LANG COGN, V19, P791, DOI 10.1017/S1366728914000261
   Colome A, 2001, J MEM LANG, V45, P721
   de Rooij Vincent A., 2000, INT J BILINGUAL, V4, P447, DOI DOI 10.1177/13670069000040040401
   DIPAOLO M, 1988, LINGUISTIC CHANGE CO, P84
   Enomoto K., 1994, EDINBURGH WORKING PA, V5, P15
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1988, J ACOUST SOC AM, V83, P729, DOI 10.1121/1.396115
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   FLEGE JE, 1987, SPEECH COMMUN, V6, P185, DOI 10.1016/0167-6393(87)90025-2
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Gogoi D. V., 2010, THESIS
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Halle PA, 1999, J PHONETICS, V27, P281, DOI 10.1006/jpho.1999.0097
   Herold Ruth, 1990, THESIS
   Hillenbrand J. M., 2003, J INT PHON ASSOC, V33, P121, DOI DOI 10.1017/S0025100303001221
   Hoshino N, 2011, BRAIN RES, V1371, P100, DOI 10.1016/j.brainres.2010.11.053
   Hunnicutt L., 2016, U PENNSYLVANIA WORKI, V22, P24
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Ju M, 2004, PSYCHOL SCI, V15, P314, DOI 10.1111/j.0956-7976.2004.00675.x
   KEATING PA, 1984, LANGUAGE, V60, P286, DOI 10.2307/413642
   Khatiwada R., 2007, INTERSPEECH 2007, P1422
   Khatiwada R, 2009, J INT PHON ASSOC, V39, P373, DOI 10.1017/S0025100309990181
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Labov W., 2005, ATLAS N AM ENGLISH P
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   Lisker L., 1970, P 6 INT C PHON SCI P, P563
   Liu S., 2000, BILING-LANG COGN, V3, P131, DOI DOI 10.1017/S1366728900000225
   Maddieson I., 1984, PATTERNS SOUNDS
   Magloire J, 1999, PHONETICA, V56, P158, DOI 10.1159/000028449
   Marian V., 2003, BILING-LANG COGN, V6, P97, DOI DOI 10.1017/S1366728903001068
   Martinez-Celdran Eugenio, 2003, J INT PHON ASSOC, V33, P255, DOI DOI 10.1017/S0025100303001373
   McKelvie-Sebileau P, 2014, J ACOUST SOC AM, V135, P3025, DOI 10.1121/1.4870701
   Myers-Scotton Carol, 1989, WORLD ENGLISH, V8, P333, DOI DOI 10.1111/J.1467-971X.1989.TB00673.X
   Oh G. E., 2011, EFFECT AGE ACQUISITI
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Piccinini P. E., 2014, P 7 SPEECH PROS C TR
   POLKA L, 1992, PERCEPT PSYCHOPHYS, V52, P37, DOI 10.3758/BF03206758
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   POON PG, 1985, PHONETICA, V42, P39, DOI 10.1159/000261736
   R Core Team, 2016, R LANG ENV STAT COMP
   Santa Ana O., 2004, HDB VARIETIES ENGLIS, V1, P417
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   SMITH BL, 1975, J ACOUST SOC AM, V57, pS71, DOI 10.1121/1.1995394
   Spalek K, 2014, COGNITION, V133, P226, DOI 10.1016/j.cognition.2014.06.016
   Spivey MJ, 1999, PSYCHOL SCI, V10, P281, DOI 10.1111/1467-9280.00151
   Tremblay MC, 2012, J ACOUST SOC AM, V132, P3465, DOI 10.1121/1.4756955
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   van den Doel Rias, 2006, THESIS
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   WILLIAMS L, 1977, PERCEPT PSYCHOPHYS, V21, P289, DOI 10.3758/BF03199477
   Williams L., 1977, J PHONETICS, V5, P169
   Zhao SY, 2010, J ACOUST SOC AM, V128, P2009, DOI 10.1121/1.3478856
NR 80
TC 0
Z9 0
U1 1
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD JUN
PY 2018
VL 61
IS 2
BP 173
EP 198
DI 10.1177/0023830917710828
PG 26
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA GK3QK
UT WOS:000436060000001
PM 28581344
DA 2021-02-24
ER

PT J
AU Schwartz, G
   Dzierla, J
AF Schwartz, Geoffrey
   Dzierla, Jerzy
TI POLISH LISTENERS' PERCEPTION OF VOWEL INHERENT SPECTRAL CHANGE IN L2
   ENGLISH
SO POZNAN STUDIES IN CONTEMPORARY LINGUISTICS
LA English
DT Article
DE Vowel inherent spectral change; L2 speech perception; phonetics and
   phonology
AB This paper describes a perception experiment with Polish listeners involving vowel inherent spectral change (VISC) in L2 English. A forced-choice rhyming task employing the Silent Center (SC) paradigm revealed relatively uniform effects of stimulus type (SC, Initial, Middle, Final) on accuracy across two proficiency groups, despite greater overall accuracy on the part of the more proficient users. Analysis of individual vowel pairs used in the rhyming trials revealed some effects of proficiency on the degree to which formant movement in the stimuli affected identification accuracy. This research contributes to the relatively sparse literature on VISC in L2 acquisition. Phonological considerations underlying the degree of VISC in Polish and English are also discussed.
C1 [Schwartz, Geoffrey; Dzierla, Jerzy] Adam Mickiewicz Univ, Poznan, Poland.
RP Schwartz, G (corresponding author), Adam Mickiewicz Univ, Fac English, Coll Novum, Al Niepodleglosci 4, PL-61874 Poznan, Poland.
EM geoff@wa.amu.edu.pl
OI Schwartz, Geoffrey/0000-0002-0728-7820
FU Polish National Science Centre [UMO-2014/15/B/HS2/00452]
FX This research is supported by a grant from the Polish National Science
   Centre, project nr UMO-2014/15/B/HS2/00452. We are grateful to Bartosz
   Brzoza and Olga Witczak for assistance with E-Prime, and to Anna Balas
   for providing the base recordings for our stimuli.
CR Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Blevins Juliette, 2004, EVOLUTIONARY PHONOLO
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Bybee Joan, 2001, PHONOLOGY LANGUAGE U
   Collins B., 2009, PRACTICAL PHONETICS
   Cruttenden A., 2001, GIMSONS PRONUNCIATIO
   Dukiewicz Leonida, 1995, GRAMATYKA WSPOLCZESN
   Elvin J, 2016, J ACOUST SOC AM, V140, P576, DOI 10.1121/1.4952387
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   Fox RA, 2009, J ACOUST SOC AM, V126, P2603, DOI 10.1121/1.3212921
   Hillenbrand JM, 2001, J ACOUST SOC AM, V109, P748, DOI 10.1121/1.1337959
   IBM Corp, 2013, IBM SPSS STAT WIND V
   Jacewicz Ewa, 2013, VOWEL INHERENT SPECT, P171
   Jekiel M, 2010, THESIS
   Jenkins JJ, 1999, PERCEPT PSYCHOPHYS, V61, P1200, DOI 10.3758/BF03207623
   Jin SH, 2013, J ACOUST SOC AM, V133, pEL363, DOI 10.1121/1.4798620
   Johnson K, 1997, TALKER VARIABILITY S, P3
   Kazmierski K., 2016, RES LANGUAGE, V14, P181, DOI DOI 10.1515/RELA-2016-0011
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   Morrison G, 2013, VOWEL INHERENT SPECT
   Morrison G., 2013, VOWEL INHERENT SPECT, P9, DOI DOI 10.1007/978-3-642-14209-3_2
   Morrison G. S., 2013, VOWEL INHERENT SPECT, P31
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   Ohala John, 1981, PAPERS PARASESSION L, P178
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   Rogers C., 2013, VOWEL INHERENT SPECT, P231
   Rojczyk A, 2011, ACHIEVEMENTS PERSPEC, V2, P239
   Schwartz G, 2016, RES LANGUAGE, V14, P61, DOI DOI 10.1515/rela-2016-0004
   Schwartz G, 2016, LINGUA, V171, P37, DOI 10.1016/j.lingua.2015.11.005
   Schwartz G, 2013, J LINGUIST, V49, P613, DOI 10.1017/S0022226712000436
   Stevens KN, 1963, J ACOUST SOC AM, V85, P2135
   STRANGE W, 1989, J ACOUST SOC AM, V85, P2081, DOI 10.1121/1.397860
   STRANGE W, 1983, J ACOUST SOC AM, V74, P695, DOI 10.1121/1.389855
   Williams D., 2015, P 18 INT C PHON SCI
   Williams D, 2014, J ACOUST SOC AM, V136, P2751, DOI 10.1121/1.4896471
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
NR 40
TC 1
Z9 1
U1 0
U2 2
PU DE GRUYTER MOUTON
PI BERLIN
PA GENTHINER STRASSE 13, 10785 BERLIN, GERMANY
SN 1897-7499
J9 POZ STUD CONTEMP LIN
JI Poznan Stud. Contemp. Linguist.
PD JUN
PY 2018
VL 54
IS 2
BP 307
EP 332
DI 10.1515/psicl-2018-0007
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA GI9IA
UT WOS:000434837200005
DA 2021-02-24
ER

PT J
AU Lobina, DJ
   Demestre, J
   Garcia-Albea, JE
AF Lobina, David J.
   Demestre, Josep
   Garcia-Albea, Jose E.
TI Disentangling perceptual and psycholinguistic factors in syntactic
   processing: Tone monitoring via ERPs
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE Tone monitoring; Processing load; Position effect; ERPs; Wrap-up
ID SPEECH PERCEPTION; MENTAL WORKLOAD; CLICK DETECTION; SEGMENTATION;
   COMPREHENSION; RECOGNITION; PERFORMANCE; ONLINE
AB Franco, Gaillard, Cleeremans, and Destrebecqz (Behavior Research Methods, 47, 1393-1403, 2015), in a study on statistical learning employing the click-detection paradigm, conclude that more needs to be known about how this paradigm interacts with statistical learning and speech perception. Past results with this monitoring technique have pointed to an end-of-clause effect in parsing-a structural effect-but we here show that the issues are a bit more nuanced. Firstly, we report two Experiments (1a and 1b), which show that reaction times (RTs) are affected by two factors: (a) processing load, resulting in a tendency for RTs to decrease across a sentence, and (b) a perceptual effect which adds to this tendency and moreover helps neutralize differences between sentences with slightly different structures. These two factors are then successfully discriminated by registering event-related brain potentials (ERPs) during a monitoring task, with Experiment 2 establishing that the amplitudes of the N1 and P3 components-the first associated with temporal uncertainty, the second with processing load in dual tasks-correlate with RTs. Finally, Experiment 3 behaviorally segregates the two factors by placing the last tone at the end of sentences, activating a wrap-up operation and thereby both disrupting the decreasing tendency and highlighting structural effects. Our overall results suggest that much care needs to be employed in designing click-detection tasks if structural effects are sought, and some of the now-classic data need to be reconsidered.
C1 [Lobina, David J.] Univ Barcelona, Dept Philosophy LOGOS, Barcelona, Spain.
   [Demestre, Josep; Garcia-Albea, Jose E.] Univ Rovira & Virgili, Dept Psychol, Tarragona, Spain.
RP Lobina, DJ (corresponding author), Univ Barcelona, Dept Philosophy LOGOS, Barcelona, Spain.
EM davidjames.lobina@ub.edu; josep.demestre@urv.cat; jegarcia.albea@urv.cat
RI Demestre, Josep/C-7257-2011; Demestre, Josep/M-5263-2019
OI Demestre, Josep/0000-0001-9221-066X; Demestre,
   Josep/0000-0001-9221-066X; Lobina, David James/0000-0003-4440-6312
FU Beatriu de Pinos fellowship - Catalan Research Council (AGAUR)
   [2011-BP-A-00127]; AGAUR research grant [2014-SGR-1444]; Spanish
   Ministry of Economy and Competitiveness [PSI2015-63525-P]
FX The research presented here was funded, at least in part, by a Beatriu
   de Pinos fellowship awarded by the Catalan Research Council (AGAUR) to
   the first author (2011-BP-A-00127), an AGAUR research grant awarded to
   the Psycholinguistics Research Group at the Universitat Rovira i Virgili
   in Tarragona, Spain (2014-SGR-1444), and a grant from the Spanish
   Ministry of Economy and Competitiveness (PSI2015-63525-P).
CR ABRAMS K, 1969, Q J EXP PSYCHOL, V21, P280, DOI 10.1080/14640746908400223
   Almela Ramon, 2005, FRECUENCIAS ESPANOL
   BEVER T, 1973, Journal of Psycholinguistic Research, V2, P287
   BEVER TG, 1975, J PSYCHOLINGUIST RES, V4, P1, DOI 10.1007/BF01066985
   BEVER TG, 1969, PERCEPT PSYCHOPHYS, V5, P225, DOI 10.3758/BF03210545
   CHAPIN PG, 1972, J VERB LEARN VERB BE, V11, P164, DOI 10.1016/S0022-5371(72)80073-2
   Cohen L, 1996, MEM COGNITION, V24, P94, DOI 10.3758/BF03197275
   Cutler A., 1979, SENTENCE PROCESSING, P113
   Flores d'Arcais G.. B, 1978, STUDIES PERCEPTION L, P155
   Fodor J., 1983, MODULARITY MIND
   Fodor J. A., 1974, PSYCHOL LANGUAGE
   FODOR JA, 1965, J VERB LEARN VERB BE, V4, P414, DOI 10.1016/S0022-5371(65)80081-0
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Franco A, 2015, BEHAV RES METHODS, V47, P1393, DOI 10.3758/s13428-014-0548-x
   GARRETT M, 1966, PERCEPT PSYCHOPHYS, V1, P30, DOI 10.3758/BF03207817
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Giraudet L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118556
   Gomez DM, 2011, LANG COGNITIVE PROC, V26, P212, DOI 10.1080/01690965.2010.482451
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   HARLEY T, 2001, PSYCHOL LANGUAGE
   HOLMES VM, 1970, PERCEPT PSYCHOPHYS, V7, P297, DOI 10.3758/BF03210171
   JUST MA, 1982, J EXP PSYCHOL GEN, V111, P228, DOI 10.1037/0096-3445.111.2.228
   Kathner I, 2014, BIOL PSYCHOL, V102, P118, DOI 10.1016/j.biopsycho.2014.07.014
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Levelt W., 1978, STUDIES PERCEPTION L, P1
   Marti M. A., 2000, LEXESP LEXICO INFORM
   Moro A., 2008, BOUNDARIES BABEL
   Mota S., 2014, IEICE TECHNICAL REPO, P1
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Pickering M.J., 2006, HDB PSYCHOLINGUISTIC, V2nd ed., P455
   REBER AS, 1970, PERCEPT PSYCHOPHYS, V8, P81, DOI 10.3758/BF03210179
   SIREVAAG EJ, 1993, ERGONOMICS, V36, P1121, DOI 10.1080/00140139308967983
   van Gompel R. P. G., 2009, OXFORD HDB PSYCHOLIN, P289
   WICKENS C, 1983, SCIENCE, V221, P1080, DOI 10.1126/science.6879207
NR 34
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD JUN
PY 2018
VL 50
IS 3
BP 1125
EP 1140
DI 10.3758/s13428-017-0932-4
PG 16
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA GI6UU
UT WOS:000434639400019
PM 28707215
OA Bronze
DA 2021-02-24
ER

PT J
AU Heikkila, J
   Tiippana, K
   Loberg, O
   Leppanen, PHT
AF Heikkila, Jenni
   Tiippana, Kaisa
   Loberg, Otto
   Leppanen, Paavo H. T.
TI Neural Processing of Congruent and Incongruent Audiovisual Speech in
   School-Age Children and Adults
SO LANGUAGE LEARNING
LA English
DT Article
DE audiovisual; speech; McGurk effect; development; EEG; neural processing
ID MISMATCH NEGATIVITY MMN; HUMAN AUDITORY-CORTEX; VISUAL SPEECH;
   ELECTROPHYSIOLOGICAL EVIDENCE; INTERINDIVIDUAL DIFFERENCES;
   SELECTIVE-ATTENTION; SEEING VOICES; PERCEPTION; INFANTS; MATURATION
AB Seeing articulatory gestures enhances speech perception. Perception of auditory speech can even be changed by incongruent visual gestures, which is known as the McGurk effect (e.g., dubbing a voice saying /mi/ onto a face articulating /ni/, observers often hear /ni/). In children, the McGurk effect is weaker than in adults, but no previous knowledge exists about the neural-level correlates of the McGurk effect in school-age children. Using brain event-related potentials, we investigated change detection responses to congruent and incongruent audiovisual speech in school-age children and adults. We used an oddball paradigm with a congruent audiovisual /mi/ as the standard stimulus and a congruent audiovisual /ni/ or McGurk A/mi/V/ni/ as the deviant stimulus. In adults, a similar change detection response was elicited by both deviant stimuli. In children, change detection responses differed between the congruent and the McGurk stimulus. This reflects a maturational difference in the influence of visual stimuli on auditory processing.
C1 [Heikkila, Jenni; Tiippana, Kaisa] Univ Helsinki, Helsinki, Finland.
   [Loberg, Otto; Leppanen, Paavo H. T.] Univ Jyvaskyla, Jyvaskyla, Finland.
RP Heikkila, J (corresponding author), Univ Helsinki, Fac Med, Dept Psychol & Logoped, POB 9, FIN-00014 Helsinki, Finland.
EM jenni.heikkila@helsinki.fi
RI Heikkila, Jenni/AAF-3574-2020
OI Tiippana, Kaisa/0000-0002-2305-8104
FU Arvo and Lea Ylppo Foundation; Finnish Brain Foundation; Otto Malm
   Foundation; Finnish Concordia Fund; Avohoidon Tutkimussaatio Foundation;
   Emil Aaltonen Foundation; University of Helsinki
FX This research was funded by grants from the Arvo and Lea Ylppo
   Foundation, Finnish Brain Foundation, Otto Malm Foundation, Finnish
   Concordia Fund, Avohoidon Tutkimussaatio Foundation, and Emil Aaltonen
   Foundation awarded to Jenni Heikkila and from the University of Helsinki
   awarded to Kaisa Tiippana.
CR Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Bullmore ET, 1999, IEEE T MED IMAGING, V18, P32, DOI 10.1109/42.750253
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Cheour M, 2000, CLIN NEUROPHYSIOL, V111, P4, DOI 10.1016/S1388-2457(99)00191-1
   Colin C, 2004, CLIN NEUROPHYSIOL, V115, P1989, DOI 10.1016/j.clinph.2004.03.027
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   Dick AS, 2010, BRAIN LANG, V114, P101, DOI 10.1016/j.bandl.2009.08.005
   DODD B, 1979, COGNITIVE PSYCHOL, V11, P478, DOI 10.1016/0010-0285(79)90021-5
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Ernst MD, 2004, STAT SCI, V19, P676, DOI 10.1214/088342304000000396
   Eskelund K, 2015, NEUROPSYCHOLOGIA, V66, P48, DOI 10.1016/j.neuropsychologia.2014.10.021
   Files BT, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00371
   Hessler D, 2013, BRAIN LANG, V124, P213, DOI 10.1016/j.bandl.2012.12.006
   Hockley N., 1994, J ACOUST SOC AM, V96, P3309, DOI DOI 10.1121/1.410782
   Kaganovich N, 2014, BRAIN LANG, V139, P36, DOI 10.1016/j.bandl.2014.09.011
   Knowland VCP, 2014, DEVELOPMENTAL SCI, V17, P110, DOI 10.1111/desc.12098
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kushnerenko E, 2008, P NATL ACAD SCI USA, V105, P11442, DOI 10.1073/pnas.0804275105
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Liu HM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095587
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MASSARO DW, 1984, CHILD DEV, V55, P1777, DOI 10.1111/j.1467-8624.1984.tb00420.x
   Maurer U, 2003, CLIN NEUROPHYSIOL, V114, P808, DOI 10.1016/S1388-2457(03)00032-4
   Maurer U, 2009, BIOL PSYCHIAT, V66, P341, DOI 10.1016/j.biopsych.2009.02.031
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   Mottonen R, 2002, COGNITIVE BRAIN RES, V13, P417, DOI 10.1016/S0926-6410(02)00053-8
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   Partanen E, 2013, CLIN NEUROPHYSIOL, V124, P1132, DOI 10.1016/j.clinph.2012.12.005
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6
   Ponton CW, 2009, BRAIN TOPOGR, V21, P207, DOI 10.1007/s10548-009-0094-5
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Shafer VL, 2010, EAR HEARING, V31, P735, DOI 10.1097/AUD.0b013e3181e5d1a7
   Shafer VL, 2000, EAR HEARING, V21, P242, DOI 10.1097/00003446-200006000-00008
   Shafer VL, 2005, J COGNITIVE NEUROSCI, V17, P1168, DOI 10.1162/0898929054475217
   Stekelenburg JJ, 2012, NEUROPSYCHOLOGIA, V50, P1425, DOI 10.1016/j.neuropsychologia.2012.02.027
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tiippana K, 2011, SEEING PERCEIVING, V24, P67, DOI 10.1163/187847511X557308
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
NR 54
TC 0
Z9 0
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD JUN
PY 2018
VL 68
SU 1
SI SI
BP 58
EP 79
DI 10.1111/lang.12266
PG 22
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GI1RD
UT WOS:000434147300004
DA 2021-02-24
ER

PT J
AU Bernstein, LE
AF Bernstein, Lynne E.
TI Response Errors in Females' and Males' Sentence Lipreading Necessitate
   Structurally Different Models for Predicting Lipreading Accuracy
SO LANGUAGE LEARNING
LA English
DT Article
DE lipreading; gender; individual differences; speech perception; noise;
   mixed models; audiovisual speech processing
ID VISUAL SPEECH-PERCEPTION; NORMAL-HEARING; SEX-DIFFERENCES; SPEECHREADING
   PERFORMANCE; AUDIOVISUAL INTEGRATION; WORD-RECOGNITION; AGE;
   GENERALIZABILITY; DISTINCTIVENESS; LEXICON
AB Lipreaders recognize words with phonetically impoverished stimuli, an ability that varies widely in normal-hearing adults. Lipreading accuracy for sentence stimuli was modeled with data from 339 normal-hearing adults. Models used measures of phonemic perceptual errors, insertion of text that was not in the stimulus, gender, and auditory speech perception in noise thresholds to predict lipreading accuracy of 10,170 responses. Interactions of the lipreading predictors with gender necessitated different models for males' versus females' lipreading. Females' lipreading accuracy was significantly predicted by their auditory speech in noise thresholds and an interaction between the magnitude of their perceptual errors and the number of nonstimulus phonemes in their responses. Males' lipreading accuracy was a function of their auditory speech in noise thresholds in interaction with the magnitude of their perceptual errors. The predictor coefficients of the two models suggest the possibility of different mechanisms influencing lipreading accuracy in males versus females.
C1 [Bernstein, Lynne E.] George Washington Univ, Washington, DC 20052 USA.
RP Bernstein, LE (corresponding author), George Washington Univ, Washington, DC 20052 USA.
FU U.S. National Institutes of HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [DC014523,
   DC012634]
FX The research was supported by the U.S. National Institutes of Health
   (DC014523 and DC012634).
CR Anderson LC, 2013, NEUROIMAGE, V83, P751, DOI 10.1016/j.neuroimage.2013.07.040
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Auer ET, 1997, J ACOUST SOC AM, V102, P3704, DOI 10.1121/1.420402
   Auer ET, 2002, PSYCHON B REV, V9, P341, DOI 10.3758/BF03196291
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beltz AM, 2016, ASSESSMENT, V23, P447, DOI 10.1177/1073191116648209
   Bernstein L. E., 2012, AUDIOVISUAL SPEECH P, P21, DOI DOI 10.1017/CB097805118
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bernstein LE, 2001, J SPEECH LANG HEAR R, V44, P5, DOI 10.1044/1092-4388(2001/001)
   BERNSTEIN LE, 1994, J ACOUST SOC AM, V95, P3617, DOI 10.1121/1.409930
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Cahill L, 2006, NAT REV NEUROSCI, V7, P477, DOI 10.1038/nrn1909
   CLARK HH, 1973, J VERB LEARN VERB BE, V12, P335, DOI 10.1016/S0022-5371(73)80014-3
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297
   DANCER J, 1994, VOLTA REV, V96, P31
   Davis H, 1970, HEARING AND DEAFNESS
   DEMOREST ME, 1992, J SPEECH HEAR RES, V35, P876, DOI 10.1044/jshr.3504.876
   Demorest ME, 1996, J SPEECH HEAR RES, V39, P697, DOI 10.1044/jshr.3904.697
   Demorest ME, 1997, J SPEECH LANG HEAR R, V40, P900, DOI 10.1044/jslhr.4004.900
   Dunn L.M., 1981, PEABODY PICTURE VOCA
   Files BT, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00878
   Filkowski MM, 2017, NEUROIMAGE, V147, P925, DOI 10.1016/j.neuroimage.2016.12.016
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   HAMMILL DD, 1996, COMPREHENSIVE TEST N
   Harmon-Jones E, 2011, PSYCHOL BULL, V137, P508, DOI 10.1037/a0022744
   Haxby JV, 2002, BIOL PSYCHIAT, V51, P59, DOI 10.1016/S0006-3223(01)01330-0
   Hommel B, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00100
   HONNELL S, 1991, VOLTA REV, V93, P207
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Jiang JT, 2002, EURASIP J APPL SIG P, V2002, P1174, DOI 10.1155/S1110865702206046
   JOHNSON FM, 1988, B PSYCHONOMIC SOC, V26, P106
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kruskal J., 1983, TIME WARPS STRING ED, P265
   Kruskal J. B., 1978, MULTIDIMENSIONAL SCA
   Liu SW, 2012, PSYCHOL METHODS, V17, P15, DOI 10.1037/a0026971
   Massaro D. W., 2012, AUDIOVISUAL SPEECH P, P246, DOI DOI 10.1017/CB09780511843
   Massaro D. W., 1998, PERCEIVING TALKING F
   Mattheyses W, 2015, SPEECH COMMUN, V66, P182, DOI 10.1016/j.specom.2014.11.001
   Mattys SL, 2002, PERCEPT PSYCHOPHYS, V64, P667, DOI 10.3758/BF03194734
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MIDDELWEERD MJ, 1987, J ACOUST SOC AM, V82, P2145, DOI 10.1121/1.395659
   Molenaar PCM, 2009, CURR DIR PSYCHOL SCI, V18, P112, DOI 10.1111/j.1467-8721.2009.01619.x
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   OWENS E, 1985, J SPEECH HEAR RES, V28, P381, DOI 10.1044/jshr.2803.381
   Proverbio AM, 2017, J NEUROSCI RES, V95, P222, DOI 10.1002/jnr.23817
   Ramscar M, 2014, TOP COGN SCI, V6, P5, DOI 10.1111/tops.12078
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ruytjens L, 2007, AUDIOL NEURO-OTOL, V12, P371, DOI 10.1159/000106480
   Ruytjens L, 2006, EUR J NEUROSCI, V24, P1835, DOI 10.1111/j.1460-9568.2006.05072.x
   Seitz P. F., 1998, PHLEX PHONOLOGICALLY
   SHOOP C, 1979, Scandinavian Audiology, V8, P3, DOI 10.3109/01050397909076295
   Shoup J.E., 1980, TRENDS SPEECH RECOGN, P125
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Song JJ, 2015, BRAIN STRUCT FUNCT, V220, P1109, DOI 10.1007/s00429-013-0704-6
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2012, BRAIN TOPOGR, V25, P308, DOI 10.1007/s10548-012-0220-7
   Stevenson RA, 2009, NEUROIMAGE, V44, P1210, DOI 10.1016/j.neuroimage.2008.09.034
   Strelnikov K, 2015, EUR J NEUROSCI, V41, P677, DOI 10.1111/ejn.12827
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Thompson AE, 2014, COGNITION EMOTION, V28, P1164, DOI 10.1080/02699931.2013.875889
   Tye-Murray N, 2007, J AM ACAD AUDIOL, V18, P883, DOI 10.3766/jaaa.18.10.7
   VANTASELL DJ, 1981, AM ANN DEAF, V126, P840, DOI 10.1353/aad.2012.1284
   Vatikiotis-Bateson E, 1998, HEARING EYE 2, P123
   WALDEN BE, 1977, J SPEECH HEAR RES, V20, P130, DOI 10.1044/jshr.2001.130
   Watson CS, 1996, J ACOUST SOC AM, V100, P1153, DOI 10.1121/1.416300
   West B. T., 2015, LINEAR MIXED MODELS
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Young F. W., 1987, MULTIDIMENSIONAL SCA
NR 74
TC 0
Z9 0
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD JUN
PY 2018
VL 68
SU 1
SI SI
BP 127
EP 158
DI 10.1111/lang.12281
PG 32
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GI1RD
UT WOS:000434147300007
PM 31485084
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Worster, E
   Pimperton, H
   Ralph-Lewis, A
   Monroy, L
   Hulme, C
   MacSweeney, M
AF Worster, Elizabeth
   Pimperton, Hannah
   Ralph-Lewis, Amelia
   Monroy, Laura
   Hulme, Charles
   MacSweeney, Mairead
TI Eye Movements During Visual Speech Perception in Deaf and Hearing
   Children
SO LANGUAGE LEARNING
LA English
DT Article
DE deaf; hearing; lipreading; speechreading; eye gaze; eye tracking
ID SELECTIVE ATTENTION; GAZE BEHAVIOR; TALKING FACE; INFANTS; MOUTH;
   ACHIEVEMENT; AUTISM; LIPS
AB For children who are born deaf, lipreading (speechreading) is an important source of access to spoken language. We used eye tracking to investigate the strategies used by deaf (n=33) and hearing 5-8-year-olds (n=59) during a sentence speechreading task. The proportion of time spent looking at the mouth during speech correlated positively with speechreading accuracy. In addition, all children showed a tendency to watch the mouth during speech and watch the eyes when the model was not speaking. The extent to which the children used this communicative pattern, which we refer to as social-tuning, positively predicted their speechreading performance, with the deaf children showing a stronger relationship than the hearing children. These data suggest that better speechreading skills are seen in those children, both deaf and hearing, who are able to guide their visual attention to the appropriate part of the image and in those who have a good understanding of conversational turn-taking.
C1 [Worster, Elizabeth; Pimperton, Hannah; Monroy, Laura; MacSweeney, Mairead] UCL, Inst Cognit Neurosci, 17 Queen Sq, London WC1N 3AR, England.
   [Ralph-Lewis, Amelia; MacSweeney, Mairead] UCL, Deafness Cognit & Language Res Ctr, London, England.
   [Hulme, Charles] Univ Oxford, Oxford, England.
RP MacSweeney, M (corresponding author), UCL, Inst Cognit Neurosci, 17 Queen Sq, London WC1N 3AR, England.
EM m.macsweeney@ucl.ac.uk
OI Ralph-Lewis, Amelia/0000-0003-4474-6288; Buchanan-Worster,
   Elizabeth/0000-0003-4630-5945; Macsweeney, Mairead/0000-0002-2315-3507
FU Wellcome Trust Senior Research FellowshipWellcome Trust [100229/Z/12/Z];
   Economic and Social Research Council Ph.D. StudentshipUK Research &
   Innovation (UKRI)Economic & Social Research Council (ESRC); Economic and
   Social Research Council (Deafness Cognition and Language Research Centre
   (DCAL)UK Research & Innovation (UKRI)Economic & Social Research Council
   (ESRC) [RES-620-28-0002]; Economic and Social Research CouncilUK
   Research & Innovation (UKRI)Economic & Social Research Council (ESRC)
   [ES/I03479X/1, 1474670] Funding Source: researchfish; Wellcome
   TrustWellcome Trust [100229/Z/12/Z] Funding Source: researchfish
FX This research was supported by Wellcome Trust Senior Research Fellowship
   awarded to MMacS (100229/Z/12/Z). EW is supported by an Economic and
   Social Research Council Ph.D. Studentship. ARL was supported by the
   Economic and Social Research Council (Deafness Cognition and Language
   Research Centre (DCAL) [RES-620-28-0002]. We would also like to
   acknowledge and thank Tracksys and SensoMotoric Instruments for the use
   of the eye tracker.
CR Arnold P, 1996, SCAND AUDIOL, V25, P13, DOI 10.3109/01050399609047550
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Conrad R., 1979, DEAF SCH CHILD LANGU
   DiFrancesca S., 1972, 9 GALL COLL OFF DE D
   Hanley M, 2014, RES AUTISM SPECT DIS, V8, P908, DOI 10.1016/j.rasd.2014.03.020
   Jerger S, 2009, J EXP CHILD PSYCHOL, V102, P40, DOI 10.1016/j.jecp.2008.08.002
   Kyle FE, 2006, J DEAF STUD DEAF EDU, V11, P273, DOI 10.1093/deafed/enj037
   Kyle FE, 2013, J SPEECH LANG HEAR R, V56, P416, DOI 10.1044/1092-4388(2012/12-0039)
   Kyle FE, 2011, J DEAF STUD DEAF EDU, V16, P289, DOI 10.1093/deafed/enq069
   Kyle FE, 2010, J EXP CHILD PSYCHOL, V107, P229, DOI 10.1016/j.jecp.2010.04.011
   Kyle FE, 2016, RES DEV DISABIL, V48, P13, DOI 10.1016/j.ridd.2015.10.004
   Lansing C. R., 1994, J ACAD REHABILITATIV, V27, P25
   Lansing CR, 1999, J SPEECH LANG HEAR R, V42, P526, DOI 10.1044/jslhr.4203.526
   Lansing IR, 2003, PERCEPT PSYCHOPHYS, V65, P536, DOI 10.3758/BF03194581
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lusk LG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00052
   Massaro D. W., 1998, PERCEIVING TALKING F
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mitchel AD, 2014, LANG COGN NEUROSCI, V29, P771, DOI 10.1080/01690965.2013.791703
   Mohammed T, 2006, CLIN LINGUIST PHONET, V20, P621, DOI 10.1080/02699200500266745
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   Pimperton H, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00106
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Rescorla L., 1984, ACTA PAEDOLOGICA, V1, P97
   Smith NA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00601
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Wauters LN, 2006, READ WRIT, V19, P49, DOI 10.1007/s11145-004-5894-0
   Weatherhead D, 2017, COGNITION, V160, P103, DOI 10.1016/j.cognition.2017.01.002
   Wilson AH, 2016, J SPEECH LANG HEAR R, V59, P601, DOI 10.1044/2016_JSLHR-S-15-0092
   Yi A, 2013, J SPEECH LANG HEAR R, V56, P471, DOI 10.1044/1092-4388(2012/10-0288)
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 36
TC 9
Z9 9
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD JUN
PY 2018
VL 68
SU 1
SI SI
BP 159
EP 179
DI 10.1111/lang.12264
PG 21
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GI1RD
UT WOS:000434147300008
PM 29937576
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Pons, F
   Sanz-Torrent, M
   Ferinu, L
   Birules, J
   Andreu, L
AF Pons, Ferran
   Sanz-Torrent, Monica
   Ferinu, Laura
   Birules, Joan
   Andreu, Llorenc
TI Children With SLI Can Exhibit Reduced Attention to a Talker's Mouth
SO LANGUAGE LEARNING
LA English
DT Article
DE specific language impairment (SLI); children; audiovisual speech;
   eyes-mouth
ID VISUAL SPEECH-PERCEPTION; LANGUAGE-DEVELOPMENT; SELECTIVE ATTENTION;
   TALKING FACE; INFANTS; INTEGRATION; IMPAIRMENT; SYNCHRONY; BEHAVIOR;
   HEARING
AB It has been demonstrated that children with specific language impairment (SLI) show difficulties not only with auditory but also with audiovisual speech perception. The goal of this study was to assess whether children with SLI might show reduced attention to the talker's mouth compared to their typically developing (TD) peers. An additional aim was to determine whether the pattern of attention to a talking face would be related to a specific subtype of SLI. We used an eye-tracker methodology and presented a video of a talker speaking the children's native language. Results revealed that children with SLI paid significantly less attention to the mouth than the TD children. More specifically, it was also observed that children with a phonological-syntactic deficit looked less to the mouth as compared to the children with a lexical-syntactic deficit.
C1 [Pons, Ferran; Sanz-Torrent, Monica; Birules, Joan] Univ Barcelona, Barcelona, Spain.
   [Ferinu, Laura; Andreu, Llorenc] Univ Oberta Catalunya, Barcelona, Spain.
RP Pons, F (corresponding author), Univ Barcelona, Dept Cognit Dev & Educ Psychol, 171 Pg Vall Hebron, Barcelona 08035, Spain.
EM ferran.pons@ub.edu
RI Pons, Ferran/A-1156-2013; Birules, Joan/L-4620-2019; Birules,
   Joan/S-2846-2018; Andreu, Llorenc/K-4286-2015; Birules,
   Joan/AAY-2457-2020
OI Pons, Ferran/0000-0001-5919-8590; Birules, Joan/0000-0001-9708-4922;
   Andreu, Llorenc/0000-0001-8568-2511; Birules, Joan/0000-0001-9708-4922;
   Sanz-Torrent, Monica/0000-0002-2012-1956
FU Ministerio de Economia y CompetitividadSpanish Government
   [PSI2014-55105-P, EDU2016-75368-P]; AGAUR Generalitat de
   CatalunyaAgencia de Gestio D'Ajuts Universitaris de Recerca Agaur
   (AGAUR)Generalitat de Catalunya [2014SGR1413]
FX This research was supported by the Ministerio de Economia y
   Competitividad (PSI2014-55105-P and EDU2016-75368-P) and by AGAUR
   Generalitat de Catalunya (2014SGR1413).
CR AGUADO GERARDO, 2015, REV LOGOPEDIA FONIAT, V35, P147, DOI DOI 10.1016/J.RLFA.2015.06.004
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Boliek C, 2010, CAN J SPEECH-LANG PA, V34, P124
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   ContiRamsden G, 1997, J SPEECH LANG HEAR R, V40, P765, DOI 10.1044/jslhr.4004.765
   de Boisferon AH, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12381
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Dodd B, 2008, CLIN LINGUIST PHONET, V22, P69, DOI 10.1080/02699200701660100
   Dunn L., 2006, PPVT 3 PEABODY TEST
   Heikkila J., LSCD 2014 WORKSH LAT, P70
   Kaganovich N, 2016, J NEURODEV DISORD, V8, DOI 10.1186/s11689-016-9168-3
   Kaganovich N, 2014, J SPEECH LANG HEAR R, V57, P1480, DOI 10.1044/2014_JSLHR-L-13-0192
   Kaufman AS, 2004, KBIT KAUFMAN BRIEF I
   King AJ, 2001, CURR BIOL, V11, pR322, DOI 10.1016/S0960-9822(01)00175-0
   Knowland VCP, 2016, J SPEECH LANG HEAR R, V59, P1, DOI 10.1044/2015_JSLHR-S-14-0269
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Lachs L, 2001, EAR HEARING, V22, P236, DOI 10.1097/00003446-200106000-00007
   Leonard L., 1998, SPECIFIC LANGUAGE IM
   Lewkowicz DJ, 2013, INT J BEHAV DEV, V37, P90, DOI 10.1177/0165025412467582
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lewkowicz DJ, 2010, DEV PSYCHOL, V46, P66, DOI 10.1037/a0015579
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mendoza E., 2005, TEST COMPRENSION EST, P151
   Meronen A, 2013, J SPEECH LANG HEAR R, V56, P211, DOI 10.1044/1092-4388(2012/11-0270)
   Norrix LW, 2007, J SPEECH LANG HEAR R, V50, P1639, DOI 10.1044/1092-4388(2007/111)
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Pons F, 2013, J CHILD LANG, V40, P687, DOI 10.1017/S0305000912000189
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Preminger JE, 2008, AM J AUDIOL, V17, P80, DOI 10.1044/1059-0889(2008/009)
   RAPIN I, 1987, P 1 INT S SPEC SPEEC, P20
   Rapin I., 1983, NEUROPSYCHOLOGY LANG, P155
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   STARK RE, 1981, J SPEECH HEAR DISORD, V46, P114, DOI 10.1044/jshd.4602.114
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Thompson LA, 2004, EXP AGING RES, V30, P241, DOI 10.1080/03610730490447877
   van Daal J, 2004, J SPEECH LANG HEAR R, V47, P1411, DOI 10.1044/1092-4388(2004/105)
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Woodhouse L, 2009, INT J LANG COMM DIS, V44, P253, DOI 10.1080/13682820802090281
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 46
TC 8
Z9 8
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD JUN
PY 2018
VL 68
SU 1
SI SI
BP 180
EP 192
DI 10.1111/lang.12276
PG 13
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GI1RD
UT WOS:000434147300009
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Ganesh, AC
   Berthommier, F
   Schwartz, JL
AF Ganesh, Attigodu Chandrashekara
   Berthommier, Frederic
   Schwartz, Jean-Luc
TI Audiovisual Binding for Speech Perception in Noise and in Aging
SO LANGUAGE LEARNING
LA English
DT Article
DE audiovisual integration; McGurk effect; speech perception; audiovisual
   binding
ID OLDER-ADULTS; SUPERIOR COLLICULUS; VISUAL-ATTENTION; INTEGRATION;
   HEARING; RECOGNITION; MEMORY; INTELLIGIBILITY; INFORMATION; STIMULI
AB Speech perception involves fusion of multiple sensory inputs, but fusion is not automatic, likely depending on several external and internal factors (e.g., attention, noise, age). In this study, we exploited a specific paradigm in which a short audiovisual context made of coherent or incoherent speech material is displayed before an incongruent audiovisual target likely to provide fusion (McGurk & MacDonald, 1976). We confirmed that incoherent context leads to unbinding, that is, a reduction in the amount of fusion. Importantly, adding acoustic noise in the context though not in the target increases fusion. This suggests that listeners systematically evaluate the reliability of their sensory channels and weight them accordingly in the fusion process. We also showed that older participants display more unbinding than younger participants. We discuss the potential consequences concerning people's ability to understand speech in adverse conditions and relate our findings to a Binding-and-Fusion model of audiovisual speech perception.
C1 [Ganesh, Attigodu Chandrashekara; Berthommier, Frederic; Schwartz, Jean-Luc] Univ Grenoble Alpes, Grenoble, France.
RP Schwartz, JL (corresponding author), Grenoble Univ, CNRS, GIPSA Lab, UMR 5216, Grenoble, France.
EM jean-luc.schwartz@gipsa-lab.grenoble-inp.fr
FU European Research Council under the European CommunityEuropean Research
   Council (ERC) [339152]; Academic Research Community "Quality of life and
   ageing" (ARC 2) of the Rhone-Alpes Region
FX This research was funded by the European Research Council under the
   European Community's Seventh Framework Program (FP7/2007-2013 Grant
   Agreement no. 339152, "Speech Unit(e)s," PI J. L. Schwartz). This
   project has been supported by Academic Research Community "Quality of
   life and ageing" (ARC 2) of the Rhone-Alpes Region, which provided a
   doctoral funding for Ganesh Attigodu Chandrashekara.
CR Alain C, 1999, PSYCHOL AGING, V14, P507, DOI 10.1037/0882-7974.14.3.507
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   [Anonymous], 1988, J Acoust Soc Am, V83, P859
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Baltes PB, 1997, PSYCHOL AGING, V12, P12, DOI 10.1037/0882-7974.12.1.12
   Behne D., 2007, P AVSP 2007
   BENOI C, 1994, J SPEECH HEAR RES, V37, P1195, DOI 10.1044/jshr.3705.1195
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Berthommier F, 2004, SPEECH COMMUN, V44, P31, DOI 10.1016/j.specom.2004.10.003
   Buchan JN, 2012, SEEING PERCEIVING, V25, P87, DOI 10.1163/187847611X620937
   Cabeza R, 2002, NEUROIMAGE, V17, P1394, DOI 10.1006/nimg.2002.1280
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Colin C, 2005, EUR J COGN PSYCHOL, V17, P541, DOI 10.1080/09541440440000168
   DANCER J, 1994, VOLTA REV, V96, P31
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Feld JE, 2009, J SPEECH LANG HEAR R, V52, P1555, DOI 10.1044/1092-4388(2009/08-0137)
   Fixmer E., 1998, P AVSP 1998 TERR AUS
   Fullgrabe C, 2016, ADV EXP MED BIOL, V894, P29, DOI 10.1007/978-3-319-25474-6_4
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Hay-McCutcheon MJ, 2005, LARYNGOSCOPE, V115, P1887, DOI 10.1097/01.mlg.0000173197.94769.ba
   Huyse A, 2013, EAR HEARING, V34, P110, DOI 10.1097/AUD.0b013e3182670993
   Kim J., 2011, P AVSP 2011 VOLT IT
   Massaro D. W., 1998, PERCEIVING TALKING F
   MASSARO DW, 1989, COGNITIVE PSYCHOL, V21, P398, DOI 10.1016/0010-0285(89)90014-5
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   MEREDITH MA, 1986, J NEUROPHYSIOL, V56, P640
   Moore BJ, 2004, INTRO PSYCHOL HEARIN
   Mozolic JL, 2012, NEURAL BASEMULTISE
   Nahorna O, 2015, J ACOUST SOC AM, V137, P362, DOI 10.1121/1.4904536
   Nahorna O, 2012, J ACOUST SOC AM, V132, P1061, DOI 10.1121/1.4728187
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   Poliakoff E, 2006, NEUROPSYCHOLOGIA, V44, P507, DOI 10.1016/j.neuropsychologia.2005.07.004
   Ratcliff R, 2001, PSYCHOL AGING, V16, P323, DOI 10.1037//0882-7974.16.2.323
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   Sekiyama K., 1994, Journal of the Acoustical Society of Japan (E), V15, P143
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Setti A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00575
   SHOOP C, 1979, Scandinavian Audiology, V8, P3, DOI 10.3109/01050397909076295
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1984, Q J EXP PSYCHOL-A, V36, P51, DOI 10.1080/14640748408401503
   THOMPSON LA, 1995, PSYCHOL AGING, V10, P215, DOI 10.1037/0882-7974.10.2.215
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   WALDEN BE, 1993, J SPEECH HEAR RES, V36, P431, DOI 10.1044/jshr.3602.431
NR 49
TC 0
Z9 0
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD JUN
PY 2018
VL 68
SU 1
SI SI
BP 193
EP 220
DI 10.1111/lang.12271
PG 28
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GI1RD
UT WOS:000434147300010
DA 2021-02-24
ER

PT J
AU Wang, J
   le Clercq, CMP
   Sung, V
   Carew, P
   Liu, RS
   Mensah, FK
   Burt, RA
   Gold, L
   Wake, M
AF Wang, Jing
   le Clercq, Carliin M. P.
   Sung, Valerie
   Carew, Peter
   Liu, Richard S.
   Mensah, Fiona K.
   Burt, Rachel A.
   Gold, Lisa
   Wake, Melissa
TI Cross-sectional epidemiology of hearing loss in Australian children aged
   11-12 years old and 25-year secular trends
SO ARCHIVES OF DISEASE IN CHILDHOOD
LA English
DT Article
ID NUTRITION EXAMINATION SURVEY; 3RD NATIONAL-HEALTH; THRESHOLD SHIFTS;
   PREVALENCE; NOISE; IMPAIRMENT; ADULTS; EXPOSURE; DISEASE; LIFE
AB Objective In a national study of Australian children aged 11-12years old, we examined the (1) prevalence and characteristics of hearing loss, (2) its demographic risk factors and (3) evidence for secular increases since 1990.
   Methods This is a cross-sectional Checkpoint wave within the Longitudinal Study of Australian Children. 1485 children (49.8% retention, 49.7% boys) underwent air-conduction audiometry Aim 1: hearing loss (>= 16 decibels hearing level (dB HL)) was defined in four ways to enable prior/future comparisons high Fletcher Index (mean of 1, 2 and 4 kHz, primary outcome relevant to speech perception), four frequency (1, 2,4 and 8 kHz), lower frequency (1 and 2 kHz) and higher frequency (4 and 8 kHz), aim 2: logistic regression of hearing loss by age, gender and disadvantage index; and aim 3: P for trend examining Checkpoint and reported prevalence in studies arranged by date since 1990.
   Results For high Fletcher Index, the prevalence of bilateral and unilateral hearing loss >= 16dB HL was 9.3% and 13.3%, respectively Slight losses (16-25 dB HL) were more prevalent than mild or greater (>= 26 dB HL) losses (bilateral 8.5% vs 0.8%, unilateral 12.5% vs 0.9%), and Sower frequency more prevalent than higher frequency losses (bilateral 11.0% vs 6.9%; unilateral 15.4% vs 11.5%) Demographic characteristics did not convincingly predict hearing loss Prevalence of bilateral/unilateral lower and higher frequency losses >= 16dB HL has risen since 1990. (all P for trend <0.001).
   Conclusions and relevance Childhood hearing loss is prevalent and has risen since 1990. Future research should investigate the causes, course and impact of these changes.
C1 [Wang, Jing; le Clercq, Carliin M. P.; Sung, Valerie; Carew, Peter; Liu, Richard S.; Mensah, Fiona K.; Burt, Rachel A.; Gold, Lisa; Wake, Melissa] Royal Childrens Hosp, Murdoch Childrens Res Inst, Melbourne, Vic 3052, Australia.
   [Wang, Jing; Sung, Valerie; Liu, Richard S.; Mensah, Fiona K.] Univ Melbourne, Dept Paediat, Melbourne, Vic, Australia.
   [le Clercq, Carliin M. P.] Erasmus Univ, Dept Otolaryngol, Med Ctr, Rotterdam, Netherlands.
   [Carew, Peter] Univ Melbourne, Dept Audiol & Speech Pathol, Melbourne, Vic, Australia.
   [Burt, Rachel A.] Univ Melbourne, HEARing Cooperat Res Ctr, Melbourne, Vic, Australia.
   [Gold, Lisa] Deakin Univ, Sch Hlth & Social Dev, Geelong, Vic, Australia.
   [Wake, Melissa] Univ Auckland, Liggins Inst, Dept Paediat, Auckland, New Zealand.
RP Wake, M (corresponding author), Royal Childrens Hosp, Murdoch Childrens Res Inst, Melbourne, Vic 3052, Australia.
EM melissa.wake@mcri.edu.au
RI Mensah, Fiona K/G-3382-2018; Wake, Melissa/J-1396-2012; Carew,
   Peter/L-4732-2019; Sung, Valerie/AAB-9858-2019
OI Mensah, Fiona K/0000-0002-6951-9949; Wake, Melissa/0000-0001-7501-9257;
   Carew, Peter/0000-0003-4133-5723; Gold, Lisa/0000-0002-2733-900X; Liu,
   Richard S/0000-0002-0949-9229; Wang, Jing/0000-0001-5701-476X
FU National Health and Medical Research Council (NHMRC) of
   AustraliaNational Health and Medical Research Council of Australia
   [1041352, 1109355]; The Royal Children's Hospital Foundation [2014-241];
   Murdoch Children's Research Institute; University of MelbourneUniversity
   of Melbourne; National Heart Foundation of AustraliaNational Heart
   Foundation of Australia [100660]; Financial Markets Foundation for
   Children [2014-055, 2016-310]; NHMRCNational Health and Medical Research
   Council of Australia [1125687, 1023493, 1114567, 1111160, 1035100,
   1046518]; Cottrell Research Fellowship from the Royal Australasian
   College of Physicians; Ter Meulen Grant from the Royal Netherlands
   Academy of Arts and Sciences; HEARing Cooperative Research Centre under
   the Cooperative Research Centres Program, an Australian Government
   InitiativeAustralian GovernmentDepartment of Industry, Innovation and
   ScienceCooperative Research Centres (CRC) Programme; Cure Kids New
   Zealand
FX This work was supported by the National Health and Medical Research
   Council (NHMRC) of Australia (1041352, 1109355), The Royal Children's
   Hospital Foundation (2014-241), the Murdoch Children's Research
   Institute, The University of Melbourne, the National Heart Foundation of
   Australia (100660) and Financial Markets Foundation for Children
   (2014-055, 2016-310). The funding bodies did not play any role in the
   study. The following authors were supported by the NHMRC: VS (Early
   Career Fellowship 1125687), PC (Centre of Research Excellence in Child
   Language 1023493), RSL (Postgraduate Scholarship 1114567), FKM (Career
   Development Fellowship 1111160), LG (Early Career Fellowship 1035100)
   and MW (Senior Research Fellowship 1046518). VS was additionally
   supported by a Cottrell Research Fellowship from the Royal Australasian
   College of Physicians; CMPC by a Ter Meulen Grant from the Royal
   Netherlands Academy of Arts and Sciences; RAB by the HEARing Cooperative
   Research Centre, established and supported under the Cooperative
   Research Centres Program, an Australian Government Initiative; and MW by
   Cure Kids New Zealand.
CR Agrawal Y, 2008, ARCH INTERN MED, V168, P1522, DOI 10.1001/archinte.168.14.1522
   Boyle CA, 2011, PEDIATRICS, V127, P1034, DOI 10.1542/peds.2010-2989
   Chia EM, 2007, EAR HEARING, V28, P187, DOI 10.1097/AUD.0b013e31803126b6
   Clark J G, 1981, ASHA, V23, P493
   Cone BK, 2010, EAR HEARING, V31, P202, DOI 10.1097/AUD.0b013e3181c62263
   Eriksson JG, 2005, BMJ-BRIT MED J, V330, P1096, DOI 10.1136/bmj.330.7500.1096
   GATES GA, 1993, ARCH OTOLARYNGOL, V119, P156
   Godfrey KM, 2010, TRENDS ENDOCRIN MET, V21, P199, DOI 10.1016/j.tem.2009.12.008
   Haggard MP, 2000, BRIT J AUDIOL, V34, P231
   Helzner EP, 2011, J AM GERIATR SOC, V59, P972, DOI 10.1111/j.1532-5415.2011.03444.x
   Henderson E, 2011, PEDIATRICS, V127, pE39, DOI 10.1542/peds.2010-0926
   Hong OS, 2013, DM-DIS MON, V59, P110, DOI 10.1016/j.disamonth.2013.01.002
   Kim TS, 2014, CLIN ENDOCRINOL, V80, P368, DOI 10.1111/cen.12184
   Kujawa SG, 2006, J NEUROSCI, V26, P2115, DOI 10.1523/JNEUROSCI.4985-05.2006
   Lalwani AK, 2013, LARYNGOSCOPE, V123, P3178, DOI 10.1002/lary.24244
   le Clercq CMP, 2016, OTOL NEUROTOL, V37, P1208, DOI 10.1097/MAO.0000000000001163
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lumley T, 2002, ANNU REV PUBL HEALTH, V23, P151, DOI 10.1146/annurev.publhealth.23.100901.140546
   Marcoux AM, 2012, J ACOUST SOC AM, V131, P2787, DOI 10.1121/1.3689550
   Masuda M, 2012, OTOL NEUROTOL, V33, P1142, DOI 10.1097/MAO.0b013e3182635417
   Mitchell P, 2009, DIABETIC MED, V26, P483, DOI 10.1111/j.1464-5491.2009.02710.x
   Nash SD, 2013, J AM GERIATR SOC, V61, P1269, DOI 10.1111/jgs.12382
   Ng M, 2014, LANCET, V384, P766, DOI 10.1016/S0140-6736(14)60460-8
   Niskar AS, 1998, JAMA-J AM MED ASSOC, V279, P1071, DOI 10.1001/jama.279.14.1071
   Niskar AS, 2001, PEDIATRICS, V108, P40, DOI 10.1542/peds.108.1.40
   Norton A, 2015, 15 LSAC AUSTR I FAM
   Olusanya BO, 2014, B WORLD HEALTH ORGAN, V92, P367, DOI 10.2471/BLT.13.128728
   Pink B, 2006, SOCIOECONOMIC INDEXE
   Rawlinson WD, 2017, LANCET INFECT DIS, V17, pE177, DOI 10.1016/S1473-3099(17)30143-3
   Sanson A, 2004, FAMILY MATTERS, V67, P46
   Shargorodsky J, 2011, ARCH OTOLARYNGOL, V137, P1177, DOI 10.1001/archoto.2011.202
   Shargorodsky J, 2010, JAMA-J AM MED ASSOC, V304, P772, DOI 10.1001/jama.2010.1124
   Shield BM, 2008, J ACOUST SOC AM, V123, P133, DOI 10.1121/1.2812596
   Teunisse RJ, 2012, AM J GERIAT PSYCHIAT, V20, P1075, DOI 10.1097/JGP.0b013e31823e31c4
   Wake M, 2005, ARCH DIS CHILD, V90, P238, DOI 10.1136/adc.2003.039354
   Wake M, 2014, FAMILY MATTERS, P15
   Wang J, PREVALENCE PERMANENT
   Wilson RH, 2014, J AM ACAD AUDIOL, V25, P171, DOI 10.3766/jaaa.25.2.6
   Yamasoba T, 2013, HEARING RES, V303, P30, DOI 10.1016/j.heares.2013.01.021
NR 39
TC 8
Z9 8
U1 0
U2 4
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0003-9888
EI 1468-2044
J9 ARCH DIS CHILD
JI Arch. Dis. Child.
PD JUN
PY 2018
VL 103
IS 6
BP 579
EP 585
DI 10.1136/archdischild-2017-313505
PG 7
WC Pediatrics
SC Pediatrics
GA GH2KA
UT WOS:000433229600012
PM 29386180
DA 2021-02-24
ER

PT J
AU Vickers, D
   Canas, A
   Degun, A
   Brigg, J
   Bingham, M
   Toner, J
   Cooper, H
   Rogers, S
   Cooper, S
   Irving, R
   Spielman, P
   Batty, S
   Jones, S
   Asher, A
   Chung, M
   Donnelly, N
   Skibinska, A
   Gardner, R
   Raine, C
   Andrew, R
   Green, K
   Ghulam, H
   Nunn, T
   Jiang, D
   Furhapter, S
   Urban, M
   Hanvey, K
   Flynn, S
   Lovegrove, D
   Saeed, S
AF Vickers, Deborah
   Canas, Angela
   Degun, Aneeka
   Brigg, John
   Bingham, Mina
   Toner, Joseph
   Cooper, Huw
   Rogers, Sarah
   Cooper, Stacey
   Irving, Richard
   Spielman, Patrick
   Batty, Samantha
   Jones, Stephen
   Asher, Abi
   Chung, Mark
   Donnelly, Neil
   Skibinska, Anna
   Gardner, Robert
   Raine, Chris
   Andrew, Rachel
   Green, Kevin
   Ghulam, Hashmat
   Nunn, Terry
   Jiang, Dan
   Fuerhapter, Severin
   Urban, Michael
   Hanvey, Kate
   Flynn, Sarah
   Lovegrove, David
   Saeed, Shakeel
TI Evaluating the effectiveness and reliability of the Vibrant Soundbridge
   and Bonebridge auditory implants in clinical practice: Study design and
   methods for a multi-centre longitudinal observational study
SO CONTEMPORARY CLINICAL TRIALS COMMUNICATIONS
LA English
DT Article
DE Bone conducting device; Bonebridge; Soundbridge; Middle ear implant;
   Implant registry; Quality of life
ID HEARING; SURGERY
AB Background: The Vibrant Soundbridge middle ear implant and the Bonebridge bone conducting hearing device are hearing implants that use radio frequency transmission to send information from the sound processor to the internal transducer. This reduces the risk of skin problems and infection but requires a more involved surgical procedure than competitor skin penetrating devices. It is not known whether more complex surgery will lead to additional complications. There is little information available on the reliability of these systems and adverse medical or surgical events. The primary research question is to determine the reliability and complication rate for the Vibrant Soundbridge and Bonebridge. The secondary research question explores changes in quality of life following implantation of the devices. The tertiary research question looks at effectiveness via changes in auditory performance.
   Method: The study was designed based on a combination of a literature search, two clinician focus groups and expert review.
   A multi-centre longitudinal observational study was designed. There are three study groups, two will have been implanted prior to the start of the study and one group, the prospective group, will be implanted after initiation of the study. Outcomes are surgical questionnaires, measures of quality of life, user satisfaction and speech perception tests in quiet and in noise.
   Conclusion: This is the first multi- centre study to look at these interventions and includes follow up over time to understand effectiveness, reliability, quality of life and complications.
C1 [Vickers, Deborah; Canas, Angela; Degun, Aneeka; Brigg, John; Saeed, Shakeel] UCL, Fac Brain Sci, London, England.
   [Degun, Aneeka; Chung, Mark; Saeed, Shakeel] Univ Coll London Hosp NHS Fdn Trust, Royal Natl Throat Nose & Ear Hosp, London, England.
   [Bingham, Mina; Toner, Joseph] Belfast HSC Trust, Auditory Implant Ctr, Belfast, Antrim, North Ireland.
   [Cooper, Huw; Rogers, Sarah; Cooper, Stacey; Irving, Richard] Queen Elizabeth Hosp, Midlands Hearing Implant Programme, Birmingham, W Midlands, England.
   [Spielman, Patrick; Batty, Samantha; Jones, Stephen] Ninewells Hosp NHS Tayside, Dept Otolaryngol, Dundee, Scotland.
   [Brigg, John; Asher, Abi; Chung, Mark; Donnelly, Neil] Cambridge Univ Hosp NHS Fdn Trust, Emmeline Ctr Hearing Implants, Cambridge, England.
   [Skibinska, Anna; Gardner, Robert; Raine, Chris] Bradford Teaching Hosp NHS Fdn Trust, Yorkshire Auditory Implant Serv, Bradford, W Yorkshire, England.
   [Andrew, Rachel; Green, Kevin] Cent Manchester Univ Hosp NHS Fdn Trust, Audiol Hearing & Balance Ctr, Manchester, Lancs, England.
   [Ghulam, Hashmat; Nunn, Terry; Jiang, Dan] Guys & St Thomas NHS Fdn Trust, Hearing Implant Ctr, London, England.
   [Brigg, John] MED EL UK Ltd, Sheffield, S Yorkshire, England.
   [Fuerhapter, Severin; Urban, Michael] MED EL Electromed Geraete GmbH, Innsbruck, Austria.
   [Hanvey, Kate] Birmingham Childrens Hosp NHS Fdn Trust, Birmingham, W Midlands, England.
   [Flynn, Sarah] Univ Hosp Southampton NHS Fdn Trust, Southampton, Hants, England.
   [Lovegrove, David] Lothian Univ Hosp NHS Trust, Edinburgh, Midlothian, Scotland.
RP Vickers, D (corresponding author), UCL, Div Psychol & Language Sci, 2 Wakefield St, London WC1N 1PF, England.
EM d.vickers@ucl.ac.uk
RI Vickers, Deborah/AAD-1434-2021
OI Vickers, Deborah/0000-0002-7498-5637; Saeed, Shakeel/0000-0002-2316-5655
CR Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bento RF, 2012, INT ARCH OTORHINOLAR, V16, P400, DOI 10.7162/S1809-97772012000300017
   Boothroyd A., 1968, AUDIOL BR J, V2, P3, DOI DOI 10.3109/00381796809075436
   Fan Y, 2014, JAMA OTOLARYNGOL, V140, P357, DOI 10.1001/jamaoto.2013.6642
   Fontaine N, 2014, EUR ANN OTORHINOLARY, V131, P69, DOI 10.1016/j.anorl.2012.10.006
   Furlong WJ, 2001, ANN MED, V33, P375, DOI 10.3109/07853890109002092
   Gardell ISK, 2015, DAN MED J, V62
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Hildrew Douglas M, 2015, Ochsner J, V15, P277
   Kiringoda R, 2013, OTOL NEUROTOL, V34, P790, DOI 10.1097/MAO.0b013e318291c651
   Mojallal H, 2015, INT J AUDIOL, V54, P391, DOI 10.3109/14992027.2014.986690
   National Institute for Health and Care Excellence, 2009, COCH IMPL CHILDR AD
   National Institute for Health and Care Excellence, 2005, AUD BRAIN STEM IMPL
   Robinson K, 1996, ANN OTO RHINOL LARYN, V105, P415, DOI 10.1177/000348949610500601
   Saeed S., COCHLEAR IMPLANTS IN
   Siau D, 2015, J LARYNGOL OTOL, V129, P321, DOI 10.1017/S0022215115000602
   Tysome JR, 2010, OTOL NEUROTOL, V31, P1369, DOI 10.1097/MAO.0b013e3181db716c
   Yue F., 2015, CHINESE J OTORHINOLA, V50, P203
NR 18
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER INC
PI SAN DIEGO
PA 525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 2451-8654
J9 CONT CLIN TRIAL COMM
JI Contemp. Clin. Trials Commun.
PD JUN
PY 2018
VL 10
BP 137
EP 140
DI 10.1016/j.conctc.2018.03.007
PG 4
WC Medicine, Research & Experimental
SC Research & Experimental Medicine
GA GH3PQ
UT WOS:000433315000020
PM 30023447
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Uhler, KM
   Hunter, SK
   Tierney, E
   Gilley, PM
AF Uhler, Kristin M.
   Hunter, Sharon K.
   Tierney, Elyse
   Gilley, Phillip M.
TI The relationship between mismatch response and the acoustic change
   complex in normal hearing infants
SO CLINICAL NEUROPHYSIOLOGY
LA English
DT Article
DE Acoustic change complex; Mismatched response; Infant; Hearing loss;
   Speech discrimination; Sleep
ID COCHLEAR-IMPLANT USERS; FALSE DISCOVERY RATE; AUDITORY-CORTEX;
   2-MONTH-OLD INFANTS; SPEECH-PERCEPTION; BRAIN RESPONSES; NEGATIVITY MMN;
   1ST YEAR; LANGUAGE; POTENTIALS
AB Objective: To examine the utility of the mismatch response (MMR) and acoustic change complex (ACC) for assessing speech discrimination in infants.
   Methods: Continuous EEG was recorded during sleep from 48 (24 male, 20 female) normally hearing aged 1.77 to -4.57 months in response to two auditory discrimination tasks. ACC was recorded in response to a three-vowel sequence (/i/-/a/-/i/). MMR was recorded in response to a standard vowel, /a/, (probability 85%), and to a deviant vowel, /i/, (probability of 15%). A priori comparisons included: age, sex, and sleep state. These were conducted separately for each of the three bandpass filter settings were compared (1-18, 1-30, and 1-40 Hz).
   Results: A priori tests revealed no differences in MMR or ACC for age, sex, or sleep state for any of the three filter settings. ACC and MMR responses were prominently observed in all 44 sleeping infants (data from four infants were excluded). Significant differences observed for ACC were to the onset and offset of stimuli. However, neither group nor individual differences were observed to changes in speech stimuli in the ACC. MMR revealed two prominent peaks occurring at the stimulus onset and at the stimulus offset. Permutation t-tests revealed significant differences between the standard and deviant stimuli for both the onset and offset MMR peaks (p < 0.01). The 1-18 Hz filter setting revealed significant differences for all participants in the MMR paradigm.
   Conclusion: Both ACC and MMR responses were observed to auditory stimulation suggesting that infants perceive and process speech information even during sleep. Significant differences between the standard and deviant responses were observed in the MMR, but not ACC paradigm. These findings suggest that the MMR is sensitive to detecting auditory/speech discrimination processing.
   Significance: This paper identified that MMR can be used to identify discrimination in normal hearing infants. This suggests that MMR has potential for use in infants with hearing loss to validate hearing aid fittings. (C) 2018 International Federation of Clinical Neurophysiology. Published by Elsevier B.V. All rights reserved.
C1 [Uhler, Kristin M.] Univ Colorado Denver, Childrens Hosp Colorado, Dept Phys Med & Rehabil, Aurora, CO USA.
   [Uhler, Kristin M.] Univ Colorado Denver, Childrens Hosp Colorado, Dept Otolaryngol, Aurora, CO USA.
   [Uhler, Kristin M.] Univ Colorado Denver, Childrens Hosp Colorado, Dept Psychiat, Aurora, CO USA.
   [Hunter, Sharon K.; Tierney, Elyse] Univ Colorado Denver, Dept Psychiat, Aurora, CO USA.
   [Hunter, Sharon K.; Tierney, Elyse] Univ Colorado Denver, Dept Pediat, Aurora, CO USA.
   [Gilley, Phillip M.] Univ Colorado, Inst Cognit Sci, Neurodynam Lab, Boulder, CO 80309 USA.
RP Uhler, KM (corresponding author), 12631 E 17th Pl, Aurora, CO 80045 USA.
EM Kristin.Uhler@ucdenver.edu
OI Hunter, Sharon/0000-0003-4136-1673
FU National Institutes of Health - National Institute on Deafness and other
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [1K23DC01358];
   National Organization of Hearing Research; CCTSI=NIH/NCRR Colorado CTSI
   Grant [UL1 TR001082]; National Institute on Disability, Independent
   Living, and Rehabilitation Research (NIDILRR)United States Department of
   Health & Human Services [90RE5020]; NATIONAL CENTER FOR ADVANCING
   TRANSLATIONAL SCIENCESUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Center for
   Advancing Translational Sciences (NCATS) [UL1TR001082, UL1TR001082,
   UL1TR001082, UL1TR001082, UL1TR001082, UL1TR001082, UL1TR001082] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [K23DC013583,
   K23DC013583, K23DC013583, K23DC013583, K23DC013583] Funding Source: NIH
   RePORTER
FX Funding for this research was provided by the National Institutes of
   Health - National Institute on Deafness and other Communication
   Disorders 1K23DC01358; National Organization of Hearing Research
   (http://www.nohrfoundation.org) and by CCTSI=NIH/NCRR Colorado CTSI
   Grant Number UL1 TR001082 to author KU and by the National Institute on
   Disability, Independent Living, and Rehabilitation Research (NIDILRR
   #90RE5020) to author PMG. NIDILRR is a Center within the Administration
   for Community Living (ACL), Department of Health and Human Services
   (HHS). The contents of this research manuscript do not necessarily
   represent the policy of NIDILRR, ACL, HHS, and you should not assume
   endorsement by the Federal Government.
CR ALHO K, 1995, EAR HEARING, V16, P38, DOI 10.1097/00003446-199502000-00004
   Baltzell LS, 2014, CLIN NEUROPHYSIOL, V125, P370, DOI 10.1016/j.clinph.2013.08.003
   Benjamini Y, 2001, ANN STAT, V29, P1165
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bishop DVM, 2010, PSYCHOPHYSIOLOGY, V47, P697, DOI 10.1111/j.1469-8986.2009.00970.x
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Ceponiene R, 2002, CLIN NEUROPHYSIOL, V113, P870, DOI 10.1016/S1388-2457(02)00078-0
   Ceponiene R, 2000, DEV MED CHILD NEUROL, V42, P258, DOI 10.1017/S001216220000044X
   Cheour M, 1998, INT J PSYCHOPHYSIOL, V29, P217, DOI 10.1016/S0167-8760(98)00017-8
   Cheour M, 2002, NATURE, V415, P599, DOI 10.1038/415599b
   Cone BK, 2015, INT J PSYCHOPHYSIOL, V95, P65, DOI 10.1016/j.ijpsycho.2014.06.002
   Cranford Jerry L, 2003, J Am Acad Audiol, V14, P251
   Estes KG, 2007, PSYCHOL SCI, V18, P254, DOI 10.1111/j.1467-9280.2007.01885.x
   Freeman WJ, 2006, PHYS LIFE REV, V3, P93, DOI 10.1016/j.plrev.2006.02.001
   Friedrich M, 2011, J COGNITIVE NEUROSCI, V23, P3228, DOI 10.1162/jocn_a_00002
   GIARD MH, 1990, PSYCHOPHYSIOLOGY, V27, P627, DOI 10.1111/j.1469-8986.1990.tb03184.x
   Gilley PM, 2017, BMC NEUROSCI, V18, DOI 10.1186/s12868-017-0353-4
   Gilley PM, 2016, CLIN NEUROPHYSIOL, V127, P1618, DOI 10.1016/j.clinph.2015.11.003
   Gilley Phillip M., 2014, Seminars in Hearing, V35, P15, DOI 10.1055/s-0033-1363521
   Grigg-Damberger MM, 2016, J CLIN SLEEP MED, V12, P429, DOI 10.5664/jcsm.5600
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   HAYAKAWA F, 1987, ELECTROEN CLIN NEURO, V67, P27, DOI 10.1016/0013-4694(87)90158-1
   He C, 2009, EUR J NEUROSCI, V29, P861, DOI 10.1111/j.1460-9568.2009.06625.x
   Holinger DP, 2000, J CLIN NEUROPHYSIOL, V17, P331, DOI 10.1097/00004691-200005000-00011
   KAUKORANTA E, 1989, HEARING RES, V41, P15, DOI 10.1016/0378-5955(89)90174-3
   KRAUS N, 1993, HEARING RES, V65, P118, DOI 10.1016/0378-5955(93)90206-G
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Kurth S, 2013, BRAIN SCI, V3, P1445, DOI 10.3390/brainsci3041445
   Kushnerenko E, 2001, NEUROREPORT, V12, P3777, DOI 10.1097/00001756-200112040-00035
   Kushnerenko E, 2002, NEUROREPORT, V13, P47, DOI 10.1097/00001756-200201210-00014
   Kushnerenko E, 2002, NEUROREPORT, V13, P1843, DOI 10.1097/00001756-200210280-00002
   Kushnerenko E, 2007, EUR J NEUROSCI, V26, P265, DOI 10.1111/j.1460-9568.2007.05628.x
   Leppanen PHT, 2012, NEUROPHYSIOL CLIN, V42, P35, DOI 10.1016/j.neucli.2011.08.005
   Leppanen PHT, 1997, DEV NEUROPSYCHOL, V13, P175, DOI 10.1080/87565649709540677
   Lieder F, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002911
   Luck SJ, 2005, INTRO EVENT RELATED, P99
   Luck SJ, 2017, PSYCHOPHYSIOLOGY, V54, P146, DOI 10.1111/psyp.12639
   Mueller JL, 2012, P NATL ACAD SCI USA, V109, P15953, DOI 10.1073/pnas.1204319109
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1997, AUDIOL NEURO-OTOL, V2, P341
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Naatanen R, 1995, Int J Neurosci, V80, P317, DOI 10.3109/00207459508986107
   Ostroff J, 1998, EAR HEARING, V19, P280
   Otte RA, 2013, BIOL PSYCHOL, V92, P315, DOI 10.1016/j.biopsycho.2012.09.009
   Portas CM, 2000, NEURON, V28, P991, DOI 10.1016/S0896-6273(00)00169-0
   Small SA, 2012, EAR HEARING, V33, pE59, DOI 10.1097/AUD.0b013e31825f29be
   SOKOLOV EN, 1963, ANNU REV PHYSIOL, V25, P545, DOI 10.1146/annurev.ph.25.030163.002553
   Strange W., 1978, PERCEPTION EXPERIENC
   Sussman ES, 2007, J PSYCHOPHYSIOL, V21, P164, DOI 10.1027/0269-8803.21.34.164
   Tervaniemi M, 2000, HUM BRAIN MAPP, V10, P74, DOI 10.1002/(SICI)1097-0193(200006)10:2<74::AID-HBM30>3.3.CO;2-U
   Trainor L, 2003, INT J PSYCHOPHYSIOL, V51, P5, DOI 10.1016/S0167-8760(03)00148-X
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   Tremblay Kelly L, 2004, J Am Acad Audiol, V15, P226
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Uhler K, 2011, J AM ACAD AUDIOL, V22, P129, DOI 10.3766/jaaa.22.3.2
   Uhler KM, 2015, J AM ACAD AUDIOL, V26, P807, DOI 10.3766/jaaa.14093
   van den Heuvel MI, 2016, INT J PSYCHOPHYSIOL, P75, DOI [10.1016/j.ijphysho.2015.04.003, DOI 10.1016/J.IJPHYSHO.2015.04.003]
   van Leeuwen T, 2008, J NEUROLINGUIST, V21, P333, DOI 10.1016/j.jneuroling.2007.07.004
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yoshinaga-Itano C, 1998, PEDIATRICS, V102, P1161, DOI 10.1542/peds.102.5.1161
NR 62
TC 2
Z9 2
U1 0
U2 6
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 1388-2457
EI 1872-8952
J9 CLIN NEUROPHYSIOL
JI Clin. Neurophysiol.
PD JUN
PY 2018
VL 129
IS 6
BP 1148
EP 1160
DI 10.1016/j.clinph.2018.02.132
PG 13
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA GG5EE
UT WOS:000432717300006
PM 29635099
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Spinu, LE
   Hwang, J
   Lohmann, R
AF Spinu, Laura E.
   Hwang, Jiwon
   Lohmann, Renata
TI Is there a bilingual advantage in phonetic and phonological acquisition?
   The initial learning of word-final coronal stop realization in a novel
   accent of English
SO INTERNATIONAL JOURNAL OF BILINGUALISM
LA English
DT Article
DE Bilingualism; cognitive advantage; phonetic and phonological learning;
   echoic memory; accented speech; dialects of English; second dialect
   learning; speech perception
ID LANGUAGE SPEECH-PERCEPTION; 2ND-LANGUAGE; DISCRIMINATION; SPEAKERS;
   MEMORY; BRAIN; SOUND; PRONUNCIATION; DISTINCTNESS; INTONATION
AB Research question: We address the question of whether the cognitive advantage of the bilingual mind, already demonstrated in the case of auditory processing or novel word acquisition, also applies to other linguistic domains, specifically to phonetic and phonological learning.
   Design: We compare the performance of 17 monolinguals and 25 bilinguals from Canada in a production experiment with two tasks: imitation and spontaneous reproduction of a novel foreign accent, specifically Sussex English.
   Data and analysis: To eliminate potential sources of variability, our focus is on a sound already existing in the subjects' production (the glottal stop), but differently mapped to surface representations in the novel accent to which they were exposed (i.e., as an allophone of coronal stops in word-final position). We measured the glottal stop rates of our subjects in baseline, training, and post-training.
   Results: The two groups behaved differently, with bilinguals showing a larger increase of their glottal stop rate post-training. Our results are thus consistent with a bilingual advantage in phonetic and phonological learning.
   Originality: We interpret these findings in light of recent psycholinguistic work and conclude that echoic memory strategies, possibly underlain by stronger subcortical encoding of sound in bilinguals, may account for our results by facilitating the re-mapping between existing mental representations of sounds and existing articulatory command configurations.
   Significance: Our study adds to the body of work suggesting that there may be an advantage of bilingualism in second dialect learning in adulthood, and provides an explanation in terms of perceptual strategies in which echoic memory is involved. We also contribute to the body of research suggesting that imitation of an action can result in improved understanding of that action.
C1 [Spinu, Laura E.] York Univ, Dept Languages Literatures & Linguist, Toronto, ON, Canada.
   [Hwang, Jiwon] SUNY Stony Brook, Dept Asian & Asian Amer Studies, Stony Brook, NY 11794 USA.
   [Lohmann, Renata] Western Univ, Dept French Studies, Linguist, London, ON, Canada.
RP Spinu, LE (corresponding author), Dept Languages Literatures & Linguist, Ross Bldg S555, Toronto, ON M3J 1P3, Canada.
EM lspinu@yorku.ca
CR Adamson HD, 2015, STUD SECOND LANG ACQ, V37, P167, DOI 10.1017/S0272263114000746
   Adank P, 2012, HUM BRAIN MAPP, V33, P360, DOI 10.1002/hbm.21218
   Adank P, 2010, PSYCHOL SCI, V21, P1903, DOI 10.1177/0956797610389192
   ANDERSONHSIEH J, 1992, LANG LEARN, V42, P529, DOI 10.1111/j.1467-1770.1992.tb01043.x
   Antoniou M, 2015, BILING-LANG COGN, V18, P683, DOI 10.1017/S1366728914000777
   ASLIN RN, 1998, HDB CHILD PSYCHOL, V2, P147
   Baker W, 2008, LANG SPEECH, V51, P317, DOI 10.1177/0023830908099068
   Banai K, 2009, CEREB CORTEX, V19, P2699, DOI 10.1093/cercor/bhp024
   Barry W. J., 1989, Computer Speech and Language, V3, P355, DOI 10.1016/0885-2308(89)90003-X
   Bent T, 2008, PHONETICA, V65, P131, DOI 10.1159/000144077
   Bialystok E, 1999, CHILD DEV, V70, P636, DOI 10.1111/1467-8624.00046
   Bialystok E, 2004, PSYCHOL AGING, V19, P290, DOI 10.1037/0882-7974.19.2.290
   Bialystok E, 2005, SCI STUD READ, V9, P43, DOI 10.1207/s1532799xssr0901_4
   Bialystok E, 2012, TRENDS COGN SCI, V16, P240, DOI 10.1016/j.tics.2012.03.001
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bongaerts T, 1995, AGE FACTOR IN SECOND LANGUAGE ACQUISITION, P30
   BRUCK M, 1995, J CHILD LANG, V22, P307, DOI 10.1017/S0305000900009806
   Calabrese A, 2012, J NEUROLINGUIST, V25, P355, DOI 10.1016/j.jneuroling.2011.03.005
   Colzato LS, 2008, J EXP PSYCHOL LEARN, V34, P302, DOI 10.1037/0278-7393.34.2.302
   Costa A, 2008, COGNITION, V106, P59, DOI 10.1016/j.cognition.2006.12.013
   Crinion J, 2006, SCIENCE, V312, P1537, DOI 10.1126/science.1127761
   Crowder R. G., 2014, NEW DIRECTIONS MEMOR, P181
   D'Imperio M., 2015, P ICPHS 2015 GLASG 1
   D'Imperio M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01226
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Delvaux V., 2013, P 14 INT LYON, V14, P2375
   Docherty Gerard J., 1999, URBAN VOICES, P47
   Docherty GJ, 2005, FIGURE OF SPEECH: A FESTSCHRIFT FOR JOHN LAVER, P173
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1988, HUMAN COMMUNICATION, P224
   Fowler CA, 2008, J PHONETICS, V36, P649, DOI 10.1016/j.wocn.2008.04.001
   Gass Susan M., 2013, 2 LANGUAGE ACQUISITI
   Gavac N., 2002, THESIS
   Grossheinrich N, 2010, PSYCHOPHYSIOLOGY, V47, P822, DOI 10.1111/j.1469-8986.2010.00996.x
   GUENTHER FH, 1995, PSYCHOL REV, V102, P594, DOI 10.1037/0033-295X.102.3.594
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Gundel J. K., 1988, STUDIES SYNTACTIC TY, P285
   Han Z., 2006, STUDIES FOSSILIZATIO, V14
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   Hosoda M, 2007, PERCEPT MOTOR SKILL, V104, P307, DOI 10.2466/PMS.104.1.307-326
   Hu XC, 2013, BRAIN LANG, V127, P366, DOI 10.1016/j.bandl.2012.11.006
   Hughes A., 1997, ENGLISH ACCENTS DIAL
   Javitt DC, 1997, J ABNORM PSYCHOL, V106, P315, DOI 10.1037/0021-843X.106.2.315
   Jilka M., 2007, P 16 INT C PHON SCI, P1737
   Jilka M., 2000, THESIS
   Kaushanskaya M, 2009, PSYCHON B REV, V16, P705, DOI 10.3758/PBR.16.4.705
   Keys K. J., 2012, REV LINGUAGEM ENSINO, V5, P75
   Kim KHS, 1997, NATURE, V388, P171, DOI 10.1038/40623
   Kluge D. C., 2008, P 5 JORN TECN HABL B, P199
   Kondratenko Y., 2014, P 48 ANN M CHIC LING, P387
   Kovacs AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   Kraus N, 2016, ANNU REV PSYCHOL, V67, P83, DOI 10.1146/annurev-psych-122414-033318
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Kuhl P., 1995, P 13 INT C PHON SCI, P146
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lev-Ari S, 2010, J EXP SOC PSYCHOL, V46, P1093, DOI 10.1016/j.jesp.2010.05.025
   Levi SV, 2007, J ACOUST SOC AM, V121, P2327, DOI 10.1121/1.2537345
   Lindemann S, 2005, INT J APPL LINGUIST, V15, P187, DOI 10.1111/j.1473-4192.2005.00087.x
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Ljungberg JK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073029
   MALECOT A, 1975, PHONETICA, V31, P51, DOI 10.1159/000259649
   MALECOT A, 1958, LANGUAGE, V34, P370, DOI 10.2307/410929
   Markham D., 1997, PHONETIC IMITATION A
   Masgoret AM, 2003, LANG LEARN, V53, P167, DOI 10.1111/1467-9922.00227
   Michael E. B., 2005, HDB BILINGUALISM PSY, P389, DOI DOI 10.1017/S0272263107210071
   Moyer A., 1999, STUD SECOND LANG ACQ, V21, DOI [DOI 10.1017/S0272263199001035, https://doi.org/10.1017/S0272263199001035]
   Neisser U., 1967, COGNITIVE PSYCHOL
   Perkell JS, 2004, J SPEECH LANG HEAR R, V47, P1259, DOI 10.1044/1092-4388(2004/095)
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   ROBINSON P, 2001, COGNITION 2 LANGUAGE
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Selinker L., 2013, REDISCOVERING INTERL
   Selkirk Elisabeth, 1980, PHRASE PHONOLOGY ENG
   Sereno J, 2016, APPL PSYCHOLINGUIST, V37, P303, DOI 10.1017/S0142716414000575
   SIPE S, 1986, J EXP PSYCHOL LEARN, V12, P402, DOI 10.1037/0278-7393.12.3.402
   Skoruppa K, 2011, COGNITIVE SCI, V35, P348, DOI 10.1111/j.1551-6709.2010.01152.x
   Smith Aaron, 2009, THESIS
   Sumner M, 2005, J MEM LANG, V52, P322, DOI 10.1016/j.jml.2004.11.004
   Sundara M, 2006, BILING-LANG COGN, V9, P97, DOI 10.1017/S1366728905002403
   Thomas E. R., 2011, SOCIOPHONETICS INTRO
   Tranel B., 1981, CONCRETENESS GENERAT
   Tremblay MC, 2012, J ACOUST SOC AM, V132, P3465, DOI 10.1121/1.4756955
   Walker D. C., 1984, PRONUNCIATION CANADI
   WATKINS MJ, 1980, J VERB LEARN VERB BE, V19, P46, DOI 10.1016/S0022-5371(80)90512-5
   WEI LY, 2008, BLACKWELL GUIDE RES, V34, P3
   Wells J., 1997, ENGLISH TEACHING PRO, V3, P46
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Yarrington D., 2008, P ACL 08 HLT DEM SES, P28
NR 98
TC 1
Z9 1
U1 0
U2 7
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1367-0069
EI 1756-6878
J9 INT J BILINGUAL
JI Int. J. Biling.
PD JUN
PY 2018
VL 22
IS 3
BP 350
EP 370
DI 10.1177/1367006916681080
PG 21
WC Linguistics; Language & Linguistics
SC Linguistics
GA GH1YQ
UT WOS:000433198900006
DA 2021-02-24
ER

PT J
AU Sjerps, MJ
   Zhang, CC
   Peng, G
AF Sjerps, Matthias J.
   Zhang, Caicai
   Peng, Gang
TI Lexical Tone is Perceived Relative to Locally Surrounding Context, Vowel
   Quality to Preceding Context
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE speech perception; lexical tone; vowel quality; normalization; context
   effects
ID SPECTRAL-ENVELOPE DISTORTION; CANTONESE LEVEL TONES; PERCEPTUAL
   NORMALIZATION; SPEECH CATEGORIZATION; SPEAKER NORMALIZATION; TALKER
   NORMALIZATION; CLEAR SPEECH; INFORMATION; CHINESE; COMPENSATION
AB Important speech cues such as lexical tone and vowel quality are perceptually contrasted to the distribution of those same cues in surrounding contexts. However, it is unclear whether preceding and following contexts have similar influences, and to what extent those influences are modulated by the auditory history of previous trials. To investigate this, Cantonese participants labeled sounds from (a) a tone continuum (mid-to high-level), presented with a context that had raised or lowered fundamental frequency (F0) values and (b) a vowel quality continuum (/u/ to /o/), where the context had raised or lowered first formant (F1) values. Contexts with high or low F0/F1 were presented in separate blocks or intermixed in 1 block. Contexts were presented following (Experiment 1) or preceding the target continuum (Experiment 2). Contrastive effects were found for both tone and vowel quality (e.g., decreased F0 values in contexts lead to more high tone target judgments and vice versa). Importantly, however, lexical tone was only influenced by F0 in immediately preceding and following contexts. Vowel quality was only influenced by the F1 in preceding contexts, but this extended to contexts from preceding trials. Contextual influences on tone and vowel quality are qualitatively different, which has important implications for understanding the mechanism of context effects in speech perception.
   Public Significance Statement
   Speech perception is highly context dependent. This study compares the strength of contextual influences in the perception of lexical tone and vowel quality in a number of ways. Perception of lexical tone was found to be influenced by locally preceding and following contexts, while vowel quality was only influenced by the preceding context, and that influence extended further back in time. These patterns demonstrate that the temporal scope of contextual influences are cue specific.
C1 [Sjerps, Matthias J.] Radboud Univ Nijmegen, Neurobiol Language Dept, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Sjerps, Matthias J.] Univ Calif Berkeley, Dept Linguist, Berkeley, CA 94720 USA.
   [Zhang, Caicai; Peng, Gang] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Kowloon, Hong Kong, Peoples R China.
   [Zhang, Caicai; Peng, Gang] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
RP Peng, G (corresponding author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Kowloon, Hong Kong, Peoples R China.
EM gpengjack@gmail.com
RI Sjerps, Matthias/T-3084-2019; Zhang, Caicai/Q-6914-2018; Sjerps,
   Matthias/H-9022-2013
OI Zhang, Caicai/0000-0002-7687-0518; Sjerps, Matthias/0000-0003-3098-7152
FU Research Grants Council of Hong Kong (GRF)Hong Kong Research Grants
   Council [14408914]; People Programme (Marie Curie Actions) of the
   European Union's Seventh Framework Programme FP7 under REA [623072]
FX The project was supported through the Research Grants Council of Hong
   Kong (GRF Project 14408914). Matthias J. Sjerps received funding from
   the People Programme (Marie Curie Actions) of the European Union's
   Seventh Framework Programme FP7 2007-2013 under REA Grant Agreement
   Number 623072. We thank Neal Fox for his suggestions on parts of the
   analyses and thank Zijia Tian for her help in data collection. We would
   also like to thank Christian Stilp for useful comments on an earlier
   submitted version of this article. All data and analysis scripts have
   been made available through the Open Science Framework
   (https://osf.io/8pev9/).
CR Assgari AA, 2015, J ACOUST SOC AM, V138, P3023, DOI 10.1121/1.4934559
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Benders T, 2012, J ACOUST SOC AM, V131, P3079, DOI 10.1121/1.3688512
   Boersma P., 2014, PRAAT DOING PHONETIC
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chen YY, 2008, J PHONETICS, V36, P724, DOI 10.1016/j.wocn.2008.06.003
   Chen YY, 2008, J PHONETICS, V36, P629, DOI 10.1016/j.wocn.2008.03.001
   Cho TH, 2004, J PHONETICS, V32, P141, DOI 10.1016/S0095-4470(03)00043-3
   Connell B., 2001, TYP AFR PROS SYST WO
   Cutler A, 1997, PERCEPT PSYCHOPHYS, V59, P165, DOI 10.3758/BF03211886
   Francis AL, 2006, J ACOUST SOC AM, V119, P1712, DOI 10.1121/1.2149768
   Fromkin V. A., 1978, TONE LINGUISTIC SURV, P5, DOI DOI 10.1353/LAN.1980.0007
   GARRETT KL, 1987, J ACOUST SOC AM, V82, P58, DOI 10.1121/1.395437
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Heald SLM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136791
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Huang JY, 2011, J ACOUST SOC AM, V129, P1145, DOI 10.1121/1.3543994
   Huang JY, 2009, J ACOUST SOC AM, V125, P3983, DOI 10.1121/1.3125342
   JOHNSON K, 1993, LANGUAGE, V69, P505, DOI 10.2307/416697
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   JOHNSON TL, 1982, J ACOUST SOC AM, V72, P1761, DOI 10.1121/1.388649
   Kiefte M, 2008, J ACOUST SOC AM, V123, P366, DOI 10.1121/1.2804951
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   Krause JC, 2004, J ACOUST SOC AM, V115, P362, DOI 10.1121/1.1635842
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   LEATHER J, 1983, J PHONETICS, V11, P373, DOI 10.1016/S0095-4470(19)30836-8
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lin T., 1984, ZHONGGUO YUYAN XUEBA, V2, P59
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   Mitterer H, 2006, PHONETICA, V63, P209, DOI 10.1159/000097306
   Moore CB, 1997, J ACOUST SOC AM, V102, P1864, DOI 10.1121/1.420092
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PICHENY MA, 1989, J SPEECH HEAR RES, V32, P600, DOI 10.1044/jshr.3203.600
   PICHENY MA, 1986, J SPEECH HEAR RES, V29, P434, DOI 10.1044/jshr.2904.434
   Poser W. J., 1983, J ACOUST SOC AM, V74, pS89, DOI [10.1121/1.2021203, DOI 10.1121/1.2021203]
   Protopapas A, 1997, J ACOUST SOC AM, V101, P2267, DOI 10.1121/1.418247
   R Core Team, 2014, R LANG ENV STAT COMP
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Sjerps MJ, 2013, J PHONETICS, V41, P145, DOI 10.1016/j.wocn.2013.01.005
   Sjerps MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P576, DOI 10.3758/s13414-012-0408-7
   Sjerps MJ, 2012, BRAIN LANG, V120, P401, DOI 10.1016/j.bandl.2011.12.012
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Smiljanic R, 2005, J ACOUST SOC AM, V118, P1677, DOI 10.1121/1.2000788
   Stilp CE, 2017, J ACOUST SOC AM, V141, pEL153, DOI 10.1121/1.4974769
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   VANBERGEM DR, 1988, SPEECH COMMUN, V7, P1, DOI 10.1016/0167-6393(88)90018-0
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P3749, DOI 10.1121/1.414981
   Wong PCM, 2003, J SPEECH LANG HEAR R, V46, P413, DOI 10.1044/1092-4388(2003/034)
   Xu Y, 1997, J PHONETICS, V25, P61, DOI 10.1006/jpho.1996.0034
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Zhang CC, 2016, J EXP PSYCHOL HUMAN, V42, P1252, DOI 10.1037/xhp0000216
   Zhang CC, 2013, BRAIN LANG, V126, P193, DOI 10.1016/j.bandl.2013.05.010
   Zhang CC, 2012, J ACOUST SOC AM, V132, P1088, DOI 10.1121/1.4731470
   Zhang KL, 2017, J ACOUST SOC AM, V141, P38, DOI 10.1121/1.4973414
NR 61
TC 13
Z9 12
U1 0
U2 5
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD JUN
PY 2018
VL 44
IS 6
BP 914
EP 924
DI 10.1037/xhp0000504
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA GH1HF
UT WOS:000433153100009
PM 29172630
OA Green Published
DA 2021-02-24
ER

PT J
AU Luft, P
   Amiruzzaman, S
AF Luft, Pamela
   Amiruzzaman, Stefanie
TI Examining States' Responses to the IDEA Special Factors Requirements for
   DHH Students
SO JOURNAL OF DISABILITY POLICY STUDIES
LA English
DT Article
DE IDEA; special factors; communication; deaf; hard-of-hearing; state
   regulations
ID AMERICAN SIGN-LANGUAGE; VOCABULARY DEVELOPMENT; EARLY INTERVENTION;
   SPEECH-PERCEPTION; HEARING-LOSS; DEAF; CHILDREN; ACQUISITION; AGE;
   INFANTS
AB Deaf and hard-of-hearing (DHH) students have exhibited deficient language competencies and low academic achievement for over four decades. As a result, Individuals With Disabilities Education Act (IDEA) 2004 requires schools to address special language and communication factors through each student's Individualized Education Program (IEP). States have responded in a variety of ways with several that supplement their IEPs using a communication plan. This article examined states' IEP or communication plan templates to identify the format and specificity with which they addressed these requirements. The IDEA language was parsed into distinct items to allow ratings using a Likert-type scale. The analyses performed descriptive, t test, and ANOVA comparisons on the forms posted on states' website. Those states using a communication plan had significantly higher ratings overall. Kentucky's form was the most highly rated IEP and identified each required item. Most state IEP forms identified these factors more generally with a majority rated as only minimally specified. Use of a communication plan or IEP form that incorporates IDEA language similar was the most effective strategy. Overt specificity ensures that DHH students' language and communication needs are being met in the educational environment and facilitates states' oversight in meeting their educational responsibilities.
C1 [Luft, Pamela; Amiruzzaman, Stefanie] Kent State Univ, Kent, OH 44242 USA.
RP Luft, P (corresponding author), Kent State Univ, Sch Lifespan Dev & Educ Sci, Coll Educ Hlth & Human Serv, 405 White Hall,150 Terrace Dr, Kent, OH 44242 USA.
EM pluft@kent.edu
RI Luft, Pamela/ABH-9866-2020
CR Allen TE, 2010, J DEAF STUD DEAF EDU, V15, P334, DOI 10.1093/deafed/enq034
   *AM SPEECH LANG HE, DEGR HEAR LOSS
   Anderson D., 2002, J DEAF STUD DEAF EDU, V7, P83, DOI DOI 10.1093/DEAFED/7.2.83
   Anderson D., 2006, ADV SIGN LANGUAGE DE, P135
   Andrews JF, 2010, AM ANN DEAF, V155, P407, DOI 10.1353/aad.2010.0036
   Archbold S, 2012, DEAF EDUC INT, V14, P2, DOI 10.1179/1557069X12Y.0000000003
   Barker DH, 2009, DEV PSYCHOPATHOL, V21, P373, DOI 10.1017/S0954579409000212
   Blamey P, 2002, AUDIOL NEURO-OTOL, V7, P114, DOI 10.1159/000057659
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Boudreault P, 2006, LANG COGNITIVE PROC, V21, P608, DOI 10.1080/01690960500139363
   Bowe F., 2003, J DEAF STUD DEAF EDU, V8, P485, DOI [10.1093/deafed/eng024, DOI 10.1093/DEAFED/ENG024]
   Bowers LM, 2013, COMMUN DISORD Q, V34, P221, DOI 10.1177/1525740112469662
   Busa J, 2007, PEDIATRICS, V120, P898, DOI 10.1542/peds.2007-2333
   Calderon R, 1998, VOLTA REV, V100, P53
   DAVIS JM, 1986, J SPEECH HEAR DISORD, V51, P53, DOI 10.1044/jshd.5101.53
   Delage H, 2007, J SPEECH LANG HEAR R, V50, P1300, DOI 10.1044/1092-4388(2007/091)
   Easterbrooks S.R., 2002, LANGUAGE LEARNING CH
   Foster S. B., 1998, CULTURAL LANGUAGE DI, P117
   Friedmann N, 2006, J DEAF STUD DEAF EDU, V11, P56, DOI 10.1093/deafed/enj002
   Gallaudet Research Institute, 2013, REG NAT SUMM REP DAT
   GANNON JR, 1981, DEAF HERITAGE NARRAT
   GILBERTSON M, 1995, J SPEECH HEAR RES, V38, P630, DOI 10.1044/jshr.3803.630
   Holte L, 2012, AM J AUDIOL, V21, P163, DOI 10.1044/1059-0889(2012/12-0016)
   Humphries T, 2016, CLIN PEDIATR, V55, P513, DOI 10.1177/0009922815616891
   Johnson C. D., 2013, ED ADVOCACY STUDENTS
   Karchmer M., 2003, OXFORD HDB DEAF STUD, P21, DOI [DOI 10.1093/OXFORDHB/9780199750986.013.0003, 10.1093/oxfordhb/9780199750986.013.0003]
   King F., 2017, EXCEPTIONAL PARENT, V47, P38
   Kuhl P, 2008, ANNU REV NEUROSCI, V31, P511, DOI 10.1146/annurev.neuro.30.051606.094321
   Kushalnagar P, 2011, J DEAF STUD DEAF EDU, V16, P512, DOI 10.1093/deafed/enr015
   Lane H., 1996, JOURNEY DEAF WORLD
   Lecours A. R., 1975, FDN LANGUAGE DEV MUL, P121
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   MARSCHARK M, 2001, CONTEXT COGNITION DE, P71
   Marschark M, 2007, J DEAF STUD DEAF EDU, V12, P269, DOI 10.1093/deafed/enm013
   Marschark M, 2012, DEAF EDUC INT, V14, P136, DOI 10.1179/1557069X12Y.0000000010
   Mayberry R. I., 2006, ENCY LANGUAGE LINGUI
   Mayberry RI, 2007, APPL PSYCHOLINGUIST, V28, P537, DOI 10.1017/S0142716407070294
   Mayberry RI, 2011, BRAIN LANG, V119, P16, DOI 10.1016/j.bandl.2011.05.007
   Mayberry RI, 2003, BRAIN LANG, V87, P369, DOI 10.1016/S0093-934X(03)00137-8
   Mayberry RI, 2002, NATURE, V417, P38, DOI 10.1038/417038a
   Mayne AM, 1998, VOLTA REV, V100, P29
   Mayne AM, 1998, VOLTA REV, V100, P1
   Moeller M. P., 1986, ASHA MONOGRAPH
   Moeller MP, 2000, PEDIATRICS, V106, DOI 10.1542/peds.106.3.e43
   Morningstar ME, 2008, CAREER DEV TRANSIT E, V31, P48, DOI 10.1177/0885728807313776
   National Cancer Institute National Institutes of Health U.S. Department of Health and Human Services, 2009, NIH PUBLICATION, V09-7473
   NICHOLAS JG, 2003, J DEAF STUDIES DEAF, V0008
   Parasnis I., 1998, CULTURAL LANGUAGE DI, P3
   Paul P. V., 2011, HEARING DEAFNESS INT
   Penicaud S, 2013, NEUROIMAGE, V66, P42, DOI 10.1016/j.neuroimage.2012.09.076
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Ramsey C. L., 1997, DEAF CHILDREN PUBLIC
   ROTHSTEIN LAURA, 2010, SPECIAL ED LAW
   Scott S, 2006, CONF PROC INT SYMP C, P16, DOI 10.1145/1150019.1136488
   Shaver D., 2011, FACTS NLTS2 SECONDAR
   Singleton JL, 2004, COGNITIVE PSYCHOL, V49, P370, DOI 10.1016/j.cogpsych.2004.05.001
   Stokoe W. C., 1960, STUDIES LINGUISTICS, V8
   Stredler-Brown A, 1998, VOLTA REV, V100, P85
   Traxler Carol Bloomquist, 2000, J DEAF STUD DEAF EDU, V5, P337, DOI [DOI 10.1093/DEAFED/5.4.337, 10.1093/deafed/5.4.337]
   US Department of Education, 2016, RDA RES DRIV ACC IMP
   US Department of Education, 2006, BUILD LEG ID 2014 TO
   US Department of Education, 2015, STAT PERF REP SPP B
   US Department of Education, 2007, GUID IND ED PROGR AR
   Wagner M., 2006, ACHIEVEMENT FUNCTION
   Wright P. W. D., 2016, APPENDIX NOTICE 300
   Zaidman-Zait A, 2008, J DEAF STUD DEAF EDU, V13, P193, DOI 10.1093/deafed/enm051
NR 66
TC 0
Z9 0
U1 0
U2 0
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1044-2073
EI 1538-4802
J9 J DISABIL POLICY STU
JI J. Disabil. Policy Stud.
PD JUN
PY 2018
VL 29
IS 1
SI SI
BP 32
EP 42
DI 10.1177/1044207317751675
PG 11
WC Rehabilitation
SC Rehabilitation
GA GF8QK
UT WOS:000432237200005
DA 2021-02-24
ER

PT J
AU van Heugten, M
   Paquette-Smith, M
   Krieger, DR
   Johnson, EK
AF van Heugten, Marieke
   Paquette-Smith, Melissa
   Krieger, Dena R.
   Johnson, Elizabeth K.
TI Infants' recognition of foreign-accented words: Flexible yet precise
   signal-to-word mapping strategies
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Infant speech perception; Spoken language processing; Word recognition;
   Foreign accents; Phonological specificity
ID EARLY LEXICAL REPRESENTATIONS; EARLY RECEPTIVE LEXICON; CHILDRENS
   PERCEPTION; REGIONAL ACCENT; FAMILIAR WORDS; YOUNG-CHILDREN; TODDLERS
   PERCEPTION; DIALECT VARIATION; NATIVE LANGUAGE; SPEECH
AB To develop adult-like communication skills, children need to learn to converse not only with individuals from their local community, but also with second-language leamers who might have foreign accents. Here, we ask when infants can recognize foreign-accented word forms, and what the cognitive underpinnings are that enable children to map such surface forms onto established lexical representations. In line with reports using regional accents, Canadian-English learners recognize words forms in a foreign French accent by 18 months of age, indicating that the developmental trajectory of coping with foreign accents is not always more protracted than that of regional accents. Moreover, mispronounced versions of known words appear to be treated as nonwords, suggesting that children do not accept all phonemic substitutions when listening to foreign-accented speech. Thus, infants' word form recognition is simultaneously flexible and at least somewhat specific, allowing them to cope with accents relatively efficiently from early on.
C1 [van Heugten, Marieke] Univ Buffalo State Univ New York, Dept Psychol, Buffalo, NY 14260 USA.
   [Paquette-Smith, Melissa; Krieger, Dena R.; Johnson, Elizabeth K.] Univ Toronto, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
RP van Heugten, M (corresponding author), Univ Buffalo State Univ New York, Dept Psychol, Buffalo, NY 14260 USA.
EM mariekev@buffalo.edu; m.paquette.smith@mail.utoronto.ca;
   dena.krieger@mail.utoronto.ca; elizabeth.johnson@utoronto.ca
RI Paquette-Smith, Melissa/AAP-7428-2020
OI Johnson, Elizabeth Kay/0000-0002-9941-9949; van Heugten,
   Marieke/0000-0002-4758-2314
FU NSERCNatural Sciences and Engineering Research Council of Canada
   (NSERC); SSHRCSocial Sciences and Humanities Research Council of Canada
   (SSHRC)
FX We thank Isabelle Dautriche for producing our materials. This work was
   supported by grants from NSERC and SSHRC awarded to EKJ and a SSHRC
   doctoral fellowship to MPS. Part of this work has been presented at the
   2nd Workshop on Infant Language Development, Stockholm, Sweden; the 40th
   annual Boston University Conference on Language Development, Boston, MA;
   and the 15th Conference on Laboratory Phonology, Ithaca, NY.
CR [Anonymous], 2008, COGNITION, V106, P833, DOI 10.1016/j.cognition.2007.05.002
   Baese-Berk MM, 2015, J ACOUST SOC AM, V138, pEL223, DOI 10.1121/1.4929622
   Barton D., 1976, PAPERS REPORTS CHILD, V11, P61
   Bent T, 2017, LANG SPEECH, V60, P110, DOI 10.1177/0023830916645374
   Bent T, 2015, J ACOUST SOC AM, V138, P3985, DOI 10.1121/1.4938228
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Buckler H, 2017, J EXP CHILD PSYCHOL, V164, P87, DOI 10.1016/j.jecp.2017.06.017
   Creel SC, 2012, DEVELOPMENTAL SCI, V15, P697, DOI 10.1111/j.1467-7687.2012.01173.x
   Dale PS, 1996, BEHAV RES METH INS C, V28, P125, DOI 10.3758/BF03203646
   Delle Luche C, 2014, DEVELOPMENTAL SCI, V17, P948, DOI 10.1111/desc.12164
   Durrant S, 2015, J CHILD LANG, V42, P447, DOI 10.1017/S0305000914000063
   Estes KG, 2015, DEV PSYCHOL, V51, P1517, DOI 10.1037/a0039725
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2012, COGNITION, V124, P95, DOI 10.1016/j.cognition.2012.03.011
   Floccia C, 2009, J PSYCHOLINGUIST RES, V38, P379, DOI 10.1007/s10936-008-9097-8
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Frank MC, 2017, J CHILD LANG, V44, P677, DOI 10.1017/S0305000916000209
   Girard F, 2008, BRIT J DEV PSYCHOL, V26, P409, DOI 10.1348/026151007X251712
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   Halle PA, 1996, INFANT BEHAV DEV, V19, P463, DOI 10.1016/S0163-6383(96)90007-7
   HALLE PA, 1994, INFANT BEHAV DEV, V17, P119, DOI 10.1016/0163-6383(94)90047-7
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Johnson EK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083546
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   JUSCZYK PW, 1992, COGNITION, V43, P253, DOI 10.1016/0010-0277(92)90014-9
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   KUHL PK, 1979, J ACOUST SOC AM, V66, P1668, DOI 10.1121/1.383639
   Mani N, 2008, LANG SPEECH, V51, P3, DOI 10.1177/00238309080510010201
   Mani N, 2007, J MEM LANG, V57, P252, DOI 10.1016/j.jml.2007.03.005
   Mani N, 2011, J CHILD LANG, V38, P606, DOI 10.1017/S0305000910000243
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   Metsala JL, 1999, J EDUC PSYCHOL, V91, P3, DOI 10.1037/0022-0663.91.1.3
   Mulak KE, 2013, CHILD DEV, V84, P2064, DOI 10.1111/cdev.12087
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   Parise E, 2012, PSYCHOL SCI, V23, P728, DOI 10.1177/0956797612438734
   Polka L, 2014, PSYCHOL SCI, V25, P1448, DOI 10.1177/0956797614533571
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Schmale R, 2015, DEVELOPMENTAL SCI, V18, P664, DOI 10.1111/desc.12244
   Schmale R, 2011, J CHILD LANG, V38, P1096, DOI 10.1017/S0305000910000619
   Schmale R, 2012, DEVELOPMENTAL SCI, V15, P732, DOI 10.1111/j.1467-7687.2012.01175.x
   Schmale R, 2010, INFANCY, V15, P650, DOI 10.1111/j.1532-7078.2010.00032.x
   Schmale R, 2009, DEVELOPMENTAL SCI, V12, P583, DOI 10.1111/j.1467-7687.2009.00809.x
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Singh L, 2008, INFANCY, V13, P57, DOI 10.1080/15250000701779386
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   Swingley D, 2016, DEV PSYCHOL, V52, P1011, DOI 10.1037/dev0000114
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   van der Feest SVH, 2016, LANG ACQUIS, V23, P89, DOI 10.1080/10489223.2015.1047096
   van Heugten M, 2017, J ACOUST SOC AM, V142, pEL196, DOI 10.1121/1.4997604
   van Heugten M, 2016, LANG SPEECH, V59, P353, DOI 10.1177/0023830915600471
   van Heugten M, 2015, LANG LEARN DEV, V11, P41, DOI 10.1080/15475441.2013.879636
   van Heugten M, 2014, J EXP PSYCHOL GEN, V143, P340, DOI 10.1037/a0032192
   van Heugten M, 2012, J SPEECH LANG HEAR R, V55, P554, DOI 10.1044/1092-4388(2011/10-0347)
   Vihman MM, 2004, J MEM LANG, V50, P336, DOI 10.1016/j.jml.2003.11.004
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Wade T, 2007, PHONETICA, V64, P122, DOI 10.1159/000107913
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   Weatherhead D, 2016, LANG LEARN DEV, V12, P92, DOI 10.1080/15475441.2015.1024835
   White KS, 2008, J MEM LANG, V59, P114, DOI 10.1016/j.jml.2008.03.001
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
   Willits JA, 2013, INFANCY, V18, P1053, DOI 10.1111/infa.12026
NR 67
TC 2
Z9 2
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD JUN
PY 2018
VL 100
BP 51
EP 60
DI 10.1016/j.jml.2018.01.003
PG 10
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA GC8HL
UT WOS:000430034300004
DA 2021-02-24
ER

PT J
AU Moses, DA
   Leonard, MK
   Chang, EF
AF Moses, David A.
   Leonard, Matthew K.
   Chang, Edward F.
TI Real-time classification of auditory sentences using evoked cortical
   activity in humans
SO JOURNAL OF NEURAL ENGINEERING
LA English
DT Article
DE neural speech recognition; real-time speech classification; speech
   perception; electrocorticography; high gamma; human auditory cortex
ID BRAIN-COMPUTER-INTERFACE; SPEECH; CORTEX
AB Objective. Recent research has characterized the anatomical and functional basis of speech perception in the human auditory cortex. These advances have made it possible to decode speech information from activity in brain regions like the superior temporal gyrus, but no published work has demonstrated this ability in real-time, which is necessary for neuroprosthetic brain-computer interfaces. Approach. Here, we introduce a real-time neural speech recognition (rtNSR) software package, which was used to classify spoken input from high-resolution electrocorticography signals in real-time. We tested the system with two human subjects implanted with electrode arrays over the lateral brain surface. Subjects listened to multiple repetitions of ten sentences, and rtNSR classified what was heard in real-time from neural activity patterns using direct sentence-level and HMM-based phoneme-level classification schemes. Main results. We observed single-trial sentence classification accuracies of 90% or higher for each subject with less than 7 minutes of training data, demonstrating the ability of rtNSR to use cortical recordings to perform accurate real-time speech decoding in a limited vocabulary setting. Significance. Further development and testing of the package with different speech paradigms could influence the design of future speech neuroprosthetic applications.
C1 [Moses, David A.; Leonard, Matthew K.; Chang, Edward F.] UC San Francisco, Dept Neurol Surg, San Francisco, CA 94131 USA.
   [Moses, David A.; Leonard, Matthew K.; Chang, Edward F.] UC San Francisco, Ctr Integrat Neurosci, San Francisco, CA 94131 USA.
   [Moses, David A.; Chang, Edward F.] UC San Francisco, UC Berkeley, Grad Program Bioengn, San Francisco, CA 94131 USA.
RP Chang, EF (corresponding author), UC San Francisco, Dept Neurol Surg, San Francisco, CA 94131 USA.; Chang, EF (corresponding author), UC San Francisco, Ctr Integrat Neurosci, San Francisco, CA 94131 USA.; Chang, EF (corresponding author), UC San Francisco, UC Berkeley, Grad Program Bioengn, San Francisco, CA 94131 USA.
EM David.Moses@ucsf.edu; Matthew.Leonard@ucsf.edu;
   ChangEd@neurosurg.ucsf.edu
OI Leonard, Matthew/0000-0002-8530-880X
FU National Institutes of Health National Research ServiceUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [F32-DC013486, R00-NS065120, DP2-OD00862, R01-DC012379]; Ester A
   and Joseph Klingenstein Foundation; National Science FoundationNational
   Science Foundation (NSF) [1144247]
FX This work was supported by the National Institutes of Health National
   Research Service Award F32-DC013486 and Grants R00-NS065120, DP2-OD00862
   and R01-DC012379, the Ester A and Joseph Klingenstein Foundation, and
   the National Science Foundation Grant No. 1144247. The content is solely
   the responsibility of the authors and does not necessarily represent the
   official views of the National Institutes of Health.
CR Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Boatman D, 1997, CORTEX, V33, P83, DOI 10.1016/S0010-9452(97)80006-8
   Bruno MA, 2011, BMJ OPEN, V1, DOI 10.1136/bmjopen-2010-000039
   Canolty RT, 2007, FRONT NEUROSCI-SWITZ, V1, P185, DOI 10.3389/neuro.01.1.1.014.2007
   Cheung C, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/4/046018
   Crone NE, 1998, BRAIN, V121, P2301, DOI 10.1093/brain/121.12.2301
   Denby B, 2010, SPEECH COMMUN, V52, P270, DOI 10.1016/j.specom.2009.08.002
   Garofolo J, 1993, LINGUISTIC DATA CONS, V33
   GIACINO JT, 1995, ARCH PHYS MED REHAB, V76, P205
   Hamilton LS, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00062
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hotson G, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/2/026017
   Kanas VG, 2014, INT CONF DIGIT SIG, P862, DOI 10.1109/ICDSP.2014.6900790
   Kellis S, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/5/056007
   Khalighinejad B, 2017, INT CONF ACOUST SPEE, P846, DOI 10.1109/ICASSP.2017.7952275
   LAM M, 1988, ACM SIGPLAN NOTICES, V23, P318, DOI DOI 10.1145/960116.54022
   Laureys S, 2005, PROG BRAIN RES, V150, P495, DOI 10.1016/S0079-6123(05)50034-7
   Ledoit O, 2004, J PORTFOLIO MANAGE, V30, P110, DOI 10.3905/jpm.2004.110
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Leuthardt EC, 2006, IEEE T NEUR SYS REH, V14, P194, DOI 10.1109/TNSRE.2006.875536
   Leuthardt EC, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036004
   Mainsah BO, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/1/016013
   Martin S, 2016, SCI REP-UK, V6, DOI 10.1038/srep25803
   Martin Stephanie, 2014, Front Neuroeng, V7, P14, DOI 10.3389/fneng.2014.00014
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Moses DA, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/056004
   Mugler EM, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/035015
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pei XM, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/4/046028
   Python Software Foundation, 2010, PYTH LANG REF VERS 2
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rousseau MC, 2015, ORPHANET J RARE DIS, V10, DOI 10.1186/s13023-015-0304-z
   Sellers EW, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3007801
   Spuler M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051077
   Vansteensel MJ, 2016, NEW ENGL J MED, V375, P2060, DOI 10.1056/NEJMoa1608085
   von Luhmann A, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00617
   Yang MD, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1121
NR 38
TC 15
Z9 16
U1 2
U2 27
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1741-2560
EI 1741-2552
J9 J NEURAL ENG
JI J. Neural Eng.
PD JUN
PY 2018
VL 15
IS 3
AR 036005
DI 10.1088/1741-2552/aaab6f
PG 9
WC Engineering, Biomedical; Neurosciences
SC Engineering; Neurosciences & Neurology
GA FX7MQ
UT WOS:000426274400005
PM 29378977
DA 2021-02-24
ER

PT J
AU Dietrich, S
   Hertrich, I
   Muller-Dahlhaus, F
   Ackermann, H
   Belardinelli, P
   Desideri, D
   Seibold, VC
   Ziemann, U
AF Dietrich, Susanne
   Hertrich, Ingo
   Mueller-Dahlhaus, Florian
   Ackermann, Hermann
   Belardinelli, Paolo
   Desideri, Debora
   Seibold, Verena C.
   Ziemann, Ulf
TI Reduced Performance During a Sentence Repetition Task by Continuous
   Theta-Burst Magnetic Stimulation of the Pre-supplementary Motor Area
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cognitive control; inhibition; prediction; speech perception; top-down
   processing
ID MEDIAL FRONTAL-CORTEX; FUNCTIONAL-ANATOMIC ORGANIZATION; DECODING
   DEGRADED SPEECH; RIGHT-HEMISPHERE; WHITE-MATTER; HUMAN BRAIN; STRUCTURAL
   CONNECTIVITY; LANGUAGE COMPREHENSION; PSYCHOMETRIC FUNCTION;
   RESPONSE-INHIBITION
AB The pre-supplementary motor area (pre-SMA) is engaged in speech comprehension under difficult circumstances such as poor acoustic signal quality or time-critical conditions. Previous studies found that left pre-SMA is activated when subjects listen to accelerated speech. Here, the functional role of pre-SMA was tested for accelerated speech comprehension by inducing a transient "virtual lesion" using continuous theta-burst stimulation (cTBS). Participants were tested (1) prior to (pre-baseline), (2) 10 min after (test condition for the cTBS effect), and (3) 60 min after stimulation (post-baseline) using a sentence repetition task (formant-synthesized at rates of 8, 10, 12, 14, and 16 syllables/s). Speech comprehension was quantified by the percentage of correctly reproduced speech material. For high speech rates, subjects showed decreased performance after cTBS of pre-SMA. Regarding the error pattern, the number of incorrect words without any semantic or phonological similarity to the target context increased, while related words decreased. Thus, the transient impairment of pre-SMA seems to affect its inhibitory function that normally eliminates erroneous speech material prior to speaking or, in case of perception, prior to encoding into a semantically/pragmatically meaningful message.
C1 [Dietrich, Susanne; Hertrich, Ingo; Mueller-Dahlhaus, Florian; Ackermann, Hermann; Belardinelli, Paolo; Desideri, Debora; Ziemann, Ulf] Univ Tubingen, Hertie Inst Clin Brain Res, Dept Neurol & Stroke, Tubingen, Germany.
   [Dietrich, Susanne; Seibold, Verena C.] Univ Tubingen, Evolutionary Cognit, Dept Psychol, Tubingen, Germany.
   [Mueller-Dahlhaus, Florian] Johannes Gutenberg Univ Mainz, Johannes Gutenberg Univ, Univ Med Ctr, Dept Psychiat & Psychotherapy, Mainz, Germany.
RP Dietrich, S (corresponding author), Univ Tubingen, Hertie Inst Clin Brain Res, Dept Neurol & Stroke, Tubingen, Germany.; Dietrich, S (corresponding author), Univ Tubingen, Evolutionary Cognit, Dept Psychol, Tubingen, Germany.
EM a.dietrich@uni-tuebingen.de
RI Ziemann, Ulf/AAY-9125-2020; Hertrich, Ingo/T-1154-2018
OI Hertrich, Ingo/0000-0001-8965-6249
FU German Research Foundation (DFG)German Research Foundation (DFG) [HE
   1573/6-2]; Hertie Institute for Clinical Brain Research (Tubingen,
   Germany); Open Access Publishing Fund of University of Tubingen
FX This study was supported by the German Research Foundation (DFG Project
   HE 1573/6-2) and by the Hertie Institute for Clinical Brain Research
   (Tubingen, Germany). The authors would like to thank Fotini Scherer for
   excellent technical assistance. It should be noted that a preliminary
   version of the study was presented on the 18th International Congress of
   Phonetic Sciences (Dietrich el al., 2005). We acknowledge support by
   Open Access Publishing Fund of University of Tubingen.
CR Adank P, 2010, NEUROIMAGE, V49, P1124, DOI 10.1016/j.neuroimage.2009.07.032
   Anwander A, 2007, CEREB CORTEX, V17, P816, DOI 10.1093/cercor/bhk034
   Aron AR, 2014, TRENDS COGN SCI, V18, P177, DOI 10.1016/j.tics.2013.12.003
   Brendel B, 2010, NEUROIMAGE, V50, P1219, DOI 10.1016/j.neuroimage.2010.01.039
   Catani M, 2012, CORTEX, V48, P273, DOI 10.1016/j.cortex.2011.12.001
   Chao HHA, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-75
   Chee MWL, 1999, HUM BRAIN MAPP, V7, P15, DOI 10.1002/(SICI)1097-0193(1999)7:1<15::AID-HBM2>3.0.CO;2-6
   Chen CY, 2009, NEUROIMAGE, V44, P537, DOI 10.1016/j.neuroimage.2008.09.005
   Chen R, 1998, J NEUROPHYSIOL, V80, P2870
   Chouinard PA, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00173
   Clos M, 2014, BRAIN STRUCT FUNCT, V219, P581, DOI 10.1007/s00429-013-0519-5
   Clos M, 2014, HUM BRAIN MAPP, V35, P61, DOI 10.1002/hbm.22151
   de Bruin A, 2014, NEUROIMAGE, V90, P348, DOI 10.1016/j.neuroimage.2013.12.049
   DESIMONE R, 1987, J NEUROPHYSIOL, V57, P835
   DESIMONE R, 1991, J COGNITIVE NEUROSCI, V3, P1, DOI 10.1162/jocn.1991.3.1.1
   Dietrich S., 2015, 18 INT C PHON SCI IC
   Dietrich S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00701
   Dietrich S, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-74
   Ford A, 2010, NEUROIMAGE, V52, P1230, DOI 10.1016/j.neuroimage.2010.05.018
   Friederici AD, 2013, CURR OPIN NEUROBIOL, V23, P250, DOI 10.1016/j.conb.2012.10.002
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Geranmayeh F, 2017, BRAIN, V140, P1947, DOI 10.1093/brain/awx134
   GORELICK PB, 1987, J NEUROL NEUROSUR PS, V50, P553, DOI 10.1136/jnnp.50.5.553
   Grossheinrich N, 2009, BIOL PSYCHIAT, V65, P778, DOI 10.1016/j.biopsych.2008.10.029
   Hertrich I, 2016, NEUROSCI BIOBEHAV R, V68, P602, DOI 10.1016/j.neubiorev.2016.06.030
   Hertrich I, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00530
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Huang YZ, 2005, NEURON, V45, P201, DOI 10.1016/j.neuron.2004.12.033
   Kennerley SW, 2004, J NEUROPHYSIOL, V91, P978, DOI 10.1152/jn.00651.2003
   Kim JH, 2010, NEUROIMAGE, V49, P2375, DOI 10.1016/j.neuroimage.2009.10.016
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Kwon YH, 2013, J PHYS THER SCI, V25, P1083, DOI 10.1589/jpts.25.1083
   Lawes INC, 2008, NEUROIMAGE, V39, P62, DOI 10.1016/j.neuroimage.2007.06.041
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Mars RB, 2009, J NEUROSCI, V29, P6926, DOI 10.1523/JNEUROSCI.1396-09.2009
   Moore-Parks EN, 2010, BRAIN LANG, V114, P90, DOI 10.1016/j.bandl.2010.03.009
   Moos Anja, 2007, P 16 INT C PHON SCI, P677
   Murakami T, 2015, J NEUROSCI, V35, P1411, DOI 10.1523/JNEUROSCI.0246-14.2015
   Nachev P, 2008, NAT REV NEUROSCI, V9, P856, DOI 10.1038/nrn2478
   Oishi K, 2008, NEUROIMAGE, V43, P447, DOI 10.1016/j.neuroimage.2008.07.009
   PENFIELD W, 1951, AMA ARCH NEUROL PSY, V66, P289, DOI 10.1001/archneurpsyc.1951.02320090038004
   Picard N, 1996, CEREB CORTEX, V6, P342, DOI 10.1093/cercor/6.3.342
   Picard N, 2001, CURR OPIN NEUROBIOL, V11, P663, DOI 10.1016/S0959-4388(01)00266-5
   Restle J, 2012, NEUROPSYCHOLOGIA, V50, P2026, DOI 10.1016/j.neuropsychologia.2012.05.001
   Rodigari A, 2014, NEUROSCI LETT, V579, P30, DOI 10.1016/j.neulet.2014.07.012
   ROSS ED, 1981, ARCH NEUROL-CHICAGO, V38, P561, DOI 10.1001/archneur.1981.00510090055006
   Ross ED, 2008, BRAIN LANG, V104, P51, DOI 10.1016/j.bandl.2007.04.007
   Rossini PM, 2015, CLIN NEUROPHYSIOL, V126, P1071, DOI 10.1016/j.clinph.2015.02.001
   Saur D, 2010, NEUROIMAGE, V49, P3187, DOI 10.1016/j.neuroimage.2009.11.009
   Schwartze M, 2012, INT J PSYCHOPHYSIOL, V83, P200, DOI 10.1016/j.ijpsycho.2011.11.003
   Schwartze M, 2012, NEUROIMAGE, V60, P290, DOI 10.1016/j.neuroimage.2011.11.089
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Sharp DJ, 2010, P NATL ACAD SCI USA, V107, P6106, DOI 10.1073/pnas.1000175107
   Shima K, 1996, P NATL ACAD SCI USA, V93, P8694, DOI 10.1073/pnas.93.16.8694
   Simonyan K, 2011, NEUROSCIENTIST, V17, P197, DOI 10.1177/1073858410386727
   Smith MJ, 2002, ANN NEUROL, V51, P599, DOI 10.1002/ana.10180
   Swann NC, 2012, NEUROIMAGE, V59, P2860, DOI 10.1016/j.neuroimage.2011.09.049
   Tanaka K, 1997, CURR OPIN NEUROBIOL, V7, P523, DOI 10.1016/S0959-4388(97)80032-3
   Tanji J, 1996, CURR OPIN NEUROBIOL, V6, P782, DOI 10.1016/S0959-4388(96)80028-6
   Tremblay P, 2006, NEUROIMAGE, V33, P947, DOI 10.1016/j.neuroimage.2006.07.041
   Tremblay P, 2010, CORTEX, V46, P15, DOI 10.1016/j.cortex.2009.03.003
   TROUVAIN J, 2007, SAARLAND WORKING PAP, V1, P5
   Vagharchakian L, 2012, J NEUROSCI, V32, P9089, DOI 10.1523/JNEUROSCI.5685-11.2012
   Vergani F, 2014, J NEUROL NEUROSUR PS, V85, P1377, DOI 10.1136/jnnp-2013-307492
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1314, DOI 10.3758/BF03194545
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   ZEKI S, 1983, NEUROSCIENCE, V9, P741, DOI 10.1016/0306-4522(83)90265-8
   Zeki S, 2015, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00021
NR 68
TC 2
Z9 2
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD MAY 29
PY 2018
VL 12
AR 361
DI 10.3389/fnins.2018.00361
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA GH4JU
UT WOS:000433370600003
PM 29896086
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bennett, R
   Tang, K
   Sian, JA
AF Bennett, Ryan
   Tang, Kevin
   Sian, Juan Ajsivinac
TI Statistical and acoustic effects on the perception of stop consonants in
   Kaqchikel (Mayan)
SO LABORATORY PHONOLOGY
LA English
DT Article
DE contrast; discriminability; functional load; Exemplar Theory; Mayan
   languages; ejectives
ID LEXICAL DECISION DATA; WORD-FREQUENCY; FUNCTIONAL LOAD; CROSS-LANGUAGE;
   NASAL CONSONANTS; PHONETIC MEMORY; DISCRIMINATION; IDENTIFICATION;
   CATEGORIZATION; RECOGNITION
AB This paper investigates the relationship between speech perception and linguistic experience in Kaqchikel, a Guatemalan Mayan language. Our empirical focus is the perception of plain, ejective, and implosive stops. Drawing on an AX discrimination task, a corpus of spoken Kaqchikel, and a text corpus, we make two claims. First, we argue that speech perception is mediated by phonemic representations which include acoustic detail drawn from prior phonetic experience, as in Exemplar Theory. Second, segmental distributions also condition speech perception: The perceptual distinctiveness of a pair of phonemes is affected by their functional load and relative contextual predictability. These top-down factors influence phoneme discrimination even at relatively fast response times. We take this result as evidence that distributional factors like functional load may affect speech perception by shaping perceptual tuning during linguistic development. This study replicates and extends some key findings in speech perception in the context of a language (Kaqchikel) which is structurally and sociolinguistically different from the majority languages (like English) which have served as the basis of most work in the speech perception literature. At the practical level, our research illustrates methods for conducting corpus-based laboratory phonology with lesser-studied and under-resourced languages.
C1 [Bennett, Ryan] Univ Calif Santa Cruz, Dept Linguist, Santa Cruz, CA 95064 USA.
   [Tang, Kevin] Zhejiang Univ, Dept Linguist, Hangzhou 310058, Zhejiang, Peoples R China.
RP Tang, K (corresponding author), Zhejiang Univ, Dept Linguist, Hangzhou 310058, Zhejiang, Peoples R China.
EM linguist@kevintang.org
RI Tang, Kevin/O-5243-2019
OI Tang, Kevin/0000-0001-7382-9344; Bennett, Ryan/0000-0001-6160-7007
CR Atkins S., 1992, Literary & Linguistic Computing, V7, P1, DOI 10.1093/llc/7.1.1
   Baayen RH., 2008, ANAL LINGUISTIC DATA, DOI [10.1017/CBO9780511801686, DOI 10.1017/CBO9780511801686]
   Babel M, 2010, LAB PHONOLOGY, V1, P179, DOI DOI 10.1515/LABPHON.2010.009
   Baese-Berk M, 2009, LANG COGNITIVE PROC, V24, P527, DOI 10.1080/01690960802299378
   Barrett R., 1999, THESIS
   Benki JR, 2003, PHONETICA, V60, P129, DOI 10.1159/000071450
   Bennett R., 2013, CORPUS FONETIC UNPUB
   Bennett R., LARYNGEAL COOC UNPUB
   Bennett R, 2015, LAB PHON 15 C
   Bennett R, 2016, LANG LINGUIST COMPAS, V10, P469, DOI 10.1111/lnc3.12148
   Bennett R, 2016, LANG LINGUIST COMPAS, V10, P455, DOI 10.1111/lnc3.12159
   Bennett Ryan, 2010, UC SANTA CRUZ LINGUI, P93
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Biber Douglas, 1993, LIT LINGUISTIC COMPU, V8, P243, DOI [10.1093/llc/8.4.243, DOI 10.1093/LLC/8.4.243]
   Bladon A., 1986, LANGUAGE HEARERS, P1, DOI DOI 10.1093/LLC/8.4.243
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Boomershine A, 2008, PHONOL PHONET, V13, P145
   BROADBEN.DE, 1967, PSYCHOL REV, V74, P1, DOI 10.1037/h0024206
   Brody M, 2004, THESIS
   Browman Catherine, 1986, PHONOLOGY YB, V3, P219, DOI DOI 10.1017/S0952675700000658
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Browman CP., 1989, PHONOLOGY, V6, P201, DOI [10.1017/S0952675700001019, DOI 10.1017/S0952675700001019]
   BROWN CR, 1961, SCIENCE, V133, P280, DOI 10.1126/science.133.3448.280
   Brown R.M, 2010, UTZ AWACH INTRO KAQC
   Brysbaert M, 2013, BEHAV RES METHODS, V45, P422, DOI 10.3758/s13428-012-0270-5
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Bundgaard-Nielsen RL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142054
   Bundgaard-Nielsen RL, 2014, P 15 AUSTR INT SPEEC, P205
   Calamaro S, 2015, COGNITIVE SCI, V39, P647, DOI 10.1111/cogs.12167
   Campbell L., 1977, QUICHEAN LINGUISTIC, V81
   Chacach Cutzal M, 1990, LECT LINGUISTICA MAY, P145
   Chang S, 2001, ROLE SPEECH PERCEPTI, P79
   Cojti Macario Narciso, 1990, LECT LINGUISTICA MAY, P193
   Coon J, 2016, LANG LINGUIST COMPAS, V10, P515, DOI 10.1111/lnc3.12149
   COWAN N, 1986, J ACOUST SOC AM, V79, P500, DOI 10.1121/1.393537
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Cutler A, 2012, NATIVE LISTENING LAN
   Daelemans W., 2009, 0901 ILK
   Dar M, 2018, J PHONETICS, V67, P49, DOI 10.1016/j.wocn.2017.12.002
   Davidson DJ, 2013, ACTA PSYCHOL, V144, P83, DOI 10.1016/j.actpsy.2013.04.016
   Davidson L, 2007, J ACOUST SOC AM, V122, P3697, DOI 10.1121/1.2801548
   DiCanio C, 2014, J ACOUST SOC AM, V135, P884, DOI 10.1121/1.4861921
   DiCanio C, 2013, J ACOUST SOC AM, V134, P2235, DOI 10.1121/1.4816491
   Dockum R., 2017, MINIMUM SUFFICIENT W
   DUBNO JR, 1981, J ACOUST SOC AM, V69, P249, DOI 10.1121/1.385345
   DuBois John W, 1981, THESIS
   Dunbar E, 2010, PHONOLOGY, V27, P325, DOI 10.1017/S095267571000014X
   ElHattab H., 2016, REVEAL JS
   ENGLAND N, 1983, GRAMMAR MAM MAYAN LA
   England N., 1996, MAYA CULTURAL ACTIVI, P178, DOI [10.1525/aa.2003.105.4.733, DOI 10.1525/AA.2003.105.4.733]
   England NC, 2003, AM ANTHROPOL, V105, P733, DOI 10.1525/aa.2003.105.4.733
   England Nora C., 2001, INTRO GRAMATICA IDIO
   Ernestus M, 2014, LINGUA, V142, P27, DOI 10.1016/j.lingua.2012.12.006
   Felty RA, 2013, J ACOUST SOC AM, V134, P572, DOI 10.1121/1.4809540
   Ferrand L, 2010, BEHAV RES METHODS, V42, P488, DOI 10.3758/BRM.42.2.488
   Fischer Edward F., 1996, MAYA CULTURAL ACTIVI
   FOX RA, 1984, J EXP PSYCHOL HUMAN, V10, P526, DOI 10.1037/0096-1523.10.4.526
   Fre Woldu K, 1985, PERCEPTION PRODUCTIO, V13
   FUJIMURA O, 1978, LANG SPEECH, V21, P337, DOI 10.1177/002383097802100408
   Gahl S, 2006, LINGUIST REV, V23, P213, DOI 10.1515/TLR.2006.007
   Gallagher G, 2014, LAB PHONOL, V5, P337, DOI 10.1515/lp-2014-0012
   Gallagher G, 2012, LINGUA, V122, P112, DOI 10.1016/j.lingua.2011.11.012
   Gallagher G, 2011, LINGUIST REV, V28, P281, DOI 10.1515/tlir.2011.008
   Gallagher G, 2010, PHONOLOGY, V27, P435, DOI 10.1017/S0952675710000217
   Gallagher Gillian E. S., 2010, THESIS
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gasser Emily, 2014, P 2013 ANN M PHON, V1, DOI [10.3765/amp.v1i1.17, DOI 10.3765/AMP.V1I1.17]
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Goldrick M, 2013, J ACOUST SOC AM, V134, pEL172, DOI 10.1121/1.4812821
   Gorman K., 2011, CANADIAN ACOUSTICS, V39, P192
   Graff P. N. H. M., 2012, THESIS
   Hall K. C, MESSAGE SHAPES UNPUB
   Hall K. C., MODELING PERCE UNPUB
   Hall K. C., 2014, P 2015 ANN C CAN LIN, P1
   Hall K. C., 2012, MCGILL WORKING PAPER, V22, P1
   Hall K. C., 2015, PHONOLOGICAL CORPUST
   Hall KC, 2013, LINGUIST REV, V30, P215, DOI 10.1515/tlr-2013-0008
   Hall Kathleen Currie, 2009, THESIS
   Harnsberger JD, 2000, J ACOUST SOC AM, V108, P764, DOI 10.1121/1.429610
   Harnsberger JD, 2001, J PHONETICS, V29, P303, DOI 10.1006/jpho.2001.0140
   Harnsberger JD, 2001, J ACOUST SOC AM, V110, P489, DOI 10.1121/1.1371758
   Harris J., 1969, SPANISH PHONOLOGY
   Hayes B, 2008, LINGUIST INQ, V39, P379, DOI 10.1162/ling.2008.39.3.379
   Heitz RP, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00150
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P111, DOI 10.1017/S0140525X10000725
   Hockett Charles F., 1966, WORD, V23, P320, DOI [10.1080/00437956.1967.11435484., DOI 10.1080/00437956.1967.11435484]
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   HOWES D, 1957, J ACOUST SOC AM, V29, P296, DOI 10.1121/1.1908862
   Hyman Larry, 2015, UC BERKELEY PHONOLOG, P210
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Johnson PCD, 2014, METHODS ECOL EVOL, V5, P944, DOI 10.1111/2041-210X.12225
   Jun J., 2004, PHONETICALLY BASED P, P58, DOI [DOI 10.1017/CBO9780511486401.003, 10.1017/CBO9780511486401.003]
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kataoka R., 2007, U CALIFORNIA BERKELE, P273
   Kaufman T., 2003, PRELIMINARY MAYAN ET
   KAUFMAN TERRENCE, 1990, LECT LINGUISTICA MAY, P59, DOI DOI 10.1086/466206
   Keuleers E, 2012, BEHAV RES METHODS, V44, P287, DOI 10.3758/s13428-011-0118-4
   Keuleers E, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00174
   KING RD, 1967, LANGUAGE, V43, P831, DOI 10.2307/411969
   Kingston J, 1984, THESIS
   Kingston J., 2005, ATHABASKAN PROSODY, P137, DOI [DOI 10.1075/CILT.269.09KIN, 10.1075/cilt.269.09kin]
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Kingston J, 2005, PHONOL PHONET, V9, P177, DOI 10.1515/9783110197587.2.177
   Kucera H., 1963, ENTROPY REDUNDANCY F
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   LADEFOGED P, 2012, VOWELS CONSONANTS
   Larsen Thomas, 1988, THESIS
   LINDAU M, 1984, J PHONETICS, V12, P147, DOI 10.1016/S0095-4470(19)30861-7
   Lodge K., 2009, FUNDAMENTAL CONCEPTS, DOI [10.3366/edinburgh/9780748625659.001.0001, DOI 10.3366/EDINBURGH/9780748625659.001.0001]
   Macario Narciso Cojti, 1998, DICCIONARIO KAQCHIKE
   Macklin-Cordes J. L., 2015, P 6 C QUANT INV THER, DOI [10.15496/publikation-8609, DOI 10.15496/PUBLIKATION-8609]
   Macmillan N. A., 2004, DETECTION THEORY USE, DOI [10.4324/9781410611147, DOI 10.4324/9781410611147]
   Maddieson I., 2009, WORLD ATLAS LANGUAGE
   Maekawa K., 2003, SPONTANEOUS SPEECH P
   Majzul L. F. P., 2000, RUJUNAMAXIK RI KAQCH
   Majzul L. F. P., 2007, RUSOLTZIJ RI KAQCHIK
   Martinet A, 1952, WORD, V8, P1
   Matzar Garcia, 1999, GRAMATICA IDIOMA KAQ
   Maxwell J, 2010, KAQCHIKEL CHRONICLES
   McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1, P3, DOI DOI 10.1016/B978-1-4832-1446-7.50010-8
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McCloy D., 2014, PRAAT SEMIAUTO
   McGuire G, 2010, BRIEF PRIMER EXPT DE
   McGuire G. L., 2007, THESIS
   Meyer J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079279
   Mielke J, 2012, LINGUA, V122, P145, DOI 10.1016/j.lingua.2011.04.006
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Nelson NR, 2017, J PHONETICS, V64, P51, DOI 10.1016/j.wocn.2017.01.008
   Nevins A, GRACEFUL DEGRA UNPUB
   Nevins A, 2014, MEASURING SEGMENTAL, V2, P153
   Niyogi P, 2003, TECH REP
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Oh YM, 2013, INTERSPEECH, P3031
   Oh YM, 2015, J PHONETICS, V53, P153, DOI 10.1016/j.wocn.2015.08.003
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Peperkamp S, 2006, COGNITION, V101, pB31, DOI 10.1016/j.cognition.2005.10.006
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pinkerton S., 1986, EXPT PHONOLOGY, P125
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   PISONI DB, 1975, MEM COGNITION, V3, P7, DOI 10.3758/BF03198202
   PITT MA, 1993, J EXP PSYCHOL HUMAN, V19, P699, DOI 10.1037/0096-1523.19.4.699
   Port RF, 2005, LANGUAGE, V81, P927, DOI 10.1353/lan.2005.0195
   Quene H, 2010, SPEECH COMMUN, V52, P911, DOI 10.1016/j.specom.2010.03.005
   R Development Core Team, 2013, R LANG ENV STAT COMP
   Redford MA, 1999, J ACOUST SOC AM, V106, P1555, DOI 10.1121/1.427152
   Renwick M., 2014, PHONETICS PHONOLOGY, DOI [10.1515/9783110362770, DOI 10.1515/9783110362770]
   REPP BH, 1990, J ACOUST SOC AM, V88, P2080, DOI 10.1121/1.400105
   Richards M., 2003, ATLAS LINGUISTICO GU
   Rose S, 2007, LANG SPEECH, V50, P451, DOI 10.1177/00238309070500040101
   Russell S., 1997, THESIS
   Sakoe H., 1971, Proceedings of the 7th International congress on acoustics, P65
   Sebastian-Galles N, 2005, BLACKW HBK LINGUIST, P546, DOI 10.1002/9780470757024.ch22
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Silverman D, 2012, KEY TOP PHONOL, P1
   Silverman Daniel, 2006, CRITICAL INTRO PHONO
   Smits R, 2006, J EXP PSYCHOL HUMAN, V32, P733, DOI 10.1037/0096-1523.32.3.733
   Steriade D, 2009, CURR STUD LINGUIST, V47, P151
   Steriade Donca, 2001, ROLE SPEECH PERCEPTI, P219
   Stevenson S, 2017, GLOSSA-UK, V2, DOI 10.5334/gjgl.162
   Surendran D, 2006, AMST STUD THEORY HIS, V279, P43
   Sze WP, 2014, BEHAV RES METHODS, V46, P263, DOI 10.3758/s13428-013-0355-9
   Tang K, 2015, THESIS
   Tang K., CONTEXTUAL PRE UNPUB
   Tilsen S, 2016, J PHONETICS, V55, P53, DOI 10.1016/j.wocn.2015.11.005
   Tomlinson J., 2011, 33 ANN M COGN SCI SO, P3575
   Trubetzkoy N., 1969, PRINCIPLES PHONOLOGY
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521
   Vitevitch MS, 2016, ANNU REV LINGUIST, V2, P75, DOI 10.1146/annurev-linguistics-030514-124832
   Vitevitch MS, 2002, LANG SPEECH, V45, P407, DOI 10.1177/00238309020450040501
   WANG MD, 1973, J ACOUST SOC AM, V54, P1248, DOI 10.1121/1.1914417
   Wedel A, 2013, LANG SPEECH, V56, P395, DOI 10.1177/0023830913489096
   Wedel A, 2013, COGNITION, V128, P179, DOI 10.1016/j.cognition.2013.03.002
   Wedel Andrew, 2004, THESIS
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Whalen DH, 2015, ANNU REV LINGUIST, V1, P395, DOI 10.1146/annurev-linguist-030514-124915
   WRIGHT CE, 1979, MEM COGNITION, V7, P411, DOI 10.3758/BF03198257
   Wright R., 2002, J INT PHON ASSOC, V32, P43, DOI [DOI 10.1017/S0025100302000142, 10.1017/S0025100302000142]
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
   Xu Y, 2010, J PHONETICS, V38, P329, DOI 10.1016/j.wocn.2010.04.003
   Yao Yao, 2011, THESIS
   Yap MJ, 2015, J EXP PSYCHOL LEARN, V41, P597, DOI 10.1037/xlm0000064
   Yu ACL, 2011, PHONOLOGY, V28, P491, DOI 10.1017/S0952675711000236
   Zipf G. K., 1935, PSYCHOBIOLOGY LANGUA
NR 193
TC 2
Z9 2
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD MAY 25
PY 2018
VL 9
IS 1
AR 9
DI 10.5334/labphon.100
PG 42
WC Linguistics; Language & Linguistics
SC Linguistics
GA GQ2HW
UT WOS:000441475200002
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Rizza, A
   Terekhov, AV
   Montone, G
   Olivetti-Belardinelli, M
   O'Regan, JK
AF Rizza, Aurora
   Terekhov, Alexander V.
   Montone, Guglielmo
   Olivetti-Belardinelli, Marta
   O'Regan, J. Kevin
TI Why Early Tactile Speech Aids May Have Failed: No Perceptual Integration
   of Tactile and Auditory Signals
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE tactile aids; auditory-tactile binding; speech perception; sensory
   substitution; cue integration
ID HEARING; TOUCH; LOUDNESS; CHILDREN; CORTEX
AB Tactile speech aids, though extensively studied in the 1980's and 1990's, never became a commercial success. A hypothesis to explain this failure might be that it is difficult to obtain true perceptual integration of a tactile signal with information from auditory speech: exploitation of tactile cues from a tactile aid might require cognitive effort and so prevent speech understanding at the high rates typical of everyday speech. To test this hypothesis, we attempted to create true perceptual integration of tactile with auditory information in what might be considered the simplest situation encountered by a hearing-impaired listener. We created an auditory continuum between the syllables /BA/ and /VA/, and trained participants to associate /BA/ to one tactile stimulus and /VA/ to another tactile stimulus. After training, we tested if auditory discrimination along the continuum between the two syllables could be biased by incongruent tactile stimulation. We found that such a bias occurred only when the tactile stimulus was above, but not when it was below its previously measured tactile discrimination threshold. Such a pattern is compatible with the idea that the effect is due to a cognitive or decisional strategy, rather than to truly perceptual integration. We therefore ran a further study (Experiment 2), where we created a tactile version of the McGurk effect. We extensively trained two Subjects over 6 days to associate four recorded auditory syllables with four corresponding apparent motion tactile patterns. In a subsequent test, we presented stimulation that was either congruent or incongruent with the learnt association, and asked Subjects to report the syllable they perceived. We found no analog to the McGurk effect, suggesting that the tactile stimulation was not being perceptually integrated with the auditory syllable. These findings strengthen our hypothesis according to which tactile aids failed because integration of tactile cues with auditory speech occurred at a cognitive or decisional level, rather than truly at a perceptual level.
C1 [Rizza, Aurora; Olivetti-Belardinelli, Marta] Sapienza Univ Rome, Fac Med & Psychol, Dept Psychol, Rome, Italy.
   [Terekhov, Alexander V.; Montone, Guglielmo; O'Regan, J. Kevin] Univ Paris 05, Lab Psychol Percept, Paris, France.
   [Olivetti-Belardinelli, Marta] ECONA Interuniv Ctr Res Cognit Proc Nat & Artific, Rome, Italy.
RP Rizza, A (corresponding author), Sapienza Univ Rome, Fac Med & Psychol, Dept Psychol, Rome, Italy.
EM aurorarizza@gmail.com
FU ERCEuropean Research Council (ERC)European Commission [323674]; ERC
   Proof of Concept Grant FeelSpeech [692765]
FX This work was funded by the ERC Grant FEEL Number 323674 and ERC Proof
   of Concept Grant FeelSpeech Number 692765.
CR Alcantara J I, 1993, J Am Acad Audiol, V4, P98
   Alcorn S., 1932, VOLTA REV, V34, P195
   Caetano G, 2006, NEUROIMAGE, V29, P15, DOI 10.1016/j.neuroimage.2005.07.023
   Calabrese I., 1997, P 3 TRIENN ESCOM C G
   CARNEY AE, 1993, J ACOUST SOC AM, V94, P2036, DOI 10.1121/1.407477
   COWAN RSC, 1990, J ACOUST SOC AM, V88, P1374, DOI 10.1121/1.399715
   Darrow A. A, 1989, APPL RES MUSIC ED, V7, P10, DOI [10.1177/875512338900700205, DOI 10.1177/875512338900700205]
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   Foxe JJ, 2002, J NEUROPHYSIOL, V88, P540, DOI 10.1152/jn.2002.88.1.540
   Foxe JJ, 2009, CURR BIOL, V19, pR373, DOI 10.1016/j.cub.2009.03.029
   Galvin Karyn L., 2001, Australian and New Zealand Journal of Audiology, V23, P18, DOI 10.1375/audi.23.1.18.31095
   GESCHEIDER GA, 1970, IEEE T MAN MACHINE, VMM11, P28, DOI 10.1109/TMMS.1970.299958
   GESCHEIDGA, 1974, PERCEPT MOTOR SKILL, V38, P15, DOI DOI 10.2466/PMS.1974.38.1.15
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Gillmeister H, 2007, BRAIN RES, V1160, P58, DOI 10.1016/j.brainres.2007.03.041
   Huang Q, 2010, EUR ARCH OTO-RHINO-L, V267, P1179, DOI 10.1007/s00405-010-1270-7
   Jain A, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013295
   Jousmaki V, 1998, CURR BIOL, V8, pR190, DOI 10.1016/S0960-9822(98)70120-4
   Kassuba T, 2013, CEREB CORTEX, V23, P1097, DOI 10.1093/cercor/bhs076
   Massaro D. W., 1998, PERCEIVING TALKING F
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   Massaro D. W., 2004, HDB MULTISENSORY PRO, P153
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Nava E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099606
   Okazaki Ryuta, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P103, DOI 10.1007/978-3-642-31404-9_18
   Olivetti Belardinelli M, 2011, LOOKING EFFECTIVE AC
   OSBERGER MJ, 1991, AM J OTOL, V12, P105
   Ro T, 2009, EXP BRAIN RES, V195, P135, DOI 10.1007/s00221-009-1759-8
   Sarant J, 1996, J Am Acad Audiol, V7, P63
   Sato M, 2010, NEUROPSYCHOLOGIA, V48, P3683, DOI 10.1016/j.neuropsychologia.2010.08.017
   Schurmann M, 2004, J ACOUST SOC AM, V115, P830, DOI 10.1121/1.1639909
   Soto-Faraco S, 2004, COGN AFFECT BEHAV NE, V4, P208, DOI 10.3758/CABN.4.2.208
   Soto-Faraco S, 2009, BEHAV BRAIN RES, V196, P145, DOI 10.1016/j.bbr.2008.09.018
   Yarrow K, 2008, PERCEPTION, V37, P1114, DOI 10.1068/p5824
   Yau JM, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00160
   Yau JM, 2009, CURR BIOL, V19, P561, DOI 10.1016/j.cub.2009.02.013
NR 39
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAY 23
PY 2018
VL 9
AR 767
DI 10.3389/fpsyg.2018.00767
PG 12
WC Psychology, Multidisciplinary
SC Psychology
GA GG7EN
UT WOS:000432861400004
PM 29875719
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Sun, K
   Sanchez, GME
   De Coensel, B
   Van Renterghem, T
   Talsma, D
   Botteldooren, D
AF Sun, Kang
   Sanchez, Gemma M. Echevarria
   De Coensel, Bert
   Van Renterghem, Timothy
   Talsma, Durk
   Botteldooren, Dick
TI Personal Audiovisual Aptitude Influences the Interaction Between
   Landscape and Soundscape Appraisal
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE audiovisual interactions; landscape; soundscape; environmental
   perception; personal factor
ID VISUAL SPEECH-PERCEPTION; INDIVIDUAL-DIFFERENCES; INATTENTIONAL
   BLINDNESS; NOISE SENSITIVITY; LOAD; MEMORY; INTEGRATION; MODEL;
   ANNOYANCE; YOUNGER
AB It has been established that there is an interaction between audition and vision in the appraisal of our living environment, and that this appraisal is influenced by personal factors. Here, we test the hypothesis that audiovisual aptitude influences appraisal of our sonic and visual environment. To measure audiovisual aptitude, an auditory deviant detection experiment was conducted in an ecologically valid and complex context. This experiment allows us to distinguish between accurate and less accurate listeners. Additionally, it allows to distinguish between participants that are easily visually distracted and those who are not. To do so, two previously conducted laboratory experiments werere-analyzed. The first experiment focuses on self-reported noise annoyance in a living room context, whereas the second experiment focuses on the perceived pleasantness of using outdoor public spaces. In the first experiment, the influence of visibility of vegetation on self-reported noise annoyance was modified by audiovisual aptitude. In the second one, it was found that the overall appraisal of walking across a bridge is influenced by audiovisual aptitude, in particular when a visually intrusive noise barrier is used to reduce highway traffic noise levels. We conclude that audiovisual aptitude may affect the appraisal of the living environment.
C1 [Sun, Kang; Sanchez, Gemma M. Echevarria; De Coensel, Bert; Van Renterghem, Timothy; Botteldooren, Dick] Univ Ghent, Dept Informat Technol, Ghent, Belgium.
   [Talsma, Durk] Univ Ghent, Dept Expt Psychol, Ghent, Belgium.
RP Sun, K (corresponding author), Univ Ghent, Dept Informat Technol, Ghent, Belgium.
EM kang.sun@ugent.be
RI Botteldooren, Dick/P-1506-2019; De Coensel, Bert/C-2364-2008
OI Botteldooren, Dick/0000-0002-7756-7238; Sun, Kang/0000-0002-0338-0104;
   De Coensel, Bert/0000-0003-1815-6436
FU European Union under REA grant [290110]; Chinese Scholarship Council
   (CSC)China Scholarship Council
FX This study was supported by the People Programme Marie Curie Actions of
   the European Union's Seventh Framework Programme FP7/2007e2013/under REA
   grant agreement no. 290110, SONORUS "Urban Sound Planner". KS was funded
   by the Chinese Scholarship Council (CSC), the support of this
   organization is gratefully acknowledged.
CR Abbott LC, 2016, J PARK RECREAT ADM, V34, P5
   Apthorp D, 2013, J VISION, V13, DOI 10.1167/13.5.3
   Axelsson O, 2010, J ACOUST SOC AM, V128, P2836, DOI 10.1121/1.3493436
   Beaman CP, 2004, J EXP PSYCHOL LEARN, V30, P1106, DOI 10.1037/0278-7393.30.5.1106
   Bell R, 2008, PSYCHOL AGING, V23, P377, DOI 10.1037/0882-7974.23.2.377
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Botteldooren D, 2006, J SOUND VIB, V292, P105, DOI 10.1016/j.jsv.2005.07.026
   Botteldooren D., 2015, SOUNDSCAPE BUILT ENV, P17, DOI [10.1201/b19145-3, DOI 10.1201/B19145-3]
   Brown AL, 2012, INT J ACOUST VIB, V17, P73
   Cartwright-Finch U, 2007, COGNITION, V102, P321, DOI 10.1016/j.cognition.2006.01.002
   Cohena JI, 2017, J ACOUST SOC AM, V141, pEL470, DOI 10.1121/1.4983399
   COLAVITA FB, 1974, PERCEPT PSYCHOPHYS, V16, P409, DOI 10.3758/BF03203962
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   Cycowicz YM, 1998, BRAIN COGNITION, V36, P30, DOI 10.1006/brcg.1997.0955
   De Coensel B, 2009, J ACOUST SOC AM, V126, P656, DOI 10.1121/1.3158601
   Sanchez GME, 2017, LANDSCAPE URBAN PLAN, V167, P98, DOI 10.1016/j.landurbplan.2017.05.018
   Edwards B, 2016, EAR HEARING, V37, p85S, DOI 10.1097/AUD.0000000000000308
   Ellermeier W, 1997, J ACOUST SOC AM, V102, P2191, DOI 10.1121/1.419596
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Filipan K, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7010091
   Fougnie D, 2007, PSYCHON B REV, V14, P142, DOI 10.3758/BF03194041
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Giard MH, 1999, J COGNITIVE NEUROSCI, V11, P473, DOI 10.1162/089892999563544
   GIBSON JJ, 1963, AM J PSYCHOL, V76, P386, DOI 10.2307/1419779
   Graham ER, 2011, PSYCHOL AGING, V26, P162, DOI 10.1037/a0020647
   Heinonen-Guzejev M., 2009, THESIS
   International Organization for Standardization, 2014, 1291312014 ISO
   Jiang YH, 2001, Q J EXP PSYCHOL-A, V54, P1105, DOI 10.1080/02724980042000516
   Kahneman D., 1973, ATTENTION EFFORT, V1063
   Kaplan R., 1989, EXPERIENCE NATURE PS
   Kliuchko M, 2016, SCI REP-UK, V6, DOI 10.1038/srep39236
   Kondo HM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00170
   LAVIE N, 1995, J EXP PSYCHOL HUMAN, V21, P451, DOI 10.1037/0096-1523.21.3.451
   Lavie N, 2000, J EXP PSYCHOL HUMAN, V26, P1038, DOI 10.1037//0096-1523.26.3.1038
   Lavie N, 2009, J EXP PSYCHOL HUMAN, V35, P1346, DOI 10.1037/a0016454
   Leung TM, 2017, J ACOUST SOC AM, V141, P2399, DOI 10.1121/1.4979336
   Li HN, 2010, SCI TOTAL ENVIRON, V408, P4376, DOI 10.1016/j.scitotenv.2010.06.025
   Macdonald JSP, 2011, ATTEN PERCEPT PSYCHO, V73, P1780, DOI 10.3758/s13414-011-0144-4
   Mack A., 1998, INATTENTIONAL BLINDN
   Maffei L, 2013, SCI TOTAL ENVIRON, V445, P41, DOI 10.1016/j.scitotenv.2012.12.025
   Miedema HME, 2003, J ACOUST SOC AM, V113, P1492, DOI 10.1121/1.1547437
   Miller Z. D., 2018, INT J WILDERNESS, V2
   Miller Zachary D., 2014, Human Dimensions of Wildlife, V19, P498, DOI 10.1080/10871209.2014.921845
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   NEISSER U, 1975, COGNITIVE PSYCHOL, V7, P480, DOI 10.1016/0010-0285(75)90019-5
   O'Shea DM, 2015, PSYCHOL RES-PSYCH FO, V79, P570, DOI 10.1007/s00426-014-0594-0
   Pammer K, 2014, VIS COGN, V22, P1173, DOI 10.1080/13506285.2014.987859
   Payne SR, 2013, APPL ACOUST, V74, P255, DOI 10.1016/j.apacoust.2011.11.005
   Pilcher EJ, 2009, ENVIRON MANAGE, V43, P425, DOI 10.1007/s00267-008-9224-1
   Sandhu R, 2016, EXP BRAIN RES, V234, P1279, DOI 10.1007/s00221-015-4517-0
   Scialfa CT, 1998, EXP AGING RES, V24, P337
   Shepherd D, 2015, NOISE HEALTH, V17, P165, DOI 10.4103/1463-1741.155850
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Sorqvist P, 2014, PSYCH J, V3, P42, DOI 10.1002/pchj.47
   Sorqvist P, 2010, J ENVIRON PSYCHOL, V30, P112, DOI 10.1016/j.jenvp.2009.11.004
   Stansfeld S.A, 1992, PSYCHOL MED        S, V22S, P1, DOI DOI 10.1017/S0264180100001119
   Sun K, 2018, APPL ACOUST, V134, P16, DOI 10.1016/j.apacoust.2018.01.001
   van den Brink RL, 2014, CEREB CORTEX, V24, P2169, DOI 10.1093/cercor/bht069
   Van Renterghem T, 2016, LANDSCAPE URBAN PLAN, V148, P203, DOI 10.1016/j.landurbplan.2015.12.018
   Wada Y, 2003, INT J PSYCHOPHYSIOL, V50, P117, DOI 10.1016/S0167-8760(03)00128-4
   WEINSTEIN ND, 1978, J APPL PSYCHOL, V63, P458, DOI 10.1037/0021-9010.63.4.458
   Weinzimmer D, 2014, LEISURE SCI, V36, P251, DOI 10.1080/01490400.2014.888022
   World Med Assoc, 2013, JAMA-J AM MED ASSOC, V310, P2191, DOI 10.1001/jama.2013.281053
   Zhang BJ, 2003, APPL ACOUST, V64, P1205, DOI 10.1016/S0003-682X(03)00074-4
NR 66
TC 9
Z9 9
U1 0
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAY 22
PY 2018
VL 9
AR 780
DI 10.3389/fpsyg.2018.00780
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA GG5CP
UT WOS:000432713100003
PM 29910750
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Havenhill, J
   Do, Y
AF Havenhill, Jonathan
   Do, Youngah
TI Visual Speech Perception Cues Constrain Patterns of Articulatory
   Variation and Sound Change
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE audiovisual speech perception; sound change; articulatory variation;
   ultrasound tongue imaging; misperception; Northern Cities Vowel Shift
ID CONGENITALLY BLIND ADULTS; FRENCH VOWELS; TONGUE; SHAPE; LIPS
AB What are the factors that contribute to (or inhibit) diachronic sound change? While acoustically motivated sound changes are well-documented, research on the articulatory and audiovisual-perceptual aspects of sound change is limited. This paper investigates the interaction of articulatory variation and audiovisual speech perception in the Northern Cities Vowel Shift (NCVS), a pattern of sound change observed in the Great Lakes region of the United States. We focus specifically on the maintenance of the contrast between the vowels /alpha/ and /(sic)/, both of which are fronted as a result of the NCVS. We present results from two experiments designed to test how the NCVS is produced and perceived. In the first experiment, we present data from an articulatory and acoustic analysis of the production of fronted /alpha/ and /(sic)/. We find that some speakers distinguish /(sic)/ from /alpha/ with a combination of both tongue position and lip rounding, while others do so using either tongue position or lip rounding alone. For speakers who distinguish /(sic)/ from /alpha/ along only one articulatory dimension /alpha/ and /(sic)/ are acoustically more similar than for speakers who produce multiple articulatory distinctions. While all three groups of speakers maintain some degree of acoustic contrast between the vowels, the question is raised as to whether these articulatory strategies differ in their perceptibility. In the perception experiment, we test the hypothesis that visual speech cues play a role in maintaining contrast between the two sounds. The results of this experiment suggest that articulatory configurations in which /(sic)/ is produced with unround lips are perceptually weaker than those in which /(sic)/ is produced with rounding, even though these configurations result in acoustically similar output. We argue that these findings have implications for theories of sound change and variation in at least two respects: (1) visual cues can shape phonological systems through misperception-based sound change, and (2) phonological systems may be optimized not only for auditory but also for visual perceptibility.
C1 [Havenhill, Jonathan] Georgetown Univ, Dept Linguist, Washington, DC 20057 USA.
   [Do, Youngah] Univ Hong Kong, Dept Linguist, Hong Kong, Hong Kong, Peoples R China.
RP Havenhill, J (corresponding author), Georgetown Univ, Dept Linguist, Washington, DC 20057 USA.; Do, Y (corresponding author), Univ Hong Kong, Dept Linguist, Hong Kong, Hong Kong, Peoples R China.
EM jeh241@georgetown.edu; youngah@hku.hk
OI Havenhill, Jonathan/0000-0002-6829-8371; Do, Youngah/0000-0003-1926-2230
CR Baker A., 2006, MWAV 35 COL OH
   Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   Bakst S., 2015, P 18 INT C PHON SCI
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Blevins J, 2006, THEOR LINGUIST, V32, P117, DOI 10.1515/TL.2006.009
   Blevins Juliette, 2004, EVOLUTIONARY PHONOLO
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Braida L. D., 1998, P AVSP 98 INT C AUD
   Brunner J, 2009, J ACOUST SOC AM, V125, P3936, DOI 10.1121/1.3125313
   Chen YS, 2011, ADV MATER RES-SWITZ, V338, P124, DOI 10.4028/www.scientific.net/AMR.338.124
   Davidson L, 2006, J ACOUST SOC AM, V120, P407, DOI 10.1121/1.2205133
   De Decker PM, 2012, LINGUA, V122, P810, DOI 10.1016/j.lingua.2012.01.003
   DELATTRE P, 1968, LINGUISTICS, P29
   Di Canio C., 2013, VISUALIZING VOWEL SP
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Dinkin A., 2009, THESIS
   Driscoll A., 2015, U PENNSYLVANIA WORKI, V21, P6
   Espy-Wilson C. Y., 1987, TECHNICAL REPORT
   Espy-Wilson C. Y., 2004, P SOUND SENS 50 YEAR, pB62
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   Friedman Lauren, 2014, THESIS
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Gluth C., 2015, P 18 INT C PHON SCI, P1
   Grammont M., 1939, TRAITE DE PHONETIQUE
   Gu C, 2002, SPR S STAT
   Gu C, 2014, J STAT SOFTW, V58, P1, DOI 10.18637/jss.v058.i05
   Guion SG, 1998, PHONETICA, V55, P18
   Hagiwara RE, 1995, UCLA WORKING PAPERS, V90
   Hale M., 2008, PHONOLOGICAL ENTERPR
   Hall-Lew L., 2010, J ACOUST SOC AM, V127, P2020, DOI [10.1121/1.3385271, DOI 10.1121/1.3385271]
   Harrington J, 2011, J INT PHON ASSOC, V41, P137, DOI 10.1017/S0025100310000265
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Hayes B., 2004, PHONETICALLY BASED P
   Johnson K., 2015, UC BERKELEY PHONOLOG, P227
   Johnson K., 2007, UC BERKELEY PHONOLOG
   Kendall T., 2014, VOWELS VOWEL MANIPUL
   KRAKOW RA, 1988, J ACOUST SOC AM, V83, P1146, DOI 10.1121/1.396059
   Kricos P. B., 1996, SPEECHREADING HUMANS, P43
   Labov William, 2006, ATLAS N AM ENGLISH
   Labov William, 1994, PRINCIPLES LINGUISTI
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lee-Kim SI, 2014, PHONETICA, V71, P50, DOI 10.1159/000362672
   Lee-Kim SI, 2013, LAB PHONOL, V4, P475, DOI 10.1515/lp-2013-0015
   Li M, 2005, CLIN LINGUIST PHONET, V19, P545, DOI 10.1080/02699200500113616
   LINDAU M, 1978, LANGUAGE, V54, P541, DOI 10.2307/412786
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   Linker Wendy, 1982, THESIS
   Majors T., 2008, U PENNSYLVANIA WORKI, V14, P111
   Mayer Connor, 2013, Can Acoust, V41, P23
   McCarthy C., 2010, U PENNSYLVANIA WORKI, V15, P12
   McGuire G., 2012, LAB PHONOLOGY, V3, P1, DOI [10.1515/lp-2012-0014, DOI 10.1515/LP-2012-0014]
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Menard L., 2015, P 18 INT C PHON SCI
   Menard L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160088
   Menard L, 2013, J ACOUST SOC AM, V134, P2975, DOI 10.1121/1.4818740
   Menard L, 2009, J ACOUST SOC AM, V126, P1406, DOI 10.1121/1.3158930
   Mielke J., 2010, LAB PHONOLOGY, V10, P699, DOI DOI 10.1017/S0954394511000135
   Mielke J., 2013, TONGUE SSANOVAR R SC
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Nolan F, 1977, J PHONETICS, V5, P185
   Nycz J., 2006, NWAV 35 COL OH
   Nycz Jennifer, 2014, P M AC, V20, DOI [DOI 10.1121/1.4894063, 10.1121/1.4894063]
   Ohala J., 1983, PRODUCTION SPEECH, P189, DOI [DOI 10.1007/978-1-4613-8202-7_9, 10.1007/978-1-4613-8202-7_9]
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Ohala John J., 1989, LANGUAGE CHANGE CONT, P173, DOI DOI 10.1515/9783110853063
   PERKELL JS, 1993, J ACOUST SOC AM, V93, P2948, DOI 10.1121/1.405814
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Plichta B., 2004, THESIS
   R Core Team, 2016, R LANG ENV STAT COMP
   Stevens Kenneth N., 2000, ACOUSTIC PHONETICS
   STONE M, 1988, J ACOUST SOC AM, V83, P1586, DOI 10.1121/1.395913
   STONE M, 1995, J PHONETICS, V23, P81, DOI 10.1016/S0095-4470(95)80034-4
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Traunmuller H., 2007, P 16 INT C PHON SCI, P721
   Traunmuller H, 2007, J PHONETICS, V35, P244, DOI 10.1016/j.wocn.2006.03.002
   Twist A., 2007, U PENNSYLVANIA WORKI, V13, P207
   Uldall E., 1958, REV LABORATORIO FONE, V4, P103
   Vennemann Theo, 1988, PREFERENCE LAWS SYLL
   Wagner S.E., 2016, U PENNSYLVANIA WORKI, V22
   Weinreich U., 1968, DIRECTIONS HIST LING, P95
   Westbury J, 1995, P 13 INT C PHON SCI, V4, P50
   Zhou XH, 2008, J ACOUST SOC AM, V123, P4466, DOI 10.1121/1.2902168
NR 85
TC 2
Z9 2
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAY 15
PY 2018
VL 9
AR 728
DI 10.3389/fpsyg.2018.00728
PG 17
WC Psychology, Multidisciplinary
SC Psychology
GA GG3FO
UT WOS:000432577900002
PM 29867686
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Keetels, M
   Bonte, M
   Vroomen, J
AF Keetels, Mirjam
   Bonte, Milene
   Vroomen, Jean
TI A Selective Deficit in Phonetic Recalibration by Text in Developmental
   Dyslexia
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE phonetic recalibration; orthographic information; dyslexia; letters;
   speech perception
ID AUDITORY-VISUAL SPEECH; MULTISENSORY INTEGRATION; PHONOLOGICAL DEFICITS;
   LIPREAD SPEECH; PERCEPTION; SOUNDS; ADAPTATION; DISABILITIES; CONTEXT;
   WRITTEN
AB Upon hearing an ambiguous speech sound, listeners may adjust their perceptual interpretation of the speech input in accordance with contextual information, like accompanying text or lipread speech (i.e., phonetic recalibration; Bertelson et al., 2003). As developmental dyslexia (DD) has been associated with reduced integration of text and speech sounds, we investigated whether this deficit becomes manifest when text is used to induce this type of audiovisual learning. Adults with DD and normal readers were exposed to ambiguous consonants halfway between /aba/ and /ada/ together with text or lipread speech. After this audiovisual exposure phase, they categorized auditory-only ambiguous test sounds. Results showed that individuals with DD, unlike normal readers, did not use text to recalibrate their phoneme categories, whereas their recalibration by lipread speech was spared. Individuals with DD demonstrated similar deficits when ambiguous vowels (halfway between /wIt/ and /wet/) were recalibrated by text. These findings indicate that DD is related to a specific letter-speech sound association deficit that extends over phoneme classes (vowels and consonants), but - as lipreading was spared - does not extend to a more general audio-visual integration deficit. In particular, these results highlight diminished reading-related audiovisual learning in addition to the commonly reported phonological problems in developmental dyslexia.
C1 [Keetels, Mirjam; Vroomen, Jean] Tilburg Univ, Dept Cognit Neuropsychol, Cognit Neuropsychol Lab, Tilburg, Netherlands.
   [Bonte, Milene] Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, Maastricht Brain Imaging Ctr, Maastricht, Netherlands.
RP Keetels, M (corresponding author), Tilburg Univ, Dept Cognit Neuropsychol, Cognit Neuropsychol Lab, Tilburg, Netherlands.
EM M.N.Keetels@uvt.nl
RI Vroomen, Jean/K-1033-2013
OI Vroomen, Jean/0000-0001-5923-5988; Keetels, Mirjam/0000-0002-1554-9229
FU NWO-VIDINetherlands Organization for Scientific Research (NWO)
   [452-16-004]
FX MB was supported by NWO-VIDI Grant 452-16-004.
CR Baart M, 2012, ACTA PSYCHOL, V140, P91, DOI 10.1016/j.actpsy.2012.03.003
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Blomert L, 2004, J SPEECH LANG HEAR R, V47, P1030, DOI 10.1044/1092-4388(2004/077)
   Blomert L, 2011, NEUROIMAGE, V57, P695, DOI 10.1016/j.neuroimage.2010.11.003
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3
   Brus B. T., 1997, EEN MINUUT TEST
   de Gelder B, 1998, BRAIN LANG, V64, P269, DOI 10.1006/brln.1998.1973
   DEGELDER B, 1991, PSYCHOL RES-PSYCH FO, V53, P88, DOI 10.1007/BF00867336
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Francisco AA, 2017, LEARN INDIVID DIFFER, V54, P60, DOI 10.1016/j.lindif.2017.01.003
   Froyen D, 2008, NEUROSCI LETT, V430, P23, DOI 10.1016/j.neulet.2007.10.014
   Froyen D, 2011, DEVELOPMENTAL SCI, V14, P635, DOI 10.1111/j.1467-7687.2010.01007.x
   Froyen DJW, 2009, J COGNITIVE NEUROSCI, V21, P567, DOI 10.1162/jocn.2009.21061
   Gonzalez GF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143914
   Hahn N, 2014, NEUROSCI BIOBEHAV R, V47, P384, DOI 10.1016/j.neubiorev.2014.09.007
   Harrar V, 2014, CURR BIOL, V24, P531, DOI 10.1016/j.cub.2014.01.029
   Hayes EA, 2003, NEUROSCI LETT, V351, P46, DOI 10.1016/S0304-3940(03)00971-6
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Keetels M, 2016, ATTEN PERCEPT PSYCHO, V78, P938, DOI 10.3758/s13414-015-1034-y
   Keetels M, 2015, COGNITION, V141, P121, DOI 10.1016/j.cognition.2015.04.019
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kronschnabel J, 2014, NEUROPSYCHOLOGIA, V62, P245, DOI 10.1016/j.neuropsychologia.2014.07.024
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   LIBERMAN AM, 1992, ORTHOGRAPHY PHONOLOG, P167, DOI DOI 10.1016/S0166-4115(08)62794-6
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   McNorgan C, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00388
   Mittag M, 2013, CLIN NEUROPHYSIOL, V124, P315, DOI 10.1016/j.clinph.2012.08.003
   Mitterer H, 2015, J MEM LANG, V85, P116, DOI 10.1016/j.jml.2015.08.005
   Moll K, 2016, CLIN NEUROPHYSIOL, V127, P1989, DOI 10.1016/j.clinph.2016.01.005
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Nash HM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12423
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Ramirez J, 2005, J ACOUST SOC AM, V118, P1122, DOI 10.1121/1.1940509
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   Samuel AG, 2014, J EXP PSYCHOL HUMAN, V40, P1479, DOI 10.1037/a0036656
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Snowling M., 2000, DYSLEXIA
   Snowling M.J., 1995, J RES READ, V18, P132, DOI [10.1111/j.1467-9817.1995.tb00079.x, DOI 10.1111/J.1467-9817.1995.TB00079.X]
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Stekelenburg JJ, 2018, EUR J NEUROSCI, V47, P1135, DOI 10.1111/ejn.13908
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Taroyan NA, 2009, INT J PSYCHOPHYSIOL, V74, P199, DOI 10.1016/j.ijpsycho.2009.09.001
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   Van den Bos KP, 1999, KLEPEL PSEUDOWOORDEN
   van Laarhoven T, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12504
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J, 2004, COGNITIVE BRAIN RES, V22, P32, DOI 10.1016/j.cogbrainres.2004.07.003
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Widmann Andreas, 2012, Front Psychol, V3, P60, DOI 10.3389/fpsyg.2012.00060
   Widmann A, 2014, J NEUROSCI, V34, P11152, DOI 10.1523/JNEUROSCI.1568-14.2014
   YAP R, 1993, READ WRIT, V5, P261, DOI 10.1007/BF01027391
   Zaric G, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00369
   Zaric G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110337
NR 60
TC 3
Z9 3
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAY 15
PY 2018
VL 9
AR 710
DI 10.3389/fpsyg.2018.00710
PG 11
WC Psychology, Multidisciplinary
SC Psychology
GA GG3FD
UT WOS:000432576700001
PM 29867675
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Brodbeck, C
   Presacco, A
   Simon, JZ
AF Brodbeck, Christian
   Presacco, Alessandro
   Simon, Jonathan Z.
TI Neural source dynamics of brain responses to continuous stimuli: Speech
   processing from acoustics to comprehension
SO NEUROIMAGE
LA English
DT Article
DE Magnetoencephalography; Minimum norm estimate; Speech representation;
   Impulse response; Temporal response function; Reverse correlation
ID AUDITORY WORD RECOGNITION; CORTICAL REPRESENTATION; MOTOR CORTEX;
   TIME-COURSE; EEG-DATA; MEG; FREQUENCY; LANGUAGE; LOCALIZATION;
   RESOLUTION
AB Human experience often involves continuous sensory information that unfolds over time. This is true in particular for speech comprehension, where continuous acoustic signals are processed over seconds or even minutes. We show that brain responses to such continuous stimuli can be investigated in detail, for magnetoencephalography (MEG) data, by combining linear kernel estimation with minimum norm source localization. Previous research has shown that the requirement to average data over many trials can be overcome by modeling the brain response as a linear convolution of the stimulus and a kernel, or response function, and estimating a kernel that predicts the response from the stimulus. However, such analysis has been typically restricted to sensor space. Here we demonstrate that this analysis can also be performed in neural source space. We first computed distributed minimum norm current source estimates for continuous MEG recordings, and then computed response functions for the current estimate at each source element, using the boosting algorithm with cross-validation. Permutation tests can then assess the significance of individual predictor variables, as well as features of the corresponding spatio-temporal response functions. We demonstrate the viability of this technique by computing spatio-temporal response functions for speech stimuli, using predictor variables reflecting acoustic, lexical and semantic processing. Results indicate that processes related to comprehension of continuous speech can be differentiated anatomically as well as temporally: acoustic information engaged auditory cortex at short latencies, followed by responses over the central sulcus and inferior frontal gyrus, possibly related to somatosensory/motor cortex involvement in speech perception; lexical frequency was associated with a left-lateralized response in auditory cortex and subsequent bilateral frontal activity; and semantic composition was associated with bilateral temporal and frontal brain activity. We conclude that this technique can be used to study the neural processing of continuous stimuli in time and anatomical space with the millisecond temporal resolution of MEG. This suggests new avenues for analyzing neural processing of naturalistic stimuli, without the necessity of averaging over artificially short or truncated stimuli.
C1 [Brodbeck, Christian; Simon, Jonathan Z.] Univ Maryland, Syst Res Inst, College Pk, MD 20742 USA.
   [Presacco, Alessandro] Univ Calif Irvine, Dept Otolaryngol, Irvine, CA USA.
   [Simon, Jonathan Z.] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
   [Simon, Jonathan Z.] Univ Maryland, Dept Biol, College Pk, MD 20742 USA.
RP Brodbeck, C (corresponding author), Univ Maryland, Syst Res Inst, College Pk, MD 20742 USA.
EM brodbeck@umd.edu
RI Brodbeck, Christian/R-2207-2019; Simon, Jonathan Z/A-8196-2008
OI Brodbeck, Christian/0000-0001-8380-639X; Simon, Jonathan
   Z/0000-0003-0858-0698
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01-DC-014085];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [T32DC000046, T32DC000046, R01DC014085,
   R01DC014085, T32DC000046, T32DC000046, R01DC014085, T32DC000046,
   R01DC014085, T32DC000046, R01DC014085, T32DC000046] Funding Source: NIH
   RePORTER
FX This work was supported by the National Institutes of Health [grant
   number R01-DC-014085].
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Akram S, 2017, IEEE T BIO-MED ENG, V64, P1896, DOI 10.1109/TBME.2016.2628884
   Baayen RH, 2016, APHASIOLOGY, V30, P1174, DOI 10.1080/02687038.2016.1147767
   Bemis DK, 2013, CEREB CORTEX, V23, P1859, DOI 10.1093/cercor/bhs170
   Bemis DK, 2011, J NEUROSCI, V31, P2801, DOI 10.1523/JNEUROSCI.5003-10.2011
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brennan J, 2016, LANG LINGUIST COMPAS, V10, P299, DOI 10.1111/lnc3.12198
   Brennan J, 2012, BRAIN LANG, V120, P163, DOI 10.1016/j.bandl.2010.04.002
   Brennan JR, 2016, BRAIN LANG, V157, P81, DOI 10.1016/j.bandl.2016.04.008
   Brodbeck C., 2017, EELBRAIN 0 25, DOI [10.5281/zenodo.438193, DOI 10.5281/ZENODO.438193]
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Chow HM, 2014, J COGNITIVE NEUROSCI, V26, P279, DOI 10.1162/jocn_a_00487
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   CONNINE CM, 1990, J EXP PSYCHOL LEARN, V16, P1084, DOI 10.1037/0278-7393.16.6.1084
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1
   DALE AM, 1993, J COGNITIVE NEUROSCI, V5, P162, DOI 10.1162/jocn.1993.5.2.162
   David SV, 2007, NETWORK-COMP NEURAL, V18, P191, DOI 10.1080/09548980701609235
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Dufour S, 2013, COGNITIVE SCI, V37, P489, DOI 10.1111/cogs.12015
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gaskell M. G., 2016, SPEECH PERCEPTION AN
   Gazzaniga M. S., 2009, COGNITIVE NEUROSCIEN
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027
   Greve DN, 2013, J COGNITIVE NEUROSCI, V25, P1477, DOI 10.1162/jocn_a_00405
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476
   Hauk O, 2011, NEUROIMAGE, V54, P1966, DOI 10.1016/j.neuroimage.2010.09.053
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Lalor EC, 2006, NEUROIMAGE, V32, P1549, DOI 10.1016/j.neuroimage.2006.05.054
   Lalor EC, 2010, EUR J NEUROSCI, V31, P189, DOI 10.1111/j.1460-9568.2009.07055.x
   Lalor EC, 2009, J NEUROPHYSIOL, V102, P349, DOI 10.1152/jn.90896.2008
   Lin FH, 2006, NEUROIMAGE, V31, P160, DOI 10.1016/j.neuroimage.2005.11.054
   Mairal J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Meunier F, 1999, J MEM LANG, V41, P327, DOI 10.1006/jmla.1999.2642
   Nakamura A, 1998, NEUROIMAGE, V7, P377, DOI 10.1006/nimg.1998.0332
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Nourski KV, 2014, NEUROIMAGE, V101, P598, DOI 10.1016/j.neuroimage.2014.07.004
   Nourski KV, 2009, J NEUROSCI, V29, P15564, DOI 10.1523/JNEUROSCI.3065-09.2009
   Ochshorn R. M., 2016, GENTLE COMPUTER PROG
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Overath T, 2015, NAT NEUROSCI, V18, P903, DOI 10.1038/nn.4021
   Pallier C, 2011, P NATL ACAD SCI USA, V108, P2522, DOI 10.1073/pnas.1018711108
   Parkkonen L, 2009, HUM BRAIN MAPP, V30, P1772, DOI 10.1002/hbm.20788
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2356, DOI 10.1152/jn.00373.2016
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Ringach D, 2004, COGNITIVE SCI, V28, P147, DOI 10.1016/j.cogsci.2003.11.003
   Rogalsky C, 2011, NEUROCASE, V17, P178, DOI 10.1080/13554794.2010.509318
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schomers MR, 2015, CEREB CORTEX, V25, P3894, DOI 10.1093/cercor/bhu274
   Skipper J. I., 2017, BIORXIV, DOI [10.1101/139550, DOI 10.1101/139550]
   Smith SM, 2009, NEUROIMAGE, V44, P83, DOI 10.1016/j.neuroimage.2008.03.061
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   Thirion B, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00167
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Westerlund M, 2015, BRAIN LANG, V141, P124, DOI 10.1016/j.bandl.2014.12.003
   Willems RM, 2016, CEREB CORTEX, V26, P2506, DOI 10.1093/cercor/bhv075
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   YANG XW, 1992, IEEE T INFORM THEORY, V38, P824, DOI 10.1109/18.119739
NR 71
TC 23
Z9 23
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD MAY 15
PY 2018
VL 172
BP 162
EP 174
DI 10.1016/j.neuroimage.2018.01.042
PG 13
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GD2WK
UT WOS:000430364100014
PM 29366698
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Zhang, J
   Meng, YX
   McBride, C
   Fan, XT
   Yuan, Z
AF Zhang, Juan
   Meng, Yaxuan
   McBride, Catherine
   Fan, Xitao
   Yuan, Zhen
TI Combining Behavioral and ERP Methodologies to Investigate the
   Differences Between McGurk Effects Demonstrated by Cantonese and
   Mandarin Speakers
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE audiovisual speech perception; Cantonese; Mandarin; McGurk effect;
   mismatch negativity
ID MISMATCH NEGATIVITY MMN; CHINESE SPEECH RECOGNITION; VISUAL INFORMATION;
   SEEING VOICES; PERCEPTION; FREQUENCIES; LANGUAGE; TONES
AB The present study investigated the impact of Chinese dialects on McGurk effect using behavioral and event-related potential (ERP) methodologies. Specifically, intra-language comparison of McGurk effect was conducted between Mandarin and Cantonese speakers. The behavioral results showed that Cantonese speakers exhibited a stronger McGurk effect in audiovisual speech perception compared to Mandarin speakers, although both groups performed equally in the auditory and visual conditions. ERP results revealed that Cantonese speakers were more sensitive to visual cues than Mandarin speakers, though this was not the case for the auditory cues. Taken together, the current findings suggest that the McGurk effect generated by Chinese speakers is mainly influenced by segmental phonology during audiovisual speech integration.
C1 [Zhang, Juan; Meng, Yaxuan] Univ Macau, Fac Educ, Macau, Peoples R China.
   [McBride, Catherine] Chinese Univ Hong Kong, Dept Psychol, Shatin, Hong Kong, Peoples R China.
   [Fan, Xitao] Chinese Univ Hong Kong, Sch Humanities & Social Sci, Shenzhen, Shenzhen, Peoples R China.
   [Yuan, Zhen] Univ Macau, Fac Hlth Sci, Macau, Peoples R China.
RP Meng, YX (corresponding author), Univ Macau, Fac Educ, Macau, Peoples R China.
EM yb57105@umac.mo
RI , 镜海真人（袁振）/ABG-2380-2020; Yuan, zhen/ABG-3111-2020
FU University of Macau in Macau [MYRG2017-00217-FED, MYRG2016-00193-FED,
   MYRG2015-00221-FED, MYRG2014-00093-FHS, MYRG 2015-00036-FHS]; Macau
   government [FDCT 026/2014/A1, FDCT 025/2015/A1]
FX This study was supported by MYRG2017-00217-FED, MYRG2016-00193-FED,
   MYRG2015-00221-FED, MYRG2014-00093-FHS, and MYRG 2015-00036-FHS grants
   from the University of Macau in Macau, FDCT 026/2014/A1 and FDCT
   025/2015/A1 grants from the Macau government.
CR Bauer R. S., 1997, TRENDS LINGUISTICS S, DOI [10.1515/9783110823707, DOI 10.1515/9783110823707]
   Burnham D., 2001, CHANCE, V1, P16
   Burnham D., 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI [10.1017/S0142716414000496, DOI 10.1017/S0142716414000496]
   Burnham D, 2006, P 7 INT SEM SPEECH P
   Chan Alice Y. W., 2000, LANG CULT CURRIC, V13, P67, DOI DOI 10.1080/07908310008666590
   Chen LM, 2010, J CHILD LANG, V37, P341, DOI 10.1017/S0305000909009581
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   Czigler I, 2007, J PSYCHOPHYSIOL, V21, P224, DOI 10.1027/0269-8803.21.34.224
   Fisher DJ, 2010, BRAIN RES, V1313, P162, DOI 10.1016/j.brainres.2009.12.002
   Flynn M, 2009, EXP BRAIN RES, V197, P153, DOI 10.1007/s00221-009-1901-7
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gao S, 2000, INT CONF ACOUST SPEE, P1261
   Hayashi Y., 1998, P INT C AUD VIS SPEE
   Hume E., 2001, OHIO STATE U WORKING, V55, P1
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   Kreegipuu K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00714
   Lansing CR, 1999, J SPEECH LANG HEAR R, V42, P526, DOI 10.1044/jslhr.4203.526
   Lee T, 2002, SPEECH COMMUN, V36, P327, DOI 10.1016/S0167-6393(00)00101-1
   LEE T, 1995, IEEE T SPEECH AUDI P, V3, P204, DOI 10.1109/89.388147
   Lee T, 2006, ADVANCES IN CHINESE SPOKEN LANGUAGE PROCESSING, P179, DOI 10.1142/9789812772961_0008
   Leung MT, 2004, BEHAV RES METH INS C, V36, P500, DOI 10.3758/BF03195596
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MASSARO DW, 1989, COGNITIVE PSYCHOL, V21, P398, DOI 10.1016/0010-0285(89)90014-5
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x
   Naatanen R., 1995, Brain Topography, V7, P315, DOI 10.1007/BF01195257
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Pitcher D, 2007, CURR BIOL, V17, P1568, DOI 10.1016/j.cub.2007.07.063
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   Sekiyama K., 2003, P AVSP 2003 INT C AU
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Shu H, 2006, J EDUC PSYCHOL, V98, P122, DOI 10.1037/0022-0663.98.1.122
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tamaoka K, 2009, LANG SPEECH, V52, P79, DOI 10.1177/0023830908099884
   Tsang YK, 2011, NEUROSCI LETT, V487, P268, DOI 10.1016/j.neulet.2010.10.035
   Tsuhan Chen, 2001, IEEE Signal Processing Magazine, V18, P9, DOI 10.1109/79.911195
   Yao DZ, 2001, PHYSIOL MEAS, V22, P693, DOI 10.1088/0967-3334/22/4/305
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
NR 45
TC 1
Z9 1
U1 1
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD MAY 4
PY 2018
VL 12
AR 181
DI 10.3389/fnhum.2018.00181
PG 11
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA GE7YH
UT WOS:000431448500001
PM 29780312
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cardon, G
   Sharma, A
AF Cardon, Garrett
   Sharma, Anu
TI Somatosensory Cross-Modal Reorganization in Adults With Age-Related,
   Early-Stage Hearing Loss
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE neuroplasticity; cross-modal plasticity; sensorineural hearing loss;
   sLORETA; mild-moderate hearing loss; age-related hearing loss;
   somatosensory evoked potentials
ID AUDITORY ASSOCIATION CORTEX; EVOKED-POTENTIALS; SPEECH-PERCEPTION;
   CORTICAL REORGANIZATION; MALADAPTIVE PLASTICITY; COCHLEAR NUCLEUS;
   PREMOTOR CORTEX; OLDER-ADULTS; DEAF; NOISE
AB Under conditions of profound sensory deprivation, the brain has the propensity to reorganize. For example, intact sensory modalities often recruit deficient modalities' cortices for neural processing. This process is known as cross-modal reorganization and has been shown in congenitally and profoundly deaf patients. However, much less is known about cross-modal cortical reorganization in persons with less severe cases of age-related hearing loss (ARHL), even though such cases are far more common. Thus, we investigated cross-modal reorganization between the auditory and somatosensory modalities in older adults with normal hearing (NH) and mild-moderate ARHL in response to vibrotactile stimulation using high density electroencephalography (EEG). Results showed activation of the somatosensory cortices in adults with NH as well as those with hearing loss (HL). However, adults with mild-moderate ARHL also showed robust activation of auditory cortical regions in response to somatosensory stimulation. Neurophysiologic data exhibited significant correlations with speech perception in noise outcomes suggesting that the degree of cross-modal reorganization may be associated with functional performance. Our study presents the first evidence of somatosensory cross-modal reorganization of the auditory cortex in adults with early-stage, mild-moderate ARHL. Our findings suggest that even mild levels of ARHL associated with communication difficulty result in fundamental cortical changes.
C1 [Cardon, Garrett] Univ Colorado Denver, Dept Psychiat, Anschutz Med Campus, Aurora, CO USA.
   [Sharma, Anu] Univ Colorado, Dept Speech Language & Hearing Sci, Boulder, CO 80309 USA.
RP Sharma, A (corresponding author), Univ Colorado, Dept Speech Language & Hearing Sci, Boulder, CO 80309 USA.
EM anu.sharma@colorado.edu
OI Cardon, Garrett/0000-0003-4294-0204
FU NIMH NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) [T32 MH015442] Funding Source: Medline; NATIONAL INSTITUTE OF
   MENTAL HEALTHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) [T32MH015442, T32MH015442] Funding Source: NIH RePORTER
CR Allman BL, 2009, P NATL ACAD SCI USA, V106, P5925, DOI 10.1073/pnas.0809483106
   Ammirante P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053585
   Armstrong BA, 2002, COGNITIVE BRAIN RES, V14, P422, DOI 10.1016/S0926-6410(02)00211-2
   Auer ET, 2007, NEUROREPORT, V18, P645, DOI 10.1097/WNR.0b013e3280d943b9
   Baldwin R. L, 2002, THESIS
   Basura GJ, 2015, J NEUROPHYSIOL, V114, P3064, DOI 10.1152/jn.00319.2015
   Bavelier D, 2002, NAT REV NEUROSCI, V3, P443, DOI 10.1038/nrn848
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernstein LE, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1477, DOI 10.1109/ICSLP.1996.607895
   Bolognini N, 2010, J COGNITIVE NEUROSCI, V22, P1201, DOI 10.1162/jocn.2009.21267
   Bolton DAE, 2014, NEUROPSYCHOLOGIA, V57, P101, DOI 10.1016/j.neuropsychologia.2014.03.003
   Brosch M, 2005, J NEUROSCI, V25, P6797, DOI 10.1523/JNEUROSCI.1571-05.2005
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Caetano G, 2006, NEUROIMAGE, V29, P15, DOI 10.1016/j.neuroimage.2005.07.023
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Campbell J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147793
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Cardin V, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2463
   Chen LC, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4382656
   Christensen K, 2009, LANCET, V374, P1196, DOI 10.1016/S0140-6736(09)61460-4
   Debener S, 2008, PSYCHOPHYSIOLOGY, V45, P20, DOI 10.1111/j.1469-8986.2007.00610.x
   Dehmel S, 2008, AM J AUDIOL, V17, pS193, DOI 10.1044/1059-0889(2008/07-0045)
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Eggermont J. J, 2007, AUDITORY EVOKED POTE, P3
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Foxe JJ, 2000, COGNITIVE BRAIN RES, V10, P77, DOI 10.1016/S0926-6410(00)00024-0
   Foxe JJ, 2002, J NEUROPHYSIOL, V88, P540, DOI 10.1152/jn.2002.88.1.540
   Fu KMG, 2003, J NEUROSCI, V23, P7510
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Gifford RH, 2011, J AM ACAD AUDIOL, V22, P623, DOI 10.3766/jaaa.22.9.7
   Gilley PM, 2008, BRAIN RES, V1239, P56, DOI 10.1016/j.brainres.2008.08.026
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Gobbele R, 2003, NEUROIMAGE, V20, P503, DOI 10.1016/S1053-8119(03)00312-4
   Hackett TA, 2007, PERCEPTION, V36, P1419, DOI 10.1068/p5841
   Hallez H, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-46
   HAMALAINEN H, 1990, ELECTROEN CLIN NEURO, V75, P13, DOI 10.1016/0013-4694(90)90148-D
   Harrington GS, 2001, BRAIN RES, V897, P188, DOI 10.1016/S0006-8993(01)02139-4
   Hine J, 2007, CLIN NEUROPHYSIOL, V118, P1274, DOI 10.1016/j.clinph.2007.03.012
   Huang JB, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09211-3
   Hubka P, 2015, CELL TISSUE RES, V361, P279, DOI 10.1007/s00441-014-2059-6
   HYVARINEN J, 1981, NEUROSCI LETT, V26, P239, DOI 10.1016/0304-3940(81)90139-7
   IBM Corp, 2015, IBM SPSS STAT MAC VE
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   JOHNSON D, 1980, ARCH PSYCHIAT NERVEN, V228, P101, DOI 10.1007/BF00365598
   Jousmaki V, 1998, CURR BIOL, V8, pR190, DOI 10.1016/S0960-9822(98)70120-4
   Karns CM, 2012, J NEUROSCI, V32, P9626, DOI 10.1523/JNEUROSCI.6488-11.2012
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kim MB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148466
   Kochkin S., 2009, HEARING REV, V16, P12
   Kok MA, 2017, HEARING RES, V343, P108, DOI 10.1016/j.heares.2016.05.013
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011
   Land R, 2016, J NEUROSCI, V36, P6175, DOI 10.1523/JNEUROSCI.0046-16.2016
   Levanen S, 1998, CURR BIOL, V8, P869, DOI 10.1016/S0960-9822(07)00348-X
   Levanen S, 2001, NEUROSCI LETT, V301, P75, DOI 10.1016/S0304-3940(01)01597-X
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2012, JAMA-J AM MED ASSOC, V307, P1147, DOI 10.1001/jama.2012.321
   Lin FR, 2011, ARCH INTERN MED, V171, P1851, DOI 10.1001/archinternmed.2011.506
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Lindsley R. W., 1999, Society for Neuroscience Abstracts, V25, P1417
   Lomber SG, 2010, NAT NEUROSCI, V13, P1421, DOI 10.1038/nn.2653
   Lutkenhoner B, 2007, HEARING RES, V228, P188, DOI 10.1016/j.heares.2007.02.011
   LUU P, 2000, DETERMINATION GEODES
   Makeig S, 2004, PLOS BIOL, V2, P747, DOI 10.1371/journal.pbio.0020176
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979
   Masterson EA, 2016, MMWR-MORBID MORTAL W, V65, P389, DOI 10.15585/mmwr.mm6515a2
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758
   Merat N., 1999, Society for Neuroscience Abstracts, V25, P356
   Meredith MA, 2012, NEUROSCIENCE, V214, P136, DOI 10.1016/j.neuroscience.2012.04.001
   Meredith MA, 2015, EUR J NEUROSCI, V41, P686, DOI 10.1111/ejn.12828
   Meredith MA, 2011, HEARING RES, V280, P38, DOI 10.1016/j.heares.2011.02.004
   Mitchell TV, 2007, INT J AUDIOL, V46, P500, DOI 10.1080/14992020701383050
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   PascualMarqui R.D., 2007, DISCRETE 3D DISTRI 1
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Russo FA, 2012, J EXP PSYCHOL HUMAN, V38, P822, DOI 10.1037/a0029046
   Sadato N, 1996, NATURE, V380, P526, DOI 10.1038/380526a0
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Schormans AL, 2017, HEARING RES, V343, P92, DOI 10.1016/j.heares.2016.06.017
   Schroeder CE, 2002, COGNITIVE BRAIN RES, V14, P187, DOI 10.1016/S0926-6410(02)00073-3
   Schroeder CE, 2001, J NEUROPHYSIOL, V85, P1322
   Schurmann M, 2004, J ACOUST SOC AM, V115, P830, DOI 10.1121/1.1639909
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma A, 2016, OTOL NEUROTOL, V37, pE26, DOI 10.1097/MAO.0000000000000904
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Shiell MM, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/7217630
   Shore SE, 2008, EUR J NEUROSCI, V27, P155, DOI 10.1111/j.1460-9568.2007.05983.x
   Shore S. E., 2011, J ACOUST SOC AM, V129, P2524, DOI [10.1121/1.3588354, DOI 10.1121/1.3588354]
   Shore SE, 2016, NAT REV NEUROL, V12, P150, DOI 10.1038/nrneurol.2016.12
   Soto-Faraco S, 2009, BEHAV BRAIN RES, V196, P145, DOI 10.1016/j.bbr.2008.09.018
   Spence C, 1998, PERCEPT PSYCHOPHYS, V60, P544, DOI 10.3758/BF03206045
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Stropahl M, 2017, NEUROIMAGE-CLIN, V16, P514, DOI 10.1016/j.nicl.2017.09.001
   Stropahl M, 2015, NEUROIMAGE, V121, P159, DOI 10.1016/j.neuroimage.2015.07.062
   VONBEKESY G, 1959, PSYCHOL REV, V66, P1, DOI 10.1037/h0046967
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   WEINSTEIN SIDNEY, 1968, P195
   Wong C, 2015, J COMP NEUROL, V523, P1925, DOI 10.1002/cne.23771
   YAMAGUCHI S, 1991, ELECTROEN CLIN NEURO, V78, P297, DOI 10.1016/0013-4694(91)90184-6
   Zeng C, 2011, NEUROSCIENCE, V176, P142, DOI 10.1016/j.neuroscience.2010.12.010
   Zeng CH, 2012, J NEUROSCI, V32, P15791, DOI 10.1523/JNEUROSCI.2598-12.2012
NR 112
TC 9
Z9 11
U1 1
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD MAY 3
PY 2018
VL 12
AR 172
DI 10.3389/fnhum.2018.00172
PG 11
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA GE6OY
UT WOS:000431349700001
PM 29773983
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Levi, SV
AF Levi, Susannah, V
TI Another bilingual advantage? Perception of talker-voice information
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE speech perception; talker processing; bilinguals
ID TRAINING JAPANESE LISTENERS; SPEECH-PERCEPTION; LANGUAGE-FAMILIARITY;
   4-MONTH-OLD INFANTS; COGNITIVE CONTROL; RECOGNITION; IDENTIFICATION;
   CHILDREN; DISCRIMINATION; EXPERIENCE
AB A bilingual advantage has been found in both cognitive and social tasks. In the current study, we examine whether there is a bilingual advantage in how children process information about who is talking (talker-voice information). Younger and older groups of monolingual and bilingual children completed the following talker-voice tasks with bilingual speakers: a discrimination task in English and German (an unfamiliar language), and a talker-voice learning task in which they learned to identify the voices of three unfamiliar speakers in English. Results revealed effects of age and bilingual status. Across the tasks, older children performed better than younger children and bilingual children performed better than monolingual children. Improved talker-voice processing by the bilingual children suggests that a bilingual advantage exists in a social aspect of speech perception, where the focus is not on processing the linguistic information in the signal, but instead on processing information about who is talking.
C1 [Levi, Susannah, V] NYU, New York, NY 10012 USA.
RP Levi, SV (corresponding author), NYU, Dept Commun Sci & Disorders, 665 Broadway,9th Floor, New York, NY 10012 USA.
EM svlevi@nyu.edu
OI Levi, Susannah/0000-0002-3115-8981
FU NIH-NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [1R03DC009851-01A2]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R03DC009851, R03DC009851, R03DC009851] Funding Source: NIH
   RePORTER
FX This work was supported by a grant from the NIH-NIDCD:
   1R03DC009851-01A2. We would like to thank Jennifer Bruno, Emma Mack,
   Alexandra Muratore, Sydney Robert, and Margo Waltz for help with data
   collection, three anonymous reviewers for their extremely helpful
   comments, and the children and families for their participation.
CR Ansaldo AI, 2015, J CLIN EXP NEUROPSYC, V37, P455, DOI 10.1080/13803395.2014.990359
   Arredondo MM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12377
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   BARTHOLOMEUS B, 1973, CAN J PSYCHOL, V27, P464, DOI 10.1037/h0082498
   Bates D, 2010, LME4 LINEAR MIXED EF
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bialystok E, 2004, DEVELOPMENTAL SCI, V7, P325, DOI 10.1111/j.1467-7687.2004.00351.x
   Bialystok E, 1999, CHILD DEV, V70, P636, DOI 10.1111/1467-8624.00046
   Bialystok E, 2004, PSYCHOL AGING, V19, P290, DOI 10.1037/0882-7974.19.2.290
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   Brown L., 1997, TONI 3 TEST NONVERBA
   Buac M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01098
   Carlson SM, 2008, DEVELOPMENTAL SCI, V11, P282, DOI 10.1111/j.1467-7687.2008.00675.x
   Clopper CG, 2004, LANG SPEECH, V47, P207, DOI 10.1177/00238309040470030101
   Costa A, 2008, COGNITION, V106, P59, DOI 10.1016/j.cognition.2006.12.013
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   Cutler A., 2011, P 17 INT C PHON SCI, P552
   de Bruin A, 2015, PSYCHOL SCI, V26, P99, DOI 10.1177/0956797614557866
   DECASPER AJ, 1984, DEV PSYCHOBIOL, V17, P481, DOI 10.1002/dev.420170506
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Ensminger ME, 2003, MON PARENT, P13
   Fan SP, 2015, PSYCHOL SCI, V26, P1090, DOI 10.1177/0956797615574699
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Fleming D, 2014, P NATL ACAD SCI USA, V111, P13795, DOI 10.1073/pnas.1401383111
   Friesen DC, 2015, INT J BILINGUAL, V19, P693, DOI 10.1177/1367006914534331
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   Gold BT, 2013, J NEUROSCI, V33, P387, DOI 10.1523/JNEUROSCI.3837-12.2013
   GOLDSTEIN AG, 1981, B PSYCHONOMIC SOC, V17, P217
   Green KP, 1997, PERCEPT PSYCHOPHYS, V59, P675, DOI 10.3758/BF03206015
   Greenberg A, 2013, COGNITIVE DEV, V28, P41, DOI 10.1016/j.cogdev.2012.10.002
   Hamers Josiane F., 2000, BILINGUALITY BILINGU
   HOLLIEN H, 1982, J PHONETICS, V10, P139, DOI 10.1016/S0095-4470(19)30953-2
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Kerstholt JH, 2006, APPL COGNITIVE PSYCH, V20, P187, DOI 10.1002/acp.1175
   Kisilevsky BS, 2003, PSYCHOL SCI, V14, P220, DOI 10.1111/1467-9280.02435
   Koster O, 1997, FORENSIC LINGUIST, V4, P18, DOI DOI 10.1558/IJSLL.V4I1.18
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   Levi SV, 2007, J ACOUST SOC AM, V121, P2327, DOI 10.1121/1.2537345
   Levi SV, 2015, J CHILD LANG, V42, P843, DOI 10.1017/S0305000914000506
   Levi SV, 2014, PHONETICA, V71, P201, DOI 10.1159/000370160
   Levi SV, 2013, J SPEECH LANG HEAR R, V56, P913, DOI 10.1044/1092-4388(2012/12-0095)
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   MANN VA, 1979, J EXP CHILD PSYCHOL, V27, P153, DOI 10.1016/0022-0965(79)90067-5
   McLennan C. T., 2015, BILING-LANG COGN, P1, DOI DOI 10.1017/S1366728915000218
   Moher M, 2010, COGNITIVE SCI, V34, P719, DOI 10.1111/j.1551-6709.2010.01109.x
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Orena AJ, 2015, COGNITION, V143, P36, DOI 10.1016/j.cognition.2015.06.002
   Paap KR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00962
   Paap KR, 2014, AIMS NEUROSCI, V1, P245, DOI 10.3934/Neuroscience.2014.3.245
   Paap KR, 2014, J COGN PSYCHOL, V26, P615, DOI 10.1080/20445911.2014.944914
   Paap KR, 2013, COGNITIVE PSYCHOL, V66, P232, DOI 10.1016/j.cogpsych.2012.12.002
   Perrachione T. K, 2015, P 18 INT C PHON SCI
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Perrachione TK, 2010, COGNITION, V114, P42, DOI 10.1016/j.cognition.2009.08.012
   Purhonen M, 2005, COGNITIVE BRAIN RES, V24, P627, DOI 10.1016/j.cogbrainres.2005.03.012
   Purhonen M, 2004, INT J PSYCHOPHYSIOL, V52, P257, DOI 10.1016/j.ijpsycho.2003.11.003
   Saidi LG, 2015, AIMS NEUROSCI, V2, P52, DOI 10.3934/Neuroscience.2015.1.52
   Schiller N.O., 1996, FORENSIC LINGUIST, V3, P176
   Schneider W., 2007, E PRIME 2 0 PROFESSI
   Semel E. M., 2003, CLIN EVALUATION LANG
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Spence MJ, 2002, J SPEECH LANG HEAR R, V45, P214, DOI 10.1044/1092-4388(2002/016)
   Stevenage SV, 2012, J COGN PSYCHOL, V24, P647, DOI 10.1080/20445911.2012.675321
   Strange W., 2006, J ACOUST SOC AM, V120, P3137, DOI DOI 10.1121/1.4787743
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Sullivan KPH, 2000, FORENSIC LINGUIST, V17, P95
   THOMPSON CP, 1987, APPL COGNITIVE PSYCH, V1, P121, DOI 10.1002/acp.2350010205
   VANDOMMELEN WA, 1987, LANG SPEECH, V30, P325, DOI 10.1177/002383098703000403
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   Xie X, 2015, J ACOUST SOC AM, V137, P419, DOI 10.1121/1.4904699
   Zarate JM, 2015, SCI REP-UK, V5, DOI 10.1038/srep11475
NR 80
TC 9
Z9 9
U1 5
U2 9
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD MAY
PY 2018
VL 21
IS 3
BP 523
EP 536
DI 10.1017/S1366728917000153
PG 14
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA GF7VF
UT WOS:000432175700011
PM 29755282
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Rapport, F
   Bierbaum, M
   McMahon, C
   Boisvert, I
   Lau, A
   Braithwaite, J
   Hughes, S
AF Rapport, Frances
   Bierbaum, Mia
   McMahon, Catherine
   Boisvert, Isabelle
   Lau, Annie
   Braithwaite, Jeffrey
   Hughes, Sarah
TI Qualitative, multimethod study of behavioural and attitudinal responses
   to cochlear implantation from the patient and healthcare professional
   perspective i n Australia and the UK: study protocol
SO BMJ OPEN
LA English
DT Article
ID FAMILIAL BREAST-CANCER; HEARING-LOSS; CHRONIC DISEASES; UNITED-STATES;
   FOCUS GROUPS; OF-LIFE; ADULTS; IMPAIRMENT; AID; DEAF
AB Introduction The growing prevalence of adults with 'severe or greater' hearing loss globally is of great concern, with hearing loss leading to diminished communication, and impacting on an individual's quality of life (QoL). Cochlear implants (CI) are a recommended device for people with severe or greater, sensorineural hearing loss, who obtain limited benefits from conventional hearing aids (HA), and through improved speech perception, Cls can improve the QoL of recipients. Despite this, utilisation of Cls is low.
   Methods and analysis This qualitative, multiphase and multimethod dual-site study (Australia and the UK) explores patients' and healthcare professionals' behaviours and attitudes to cochlear implantation. Participants include general practitioners, audiologists and older adults with severe or greater hearing loss, who are HA users, CI users and CI candidates. Using purposive time frame sampling, participants will be recruited to take part in focus groups or individual interviews, and will each complete a demographic questionnaire and a qualitative proforma. The study aims to conduct 147 data capture events across a sample of 49 participants, or until data saturation occurs. Schema and thematic analysis with extensive group work will be used to analyse data alongside reporting of demographic and participant characteristics.
   Ethics and dissemination Ethics approval for this study was granted by Macquarie University (HREC: 5201700539), and the study will abide by Australian National Health and Medical Research Council ethical guidelines. Study findings will be published through peer-reviewed journal articles, and disseminated through public and academic conference presentations, participant information sheets and a funders' final report.
C1 [Rapport, Frances; Bierbaum, Mia; Lau, Annie; Braithwaite, Jeffrey] Macquarie Univ, Australian Inst Hlth Innovat, Sydney, NSW, Australia.
   [Rapport, Frances; McMahon, Catherine; Boisvert, Isabelle; Braithwaite, Jeffrey; Hughes, Sarah] Macquarie Univ, Ctr Implementat Hearing Res, Sydney, NSW, Australia.
   [McMahon, Catherine; Boisvert, Isabelle] HEARing Cooperat Res Ctr, Sydney, NSW, Australia.
   [Hughes, Sarah] Abertawe Bro Morgannwg Univ Hlth Board, South Wales Cochlear Implant Programme, Bridgend, Wales.
   [Hughes, Sarah] Swansea Univ, Med Sch, Swansea, W Glam, Wales.
RP Bierbaum, M (corresponding author), Macquarie Univ, Australian Inst Hlth Innovat, Sydney, NSW, Australia.
EM mia.bierbaum@mq.edu.au
RI Boisvert, Isabelle/AAB-8090-2021; Braithwaite, Jeffrey/AAN-1467-2020;
   Bierbaum, Mia/AAJ-9497-2020
OI Boisvert, Isabelle/0000-0001-7050-3197; Braithwaite,
   Jeffrey/0000-0003-0296-4957; Bierbaum, Mia/0000-0002-7037-4708; McMahon,
   Catherine/0000-0001-7312-6593; Lau, Annie Y.S./0000-0002-3028-4222
FU Cochlear Macquarie University Partnership (MQ-Cochlear)
FX This work is supported by Cochlear Macquarie University Partnership
   (MQ-Cochlear).
CR Access Economics, 2006, EC IMP COST HEAR LOS
   Balch GI, 1999, AM J EVAL, V20, P265, DOI 10.1016/S1098-2140(99)00019-3
   Barnett M, 2017, LARYNGOSCOPE, V127, P1187, DOI 10.1002/lary.26234
   Berends L, 2005, ADDICT RES THEORY, V13, P373, DOI 10.1080/16066350500102237
   Bittencourt AG, 2012, BRAZ J OTORHINOLAR, V78, P124, DOI 10.1590/S1808-86942012000200019
   Bloor M., 2001, FOCUS GROUPS SOCIAL
   BOND M, 2009, HEALTH TECHNOL ASSES, V13, P1, DOI DOI 10.3310/HTA13440
   Braun V, 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   British Cochlear Implant Group, 2017, HOW DO I GET ON
   British Cochlear Implant Group, 2018, CI ACT 2017 ANN UK U
   Clark J G, 1981, ASHA, V23, P493
   Cochlear Ltd, 2017, FUND OPT COCHL IMPL
   Coelho DH, 2009, LARYNGOSCOPE, V119, P355, DOI 10.1002/lary.20067
   Cohen Seth M, 2005, Ear Nose Throat J, V84, P29
   Contrera KJ, 2016, LARYNGOSCOPE, V126, P2110, DOI 10.1002/lary.25848
   Cox RM, 2005, EAR HEARING, V26, P513, DOI 10.1097/01.aud.0000188188.01311.0b
   Damen GWJA, 2007, OTOLARYNG HEAD NECK, V136, P597, DOI 10.1016/j.otohns.2006.11.044
   Davis A, 2007, HEALTH TECHNOL ASSES, V11, P1, DOI 10.3310/hta11420
   Denzin N.K., 2005, HDB QUALITATIVE RES, V3rd
   Flick Uwe, 2004, COMPANION QUALITATIV, P178
   FOLCHLYON E, 1981, STUD FAMILY PLANN, V12, P443, DOI 10.2307/1965656
   Foteff C, 2016, OTOL NEUROTOL, V37, P454, DOI 10.1097/MAO.0000000000000999
   Francis HW, 2002, LARYNGOSCOPE, V112, P1482, DOI 10.1097/00005537-200208000-00028
   Fusch PI, 2015, QUAL REP, V20, P1408
   Gaylor JM, 2013, JAMA OTOLARYNGOL, V139, P265, DOI 10.1001/jamaoto.2013.1744
   Golafshani N., 2003, QUAL REP, V8, P597, DOI DOI 10.18187/PJS0R.V4I1.59
   Goman AM, 2017, JAMA OTOLARYNGOL, V143, P733, DOI 10.1001/jamaoto.2016.4642
   Hammersley M, 2007, ETHNOGRAPHY PRINCIPL
   Iredale R, 2008, J EVAL CLIN PRACT, V14, P110, DOI 10.1111/j.1365-2753.2007.00811.x
   JICK TD, 1979, ADMIN SCI QUART, V24, P602, DOI 10.2307/2392366
   Jung D, 2012, ANN OTO RHINOL LARYN, V121, P771, DOI 10.1177/000348941212101201
   Kitzinger J., 2005, QUALITATIVE RES HLTH
   Kramer SE, 2002, J AGING HEALTH, V14, P122, DOI 10.1177/089826430201400107
   KRUEGER R. A., 2002, SOCIAL ANAL SELECTED, V4, P4, DOI DOI 10.1136/BMJ.311.7000.299
   Labadie RF, 2000, OTOLARYNG HEAD NECK, V123, P419, DOI 10.1067/mhn.2000.109759
   Laplante-Levesque A, 2010, INT J AUDIOL, V49, P497, DOI 10.3109/14992021003645902
   Leigh JR, 2016, INT J AUDIOL, V55, pS3, DOI 10.3109/14992027.2016.1146415
   Li CM, 2014, JAMA OTOLARYNGOL, V140, P293, DOI 10.1001/jamaoto.2014.42
   Liamputtong P, 2013, QUALITATIVE RES METH
   Lian OS, 2016, HEALTH-LONDON, V20, P578, DOI 10.1177/1363459315622041
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Lincoln Y. S., 1986, NEW DIRECTIONS PROGR, V1986, P73, DOI [10.1002/(ISSN)1551-2371, DOI 10.1002/EV.1427]
   Looi V, 2017, INT J AUDIOL, V56, P919, DOI 10.1080/14992027.2017.1344361
   Maki-Torkko EM, 2015, DISABIL REHABIL, V37, P541, DOI 10.3109/09638288.2014.935490
   Mohr PE, 2000, INT J TECHNOL ASSESS, V16, P1120, DOI 10.1017/S0266462300103162
   Monzani D, 2008, ACTA OTORHINOLARYNGO, V28, P61
   Napier Jemina, 2004, J Deaf Stud Deaf Educ, V9, P228, DOI 10.1093/deafed/enh024
   National Health and Medical Research Council, 2007, NAT STAT ETH COND HU
   National Institute for Health and Care Excellence, 2009, COCHL IMPL CHILDR AD
   Nikolopoulos TP, 2010, EARLY HUM DEV, V86, P669, DOI 10.1016/j.earlhumdev.2010.10.001
   Oberg M, 2012, INT J AUDIOL, V51, P108, DOI 10.3109/14992027.2011.622301
   Patton M. Q., 2005, QUALITATIVE RES
   Pope C, 2000, BMJ-BRIT MED J, V320, P114, DOI 10.1136/bmj.320.7227.114
   Raine Chris, 2013, Cochlear Implants Int, V14 Suppl 1, pS32, DOI 10.1179/1467010013Z.00000000077
   Raine Christopher, 2016, Cochlear Implants Int, V17 Suppl 1, P42, DOI 10.1080/14670100.2016.1155808
   Rapport F, 2018, HDB RES METHODS HLTH
   Rapport F, 2006, HEALTH EXPECT, V9, P232, DOI 10.1111/j.1369-7625.2006.00392.x
   Rapport F, 2017, BMJ OPEN, V7, DOI 10.1136/bmjopen-2017-017148
   Rapport F, 2010, QUAL HEALTH RES, V20, P922, DOI 10.1177/1049732309354282
   Robinson N, 1999, J ADV NURS, V29, P905, DOI 10.1046/j.1365-2648.1999.00966.x
   Robson C., 2011, REAL WORLD RES RESOU
   Shin YJ, 2000, OTOLARYNG HEAD NECK, V122, P602, DOI 10.1016/S0194-5998(00)70112-4
   Sindhusake D, 2001, INT J EPIDEMIOL, V30, P1371, DOI 10.1093/ije/30.6.1371
   Sorkin DL, 2013, COCHLEAR IMPLANTS S1, V14, pS12
   Sorkin DL, 2016, OTOL NEUROTOL, V37, pE161, DOI 10.1097/MAO.0000000000000946
   Stevens G, 2013, EUR J PUBLIC HEALTH, V23, P146, DOI 10.1093/eurpub/ckr176
   Taylor J. K., 2004, STAT TECHNIQUES DATA
   Tong A, 2007, INT J QUAL HEALTH C, V19, P349, DOI 10.1093/intqhc/mzm042
   United Nations DoEaSA Population Division, 2017, ESAPWP248 UN DOEASA
   United Nations DoEaSA Population Division, 2015, STESASERA390 UN DOEA
   Vos T, 2015, LANCET, V386, P743, DOI 10.1016/S0140-6736(15)60692-4
   Wallhagen MI, 2010, GERONTOLOGIST, V50, P66, DOI 10.1093/geront/gnp107
   Welfare AIoHa, 2018, AIHW NAT HOSP MORB D
NR 73
TC 7
Z9 7
U1 0
U2 6
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 2044-6055
J9 BMJ OPEN
JI BMJ Open
PD MAY
PY 2018
VL 8
IS 5
AR e019623
DI 10.1136/bmjopen-2017-019623
PG 10
WC Medicine, General & Internal
SC General & Internal Medicine
GA GJ7KZ
UT WOS:000435567200045
PM 29844099
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hamalainen, J
   Landi, N
   Loberg, O
   Lohvansuu, K
   Pugh, K
   Leppanen, PHT
AF Hamalainen, Jarmo
   Landi, Nicole
   Loberg, Otto
   Lohvansuu, Kaisa
   Pugh, Kenneth
   Leppanen, Paavo H. T.
TI Brain event-related potentials to phoneme contrasts and their
   correlation to reading skills in school-age children
SO INTERNATIONAL JOURNAL OF BEHAVIORAL DEVELOPMENT
LA English
DT Article
DE children; cross-linguistic; dyslexia; EEG; event-related potentials;
   phonology; reading; speech
ID EARLY LANGUAGE-ACQUISITION; MISMATCH NEGATIVITY MMN; SPEECH-PERCEPTION;
   FAMILIAL RISK; PHONOLOGICAL REPRESENTATIONS; DYSLEXIC-CHILDREN; POOR
   READERS; RESPONSES; INFANTS; DISCRIMINATION
AB Development of reading skills has been shown to be tightly linked to phonological processing skills and to some extent to speech perception abilities. Although speech perception is also known to play a role in reading development, it is not clear which processes underlie this connection. Using event-related potentials (ERPs) we investigated the speech processing mechanisms for common and uncommon sound contrasts (/ba/-/da/-/ga/ and /ata/-/at: a/) with respect to the native language of school-age children in Finland and the US. In addition, a comprehensive behavioral test battery of reading and phonological processing was administered. ERPs revealed that the children could discriminate between the speech sound contrasts (place of articulation and phoneme length) regardless of their native language. No differences emerged between the Finnish and US children in their change detection responses. The brain responses to the phoneme length contrast, however, correlated robustly with reading scores in the US children, with larger responses being linked to poorer reading skills. Finnish children also showed correlations between the reading and phonological measures and ERP responses, but the pattern of results was not as clear as for the US children. The results indicate that speech perception is linked to reading skills and this link is more robust for uncommon speech sound contrasts.
C1 [Hamalainen, Jarmo; Loberg, Otto; Lohvansuu, Kaisa; Leppanen, Paavo H. T.] Univ Jyvaskyla, Dept Psychol, POB 35, Jyvaskyla 40014, Finland.
   [Landi, Nicole; Pugh, Kenneth] Haskins Labs Inc, New Haven, CT USA.
   [Landi, Nicole; Pugh, Kenneth] Univ Connecticut, Dept Psychol, Storrs, CT USA.
   [Landi, Nicole] Yale Univ, Ctr Child Study, New Haven, CT 06520 USA.
   [Pugh, Kenneth] Yale Univ, Sch Med, Dept Diagnost Radiol, New Haven, CT 06510 USA.
RP Hamalainen, J (corresponding author), Univ Jyvaskyla, Dept Psychol, POB 35, Jyvaskyla 40014, Finland.
EM jarmo.a.hamalainen@jyu.fi
RI landi, nicole/ABG-5374-2020; Landi, Nicole/P-2954-2014
OI Landi, Nicole/0000-0003-2890-2519; Lohvansuu, Kaisa/0000-0002-1641-844X;
   Hamalainen, Jarmo/0000-0001-7188-8148
FU Academy of FinlandAcademy of FinlandEuropean Commission [292 466];
   European UnionEuropean Commission [641652]; NIHUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USA [P01
   HD HD001994, R01 HD 48830, R03 HD053409]; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   R37HD090153, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, R37HD090153, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, R37HD090153, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994] Funding
   Source: NIH RePORTER; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH &HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   R01HD048830, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, R01HD048830,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   R01HD048830, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, R01HD048830, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, R01HD048830, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, R03HD053409, P01HD001994, P01HD001994, R01HD048830,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   R03HD053409, P01HD001994, P01HD001994, P01HD001994] Funding Source: NIH
   RePORTER
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   was supported by the Academy of Finland (profiling action "Multilete"
   #292 466), European Union H2020MSCA-ITN-2014-ETN Programme, "Advancing
   brain research in children's developmental neurocognitive
   disorders"-project (ChildBrain, #641652), NIH grants: P01 HD HD001994
   "Nature and acquisition of the speech code and reading", PI: C. Fowler;
   R01 HD 48830 Neurobiological Foundations of Reading (Dis)ability, PI: K.
   Pugh R03 HD053409 & R03 HD053409 "Neurocognitive development in RD
   children with/without general cognitive deficits", PI: N. Landi.
CR Anthony JL, 2005, CURR DIR PSYCHOL SCI, V14, P255, DOI 10.1111/j.0963-7214.2005.00376.x
   Barry JG, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006270
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Bonte ML, 2007, NEUROPSYCHOLOGIA, V45, P1427, DOI 10.1016/j.neuropsychologia.2006.11.009
   BRADLEY L, 1978, NATURE, V271, P746, DOI 10.1038/271746a0
   Ceponiene R, 2005, PSYCHOPHYSIOLOGY, V42, P391, DOI 10.1111/j.1469-8986.2005.00305.x
   Ceponiene R, 2004, PSYCHOPHYSIOLOGY, V41, P130, DOI 10.1111/j.1469-8986.2003.00138.x
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Choudhury N, 2011, CLIN NEUROPHYSIOL, V122, P320, DOI 10.1016/j.clinph.2010.05.035
   Conboy BT, 2008, TRENDS LANG ACQUIS R, V5, P23
   DENCKLA MB, 1976, NEUROPSYCHOLOGIA, V14, P471, DOI 10.1016/0028-3932(76)90075-0
   Dunn L.M., 1997, PPVT 3 PEABODY PICTU
   Eklund K, 2015, J EDUC PSYCHOL, V107, P126, DOI 10.1037/a0037121
   Elbro C, 2005, SCAND J PSYCHOL, V46, P375, DOI 10.1111/j.1467-9450.2005.00468.x
   Elbro C, 1998, SCAND J PSYCHOL, V39, P149, DOI 10.1111/1467-9450.393070
   Espy KA, 2004, ANN DYSLEXIA, V54, P9, DOI 10.1007/s11881-004-0002-3
   Friederici AD, 2005, TRENDS COGN SCI, V9, P481, DOI 10.1016/j.tics.2005.08.008
   Georgiou GK, 2008, J EDUC PSYCHOL, V100, P566, DOI 10.1037/0022-0663.100.3.566
   Goswami U., 1990, PHONOLOGICAL SKILLS
   Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3
   Guttorm TK, 2001, J LEARN DISABIL-US, V34, P534, DOI 10.1177/002221940103400606
   Guttorm TK, 2010, J LEARN DISABIL-US, V43, P391, DOI 10.1177/0022219409345005
   Hamalainen JA, 2009, APPL PSYCHOLINGUIST, V30, P511, DOI 10.1017/S0142716409090250
   Hamalainen JA, 2015, INT J PSYCHOPHYSIOL, V95, P101, DOI 10.1016/j.ijpsycho.2014.04.004
   Hamalainen JA, 2013, DEV NEUROPSYCHOL, V38, P550, DOI 10.1080/87565641.2012.718817
   HAYRINEN T, 1999, LUKILASSE
   Helenius P, 2002, J COGNITIVE NEUROSCI, V14, P603, DOI 10.1162/08989290260045846
   Jacobsen T, 2001, PSYCHOPHYSIOLOGY, V38, P723, DOI 10.1017/S0048577201000993
   Jakoby H, 2011, PSYCHOPHYSIOLOGY, V48, P1516, DOI 10.1111/j.1469-8986.2011.01227.x
   Kirmse U, 2008, INT J PSYCHOPHYSIOL, V67, P131, DOI 10.1016/j.ijpsycho.2007.10.012
   Korkman M., 1998, NEPSY LASTEN NEUROPS
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuuluvainen S, 2016, EUR J NEUROSCI, V43, P738, DOI 10.1111/ejn.13141
   Leppanen PHT, 2002, DEV NEUROPSYCHOL, V22, P407, DOI 10.1207/S15326942dn2201_4
   Leppanen PHT, 1999, NEUROREPORT, V10, P969, DOI 10.1097/00001756-199904060-00014
   Lindeman J., 1998, ALLU ALA ASTEEN LUKU
   Lohvansuu K, 2014, INT J PSYCHOPHYSIOL, V94, P298, DOI 10.1016/j.ijpsycho.2014.10.002
   Lohvansuu K, 2013, PSYCHOPHYSIOLOGY, V50, P640, DOI 10.1111/psyp.12048
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   MCBRIDECHANG C, 1995, EDUC PSYCHOL, V30, P109, DOI 10.1207/s15326985ep3003_2
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 2010, BRAIN RES REV, V64, P123, DOI 10.1016/j.brainresrev.2010.03.001
   Parviainen T, 2011, HUM BRAIN MAPP, V32, P2193, DOI 10.1002/hbm.21181
   Psychological Corporation, 1999, WECHSLER ABBREVIATED
   Puolakanaho A, 2008, J LEARN DISABIL-US, V41, P353, DOI 10.1177/0022219407311747
   Richardson U, 2003, DEV NEUROPSYCHOL, V23, P385, DOI 10.1207/S15326942DN2303_5
   Schroger E, 1996, NEUROREPORT, V7, P3005, DOI 10.1097/00001756-199611250-00041
   Schulte-Korne G, 2010, CLIN NEUROPHYSIOL, V121, P1794, DOI 10.1016/j.clinph.2010.04.028
   Schulte-Korne G, 1998, NEUROREPORT, V9, P337, DOI 10.1097/00001756-199801260-00029
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Shestakova A, 2003, CLIN NEUROPHYSIOL, V114, P1507, DOI 10.1016/S1388-2457(03)00134-2
   Torgeson J., 1999, TEST WORD READING EF
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   van Zuijen TL, 2013, DEVELOPMENTAL SCI, V16, P554, DOI 10.1111/desc.12049
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Wagner R, 1999, COMPREHENSIVE TEST P
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Wechsler D, 1991, WISC 3 WECHSLER INTE
   Wiederholt J. L., 1992, GORT 3 GRAY ORAL REA
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
NR 65
TC 5
Z9 5
U1 1
U2 14
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0165-0254
EI 1464-0651
J9 INT J BEHAV DEV
JI Int. J. Behav. Dev.
PD MAY
PY 2018
VL 42
IS 3
BP 357
EP 372
DI 10.1177/0165025417728582
PG 16
WC Psychology, Developmental
SC Psychology
GA GF6KS
UT WOS:000432076300007
PM 29892138
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Tsang, T
   Atagi, N
   Johnson, SP
AF Tsang, Tawny
   Atagi, Natsuki
   Johnson, Scott P.
TI Selective attention to the mouth is associated with expressive language
   skills in monolingual and bilingual infants
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Bilingualism; Language development; Selective attention; Face
   perception; Infant; Eye-tracking; Social attention
ID SPEECH-PERCEPTION; DISCRIMINATION; ADVANTAGE; EXPOSURE; TODDLERS;
   FEEDBACK; OUTCOMES; FACES
AB Infants increasingly attend to the mouths of others during the latter half of the first postnatal year, and individual differences in selective attention to talking mouths during infancy predict verbal skills during toddlerhood. There is some evidence suggesting that trajectories in mouth-looking vary by early language environment, in particular monolingual or bilingual language exposure, which may have differential consequences in developing sensitivity to the communicative and social affordances of the face. Here, we evaluated whether 6- to 12-month-olds' mouth-looking is related to skills associated with concurrent social communicative development including early language functioning and emotion discriminability. We found that attention to the mouth of a talking face increased with age but that mouth-looking was more strongly associated with concurrent expressive language skills than chronological age for both monolingual and bilingual infants. Mouth-looking was not related to emotion discrimination. These data suggest that selective attention to a talking mouth may be one important mechanism by which infants learn language regardless of home language environment. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Tsang, Tawny; Atagi, Natsuki; Johnson, Scott P.] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA.
RP Tsang, T (corresponding author), Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA.
EM tsangtt89@ucla.edu
OI /0000-0002-8562-7341
FU National Defense Science and Engineering Graduate Fellowship; National
   Science Foundation Graduate Research FellowshipNational Science
   Foundation (NSF) [DGE-07074240707424]; National Institutes of
   HealthUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01 HD082844]; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [R01HD082844, F31HD090937, R01HD082844,
   R01HD082844, R01HD082844] Funding Source: NIH RePORTER
FX The authors thank all the families who participated as well as the UCLA
   Baby Lab for helpful feedback and comments. This work was supported by
   grants from the National Defense Science and Engineering Graduate
   Fellowship to TT, National Science Foundation Graduate Research
   Fellowship (DGE-07074240707424) to NA, and National Institutes of Health
   (R01 HD082844) to SPJ.
CR Amso D, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00180
   Ayneto A, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12446
   Brito N, 2014, DEV PSYCHOBIOL, V56, P1156, DOI 10.1002/dev.21188
   Brito N, 2012, DEVELOPMENTAL SCI, V15, P812, DOI 10.1111/j.1467-7687.2012.1184.x
   Brito NH, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01369
   Brooks R, 2005, DEVELOPMENTAL SCI, V8, P535, DOI 10.1111/j.1467-7687.2005.00445.x
   Campbell DJ, 2014, J AUTISM DEV DISORD, V44, P431, DOI 10.1007/s10803-013-1885-9
   Chawarska K, 2012, J CHILD PSYCHOL PSYC, V53, P903, DOI 10.1111/j.1469-7610.2012.02538.x
   Dunn LM, 2007, PPVT 4 PEABODY PICTU
   Elsabbagh M, 2014, SOC COGN AFFECT NEUR, V9, P538, DOI 10.1093/scan/nst012
   Fenson L., 1994, MONOGRAPHS SOC RES C, V59
   Frank MC, 2014, J EXP CHILD PSYCHOL, V118, P13, DOI 10.1016/j.jecp.2013.08.012
   Frank MC, 2012, INFANCY, V17, P355, DOI 10.1111/j.1532-7078.2011.00086.x
   Goldstein MH, 2008, PSYCHOL SCI, V19, P515, DOI 10.1111/j.1467-9280.2008.02117.x
   Gros-Louis J, 2006, INT J BEHAV DEV, V30, P509, DOI 10.1177/0165025406071914
   Hillairet de Boisferon A., 2017, DEV SCI, V20
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   Hoshino N, 2008, COGNITION, V106, P501, DOI 10.1016/j.cognition.2007.02.001
   Howard LH, 2014, COGNITION, V133, P474, DOI 10.1016/j.cognition.2014.08.002
   Hunnius S, 2004, INFANCY, V6, P231, DOI 10.1207/s15327078in0602_5
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Jones W, 2008, ARCH GEN PSYCHIAT, V65, P946, DOI 10.1001/archpsyc.65.8.946
   Kovacs AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   Kovacs AM, 2009, SCIENCE, V325, P611, DOI 10.1126/science.1173947
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Lewkowicz DJ, 2013, INT J BEHAV DEV, V37, P90, DOI 10.1177/0165025412467582
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Luk G, 2013, J COGN PSYCHOL, V25, P605, DOI 10.1080/20445911.2013.795574
   Marchman VA, 2002, J SPEECH LANG HEAR R, V45, P983, DOI 10.1044/1092-4388(2002/080)
   Martin N., 2012, EXPRESSIVE ONE WORD
   Martin N, 2010, RECEPTIVE ONE WORD P
   Martin N. A., 2010, EXPRESSIVE ONE WORD
   Mullen E., 1995, MULLEN SCALES EARLY
   Munhalll KG, 2012, CURR BIOL, V22, pR190, DOI 10.1016/j.cub.2012.02.026
   Pearson BZ, 1997, APPL PSYCHOLINGUIST, V18, P41, DOI 10.1017/S0142716400009863
   Pefia E. D., 2014, BILINGUAL ENGLISH SP
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Poulin-Dubois D, 2011, J EXP CHILD PSYCHOL, V108, P567, DOI 10.1016/j.jecp.2010.10.009
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Schonberg C, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01429
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Shank L., 2011, ENCY CLIN NEUROPSYCH, P1669, DOI 10.1007/978-0-387-79948-3_1570
   Singh L, 2015, CHILD DEV, V86, P294, DOI 10.1111/cdev.12271
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   Thordardottir E, 2011, INT J BILINGUAL, V15, P426, DOI 10.1177/1367006911403202
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   U.S. Census Bureau, 2016, AM COMM SURV 5 YEAR
   Wagner JB, 2013, INT J BEHAV DEV, V37, P118, DOI 10.1177/0165025412468064
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Wu Z, 2014, FIRST LANG, V34, P72, DOI 10.1177/0142723714521925
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 53
TC 22
Z9 22
U1 2
U2 37
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD MAY
PY 2018
VL 169
BP 93
EP 109
DI 10.1016/j.jecp.2018.01.002
PG 17
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA FW1SV
UT WOS:000425080600007
PM 29406126
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Evans, BG
   Alshangiti, W
AF Evans, Bronwen G.
   Alshangiti, Wafaa
TI The perception and production of British English vowels and consonants
   by Arabic learners of English
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Second language learning; Speech production; Speech perception
ID R-VERTICAL-BAR; SPEECH-PERCEPTION; DUTCH VOWELS; LISTENERS;
   ASSIMILATION; ACQUISITION; SPEAKERS; SPANISH; DISCRIMINATION;
   IDENTIFICATION
AB This study investigated the perception of British English vowels and consonants by native Saudi Arabic learners of English from a range of proficiency levels. Twenty-six participants completed consonant and vowel identification tasks in quiet and noise. To investigate if predicted difficulties with vowel perception were also present in production, participants also recorded vowels embedded in words and read a short story. The results demonstrated that all learners were better able to identify consonants than vowels in quiet and noise, with more experienced learners outperforming early learners. Although learners were likely able to rely on mapping non-native to native categories when identifying consonants, there was some evidence that they had started to establish new vowel targets. This appeared to start early in learning but even highly experienced learners continued to find vowels with no direct Arabic counterpart difficult. Additionally, there was some evidence for a link between perception and production: vowel perception was better in those who had more accurate production. Overall, the results shed light on problematic phonemic contrasts for Arabic learners, and suggest that though learners may be able to establish new phonetic categories early in learning, other contrasts continue to remain difficult even for highly experienced learners. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Evans, Bronwen G.] UCL, Dept Speech Hearing & Phonet Sci, Div Psychol & Language Sci, Chandler House, London WC1N 1PF, England.
   [Alshangiti, Wafaa] King Abdulaziz Univ, English Language Inst, Jeddah, Saudi Arabia.
RP Evans, BG (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, Div Psychol & Language Sci, Chandler House, London WC1N 1PF, England.
EM bronwen.evans@ucl.ac.uk
FU King Abdul Aziz University, Saudi Arabia
FX This research was supported by a scholarship from King Abdul Aziz
   University, Saudi Arabia, to the second author.
CR Al-Ani S., 1978, DEV DISTRIBUTION QAA, P103
   Al-Tamimi J., 2007, P 16 INT C PHON SCI
   ALLAN D, 1992, OXFORD PLACEMENT TES, V1
   Amayreh MM, 1998, J SPEECH LANG HEAR R, V41, P642, DOI 10.1044/jslhr.4103.642
   BANIYASIN R, 1987, Z DEUT MORGENLAND G, V137, P297
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Chladkova K, 2011, J ACOUST SOC AM, V130, pEL186, DOI 10.1121/1.3629135
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Docherty G. J., 2011, P INT C PHON SCI HON
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P, 2011, J ACOUST SOC AM, V129, pEL1, DOI 10.1121/1.3525042
   Evans B. G., 2007, P INT C PHON SCI SAA
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   FERGUSON CA, 1959, WORD, V15, P325, DOI 10.1080/00437956.1959.11659702
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege James, 2002, INTEGRATED VIEW LANG, P217
   FLEGE JE, 1981, TESOL QUART, V15, P443, DOI 10.2307/3586485
   Flege JE, 1999, SEC LANG ACQ RES, P101
   Giannokopoulou A., 2017, PEER REV J
   GOTTFRIED TL, 1988, LANG SPEECH, V31, P57, DOI 10.1177/002383098803100103
   Harnsberger JD, 2001, J ACOUST SOC AM, V110, P489, DOI 10.1121/1.1371758
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   Holes C., 2004, MODERN ARABIC STRUCT
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P., 2007, J ACOUST SOC AM, V122, P1625
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Jia G, 2006, J ACOUST SOC AM, V119, P1118, DOI 10.1121/1.2151806
   Khattab G., 1999, LEEDS WORKING PAPERS, V7, P79
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   Morrison GS, 2002, P N W LING C 2002, P29
   Nickerson C, 2013, J BUS TECH COMMUN, V27, P329, DOI 10.1177/1050651913479930
   Peperkamp Sharon, 2015, PHONETICS PHONOLOGY, P71, DOI 10.1075/cilt.335.04pep
   Shafiro V, 2013, LANG SPEECH, V56, P145, DOI 10.1177/0023830912442925
   Strange W, 2007, J ACOUST SOC AM, V122, P1111, DOI 10.1121/1.2749716
   van Dommelen WA, 2010, SPEECH COMMUN, V52, P968, DOI 10.1016/j.specom.2010.05.001
   Watson J.C.E., 2002, PHONOLOGY MORPHOLOGY
   Wells J. C., 1962, THESIS
   Wells J. C., 1982, ACCENTS ENGLISH
NR 44
TC 5
Z9 5
U1 1
U2 6
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAY
PY 2018
VL 68
BP 15
EP 31
DI 10.1016/j.wocn.2018.01.002
PG 17
WC Linguistics; Language & Linguistics
SC Linguistics
GA GF8OY
UT WOS:000432233400002
DA 2021-02-24
ER

PT J
AU Wang, B
   Wong, W
AF Wang, Brian
   Wong, Willy
TI Real time hearing enhancement in crowded social environments with noise
   gating
SO SPEECH COMMUNICATION
LA English
DT Article
ID SPEECH ENHANCEMENT; SPEAKING-RATE; CLEAR SPEECH; INTELLIGIBILITY; AIDS
AB An extension of the noise gating method for speech enhancement in crowded social environments was investigated. Parallel noise gating involves processing the same sound stream through noise gating several times before averaging to obtain the output. A voice activity detection module is used to check for continuity in pitch and formant frequency to help identify the target speaker. The output shows reduced signal distortion and digital artifact and was verified through both objective and subjective tests. A listening test involving 10 subjects in a low-context Speech Perception in Noise task with crowd noise mixed in at 0 dB SNR yielded an average word recognition accuracy of 87% compared to 56% for the standard implementation of noise gating and 48% for the original noisy signal. Similar results were found for 5 and 10 dB SNR although the improvements were less dramatic. In all cases, parallel noise gating scored significantly higher in terms of intelligibility and clarity when compared to the standard implementation of noise gating as well as the original noisy signal. The algorithm has the computational speed to allow for real time processing and can be easily adapted to work with other speech separation methods.
C1 [Wang, Brian; Wong, Willy] Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON, Canada.
RP Wong, W (corresponding author), Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON, Canada.
EM brianzz.wang@utoronto.ca; willy.wong@utoronto.ca
FU Natural Science and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC) [458039]
FX WW acknowledges the support of the Natural Science and Engineering
   Research Council of Canada for this work (Grant no. 458039).
CR Abel SM, 2000, J ACOUST SOC AM, V108, P743, DOI 10.1121/1.429607
   Alexander J., 2016, CAN AUDIOL, V3, P4
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   Bentler R A, 2000, Am J Audiol, V9, P84, DOI 10.1044/1059-0889(2000/010)
   Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Breithaupt C, 2011, IEEE T AUDIO SPEECH, V19, P277, DOI 10.1109/TASL.2010.2047681
   BROOKS DN, 1994, BRIT J AUDIOL, V28, P91, DOI 10.3109/03005369409077919
   Chisolm Theresa Hnath, 2007, Trends Amplif, V11, P73, DOI 10.1177/1084713807300879
   Deng L, 2003, IEEE T SPEECH AUDI P, V11, P568, DOI 10.1109/TSA.2003.818076
   Eisenberg LS, 1998, J SPEECH LANG HEAR R, V41, P327, DOI 10.1044/jslhr.4102.327
   Esch T, 2009, INT CONF ACOUST SPEE, P4409, DOI 10.1109/ICASSP.2009.4960607
   Gerkmann T, 2015, IEEE SIGNAL PROC MAG, V32, P55, DOI 10.1109/MSP.2014.2369251
   Ghanbari Y, 2006, SPEECH COMMUN, V48, P927, DOI 10.1016/j.specom.2005.12.002
   Hartley D, 2010, J AM ACAD AUDIOL, V21, P642, DOI 10.3766/jaaa.21.10.4
   Hornsby BWY, 2006, J AM ACAD AUDIOL, V17, P432, DOI 10.3766/jaaa.17.6.5
   Hu GN, 2004, IEEE T NEURAL NETWOR, V15, P1135, DOI 10.1109/TNN.2004.832812
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2007, J ACOUST SOC AM, V122, pEL128, DOI 10.1121/1.2772401
   Kaladharan N., 2014, INT J COMPUTER APPL, V96, P45, DOI DOI 10.5120/16858-6739
   Kasi K, 2002, INT CONF ACOUST SPEE, P361
   Killion M C, 1993, HEARING J, V46, P31
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Killion MC, 1997, BRIT J AUDIOL, V31, P141, DOI 10.3109/03005364000000016
   Krause JC, 2002, J ACOUST SOC AM, V112, P2165, DOI 10.1121/1.1509432
   Krishnamoorthy P, 2009, IETE TECH REV, V26, P137, DOI 10.4103/0256-4602.49103
   Krishnamurthy N, 2009, IEEE T AUDIO SPEECH, V17, P1394, DOI 10.1109/TASL.2009.2015084
   LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699
   Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617
   Luts H, 2010, J ACOUST SOC AM, V127, P1491, DOI 10.1121/1.3299168
   MADELL JR, 1992, EAR HEARING, V13, P102, DOI 10.1097/00003446-199204000-00006
   Malah D, 1999, INT CONF ACOUST SPEE, P789, DOI 10.1109/ICASSP.1999.759789
   Mauger SJ, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/6/065007
   May T, 2012, IEEE T AUDIO SPEECH, V20, P108, DOI 10.1109/TASL.2011.2158309
   McCormack A, 2013, INT J AUDIOL, V52, P360, DOI 10.3109/14992027.2013.769066
   Mens LHM, 2011, INT J AUDIOL, V50, P27, DOI 10.3109/14992027.2010.521199
   Mueller HG, 1990, HEAR J, V43, P14
   Mustafa K, 2006, IEEE T AUDIO SPEECH, V14, P435, DOI 10.1109/TSA.2005.855840
   PAYTON KL, 1994, J ACOUST SOC AM, V95, P1581, DOI 10.1121/1.408545
   Plapous C, 2006, IEEE T AUDIO SPEECH, V14, P2098, DOI 10.1109/TASL.2006.872621
   Radfar MH, 2011, INT CONF ACOUST SPEE, P4468
   Radfar MH, 2007, IEEE T AUDIO SPEECH, V15, P2299, DOI 10.1109/TASL.2007.904233
   Ramirez J, 2004, INT CONF ACOUST SPEE, P1093
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Schotz S., 2005, P FONETIK 2005, P87
   Shamma SA, 2010, CURR OPIN NEUROBIOL, V20, P361, DOI 10.1016/j.conb.2010.03.009
   Sheffield A. E., 1999, J ACOUST SOC AM, V106, P2180
   Shinn-Cunningham B., 2009, HEARING J, V62, P10, DOI DOI 10.1097/01
   Singh Gurjit, 2007, Canadian Acoustics, V35, P74
   SoundJay.com, 2015, SOUNDJ FREE SOUND EF
   Stone MA, 2002, EAR HEARING, V23, P325, DOI 10.1097/00003446-200208000-00008
   Tjaden K, 1998, J SPEECH LANG HEAR R, V41, P976, DOI 10.1044/jslhr.4105.976
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   van Wijngaarden SJ, 2002, J ACOUST SOC AM, V112, P3004, DOI 10.1121/1.1512289
   Wang D. L., 2006, SPEECH SEPARATION HU
   Wang Y., 2014, THESIS
   Widrow B, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P7, DOI 10.1109/ASSPCC.2000.882437
   Yang LP, 2005, J ACOUST SOC AM, V117, P1001, DOI 10.1121/1.1852873
   Zahorian SA, 2008, J ACOUST SOC AM, V123, P4559, DOI 10.1121/1.2916590
NR 59
TC 0
Z9 0
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD MAY
PY 2018
VL 99
BP 173
EP 182
DI 10.1016/j.specom.2018.03.010
PG 10
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA GP4YI
UT WOS:000440877900017
DA 2021-02-24
ER

PT J
AU Foote, JA
   Trofimovich, P
AF Foote, Jennifer A.
   Trofimovich, Pavel
TI Is It Because of My Language Background? A Study of Language Background
   Influence on Comprehensibility Judgments
SO CANADIAN MODERN LANGUAGE REVIEW-REVUE CANADIENNE DES LANGUES VIVANTES
LA English
DT Article
DE comprehensibility; intelligibility; language background; pronunciation;
   speech perception
ID SPEECH-INTELLIGIBILITY BENEFIT; FOREIGN-ACCENT; ENGLISH; PROFICIENCY;
   PERCEPTION; LEARNERS; LISTENER; SPEAKERS; RATINGS; STRESS
AB This study examines the role of listeners' native language (L1) background in judgments of comprehensibility (ease of understanding) for speakers from same and different L1 backgrounds, to determine the extent of a shared second language (L2) comprehensibility benefit. Forty L2 English speakers from Mandarin, French, Hindi, and English backgrounds (10 per group) listened to speech samples from 30 L2 English speakers from Mandarin, French, and Hindi backgrounds (10 per group). Listeners first evaluated each speaker's comprehensibility and provided verbal reports indicating their reasons for each rating. To estimate pronunciation influences on comprehensibility, listeners then rated each speaker for four speech measures (segmental and word stress errors, intonation, speech rate). Results revealed that different speech measures were associated with comprehensibility ratings for different listener-speaker groups, and that a match in L1 background accounted for additional unique variance in comprehensibility ratings, but only for the Mandarin listeners and speakers. Verbal reports indicated that listeners more often considered L1 a benefit when rating speakers from their own L1 and a detriment when evaluating speakers from a different L1. Findings overall point to small effects of shared L1 background on comprehensibility, suggesting alternative priorities for teaching and researching comprehensible L2 speech.
C1 [Foote, Jennifer A.] Univ Alberta, Fac Extens, 1-024 Enterprise Sq,10230 Jasper Ave, Edmonton, AB T5J 4P6, Canada.
RP Foote, JA (corresponding author), Univ Alberta, Fac Extens, 1-024 Enterprise Sq,10230 Jasper Ave, Edmonton, AB T5J 4P6, Canada.
EM jfoote@ualberta.ca
RI van Dover, Robert/B-6362-2011
OI van Dover, Robert/0000-0002-6166-5650
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC)
FX This research was supported by the Social Sciences and Humanities
   Research Council of Canada. We would like to thank our participants for
   their involvement in this study. We would also like to thank our
   anonymous reviewers who provided valuable feedback and improved the
   final version immensely.
CR Alghetami G., 2011, P 2 PRON 2 LANG LEAR, P30
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Crowther D., 2016, J 2 LANGUAGE PRONUNC, V2, P160, DOI DOI 10.1075/JSLP.2.2.02CR0
   Crowther D, 2015, TESOL QUART, V49, P814, DOI 10.1002/tesq.203
   Crowther D, 2015, MOD LANG J, V99, P80, DOI 10.1111/modl.12185
   Deterding David, 2006, WORLD ENGLISH, V25, P391, DOI DOI 10.1111/J.1467-971X.2006.00478.X
   Field J, 2005, TESOL QUART, V39, P399, DOI 10.2307/3588487
   Gass S.M., 2000, STIMULATED RECALL ME
   Hahn LD, 2004, TESOL QUART, V38, P201, DOI 10.2307/3588378
   Harding L., 2008, MELBOURNE PAPERS LAN, V13, P1
   Harding L, 2012, LANG TEST, V29, P163, DOI 10.1177/0265532211421161
   Hayes-Harb R, 2009, J ACOUST SOC AM, V125, P2761, DOI [10.1121/1.4808694, DOI 10.1121/1.4808694]
   Hayes-Harb R, 2008, J PHONETICS, V36, P664, DOI 10.1016/j.wocn.2008.04.002
   Hayes-Harb Rachel, 2015, J 2 LANGUAGE PRONUCI, V1, P43, DOI DOI 10.1075/JSLP.1.1.02HAY
   Isaacs T, 2011, INT STUDENTS C UNPUB
   Isaacs T, 2012, STUD SECOND LANG ACQ, V34, P475, DOI 10.1017/S0272263112000150
   Jenkins J, 2002, APPL LINGUIST, V23, P83, DOI 10.1093/applin/23.1.83
   Jun H.G, P 1 PRON 2 LANG LEAR, P53
   Kang O, 2012, LANG ASSESS Q, V9, P249, DOI 10.1080/15434303.2011.642631
   Kang O, 2010, SYSTEM, V38, P301, DOI 10.1016/j.system.2010.01.005
   Kang O, 2010, MOD LANG J, V94, P554, DOI 10.1111/j.1540-4781.2010.01091.x
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   Levis JM, 2005, TESOL QUART, V39, P369, DOI 10.2307/3588485
   Major RC, 2002, TESOL QUART, V36, P173, DOI 10.2307/3588329
   Matsuura H., 2007, SYSTEM, V35, P293, DOI DOI 10.1016/J.SYSTEM.2007.03.003
   Matsuura H, 2014, SYSTEM, V46, P143, DOI 10.1016/j.system.2014.07.015
   Munro M. J., 2006, SYSTEM, V34, P520, DOI DOI 10.1016/J.SYSTEM.2006.09.004
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   Munro MJ, 2006, STUD SECOND LANG ACQ, V28, P111, DOI 10.1017/S0272263106060049
   Munro Murray J., 2001, STUDIES 2 LANGUAGE A, V23, P451, DOI DOI 10.1111/LANG.12082
   O'Brien MG, 2016, STUD SECOND LANG ACQ, V38, P587, DOI 10.1017/S0272263115000418
   O'Brien MG, 2014, LANG LEARN, V64, P715, DOI 10.1111/lang.12082
   Saito K, 2017, APPL LINGUIST, V38, P439, DOI 10.1093/applin/amv047
   SMITH BL, 2003, P 15 INT C PHON SCI, P519
   Smith BL, 2011, J PHONETICS, V39, P115, DOI 10.1016/j.wocn.2010.11.005
   SMITH LE, 1982, LANG LEARN, V32, P259, DOI 10.1111/j.1467-1770.1982.tb00971.x
   Stibbard RM, 2006, J ACOUST SOC AM, V120, P433, DOI 10.1121/1.2203595
   Trofimovich P, 2016, BILING-LANG COGN, V19, P122, DOI 10.1017/S1366728914000832
   Trofimovich P, 2012, BILING-LANG COGN, V15, P905, DOI 10.1017/S1366728912000168
   Winke P, 2013, TESOL QUART, V47, P762, DOI 10.1002/tesq.73
   Xie X, 2013, J PHONETICS, V41, P369, DOI 10.1016/j.wocn.2013.06.003
NR 41
TC 4
Z9 4
U1 1
U2 10
PU CANADIAN MODERN LANGUAGE REV
PI N YORK
PA UNIV TORONTO PRESS, JOURNALS DIVISION, 5201 DUFFERIN ST,, N YORK,
   ONTARIO M3H 5T8, CANADA
SN 0008-4506
EI 1710-1131
J9 CAN MOD LANG REV
JI Can. Mod. Lang. Rev.-Rev. Can. Lang. Vivantes
PD MAY
PY 2018
VL 74
IS 2
BP 253
EP 278
DI 10.3138/cmlr.2017-0011
PG 26
WC Linguistics
SC Linguistics
GA GM3YN
UT WOS:000438048900003
DA 2021-02-24
ER

PT J
AU Chen, A
   Peter, V
   Wijnen, F
   Schnack, H
   Burnham, D
AF Chen, Ao
   Peter, Varghese
   Wijnen, Frank
   Schnack, Hugo
   Burnham, Denis
TI Are lexical tones musical? Native language's influence on neural
   response to pitch in different domains
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Lexical tones; Musical pitch; Mismatch negativity; Cross-domain
   correlation
ID MISMATCH NEGATIVITY MMN; EVENT-RELATED POTENTIALS; AUDITORY-CORTEX;
   PERCEPTUAL REORGANIZATION; LINGUISTIC EXPERIENCE; PHONETIC PERCEPTION;
   CONGENITAL AMUSIA; SPEECH-PERCEPTION; MELODIC CONTOUR; 1ST YEAR
AB Language experience shapes musical and speech pitch processing. We investigated whether speaking a lexical tone language natively modulates neural processing of pitch in language and music as well as their correlation. We tested tone language (Mandarin Chinese), and non-tone language (Dutch) listeners in a passive oddball paradigm measuring mismatch negativity (MMN) for (i) Chinese lexical tones and (ii) three-note musical melodies with similar pitch contours. For lexical tones, Chinese listeners showed a later MMN peak than the non tone language listeners, whereas for MMN amplitude there were no significant differences between groups. Dutch participants also showed a late discriminative negativity (LDN). In the music condition two MMNs, corresponding to the two notes that differed between the standard and the deviant were found for both groups, and an LDN were found for both the Dutch and the Chinese listeners. The music MMNs were significantly right lateralized. Importantly, significant correlations were found between the lexical tone and the music MMNs for the Dutch but not the Chinese participants. The results suggest that speaking a tone language natively does not necessarily enhance neural responses to pitch either in language or in music, but that it does change the nature of neural pitch processing: non-tone language speakers appear to perceive lexical tones as musical, whereas for tone language speakers, lexical tones and music may activate different neural networks. Neural resources seem to be assigned differently for the lexical tones and for musical melodies, presumably depending on the presence or absence of long-term phonological memory traces.
C1 [Chen, Ao; Wijnen, Frank; Schnack, Hugo] Univ Utrecht, Utrecht Inst Linguist OTS, Utrecht, Netherlands.
   [Chen, Ao; Peter, Varghese; Burnham, Denis] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
   [Schnack, Hugo] Univ Med Ctr Utrecht, Dept Psychiat, Brain Ctr Rudolf Magnus, Utrecht, Netherlands.
   [Chen, Ao] Beijing Language & Culture Univ, Sch Commun Sci, Beijing, Peoples R China.
   [Peter, Varghese] Macquarie Univ, Dept Linguist, N Ryde, NSW 2109, Australia.
RP Chen, A (corresponding author), Beijing Language & Culture Univ, 15 Xueyuan Rd, Beijing 100083, Peoples R China.
EM irischen71@hotmail.com
RI Burnham, Denis/L-3742-2019
OI Burnham, Denis/0000-0002-1980-3458; Wijnen, Frank/0000-0002-7196-6000;
   Peter, Varghese/0000-0002-4007-507X
FU Endeavor Research Fellowship - Australian Department of Education
   [ERF_PDR_113381_2013]; Australian Research CouncilAustralian Research
   Council [DP110105123]
FX This study was supported by Endeavor Research Fellowship funded by
   Australian Department of Education to the first author, with grant
   number ERF_PDR_113381_2013.The study was also supported by Discovery
   Project Grant funded by Australian Research Council to the last author,
   with grant number DP110105123. We also thank two anonymous reviewers for
   their helpful comments on an earlier version of the manuscript.
CR Alexander J.A., 2005, LEXICAL TONE PERCEPT, P397
   Alho K, 1998, PSYCHOPHYSIOLOGY, V35, P211, DOI 10.1111/1469-8986.3520211
   Bidelman GM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060676
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Boersma P., 2011, PRAAT DOING PHONETIC
   Brusini P, 2017, NEUROPSYCHOLOGIA, V98, P4, DOI 10.1016/j.neuropsychologia.2016.08.015
   Ceponiene R, 1998, EVOKED POTENTIAL, V108, P345, DOI 10.1016/S0168-5597(97)00081-6
   Ceponiene R, 2004, PSYCHOPHYSIOLOGY, V41, P130, DOI 10.1111/j.1469-8986.2003.00138.x
   Chandrasekaran B, 2007, NEUROREPORT, V18, P1963, DOI 10.1097/WNR.0b013e3282f213c5
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Chen A., 2016, P 14 INT C MUS PERC, P364
   Chen A, 2016, LANG COGN NEUROSCI, V31, P751, DOI 10.1080/23273798.2016.1156715
   Chen A, 2016, PEERJ, V4, DOI 10.7717/peerj.1580
   Chen A, 2015, LANG SCI, V48, P62, DOI 10.1016/j.langsci.2014.12.002
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   DehaeneLambertz G, 1997, NEUROREPORT, V8, P919, DOI 10.1097/00001756-199703030-00021
   Delogu Franco, 2006, Cogn Process, V7, P203, DOI 10.1007/s10339-006-0146-7
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Francis AL, 2003, PERCEPT PSYCHOPHYS, V65, P1029, DOI 10.3758/BF03194832
   Giuliano RJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00146
   Gu F, 2013, NEUROIMAGE, V83, P637, DOI 10.1016/j.neuroimage.2013.02.080
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   HARI R, 1984, NEUROSCI LETT, V50, P127, DOI 10.1016/0304-3940(84)90474-9
   HUME E, 2001, ROLE SPEECH PERCEPTI, P3
   Jacobsen T, 2004, PSYCHOPHYSIOLOGY, V41, P654, DOI 10.1111/1469-8986.2004.00175.x
   Jacobsen T, 2003, CLIN NEUROPHYSIOL, V114, P1133, DOI 10.1016/S1388-2457(03)00043-9
   Kaan E, 2007, BRAIN RES, V1148, P113, DOI 10.1016/j.brainres.2007.02.019
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426
   Krishnan A, 2010, J NEUROLINGUIST, V23, P81, DOI 10.1016/j.jneuroling.2009.09.001
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Levanen S, 1996, CEREB CORTEX, V6, P288, DOI 10.1093/cercor/6.2.288
   Luo H, 2006, P NATL ACAD SCI USA, V103, P19558, DOI 10.1073/pnas.0607065104
   LYNCH MP, 1990, PSYCHOL SCI, V1, P272, DOI 10.1111/j.1467-9280.1990.tb00213.x
   LYNCH MP, 1992, PERCEPT PSYCHOPHYS, V52, P599, DOI 10.3758/BF03211696
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   MOULINES E, 1995, SPEECH COMMUN, V16, P175, DOI 10.1016/0167-6393(94)00054-E
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Nan Y, 2016, BIOL PSYCHOL, V113, P59, DOI 10.1016/j.biopsycho.2015.11.010
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Patel A. D., 2008, MUSIC LANGUAGE BRAIN
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Peter V, 2012, PSYCHOPHYSIOLOGY, V49, P1590, DOI 10.1111/j.1469-8986.2012.01472.x
   Ren GQ, 2009, NEUROSCIENCE, V162, P87, DOI 10.1016/j.neuroscience.2009.04.021
   Rinker T, 2007, NEUROSCI LETT, V413, P99, DOI 10.1016/j.neulet.2006.11.033
   Schellenberg EG, 1999, J EXP CHILD PSYCHOL, V74, P107, DOI 10.1006/jecp.1999.2511
   Schroger E, 1996, NEUROREPORT, V7, P3005, DOI 10.1097/00001756-199611250-00041
   Shestakova A, 2002, NEUROREPORT, V13, P1813, DOI 10.1097/00001756-200210070-00025
   Stevens CJ, 2013, PSYCHOL MUSIC, V41, P59, DOI 10.1177/0305735611415749
   TRAINOR LJ, 1992, J EXP PSYCHOL HUMAN, V18, P394, DOI 10.1037/0096-1523.18.2.394
   Trainor LJ, 2002, J COGNITIVE NEUROSCI, V14, P430, DOI 10.1162/089892902317361949
   Trehub SE, 2006, COGNITION, V100, P73, DOI 10.1016/j.cognition.2005.11.006
   TREHUB SE, 1984, CHILD DEV, V55, P821, DOI 10.2307/1130133
   Trehub SE, 1999, J EXP PSYCHOL HUMAN, V25, P965, DOI 10.1037/0096-1523.25.4.965
   van Zuijen TL, 2005, COGNITIVE BRAIN RES, V23, P270, DOI 10.1016/j.cogbrainres.2004.10.007
   Vuust P, 2012, NEUROPSYCHOLOGIA, V50, P1432, DOI 10.1016/j.neuropsychologia.2012.02.028
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Yoder PJ, 2004, J CLIN EXP NEUROPSYC, V26, P320, DOI 10.1080/13803390490510040
   Zachau S, 2005, NEUROREPORT, V16, P2015, DOI 10.1097/00001756-200512190-00009
NR 69
TC 3
Z9 3
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD MAY-JUL
PY 2018
VL 180
BP 31
EP 41
DI 10.1016/j.bandl.2018.04.006
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA GJ6XX
UT WOS:000435528800005
PM 29689493
DA 2021-02-24
ER

PT J
AU Koiek, S
   Pourbakht, A
   Tahaie, SAA
   Mahdavi, ME
   Sanei, SH
AF Koiek, Shno
   Pourbakht, Akram
   Tahaie, Seyed Ali Akbar
   Mahdavi, Mohammad Ebrahim
   Sanei, Seyed Hassan
TI Cortical and subcortical lateralization among normal 7-12 years old
   children by using speech perception in noise and acceptable noise level
SO MEDICAL SCIENCE
LA English
DT Article
DE Lateralization; Cortex; Subcortex; Right-handed; Left-handed; ANL;
   PARWIN
AB Lateralization of processing acoustic signal is not only limited to cortex area, but also involves subcortex region. Persian Auditory Recognition of Word-in-Noise (PARWIN) test which is the Persian version of Word in Noise test has been developed by Mahdavi et al. It contains three 35-monosyllabic words lists that are presented in the presence of six talkers babble noise as distracting noise. PARWIN test is practicable in children of age 7-12 years with content validity of 79%. Persian Auditory Recognition of Word-in-Noise test assesses speech perception of individuals by presenting monosyllabic words presented in babble noise. Acceptable noise level measures maximum amount of background noise individuals are willing to accept. This study was designed to examine lateralization at the level of cortical and subcortical area by using PARWIN and ANL. Fifty two normal 7-12 years old children were participated in this study. The difference between right and left ANL as well as right and left PARWIN was considered among all participants. Moreover, the different of right data between right-handed and left-handed children as well as the difference of left results between these two groups of children was explored. Finally, the relationship between right ANL, left ANL, and binaural ANL was taken into account. A significant difference between right ANL and left ANL as well as right PARWIN and left PARWIN was found among right-handed children at p=0.000. The difference of results between two groups of right-handed and left-handed children was revealed only for right PARWIN at sig=0.013. Furthermore, a significant positive correlation was found between right ANL, left ANL, and binaural ANL (p=0.000). The results confirmed the lateralization at the level of cortex and subcortex due to the significant differences between right and left results of PARWIN test and ANL among right-handed children. It is not necessary to administer right, left, and binaural ANL separately due to the strong positive relationship between right, left, and binaural ANL.
C1 [Koiek, Shno; Pourbakht, Akram; Tahaie, Seyed Ali Akbar] Iran Univ Med Sci, Sch Rehabil Sci, Dept Audiol, Tehran, Iran.
   [Mahdavi, Mohammad Ebrahim] Shahid Beheshti Univ Med Sci, Sch Rehabil, Dept Audiol, Tehran, Iran.
   [Sanei, Seyed Hassan] Iran Univ Med Sci, Sch Rehabil Sci, Dept Basic Sci, Tehran, Iran.
RP Pourbakht, A (corresponding author), Sch Rehabil Sci, Dept Audiol, Tehran, Iran.
EM pourbakht.a@iums.ac.ir
RI Mahdavi, Mohammad Ebrahim/D-6283-2013
OI Mahdavi, Mohammad Ebrahim/0000-0002-7589-7065
FU Iran University of Medical Sciences [96/S/105/1285]
FX We sincerely thank Hamid Haqani for his assistance in data selection.
   This research was supported by grant 96/S/105/1285 from Iran University
   of Medical Sciences.
CR Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   BROADBENT DE, 1964, Q J EXP PSYCHOL, V16, P359, DOI 10.1080/17470216408416392
   Broca P., 1861, B SOC ANAT PARIS, V6, P330, DOI DOI 10.1093/ACPROF:OSO/9780195177640.003.0018
   Bryden M.P, 2012, LATERALITY FUNCTIONA
   BRYDEN MP, 1963, J EXP PSYCHOL, V65, P103, DOI 10.1037/h0042773
   DAMASIO AR, 1992, SCI AM, V267, P89
   DEUTSCH G, 1993, LEFT BRAIN RIGHT BRA
   Freyaldenhoven M. C., 2006, J ED AUDIOLOGY, V13, P27
   GALABURDA AM, 1978, SCIENCE, V199, P852, DOI 10.1126/science.341314
   Harkrider Ashley W, 2005, J Am Acad Audiol, V16, P530, DOI 10.3766/jaaa.16.8.2
   Hornickel J, 2009, AUDIOL NEURO-OTOL, V14, P198, DOI 10.1159/000188533
   MAHDAVI M. E., 2016, IRANIAN RED CRESCENT, V19
   NABELEK AK, 1991, J SPEECH HEAR RES, V34, P679, DOI 10.1044/jshr.3403.679
   Nabelek AK, 2004, J SPEECH LANG HEAR R, V47, P1001, DOI 10.1044/1092-4388(2004/074)
   STEINMETZ H, 1991, ANN NEUROL, V29, P315, DOI 10.1002/ana.410290314
   STUDDERTKENNEDY M, 1970, J ACOUST SOC AM, V48, P579, DOI 10.1121/1.1912174
   Wilson RH, 2005, J REHABIL RES DEV, V42, P839, DOI 10.1682/JRRD.2005.01.0009
NR 17
TC 0
Z9 0
U1 0
U2 2
PU DISCOVERY PUBLICATION
PI TAMILNADU
PA KANYAKUMARI DISTRICT, TAMILNADU, 00000, INDIA
SN 2321-7359
EI 2321-7367
J9 MED SCI
JI Med. Sci.
PD MAY-JUN
PY 2018
VL 22
IS 91
BP 343
EP 349
PG 7
WC Medicine, Research & Experimental
SC Research & Experimental Medicine
GA GJ9KK
UT WOS:000435720100013
DA 2021-02-24
ER

PT J
AU Marian, V
   Hayakawa, S
   Lam, TQ
   Schroeder, SR
AF Marian, Viorica
   Hayakawa, Sayuri
   Lam, Tuan Q.
   Schroeder, Scott R.
TI Language Experience Changes Audiovisual Perception
SO BRAIN SCIENCES
LA English
DT Article
DE speech perception; bilingualism; multisensory integration; McGurk
   effect; language
ID AUTISM SPECTRUM DISORDERS; VISUAL SPEECH-PERCEPTION;
   INDIVIDUAL-DIFFERENCES; SELECTIVE ATTENTION; HEARING LIPS; BILINGUALISM;
   INTEGRATION; SUSCEPTIBILITY; LISTENERS; CHILDREN
AB Can experience change perception? Here, we examine whether language experience shapes the way individuals process auditory and visual information. We used the McGurk effect-the discovery that when people hear a speech sound (e.g., ba) and see a conflicting lip movement (e.g., ga), they recognize it as a completely new sound (e.g., da). This finding that the brain fuses input across auditory and visual modalities demonstrates that what we hear is profoundly influenced by what we see. We find that cross-modal integration is affected by language background, with bilinguals experiencing the McGurk effect more than monolinguals. This increased reliance on the visual channel is not due to decreased language proficiency, as the effect was observed even among highly proficient bilinguals. Instead, we propose that the challenges of learning and monitoring multiple languages have lasting consequences for how individuals process auditory and visual information.
C1 [Marian, Viorica; Hayakawa, Sayuri] Northwestern Univ, Dept Commun Sci & Disorders, Evanston, IL 60201 USA.
   [Lam, Tuan Q.] Loyola Univ, Dept Psychol Sci, New Orleans, LA 70118 USA.
   [Schroeder, Scott R.] Hofstra Univ, Dept Speech Language Hearing Sci, Hempstead, NY 11549 USA.
RP Marian, V (corresponding author), Northwestern Univ, Dept Commun Sci & Disorders, Evanston, IL 60201 USA.
EM v-marian@northwestern.edu; sayuri.hayakawa@northwestern.edu;
   tlam@loyno.edu; Scott.R.Schroeder@hofstra.edu
RI Hayakawa, Sayuri/AAE-6252-2020
OI Hayakawa, Sayuri/0000-0001-9863-1406; Schroeder,
   Scott/0000-0003-0616-3276
FU National Institute of Child Health and Human DevelopmentUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [RO1HD059858]; National Institute on Deafness
   and Other Communication DisordersUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD)
   [T32-DC009399-04]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH & HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD059858, R01HD059858, R01HD059858, R01HD059858] Funding Source: NIH
   RePORTER
FX This research was funded by the National Institute of Child Health and
   Human Development grant number RO1HD059858 and the National Institute on
   Deafness and Other Communication Disorders grant number T32-DC009399-04.
CR Alladi S, 2013, NEUROLOGY, V81, P1938, DOI 10.1212/01.wnl.0000436620.33155.a4
   Aloufy S, 1996, BRAIN LANG, V53, P51, DOI 10.1006/brln.1996.0036
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Best C. T., 1994, DEV SPEECH PERCEPT, V167, P224
   Bialystok E, 2001, BILINGUALISM DEV
   Bialystok E, 2007, NEUROPSYCHOLOGIA, V45, P459, DOI 10.1016/j.neuropsychologia.2006.10.009
   Bialystok E, 2011, J EXP CHILD PSYCHOL, V110, P461, DOI 10.1016/j.jecp.2011.05.005
   Bovo R, 2009, ACTA OTORHINOLARYNGO, V29, P203
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Carvalho FR, 2017, APPETITE, V108, P383, DOI 10.1016/j.appet.2016.10.026
   Chen Y., 2007, P 16 INT C PHON SCI, P2177
   Costa A, 2008, COGNITION, V106, P59, DOI 10.1016/j.cognition.2006.12.013
   CUMMINS J, 1978, J CROSS CULT PSYCHOL, V9, P131, DOI 10.1177/002202217892001
   Fan SP, 2015, PSYCHOL SCI, V26, P1090, DOI 10.1177/0956797615574699
   Fennell CT, 2007, CHILD DEV, V78, P1510, DOI 10.1111/j.1467-8624.2007.01080.x
   Fixmer E., 1998, P AUD VIS SPEECH PRO, P27
   FRANK RA, 1988, CHEM SENSES, V13, P445, DOI 10.1093/chemse/13.3.445
   Fuster-Duran A., 1996, SPEECHREADING HUMANS, P135, DOI DOI 10.1007/978-3-662-13015-5_9
   GALAMBOS SJ, 1990, COGNITION, V34, P1, DOI 10.1016/0010-0277(90)90030-N
   Goetz P. J., 2003, BILING-LANG COGN, V6, P1, DOI DOI 10.1017/S1366728903001007
   Gollan TH, 2008, J MEM LANG, V58, P787, DOI 10.1016/j.jml.2007.07.001
   Gollan TH, 2011, J EXP PSYCHOL GEN, V140, P186, DOI 10.1037/a0022256
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Grosjean Francois, 2010, BILINGUAL LIFE REALI
   Ho HN, 2014, SCI REP-UK, V4, DOI 10.1038/srep05527
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Kuhl P., 1992, SPEECH PERCEPTION LI, P121, DOI [10.1126/science.1736364, DOI 10.1126/SCIENCE.1736364]
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Magnotti JF, 2015, PSYCHON B REV, V22, P701, DOI 10.3758/s13423-014-0722-2
   Maguire EA, 2000, P NATL ACAD SCI USA, V97, P4398, DOI 10.1073/pnas.070039597
   Maier JX, 2004, NEURON, V43, P177, DOI 10.1016/j.neuron.2004.06.027
   Marian V., 2003, BILING-LANG COGN, V6, P97, DOI DOI 10.1017/S1366728903001068
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   MARKS LE, 1975, PSYCHOL BULL, V82, P303, DOI 10.1037/0033-2909.82.3.303
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Navarra J, 2010, BRAIN RES, V1323, P84, DOI 10.1016/j.brainres.2010.01.059
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Price C, 2005, TRENDS COGN SCI, V9, P271, DOI 10.1016/j.tics.2005.03.009
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   SALDANA HM, 1993, PERCEPT PSYCHOPHYS, V54, P406, DOI 10.3758/BF03205276
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   Sekiyama K., 1994, Journal of the Acoustical Society of Japan (E), V15, P143
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Shams L, 2002, COGNITIVE BRAIN RES, V14, P147, DOI 10.1016/S0926-6410(02)00069-1
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Thierry G, 2007, P NATL ACAD SCI USA, V104, P12530, DOI 10.1073/pnas.0609927104
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   WALKER S, 1995, PERCEPT PSYCHOPHYS, V57, P1124, DOI 10.3758/BF03208369
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   Ward J, 2005, COGN NEUROPSYCHOL, V22, P28, DOI 10.1080/02643290442000022
NR 63
TC 2
Z9 2
U1 0
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD MAY
PY 2018
VL 8
IS 5
AR 85
DI 10.3390/brainsci8050085
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA GJ3JU
UT WOS:000435190800011
PM 29751619
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Yu, L
AF Yu, Liang
TI Brain evoked potential Analysis of Effects of Popular Music Training on
   Adolescents' Cognitive Neurobehavioral Plasticity
SO NEUROQUANTOLOGY
LA English
DT Article
DE Pop Music Training; Cognitive Function Transmission; Brain Plasticity
ID SPEECH-PERCEPTION
AB In order to study the impact of pop music on cognitive neurobehavioral plasticity through the use of ERP technology, this study selected adolescents as the research target group, and studied the impact of music training on multiple cognitive functions, influence characteristics, brain structure and brain functional connection in different stages of popular music training through experimental analysis. The results indicated that pop music training not only enabled adolescents to acquire corresponding musical skill and music knowledge reserve, but also exerted a profound effect on adolescents' cerebral neural development. Meanwhile, the brain plasticity could also be improved, including the neural connection and information communication in the nervous system, making it possible for young people to exercise and develop multiple brain regions. The research results of this paper bear important reference significance for the application of pop music in adolescent education.
C1 [Yu, Liang] Shaanxi Normal Univ, Xian 710000, Shaanxi, Peoples R China.
RP Yu, L (corresponding author), Shaanxi Normal Univ, Xian 710000, Shaanxi, Peoples R China.
EM yuliang0954@sina.com
CR Dunlap KD, 2016, BRAIN BEHAV EVOLUT, V87, P156, DOI 10.1159/000446907
   Jain C, 2015, AUDIOL RES, V5, P5, DOI 10.4081/audiores.2015.111
   Karbach J, 2015, REV ARGENT CIENC COM, V7, P64
   Kim P, 2016, NEW DIR CHILD ADOLES, V153, P47, DOI 10.1002/cad.20168
   McEwen BS, 2016, ANN NY ACAD SCI, V1373, P56, DOI 10.1111/nyas.13020
   Schellenberg EG, 2015, ANN NY ACAD SCI, V1337, P170, DOI 10.1111/nyas.12627
   Sherwood CC, 2017, ANNU REV ANTHROPOL, V46, P399, DOI 10.1146/annurev-anthro-102215-100009
   Szumlinski KK, 2016, BIOL PSYCHIAT, V80, P176, DOI 10.1016/j.biopsych.2016.06.004
   Tierney AT, 2015, P NATL ACAD SCI USA, V112, P10062, DOI 10.1073/pnas.1505114112
NR 9
TC 0
Z9 0
U1 2
U2 5
PU ANKA PUBLISHER
PI BORNOVA
PA 116-11 SOK NO.10 K 2 D 2, BORNOVA, IZMIR 35050, TURKEY
SN 1303-5150
J9 NEUROQUANTOLOGY
JI NeuroQuantology
PD MAY
PY 2018
VL 16
IS 5
BP 654
EP 658
DI 10.14704/nq.2018.16.5.1424
PG 5
WC Neurosciences
SC Neurosciences & Neurology
GA GH9SD
UT WOS:000434008600095
DA 2021-02-24
ER

PT J
AU Noel, JP
   Stevenson, RA
   Wallace, MT
AF Noel, Jean-Paul
   Stevenson, Ryan A.
   Wallace, Mark T.
TI Atypical audiovisual temporal function in autism and schizophrenia:
   similar phenotype, different cause
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE autism; causal inference; multisensory integration; schizophrenia;
   speech
ID ENDOGENOUS NEURAL NOISE; MULTISENSORY INTEGRATION; BINDING WINDOW;
   SPEECH-PERCEPTION; SPECTRUM; SYNCHRONY; TIME; HALLUCINATIONS; DISORDERS;
   CHILDREN
AB Binding across sensory modalities yields substantial perceptual benefits, including enhanced speech intelligibility. The coincidence of sensory inputs across time is a fundamental cue for this integration process. Recent work has suggested that individuals with diagnoses of schizophrenia (SZ) and autism spectrum disorder (ASD) will characterize auditory and visual events as synchronous over larger temporal disparities than their neurotypical counterparts. Namely, these clinical populations possess an enlarged temporal binding window (TBW). Although patients with SZ and ASD share aspects of their symptomatology, phenotypic similarities may result from distinct etiologies. To examine similarities and variances in audiovisual temporal function in these two populations, individuals diagnosed with ASD (n=46; controls n=40) and SZ (n=16, controls=16) completed an audiovisual simultaneity judgment task. In addition to standard psychometric analyses, synchrony judgments were assessed using Bayesian causal inference modeling. This approach permits distinguishing between distinct causes of an enlarged TBW: an a priori bias to bind sensory information and poor fidelity in the sensory representation. Findings indicate that both ASD and SZ populations show deficits in multisensory temporal acuity. Importantly, results suggest that while the wider TBWs in ASD most prominently results from atypical priors, the wider TBWs in SZ results from a trend toward changes in prior and weaknesses in the sensory representations. Results are discussed in light of current ASD and SZ theories and highlight that different perceptual training paradigms focused on improving multisensory integration may be most effective in these two clinical populations and emphasize that similar phenotypes may emanate from distinct mechanistic causes.
C1 [Noel, Jean-Paul] Vanderbilt Univ, Neurosci Grad Program, 7110 MRB 3 BioSci Bldg,465,21st Ave South, Nashville, TN 37235 USA.
   [Noel, Jean-Paul; Wallace, Mark T.] Vanderbilt Univ, Vanderbilt Brain Inst, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Stevenson, Ryan A.] Univ Western Ontario, Dept Psychol, London, ON, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Schulich Sch Med & Dent, Dept Psychiat, London, ON, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Schulich Sch Med & Dent, Program Neurosci, London, ON, Canada.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Psychol, Nashville, TN 37240 USA.
   [Wallace, Mark T.] Vanderbilt Univ, Med Ctr, Dept Speech & Hearing, Nashville, TN USA.
   [Wallace, Mark T.] Vanderbilt Univ, Med Ctr, Dept Psychiat & Behav Sci, Nashville, TN USA.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Pharmacol, Nashville, TN USA.
RP Noel, JP (corresponding author), Vanderbilt Univ, Neurosci Grad Program, 7110 MRB 3 BioSci Bldg,465,21st Ave South, Nashville, TN 37235 USA.
EM jean-paul.noel@vanderbilt.edu
RI Noel, Jean-Paul/I-8083-2019
OI Noel, Jean-Paul/0000-0001-5297-3363
FU National Science Foundation Graduate Research Fellowship (NSF
   GRF)National Science Foundation (NSF) [1445197]; NSERC Discovery
   GrantNatural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2017-04656]; SSHRC Insight Grant [435-2017-0936]; University of
   Western Ontario Faculty Development Research Fund; NIHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [MH109225, CA183492, HD083211]; Wallace Foundation; EUNICE KENNEDY
   SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child
   Health & Human Development (NICHD) [U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211] Funding Source: NIH
   RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute of Mental Health (NIMH) [R01MH063861, R01MH063861,
   F31MH112336, R01MH063861, R21MH109225, R01MH063861, R01MH063861,
   R01MH063861, R01MH063861, R01MH063861, R01MH063861, F31MH112336,
   R21MH109225, R01MH063861, R01MH063861, R01MH063861] Funding Source: NIH
   RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R34DC010927, R34DC010927] Funding
   Source: NIH RePORTER
FX JPN was supported by the National Science Foundation Graduate Research
   Fellowship (NSF GRF) under Grant No 1445197. RAS is funded by NSERC
   Discovery Grant (RGPIN-2017-04656), SSHRC Insight Grant (435-2017-0936),
   and the University of Western Ontario Faculty Development Research Fund.
   MTW was supported by NIH grants MH109225, CA183492, and HD083211 and the
   Wallace Foundation.
CR Andreasen NC, 1983, SCALE ASSESSMENT POS
   Andreasen NC, 1983, SCALE ASSESSMENT NEG
   Balz J, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01896
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Baum SH, 2015, JOVE-J VIS EXP, DOI 10.3791/52677
   Behrendt RP, 2004, BEHAV BRAIN SCI, V27, P771, DOI 10.1017/S0140525X04000184
   Bleuler E., 1911, DEMENTIA PRAECOX ODE
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brock J, 2012, TRENDS COGN SCI, V16, P573, DOI 10.1016/j.tics.2012.10.005
   Butler JS, 2017, CEREB CORTEX, V27, P185, DOI 10.1093/cercor/bhw375
   Calvert G., 2004, HDB MULTISENSORY PRO
   Davis G, 2015, AUTISM, V19, P351, DOI 10.1177/1362361314552198
   De Niear MA, 2017, NEURAL PLAST, V2017, DOI 10.1155/2017/3478742
   Diederich A, 2015, PSYCHOL REV, V122, P232, DOI 10.1037/a0038696
   Dinstein I, 2015, TRENDS COGN SCI, V19, P322, DOI 10.1016/j.tics.2015.04.005
   Dinstein I, 2012, NEURON, V75, P981, DOI 10.1016/j.neuron.2012.07.026
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Foucher JR, 2007, SCHIZOPHR RES, V97, P118, DOI 10.1016/j.schres.2007.08.013
   Insel T, 2010, AM J PSYCHIAT, V167, P748, DOI 10.1176/appi.ajp.2010.09091379
   Kim J, 2003, SCHIZOPHR RES, V60, P173, DOI 10.1016/S0920-9964(02)00299-2
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lewkowicz DJ, 1996, J EXP PSYCHOL HUMAN, V22, P1094, DOI 10.1037/0096-1523.22.5.1094
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   Martin B, 2013, NEUROPSYCHOLOGIA, V51, P358, DOI 10.1016/j.neuropsychologia.2012.07.002
   MCGRATH M, 1985, J ACOUST SOC AM, V77, P678, DOI 10.1121/1.392336
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Murray M.M., 2012, NEURAL BASEMULTISE
   Noel J.P., AUDIO VISUAL SENSORY
   Noel JP, 2018, IEEE T COGN DEV SYST, V10, P973, DOI 10.1109/TCDS.2017.2778141
   Noel JP, 2018, EXP BRAIN RES, V236, P1939, DOI 10.1007/s00221-018-5274-7
   Noel JP, 2017, EPILEPSY BEHAV, V70, P166, DOI 10.1016/j.yebeh.2017.02.018
   Noel JP, 2017, SCHIZOPHR RES, V179, P8, DOI 10.1016/j.schres.2016.09.021
   Noel JP, 2017, AUTISM RES, V10, P121, DOI 10.1002/aur.1633
   Noel JP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161698
   Noel JP, 2016, J VISION, V16, DOI 10.1167/16.3.21
   Noel JP, 2016, NEUROPSYCHOLOGIA, V82, P84, DOI 10.1016/j.neuropsychologia.2016.01.005
   Noel JP, 2015, SCI REP-UK, V5, DOI 10.1038/srep17467
   OVERALL JE, 1962, PSYCHOL REP, V10, P799
   Pallant J., 2013, SPSS SURVIVAL MANUAL
   Pell PJ, 2016, MOL AUTISM, V7, DOI 10.1186/s13229-016-0085-9
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pellicano E, 2012, TRENDS COGN SCI, V16, P504, DOI 10.1016/j.tics.2012.08.009
   Postmes L, 2014, SCHIZOPHR RES, V152, P41, DOI 10.1016/j.schres.2013.07.027
   Powers AR, 2012, J NEUROSCI, V32, P6263, DOI 10.1523/JNEUROSCI.6138-11.2012
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Russo N, 2010, AUTISM RES, V3, P253, DOI 10.1002/aur.152
   Schlesinger JJ, 2014, ANESTH ANALG, V118, P1249, DOI 10.1213/ANE.0000000000000222
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Shams L, 2010, TRENDS COGN SCI, V14, P425, DOI 10.1016/j.tics.2010.07.001
   Shergill SS, 2000, ARCH GEN PSYCHIAT, V57, P1033, DOI 10.1001/archpsyc.57.11.1033
   Simmons D, 2015, AUTISM, V19, P363, DOI 10.1177/1362361314557683
   Simmons DR, 2009, VISION RES, V49, P2705, DOI 10.1016/j.visres.2009.08.005
   Simon DM, 2017, FRONT INTEGR NEUROSC, V11, DOI 10.3389/fnint.2017.00008
   Stein B. E., 1993, MERGING SENSES
   Stevenson RA, 2018, AUTISM, V22, P609, DOI 10.1177/1362361317704413
   Stevenson RA, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14632-1
   Stevenson RA, 2017, SCHIZOPHR RES, V179, P97, DOI 10.1016/j.schres.2016.09.035
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2014, BRAIN TOPOGR, V27, P707, DOI 10.1007/s10548-014-0365-7
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stevenson RA, 2013, EXP BRAIN RES, V225, P479, DOI 10.1007/s00221-012-3387-y
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Stone DB, 2011, NEUROPSYCHOLOGIA, V49, P3178, DOI 10.1016/j.neuropsychologia.2011.07.017
   Su L, 2015, SCI REP-UK, V5, DOI 10.1038/srep09745
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Uhlhaas PJ, 2012, NEURON, V75, P963, DOI 10.1016/j.neuron.2012.09.004
   Van der Burg E, 2013, J NEUROSCI, V33, P14633, DOI 10.1523/JNEUROSCI.1182-13.2013
   Van der Stoep N, 2016, EXP BRAIN RES, V234, P1175, DOI 10.1007/s00221-015-4248-2
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   VOLKMAR FR, 1991, AM J PSYCHIAT, V148, P1705
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Wechsler D., 1999, WASI WECHSLER ABBREV
   Williams LE, 2010, NEUROPSYCHOLOGIA, V48, P3128, DOI 10.1016/j.neuropsychologia.2010.06.028
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Wynn JK, 2014, COGN NEUROPSYCHIATRY, V19, P319, DOI 10.1080/13546805.2013.866892
   Zhou HY, 2018, NEUROSCI BIOBEHAV R, V86, P66, DOI 10.1016/j.neubiorev.2017.12.013
   Zvyagintsev M, 2017, COGN NEUROPSYCHIATRY, V22, P361, DOI 10.1080/13546805.2017.1331160
NR 88
TC 20
Z9 20
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD MAY
PY 2018
VL 47
IS 10
SI SI
BP 1230
EP 1241
DI 10.1111/ejn.13911
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA GI1CH
UT WOS:000434106900011
PM 29575155
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Gnevsheva, K
AF Gnevsheva, Ksenia
TI The expectation mismatch effect in accentedness perception of Asian and
   Caucasian non-native speakers of English
SO LINGUISTICS
LA English
DT Article
DE Speech perception; sociophonetics; foreign accentedness; ethnicity;
   variation
ID SPEECH-PERCEPTION; PHONOLOGY
AB Previous research on speech perception has found an effect of ethnicity, such that the same audio clip may be rated more accented when presented with an Asian face (Rubin, Donald L. 1992. Nonlanguage factors affecting undergraduates' judgments of nonnative English-speaking teaching assistants. Research in Higher Education 33(4). 511-531. doi:10.1007/bf00 973770). However, most previous work has concentrated on Asian non-native English speakers, and Caucasian speakers remain under-explored. In this study, listeners carried out an accentedness rating task using stimuli from first language Korean, German, and English speakers in 3 conditions:audio only, video only, and audiovisual. Korean speakers received similar accentedness ratings regardless of condition, but German speakers were rated significantly less accented in the video condition and more accented in the audiovisual condition than the audio one. This result is explained as an expectation mismatch effect, whereby, when the listeners saw a Caucasian speaker they did not expect to hear a foreign accent, but if they actually heard one it was made more salient by their expectation to the contrary.
C1 [Gnevsheva, Ksenia] Australian Natl Univ, Sch Literature Languages & Linguist, Canberra, ACT 2600, Australia.
RP Gnevsheva, K (corresponding author), Australian Natl Univ, Sch Literature Languages & Linguist, Canberra, ACT 2600, Australia.
EM ksenia.gnevsheva@anu.edu.au
RI Gnevsheva, Ksenia/AAD-9973-2020
OI Gnevsheva, Ksenia/0000-0003-2583-2818
CR Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Campbell-Kibler K, 2007, AM SPEECH, V82, P32, DOI 10.1215/00031283-2007-002
   Campbell-Kibler K, 2010, LANG LINGUIST COMPAS, V4, P377, DOI 10.1111/j.1749-818x.2010.00201.x
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Gnevsheva K., 2015, INT J LEARNER CORPUS, V1, P256, DOI DOI 10.1075/IJLCR.1.2.04GNE
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   Kraut R, 2013, J MULTILING MULTICUL, V34, P249, DOI 10.1080/01434632.2013.767340
   Levi SV, 2007, J ACOUST SOC AM, V121, P2327, DOI 10.1121/1.2537345
   Lippi-Green R., 1997, ENGLISH ACCENT LANGU, V2nd ed.
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   R Core Team, 2014, R LANG ENV STAT COMP
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Strand E., 2000, THESIS
   Vishnevskaya Galina, 2008, ISSUES ACCENTS ENGLI, P235
   Yi HG, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00768
   Yi HG, 2013, J ACOUST SOC AM, V134, pEL387, DOI 10.1121/1.4822320
NR 24
TC 4
Z9 4
U1 0
U2 4
PU DE GRUYTER MOUTON
PI BERLIN
PA GENTHINER STRASSE 13, 10785 BERLIN, GERMANY
SN 0024-3949
EI 1613-396X
J9 LINGUISTICS
JI Linguistics
PD MAY
PY 2018
VL 56
IS 3
BP 581
EP 598
DI 10.1515/ling-2018-0006
PG 18
WC Linguistics; Language & Linguistics
SC Linguistics
GA GI6JH
UT WOS:000434475200005
DA 2021-02-24
ER

PT J
AU Jung, J
   Ertmer, DJ
AF Jung, Jongmin
   Ertmer, David J.
TI Grammatical Abilities in Young Cochlear Implant Recipients and Children
   With Normal Hearing Matched by Vocabulary Size
SO AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY
LA English
DT Article
ID SPOKEN LANGUAGE-DEVELOPMENT; ENGLISH-SPEAKING CHILDREN; DEAF-CHILDREN;
   SPEECH-PERCEPTION; RESISTANT RULES; TENSE MARKING; IMPAIRMENT; SKILLS;
   AGE; ACQUISITION
AB Purpose: This study sought to expand understanding of the impact of cochlear implantation on grammatical acquisition by comparing young children who have vocabularies of comparable size. Two research questions were investigated: (a) Do young cochlear implant (CI) recipients have grammatical skills comparable to those of children with normal hearing (NH) matched by spoken vocabulary size? (b) Do these groups show associations between vocabulary size and grammatical measures?
   Method: The participants included 13 CI recipients at 24 months postactivation (chronological ages = 33-60 months; M = 44.62) and 13 children with NH between 27 and 30 months old (M = 20.69). The 2 groups were matched by their vocabulary size. Four grammatical outcomes were analyzed from the MacArthur Communicative Development Inventory (Fenson, Marchman, Thal, Dale, & Reznick, 2007) and 20-min language samples: (a) grammatical complexity, (b) mean length of utterances, (c) tense marker total, and (d) productivity scores.
   Results: The 2 groups showed comparable grammatical skills across the 4 measures. Consistently significant associations between vocabulary size and grammatical outcomes were found in the CI group, with fewer associations in the NH group.
   Conclusions: The 2 groups showed similar grammatical abilities. The young CI recipients appeared to be following a typical pattern of linguistic development.
C1 [Jung, Jongmin; Ertmer, David J.] Purdue Univ, W Lafayette, IN 47907 USA.
   [Jung, Jongmin] Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
RP Jung, J (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.; Jung, J (corresponding author), Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
EM jongmin.jung@osumc.edu
OI Jung, Jongmin/0000-0001-9541-385X
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA; National Institute on
   Deafness and Other Communication DisordersUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC007863]; Purdue Research Foundation; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC007863, R01DC007863, R01DC007863, R01DC007863, R01DC007863]
   Funding Source: NIH RePORTER
FX This study was supported by a grant from the National Institutes of
   Health and the National Institute on Deafness and Other Communication
   Disorders (R01DC007863, David J. Ertmer, P. I.) and by grants from the
   Purdue Research Foundation, which were awarded to David J. Ertmer. The
   authors gratefully acknowledge the insightful feedback of George
   Hollich, Laurence Leonard, and Xin Luo in completing this project. The
   authors are also grateful to the parents and children who made this
   study possible. Sincere appreciation is offered to the staff of Child's
   Voice school (Wood Dale, IL), the St. Joseph Institute for the Deaf
   (Chesterfield, MO), the St. Joseph Institute for the Deaf (Indianapolis,
   IN), the Moog Center (Chesterfield, MO), and Ohio Valley Voice
   (Loveland, OH) for their indispensable assistance in recruiting
   participants and collecting data.
CR Bates E, 1997, LANG COGNITIVE PROC, V12, P507
   Boons T, 2013, RES DEV DISABIL, V34, P2008, DOI 10.1016/j.ridd.2013.03.003
   BORDUIN CM, 1981, DEV PSYCHOL, V17, P209, DOI 10.1037/0012-1649.17.2.209
   Braginsky M., 2015, P 35 ANN M COGN SCI
   Caselli MC, 2012, J SPEECH LANG HEAR R, V55, P382, DOI 10.1044/1092-4388(2011/10-0248)
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Duchesne L, 2009, J DEAF STUD DEAF EDU, V14, P465, DOI 10.1093/deafed/enp010
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Elman JL, 2004, TRENDS COGN SCI, V8, P301, DOI 10.1016/j.tics.2004.05.003
   Ertmer DJ, 2013, AM J SPEECH-LANG PAT, V22, P591, DOI 10.1044/1058-0360(2013/12-0058)
   Ertmer DJ, 2012, J DEAF STUD DEAF EDU, V17, P116, DOI 10.1093/deafed/enr021
   Ertmer DJ, 2009, J SPEECH LANG HEAR R, V52, P1579, DOI 10.1044/1092-4388(2009/06-0145)
   FENSON L, 1994, MONOGR SOC RES CHILD, V59, pR5
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   GILPIN AR, 1993, EDUC PSYCHOL MEAS, V53, P87, DOI 10.1177/0013164493053001007
   GLASCOE FP, 1993, CLIN PEDIATR, V32, P273, DOI 10.1177/000992289303200504
   Gleitman L. R., 1982, LANGUAGE ACQUISITION
   Guo LY, 2013, J DEAF STUD DEAF EDU, V18, P187, DOI 10.1093/deafed/ens069
   Hadley PA, 2005, J SPEECH LANG HEAR R, V48, P1344, DOI 10.1044/1092-4388(2005/094)
   HOAGLIN DC, 1986, J AM STAT ASSOC, V81, P991, DOI 10.2307/2289073
   HOAGLIN DC, 1987, J AM STAT ASSOC, V82, P1147, DOI 10.1080/01621459.1987.10478551
   Inscoe JR, 2009, DEAF EDUC INT, V11, P39, DOI 10.1179/146431509790559688
   Iyer SN, 2017, AM J SPEECH-LANG PAT, V26, P413, DOI 10.1044/2016_AJSLP-16-0073
   Jung J., 2011, ANN CONV AM SPEECH L
   Kampfhaus R. W., 2005, ASSESSMENT CHILD ADO
   KELLY MH, 1996, SIGNAL SYNTAX BOOTST
   Kort W., 2010, CELF 4 NL TEST DIAGN
   Leonard LB, 1997, J SPEECH LANG HEAR R, V40, P741, DOI 10.1044/jslhr.4004.741
   Leonard LB, 1999, J SPEECH LANG HEAR R, V42, P678, DOI 10.1044/jslhr.4203.678
   Marchman VA, 2005, BEYOND NATURE-NURTURE, P141
   MARCHMAN VA, 1994, J CHILD LANG, V21, P339, DOI 10.1017/S0305000900009302
   MARCUS GF, 1992, MONOGR SOC RES CHILD, V57, pR5
   Martin N.A., 2011, EXPRESSIVE ONE WORD
   May-Mederake B, 2012, INT J PEDIATR OTORHI, V76, P939, DOI 10.1016/j.ijporl.2012.02.051
   McClelland JL, 2002, TRENDS COGN SCI, V6, P465, DOI 10.1016/S1364-6613(02)01993-9
   McGregor KK, 2012, J AUTISM DEV DISORD, V42, P35, DOI 10.1007/s10803-011-1210-4
   McGregor KK, 2005, J CHILD LANG, V32, P563, DOI 10.1017/S0305000905006926
   Miller J.F., 2008, SYSTEMATIC ANAL LANG
   Moyle MJ, 2007, J SPEECH LANG HEAR R, V50, P508, DOI 10.1044/1092-4388(2007/035)
   Newborg J., 1984, BATTELLE DEV INVENTO
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S, 2005, J COMMUN DISORD, V38, P29, DOI 10.1016/j.jcomdis.2004.03.006
   PINKER S, 1991, SCIENCE, V253, P530, DOI 10.1126/science.1857983
   PLUNKETT K, 1993, COGNITION, V48, P21, DOI 10.1016/0010-0277(93)90057-3
   Redmond SM, 2001, J SPEECH LANG HEAR R, V44, P655, DOI 10.1044/1092-4388(2001/053)
   Reynell JK, 1990, REYNELL DEV LANGUAGE
   SCARBOROUGH HS, 1990, APPL PSYCHOLINGUIST, V11, P1, DOI 10.1017/S0142716400008262
   Schorr E. A., 2008, COMMUN DISORD Q, V29, P195, DOI DOI 10.1177/1525740108321217
   Szagun G, 2000, AUDIOL NEURO-OTOL, V5, P39, DOI 10.1159/000013864
   Thal DJ, 1999, J SPEECH LANG HEAR R, V42, P482, DOI 10.1044/jslhr.4202.482
   Thal DJ, 1996, J CHILD LANG, V23, P349, DOI 10.1017/S0305000900008837
   Thal D, 2007, AM J SPEECH-LANG PAT, V16, P54, DOI 10.1044/1058-0360(2007/007)
   Ullman MT, 1999, LANG COGNITIVE PROC, V14, P47, DOI 10.1080/016909699386374
   Vicari S, 2000, NEUROPSYCHOLOGIA, V38, P634, DOI 10.1016/S0028-3932(99)00110-4
   Weismer SE, 2011, J AUTISM DEV DISORD, V41, P1065, DOI 10.1007/s10803-010-1134-4
   Young GA, 2002, ANN OTO RHINOL LARYN, V111, P802, DOI 10.1177/000348940211100908
NR 58
TC 0
Z9 0
U1 0
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1058-0360
EI 1558-9110
J9 AM J SPEECH-LANG PAT
JI Am. J. Speech-Lang. Pathol.
PD MAY
PY 2018
VL 27
IS 2
BP 751
EP 764
DI 10.1044/2018_AJSLP-16-0164
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GI1UE
UT WOS:000434155300017
PM 29625430
OA Green Published
DA 2021-02-24
ER

PT J
AU Lavelli, M
   Majorano, M
   Guerzoni, L
   Murri, A
   Barachetti, C
   Cuda, D
AF Lavelli, Manuela
   Majorano, Marinella
   Guerzoni, Letizia
   Murri, Alessandra
   Barachetti, Chiara
   Cuda, Domenico
TI Communication dynamics between mothers and their children with cochlear
   implants: Effects of maternal support for language production
SO JOURNAL OF COMMUNICATION DISORDERS
LA English
DT Article
DE Cochlear implant; Mother-child communication; Linguistic repairs;
   Gestures
ID SPEECH-PERCEPTION; HEARING CHILDREN; YOUNG-CHILDREN; DEAF-CHILDREN;
   IMPAIRMENT; GESTURE; AGE; OUTCOMES; INPUT; USERS
AB This study examined (a) the functions and modalities of maternal and child communication during interaction between mothers and children with cochlear implants (CIs), comparing them with mothers and normally hearing (NH) children, and (b) the effectiveness of maternal support strategies in eliciting adequate answers in children with CL Twenty preschoolers with CIs (M = 40 months) and 40 NH children - 20 matched by chronological age (CANH, M = 40 months) and 20 matched by hearing age (HANH, M = 25 months) - were videotaped during shared book reading and toy play with their mothers. Child and maternal utterances were coded for communicative functions and modalities (vocal, gestural, bimodal), including gesture types; maternal repairs were examined for type of support provided, and child answers for adequacy. Mothers in the CI group and in the CANH group displayed higher proportions of Informative Repairs than mothers of HANH children. However, unlike the mothers of NH children, mothers of children with CIs used bimodal utterances significantly more than vocal utterances. Sequential analysis revealed that maternal Informative Repairs elicited the production of Adequate Answers in both children with CIs and CANH. Interestingly, in the CI group this association was found only when Informative Repairs were accompanied by gestures. These findings offer suggestions for intervention programs focused on parent-child conversation.
C1 [Lavelli, Manuela; Majorano, Marinella; Barachetti, Chiara] Univ Verona, Verona, Italy.
   [Guerzoni, Letizia; Murri, Alessandra; Cuda, Domenico] Guglielmo da Saliceto Hosp, Via Taverna Giuseppe 49, I-29121 Piacenza, PC, Italy.
RP Lavelli, M (corresponding author), Univ Verona, Dept Human Sci, Psychol Area, Via S Francesco 22, I-37129 Verona, VR, Italy.
EM ruanuela.lavelli@univr.it; marinella.majorano@univr.it;
   l.guerzoni@ausl.pc.it; a.murri@ausl.pc.it; chiara.barachetti@univr.it;
   d.cuda@ausl.pc.it
RI murri, alessandra/M-4104-2019
OI murri, alessandra/0000-0002-5958-8086
CR Abu Bakar Z, 2010, DEAF EDUC INT, V12, P2, DOI 10.1179/146431510X12626982043525
   Albertini J. A., 2010, CORSINI ENCY PSYCHOL, V2, P461
   Archbold S, 2008, INT J PEDIATR OTORHI, V72, P1471, DOI 10.1016/j.ijporl.2008.06.016
   Axia V, 1995, TEST 1 LINGUAGGIO TP
   Bakeman R., 2011, SEQUENTIAL ANAL OBSE
   Baldassari CM, 2009, OTOLARYNG HEAD NECK, V140, P114, DOI 10.1016/j.otohns.2008.09.008
   Barachetti C, 2011, INT J LANG COMM DIS, V46, P579, DOI 10.1111/j.1460-6984.2011.00032.x
   Barker DH, 2009, DEV PSYCHOPATHOL, V21, P373, DOI 10.1017/S0954579409000212
   Bello A., 2010, PAROLE GIOCO PING PR
   Bergeson TR, 2006, INFANCY, V10, P221, DOI 10.1207/s15327078in1003_2
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Bornstein MH, 2008, DEV PSYCHOL, V44, P867, DOI 10.1037/0012-1649.44.3.867
   Brown P.M., 2004, DEAFNESS ED INT, V6, P129, DOI DOI 10.1179/146431504790560546
   Capone NC, 2007, J SPEECH LANG HEAR R, V50, P732, DOI 10.1044/1092-4388(2007/051)
   Caselli M. C., 2016, 1 VOCABOLARIO BAMBIN
   Caselli MC, 2012, J SPEECH LANG HEAR R, V55, P382, DOI 10.1044/1092-4388(2011/10-0248)
   Chapman RS, 2000, J CHILD PSYCHOL PSYC, V41, P33, DOI 10.1111/1469-7610.00548
   Ching Teresa Y C, 2009, Cochlear Implants Int, V10 Suppl 1, P28, DOI 10.1179/cim.2009.10.Supplement-1.28
   Cresti E., 1997, PROGETTO CHILDES ITA, V2, P57
   Cruz I, 2013, CHILD DEV, V84, P543, DOI 10.1111/j.1467-8624.2012.01863.x
   D'Odorico L., 1999, FIRST LANG, V19, P313, DOI DOI 10.1177/014272379901905702
   Davidson Lisa S, 2011, Ear Hear, V32, p19S, DOI 10.1097/AUD.0b013e3181ffdb8b
   de Hoog BE, 2016, INT J LANG COMM DIS, V51, P518, DOI 10.1111/1460-6984.12228
   DesJardin JL, 2007, EAR HEARING, V28, P456, DOI 10.1097/AUD.0b013e31806dc1ab
   DesJardin JL, 2014, COMMUN DISORD Q, V35, P167, DOI 10.1177/1525740113518062
   DesJardin JL, 2009, J DEAF STUD DEAF EDU, V14, P22, DOI 10.1093/deafed/enn011
   Duchesne L, 2009, J DEAF STUD DEAF EDU, V14, P465, DOI 10.1093/deafed/enp010
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Fagan MK, 2014, INFANT BEHAV DEV, V37, P249, DOI 10.1016/j.infbeh.2014.04.001
   Fagan MK, 2010, J DEAF STUD DEAF EDU, V15, P149, DOI 10.1093/deafed/enq001
   Farran LK, 2009, INT J LANG COMM DIS, V44, P145, DOI 10.1080/13682820801973404
   Fenson L, 2006, MACARTHUR BATES COMM
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   Goldin-Meadow S, 2000, PSYCHOL SCI, V11, P307, DOI 10.1111/1467-9280.00261
   Guasti MT, 2014, APPL PSYCHOLINGUIST, V35, P739, DOI 10.1017/S0142716412000562
   Hoff E, 2006, DEV REV, V26, P55, DOI 10.1016/j.dr.2005.11.002
   HOFFGINSBERG E, 1986, DEV PSYCHOL, V22, P155, DOI 10.1037/0012-1649.22.2.155
   Holt RF, 2012, J SPEECH LANG HEAR R, V55, P848, DOI 10.1044/1092-4388(2011/11-0143)
   Iverson JM, 2006, INT J LANG COMM DIS, V41, P235, DOI 10.1080/13682820500312151
   Iverson JM, 2011, J SPEECH LANG HEAR R, V54, P72, DOI 10.1044/1092-4388(2010/08-0197)
   Kirk KI, 2000, VOLTA REV, V102, P127
   Kondaurova MV, 2013, INFANCY, V18, P825, DOI 10.1111/infa.12010
   Lavelli M, 2015, J CHILD LANG, V42, P1191, DOI 10.1017/S0305000914000762
   Lederberg A. R., 2000, J DEAF STUD DEAF EDU, V5, P303, DOI DOI 10.1093/DEAFED/5.4.303
   Lederberg AR, 1998, J SPEECH LANG HEAR R, V41, P887, DOI 10.1044/jslhr.4104.887
   MacWhinney B., 2000, COMPUT LINGUIST, VI, P657, DOI DOI 10.1162/C0LI.2000.26.4.657
   Majorano M, 2018, INT J LANG COMM DIS, V53, P70, DOI 10.1111/1460-6984.12327
   Majorano M, 2015, J COMMUN DISORD, V53, P1, DOI 10.1016/j.jcomdis.2014.10.001
   Majorano M, 2014, INT J LANG COMM DIS, V49, P204, DOI 10.1111/1460-6984.12062
   Mannle S., 1992, FIRST LANG, V12, P57, DOI [10.1177/014272379201203404, DOI 10.1177/014272379201203404]
   Masur EF, 2005, J CHILD LANG, V32, P63, DOI 10.1017/S0305000904006634
   Meadow-Orlans K. P., 2003, PARENTS THEIR DEAF C
   Mitchell Ross, 2004, SIGN LANGUAGE STUDIE, V4, P138, DOI DOI 10.1353/SLS.2004.0005
   Moeller MP, 2000, PEDIATRICS, V106, DOI 10.1542/peds.106.3.e43
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Olswang L., 1987, ASSESSING PRELINGUIS
   PRESSMAN LJ, 1999, J DEAF STUDIES DEAF, V0004
   Price LH, 2009, READ RES QUART, V44, P171, DOI 10.1598/RRQ.44.2.4
   Quittner AL, 2013, J PEDIATR-US, V162, P343, DOI 10.1016/j.jpeds.2012.08.003
   Riches NG, 2006, INT J LANG COMM DIS, V41, P117, DOI 10.1080/13682820500216501
   Richter B, 2002, INT J PEDIATR OTORHI, V64, P111, DOI 10.1016/S0165-5876(02)00037-X
   Rowe ML, 2009, DEVELOPMENTAL SCI, V12, P182, DOI 10.1111/j.1467-7687.2008.00764.x
   Spencer P., 2010, EVIDENCE BASED PRACT
   Spencer P. E., 2011, OXFORD HDB DEAF STUD, P452, DOI DOI 10.1093/0XF0RDHB/9780199750986.013.0032
   Spencer PE, 2000, DEAF CHILD FAMILY SC
   Stefanini S, 2008, GESTURE, V8, P197, DOI 10.1075/gest.8.2.05ste
   Stella G., 2000, PEABODY TEST TEST VO
   Szagun G, 2016, J CHILD LANG, V43, P505, DOI 10.1017/S0305000915000641
   Szagun G, 2012, J SPEECH LANG HEAR R, V55, P1640, DOI 10.1044/1092-4388(2012/11-0119)
   Tamis-LeMonda CS, 2001, CHILD DEV, V72, P748, DOI 10.1111/1467-8624.00313
   Tomblin JB, 2008, J SPEECH LANG HEAR R, V51, P1353, DOI 10.1044/1092-4388(2008/07-0083)
   Uhler K, 2011, J AM ACAD AUDIOL, V22, P129, DOI 10.3766/jaaa.22.3.2
   Vaccari C, 1997, J CHILD PSYCHOL PSYC, V38, P793, DOI 10.1111/j.1469-7610.1997.tb01597.x
   Vanormelingen L, 2015, INT J PEDIATR OTORHI, V79, P520, DOI 10.1016/j.ijporl.2015.01.020
   Waxman R, 1997, J Deaf Stud Deaf Educ, V2, P104
   Weizman ZO, 2001, DEV PSYCHOL, V37, P265, DOI 10.1037//0012-1649.37.2.265
   Yoshinaga-Itano C, 2003, MENT RETARD DEV D R, V9, P252, DOI 10.1002/mrdd.10088
   Yoshinaga-Itano C, 2003, J DEAF STUD DEAF EDU, V8, P11, DOI DOI 10.1093/DEAFED/8.1.11
NR 78
TC 1
Z9 1
U1 0
U2 11
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0021-9924
EI 1873-7994
J9 J COMMUN DISORD
JI J. Commun. Disord.
PD MAY-JUN
PY 2018
VL 73
BP 1
EP 14
DI 10.1016/j.jcomdis.2018.03.001
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GI4WI
UT WOS:000434371500001
PM 29544117
DA 2021-02-24
ER

PT J
AU Tokat, T
   Catli, T
   Bayrak, F
   Bozkurt, EB
   Olgun, L
AF Tokat, Taskin
   Catli, Tolgahan
   Bayrak, Feda
   Bozkurt, Ergul Basaran
   Olgun, Levent
TI Cochlear Implantation in Postmeningitic Deafness
SO JOURNAL OF CRANIOFACIAL SURGERY
LA English
DT Article
DE Auditory performance; cochlear implantation; postmeningitic deafness
ID MENINGOGENIC LABYRINTHITIS; BACTERIAL-MENINGITIS; CHILDREN;
   OSSIFICATION; INSERTION; SPEECH; BONE
AB Purpose:The aim of this study is to evaluate long-term outcomes of cochlear implantation (CI) in patients with postmeningitic deafness.Methods:Twenty-seven patients with severe to profound hearing loss due to bacterial meningitis and received CI were the subjects of this study. Surgical findings and long-term audiological performances were evaluated. Speech perception and speech intelligibility of the implanted patients were evaluated with the categories of auditory performance-II (CAP-II) test and speech intelligibility rating (SIR) test, respectively.Results:Eighteen of the 27 patients had received full electrode insertion through the patent cochlear lumen. Remaining 9 patients had varying degrees of ossification throughout the cochlea and needed to be drilled to achieve partial electrode insertion. None of the patients exhibited surgical complication. Scores in both test batteries (CAP-II and SIR) were comparable between patients who received full or partial electrode insertion (P>0.05).Conclusion:Cochlear implantation after postmeningitic deafness has favorable outcomes especially in long term. Although this type of inner ear pathology may require special considerations during surgery, it is a relatively safe procedure.
C1 [Tokat, Taskin; Catli, Tolgahan; Bozkurt, Ergul Basaran; Olgun, Levent] Bozyaka Teaching & Res Hosp, Dept Otorhinolaryngol, Izmir, Turkey.
   [Bayrak, Feda] Ataturk Teaching & Res Hosp, Dept Otorhinolaryngol, Izmir, Turkey.
RP Catli, T (corresponding author), Saim Cikrikci St, Izmir, Turkey.
EM tcatli80@hotmail.com
CR Allen C, 2001, OTOL NEUROTOL, V22, P631, DOI 10.1097/00129492-200109000-00012
   Archbold S, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P312
   Axon PR, 1998, AM J OTOL, V19, P724
   Catli T, 2015, EUR ARCH OTO-RHINO-L, V272, P3131, DOI 10.1007/s00405-014-3319-5
   COHEN NL, 1993, AM J OTOL, V14, P357
   Durisin Martin, 2015, Cochlear Implants Int, V16, P147, DOI 10.1179/1754762814Y.0000000094
   FORTNUM HM, 1992, ARCH DIS CHILD, V67, P1128, DOI 10.1136/adc.67.9.1128
   Gantz BJ, 1998, OTOLARYNGOL HEAD NEC, V98, P72
   Gilmour L, 2010, THESIS
   Lenarz T, 2002, EAR HEARING, V23, p90S, DOI 10.1097/00003446-200202001-00011
   Merchant SN, 1996, AM J OTOL, V17, P375
   NADOL JB, 1991, ANN OTO RHINOL LARYN, V100, P712, DOI 10.1177/000348949110000904
   Nichani J, 2011, OTOL NEUROTOL, V32, P784, DOI 10.1097/MAO.0b013e31821677aa
   Olgun Y, 2014, INT J PEDIATR OTORHI, V78, P1642, DOI 10.1016/j.ijporl.2014.07.013
   Rauch SD, 1997, LARYNGOSCOPE, V107, P1606, DOI 10.1097/00005537-199712000-00005
   Rotteveel LJC, 2005, CLIN OTOLARYNGOL, V30, P242, DOI 10.1111/j.1365-2273.2005.00958.x
   STEENERSON RL, 1990, AM J OTOL, V11, P360
NR 17
TC 6
Z9 6
U1 0
U2 1
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1049-2275
EI 1536-3732
J9 J CRANIOFAC SURG
JI J. Craniofac. Surg.
PD MAY
PY 2018
VL 29
IS 3
BP E245
EP E248
DI 10.1097/SCS.0000000000004265
PG 4
WC Surgery
SC Surgery
GA GI3WW
UT WOS:000434303800013
PM 29381604
DA 2021-02-24
ER

PT J
AU Wong, PS
   Leung, CTT
AF Wong, Puisan
   Leung, Carrie Tsz-Tin
TI Suprasegmental Features Are Not Acquired Early: Perception and
   Production of Monosyllabic Cantonese Lexical Tones in 4-to 6-Year-Old
   Preschool Children
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID HONG-KONG CANTONESE; SPEECH-PERCEPTION; SPEAKING CHILDREN; CHINESE
   CHILDREN; ACQUISITION; PUTONGHUA; LANGUAGE; SPEAKERS; INFANTS; TAIWAN
AB Purpose: Previous studies reported that children acquire Cantonese tones before 3 years of age, supporting the assumption in models of phonological development that suprasegmental features are acquired rapidly and early in children. Yet, recent research found a large disparity in the age of Cantonese tone acquisition. This study investigated Cantonese tone development in 4- to 6-year-old children.
   Method: Forty-eight 4- to 6-year-old Cantonese-speaking children and 28 mothers of the children labeled 30 pictures representing familiar words in the 6 tones in a picture-naming task and identified pictures representing words in different Cantonese tones in a picture-pointing task. To control for lexical biases in tone assessment, tone productions were low-pass filtered to eliminate lexical information. Five judges categorized the tones in filtered stimuli. Tone production accuracy, tone perception accuracy, and correlation between tone production and perception accuracy were examined.
   Results: Children did not start to produce adultlike tones until 5 and 6 years of age. Four-year-olds produced none of the tones with adultlike accuracy. Five-and 6-year-olds attained adultlike productions in 2 (T5 and T6) to 3 (T4, T5, and T6) tones, respectively. Children made better progress in tone perception and achieved higher accuracy in perception than in production. However, children in all age groups perceived none of the tones as accurately as adults, except that T1 was perceived with adultlike accuracy by 6-year-olds. Only weak association was found between children's tone perception and production accuracy.
   Conclusions: Contradicting to the long-held assumption that children acquire lexical tone rapidly and early before the mastery of segmentals, this study found that 4- to 6-yearold children have not mastered the perception or production of the full set of Cantonese tones in familiar monosyllabic words. Larger development was found in children's tone perception than tone production. The higher tone perception accuracy but weak correlation between tone perception and production abilities in children suggested that tone perception accuracy is not sufficient for children's tone production accuracy. The findings have clinical and theoretical implications.
C1 [Wong, Puisan; Leung, Carrie Tsz-Tin] Univ Hong Kong, Fac Educ, Div Speech & Hearing Sci, Pokfulam, Hong Kong, Peoples R China.
RP Wong, PS (corresponding author), Univ Hong Kong, Fac Educ, Div Speech & Hearing Sci, Pokfulam, Hong Kong, Peoples R China.
EM pswResearch@gmail.com
RI Wong, Puisan/P-5362-2019
OI Wong, Puisan/0000-0001-9027-8054
FU Seed Funding Programme for Basic Research from The University of Hong
   Kong [201611159068]
FX This research was supported by funding from the Seed Funding Programme
   for Basic Research from The University of Hong Kong (Project code:
   201611159068) to the first author.
CR Barry JG, 2004, J ACOUST SOC AM, V116, P1739, DOI 10.1121/1.1779272
   Bauer R. S., 2003, LANG VAR CHANGE, V15, P211, DOI DOI 10.1017/S0954394503152039
   Chen L.-M., 2012, P 24 C COMP LING SPE
   Cheung H, 2009, J CHILD PSYCHOL PSYC, V50, P726, DOI 10.1111/j.1469-7610.2008.02001.x
   Cheung P. S. P., 2006, HONG KONG CANTONESE
   CHING T, 1984, LANGUAGE LEARNING CO, V3, P243
   Ciocca V, 2002, J ACOUST SOC AM, V111, P2250, DOI 10.1121/1.1471897
   Clumeck H., 1980, CHILD PHONOLOGY, P257
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Dehaene-Lambertz G, 1998, LANG SPEECH, V41, P21, DOI 10.1177/002383099804100102
   Edwards M. L., 1974, J CHILD LANG, V1, P205, DOI [DOI 10.1017/S0305000900000659, 10.1017/S0305000900000659]
   Green JR, 2000, J SPEECH LANG HEAR R, V43, P239, DOI 10.1044/jslhr.4301.239
   Hong Kong Education and Manpower Bureau, 2006, CANT EXPR LANG SCAL
   Hua Z, 2000, J CHILD LANG, V27, P3, DOI 10.1017/S030500099900402X
   Hua Z, 2002, PHONOLOGICAL DEV SPE, V3
   KIMBROUGH D, 1975, PHONETICA, V31, P288
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Lee K. Y. S., 2012, CANTONESE TONE IDENT
   Lee KYS, 2015, INT J SPEECH-LANG PA, V17, P53, DOI 10.3109/17549507.2014.898096
   Li WS, 2011, J CHILD LANG, V38, P793, DOI 10.1017/S0305000910000346
   Lotto AJ, 2009, TRENDS COGN SCI, V13, P110, DOI 10.1016/j.tics.2008.11.008
   Ma JKY, 2006, J ACOUST SOC AM, V120, P3978, DOI 10.1121/1.2363927
   Mok PPK, 2013, LANG VAR CHANGE, V25, P341, DOI 10.1017/S0954394513000161
   Simons GF, 2017, ETHNOLOGUE LANGUAGES, V2017, P20
   Smith A, 2006, J COMMUN DISORD, V39, P331, DOI 10.1016/j.jcomdis.2006.06.017
   So LKH, 1995, J CHILD LANG, V22, P473, DOI 10.1017/S0305000900009922
   Tardif T, 2008, CHINESE COMMUNICATIV
   Tardif T, 2009, J CHILD LANG, V36, P1115, DOI 10.1017/S0305000908009185
   To CKS, 2013, J SPEECH LANG HEAR R, V56, P103, DOI 10.1044/1092-4388(2012/11-0080)
   Tse A. C.-Y, 1992, THESIS
   TSE JKP, 1978, J CHILD LANG, V5, P191, DOI 10.1017/S0305000900007418
   Tuaycharoen P., 1977, THESIS
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wong PS, 2018, J ACOUST SOC AM, V143, P765, DOI 10.1121/1.5021251
   Wong PS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01450
   Wong P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182337
   Wong P, 2013, J ACOUST SOC AM, V133, P434, DOI 10.1121/1.4768883
   Wong P, 2012, J SPEECH LANG HEAR R, V55, P1423, DOI 10.1044/1092-4388(2012/11-0273)
   Wong PS, 2012, J PHONETICS, V40, P141, DOI 10.1016/j.wocn.2011.10.005
   Yip M., 2002, TONE
   Zhang J, 2014, READ WRIT, V27, P481, DOI 10.1007/s11145-013-9453-4
NR 42
TC 9
Z9 9
U1 0
U2 10
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2018
VL 61
IS 5
BP 1070
EP 1085
DI 10.1044/2018_JSLHR-S-17-0288
PG 16
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GG7ML
UT WOS:000432882300002
PM 29710319
DA 2021-02-24
ER

PT J
AU Case, J
   Seyfarth, S
   Levi, SV
AF Case, Julie
   Seyfarth, Scott
   Levi, Susannah V.
TI Does Implicit Voice Learning Improve Spoken Language Processing?
   Implications for Clinical Practice
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID INDIVIDUAL TALKER DIFFERENCES; LISTENER SENSITIVITY; WORD
   IDENTIFICATION; SPEECH-PERCEPTION; FAMILIARITY; SPECIFICITY;
   RECOGNITION; CONTEXT; NOISE
AB Purpose: In typical interactions with other speakers, including a clinical environment, listeners become familiar with voices through implicit learning. Previous studies have found evidence for a Familiar Talker Advantage (better speech perception and spoken language processing for familiar voices) following explicit voice learning. The current study examined whether a Familiar Talker Advantage would result from implicit voice learning.
   Method: Thirty-three adults and 16 second graders were familiarized with 1 of 2 talkers' voices over 2 days through live interactions as 1 of 2 experimenters administered standardized tests and interacted with the listeners. To assess whether this implicit voice learning would generate a Familiar Talker Advantage, listeners completed a baseline sentence recognition task and a post-learning sentence recognition task with both the familiar talker and the unfamiliar talker.
   Results: No significant effect of voice familiarity was found for either the children or the adults following implicit voice learning. Effect size estimates suggest that familiarity with the voice may benefit some listeners, despite the lack of an overall effect of familiarity.
   Discussion: We discuss possible clinical implications of this finding and directions for future research.
C1 [Case, Julie; Levi, Susannah V.] NYU, Dept Commun Sci & Disorders, New York, NY 10003 USA.
   [Seyfarth, Scott] Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
   [Seyfarth, Scott] Ohio State Univ, Off Acad Affairs, Columbus, OH 43210 USA.
RP Case, J (corresponding author), NYU, Dept Commun Sci & Disorders, New York, NY 10003 USA.
EM julie.case@nyu.edu
OI Levi, Susannah/0000-0002-3115-8981
FU NIH-NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [1R03DC009851-01]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R03DC009851, R03DC009851, R03DC009851] Funding Source: NIH
   RePORTER
FX This work was supported in part by a grant from the NIH-NIDCD:
   1R03DC009851-01 (Levi). We would like to thank Gabrielle Alfano,
   Stephanie Lee, Maddy Lippman, Rebecca Piper, and Ashley Quinto for help
   with data collection and the children and families for their
   participation. Portions of this work were presented at the annual
   convention of the American Speech-Language-Hearing Association (2016)
   and at the Symposium on Research in Child Language Disorders (2017).
CR Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   American Speech-Language-Hearing Association, 1997, OMN SURV RES
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Benki JR, 2003, J ACOUST SOC AM, V113, P1689, DOI 10.1121/1.1534102
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Ebert KD, 2017, AM J SPEECH-LANG PAT, V26, P146, DOI 10.1044/2016_AJSLP-16-0018
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   FELTY R, 2007, CONTEXT EFFECTS SPOK
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Hoffman L, 2014, LANG SPEECH HEAR SER, V45, P89, DOI 10.1044/2014_LSHSS-14-0026
   Huyck JJ, 2017, J SPEECH LANG HEAR R, V60, P3334, DOI 10.1044/2017_JSLHR-H-16-0300
   Ireland M., 2016, PERSPECTIVES ASHA SP, V1, P78, DOI DOI 10.1044/PERSP1.SIG16.78
   Kisilevsky BS, 2003, PSYCHOL SCI, V14, P220, DOI 10.1111/1467-9280.02435
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Levi SV, 2015, J CHILD LANG, V42, P843, DOI 10.1017/S0305000914000506
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Nelson P, 2005, LANG SPEECH HEAR SER, V36, P219, DOI 10.1044/0161-1461(2005/022)
   New York City Department of Education, 2009, STAND OP PROC MAN RE
   New York City Early Intervention System, 2014, POL PROC MAN
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Pena ED, 1997, LANG SPEECH HEAR SER, V28, P323, DOI 10.1044/0161-1461.2804.323
   R Core Team, 2016, R LANG ENV STAT COMP
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Schneider W., 2007, E PRIME 2 0 PROFESSI
   SCHROEDER MR, 1968, J ACOUST SOC AM, V44, P1735, DOI 10.1121/1.1911323
   Semel E.M., 2004, CLIN EVALUATION LANG
   Smith GW, 2013, LEARN DISABIL RES PR, V28, P89, DOI 10.1111/ldrp.12010
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Stelmachowicz PG, 2000, J SPEECH LANG HEAR R, V43, P902, DOI 10.1044/jslhr.4304.902
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   TULVING E, 1973, PSYCHOL REV, V80, P352, DOI 10.1037/h0020071
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
   Zimmerman I. L., 2002, PRESCHOOL LANGUAGE S
NR 39
TC 2
Z9 2
U1 0
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2018
VL 61
IS 5
BP 1251
EP 1260
DI 10.1044/2018_JSLHR-L-17-0298
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GG7ML
UT WOS:000432882300015
PM 29800358
OA Green Published
DA 2021-02-24
ER

PT J
AU Magimairaj, BM
   Nagaraj, NK
   Benafield, NJ
AF Magimairaj, Beula M.
   Nagaraj, Naveen K.
   Benafield, Natalie J.
TI Children's Speech Perception in Noise: Evidence for Dissociation From
   Language and Working Memory
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID AUDITORY PROCESSING DISORDER; INDIVIDUAL-DIFFERENCES; OLDER-ADULTS;
   HEARING-LOSS; SENTENCE REPETITION; WORD RECOGNITION; YOUNG-CHILDREN;
   ATTENTION; COMPREHENSION; IMPAIRMENT
AB Purpose: We examined the association between speech perception in noise (SPIN), language abilities, and working memory (WM) capacity in school-age children. Existing studies supporting the Ease of Language Understanding (ELU) model suggest that WM capacity plays a significant role in adverse listening situations.
   Method: Eighty-three children between the ages of 7 to 11 years participated. The sample represented a continuum of individual differences in attention, memory, and language abilities. All children had normal-range hearing and normal-range nonverbal IQ. Children completed the Bamford-Kowal-Bench Speech-in-Noise Test (BKB-SIN; Etymotic Research, 2005), a selective auditory attention task, and multiple measures of language and WM.
   Results: Partial correlations (controlling for age) showed significant positive associations among attention, memory, and language measures. However, BKB-SIN did not correlate significantly with any of the other measures. Principal component analysis revealed a distinct WM factor and a distinct language factor. BKB-SIN loaded robustly as a distinct 3rd factor with minimal secondary loading from sentence recall and short-term memory. Nonverbal IQ loaded as a 4th factor.
   Conclusions: Results did not support an association between SPIN and WM capacity in children. However, in this study, a single SPIN measure was used. Future studies using multiple SPIN measures are warranted. Evidence from the current study supports the use of BKB-SIN as clinical measure of speech perception ability because it was not influenced by variation in children's language and memory abilities. More large-scale studies in school-age children are needed to replicate the proposed role played by WM in adverse listening situations.
C1 [Magimairaj, Beula M.; Benafield, Natalie J.] Univ Cent Arkansas, Commun Sci & Disorders, Cognit & Language Lab, Conway, AR 72035 USA.
   [Nagaraj, Naveen K.] Univ Arkansas, Univ Arkansas Med Sci, Cognit Hearing Sci Lab, Little Rock, AR 72204 USA.
RP Magimairaj, BM (corresponding author), Univ Cent Arkansas, Commun Sci & Disorders, Cognit & Language Lab, Conway, AR 72035 USA.
EM bmagimairaj@uca.edu
FU Hearing Health Foundation's Emerging Research Grant
FX The Hearing Health Foundation's Emerging Research Grant (which was
   awarded to the authors) supported this work. The authors thank all
   children and parents who participated. Additional thanks to Taylor
   Wentz, Sara Liggin, Miranda Gendreau, and Jessica Flores for assistance
   with data collection and data management.
CR Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahmmed AU, 2014, EAR HEARING, V35, P295, DOI 10.1097/01.aud.0000441034.02052.0a
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Allen RJ, 2018, Q J EXP PSYCHOL, V71, P2571, DOI 10.1177/1747021817746929
   Alloway TP, 2004, J EXP CHILD PSYCHOL, V87, P85, DOI 10.1016/j.jecp.2003.10.002
   Alloway TP., 2007, AUTOMATED WORKING ME
   Archibald LMD, 2013, TOP LANG DISORD, V33, P190, DOI 10.1097/TLD.0b013e31829dd8af
   Bell T S, 2001, J Am Acad Audiol, V12, P514
   Bishop D. V. M., 2003, TEST RECEPTION GRAMM
   BOOTHROYD A, 1968, J ACOUST SOC AM, V43, P362, DOI 10.1121/1.1910787
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Brown L, 1997, TEST NONVERBAL INTEL
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Cameron S, 2008, J AM ACAD AUDIOL, V19, P377, DOI 10.3766/jaaa.19.5.2
   Camos V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00900
   Camos V, 2011, DEV PSYCHOL, V47, P898, DOI 10.1037/a0023193
   CARHART R, 1959, J SPEECH HEAR DISORD, V24, P330, DOI 10.1044/jshd.2404.330
   Carrow-Woolfolk E., 1999, COMPREHENSIVE ASSESS
   Colflesh GJH, 2007, PSYCHON B REV, V14, P699, DOI 10.3758/BF03196824
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   de Wit E, 2018, EAR HEARING, V39, P1, DOI 10.1097/AUD.0000000000000479
   Dhamani I, 2013, SCI REP-UK, V3, DOI 10.1038/srep01297
   Dunn L. M., 2012, PEABODY PICTURE VOCA
   Eisenberg LS, 2000, J ACOUST SOC AM, V107, P2704, DOI 10.1121/1.428656
   Engle RW, 2002, CURR DIR PSYCHOL SCI, V11, P19, DOI 10.1111/1467-8721.00160
   *ET RES, 2005, BKB SIN SPEECH IN NO
   Ferguson MA, 2011, J SPEECH LANG HEAR R, V54, P211, DOI 10.1044/1092-4388(2010/09-0167)
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Jaroslawska AJ, 2016, MEM COGNITION, V44, P580, DOI 10.3758/s13421-015-0579-2
   JERGER J, 1968, ANN OTO RHINOL LARYN, V77, P1042, DOI 10.1177/000348946807700604
   JOLLIFFE IT, 1972, J ROY STAT SOC C-APP, V21, P160
   Jones PR, 2015, DEV PSYCHOL, V51, P353, DOI 10.1037/a0038570
   Klem M, 2015, DEVELOPMENTAL SCI, V18, P146, DOI 10.1111/desc.12202
   Kline R. B., 2011, PRINCIPLES PRACTICE
   Leonard LB, 2007, J SPEECH LANG HEAR R, V50, P408, DOI 10.1044/1092-4388(2007/029)
   Magimairaj BM, 2017, SPEECH LANG HEARING, V20, P38, DOI 10.1080/2050571X.2016.1206167
   Magimairaj BM, 2012, ACTA PSYCHOL, V140, P196, DOI 10.1016/j.actpsy.2012.05.004
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McCreery RW, 2017, INT J AUDIOL, V56, P306, DOI 10.1080/14992027.2016.1266703
   Moore DR, 2010, PEDIATRICS, V126, pE382, DOI 10.1542/peds.2009-2826
   Nagaraj NK, 2017, J SPEECH LANG HEAR R, V60, P2949, DOI 10.1044/2017_JSLHR-H-17-0022
   NITTROUER S, 1990, J ACOUST SOC AM, V87, P2705, DOI 10.1121/1.399061
   Nittrouer S, 2013, INT J AUDIOL, V52, P513, DOI 10.3109/14992027.2013.792957
   Nittrouer S, 2011, J EXP CHILD PSYCHOL, V108, P762, DOI 10.1016/j.jecp.2010.10.012
   Osman H, 2014, J SPEECH LANG HEAR R, V57, P1503, DOI 10.1044/2014_JSLHR-H-13-0286
   Polisenska K, 2015, INT J LANG COMM DIS, V50, P106, DOI 10.1111/1460-6984.12126
   Riccio CA, 2005, CHILD NEUROPSYCHOL, V11, P363, DOI 10.1080/09297040490916956
   Riches NG, 2012, INT J LANG COMM DIS, V47, P499, DOI 10.1111/j.1460-6984.2012.00158.x
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rosen S, 2010, INT J PEDIATR OTORHI, V74, P594, DOI 10.1016/j.ijporl.2010.02.021
   Schafer EC., 2010, J ED AUDIOL, V16, P4
   Schneider W., 2012, E PRIME USERS GUIDE
   Sharma M, 2014, J SPEECH LANG HEAR R, V57, P2308, DOI 10.1044/2014_JSLHR-H-13-0226
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   Smith SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01394
   Sullivan JR, 2015, J SPEECH LANG HEAR R, V58, P1043, DOI 10.1044/2015_JSLHR-H-14-0204
   Tomlin D, 2015, EAR HEARING, V36, P527, DOI 10.1097/AUD.0000000000000172
   Tun PA, 2010, PSYCHOL AGING, V25, P730, DOI 10.1037/a0019300
   Wallace G., 2013, COMPREHENSIVE RECEPT
   Wiig E.H., 2013, CLIN EVALUATION LANG
   Woodcock R.W., 2007, WOODCOCK JOHNSON 3 T
   Yang TX, 2016, J COGN PSYCHOL, V28, P186, DOI 10.1080/20445911.2015.1101118
NR 67
TC 10
Z9 10
U1 0
U2 11
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2018
VL 61
IS 5
BP 1294
EP 1305
DI 10.1044/2018_JSLHR-H-17-0312
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GG7ML
UT WOS:000432882300020
PM 29800354
DA 2021-02-24
ER

PT J
AU Peter, V
   Kalashnikova, M
   Burnham, D
AF Peter, Varghese
   Kalashnikova, Marina
   Burnham, Denis
TI Weighting of Amplitude and Formant Rise Time Cues by School-Aged
   Children: A Mismatch Negativity Study
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID TRANSITION DURATION; SPEECH-PERCEPTION; VOWEL PERCEPTION; ACOUSTIC CUES;
   RESPONSES; LANGUAGE; REPRESENTATION; SOUNDS; ADULTS; PITCH
AB Purpose: An important skill in the development of speech perception is to apply optimal weights to acoustic cues so that phonemic information is recovered from speech with minimum effort. Here, we investigated the development of acoustic cue weighting of amplitude rise time (ART) and formant rise time (FRT) cues in children as measured by mismatch negativity (MMN).
   Method: Twelve adults and 36 children aged 6-12 years listened to a /ba/-/wa/contrast in an oddball paradigm in which the standard stimulus had the ART and FRT cues of /ba/. In different blocks, the deviant stimulus had either the ART or FRT cues of /wa/.
   Results: The results revealed that children younger than 10 years were sensitive to both ART and FRT cues whereas 10-to 12-year-old children and adults were sensitive only to FRT cues. Moreover, children younger than 10 years generated a positive mismatch response, whereas older children and adults generated MMN.
   Conclusion: These results suggest that preattentive adultlike weighting of ART and FRT cues is attained only by 10 years of age and accompanies the change from mismatch response to the more mature MMN response.
C1 [Peter, Varghese; Kalashnikova, Marina; Burnham, Denis] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.
   [Peter, Varghese] Macquarie Univ, Dept Linguist, N Ryde, NSW, Australia.
RP Peter, V (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.; Peter, V (corresponding author), Macquarie Univ, Dept Linguist, N Ryde, NSW, Australia.
EM varghese.peter@mq.edu.au
RI Burnham, Denis/L-3742-2019; Kalashnikova, Marina/B-6590-2019
OI Burnham, Denis/0000-0002-1980-3458; Kalashnikova,
   Marina/0000-0002-7924-8687; Peter, Varghese/0000-0002-4007-507X
FU Australian Research CouncilAustralian Research Council [DP110105123]
FX This work was supported by Australian Research Council Discovery Project
   Grant DP110105123 awarded to the last author. We thank Susan Nittrouer
   for providing the stimuli, Rachel Lee and Scott O'Loughlin for their
   assistance in recruiting participants, and two anonymous reviewers for
   their helpful comments on an earlier version of the article. We thank
   all the adults, children, and their families who participated in the
   study.
CR Bishop D. V. M., 2003, TEST RECEPTION GRAMM
   Breaux K. C., 2009, WECHSLER INDIVIDUAL
   Brusini P, 2017, NEUROPSYCHOLOGIA, V98, P4, DOI 10.1016/j.neuropsychologia.2016.08.015
   Butler BE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00180
   Carpenter AL, 2013, NEUROSCI LETT, V544, P56, DOI 10.1016/j.neulet.2013.03.041
   Catts HW, 2005, J SPEECH LANG HEAR R, V48, P1378, DOI 10.1044/1092-4388(2005/096)
   Cheng YY, 2015, INT J PSYCHOPHYSIOL, V96, P84, DOI 10.1016/j.ijpsycho.2015.03.007
   Cheng YY, 2013, DEV NEUROPSYCHOL, V38, P281, DOI 10.1080/87565641.2013.799672
   Cheour M, 1998, INT J PSYCHOPHYSIOL, V29, P217, DOI 10.1016/S0167-8760(98)00017-8
   Corrigall KA, 2014, DEVELOPMENTAL SCI, V17, P142, DOI 10.1111/desc.12100
   Dehaene-Lambertz G, 1998, NEUROREPORT, V9, P1885, DOI 10.1097/00001756-199806010-00040
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   DORMAN MF, 1977, PERCEPT PSYCHOPHYS, V22, P109, DOI 10.3758/BF03198744
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   He C, 2007, J COGNITIVE NEUROSCI, V19, P878, DOI 10.1162/jocn.2007.19.5.878
   Horvath J, 2008, PSYCHOPHYSIOLOGY, V45, P60, DOI 10.1111/j.1469-8986.2007.00599.x
   JUSCZYK PW, 1987, DEV PSYCHOL, V23, P648, DOI 10.1037/0012-1649.23.5.648
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kovelman I, 2012, CEREB CORTEX, V22, P754, DOI 10.1093/cercor/bhr094
   Kuo YC, 2014, CLIN NEUROPHYSIOL, V125, P1568, DOI 10.1016/j.clinph.2013.11.035
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Lipski SC, 2012, PSYCHOPHYSIOLOGY, V49, P638, DOI 10.1111/j.1469-8986.2011.01347.x
   LISKER L, 1975, J ACOUST SOC AM, V57, P1547, DOI 10.1121/1.380602
   Liu HX, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0111175, 10.1371/journal.pone.0110887]
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Lowenstein JH, 2015, J SPEECH LANG HEAR R, V58, P466, DOI 10.1044/2015_JSLHR-H-14-0254
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Maurer U, 2003, CLIN NEUROPHYSIOL, V114, P808, DOI 10.1016/S1388-2457(03)00032-4
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McQueen JM, 1999, J EXP PSYCHOL HUMAN, V25, P1363, DOI 10.1037/0096-1523.25.5.1363
   Moberly AC, 2016, EAR HEARING, V37, P465, DOI 10.1097/AUD.0000000000000257
   Moberly AC, 2014, BRAIN LANG, V130, P42, DOI 10.1016/j.bandl.2014.01.007
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   MORRONGIELLO BA, 1984, J EXP CHILD PSYCHOL, V37, P231, DOI 10.1016/0022-0965(84)90002-X
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Naatanen R, 2001, TRENDS NEUROSCI, V24, P283, DOI 10.1016/S0166-2236(00)01790-2
   Naatanen R, 2008, INT J AUDIOL, V47, pS16, DOI 10.1080/14992020802340116
   NITTROUER S, 1986, J ACOUST SOC AM, V80, P1026, DOI 10.1121/1.393843
   NITTROUER S, 1992, J PHONETICS, V20, P351, DOI 10.1016/S0095-4470(19)30639-4
   Nittrouer S, 1997, J ACOUST SOC AM, V101, P2253, DOI 10.1121/1.418207
   Nittrouer S, 1996, J SPEECH HEAR RES, V39, P278, DOI 10.1044/jshr.3902.278
   Nittrouer S, 2000, PERCEPT PSYCHOPHYS, V62, P266, DOI 10.3758/BF03205548
   NITTROUER S, 1987, J SPEECH HEAR RES, V30, P319, DOI 10.1044/jshr.3003.319
   Nittrouer S., 1993, J ACOUST SOC AM, V94, pS1865
   Nittrouer Susan, 2012, Perspect Lang Learn Educ, V19, P87
   Nittrouer S, 2013, J SPEECH LANG HEAR R, V56, P427, DOI 10.1044/1092-4388(2012/12-0075)
   Nittrouer S, 2009, J EXP PSYCHOL HUMAN, V35, P1245, DOI 10.1037/a0015020
   Ohde RN, 1997, J ACOUST SOC AM, V102, P3711, DOI 10.1121/1.420135
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Peter V, 2016, SCI REP-UK, V6, DOI 10.1038/srep34273
   Peter V, 2016, DEV COGN NEUROS-NETH, V19, P152, DOI 10.1016/j.dcn.2016.03.006
   Ruhnau P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00717
   Semel E, 2006, CLIN EVALUATION LANG
   Slugocki C, 2014, EUR J NEUROSCI, V40, P3608, DOI 10.1111/ejn.12741
   Souza PE, 2015, J SPEECH LANG HEAR R, V58, P520, DOI 10.1044/2015_JSLHR-H-14-0138
   Torgesen J. K., 2012, TEST WORD READING EF
   Trainor L, 2003, INT J PSYCHOPHYSIOL, V51, P5, DOI 10.1016/S0167-8760(03)00148-X
   Trainor LJ, 2011, BRAIN TOPOGR, V24, P192, DOI 10.1007/s10548-011-0177-y
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Wagner A, 2006, J ACOUST SOC AM, V120, P2267, DOI 10.1121/1.2335422
   Wagner R. K., 2013, COMPREHENSIVE TEST P
   WALSH MA, 1991, Q J EXP PSYCHOL-A, V43, P603, DOI 10.1080/14640749108400989
   Ylinen S, 2010, J COGNITIVE NEUROSCI, V22, P1319, DOI 10.1162/jocn.2009.21272
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 69
TC 0
Z9 0
U1 0
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2018
VL 61
IS 5
BP 1322
EP 1333
DI 10.1044/2018_JSLHR-H-17-0334
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GG7ML
UT WOS:000432882300022
PM 29800360
DA 2021-02-24
ER

PT J
AU Cooke, M
   Lecumberri, MLG
AF Cooke, Martin
   Garcia Lecumberri, Maria Luisa
TI Effects of exposure to noise during perceptual training of non-native
   language sounds
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID HEARING-IMPAIRED LISTENERS; JAPANESE LISTENERS; ENGLISH CONSONANTS;
   SPEECH-PERCEPTION; IDENTIFICATION; RECOGNITION; EXPERIENCE; CONTEXT;
   USERS
AB Listeners manage to acquire the sounds of their native language in spite of experiencing a range of acoustic conditions during acquisition, including the presence of noise. Is the same true for non-native sound acquisition? This study investigates whether the presence of masking noise during consonant training is a barrier to improvement, or, conversely, whether noise can be beneficial. Spanish learners identified English consonants with and without noise, before and after undergoing one of four extensive training regimes in which they were exposed to either consonants or vowels in the presence or absence of speech-shaped noise. The consonant-trained cohorts showed substantially larger gains than the vowel-trained groups, regardless of whether they were trained in noise or quiet. A small matched-condition benefit was evident, with noise-training resulting in larger improvements when testing in noise, and vice versa for training in quiet. No evidence for habituation to noise was observed: the cohort trained on vowels in noise showed no transference to consonants in noise. These findings demonstrate that noise exposure does not impede the acquisition of second language sounds. (C) 2018 Acoustical Society of America.
C1 [Cooke, Martin] Basque Sci Fdn, Ikerbasque, Bilbao, Spain.
   [Garcia Lecumberri, Maria Luisa] Univ Basque Country, Language & Speech Lab, Vitoria 01006, Spain.
RP Cooke, M (corresponding author), Basque Sci Fdn, Ikerbasque, Bilbao, Spain.
EM m.cooke@ikerbasque.org
RI Garcia Lecumberri, Maria Luisa/P-3983-2014
OI Garcia Lecumberri, Maria Luisa/0000-0002-8651-7558
FU Basque Government Consolidados grantBasque Government
FX This study was carried out with funding from the Basque Government
   Consolidados grant to the Language and Speech Laboratory at the
   University of the Basque Country.
CR BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Burk MH, 2006, EAR HEARING, V27, P263, DOI 10.1097/01.aud.0000215980.21158.a2
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   Clopper CG, 2004, LANG SPEECH, V47, P207, DOI 10.1177/00238309040470030101
   Cooke M, 2010, SPEECH COMMUN, V52, P954, DOI 10.1016/j.specom.2010.04.004
   Cooke M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1765
   Cooper A, 2015, ATTEN PERCEPT PSYCHO, V77, P1342, DOI 10.3758/s13414-015-0855-z
   Creel SC, 2012, LANG COGNITIVE PROC, V27, P1021, DOI 10.1080/01690965.2011.610597
   Cutler A, 2008, J ACOUST SOC AM, V124, P1264, DOI 10.1121/1.2946707
   Florentine M, 1984, J ACOUST SOC AM, V75, pS84, DOI [10.1121/ 1.2021645, DOI 10.1121/1.2021645]
   Gagne JP, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216516687287
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Hayward K., 2002, EXPT PHONETICS
   Humes LE, 2009, EAR HEARING, V30, P613, DOI 10.1097/AUD.0b013e3181b00d90
   Kent R. D., 1996, PRINCIPLES EXPT PHON
   Kent R.D., 1992, ACOUSTIC ANAL SPEECH
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Lecumberri MLG, 2006, J ACOUST SOC AM, V119, P2445, DOI 10.1121/1.2180210
   Lippmann R. P., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P705
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Loizou P., 2007, SPEECH ENHANCEMENT T
   Lovitt A, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2154
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Oba SI, 2011, EAR HEARING, V32, P573, DOI 10.1097/AUD.0b013e31820fc821
   Pals C, 2015, J ACOUST SOC AM, V138, pEL187, DOI 10.1121/1.4929614
   Pufahl A, 2014, COGNITIVE PSYCHOL, V70, P1, DOI 10.1016/j.cogpsych.2014.01.001
   Seel N. M., 2012, ENCY SCI LEARNING, P2694
   Song JH, 2012, CEREB CORTEX, V22, P1180, DOI 10.1093/cercor/bhr196
   Stecker GC, 2006, J REHABIL RES DEV, V43, P537, DOI 10.1682/JRRD.2005.11.0171
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Summerfield Q. A., 2006, EAR HEARING, V17, p51S
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   van Dommelen WA, 2010, SPEECH COMMUN, V52, P968, DOI 10.1016/j.specom.2010.05.001
   Wilson RH, 2003, J REHABIL RES DEV, V40, P329, DOI 10.1682/JRRD.2003.07.0329
   Woods DL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0113965
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
NR 40
TC 1
Z9 1
U1 2
U2 7
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAY
PY 2018
VL 143
IS 5
BP 2602
EP 2610
DI 10.1121/1.5035080
PG 9
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GG9WB
UT WOS:000433050700023
PM 29857707
DA 2021-02-24
ER

PT J
AU Silbert, NH
   Zadeh, LM
AF Silbert, Noah H.
   Zadeh, Lina Motlagh
TI Modeling talker- and listener-based sources of variability in
   babble-induced consonant confusions
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID NORMAL-HEARING LISTENERS; RECOGNITION THEORY FRAMEWORK; TIME-FREQUENCY
   SEGREGATION; ENERGETIC MASKING RELEASE; STEADY BACKGROUND-NOISE;
   SPEECH-PERCEPTION; INDIVIDUAL-DIFFERENCES; NONNATIVE LISTENERS; CLEAR
   SPEECH; DECISIONAL SEPARABILITY
AB Speech communication often occurs in the presence of noise. Patterns of perceptual errors induced by background noise are influenced by properties of the listener and of the noise and target speech. The present study introduces a modification of multilevel general recognition theory in which talker-and listener-based variability in confusion patterns are modeled as global or dimension-specific scaling of shared, group-level perceptual distributions. Listener-specific perceptual correlations and response bias are also modeled as random variables. This model is applied to identification-confusion data from 11 listeners' identifications of ten tokens of each of four consonant categories-[t], [d], [s], [z]-produced by 20 talkers in CV syllables and masked by 10-talker babble. The results indicate that dimension-specific scaling for both listeners and talkers provides a good account of confusion patterns. These findings are discussed in relation to other recent research showing substantial listener-, talker-, and token-based sources of variability in noise-masked speech perception. (C) 2018 Acoustical Society of America.
C1 [Silbert, Noah H.; Zadeh, Lina Motlagh] Univ Cincinnati, Commun Sci & Disorders, Cincinnati, OH 45267 USA.
RP Silbert, NH (corresponding author), Univ Cincinnati, Commun Sci & Disorders, Cincinnati, OH 45267 USA.
EM silbernh@ucmail.uc.edu
RI Zadeh, Lina Motlagh/AAH-3532-2020
OI Motlagh Zadeh, Lina/0000-0001-7972-7138
FU University of Cincinnati
FX This research was supported by a start-up package provided to N.H.S. by
   the University of Cincinnati. In addition, three anonymous reviewers
   provided valuable feedback that helped improve this report.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Allen JB, 2005, J ACOUST SOC AM, V117, P2212, DOI 10.1121/1.1856231
   ASHBY FG, 1986, PSYCHOL REV, V93, P154, DOI 10.1037/0033-295X.93.2.154
   Bent T, 2009, J ACOUST SOC AM, V126, P2660, DOI 10.1121/1.3212930
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 2003, J SPEECH LANG HEAR R, V46, P80, DOI 10.1044/1092-4388(2003/007)
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929
   Brungart DS, 2009, J ACOUST SOC AM, V125, P4006, DOI 10.1121/1.3117686
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Clopper CG, 2008, LANG SPEECH, V51, P175, DOI 10.1177/0023830908098539
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Ferguson SH, 2004, J ACOUST SOC AM, V116, P2365, DOI 10.1121/1.1788730
   Jurgens T, 2009, J ACOUST SOC AM, V126, P2635, DOI 10.1121/1.3224721
   Kadlec H., 1992, MULTIDIMENSIONAL MOD, P181
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   Kruschke JK, 2015, DOING BAYESIAN DATA
   Lecumberri MLG, 2006, J ACOUST SOC AM, V119, P2445, DOI 10.1121/1.2180210
   Liu S, 2004, J ACOUST SOC AM, V116, P2374, DOI 10.1121/1.1787528
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Patil A, 2010, J STAT SOFTW, V35, P1
   PAYTON KL, 1994, J ACOUST SOC AM, V95, P1581, DOI 10.1121/1.408545
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Phatak SA, 2007, J ACOUST SOC AM, V121, P2312, DOI 10.1121/1.2642397
   PICHENY MA, 1985, J SPEECH HEAR RES, V28, P96, DOI 10.1044/jshr.2801.96
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   POLLACK I, 1960, LANG SPEECH, V3, P1
   Rouder JN, 2004, PSYCHOL REV, V111, P80, DOI 10.1037/0033-295X.111.1.80
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shepard N., 1972, HUMAN COMMUNICATION, P67
   Silbert NH, 2017, J MATH PSYCHOL, V77, P187, DOI 10.1016/j.jmp.2016.08.002
   Silbert NH, 2014, LAB PHONOL, V5, P289, DOI 10.1515/lp-2014-0011
   Silbert NH, 2013, PSYCHON B REV, V20, P1, DOI 10.3758/s13423-012-0329-4
   Silbert NH, 2012, J ACOUST SOC AM, V131, P4076, DOI 10.1121/1.3699209
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   Singh R, 2012, J ACOUST SOC AM, V131, P3051, DOI 10.1121/1.3682054
   Soto FA, 2015, COGNITION, V139, P105, DOI 10.1016/j.cognition.2015.02.006
   Soto FA, 2015, PSYCHON B REV, V22, P88, DOI 10.3758/s13423-014-0661-y
   Stone MA, 2016, J ACOUST SOC AM, V140, P832, DOI 10.1121/1.4960483
   Stone MA, 2014, J ACOUST SOC AM, V135, P1967, DOI 10.1121/1.4868392
   Stone MA, 2012, J ACOUST SOC AM, V132, P317, DOI 10.1121/1.4725766
   Stone MA, 2011, J ACOUST SOC AM, V130, P2874, DOI 10.1121/1.3641371
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Thomas RD, 2001, PERCEPT PSYCHOPHYS, V63, P625, DOI 10.3758/BF03194426
   Thomas RD, 2014, PSYCHON B REV, V21, P574, DOI 10.3758/s13423-013-0529-6
   Toscano JC, 2014, J SPEECH LANG HEAR R, V57, P2293, DOI 10.1044/2014_JSLHR-H-13-0244
   Vehtari A, 2017, STAT COMPUT, V27, P1413, DOI 10.1007/s11222-016-9696-4
   Watanabe S, 2010, J MACH LEARN RES, V11, P3571
   Woods DL, 2010, J REHABIL RES DEV, V47, P243, DOI 10.1682/JRRD.2009.04.0040
   Zaar J, 2015, J ACOUST SOC AM, V138, P1253, DOI 10.1121/1.4928142
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 54
TC 2
Z9 2
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAY
PY 2018
VL 143
IS 5
BP 2780
EP 2791
DI 10.1121/1.5037091
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GG9WB
UT WOS:000433050700040
PM 29857734
DA 2021-02-24
ER

PT J
AU Rojczyk, A
   Ciszewski, T
   Szwoch, G
   Czyzewski, A
AF Rojczyk, Arkadiusz
   Ciszewski, Tomasz
   Szwoch, Grzegorz
   Czyzewski, Andrzej
TI Visual perception of vowels from static and dynamic cues
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID AUDIOVISUAL SPEECH-PERCEPTION; PSYTOOLKIT; MOTION
AB The purpose of the study was to analyse human identification of Polish vowels from static and dynamic durationally slowed visual cues. A total of 152 participants identified 6 Polish vowels produced by 4 speakers from static (still images) and dynamic (videos) cues. The results show that 59% of static vowels and 63% of dynamic vowels were successfully identified. There was a strong confusion between vowels within front, central, and back classes. Finally, correct identification strongly depended on speakers, showing that speakers differ significantly in how "clearly" they produce vowel configurations. (C) 2018 Acoustical Society of America
C1 [Rojczyk, Arkadiusz] Univ Silesia, Inst English, Res Unit Appl Psycholinguist, Katowice, Poland.
   [Ciszewski, Tomasz] Univ Gdansk, Inst English & Amer Studies, Fac Languages, Gdansk, Poland.
   [Szwoch, Grzegorz; Czyzewski, Andrzej] Gdansk Univ Technol, Multimedia Syst Dept, Gdansk, Poland.
RP Rojczyk, A (corresponding author), Univ Silesia, Inst English, Res Unit Appl Psycholinguist, Katowice, Poland.
EM arkadiusz.rojczyk@us.edu.pl; angtc@ug.edu.pl; greg@sound.eti.pg.gda.pl;
   andcz@sound.eti.pg.gda.pl
RI Rojczyk, Arkadiusz/J-7255-2019; Szwoch, Grzegorz/Y-7732-2019
OI Rojczyk, Arkadiusz/0000-0002-7328-5911; Szwoch,
   Grzegorz/0000-0002-6718-6052; Czyzewski, Andrzej/0000-0001-9159-8658
FU National Science Centre PolandNational Science Center, PolandNational
   Science Centre, Poland [2015/17/B/ST6/01874]
FX The study was supported under the grant "Methodology and technology for
   the polymodal allophonic speech transcription" (Grant No.
   2015/17/B/ST6/01874) from the National Science Centre Poland.
CR Alsius A, 2016, ATTEN PERCEPT PSYCHO, V78, P1472, DOI 10.3758/s13414-016-1109-4
   [Anonymous], 201517BST601874 NAT
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   FROMKIN V, 1964, LANG SPEECH, V7, P215, DOI 10.1177/002383096400700402
   Gilbert JL, 2012, ATTEN PERCEPT PSYCHO, V74, P1761, DOI 10.3758/s13414-012-0375-z
   Ito M, 2001, J ACOUST SOC AM, V110, P1141, DOI 10.1121/1.1384908
   Kim J, 2004, COGNITION, V93, pB39, DOI 10.1016/j.cognition.2003.11.003
   Lange J, 2006, J VISION, V6, P836, DOI 10.1167/6.8.6
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Morrison G, 2013, VOWEL INHERENT SPECT
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   RHODES G, 1993, COGNITION, V47, P25, DOI 10.1016/0010-0277(93)90061-Y
   Stoet G, 2017, TEACH PSYCHOL, V44, P24, DOI 10.1177/0098628316677643
   Stoet G, 2010, BEHAV RES METHODS, V42, P1096, DOI 10.3758/BRM.42.4.1096
NR 15
TC 0
Z9 0
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAY
PY 2018
VL 143
IS 5
BP EL328
EP EL332
DI 10.1121/1.5036958
PG 5
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GG9WB
UT WOS:000433050700004
PM 29857772
OA Bronze
DA 2021-02-24
ER

PT J
AU Baumann, A
   Kazmierski, K
AF Baumann, Andreas
   Kazmierski, Kamil
TI Assessing the effect of ambiguity in compositionality signaling on the
   processing of diphones
SO LANGUAGE SCIENCES
LA English
DT Article
DE Morphonotactics; Compositionality signaling; Ambiguity; Perception
ID PHONOTACTICS; CONSTRAINTS; PERCEPTION; MODELS
AB Consonantal diphones differ as to their ambiguity (whether or not they indicate morphological complexity reliably by occurring exclusively either within or across morphemes) and lexicality (how frequently they occur within morphemes rather than across morpheme boundaries). This study empirically investigates the influence of ambiguity and lexicality on the processing speed of consonantal diphones in speech perception. More specifically, its goal is to test the predictions of the Strong Morphonotactic Hypothesis, which asserts that phonotactic processing is influenced by morphological structure, and to clarify the two conceptions thereof present in extant research. In two discrimination task experiments, it is found that the processing speed of cross-morpheme diphones decreases with their ambiguity, but there is no processing difference between primarily cross morphemic and morpheme-internal diphones. We conclude that the predictions of the Strong Morphonotactic Hypothesis are borne out only partially, and we discuss the discrepancies. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Baumann, Andreas] Univ Vienna, Dept English & Amer Studies, Spitalgasse 2-4,Court 8-3, A-1090 Vienna, Austria.
   [Kazmierski, Kamil] Adam Mickiewicz Univ, Fac English, Aleja Niepodleglosci 4, PL-61874 Poznan, Poland.
RP Baumann, A (corresponding author), Univ Vienna, Dept English & Amer Studies, Spitalgasse 2-4,Court 8-3, A-1090 Vienna, Austria.
EM andreas.baumann@univie.ac.at; kamil.kazmierski@wa.amu.edu.pl
RI Kazmierski, Kamil/J-4955-2014
OI Kazmierski, Kamil/0000-0002-5390-0964
FU Austrian Science Fund (FWF)Austrian Science Fund (FWF) [P27592-G18]
FX This research was supported by the Austrian Science Fund (FWF, grant no.
   P27592-G18).
CR Adriaans F, 2010, J MEM LANG, V62, P311, DOI 10.1016/j.jml.2009.11.007
   Albright A., 2015, CLUSTER PHONOTACTICS
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen R. H., 2013, RES METHODS LINGUIST, P337
   Balota DA, 2013, J EXP PSYCHOL LEARN, V39, P1563, DOI 10.1037/a0032186
   Baumann Andreas, 2016, YB POZNAN LINGUISTIC, V2, P115, DOI DOI 10.1515/YPLM-2016-0006
   Berent I, 2007, COGNITION, V104, P591, DOI 10.1016/j.cognition.2006.05.015
   Boll-Avetisyan N, 2016, LINGUA, V171, P74, DOI 10.1016/j.lingua.2015.11.008
   Burnham KP, 2011, BEHAV ECOL SOCIOBIOL, V65, P23, DOI 10.1007/s00265-010-1029-6
   Burnham KP., 2002, MODEL SELECTION MULT, V2
   BYBEE J. L., 2013, OXFORD HDB CONSTRUCT
   Calderone B, 2014, LANG SCI, V46, P59, DOI 10.1016/j.langsci.2014.06.007
   Celata C, 2015, ITAL J LINGUIST, V27, P85
   Cruttenden Alan, 2014, GIMSONS PRONUNCIATIO
   Daland R, 2011, COGNITIVE SCI, V35, P119, DOI 10.1111/j.1551-6709.2010.01160.x
   Donohue M, 2013, WORLD PHONOTACTICS D
   Draxler C., 2015, SPEECHRECORDER
   Dressler WU, 2010, FOLIA LINGUIST HIST, V31, P51, DOI 10.1515/FLIH.2010.003
   Dressler Wolfgang U., 2006, WIENER LINGUISTISCHE, V73, P69
   Dziubalska-Kolaczyk K., 2014, CONCORDIA WORK PAP A, V5, P130
   Dziubalska-Kolaczyk K., 2014, NAD PHONOTACTIC CALC
   Dziubalska-Kolaczyk K, 2014, LANG SCI, V46, P6, DOI 10.1016/j.langsci.2014.06.003
   Ernestus M, 2014, LINGUA, V142, P27, DOI 10.1016/j.lingua.2012.12.006
   Freiberger E.M., 2011, WIEN LINGUIST GAZ, V75, P33
   Freiberger E. M., 2007, WIEN LINGUIST GAZ, V74, P1
   Fruehwald J, 2017, LANG VAR CHANGE, V29, P1, DOI 10.1017/S0954394517000060
   Grueber CE, 2011, J EVOLUTION BIOL, V24, P699, DOI 10.1111/j.1420-9101.2010.02210.x
   Hay J, 2001, LINGUISTICS, V39, P1041, DOI 10.1515/ling.2001.041
   Hay Jennifer, 2003, CAUSES CONSEQUENCES
   Jarosz G, 2017, LANG ACQUIS, V24, P361, DOI 10.1080/10489223.2016.1179743
   Kahn D., 1976, THESIS
   Kaimierski Kamil, 2015, 23 MANCH PHON M
   Kliegl R, 2010, VIS COGN, V18, P655, DOI 10.1080/13506280902986058
   Korecky-Kroll K, 2014, LANG SCI, V46, P48, DOI 10.1016/j.langsci.2014.06.006
   Levelt C., 1998, CONSTRAINTS PHONOLOG, P204
   Leykum H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1685
   Leykum Hannah, 2015, P 18 INT C PHON SCI
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   Marecka M, 2014, LANG SCI, V46, P37, DOI 10.1016/j.langsci.2014.06.002
   Mattys S. L., 1999, J MEM LANG, V38, P465
   Moreton E, 2002, COGNITION, V84, P55, DOI 10.1016/S0010-0277(02)00014-8
   PEIRCE C.S., 1965, COLLECTED PAPERS
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Plag I, 2017, J LINGUIST, V53, P181, DOI 10.1017/S0022226715000183
   R Development Core Team, 2013, R LANG ENV STAT COMP
   Ritt N, 2016, ENGL LANG LINGUIST, V20, P1, DOI 10.1017/S1360674315000040
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   STERIADE D, 1999, P 1998 LING PHON C, P205
   Valimaa-Blum R, 2009, COGNITEXTES, V2
   van der Lugt AH, 2001, PERCEPT PSYCHOPHYS, V63, P811, DOI 10.3758/BF03194440
   van Rij J., 2015, ITSADUG INTERPRETING
   Vennemann Theo, 1988, PREFERENCE LAWS SYLL
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Wedel AB, 2006, LINGUIST REV, V23, P247, DOI 10.1515/TLR.2006.010
   West B. T., 2015, LINEAR MIXED MODELS
   Wieling M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023613
   Wood S., 2015, RANDOM EFFECTS GAMS
   Wood S., 2006, GEN ADDITIVE MODELS
   ZYDOROWICZ P, 2007, WIEN LINGUIST GAZ, V74, P24
   Zydorowicz P., 2016, PHONOTACTICS MORPHON, P342
NR 62
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0388-0001
EI 1873-5746
J9 LANG SCI
JI Lang. Sci.
PD MAY
PY 2018
VL 67
BP 14
EP 32
DI 10.1016/j.langsci.2018.03.006
PG 19
WC Linguistics; Language & Linguistics
SC Linguistics
GA GG7ON
UT WOS:000432887700002
DA 2021-02-24
ER

PT J
AU Liu, YH
   Zheng, F
   Guo, RB
   Wang, JL
   Nie, Q
   Wang, X
   Wang, ZR
AF Liu Yunhui
   Zheng Fan
   Guo Ruibin
   Wang Jiangliu
   Nie Qiang
   Wang Xin
   Wang Zerui
TI Robot Intelligence for Real World Applications
SO CHINESE JOURNAL OF ELECTRONICS
LA English
DT Article
DE Machine intelligence; Simultaneous localization and mapping (SLAM);
   Medical robots; Human robot interaction
ID FORM-CLOSURE GRASPS; DEFORMABLE OBJECTS; SIMULTANEOUS LOCALIZATION;
   FLEXIBLE OBJECT; POSE ESTIMATION; MANIPULATORS; RECOGNITION; ODOMETRY;
   TRACKING; FEATURES
AB This paper presents a brief review on recent work on machine intelligence for real-world applications of robots. To act in a real world environment, a robot should possess a broad sense of intelligence including speech, perception, reasoning, action, etc. In this paper, we particularly deal with the intelligence involving action or body motion. The intelligence related to robot action/motion can be classified into two categories: manipulation intelligence and mobility intelligence. The manipulation intelligence means the skill/intelligence of reliably manipulating objects according to tasks and the mobility intelligence corresponds to the ability of autonomously moving, or flying, and or jumping in a natural environment. Human-robot interaction is another important topic for real-world applications. In addition to reviewing the major approaches, this paper also gives an overview on our efforts in these important topics.
C1 [Liu Yunhui; Zheng Fan; Wang Jiangliu; Nie Qiang; Wang Xin; Wang Zerui] Chinese Univ Hong Kong, T Stone Robot Inst, Hong Kong, Hong Kong, Peoples R China.
   [Guo Ruibin] Natl Univ Def Technol, Changsha 410073, Hunan, Peoples R China.
RP Liu, YH (corresponding author), Chinese Univ Hong Kong, T Stone Robot Inst, Hong Kong, Hong Kong, Peoples R China.
EM yhliu@mae.cuhk.edu.hk; fzheng@link.cuhk.edu.hk; rbguo@nudt.edu.cn;
   jlwang@mae.cuhk.edu.hk; qnie@mae.cuhk.edu.hk; xwang2@mae.cuk.edu.hk;
   zrwang@mae.cuhk.edu.hk
RI Wang, Zerui/R-3094-2018
OI Wang, Zerui/0000-0003-4281-5120
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1613218]; Hong Kong Research Grant
   CouncilHong Kong Research Grants Council [14204814]; Hong Kong
   Innovation and Technology Commission [ITS/112/15FP]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1613218), Hong Kong Research Grant Council (No.14204814),
   and Hong Kong Innovation and Technology Commission (No.ITS/112/15FP).
CR Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   ARAI F, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P155, DOI 10.1109/ROBOT.1993.291976
   Astolfi A, 2002, IEEE T ROBOTIC AUTOM, V18, P387, DOI 10.1109/TRA.2002.1019475
   BICCHI A, 1995, INT J ROBOT RES, V14, P319, DOI 10.1177/027836499501400402
   Buss M, 1996, IEEE T ROBOTIC AUTOM, V12, P406, DOI 10.1109/70.499823
   Carlone L, 2014, INT J ROBOT RES, V33, P965, DOI 10.1177/0278364914523689
   Cretu AM, 2012, IEEE T SYST MAN CY B, V42, P740, DOI 10.1109/TSMCB.2011.2176115
   Das J, 2011, J INTELL ROBOT SYST, V62, P3, DOI 10.1007/s10846-010-9436-5
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Ding D, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P1223, DOI 10.1109/IROS.2000.893186
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Foresti GL, 2004, IEEE T SYST MAN CY C, V34, P325, DOI 10.1109/TSMCC.2003.819701
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321
   Gardner H., 1993, MULTIPLE INTELLIGENC
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han L, 2000, IEEE T ROBOTIC AUTOM, V16, P663, DOI 10.1109/70.897778
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Henrich Dominik, 2000, ROBOT MANIPULATION D
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258
   Higashimori M, 2010, IEEE INT CONF ROBOT, P5120, DOI 10.1109/ROBOT.2010.5509462
   Hirai S, 2000, ROBOTICA, V18, P3, DOI 10.1017/S0263574799002362
   Hou Y, 2017, ADV MECH ENG, V9, DOI 10.1177/1687814017714978
   Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972
   Johnson S., 2010, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.24.12
   Kashiwase T., 1991, Journal of Intelligent Material Systems and Structures, V2, P110, DOI 10.1177/1045389X9100200107
   Klein George, 2007, P1
   KOSUGE K, 1995, IEEE INT CONF ROBOT, P318, DOI 10.1109/ROBOT.1995.525304
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Lam ML, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P943, DOI 10.1109/IROS.2001.976290
   Leonard JJ, 2002, INT J ROBOT RES, V21, P943, DOI 10.1177/0278364902021010889
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li MH, 2007, CHINESE J ELECTRON, V16, P34
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YF, 2004, IEEE T ROBOTIC AUTOM, V20, P805, DOI 10.1109/TRO.2004.829500
   Liu YH, 2000, INT J ROBOT RES, V19, P149, DOI 10.1177/02783640022066798
   Liu YH, 2000, IEEE T AUTOMAT CONTR, V45, P2159, DOI 10.1109/9.887656
   Liu YH, 1999, IEEE T ROBOTIC AUTOM, V15, P163, DOI 10.1109/70.744611
   Liu YH, 2006, IEEE T ROBOT, V22, P804, DOI 10.1109/TRO.2006.878788
   Mallapragada V, 2011, IEEE-ASME T MECH, V16, P1011, DOI 10.1109/TMECH.2010.2068575
   Mehta Dushyant, 2017, ARXIV170501583
   Mendoza C, 2003, LECT NOTES COMPUT SC, V2673, P175
   Montemerlo M, 2002, P 8 NAT C ART INT 14, V68, P593
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Navarro-Alarcon D, 2018, IEEE T ROBOT, V34, P272, DOI 10.1109/TRO.2017.2765333
   Navarro-Alarcon D, 2017, IEEE ROBOT AUTOM LET, V2, P1648, DOI 10.1109/LRA.2017.2678542
   Navarro-Alarcon D, 2016, IEEE T ROBOT, V32, P429, DOI 10.1109/TRO.2016.2533639
   Navarro-Alarcon D, 2014, INT J ROBOT RES, V33, P1462, DOI 10.1177/0278364914529355
   Navarro-Alarcon D, 2013, IEEE T ROBOT, V29, P1457, DOI 10.1109/TRO.2013.2275651
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newman P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1802, DOI 10.1109/ROBOT.2002.1014803
   Pan MKXJ, 2017, INT J ROBOT RES, V36, P721, DOI 10.1177/0278364917692865
   Redmon J., 2016, ARXIV161208242
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30
   Schwarz LA, 2012, IMAGE VISION COMPUT, V30, P217, DOI 10.1016/j.imavis.2011.12.001
   Shibata Mizuho, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P134, DOI 10.1109/ROBOT.2009.5152448
   Shibata M, 2006, IEEE INT CONF ROBOT, P2460, DOI 10.1109/ROBOT.2006.1642071
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Simonyan K., 2014, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
   Smolen J., 2009, P INT C ADV COMP HUM, P199
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Suebsomran A, 2002, IEEE ICIT' 02: 2002 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS I AND II, PROCEEDINGS, P365, DOI 10.1109/ICIT.2002.1189923
   Sugita N, 2007, IEEE INT CONF ROBOT, P605, DOI 10.1109/ROBOT.2007.363053
   Sullivan MJ, 1996, IEEE INT CONF ROBOT, P2929, DOI 10.1109/ROBOT.1996.509157
   Sun D, 1997, J DYN SYST-T ASME, V119, P736, DOI 10.1115/1.2802385
   Sun D, 1999, INT J ROBOT RES, V18, P319, DOI 10.1177/02783649922066231
   Thrun S, 1998, AUTON ROBOT, V5, P253, DOI 10.1023/A:1008806205438
   Tokumoto S, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1457, DOI 10.1109/ROBOT.2002.1014749
   Toshev A., 2014, P ADV NEUR INF PROC, P1799, DOI DOI 10.1063/1.5024463
   Valdastril P., 2003, MEASUREMENT SCI TECH, V2673, P175
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wada T, 2001, IEEE INT CONF ROBOT, P85, DOI 10.1109/ROBOT.2001.932534
   Wang CY, 2016, PROC CVPR IEEE, P2639, DOI 10.1109/CVPR.2016.289
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang HS, 2008, IEEE T ROBOT, V24, P843, DOI 10.1109/TRO.2008.2001356
   Wang HS, 2007, IEEE T ROBOT, V23, P610, DOI 10.1109/TRO.2007.895091
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang K, 2015, IEEE T CONTR SYST T, V23, P2391, DOI 10.1109/TCST.2015.2403471
   Wang K, 2014, IEEE T ROBOT, V30, P1026, DOI 10.1109/TRO.2014.2317891
   Wang ZR, 2017, IEEE ROBOT AUTOM LET, V2, P1586, DOI 10.1109/LRA.2017.2676350
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Wu H, 2015, CHINESE J ELECTRON, V24, P795, DOI 10.1049/cje.2015.10.022
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   YUKAWA T, 1995, IEEE INT CONF ROBOT, P324, DOI 10.1109/ROBOT.1995.525305
   Yukawa T, 1996, IEEE INT CONF ROBOT, P2332, DOI 10.1109/ROBOT.1996.506512
   Zacharia P, 2009, IND ROBOT, V36, P489, DOI 10.1108/01439910910980213
NR 100
TC 0
Z9 0
U1 1
U2 41
PU TECHNOLOGY EXCHANGE LIMITED HONG KONG
PI BEIJING
PA BLDG#13, PUHUINANLI, SOUTH YUYUANTAN RD, HAIDIAN DIST, BEIJING, 00000,
   PEOPLES R CHINA
SN 1022-4653
EI 2075-5597
J9 CHINESE J ELECTRON
JI Chin. J. Electron.
PD MAY
PY 2018
VL 27
IS 3
BP 446
EP 458
DI 10.1049/cje.2018.03.007
PG 13
WC Engineering, Electrical & Electronic
SC Engineering
GA GG2IA
UT WOS:000432512200002
DA 2021-02-24
ER

PT J
AU Chang, CB
AF Chang, Charles B.
TI Perceptual attention as the locus of transfer to nonnative speech
   perception
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Selective perception routine; Language transfer; Unreleased stops; Cue
   weighting; Information value; Functional load; Coarticulation
ID PHONOLOGICAL INFLUENCES; LISTENERS PERCEPTION; ENGLISH; IDENTIFICATION;
   CONTRAST; JAPANESE; ADULTS; ASSIMILATION; ACQUISITION; EXPERIENCE
AB One's native language (L1) is known to influence the development of a nonnative language (L2) at multiple levels, but the nature of L1 transfer to L2 perception remains unclear. This study explored the hypothesis that transfer effects in perception come from L1-specific processing strategies, which direct attention to phonetic cues according to their estimated relative functional load (RFL). Using target languages that were either familiar (English) or unfamiliar (Korean), perception of unreleased final stops was tested in L1 English listeners and four groups of L2 English learners whose Lis differ in stop phonotactics and the estimated RFL of a crucial cue to unreleased stops (i.e., vowel-to-consonant formant transitions). Results were, overall, consistent with the hypothesis, with L1 Japanese listeners showing the poorest perception, followed by L1 Mandarin, Russian, English, and Korean listeners. Two exceptions occurred with Russian listeners, who underperformed Mandarin listeners in identification of English stops and outperformed English listeners in identification of Korean stops. Taken together, these findings support a cue-centric view of transfer based on perceptual attention over a direct phonotactic view based on structural conformity. However, transfer interacts with prior L2 knowledge, which may result in significantly different perceptual consequences for a familiar and an unfamiliar L2. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Chang, Charles B.] Boston Univ, Linguist Program, 621 Commonwealth Ave, Boston, MA 02215 USA.
RP Chang, CB (corresponding author), Boston Univ, Linguist Program, 621 Commonwealth Ave, Boston, MA 02215 USA.
EM cc@bu.edu
RI Chang, Charles B./M-1343-2016
OI Chang, Charles B./0000-0002-3537-2053
FU Center for Advanced Study of Language; Department of Hearing and Speech
   Sciences at New York University; Second Language Acquisition Program at
   the University of Maryland; Department of Linguistics at New York
   University
FX The author gratefully acknowledges funding from the Center for Advanced
   Study of Language and logistical assistance from the Department of
   Hearing and Speech Sciences and Second Language Acquisition Program at
   the University of Maryland and from the Department of Linguistics at New
   York University. The paper benefited from the feedback of Taehong Cho,
   Karthik Durvasula, and several anonymous reviewers, as well as
   discussions with Nick Fleisher, Slava Gorbachov, Kevin Roon, Geoff
   Schwartz, and audiences at the CUNY Graduate Center, the University of
   Cambridge, University College London, MIT, the 7th International
   Symposium on the Acquisition of Second Language Speech, and the 167th
   Meeting of the Acoustical Society of America (Chang, 2014).
CR Altenberg Evelyn P., 2005, IRAL-INT REV APPL LI, V43, P53, DOI DOI 10.1191/0267658305SR2500A
   BARRY MC, 1992, SPEECH COMMUN, V11, P393, DOI 10.1016/0167-6393(92)90044-8
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Berent I, 2007, COGNITION, V104, P591, DOI 10.1016/j.cognition.2006.05.015
   Berent I, 2010, J EXP PSYCHOL HUMAN, V36, P212, DOI 10.1037/a0017638
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Blevins Juliette, 2004, EVOLUTIONARY PHONOLO
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Bohn OS, 2012, J PHONETICS, V40, P109, DOI 10.1016/j.wocn.2011.08.002
   Boomershine A, 2008, PHONOL PHONET, V13, P145
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   BROSELOW Ellen, 2013, CAMBRIDGE HDB 2 LANG, P529
   Brown C., 2000, 2 LANGUAGE ACQUISITI, V1, P4
   Brown Cynthia, 1998, SECOND LANG RES, V14, P136, DOI DOI 10.1191/026765898669508401
   Byrd D, 1993, UCLA WORKING PAPERS, V83, P97
   Chang C. B., 2007, P 16 INT C PHON SCI, P1085
   Chang C. B., 2014, J ACOUST SOC AM, V135, P2355
   Chang CB, 2016, BILING-LANG COGN, V19, P791, DOI 10.1017/S1366728914000261
   Chang CB, 2015, SEGMENT IN PHONETICS AND PHONOLOGY, P199
   Chang CB, 2012, J ACOUST SOC AM, V132, P2700, DOI 10.1121/1.4747615
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   Chang CB, 2011, J ACOUST SOC AM, V129, P3964, DOI 10.1121/1.3569736
   Cho TH, 2006, J ACOUST SOC AM, V119, P3085, DOI 10.1121/1.2188917
   Clements G. N., 2003, PHONOLOGY, V20, P287, DOI DOI 10.1017/S095267570400003X
   Cutler A., 2000, INTERPRETING, V5, P1, DOI [10.1075/intp.5.1.02cut, DOI 10.1075/INTP.5.1.02CUT]
   Cutler A, 2008, J ACOUST SOC AM, V124, P1264, DOI 10.1121/1.2946707
   Daniels W. J., 1972, PAP LINGUIST, V5, P366
   Davidson L, 2011, SPEECH COMMUN, V53, P1042, DOI 10.1016/j.specom.2011.05.010
   Davidson L, 2011, J EXP PSYCHOL HUMAN, V37, P270, DOI 10.1037/a0020988
   Davidson L, 2008, J INT PHON ASSOC, V38, P137, DOI 10.1017/S0025100308003447
   Davies M., 2008, CORPUS CONT AM ENGLI
   Dixon P, 2008, J MEM LANG, V59, P447, DOI 10.1016/j.jml.2007.11.004
   Duanmu S., 2007, PHONOLOGY STANDARD C
   Duanmu S, 2014, BLACKW HBK LINGUIST, P422
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Ernestus M, 2017, J PHONETICS, V62, P50, DOI 10.1016/j.wocn.2017.02.003
   Escudero P., 2009, PHONOLOGY PERCEPTION, P151
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, ISSUES CLIN LINGUIST, P19
   del Puerto FG, 2007, INT J MULTILING, V4, P1, DOI 10.2167/ijm042.0
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Halle PA, 1998, J EXP PSYCHOL HUMAN, V24, P592, DOI 10.1037/0096-1523.24.2.592
   Halle PA, 1999, J PHONETICS, V27, P281, DOI 10.1006/jpho.1999.0097
   Halle PA, 2007, J ACOUST SOC AM, V121, P2899, DOI 10.1121/1.2534656
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   IWASAKI Shoichi, 2013, LONDON ORIENTAL AFRI, V17
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jones D., 1969, PHONETICS RUSSIAN
   Kang S., 2014, J ACOUSTICAL SOC AM, V135
   Kang Yoonjung, 2003, PHONOLOGY, V20, P219, DOI DOI 10.1017/S0952675703004524
   Katz J, 2012, J PHONETICS, V40, P390, DOI 10.1016/j.wocn.2012.02.004
   Kim HS, 1996, J PHONETICS, V24, P295, DOI 10.1006/jpho.1996.0016
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Lado R., 1957, LINGUISTICS CULTURES
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   Lindblom B., 2011, TMH QPSR, V51, P41
   Lisker L, 1999, PHONETICA, V56, P44, DOI 10.1159/000028440
   MacMillan N. A., 2005, DETECTION THEORY USE
   Maddieson Ian, 1985, PHONETIC LINGUISTICS, P203
   Major R. C., 2001, FOREIGN ACCENT ONTOG
   MALECOT A, 1958, LANGUAGE, V34, P370, DOI 10.2307/410929
   Martinet A., 1968, MANUAL PHONETICS, P464
   Martinet A., 1933, BSL, V34, P192
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   Newell A., 1981, COGNITIVE SKILLS THE, P1
   Odlin T., 1989, LANGUAGE TRANSFER CR
   Onishi H., 2013, THESIS
   Park H, 2017, J PHONETICS, V62, P12, DOI 10.1016/j.wocn.2017.01.005
   Parlato-Oliveira E, 2010, J ACOUST SOC AM, V127, P3738, DOI 10.1121/1.3327792
   Peperkamp S, 2007, COGNITION, V104, P631, DOI 10.1016/j.cognition.2006.12.009
   POLKA L, 1992, PERCEPT PSYCHOPHYS, V52, P37, DOI 10.3758/BF03206758
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   Rositzke Harry A., 1943, AM SPEECH, V18, P39
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Sohn H.-M., 1999, KOREAN LANGUAGE CAMB
   Steriade D, 2009, CURR STUD LINGUIST, V47, P151
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Tajima K, 2008, J ACOUST SOC AM, V123, P397, DOI 10.1121/1.2804942
   Timberlake Alan, 2004, REFERENCE GRAMMAR RU
   Tsukada K., 2007, P 16 INT C PHON SCI, P1781
   WANG WSY, 1959, J SPEECH HEAR RES, V2, P66, DOI 10.1044/jshr.0201.66
   Wedel A, 2013, COGNITION, V128, P179, DOI 10.1016/j.cognition.2013.03.002
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Wilson C, 2014, J MEM LANG, V77, P1, DOI 10.1016/j.jml.2014.08.001
   Wrembel M., 2014, CONCORDIA WORKING PA, V5, P750
   Zsiga E.C., 2003, STUDIES 2 LANGUAGE A, V25, P399, DOI DOI 10.1017/S0272263103000160
NR 89
TC 6
Z9 6
U1 1
U2 2
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAY
PY 2018
VL 68
BP 85
EP 102
DI 10.1016/j.wocn.2018.03.003
PG 18
WC Linguistics; Language & Linguistics
SC Linguistics
GA GF8OY
UT WOS:000432233400006
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Tessel, CA
   Levy, ES
   Gitterman, M
   Shafer, VL
AF Tessel, Carol A.
   Levy, Erika S.
   Gitterman, Martin
   Shafer, Valerie L.
TI Neurophysiological indices of the effect of cognates on vowel perception
   in late Spanish-English bilinguals
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Bilingualism; Cognates; Event-related potential (ERP); Second language
   acquisition; Speech perception; Vowel perception; Spanish-English
ID MISMATCH NEGATIVITY MMN; NATIVE-LANGUAGE; LEXICAL REPRESENTATION; FRENCH
   VOWELS; BRAIN; SPEECH; WORD; LISTENERS; CONTRAST; DISCRIMINATION
AB It is well established that acquiring a second language (L2) later in life results in less accurate production and perception of speech sounds in the L2. An interesting question is to what extent phonological similarity of translation equivalents across the first language (L1) and L2 affects speech-sound processing and lexical access in an L2.
   The present study examined this question by comparing processing of Spanish-English translation equivalents that either were phonologically similar (cognates) or dissimilar (non-cognates) in fifteen monolingual English speakers and 15 late Spanish-English bilinguals. Event related potentials (ERP) were used to examine whether late L2-learners had more difficulty discriminating mispronunciations of vowels in English words that have Spanish cognates compared to words that do not have cognates. Behavioral results indicated effects of language background and cognate status on discrimination, with bilinguals showing poorer discrimination of English vowel mispronunciations than the American-English monolingual control group. ERP results revealed that cognate words facilitated L2 phonological processing as evidenced by a larger frontal positive component (P400) ERP effect, similar in amplitude to the P400 from monolinguals. Results suggest that cognate words facilitate speech processing in adult L2 learners, and, thus, may also be useful as a tool for perceptual learning of L2 phonology. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Gitterman, Martin; Shafer, Valerie L.] CUNY, Grad Ctr, 365 Fifth Ave, New York, NY 10016 USA.
   [Levy, Erika S.] Columbia Univ, Teachers Coll, Box 5,525 W 120th St, New York, NY 10027 USA.
   [Gitterman, Martin] CUNY, Lehman Coll, Bedford Pk Blvd W, Bronx, NY 10468 USA.
   [Tessel, Carol A.] Florida Atlantic Univ, 777 Glades Rd,POB 3091, Boca Raton, FL 33431 USA.
RP Tessel, CA (corresponding author), Florida Atlantic Univ, 777 Glades Rd,POB 3091, Boca Raton, FL 33431 USA.
EM ctessel@fau.edu
OI Shafer, Valerie/0000-0001-8551-1878
CR Amengual M, 2012, BILING-LANG COGN, V15, P517, DOI 10.1017/S1366728911000460
   Baigorri M., 2016, PHIL PA AM SPEECH LA
   Baker W, 2005, LANG SPEECH, V48, P1, DOI 10.1177/00238309050480010101
   Barrios S, 2016, SECOND LANG RES, V32, DOI 10.1177/0267658316630784
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bice K, 2015, NEUROREPORT, V26, P966, DOI 10.1097/WNR.0000000000000453
   Bohn O.-S., 2011, INT C PHONETIC SCI, P336
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Casillas JV, 2016, SECOND LANG RES, V32, P171, DOI 10.1177/0267658315608912
   Christoffels IK, 2006, J MEM LANG, V54, P324, DOI 10.1016/j.jml.2005.12.004
   Colome A, 2001, J MEM LANG, V45, P721
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Costa A, 1999, J MEM LANG, V41, P365, DOI 10.1006/jmla.1999.2651
   Costa A, 2000, J EXP PSYCHOL LEARN, V26, P1283, DOI 10.1037//0278-7393.26.5.1283
   Costa A, 2005, BRAIN LANG, V94, P94, DOI 10.1016/j.bandl.2004.12.002
   D'Arcy RCN, 2000, CLIN NEUROPHYSIOL, V111, P40, DOI 10.1016/S1388-2457(99)00210-2
   De Bleser R, 2003, J NEUROLINGUIST, V16, P439, DOI 10.1016/S0911-6044(03)00022-8
   DEGROOT AMB, 1991, J MEM LANG, V30, P90, DOI 10.1016/0749-596X(91)90012-9
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P635, DOI 10.1162/089892900562390
   Dell GS, 1997, PSYCHOL REV, V104, P801, DOI 10.1037/0033-295X.104.4.801
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   DERWING TM, 2003, CANADIAN MODERN LANG, V59, P545, DOI DOI 10.3138/CMLR.59.4.547
   Dijkstra A., 1999, J MEM LANG, V42, P465
   Dijkstra T, 1998, SCI PSYCH S, P189
   Dijkstra T, 2010, J MEM LANG, V62, P284, DOI 10.1016/j.jml.2009.12.003
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   Dunn L. M., 1986, TEST VOCABULARIO IMA
   Escudero P., 2005, THESIS, V113
   Flege J. E., 1992, PHONOLOGICAL DEV MOD, P233
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1994, J ACOUST SOC AM, V95, P3623, DOI 10.1121/1.409931
   FLEGE JE, 1991, Q J EXP PSYCHOL-A, V43, P701, DOI 10.1080/14640749108400993
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   FOX RA, 1984, J EXP PSYCHOL HUMAN, V10, P526, DOI 10.1037/0096-1523.10.4.526
   FOX RA, 1995, J ACOUST SOC AM, V97, P2540, DOI 10.1121/1.411974
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gollan TH, 2004, J EXP PSYCHOL LEARN, V30, P246, DOI 10.1037/0278-7393.30.1.246
   Green D. W., 1998, BILING-LANG COGN, V1, P67, DOI [10.1017/S1366728998000133, DOI 10.1017/S1366728998000133]
   Hammond RH, 1986, LENGUAS MODERNAS, V13, P129
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hisagi M, 2015, BILING-LANG COGN, V18, P271, DOI 10.1017/S1366728914000170
   Hisagi M, 2010, BRAIN RES, V1360, P89, DOI 10.1016/j.brainres.2010.08.092
   HOLCOMB PJ, 1990, LANG COGNITIVE PROC, V5, P281, DOI 10.1080/01690969008407065
   Juottonen K, 1996, COGNITIVE BRAIN RES, V4, P99
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   Levy ES, 2010, J ACOUST SOC AM, V128, P1290, DOI 10.1121/1.3466879
   Levy ES, 2009, J ACOUST SOC AM, V126, P2670, DOI 10.1121/1.3224715
   Linden DEJ, 2005, NEUROSCIENTIST, V11, P563, DOI 10.1177/1073858405280524
   MACDONALD MG, 1989, AM SPANISH PRONUNCIA, P215
   Midgley KJ, 2011, J COGNITIVE NEUROSCI, V23, P1634, DOI 10.1162/jocn.2010.21463
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Nip ISB, 2015, J SPEECH LANG HEAR R, V58, P653, DOI 10.1044/2015_JSLHR-S-13-0299
   OYAMA S, 1976, J PSYCHOLINGUIST RES, V5, P261, DOI 10.1007/BF01067377
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   Peltola MS, 2003, NEUROSCI LETT, V352, P25, DOI 10.1016/j.neulet.2003.08.013
   Pickering EC, 2003, J EXP PSYCHOL LEARN, V29, P1298, DOI 10.1037/0278-7393.29.6.1298
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Polich J., 2003, DETECTION CHANGE EVE, P83, DOI DOI 10.1007/978-1-4615-0294-4_
   PRAAMSTRA P, 1993, COGNITIVE BRAIN RES, V1, P73, DOI 10.1016/0926-6410(93)90013-U
   PRAAMSTRA P, 1994, J COGNITIVE NEUROSCI, V6, P204, DOI 10.1162/jocn.1994.6.3.204
   R Core Team, 2013, R LANG ENV STAT COMP
   RUGG MD, 1990, MEM COGNITION, V18, P367, DOI 10.3758/BF03197126
   SANCHEZCASAS RM, 1992, EUR J COGN PSYCHOL, V4, P293
   Schoonbaert S, 2011, PSYCHOPHYSIOLOGY, V48, P74, DOI 10.1111/j.1469-8986.2010.01048.x
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   Sebastian-Galles N, 2006, J COGNITIVE NEUROSCI, V18, P1277, DOI 10.1162/jocn.2006.18.8.1277
   Shook A, 2013, BILING-LANG COGN, V16, P304, DOI 10.1017/S1366728912000466
   SQUIRES NK, 1975, ELECTROEN CLIN NEURO, V38, P387, DOI 10.1016/0013-4694(75)90263-1
   Strange W, 1998, J PHONETICS, V26, P311, DOI 10.1006/jpho.1998.0078
   Strange W., 2006, J ACOUST SOC AM, V120, P3137, DOI DOI 10.1121/1.4787743
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Strijkers K., 2009, CEREB CORTEX
   Verleger R, 2005, J PSYCHOPHYSIOL, V19, P165, DOI 10.1027/0269-8803.19.3.165
   Wagner M, 2012, BRAIN LANG, V123, P30, DOI 10.1016/j.bandl.2012.06.002
   Yu YH, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00095
   Yudes C, 2010, NEUROREPORT, V21, P507, DOI 10.1097/WNR.0b013e328338b9e1
NR 83
TC 1
Z9 1
U1 2
U2 11
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAY
PY 2018
VL 68
BP 117
EP 137
DI 10.1016/j.wocn.2018.03.004
PG 21
WC Linguistics; Language & Linguistics
SC Linguistics
GA GF8OY
UT WOS:000432233400008
OA Green Published
DA 2021-02-24
ER

PT J
AU Rominger, C
   Schulter, G
   Fink, A
   Weiss, EM
   Papousek, I
AF Rominger, Christian
   Schulter, Guenter
   Fink, Andreas
   Weiss, Elisabeth M.
   Papousek, Ilona
TI Meaning in meaninglessness: The propensity to perceive meaningful
   patterns in coincident events and randomly arranged stimuli is linked to
   enhanced attention in early sensory processing
SO PSYCHIATRY RESEARCH
LA English
DT Article
DE Meaningful coincidences; Apophenia; Positive schizotypy; Dichotic
   Listening Test; Lateralized speech perception
ID AUDITORY VERBAL HALLUCINATIONS; PERSONALITY-QUESTIONNAIRE SPQ; TOP-DOWN
   CONTROL; III-R CRITERIA; PARANORMAL BELIEF; SCHIZOTYPAL-PERSONALITY;
   LANGUAGE LATERALIZATION; INDIVIDUAL-DIFFERENCES; LATENT INHIBITION;
   SCHIZOPHRENIA-PATIENTS
AB Perception of objectively independent events or stimuli as being significantly connected and the associated proneness to perceive meaningful patterns constitute part of the positive symptoms of schizophrenia, which are associated with altered attentional processes in lateralized speech perception. Since perceiving meaningful patterns is to some extent already prevalent in the general population, the aim of the study was to investigate whether the propensity to experience meaningful patterns in co-occurring events and random stimuli may be associated with similar altered attentional processes in lateralized speech perception. Self-reported and behavioral indicators of the perception of meaningful patterns were assessed in non-clinical individuals, along with EEG auditory evoked potentials during the performance of an attention related lateralized speech perception task (Dichotic Listening Test). A greater propensity to perceive meaningful patterns was associated with higher Ni amplitudes of the evoked potentials to the onset of the dichotically presented consonant-vowel syllables, indicating enhanced automatic attention in early sensory processing. The study suggests that more basic mechanisms in how people associate events may play a greater role in the cognitive biases that are manifest in personality expressions such as positive schizotypy, rather than that positive schizotypy moderates these cognitive biases directly.
C1 [Rominger, Christian; Schulter, Guenter; Fink, Andreas; Weiss, Elisabeth M.; Papousek, Ilona] Karl Franzens Univ Graz, Dept Psychol, Biol Psychol Unit, Univ Pl 2, A-8010 Graz, Austria.
RP Rominger, C (corresponding author), Karl Franzens Univ Graz, Dept Psychol, Biol Psychol Unit, Univ Pl 2, A-8010 Graz, Austria.
EM christian.rominger@uni-graz.at
RI Rominger, Christian/H-7625-2019; Papousek, Ilona/H-3043-2019
OI Rominger, Christian/0000-0003-3195-4555; Papousek,
   Ilona/0000-0002-6620-0318; Fink, Andreas/0000-0001-7316-3140
CR Adcock RA, 2009, SCHIZOPHRENIA BULL, V35, P1132, DOI 10.1093/schbul/sbp068
   ADLER G, 1990, ACTA PSYCHIAT SCAND, V81, P453, DOI 10.1111/j.1600-0447.1990.tb05480.x
   Blackmore S., 1994, EUROPEAN J PARAPSYCH, V10, P91, DOI [10.1162/jocn.2009.21313, DOI 10.1162/J0CN.2009.21313]
   Blakemore SJ, 2003, PSYCHOL MED, V33, P1433, DOI 10.1017/S0033291703008341
   Braunstein-Bercovitz H, 2002, SCHIZOPHR RES, V53, P109, DOI 10.1016/S0920-9964(01)00166-9
   Bressan P, 2002, APPL COGNITIVE PSYCH, V16, P17, DOI 10.1002/acp.754
   Bressan P, 2008, CORTEX, V44, P1299, DOI 10.1016/j.cortex.2007.08.021
   Bruder G, 1999, ARCH GEN PSYCHIAT, V56, P267, DOI 10.1001/archpsyc.56.3.267
   BRUDER G, 1995, AM J PSYCHIAT, V152, P932
   BRUDER GE, 1983, SCHIZOPHRENIA BULL, V9, P134, DOI 10.1093/schbul/9.1.134
   BRUGGER P, 1990, BRIT J PSYCHOL, V81, P455, DOI 10.1111/j.2044-8295.1990.tb02372.x
   BRUGGER P, 1995, J GENET PSYCHOL, V156, P385, DOI 10.1080/00221325.1995.9914831
   BRUGGER P, 1993, PERCEPT MOTOR SKILL, V77, P1299, DOI 10.2466/pms.1993.77.3f.1299
   BRUGGER P, 1993, PSYCHOPATHOLOGY, V26, P261, DOI 10.1159/000284831
   Bryden M.P., 1982, LATERALITY FUNCTIONA
   Budd TW, 1998, INT J PSYCHOPHYSIOL, V31, P51, DOI 10.1016/S0167-8760(98)00040-3
   Calkins ME, 2004, SCHIZOPHRENIA BULL, V30, P317, DOI 10.1093/oxfordjournals.schbul.a007081
   Carson SH, 2003, J PERS SOC PSYCHOL, V85, P499, DOI 10.1037/0022-3514.85.3.499
   Chadwick PK, 2007, SCHIZOPHRENIA BULL, V33, P166, DOI 10.1093/schbul/sbl034
   CHAPMAN LJ, 1994, J ABNORM PSYCHOL, V103, P171, DOI 10.1037/0021-843X.103.2.171
   Christman SD, 2008, LATERALITY, V13, P403, DOI 10.1080/13576500802079646
   Claridge Gordon, 1997, SCHIZOTYPY IMPLICATI, DOI [10.1093/med:psych/9780198523536.001.0001, DOI 10.1093/MED:PSYCH/9780198523536.003.0001]
   CLARIDGE GS, 1966, BRIT J SOC CLIN PSYC, V5, P63
   Collinson SL, 2009, SCHIZOPHR RES, V112, P24, DOI 10.1016/j.schres.2009.03.034
   Conrad K., 1958, BEGINNENDE SCHIZOPHR
   Dagnall N, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01045
   Dale CL, 2016, SCHIZOPHRENIA BULL, V42, P220, DOI 10.1093/schbul/sbv087
   DeYoung CG, 2012, J RES PERS, V46, P63, DOI 10.1016/j.jrp.2011.12.003
   DIACONIS P, 1989, J AM STAT ASSOC, V84, P853, DOI 10.2307/2290058
   Drey Fuchs C., 1958, FUCHS RORSCHACH TEST
   Eichele T, 2005, COGNITIVE BRAIN RES, V24, P405, DOI 10.1016/j.cogbrainres.2005.02.017
   Elbers N, 2007, THEOR PSYCHOL, V17, P587, DOI 10.1177/0959354307079305
   Ethridge LE, 2015, BIOL PSYCHIAT, V77, P127, DOI 10.1016/j.biopsych.2014.03.032
   Ettinger U., 2015, SCHIZOPHR B, V41, P26
   Farias M, 2005, PERS INDIV DIFFER, V39, P979, DOI 10.1016/j.paid.2005.04.003
   Fletcher PC, 2009, NAT REV NEUROSCI, V10, P48, DOI 10.1038/nrn2536
   Folyi T, 2016, BIOL PSYCHOL, V114, P23, DOI 10.1016/j.biopsycho.2015.12.001
   Force RB, 2008, SCHIZOPHR RES, V103, P298, DOI 10.1016/j.schres.2008.04.038
   Ford JM, 2001, BIOL PSYCHIAT, V49, P848, DOI 10.1016/S0006-3223(00)01051-9
   Ford JM, 2014, SCHIZOPHRENIA BULL, V40, P804, DOI 10.1093/schbul/sbt072
   Ford JM, 2012, SCHIZOPHRENIA BULL, V38, P715, DOI 10.1093/schbul/sbs009
   Foxe JJ, 2011, EUR ARCH PSY CLIN N, V261, P331, DOI 10.1007/s00406-010-0176-0
   Frith C. D., 1992, ESSAYS COGNITIVE NEU
   Fyfe S, 2008, CORTEX, V44, P1316, DOI 10.1016/j.cortex.2007.07.009
   Gallinat J, 2002, NEUROIMAGE, V17, P110, DOI 10.1006/nimg.2002.1213
   Gallinat J, 2004, CLIN NEUROPHYSIOL, V115, P1863, DOI 10.1016/j.clinph.2004.03.013
   Gianotti LRR, 2001, PSYCHIAT CLIN NEUROS, V55, P595, DOI 10.1046/j.1440-1819.2001.00911.x
   Grant P, 2015, FRONT PSYCHIATRY, V6, DOI 10.3389/fpsyt.2015.00143
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9
   Grimshaw G. M., 2015, SCHIZOTYPY NEW DIMEN, P62
   Hadlaczky G, 2011, PERCEPT MOTOR SKILL, V113, P894, DOI 10.2466/09.22.PMS.113.6.894-908
   Hagemann D, 2004, BIOL PSYCHOL, V67, P157, DOI 10.1016/j.biopsycho.2004.03.006
   Hausmann M, 2000, NEUROPSYCHOLOGIA, V38, P1362, DOI 10.1016/S0028-3932(00)00045-2
   Hemsey DR, 2005, NEUROSCI BIOBEHAV R, V29, P977, DOI 10.1016/j.neubiorev.2004.12.008
   HEMSLEY DR, 1993, BEHAV RES THER, V31, P633, DOI 10.1016/0005-7967(93)90116-C
   Hergovich A, 2005, PERS INDIV DIFFER, V38, P1805, DOI 10.1016/j.paid.2004.11.008
   Hiscock M, 2011, BRAIN COGNITION, V76, P263, DOI 10.1016/j.bandc.2011.03.016
   Hubl D, 2007, BRIT J PSYCHIAT, V190, P57, DOI 10.1192/bjp.bp.106.022954
   HUGDAHL K, 1986, CORTEX, V22, P417, DOI 10.1016/S0010-9452(86)80005-3
   Hugdahl K, 2015, WORLD J PSYCHIATR, V5, P193, DOI 10.5498/wjp.v5.i2.193
   Hugdahl K, 2013, SCHIZOPHR RES, V147, P301, DOI 10.1016/j.schres.2013.04.005
   Hugdahl K, 2012, SCHIZOPHR RES, V140, P59, DOI 10.1016/j.schres.2012.06.019
   Hugdahl K, 2009, SCAND J PSYCHOL, V50, P553, DOI 10.1111/j.1467-9450.2009.00775.x
   JAKES S, 1986, PERS INDIV DIFFER, V7, P121, DOI 10.1016/0191-8869(86)90118-2
   Jasper JD, 2014, ACTA PSYCHOL, V148, P115, DOI 10.1016/j.actpsy.2014.01.004
   Johns LC, 2001, CLIN PSYCHOL REV, V21, P1125, DOI 10.1016/S0272-7358(01)00103-9
   Kammerer P., 1919, GESETZ SERIE LEHRE W
   Kapur S, 2003, AM J PSYCHIAT, V160, P13, DOI 10.1176/appi.ajp.160.1.13
   KESSLER C, 1989, BIOL PSYCHIAT, V26, P372, DOI 10.1016/0006-3223(89)90053-X
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   KINSBOURNE M, 1970, ACTA PSYCHOL, V33, P193, DOI 10.1016/0001-6918(70)90132-0
   Klein C, 1997, DIAGNOSTICA, V43, P347
   Klein C, 1999, BIOL PSYCHIAT, V45, P1612, DOI 10.1016/S0006-3223(98)00254-6
   Krishnan RR, 2011, PSYCHIAT CLIN NEUROS, V65, P305, DOI 10.1111/j.1440-1819.2011.02203.x
   Krummenacher P, 2010, J COGNITIVE NEUROSCI, V22, P1670, DOI 10.1162/jocn.2009.21313
   Kuhnis J, 2014, J COGNITIVE NEUROSCI, V26, P2750, DOI 10.1162/jocn_a_00674
   Lawrence E, 2004, J NERV MENT DIS, V192, P727, DOI 10.1097/01.nmd.0000144691.22135.d0
   LAWRENCE T, 1995, PERS INDIV DIFFER, V19, P209, DOI 10.1016/0191-8869(95)00034-4
   Lenzenweger MF, 2015, SCHIZOPHRENIA BULL, V41, pS483, DOI 10.1093/schbul/sbu184
   MEEHL PE, 1962, AM PSYCHOL, V17, P827, DOI 10.1037/h0041029
   Merckelbach H, 2001, J BEHAV THER EXP PSY, V32, P137, DOI 10.1016/S0005-7916(01)00029-5
   Mohr C, 2005, CEREB CORTEX, V15, P1451, DOI 10.1093/cercor/bhi025
   Morrison PD, 2009, SCHIZOPHRENIA BULL, V35, P668, DOI 10.1093/schbul/sbp049
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Ocklenburg S, 2013, J INT NEUROPSYCH SOC, V19, P410, DOI 10.1017/S1355617712001476
   Oertel-Knochell V, 2011, NEUROSCIENTIST, V17, P456, DOI 10.1177/1073858410386493
   OVERBY LA, 1992, J ABNORM PSYCHOL, V101, P96, DOI 10.1037/0021-843X.101.1.96
   Papousek I, 1999, Laterality, V4, P345, DOI 10.1080/713754344
   Park H. R. P., 2016, ASS SCHIZOTYPY CEREB
   POREH AM, 1993, CURR PSYCHOL, V12, P344, DOI 10.1007/BF02686814
   RAINE A, 1991, SCHIZOPHRENIA BULL, V17, P555, DOI 10.1093/schbul/17.4.555
   RAMACHANDRAN VS, 1995, CONSCIOUS COGN, V4, P22, DOI 10.1006/ccog.1995.1002
   Rattet SL, 2001, PERS INDIV DIFFER, V31, P433, DOI 10.1016/S0191-8869(00)00148-3
   Rominger C, 2016, SCHIZOPHR RES, V174, P192, DOI 10.1016/j.schres.2016.05.006
   Rominger C, 2014, LATERALITY, V19, P424, DOI 10.1080/1357650X.2013.858725
   Rominger C, 2011, PERS INDIV DIFFER, V51, P1002, DOI 10.1016/j.paid.2011.08.012
   Rorschach H., 1949, RORSCHACH TEST
   Rosburg T, 2008, PSYCHIAT RES, V161, P259, DOI 10.1016/j.psychres.2008.03.017
   RUST J, 1977, PSYCHOPHYSIOLOGY, V14, P123, DOI 10.1111/j.1469-8986.1977.tb03361.x
   Sable JJ, 2004, PSYCHOPHYSIOLOGY, V41, P636, DOI 10.1111/j.1469-8986.2004.00192.x
   Salisbury DF, 2010, SCHIZOPHRENIA BULL, V36, P991, DOI 10.1093/schbul/sbp003
   Sannwald G., 1962, Z PARAPSYCHOL GRENZE, V6, P28
   Schienle A, 1996, PSYCHOL REP, V78, P291, DOI 10.2466/pr0.1996.78.1.291
   Schofield K, 2014, LATERALITY, V19, P178, DOI 10.1080/1357650X.2013.789883
   Sommer I, 2001, BRIT J PSYCHIAT, V178, P344, DOI 10.1192/bjp.178.4.344
   Steingriiber H.-J., 1971, HAND DOMINANZ TEST H
   Sumich A, 2014, PERS INDIV DIFFER, V61-62, P74, DOI 10.1016/j.paid.2014.01.009
   Sumich A, 2008, CORTEX, V44, P1342, DOI 10.1016/j.cortex.2007.10.012
   Tallus J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139318
   Valkonen-Korhonen M, 2003, COGNITIVE BRAIN RES, V17, P747, DOI 10.1016/S0926-6410(03)00199-X
   Valkonen-Korhonen M, 2002, SCHIZOPHR RES, V55, P291, DOI 10.1016/S0920-9964(01)00282-1
   Weinstein S, 2002, BRAIN COGNITION, V49, P138, DOI 10.1006/brcg.2001.1493
   Weiss EM, 2006, PSYCHIAT RES-NEUROIM, V146, P185, DOI 10.1016/j.pscychresns.2005.11.003
   Westerhausen R, 2015, DEV PSYCHOL, V51, P806, DOI 10.1037/dev0000014
   Wuthrich V, 2005, PERS INDIV DIFFER, V38, P1543, DOI 10.1016/j.paid.2004.09.017
   YATES JF, 1986, ACTA PSYCHOL, V62, P293, DOI 10.1016/0001-6918(86)90092-2
   Zhu JJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep33857
   Zulliger H., 1951, DER Z TEST
   Zulliger H., 1946, BEHN RORSCHACH TEST
NR 119
TC 2
Z9 2
U1 1
U2 11
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0165-1781
J9 PSYCHIAT RES
JI Psychiatry Res.
PD MAY
PY 2018
VL 263
BP 225
EP 232
DI 10.1016/j.psychres.2017.07.043
PG 8
WC Psychiatry
SC Psychiatry
GA GF8PK
UT WOS:000432234600037
PM 29179910
DA 2021-02-24
ER

PT J
AU van Knijff, EC
   Coene, M
   Govaerts, PJ
AF van Knijff, Eline C.
   Coene, Martine
   Govaerts, Paul J.
TI Speech understanding in noise in elderly adults: the effect of
   inhibitory control and syntactic complexity
SO INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS
LA English
DT Article
DE speech-in-noise; speech perception; syntactic complexity; inhibitory
   control; hearing loss; presbycusis
ID SENTENCE INTELLIGIBILITY TEST; WORKING-MEMORY CAPACITY; HEARING-LOSS;
   LINGUISTIC COMPLEXITY; RECEPTION THRESHOLD; MASKING RELEASE; SIMON TASK;
   LIFE-SPAN; LISTENERS; COGNITION
AB BackgroundPrevious research has suggested that speech perception in elderly adults is influenced not only by age-related hearing loss or presbycusis but also by declines in cognitive abilities, by background noise and by the syntactic complexity of the message.
   AimsTo gain further insight into the influence of these cognitive as well as acoustic and linguistic factors on speech perception in elderly adults by investigating inhibitory control as a listener characteristic and background noise type and syntactic complexity as input characteristics.
   Methods & ProceduresPhoneme identification was measured in different noise conditions and in different linguistic contexts (single words, sentences with varying syntactic complexity). Additionally, inhibitory control was measured using a visual stimulus-response matching task. Fifty-one adults participated in this study, including elderly adults with age-related hearing loss (n = 9) and with normal hearing (n = 17), and a control group of normal hearing younger adults (n = 25).
   Outcomes & ResultsThe analysis revealed that elderly adults with normal hearing and with hearing loss were less likely to identify successfully phonemes in single words than younger normal hearing controls. In the context of sentences, only elderly adults with hearing loss had a lower odds of correct phoneme perception than the control group. Additionally, in elderly adults with hearing loss, phoneme-in-sentence perception was linked to age-related declines in inhibitory control. In all participants, phoneme identification in sentences was influenced by both noise type and syntactic complexity.
   Conclusions & ImplicationsInhibitory control and syntactic complexity might play a significant role in speech perception, especially in elderly listeners. These factors might also influence the results of clinical assessments of speech perception. Testing procedures thus need to be selected and their results interpreted carefully with these influences in mind.
C1 [van Knijff, Eline C.; Coene, Martine; Govaerts, Paul J.] Vrije Univ Amsterdam, Language & Hearing Ctr Amsterdam, Amsterdam, Netherlands.
   [Coene, Martine; Govaerts, Paul J.] Eargroup, Antwerp, Belgium.
RP Coene, M (corresponding author), VU Free Univ Amsterdam, Dept Language Literature & Commun, Language & Hearing Ctr Amsterdam, De Boelelaan 1105, NL-1081 HV Amsterdam, Netherlands.
EM m.m.r.coene@vu.nl
OI Coene, Martine/0000-0001-9201-7667
FU European UnionEuropean Commission [324401]
FX The authors thank all the participants for their participation in this
   study. Furthermore, they thank the reviewers for their suggestions and
   helpful comments made on an earlier version of the manuscript. The study
   received funding from the European Union's Seventh Framework Programme
   (FP7-PEOPLE-2012-IAPP) (grant agreement number 324401).
CR Amieva H, 2015, J AM GERIATR SOC, V63, P2099, DOI 10.1111/jgs.13649
   Benichov J, 2012, EAR HEARING, V33, P262, DOI 10.1097/AUD.0b013e31822f680f
   Bialystok E, 2004, PSYCHOL AGING, V19, P290, DOI 10.1037/0882-7974.19.2.290
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Borella E, 2008, ACTA PSYCHOL, V128, P33, DOI 10.1016/j.actpsy.2007.09.008
   Carroll R, 2013, J PSYCHOLINGUIST RES, V42, P139, DOI 10.1007/s10936-012-9213-7
   Clarke J, 2014, HEARING RES, V315, P80, DOI 10.1016/j.heares.2014.07.002
   Coene M, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/7249848
   Coene M, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/932519
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   CUTLER A, 1977, LANG SPEECH, V20, P1
   Dawes P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119616
   FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247
   Francart T, 2011, INT J AUDIOL, V50, P2, DOI 10.3109/14992027.2010.505582
   Fullgrabe C, 2006, HEARING RES, V211, P74, DOI 10.1016/j.heares.2005.09.001
   George ELJ, 2007, J ACOUST SOC AM, V121, P2362, DOI 10.1121/1.2642072
   George ELJ, 2006, J ACOUST SOC AM, V120, P2295, DOI 10.1121/1.2266530
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   Govaerts P J, 2006, Cochlear Implants Int, V7, P92, DOI 10.1179/146701006807508106
   Hawkins J. A., 1994, PERFORMANCE THEORY O
   Hawkins J. A., 1994, EFFICIENCY COMPLEXIT
   Hawkins John A., 2014, CROSS LINGUISTIC VAR
   Houtgast T, 2008, INT J AUDIOL, V47, P287, DOI 10.1080/14992020802127109
   Kapteyn T. S., 2012, AUDIOLOGIEBOEK 7 2 6
   Koelewijn Thomas, 2012, Int J Otolaryngol, V2012, P865731, DOI 10.1155/2012/865731
   Lamore P. J., 2010, AUDIOLOGIEBOEK 2 9 1
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Meister H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00301
   MUELLER ST, 2012, PEBL PSYCHOL EXPT BU
   Newhart H., 1945, T AM ACAD OPHTHAL S1, P1
   Oostdijk N., 2003, LINK, V14, P3
   Pan W, 2001, BIOMETRICS, V57, P120, DOI 10.1111/j.0006-341X.2001.00120.x
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   Rietveld A. C. M., 2013, ALGEMENE FONETIEK
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rudner M, 2012, J AM ACAD AUDIOL, V23, P577, DOI 10.3766/jaaa.23.7.7
   Selkirk E., 1995, HDB PHONOLOGICAL THE, p550e569
   Selkirk Elizabeth, 1984, PHONOLOGY SYNTAX REL
   SIMON JR, 1963, ERGONOMICS, V6, P99, DOI 10.1080/00140136308930679
   Stenback V., 2016, THESIS, V80
   Sweeney JA, 2001, NEUROBIOL AGING, V22, P39, DOI 10.1016/S0197-4580(00)00175-5
   Tun PA, 2012, AM J AUDIOL, V21, P344, DOI 10.1044/1059-0889(2012/12-0030)
   Uslar V, 2011, INT J AUDIOL, V50, P621, DOI 10.3109/14992027.2011.582166
   Uslar VN, 2013, J ACOUST SOC AM, V134, P3039, DOI 10.1121/1.4818760
   Van der Lubbe RHJ, 2002, PSYCHOPHYSIOLOGY, V39, P100, DOI 10.1017/S0048577202001221
   Wingfield A, 2006, J AM ACAD AUDIOL, V17, P487, DOI 10.3766/jaaa.17.7.4
   World Health Organization, 2017, DEAFN HEAR LOSS FACT
   Zelazo PD, 2004, ACTA PSYCHOL, V115, P167, DOI 10.1016/j.actpsy.2003.12.005
NR 52
TC 1
Z9 1
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1368-2822
EI 1460-6984
J9 INT J LANG COMM DIS
JI Int. J. Lang. Commun. Disord.
PD MAY-JUN
PY 2018
VL 53
IS 3
BP 628
EP 642
DI 10.1111/1460-6984.12376
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GF5MC
UT WOS:000432010500017
PM 29446191
DA 2021-02-24
ER

PT J
AU Singh, L
   Fu, CSL
   Tay, ZW
   Golinkoff, RM
AF Singh, Leher
   Fu, Charlene S. L.
   Tay, Zhi Wen
   Golinkoff, Roberta Michnick
TI Novel Word Learning in Bilingual and Monolingual Infants: Evidence for a
   Bilingual Advantage
SO CHILD DEVELOPMENT
LA English
DT Article
ID VISUAL LANGUAGE DISCRIMINATION; EARLY LEXICAL ACQUISITION; PHONETIC
   SPECIFICITY; 14-MONTH-OLD INFANTS; VOCALIC INFORMATION;
   SPEECH-PERCEPTION; 1ST YEAR; CONSONANTS; VOWELS; BIAS
AB Previous studies revealing that monolingual and bilingual infants learn similar sounding words with comparable success are largely based on prior investigations involving single-feature changes in the onset consonant of a word. There have been no investigations of bilingual infants' abilities to learn similar sounding words differentiated by vowels. In the current study, 18-month-old bilingual and monolingual infants (n=90) were compared on their sensitivity to a vowel change when learning the meanings of words. Bilingual infants learned similar sounding words differing by a vowel contrast, whereas monolingual English- and Mandarin-learning infants did not. Findings are discussed in terms of early constraints on novel word learning in bilingual and monolingual infants.
C1 [Singh, Leher; Fu, Charlene S. L.; Tay, Zhi Wen] Natl Univ Singapore, Singapore, Singapore.
   [Golinkoff, Roberta Michnick] Univ Delaware, Newark, DE USA.
RP Singh, L (corresponding author), Natl Univ Singapore, Dept Psychol, AS 4,03-40,9 Arts Link, Singapore 117570, Singapore.
EM leher.singh.nus@gmail.com
OI Fu, Charlene/0000-0003-3130-0324
FU Ministry of Education, SingaporeMinistry of Education, Singapore
   [FY2013-FRC2-009]; HSS Seed Grant; Singapore Children's Society;
   Institute of Education SciencesUS Department of Education [R305A100215,
   R305A090525]
FX We are grateful to Natalie Brezack, Felicia Poh, Tara Saunders, and Dilu
   Wewalaarachchi for assistance with recruitment and testing. This
   research was supported by a grant from the Ministry of Education,
   Singapore (MOE Tier 1 Grant FY2013-FRC2-009) and an HSS Seed Grant to
   Leher Singh, a grant from the Singapore Children's Society to Zhi Wen
   Tay, and grants by the Institute of Education Sciences (R305A100215 and
   R305A090525) to Roberta Michnick Golinkoff.
CR Acha J, 2010, EXP PSYCHOL, V57, P245, DOI 10.1027/1618-3169/a000029
   [Anonymous], 2008, COGNITION, V106, P833, DOI 10.1016/j.cognition.2007.05.002
   Apfelbaum KS, 2011, COGNITIVE SCI, V35, P1105, DOI 10.1111/j.1551-6709.2011.01181.x
   Bartolotti J, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00324
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Bialystok E, 2010, BILING-LANG COGN, V13, P525, DOI 10.1017/S1366728909990423
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Byers-Heinlein K, 2013, BILING-LANG COGN, V16, P198, DOI 10.1017/S1366728912000417
   Caramazza A, 2000, NATURE, V403, P428, DOI 10.1038/35000206
   Carreiras M, 2009, J COGNITIVE NEUROSCI, V21, P275, DOI 10.1162/jocn.2008.21023
   Chen F, 2015, J PHONETICS, V52, P26, DOI 10.1016/j.wocn.2015.04.003
   Curtin S, 2009, DEVELOPMENTAL SCI, V12, P725, DOI 10.1111/j.1467-7687.2009.00814.x
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   CUTLER A, 1993, J PHONETICS, V21, P103, DOI 10.1016/S0095-4470(19)31323-3
   De Houwer A, 2014, APPL PSYCHOLINGUIST, V35, P1189, DOI 10.1017/S0142716412000744
   DIETRICH C, 2004, BOST U C LANG DEV BO
   DODD B, 1977, PERCEPTION, V6, P31, DOI 10.1068/p060031
   Fennell C. T., 2011, 8 INT S BIL OSL NORW
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Fennell CT, 2007, CHILD DEV, V78, P1510, DOI 10.1111/j.1467-8624.2007.01080.x
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Figueroa RL, 2012, BMC MED INFORM DECIS, V12, DOI 10.1186/1472-6947-12-8
   Floccia C, 2014, J CHILD LANG, V41, P1085, DOI 10.1017/S0305000913000287
   Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430
   GROSJEAN F, 1989, BRAIN LANG, V36, P3, DOI 10.1016/0093-934X(89)90048-5
   Havy M, 2016, INT J BEHAV DEV, V40, P41, DOI 10.1177/0165025415570646
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Havy M, 2009, INFANCY, V14, P439, DOI 10.1080/15250000902996532
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   Hojen A, 2016, DEVELOPMENTAL SCI, V19, P41, DOI 10.1111/desc.12286
   Kan PF, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01024
   Kaushanskaya M, 2009, J EXP PSYCHOL LEARN, V35, P829, DOI 10.1037/a0015275
   Kolinsky R, 2009, COGNITION, V112, P1, DOI 10.1016/j.cognition.2009.02.014
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Ladefoged P., 2006, COURSE PHONETICS
   Liu LQ, 2016, INT J BILINGUAL, V20, P335, DOI 10.1177/1367006914566082
   Mani N, 2008, DEVELOPMENTAL SCI, V11, P53, DOI 10.1111/j.1467-7687.2007.00645.x
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   Mattock K, 2010, DEVELOPMENTAL SCI, V13, P229, DOI 10.1111/j.1467-7687.2009.00891.x
   Mayor J, 2010, PSYCHOL REV, V117, P1, DOI 10.1037/a0018130
   McMurray B, 2007, SCIENCE, V317, P631, DOI 10.1126/science.1144073
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Nazzi T, 2007, COGNITIVE DEV, V22, P271, DOI 10.1016/j.cogdev.2006.10.007
   Nazzi T, 2009, LANG SPEECH, V52, P463, DOI 10.1177/0023830909336584
   Nazzi T, 2009, J EXP CHILD PSYCHOL, V102, P522, DOI 10.1016/j.jecp.2008.05.003
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   New B, 2014, LANG COGN NEUROSCI, V29, P147, DOI 10.1080/01690965.2012.735678
   New B, 2008, PSYCHOL SCI, V19, P1223, DOI 10.1111/j.1467-9280.2008.02228.x
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   PEARSON BZ, 1993, LANG LEARN, V43, P93, DOI 10.1111/j.1467-1770.1993.tb00174.x
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Ramon-Casas M, 2009, COGNITIVE PSYCHOL, V59, P96, DOI 10.1016/j.cogpsych.2009.02.002
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243
   Schmale R, 2009, DEVELOPMENTAL SCI, V12, P583, DOI 10.1111/j.1467-7687.2009.00809.x
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Singh L, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00667
   Smith LB, 2003, COGNITION, V87, P209, DOI 10.1016/S0010-0277(02)00236-6
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   vonsLuxburg U., 2011, HDB HIST LOGIC, V10, P706
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Yip M., 2002, TONE
   Yoshida H, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00210
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
   Zee E., 2001, INTERSPEECH, V1, P643
NR 73
TC 14
Z9 14
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0009-3920
EI 1467-8624
J9 CHILD DEV
JI Child Dev.
PD MAY-JUN
PY 2018
VL 89
IS 3
BP E183
EP E198
DI 10.1111/cdev.12747
PG 16
WC Psychology, Educational; Psychology, Developmental
SC Psychology
GA GF5AN
UT WOS:000431976900003
PM 28160286
DA 2021-02-24
ER

PT J
AU Calcus, A
   Deltenre, P
   Colin, C
   Kolinsky, R
AF Calcus, Axelle
   Deltenre, Paul
   Colin, Cecile
   Kolinsky, Regine
TI Peripheral and central contribution to the difficulty of speech in noise
   perception in dyslexic children
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID INFORMATIONAL MASKING; DEVELOPMENTAL DYSLEXIA; NORMAL-HEARING;
   PHONOLOGICAL REPRESENTATIONS; SIMULTANEOUS TALKERS; LANGUAGE IMPAIRMENT;
   READING-DISABILITY; DEFICITS; LISTENERS; ADULTS
AB Noise typically induces both peripheral and central masking of an auditory target. Whereas the idea that a deficit of speech in noise perception is inherent to dyslexia is still debated, most studies have actually focused on the peripheral contribution to the dyslexics' difficulties of perceiving speech in noise. Here, we investigated the respective contribution of both peripheral and central noise in three groups of children: dyslexic, chronological age matched controls (CA), and reading-level matched controls (RL). In all noise conditions, dyslexics displayed significantly lower performance than CA controls. However, they performed similarly or even better than RL controls. Scrutinizing individual profiles failed to reveal a strong consistency in the speech perception difficulties experienced across all noise conditions, or across noise conditions and reading-related performances. Taken together, our results thus suggest that both peripheral and central interference contribute to the poorer speech in noise perception of dyslexic children, but that this difficulty is not a core deficit inherent to dyslexia.
C1 [Calcus, Axelle; Kolinsky, Regine] FRS FNRS, Paris, France.
   [Calcus, Axelle; Colin, Cecile; Kolinsky, Regine] ULB, CRCN, Unite Rech Neurosci Cognit UNESCOG, Brussels, Belgium.
   [Calcus, Axelle; Deltenre, Paul; Colin, Cecile] Hop Brugmann, Lab Neurophysiol Sensorielle & Cognit, Brussels, Belgium.
   [Calcus, Axelle] UCL, Speech Hearing & Phonet Sci, 2 Wakefield St, London WC1N 1PF, England.
RP Calcus, A (corresponding author), UCL, Speech Hearing & Phonet Sci, 2 Wakefield St, London WC1N 1PF, England.
EM a.calcus@ucl.ac.uk
RI Colin, Cecile/AAF-6253-2019; Calcus, Axelle/AAS-8137-2020
FU F.R.S.-FNRSFonds de la Recherche Scientifique - FNRS [FRFC 2.4515.12];
   iCARE Innovative Training Network [FP7-607139]
FX F.R.S.-FNRS, Grant/Award Number: FRFC 2.4515.12; iCARE Innovative
   Training Network, Marie Curie, Grant/Award Number: FP7-607139
CR Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   Agus TR, 2014, J SPEECH LANG HEAR R, V57, P1069, DOI 10.1044/1092-4388(2013/13-0020)
   Agus TR, 2009, J ACOUST SOC AM, V126, P1926, DOI 10.1121/1.3205403
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Baker M, 2014, J SPEECH LANG HEAR R, V57, P327, DOI 10.1044/1092-4388(2013/12-0287)
   Bishop DVM, 2006, CURR DIR PSYCHOL SCI, V15, P217, DOI 10.1111/j.1467-8721.2006.00439.x
   Boada R, 2006, J EXP CHILD PSYCHOL, V95, P153, DOI 10.1016/j.jecp.2006.04.003
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Bradlow AR, 2003, J SPEECH LANG HEAR R, V46, P80, DOI 10.1044/1092-4388(2003/007)
   BRADY S, 1983, J EXP CHILD PSYCHOL, V35, P345, DOI 10.1016/0022-0965(83)90087-5
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Calcus A., 2016, J SPEECH LANG HEAR R, V59, P1
   Calcus A, 2015, J ACOUST SOC AM, V137, pEL496, DOI 10.1121/1.4922012
   Calcus A, 2015, NEUROSCI LETT, V584, P71, DOI 10.1016/j.neulet.2014.10.026
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Di Filippo G, 2008, DEVELOPMENTAL SCI, V11, pF40, DOI 10.1111/j.1467-7687.2008.00752.x
   Dole M, 2012, NEUROPSYCHOLOGIA, V50, P1543, DOI 10.1016/j.neuropsychologia.2012.03.007
   Durlach NI, 2003, J ACOUST SOC AM, V114, P368, DOI 10.1121/1.1577562
   Durlach NI, 2003, J ACOUST SOC AM, V113, P2984, DOI 10.1121/1.1570435
   Elbro C, 1998, READ RES QUART, V33, P36, DOI 10.1598/RRQ.33.1.3
   Fallon M, 2000, J ACOUST SOC AM, V108, P3023, DOI 10.1121/1.1323233
   Fluss J, 2009, J DEV BEHAV PEDIATR, V30, P206, DOI 10.1097/DBP.0b013e3181a7ed6c
   Freyman RL, 2001, J ACOUST SOC AM, V109, P2112, DOI 10.1121/1.1354984
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Goswami U, 2003, TRENDS COGN SCI, V7, P534, DOI 10.1016/j.tics.2003.10.003
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2014, BRAIN, V137, P3100, DOI 10.1093/brain/awu296
   Gutschalk A, 2008, PLOS BIOL, V6, P1156, DOI 10.1371/journal.pbio.0060138
   Hazan V, 2013, J SPEECH LANG HEAR R, V56, P44, DOI 10.1044/1092-4388(2012/10-0107)
   Hazan V, 2009, J SPEECH LANG HEAR R, V52, P1510, DOI 10.1044/1092-4388(2009/08-0220)
   JACOBY LL, 1988, J EXP PSYCHOL LEARN, V14, P240, DOI 10.1037/0278-7393.14.2.240
   Kidd G, 2002, JARO, V3, P107, DOI 10.1007/s1016200210095
   Korkman M., 1998, NEPSY DEV NEUROPSYCH
   Leger AC, 2012, J ACOUST SOC AM, V131, P1502, DOI 10.1121/1.3665993
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   McDermott JH, 2009, CURR BIOL, V19, pR1024, DOI 10.1016/j.cub.2009.09.005
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Moore B, 2012, INTRO PSYCHOL HEARIN, P67
   Mousty M., 1999, EUR REV APPL PSYCHOL, V49, P325
   Mousty P., 1994, EVALUER TROUBLES LEC, P127
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Pattamadilok C, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00361
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Poelmans H, 2011, RES DEV DISABIL, V32, P2810, DOI 10.1016/j.ridd.2011.05.025
   POLLACK I, 1975, J ACOUST SOC AM, V57, pS5, DOI 10.1121/1.1995329
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Rosen S, 2013, J ACOUST SOC AM, V133, P2431, DOI 10.1121/1.4794379
   Ruggles D, 2011, P NATL ACAD SCI USA, V108, P15516, DOI 10.1073/pnas.1108912108
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   Shaywitz SE, 2003, BIOL PSYCHIAT, V54, P25, DOI 10.1016/S0006-3223(02)01836-X
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   SNOWLING M, 1986, J EXP CHILD PSYCHOL, V41, P489, DOI 10.1016/0022-0965(86)90006-8
   Snowling M., 2000, DYSLEXIA
   Stone MA, 2012, J ACOUST SOC AM, V132, P317, DOI 10.1121/1.4725766
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Temple E, 2003, P NATL ACAD SCI USA, V100, P2860, DOI 10.1073/pnas.0030098100
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   WECHSLER D, 1996, ECHELLE INTELLIGENCE
   Wightman FL, 2005, J ACOUST SOC AM, V118, P3164, DOI 10.1121/1.2082567
   Wightman FL, 2010, J ACOUST SOC AM, V128, P270, DOI 10.1121/1.3436536
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 71
TC 3
Z9 4
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD MAY
PY 2018
VL 21
IS 3
AR e12558
DI 10.1111/desc.12558
PG 13
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GC9LP
UT WOS:000430119100003
PM 28256107
DA 2021-02-24
ER

PT J
AU Carroll, JM
   Breadmore, HL
AF Carroll, Julia M.
   Breadmore, Helen L.
TI Not all phonological awareness deficits are created equal: evidence from
   a comparison between children with Otitis Media and poor readers
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID SCHOOL-AGE-CHILDREN; MORPHOLOGICAL AWARENESS; DEVELOPMENTAL DYSLEXIA;
   LANGUAGE IMPAIRMENT; DYNAMIC ASSESSMENT; LITERACY OUTCOMES;
   SPEECH-PERCEPTION; SKILLS; EFFUSION; WORDS
AB Children with reading difficulties and children with a history of repeated ear infections (Otitis Media, OM) are both thought to have phonological impairments, but for quite different reasons. This paper examines the profile of phonological and morphological awareness in poor readers and children with OM. Thirty-three poor readers were compared to individually matched chronological age and reading age controls. Their phonological awareness and morphological awareness skills were consistently at the level of reading age matched controls. Unexpectedly, a significant minority (25%) of the poor readers had some degree of undiagnosed mild or very mild hearing loss. Twenty-nine children with a history of OM and their matched controls completed the same battery of tasks. They showed relatively small delays in their literacy and showed no impairment in morphological awareness but had phonological awareness scores below the level of reading age matched controls. Further analysis suggested that this weakness in phonological awareness was carried by a specific weakness in segmenting and blending phonemes, with relatively good performance on phoneme manipulation tasks. Results suggest that children with OM show a circumscribed deficit in phoneme segmentation and blending, while poor readers show a broader metalinguistic impairment which is more closely associated with reading difficulties.
C1 [Carroll, Julia M.; Breadmore, Helen L.] Coventry Univ, Ctr Res Psychol Behav & Achievement, Coventry, W Midlands, England.
RP Carroll, JM (corresponding author), Coventry Univ, Fac Hlth & Life Sci, Ctr Res Psychol Behav & Achievement, Priory St, Coventry CV1 5FB, W Midlands, England.
EM Julia.Carroll@coventry.ac.uk
RI ; Carroll, Julia/D-6259-2011
OI Breadmore, Helen/0000-0003-3050-8908; Carroll, Julia/0000-0002-3614-6883
FU Nuffield Foundation [EDU/40250]
FX Nuffield Foundation, Grant/Award Number: EDU/40250
CR Alloway TP., 2007, AUTOMATED WORKING ME
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   Bowers PN, 2010, REV EDUC RES, V80, P144, DOI 10.3102/0034654309359353
   BRADLEY L, 1978, NATURE, V271, P746, DOI 10.1038/271746a0
   Breadmore HL, 2016, SCI STUD READ, V20, P471, DOI 10.1080/10888438.2016.1246554
   Breadmore HL, 2016, APPL PSYCHOLINGUIST, V37, P1439, DOI 10.1017/S0142716416000072
   Bridges MS, 2011, J LEARN DISABIL-US, V44, P330, DOI 10.1177/0022219411407863
   British Society of Audiology, 2011, REC PROC PUR TON AIR
   Byrne B., 1998, FDN LITERACY CHILDS
   Casalis S, 2004, ANN DYSLEXIA, V54, P114, DOI 10.1007/s11881-004-0006-z
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cunningham A, 2011, J EXP CHILD PSYCHOL, V109, P248, DOI 10.1016/j.jecp.2010.12.005
   Cunningham AJ, 2015, APPL PSYCHOLINGUIST, V36, P509, DOI 10.1017/S0142716413000295
   Dunn L.M., 2009, BRIT PICTURE VOCABUL
   Elbro C, 1998, READ RES QUART, V33, P36, DOI 10.1598/RRQ.33.1.3
   Elbro C, 1996, ANN DYSLEXIA, V46, P209, DOI 10.1007/BF02648177
   Elliott C., 2011, BRIT ABILITY SCALES
   FERGUSON CA, 1975, LANGUAGE, V51, P419, DOI 10.2307/412864
   Goodwin AP, 2013, SCI STUD READ, V17, P257, DOI 10.1080/10888438.2012.689791
   HATCHER PJ, 1994, CHILD DEV, V65, P41, DOI 10.1111/j.1467-8624.1994.tb00733.x
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Johnson DL, 2008, J COMMUN DISORD, V41, P20, DOI 10.1016/j.jcomdis.2007.03.001
   Kindig JS, 2000, J PEDIATR PSYCHOL, V25, P15, DOI 10.1093/jpepsy/25.1.15
   Klein JO, 2000, VACCINE, V19, pS2, DOI 10.1016/S0264-410X(00)00271-1
   Larsen JA, 2007, LANG SPEECH HEAR SER, V38, P201, DOI 10.1044/0161-1461(2007/021)
   Law JM, 2015, DYSLEXIA, V21, P254, DOI 10.1002/dys.1495
   Luotonen M, 1996, PEDIATR INFECT DIS J, V15, P854, DOI 10.1097/00006454-199610000-00005
   McArthur GM, 2000, J CHILD PSYCHOL PSYC, V41, P869, DOI 10.1111/1469-7610.00674
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Nittrouer S, 2005, J COMMUN DISORD, V38, P29, DOI 10.1016/j.jcomdis.2004.03.006
   Pennington BF, 2009, ANNU REV PSYCHOL, V60, P283, DOI 10.1146/annurev.psych.60.110707.163548
   PETERS SAF, 1994, J LEARN DISABIL, V27, P111, DOI 10.1177/002221949402700206
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Roberts JE, 2004, PEDIATRICS, V113, pE238, DOI 10.1542/peds.113.3.e238
   Semel E, 2006, CLIN EVALUATION LANG
   Shapiro LR, 2009, DYSLEXIA, V15, P1, DOI 10.1002/dys.380
   Siegel LS, 2008, TOP LANG DISORD, V28, P15, DOI 10.1097/01.adt.0000311413.75804.60
   Snowling M., 2000, DYSLEXIA
   Snowling M.J., 2011, CAMBRIDGE ENCY LANGU, P270
   Snowling M.J., 2011, YORK ASSESSMENT READ
   Snowling MJ, 2016, J CHILD PSYCHOL PSYC, V57, P1360, DOI 10.1111/jcpp.12497
   SPECTOR JE, 1992, J EDUC PSYCHOL, V84, P353, DOI 10.1037/0022-0663.84.3.353
   STANOVICH KE, 1986, READ RES QUART, V21, P360, DOI 10.1598/RRQ.21.4.1
   STANOVICH KE, 1994, J EDUC PSYCHOL, V86, P24, DOI 10.1037/0022-0663.86.1.24
   Studdert-Kennedy M., 1987, LANGUAGE PERCEPTION, P67
   TEELE DW, 1989, J INFECT DIS, V160, P83, DOI 10.1093/infdis/160.1.83
   TREIMAN R, 1993, BEGINNING SPELL
   Tsesmeli SN, 2009, BRIT J PSYCHOL, V100, P565, DOI 10.1348/000712608X371915
   WALLEY AC, 1993, DEV REV, V13, P286, DOI 10.1006/drev.1993.1015
   Winskel H, 2006, BRIT J EDUC PSYCHOL, V76, P727, DOI 10.1348/000709905X68312
   Wolter J.A., 2011, SOC SCI STUD READ
NR 51
TC 4
Z9 4
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD MAY
PY 2018
VL 21
IS 3
AR e12588
DI 10.1111/desc.12588
PG 12
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GC9LP
UT WOS:000430119100032
PM 28880490
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lany, J
   Giglio, M
   Oswald, M
AF Lany, Jill
   Giglio, Michael
   Oswald, Madeleine
TI Infants' Lexical Processing Efficiency is Related to Vocabulary Size by
   One Year of Age
SO INFANCY
LA English
DT Article
ID WORD COMPREHENSION; SPEECH-PERCEPTION; SEGMENTATION; PREFERENCE;
   TALKING; GROWTH
AB By 15-18months, infants' skill in interpreting familiar words, or lexical processing efficiency (LPE), improves substantially and is correlated with vocabulary size concurrently and several months later. Prior to this age LPE is quite poor, and to date there is little evidence that it is related to vocabulary size. If this relation only emerges once infants have relatively good LPE, and also know a substantial number of words, it could suggest that the processes that support the rapid growth in vocabulary commonly observed as infants approach age 2 may not yet be functional in the earlier stages of lexical development. However, using a modified LPE task we found that 12-month-olds with better LPE understood more words at that age and also produced more words several months later. These results suggest that meaningful individual differences in LPE are already emerging by 12months and may support lexical development across the second year.
C1 [Lany, Jill] Univ Notre Dame, Notre Dame, IN 46556 USA.
   [Giglio, Michael] Univ Texas Houston, McGovern Med Sch, Houston, TX USA.
   [Oswald, Madeleine] Univ Chicago, Chicago, IL 60637 USA.
RP Lany, J (corresponding author), Univ Notre Dame, Dept Psychol, 118C Haggar Hall, Notre Dame, IN 46656 USA.
EM jlany@nd.edu
FU NSFNational Science Foundation (NSF) [BCS-1352443]; Notre Dame's
   Institute for Scholarship in the Liberal Arts
FX This work was supported by funds from NSF BCS-1352443 and by Notre
   Dame's Institute for Scholarship in the Liberal Arts to J.L.
CR Bergelson E, 2015, LANG LEARN DEV, V11, P369, DOI 10.1080/15475441.2014.979387
   Bergelson E, 2013, COGNITION, V127, P391, DOI 10.1016/j.cognition.2013.02.011
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Borovsky A, 2016, CHILD DEV, V87, P1893, DOI 10.1111/cdev.12554
   Dale PS, 1996, BEHAV RES METH INS C, V28, P125, DOI 10.3758/BF03203646
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fernald A, 2006, DEVELOPMENTAL SCI, V9, pF33, DOI 10.1111/j.1467-7687.2006.00482.x
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Fernald A., 2008, DEV PSYCHOLINGUISTIC, P113
   Fernald A, 2013, DEVELOPMENTAL SCI, V16, P234, DOI 10.1111/desc.12019
   Fernald A, 2012, CHILD DEV, V83, P203, DOI 10.1111/j.1467-8624.2011.01692.x
   Frank MC, 2017, J CHILD LANG, V44, P677, DOI 10.1017/S0305000916000209
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Junge C, 2012, DEVELOPMENTAL SCI, V15, P463, DOI 10.1111/j.1467-7687.2012.1144.x
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Lany J, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12569
   Lany J, 2018, J CHILD LANG, V45, P368, DOI 10.1017/S0305000917000253
   Law F, 2015, LANG LEARN DEV, V11, P331, DOI 10.1080/15475441.2014.961066
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   Newman RS, 2016, J CHILD LANG, V43, P1158, DOI 10.1017/S0305000915000446
   REZNICK JS, 1990, APPL PSYCHOLINGUIST, V11, P145, DOI 10.1017/S0142716400008742
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Zangl R, 2005, J COGN DEV, V6, P179, DOI 10.1207/s15327647jcd0602_2
NR 32
TC 3
Z9 3
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD MAY-JUN
PY 2018
VL 23
IS 3
BP 342
EP 366
DI 10.1111/infa.12228
PG 25
WC Psychology, Developmental
SC Psychology
GA GC9HB
UT WOS:000430107000003
OA Bronze
DA 2021-02-24
ER

PT J
AU Tong, XH
   Tong, XL
   Yiu, FK
AF Tong, Xiuhong
   Tong, Xiuli
   Yiu, Fung King
TI Beyond Auditory Sensory Processing Deficits: Lexical Tone Perception
   Deficits in Chinese Children With Developmental Dyslexia
SO JOURNAL OF LEARNING DISABILITIES
LA English
DT Article
DE developmental dyslexia; lexical tone perception; rise time
ID PHONOLOGICAL AWARENESS; SPEECH-PERCEPTION; CATEGORICAL PERCEPTION;
   READING-ABILITY; SENSITIVITY; DISCRIMINATION; SUBTYPES; SKILLS; CUES
AB Increasing evidence suggests that children with developmental dyslexia exhibit a deficit not only at the segmental level of phonological processing but also, by extension, at the suprasegmental level. However, it remains unclear whether such a suprasegmental phonological processing deficit is due to a difficulty in processing acoustic cues of speech rhythm, such as rise time and intensity. This study set out to investigate to what extent suprasegmental phonological processing (i.e., Cantonese lexical tone perception) and rise time sensitivity could distinguish Chinese children with dyslexia from typically developing children. Sixteen children with dyslexia and 44 age-matched controls were administered a Cantonese lexical tone perception task, psychoacoustic tasks, a nonverbal reasoning ability task, and word reading and dictation tasks. Children with dyslexia performed worse than controls on Cantonese lexical tone perception, rise time, and intensity. Furthermore, Cantonese lexical tone perception appeared to be a stable indicator that distinguishes children with dyslexia from controls, even after controlling for basic auditory processing skills. These findings suggest that suprasegmental phonological processing (i.e., lexical tone perception) is a potential factor that accounts for reading difficulty in Chinese.
C1 [Tong, Xiuhong] Hangzhou Normal Univ, Zhejiang Key Lab Res Assessment Cognit Impairment, Inst Psychol Sci, Hangzhou, Zhejiang, Peoples R China.
   [Tong, Xiuhong] Hangzhou Normal Univ, Ctr Cognit & Brain Disorders, Hangzhou, Zhejiang, Peoples R China.
   [Tong, Xiuli; Yiu, Fung King] Univ Hong Kong, Fac Educ, Div Speech & Hearing Sci, Room 804C,Meng Wah Complex,Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
RP Tong, XL (corresponding author), Univ Hong Kong, Fac Educ, Div Speech & Hearing Sci, Room 804C,Meng Wah Complex,Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM xltong@hku.hk
RI ; Tong, Xiuli/F-4454-2011
OI Tong, Xiuhong/0000-0002-2934-5278; Tong, Xiuli/0000-0003-3319-4609
FU ECS/RGC Early Career Scheme [27402514]; General Research Fund from the
   Hong Kong Special Administrative Region Research [17673216]; University
   of Hong Kong Seed Funding Programme for Basic ResearchUniversity of Hong
   Kong [201410159033]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was supported in part by the the ECS/RGC Early Career Scheme
   (27402514), and the General Research Fund (17673216) from the Hong Kong
   Special Administrative Region Research, and The University of Hong Kong
   Seed Funding Programme for Basic Research (201410159033) to Xiuli Tong.
CR ACKERMAN PT, 1990, J LEARN DISABIL, V23, P325, DOI 10.1177/002221949002300514
   Arciuli J, 2010, J MEM LANG, V63, P180, DOI 10.1016/j.jml.2010.03.005
   BADIAN NA, 1995, ANN DYSLEXIA, V45, P79, DOI 10.1007/BF02648213
   BRUCK M, 1992, DEV PSYCHOL, V28, P874, DOI 10.1037/0012-1649.28.5.874
   Cheung H, 2009, J CHILD PSYCHOL PSYC, V50, P726, DOI 10.1111/j.1469-7610.2008.02001.x
   Cooper A, 2012, J ACOUST SOC AM, V131, P4756, DOI 10.1121/1.4714355
   Crystal D, 2003, DICT LINGUISTICS PHO
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2000, Dyslexia, V6, P133, DOI 10.1002/(SICI)1099-0909(200004/06)6:2<133::AID-DYS160>3.0.CO;2-A
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Ho CS-H., 2000, HONG KONG TEST SPECI
   Ho CSH, 2000, READ WRIT, V13, P57, DOI 10.1023/A:1008040922662
   Ho CSH, 1999, LEARN INDIVID DIFFER, V11, P173, DOI 10.1016/S1041-6080(00)80004-7
   Holliman AJ, 2010, J EDUC PSYCHOL, V102, P356, DOI 10.1037/a0018049
   Hu CF, 1998, SCI STUD READ, V2, P55, DOI DOI 10.1207/S1532799XSSR0201_3
   Kuppen S, 2011, SCI STUD READ, V15, P211, DOI 10.1080/10888431003706291
   Leong C. K., 2005, READING WRITING INTE, V18, P1, DOI DOI 10.1007/S11145-004-3357-2
   Li WS, 2011, J CHILD LANG, V38, P793, DOI 10.1017/S0305000910000346
   *LING SOC HONG KON, 2002, HONG KONG JYUTP CHAR
   Luo H, 2006, P NATL ACAD SCI USA, V103, P19558, DOI 10.1073/pnas.0607065104
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Manis FR, 1996, COGNITION, V58, P157, DOI 10.1016/0010-0277(95)00679-6
   McBride-Chang C, 2000, J EDUC PSYCHOL, V92, P50, DOI 10.1037/0022-0663.92.1.50
   McBride-Chang C., 2011, DYSLEXIA LANGUAGES O
   McBride-Chang C, 2008, SCI STUD READ, V12, P171, DOI 10.1080/10888430801917290
   MCBRIDECHANG C, 1995, EDUC PSYCHOL, V30, P109, DOI 10.1207/s15326985ep3003_2
   Menell P, 1999, J SPEECH LANG HEAR R, V42, P797, DOI 10.1044/jslhr.4204.797
   Palmer S., 2000, J RES READ, V23, P28, DOI DOI 10.1111/1467-9817.00100
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Raven JC., 1960, GUIDE STANDARD PROGR
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Schneider W, 2000, J EDUC PSYCHOL, V92, P284, DOI 10.1037//0022-0663.92.2.284
   Schulte-Korne G, 1999, EUR CHILD ADOLES PSY, V8, P28
   Snowling M., 1998, CHILD ADOL MENT H-UK, V3, P4, DOI [10.1111/1475-3588.00201, DOI 10.1111/1475-3588.00201]
   SNOWLING MJ, 1981, PSYCHOL RES-PSYCH FO, V43, P219, DOI 10.1007/BF00309831
   Stanovich KE, 1997, J EDUC PSYCHOL, V89, P114, DOI 10.1037/0022-0663.89.1.114
   Swan D, 1997, J EXP CHILD PSYCHOL, V66, P18, DOI 10.1006/jecp.1997.2375
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tong XL, 2015, LANG SPEECH, V58, P441, DOI 10.1177/0023830914562988
   Tong XL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142896
   Tong XL, 2014, J SPEECH LANG HEAR R, V57, P1589, DOI 10.1044/2014_JSLHR-S-13-0145
   Tseng CY, 2004, 2004 International Symposium on Chinese Spoken Language Processing, Proceedings, P217
   Wang HLS, 2012, READ WRIT, V25, P509, DOI 10.1007/s11145-010-9284-5
   Witton C, 2002, J COGNITIVE NEUROSCI, V14, P866, DOI 10.1162/089892902760191090
   Wright BA, 2000, CURR OPIN NEUROBIOL, V10, P482, DOI 10.1016/S0959-4388(00)00119-7
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Yin L., 2011, WRITING SYSTEMS RES, V3, P59, DOI DOI 10.1093/wsr/wsr010
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 50
TC 3
Z9 3
U1 1
U2 22
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0022-2194
EI 1538-4780
J9 J LEARN DISABIL-US
JI J. Learn. Disabil.
PD MAY-JUN
PY 2018
VL 51
IS 3
BP 293
EP 301
DI 10.1177/0022219417712018
PG 9
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA GC6CV
UT WOS:000429878600008
PM 28608732
DA 2021-02-24
ER

PT J
AU Wang, LC
   Yang, HM
AF Wang, Li-Chih
   Yang, Hsien-Ming
TI Temporal Processing Development in Chinese Primary School-Aged Children
   With Dyslexia
SO JOURNAL OF LEARNING DISABILITIES
LA English
DT Article
DE dyslexia; Chinese; temporal processing
ID SPEECH-PERCEPTION DEFICITS; READING DISABILITIES; POOR READERS;
   NAMING-SPEED; AWARENESS; PERFORMANCE; WORD; SEARCH; SKILLS
AB This study aimed to investigate the development of visual and auditory temporal processing among children with and without dyslexia and to examine the roles of temporal processing in reading and reading-related abilities. A total of 362 Chinese children in Grades 1-6 were recruited from Taiwan. Half of the children had dyslexia, and the other half were typically developing children who matched the dyslexic group on age, intelligence, and gender. Our results indicate that for typically developing children, the visual and auditory modalities follow the same developmental trend: The children in first and second grades performed significantly worse than the older children. Among the children with dyslexia, however, significant improvements in the visual modality were observed with increasing age. Furthermore, although both modalities were important for all reading-related abilities and for Chinese character reading in first and second grades, the visual modality significantly predicted only orthographic knowledge and Chinese character reading in third and fourth grades. In contrast, the auditory modality affected only phonological awareness. In fifth and sixth grades, only visual temporal processing slightly contributed to the orthographic knowledge and Chinese character reading of the dyslexic group. Also, the relationship between temporal processing and Chinese character reading is strongly influenced by age.
C1 [Wang, Li-Chih] Educ Univ Hong Kong, Dept Special Educ & Counselling, 10 Lo Ping Rd, Tai Po, Hong Kong, Peoples R China.
   [Yang, Hsien-Ming] Natl Univ Tainan, Dept Special Educ, Tainan, Taiwan.
RP Wang, LC (corresponding author), Educ Univ Hong Kong, Dept Special Educ & Counselling, 10 Lo Ping Rd, Tai Po, Hong Kong, Peoples R China.
EM wanglca@eduhk.hk
RI WANG, Li-Chih/H-8173-2019
OI WANG, Li-Chih/0000-0002-4011-7305
FU Research Support Scheme of the Department of Special Education and
   Counselling at the Education University of Hong Kong
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The work
   described in this article was partially supported by the Research
   Support Scheme (2016-2017) of the Department of Special Education and
   Counselling at the Education University of Hong Kong.
CR Booth JR, 2000, SCI STUD READ, V4, P101, DOI DOI 10.1207/S1532799XSSR0402_02
   Bretherton L, 2003, J EXP CHILD PSYCHOL, V84, P218, DOI 10.1016/S0022-0965(03)00023-7
   Burt JS, 2006, J RES READ, V29, P400, DOI 10.1111/j.1467-9817.2006.00315.x
   Catts HW, 2002, J LEARN DISABIL-US, V35, P509
   Chen J. H., 2006, RAVENS PROGR MATRICE
   Chung KKH, 2008, ANN DYSLEXIA, V58, P15, DOI 10.1007/s11881-008-0015-4
   DAVIS SM, 1980, CHILD DEV, V51, P75, DOI 10.1111/j.1467-8624.1980.tb02511.x
   de Jong PF, 2003, J EDUC PSYCHOL, V95, P22, DOI 10.1037/0022-0663.95.1.22
   Denenberg VH, 1999, J LEARN DISABIL, V32, P379, DOI 10.1177/002221949903200502
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Hautus MJ, 2003, DYSLEXIA, V9, P37, DOI 10.1002/dys.234
   Ho CSH, 2007, J EXP CHILD PSYCHOL, V97, P61, DOI 10.1016/j.jecp.2007.01.002
   Ho CSH, 2004, COGNITION, V91, P43, DOI 10.1016/S0010-0277(03)00163-X
   Huang H. S., 2001, CHINESE CHARACTER RE
   Hung L. Y., 2006, PHONETIC RADICAL TES
   Hung L. Y., 2006, SEMANTIC RADICAL TES
   Hung L.-Y., 2006, RADICAL RECOGNITION
   IRWIN RJ, 1985, CHILD DEV, V56, P614
   Klein R. M., 2002, READING WRITING INTE, V15, P207, DOI [10.1023/A:1013828723016, DOI 10.1023/A:1013828723016]
   Ku Y., 2003, READ WRIT, V16, P399, DOI [DOI 10.1023/A:1024227231216, 10.1023/A:1024227231216]
   Lin D, 2010, PSYCHOL SCI, V21, P1117, DOI 10.1177/0956797610375447
   Liu D, 2015, SCI STUD READ, V19, P307, DOI 10.1080/10888438.2015.1030749
   LOVEGROVE W, 1980, PERCEPTION, V9, P529, DOI 10.1068/p090529
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Mcbride-Chang C., 2005, READ WRIT, V18, P99, DOI [DOI 10.1007/S11145-004-7343-5, 10.1007/s11145-004-7343-5]
   McBride-Chang C, 2008, APPL PSYCHOLINGUIST, V29, P437, DOI 10.1017/S014271640808020X
   Meng XZ, 2005, DYSLEXIA, V11, P292, DOI 10.1002/dys.309
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Olson R, 2002, READING WRITING INTE, P127, DOI DOI 10.1023/A:1013872422108
   Plaza M, 2003, BRAIN COGNITION, V53, P287, DOI 10.1016/S0278-2626(03)00128-3
   Protopapas A, 2013, J EXP CHILD PSYCHOL, V116, P914, DOI 10.1016/j.jecp.2013.08.004
   Ramus F, 2001, NATURE, V412, P393, DOI 10.1038/35086683
   Steinbrink C, 2014, CHILD DEV, V85, P1711, DOI 10.1111/cdev.12208
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   TORGESEN JK, 1994, J LEARN DISABIL, V27, P276, DOI 10.1177/002221949402700503
   Tzeng S. J., 2006, PHONOLOGICAL AWARENE
   Tzeng S. J., 2011, RAPID AUTOMATIZED NA
   Walker MM, 2002, J SPEECH LANG HEAR R, V45, P598, DOI 10.1044/1092-4388(2002/048)
   Wolf M, 2000, J LEARN DISABIL-US, V33, P322, DOI 10.1177/002221940003300404
NR 39
TC 13
Z9 13
U1 4
U2 29
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0022-2194
EI 1538-4780
J9 J LEARN DISABIL-US
JI J. Learn. Disabil.
PD MAY-JUN
PY 2018
VL 51
IS 3
BP 302
EP 312
DI 10.1177/0022219416680798
PG 11
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA GC6CV
UT WOS:000429878600009
PM 27940605
DA 2021-02-24
ER

PT J
AU Liu, LD
   Jaeger, TF
AF Liu, Linda
   Jaeger, T. Florian
TI Inferring causes during speech perception
SO COGNITION
LA English
DT Article
DE Speech perception; Perceptual recalibration; Talker variation; Accent
   adaptation; Causal reasoning
ID WORD RECOGNITION; ACCENTED SPEECH; MIXED MODELS; ADAPTATION;
   RECALIBRATION; REPRESENTATIONS; COMPREHENSION; CONTEXT
AB One of the central challenges in speech perception is the lack of invariance: talkers differ in how they map words onto the speech signal. Previous work has shown that one mechanism by which listeners overcome this variability is adaptation. However, talkers differ in how they pronounce words for a number of reasons, ranging from more permanent, characteristic factors such as having a foreign accent, to more temporary, incidental factors, such as speaking with a pen in the mouth. One challenge for listeners is that the true cause underlying atypical pronunciations is never directly known, and instead must be inferred from (often causally ambiguous) evidence. In three experiments, we investigate whether these inferences underlie speech perception, and how the speech perception system deals with uncertainty about competing causes for atypical pronunciations. We find that adaptation to atypical pronunciations is affected by whether the atypical pronunciations are seen as characteristic or incidental. Furthermore, we find that listeners are able to maintain information about previous causally ambiguous pronunciations that they experience, and use this previously experienced evidence to drive their adaptation after additional evidence has disambiguated the cause. Our findings revise previous proposals that causally ambiguous evidence is ignored during speech adaptation.
C1 [Liu, Linda; Jaeger, T. Florian] Univ Rochester, Dept Brain & Cognit Sci, Rochester, NY 14627 USA.
   [Jaeger, T. Florian] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
RP Liu, LD (corresponding author), Univ Rochester, Dept Brain & Cognit Sci, Rochester, NY 14627 USA.
EM lliu47@ur.rochester.edu; fjaeger@ur.rochester.edu
RI Jaeger, T. Florian/O-8224-2019
OI Jaeger, T. Florian/0000-0002-1158-7308
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [HD075797]; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [R01HD075797] Funding Source: NIH RePORTER
FX We would like to thank Arty Samuel for generously providing the audio
   stimuli and for his helpful feedback on earlier presentations of this
   work. We also thank Molly Babel and Jamie Russell for generously
   providing the video stimuli used in this experiment and Dave
   Kleinschmidt for his help setting up the web-based experiment, and
   members of both the Human Language Processing and KurTan lab at
   Rochester as well as the Prosody Lab at McGill for feedback on earlier
   presentations of this work. Some of the results were presented at the
   2015 Architectures and Mechanism of Language Processing Conference. This
   work was funded by the NIH R01 grant HD075797 to T. Florian Jaeger. The
   views expressed here are those of the authors and not necessarily those
   of the funding agencies.
CR Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Babel M., 2016, REPLICATION T KRALJI, V19
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Bicknell K., 2014, 27 ANN CUNY C HUM SC
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105
   BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.1080/01621459.1993.10594284
   Burchill Z., MAINTAINING PE UNPUB
   Bushong W., 2017, 39 ANN C COGN SCI SO
   Byun TM, 2015, J COMMUN DISORD, V53, P70, DOI 10.1016/j.jcomdis.2014.11.003
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Chin S. B., 1997, ALCOHOL AND SPEECH
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   CONNINE CM, 1991, J MEM LANG, V30, P234, DOI 10.1016/0749-596X(91)90005-5
   Dahan D, 2010, CURR DIR PSYCHOL SCI, V19, P121, DOI 10.1177/0963721410364726
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Grodner D, 2011, PROCESSING ACQUISITI
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   JOHNSON K, 1990, PHONETICA, V47, P215, DOI 10.1159/000261863
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Klatt DH, 1986, INVARIANCE VARIABILI, P300
   Kleinschmidt D. F., 2015, COGSCI
   Kleinschmidt D. F., 2011, ACL WORKSH COGN MOD
   Kleinschmidt D. F., 2012, ANN C COGN SCI SOC S
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kraljic T, 2011, COGNITION, V121, P459, DOI 10.1016/j.cognition.2011.08.015
   Kunath S. A., 2010, P NAACL HLT 2010 WOR
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lancia L, 2013, LAB PHONOL, V4, P221, DOI 10.1515/lp-2013-0009
   Liu L., ADAPTATION GEN UNPUB
   McMurray B., 2012, FRICATIVEMAKERPRO
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Pardo J. S., 2006, HDB PSYCHOLINGUISTIC, P201
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   PISONI DB, 1989, ALCOHOL CLIN EXP RES, V13, P577, DOI 10.1111/j.1530-0277.1989.tb00381.x
   Qian T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00228
   Reitter D, 2011, COGNITIVE SCI, V35, P587, DOI 10.1111/j.1551-6709.2010.01165.x
   Samuel AG, 2011, LEXICAL REPRESENTATI
   Samuel AG, 2016, COGNITIVE PSYCHOL, V88, P88, DOI 10.1016/j.cogpsych.2016.06.007
   Scharenborg O., 2011, INT FLOR IT
   Scharenborg O, 2015, J ACOUST SOC AM, V138, P1408, DOI 10.1121/1.4927728
   Scharenborg O, 2013, ATTEN PERCEPT PSYCHO, V75, P525, DOI 10.3758/s13414-013-0422-4
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Sobin C, 1999, J PSYCHOLINGUIST RES, V28, P347, DOI 10.1023/A:1023237014909
   Szostak CM, 2013, ATTEN PERCEPT PSYCHO, V75, P1533, DOI 10.3758/s13414-013-0492-3
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, LANG SPEECH, V52, P341, DOI 10.1177/0023830909103178
   Weatherholtz K., 2016, SPEECH PERCEPTION GE
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Witteman MJ, 2015, LANG SPEECH, V58, P168, DOI 10.1177/0023830914528102
   Xie X., 2016, ANN M AC SOC AM HON
   Xie X., 2004, RAPID ADAPTATI UNPUB
   Yu Angela J, 2008, Adv Neural Inf Process Syst, V21, P1873
   Zhang XJ, 2014, J EXP PSYCHOL HUMAN, V40, P200, DOI 10.1037/a0033182
NR 61
TC 9
Z9 9
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD MAY
PY 2018
VL 174
BP 55
EP 70
DI 10.1016/j.cognition.2018.01.003
PG 16
WC Psychology, Experimental
SC Psychology
GA GA0LZ
UT WOS:000428006100006
PM 29425987
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Durvasula, K
   Huang, HH
   Uehara, S
   Luo, Q
   Lin, YH
AF Durvasula, Karthik
   Huang, Ho-Hsin
   Uehara, Sayako
   Luo, Qian
   Lin, Yen-Hwei
TI Phonology modulates the illusory vowels in perceptual illusions:
   Evidence from Mandarin and English
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Speech Perception; Illusory Vowels; Mandarin; American English
ID ANALYSIS-BY-SYNTHESIS; SPEECH-PERCEPTION; LOANWORD ADAPTATIONS;
   CONSONANT CLUSTERS; SYLLABLE STRUCTURE; EPENTHESIS; JAPANESE;
   PRESERVATION; ASSIMILATION; UNIVERSALS
AB Native speakers perceive illusory vowels when presented with sound sequences that do not respect the phonotactic constraints of their language (Dupoux, Kakehi, Hirose, Pallier, & Mehler, 1999; Kabak & Idsardi, 2007). There is, however, less work on the quality of the illusory vowel. Recently, it has been claimed that the quality of the illusory vowel is also modulated by the phonology of the language, and that the phenomenon of illusory vowels can be understood as a result of the listener reverse inferring the best parse of the underlying representation given their native language phonology and the acoustics of the input stream (Durvasula & Kahng, 2015). The view predicts that listeners are likely to hear different illusory vowels in different phonological contexts. In support of this prediction, we show through two perceptual experiments that Mandarin Chinese speakers (but not American English speakers) perceive different illusory vowels in different phonotactic contexts. Specifically, when presented with phonotactically illegal alveopalatal coda consonants, Mandarin speakers perceived an illusory /i/, but in illegal alveolar stop coda contexts, they perceived a /e/.
C1 [Durvasula, Karthik; Huang, Ho-Hsin; Uehara, Sayako; Luo, Qian; Lin, Yen-Hwei] Michigan State Univ, E Lansing, MI 48824 USA.
RP Durvasula, K (corresponding author), Michigan State Univ, E Lansing, MI 48824 USA.
EM durvasul@msu.edu
CR Berent I, 2008, P NATL ACAD SCI USA, V105, P5321, DOI 10.1073/pnas.0801469105
   Berent I, 2007, COGNITION, V104, P591, DOI 10.1016/j.cognition.2006.05.015
   Berent I, 2009, PHONOLOGY, V26, P75, DOI 10.1017/S0952675709001729
   Best C. T., 2003, INT C PHONETIC SCI, P2889
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   Boersma P, 2009, AMST STUD THEORY HIS, V307, P11
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Boomershine A, 2008, PHONOL PHONET, V13, P145
   Burzio L, 2007, LANG SCI, V29, P154, DOI 10.1016/j.langsci.2006.12.019
   Chao Yuen Ren, 1968, GRAMMAR SPOKEN CHINE
   Cheng C. -C., 1973, SYNCHRONIC PHONOLOGY, DOI [10.1515/9783110866407, DOI 10.1515/9783110866407]
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Davidson L., 2007, PHONOLOGY, V24, P261, DOI DOI 10.1017/S0952675707001200
   Davidson L, 2012, J PHONETICS, V40, P234, DOI 10.1016/j.wocn.2011.11.005
   de Jong K, 2012, LANGUAGE, V88, P341, DOI 10.1353/lan.2012.0035
   Dilley LC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01002
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Duanmu S, 1999, J EAST ASIAN LINGUIS, V8, P1, DOI 10.1023/A:1008353028173
   Duanmu S., 2007, PHONOLOGY STANDARD C
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dupoux E, 2011, J MEM LANG, V64, P199, DOI 10.1016/j.jml.2010.12.004
   Durvasula K, 2015, PHONOLOGY, V32, P385, DOI 10.1017/S0952675715000263
   Durvasula K, 2016, J PHONETICS, V54, P15, DOI 10.1016/j.wocn.2015.08.002
   Feldman N. H., 2007, P 29 ANN COGN SCI SO, P257
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gaskell MG, 1998, J EXP PSYCHOL HUMAN, V24, P380, DOI 10.1037/0096-1523.24.2.380
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Guevara-Rukoz A, 2017, J ACOUST SOC AM, V142, pEL211, DOI 10.1121/1.4998138
   Halle PA, 1998, J EXP PSYCHOL HUMAN, V24, P592, DOI 10.1037/0096-1523.24.2.592
   Heffner CC, 2013, LANG COGNITIVE PROC, V28, P1275, DOI 10.1080/01690965.2012.672229
   Honeybone Patrick, 2005, INTERNAL ORG PHONOLO, P319, DOI DOI 10.1515/9783110890402.317
   Hooper J. B., 1978, CONSTRAINTS SCHWA DE, P183
   Huang T., 2001, OSU WORKING PAPERS L, V55, P23
   Hume E, 2003, P 15 INT C PHON SCI, P2385
   JACOBS H, 2000, OPTIMALITY THEORY PH, P193
   Johnson K, 2010, J PHONETICS, V38, P127, DOI 10.1016/j.wocn.2009.11.001
   Kabak B, 2007, LANG SPEECH, V50, P23, DOI 10.1177/00238309070500010201
   Kang Yoonjung, 2011, COMPANION PHONOLOGY, P2258, DOI [DOI 10.1002/9781444335262.WBCTP0095, DOI 10.1002/9781444335262]
   Kreidler C., 1989, PRONUNCIATION ENGLIS, DOI [10.1002/9781444335262.wbctp0095, DOI 10.1002/9781444335262.WBCTP0095]
   LaCharite D, 2005, LINGUIST INQ, V36, P223, DOI 10.1162/0024389053710666
   LaCharite D., 2000, P 2000 ANN C CAN LIN, P221
   Lin Yen-Hwei, 2007, SOUNDS CHINESE
   Marr D., 1982, VISION COMPUTATIONAL
   Mattingley W., 2015, P 18 INT C PHON SCI
   McEnery Tony, 2004, P 4 INT C LANG RES E, P1175
   Miao Ruiqin, 2005, THESIS
   Mitterer H, 2013, J MEM LANG, V69, P59, DOI 10.1016/j.jml.2013.02.001
   Monahan P. J., 2009, P 17 ANN JAP KOR LIN, P391
   Paradis C, 1997, J LINGUIST, V33, P379, DOI 10.1017/S0022226797006786
   Peperkamp S., 2005, P BERKELEY LINGUISTI, V30, P342
   Peperkamp S, 2008, PHONOLOGY, V25, P129, DOI 10.1017/S0952675708001425
   Peperkamp Sharon, 2003, P 15 INT C PHON SCI, P367
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   R Development Core Team, 2014, R LANG ENV STAT COMP
   Salmons J. C., 1995, PHONOLOGY, V12, P369, DOI DOI 10.1017/S0952675700002566
   Shaw JA, 2018, J PHONETICS, V66, P100, DOI 10.1016/j.wocn.2017.09.007
   Smith J., 2006, JAPANESE KOREAN LING, V14, P63
   Sonderegger M, 2010, COGNITION IN FLUX, P375
   Tsuchida A., 1997, THESIS
   Uffmann C, 2006, LINGUA, V116, P1079, DOI 10.1016/j.lingua.2005.06.009
   Varden J. Kevin, 1998, THESIS
   Vaux B., 2002, ASPIRATION ENGLISH
   Vendelin I, 2006, LINGUA, V116, P996, DOI 10.1016/j.lingua.2005.07.005
   Weinberger S. H., 1996, 2 LANGUAGE SPEECH ST, P263
   Wilson Colin, 2013, P NE LINGUISTICS SOC, V40, P265
   Yip M.J., 1980, THESIS
   Yun S., 2016, THESIS
   Zhao X, 2016, J PSYCHOLINGUIST RES, V45, P795, DOI 10.1007/s10936-015-9375-1
NR 68
TC 1
Z9 1
U1 0
U2 2
PU UBIQUITY PRESS LTD
PI LONDON
PA 6 WINDMILL ST, LONDON, W1T 2JB, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD APR 27
PY 2018
VL 9
IS 1
AR 7
DI 10.5334/labphon.57
PG 27
WC Linguistics; Language & Linguistics
SC Linguistics
GA GQ2HV
UT WOS:000441475100002
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Ozker, M
   Yoshor, D
   Beauchamp, MS
AF Ozker, Muge
   Yoshor, Daniel
   Beauchamp, Michael S.
TI Converging Evidence From Electrocorticography and BOLD fMRI for a Sharp
   Functional Boundary in Superior Temporal Gyrus Related to Multisensory
   Speech Processing
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE multisensory; speech perception; temporal lobe; electrocorticography
   (ECoG); BOLD fMRI; audiovisual speech perception; multisensory
   integration; speech in noise
ID HUMAN AUDITORY-CORTEX; HUMAN CEREBRAL-CORTEX; AUDIOVISUAL SPEECH;
   INTERINDIVIDUAL DIFFERENCES; CORTICAL NETWORK; INTEGRATION; PERCEPTION;
   SULCUS; STIMULATION; REGIONS
AB Although humans can understand speech using the auditory modality alone, in noisy environments visual speech information from the talker's mouth can rescue otherwise unintelligible auditory speech. To investigate the neural substrates of multisensory speech perception, we compared neural activity from the human superior temporal gyrus (STG) in two datasets. One dataset consisted of direct neural recordings (electrocorticography, ECoG) from surface electrodes implanted in epilepsy patients (this dataset has been previously published). The second dataset consisted of indirect measures of neural activity using blood oxygen level dependent functional magnetic resonance imaging (BOLD fMRI). Both ECoG and fMRI participants viewed the same clear and noisy audiovisual speech stimuli and performed the same speech recognition task. Both techniques demonstrated a sharp functional boundary in the STG, spatially coincident with an anatomical boundary defined by the posterior edge of Heschl's gyrus. Cortex on the anterior side of the boundary responded more strongly to clear audiovisual speech than to noisy audiovisual speech while cortex on the posterior side of the boundary did not. For both ECoG and fMRI measurements, the transition between the functionally distinct regions happened within 10 mm of anterior-to-posterior distance along the STG. We relate this boundary to the multisensory neural code underlying speech perception and propose that it represents an important functional division within the human speech perception network.
C1 [Ozker, Muge; Yoshor, Daniel; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
   [Yoshor, Daniel] Michael E DeBakey VA Med Ctr, Houston, TX USA.
RP Beauchamp, MS (corresponding author), Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
EM michael.beauchamp@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934
FU Veterans Administration Clinical Science Research and Development Merit
   Award [1I01CX000325-01A1]; National Institutes of Health (NIH)United
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USA [R01NS065395]; NATIONAL INSTITUTE OF NEUROLOGICAL
   DISORDERS AND STROKEUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Neurological Disorders & Stroke (NINDS) [R01NS065395, R01NS065395,
   R01NS065395, R01NS065395, U01NS098976, R01NS065395, R01NS065395,
   R01NS065395, U01NS098976, R01NS065395, U01NS098976, R01NS065395,
   U01NS098976] Funding Source: NIH RePORTER; Veterans AffairsUS Department
   of Veterans Affairs [I01CX001122, I01CX001122, I01CX001122, I01CX001122]
   Funding Source: NIH RePORTER
FX This work was funded by Veterans Administration Clinical Science
   Research and Development Merit Award Number 1I01CX000325-01A1 and
   National Institutes of Health (NIH) R01NS065395.
CR Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Beck JM, 2008, NEURON, V60, P1142, DOI 10.1016/j.neuron.2008.09.021
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   Bernstein LE, 2011, HUM BRAIN MAPP, V32, P1660, DOI 10.1002/hbm.21139
   Bishop CW, 2009, J COGNITIVE NEUROSCI, V21, P1790, DOI 10.1162/jocn.2009.21118
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cheng K, 2001, NEURON, V32, P359, DOI 10.1016/S0896-6273(01)00477-9
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Crosse MJ, 2016, J NEUROSCI, V36, P9888, DOI 10.1523/JNEUROSCI.1396-16.2016
   Dale AM, 1999, 5 INT C FUNCT MAPP H
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Fischl B, 2001, IEEE T MED IMAGING, V20, P70, DOI 10.1109/42.906426
   Foxe JJ, 2002, J NEUROPHYSIOL, V88, P540, DOI 10.1152/jn.2002.88.1.540
   Grill-Spector K, 2004, ANNU REV NEUROSCI, V27, P649, DOI 10.1146/annurev.neuro.27.070203.144220
   Hermes D, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001461
   Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032
   Janszky J, 2003, BRAIN, V126, P2043, DOI 10.1093/brain/awg193
   Kramer MA, 2012, NEUROSCIENTIST, V18, P360, DOI 10.1177/1073858411422754
   Lachaux JP, 2012, PROG NEUROBIOL, V98, P279, DOI 10.1016/j.pneurobio.2012.06.008
   Leaver AM, 2016, J NEUROSCI, V36, P1416, DOI 10.1523/JNEUROSCI.0226-15.2016
   Lee H, 2011, J NEUROSCI, V31, P11338, DOI 10.1523/JNEUROSCI.6510-10.2011
   Lindquist MA, 2009, NEUROIMAGE, V45, pS187, DOI 10.1016/j.neuroimage.2008.10.065
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Moerel M, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00225
   Murphey DK, 2008, CURR BIOL, V18, P216, DOI 10.1016/j.cub.2008.01.013
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   Ojemann GA, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00034
   Ozker M, 2017, J COGNITIVE NEUROSCI, V29, P1044, DOI 10.1162/jocn_a_01110
   Parvizi J, 2012, J NEUROSCI, V32, P14915, DOI 10.1523/JNEUROSCI.2609-12.2012
   Rangarajan V, 2016, NEUROPSYCHOLOGIA, V83, P29, DOI 10.1016/j.neuropsychologia.2015.08.003
   Ray S, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1000610
   Reale RA, 2007, NEUROSCIENCE, V145, P162, DOI 10.1016/j.neuroscience.2006.11.036
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Salmelin R, 2007, CLIN NEUROPHYSIOL, V118, P237, DOI 10.1016/j.clinph.2006.07.316
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Setsompop K, 2012, MAGN RESON MED, V67, P1210, DOI 10.1002/mrm.23097
   Shahin AJ, 2012, NEUROIMAGE, V60, P530, DOI 10.1016/j.neuroimage.2011.11.097
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Stevenson RA, 2009, NEUROIMAGE, V44, P1210, DOI 10.1016/j.neuroimage.2008.09.034
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tang C, 2017, SCIENCE, V357, P797, DOI 10.1126/science.aam8577
   Tyler LK, 2003, COGN NEUROPSYCHOL, V20, P541, DOI 10.1080/02643290244000211
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   Weiner KS, 2011, NEUROIMAGE, V56, P2183, DOI 10.1016/j.neuroimage.2011.03.041
   Witthoft N, 2014, CEREB CORTEX, V24, P2401, DOI 10.1093/cercor/bht092
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 55
TC 4
Z9 4
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD APR 24
PY 2018
VL 12
AR 141
DI 10.3389/fnhum.2018.00141
PG 13
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA GD9IR
UT WOS:000430826900001
PM 29740294
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cheng, YY
   Lee, CY
AF Cheng, Ying-Ying
   Lee, Chia-Ying
TI The Development of Mismatch Responses to Mandarin Lexical Tone in 12-to
   24-Month-Old Infants
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE mismatch negativity (MMN); positive mismatch response (P-MMR); infant;
   lexical tone; Mandarin; event-related potentials (ERPs)
ID LATE DISCRIMINATIVE NEGATIVITY; SPEECH-PERCEPTION; ELECTROPHYSIOLOGICAL
   EVIDENCE; LANGUAGE IMPAIRMENT; BRAIN RESPONSES; PHONETIC PERCEPTION;
   SPEAKING CHILDREN; HUMAN NEWBORNS; MATURATION; ACQUISITION
AB This study explores the development of mismatch responses (MMRs) to Mandarin lexical tone changes in infants at 12, 18, and 24 months of age using the multi-deviant oddball paradigm with the low dipping Tone 3 (T3) as the standard, the high level Tone 1 (T1) as the large, and the high rising Tone 2 (T2) as the small deviant. The results show that the large acoustic change between T1/T3 elicited mismatch negativity (MMN) in all three age groups. The small acoustic change between T2/T3 elicited a positive mismatch response (P-MMR) at 12 and 18 months of age, but no MMR was found to the T2/T3 change at 24 months. The coexistence of MMN and P-MMR in the same age group implies that different mechanisms were used for discriminating large and small deviants. Infants were able to detect the T1/T3 change automatically and showed adult-like MMN as early as 6 months of age. However, the detection of the T2/T3 change remains effortful in infants under 24 months of age. These findings support the notion that MMN and P-MMR may be used to index the maturation of speech perception.
C1 [Cheng, Ying-Ying; Lee, Chia-Ying] Acad Sinica, Inst Linguist, Brain & Language Lab, Taipei, Taiwan.
   [Cheng, Ying-Ying; Lee, Chia-Ying] Natl Yang Ming Univ, Inst Neurosci, Taipei, Taiwan.
   [Cheng, Ying-Ying] Natl Taiwan Normal Univ, Aim Top Univ Project, Taipei, Taiwan.
   [Lee, Chia-Ying] Natl Cent Univ, Inst Cognit Neurosci, Taoyuan, Taiwan.
   [Lee, Chia-Ying] Natl Chengchi Univ, Res Ctr Mind Brain & Learning, Taipei, Taiwan.
RP Lee, CY (corresponding author), Acad Sinica, Inst Linguist, Brain & Language Lab, Taipei, Taiwan.; Lee, CY (corresponding author), Natl Yang Ming Univ, Inst Neurosci, Taipei, Taiwan.; Lee, CY (corresponding author), Natl Cent Univ, Inst Cognit Neurosci, Taoyuan, Taiwan.; Lee, CY (corresponding author), Natl Chengchi Univ, Res Ctr Mind Brain & Learning, Taipei, Taiwan.
EM chiaying@gate.sinica.edu.tw
CR Ahmmed AU, 2008, DEV MED CHILD NEUROL, V50, P938, DOI 10.1111/j.1469-8749.2008.03093.x
   ALHO K, 1990, ELECTROEN CLIN NEURO, V77, P151, DOI 10.1016/0168-5597(90)90031-8
   Bishop DVM, 2011, DEVELOPMENTAL SCI, V14, P402, DOI 10.1111/j.1467-7687.2010.00990.x
   Bishop DVM, 2010, J NEUROSCI, V30, P15578, DOI 10.1523/JNEUROSCI.2217-10.2010
   Brannon EM, 2008, J COGNITIVE NEUROSCI, V20, P193, DOI 10.1162/jocn.2008.20016
   Brannon EM, 2004, COGNITIVE BRAIN RES, V21, P227, DOI 10.1016/j.cogbrainres.2004.04.007
   Cabrera L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01290
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chen YC, 2016, DEV COGN NEUROS-NETH, V19, P190, DOI 10.1016/j.dcn.2016.03.007
   Cheng YY, 2015, INT J PSYCHOPHYSIOL, V96, P84, DOI 10.1016/j.ijpsycho.2015.03.007
   Cheng YY, 2013, DEV NEUROPSYCHOL, V38, P281, DOI 10.1080/87565641.2013.799672
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 1998, INT J PSYCHOPHYSIOL, V29, P217, DOI 10.1016/S0167-8760(98)00017-8
   Cheour M, 2002, DEV NEUROPSYCHOL, V22, P471, DOI 10.1207/S15326942DN2202_3
   Cheour M, 2002, SCAND J PSYCHOL, V43, P33, DOI 10.1111/1467-9450.00266
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   CHEOURLUHTANEN M, 1995, HEARING RES, V82, P53
   Dehaene-Lambertz G, 2001, NEUROREPORT, V12, P3155, DOI 10.1097/00001756-200110080-00034
   Dehaene-Lambertz G, 1998, NEUROREPORT, V9, P1885, DOI 10.1097/00001756-199806010-00040
   DEHAENELAMBERTZ G, 1994, NATURE, V370, P292, DOI 10.1038/370292a0
   Friederici AD, 2002, NEUROREPORT, V13, P1251, DOI 10.1097/00001756-200207190-00006
   Friedrich M, 2004, PSYCHOPHYSIOLOGY, V41, P772, DOI 10.1111/j.1469-8986.2004.00202.x
   Friedrich M, 2009, CORTEX, V45, P662, DOI 10.1016/j.cortex.2008.06.014
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Garcia-Sierra A, 2016, INT J PSYCHOPHYSIOL, V110, P1, DOI 10.1016/j.ijpsycho.2016.10.004
   GUTHRIE D, 1991, PSYCHOPHYSIOLOGY, V28, P240, DOI 10.1111/j.1469-8986.1991.tb00417.x
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   He C, 2007, J COGNITIVE NEUROSCI, V19, P878, DOI 10.1162/jocn.2007.19.5.878
   Hommet C, 2009, NEUROPSYCHOLOGIA, V47, P761, DOI 10.1016/j.neuropsychologia.2008.12.010
   Hsu CH, 2014, BRAIN RES, V1582, P154, DOI 10.1016/j.brainres.2014.07.023
   Hua Z, 2000, J CHILD LANG, V27, P3, DOI 10.1017/S030500099900402X
   Kooijman V, 2005, COGNITIVE BRAIN RES, V24, P109, DOI 10.1016/j.cogbrainres.2004.12.009
   Kooijman V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00025
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426
   Korpilahti P., 1995, ELECTROENCEPHALOGRAP, V95, P95, DOI [10.1016/0013-4694(95)90016-g, DOI 10.1016/0013-4694(95)90016-G]
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kujala T, 2017, DEV COGN NEUROS-NETH, V28, P65, DOI 10.1016/j.dcn.2017.10.005
   Kuo YC, 2014, CLIN NEUROPHYSIOL, V125, P1568, DOI 10.1016/j.clinph.2013.11.035
   Kushnerenko E, 2001, DEV NEUROPSYCHOL, V19, P83, DOI 10.1207/S15326942DN1901_6
   Kushnerenko E, 2002, NEUROREPORT, V13, P1843, DOI 10.1097/00001756-200210280-00002
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Leppanen PHT, 1997, DEV NEUROPSYCHOL, V13, P175, DOI 10.1080/87565649709540677
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Lin BG, 2008, LANGUAGE DISORDER SC
   Liu HX, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0111175, 10.1371/journal.pone.0110887]
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Martynova O, 2003, NEUROSCI LETT, V340, P75, DOI 10.1016/S0304-3940(02)01401-5
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   Maurer U, 2003, CLIN NEUROPHYSIOL, V114, P808, DOI 10.1016/S1388-2457(03)00032-4
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Neuhoff N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034909
   Novitski N, 2007, CLIN NEUROPHYSIOL, V118, P412, DOI 10.1016/j.clinph.2006.10.008
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Shafer VL, 2011, J PHONETICS, V39, P527, DOI 10.1016/j.wocn.2010.11.010
   Shafer VL, 2010, EAR HEARING, V31, P735, DOI 10.1097/AUD.0b013e3181e5d1a7
   Shi RS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01117
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   Trainor L, 2003, INT J PSYCHOPHYSIOL, V51, P5, DOI 10.1016/S0167-8760(03)00148-X
   Tsao F.-M., 2008, CHINESE J PSYCHOL, V50, P111, DOI [10.6129/CJP.2008.5002.01, DOI 10.6129/CJP.2008.5002.01]
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Yang MT, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00470
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
NR 75
TC 3
Z9 3
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD APR 10
PY 2018
VL 9
AR 448
DI 10.3389/fpsyg.2018.00448
PG 11
WC Psychology, Multidisciplinary
SC Psychology
GA GC2JF
UT WOS:000429607500001
PM 29692746
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Spirrov, D
   Van Eeckhoutte, M
   Van Deun, L
   Francart, T
AF Spirrov, Dimitar
   Van Eeckhoutte, Maaike
   Van Deun, Lieselot
   Francart, Tom
TI Real-time loudness normalisation with combined cochlear implant and
   hearing aid stimulation
SO PLOS ONE
LA English
DT Article
ID LEVEL; DIFFERENCE; MODEL
AB Background
   People who use a cochlear implant together with a contralateral hearing aid so-called bimodal listeners have poor localisation abilities and sounds are often not balanced in loudness across ears. In order to address the latter, a loudness balancing algorithm was created, which equalises the loudness growth functions for the two ears. The algorithm uses loudness models in order to continuously adjust the two signals to loudness targets. Previous tests demonstrated improved binaural balance, improved localisation, and better speech intelligibility in quiet for soft phonemes. In those studies, however, all stimuli were preprocessed so spontaneous head movements and individual head-related transfer functions were not taken into account. Furthermore, the hearing aid processing was linear.
   Study design
   In the present study, we simplified the acoustical loudness model and implemented the algorithm in a real-time system. We tested bimodal listeners on speech perception and on sound localisation, both in normal loudness growth configuration and in a configuration with a modified loudness growth function. We also used linear and compressive hearing aids.
   Results
   The comparison between the original acoustical loudness model and the new simplified model showed loudness differences below 3% for almost all tested speech-like stimuli and levels. We found no effect of balancing the loudness growth across ears for speech perception ability in quiet and in noise. We found some small improvements in localisation performance. Further investigation with a larger sample size is required.
C1 [Spirrov, Dimitar; Van Eeckhoutte, Maaike; Van Deun, Lieselot; Francart, Tom] Univ Leuven, KU Leuven, ExpORL, Neurosci, Leuven, Belgium.
   [Van Deun, Lieselot] Univ Hosp Leuven, Dept Otorhinolaryngol Head & Neck Surg, Leuven, Belgium.
RP Spirrov, D (corresponding author), Univ Leuven, KU Leuven, ExpORL, Neurosci, Leuven, Belgium.
EM dimitar.spirrov@kuleuven.be
OI Spirrov, Dimitar/0000-0003-2072-4682; Van Eeckhoutte,
   Maaike/0000-0002-5612-5326
FU Flanders Innovation; Cochlear Ltd. (IWT R D) [110722]; Cochlear Ltd.
   (IWT Baekeland) [140748]; Agency for Innovation by Science and
   Technology in Flanders (IWT)Institute for the Promotion of Innovation by
   Science and Technology in Flanders (IWT) [131106]
FX This work was supported by Flanders Innovation (https:/www.iwt.be) and
   Cochlear Ltd. (http://www.cochlear.com/wps/wcm/connect/be/home) (IWT R &
   D 110722 and IWT Baekeland 140748). Maaike Van Eeckhoutte was supported
   by a PhD grant for Strategic Basic Research by the Agency for Innovation
   by Science and Technology in Flanders (IWT, 131106).; This work was
   supported by Flanders Innovation and Cochlear Ltd. (IWT R & D 110722 and
   IWT Baekeland 140748). Maaike Van Eeckhoutte was supported by a PhD
   grant for Strategic Basic Research by the Agency for Innovation by
   Science and Technology in Flanders (IWT, 131106). Cochlear Ltd. also
   provided the necessary additional equipment. The authors would like to
   acknowledge Kato Van Deun who helped with the testing. We are also very
   grateful to all subjects who participated in this study. Finally, we
   would like to thank the two reviewers for their constructive and helpful
   feedback.
CR Allen JB, 1997, J ACOUST SOC AM, V102, P3628, DOI 10.1121/1.420150
   Blamey PJ, 2000, EAR HEARING, V21, P6, DOI 10.1097/00003446-200002000-00004
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Burdiel E, 2012, AUDIO ENGINEERING SO
   Buus S, 1997, J ACOUST SOC AM, V101, P669, DOI 10.1121/1.417959
   BYRNE D, 1990, EAR HEARING, V11, P40, DOI 10.1097/00003446-199002000-00009
   Byrne D, 2001, J Am Acad Audiol, V12, P37
   BYRNE D, 1994, J ACOUST SOC AM, V96, P2108, DOI 10.1121/1.410152
   Ching T Y C, 2007, Trends Amplif, V11, P161, DOI 10.1177/1084713807304357
   Ching TYC, 2001, EAR HEARING, V22, P365, DOI 10.1097/00003446-200110000-00002
   Dillon H, 1996, EAR HEARING, V17, P287, DOI 10.1097/00003446-199608000-00001
   Dillon H, 2011, PHONAK FOCUS, V40, P1
   Dorman MF, 2014, AUDIOL NEURO-OTOL, V19, P234, DOI 10.1159/000360070
   English R, 2016, INT J AUDIOL, P1
   Fitzpatrick EM, 2010, TRENDS AMPLIF, V14, P199, DOI 10.1177/1084713810396511
   Francart T, 2012, PLOS ONE, P7
   Francart T, 2008, J NEUROSCI METH, V172, P283, DOI 10.1016/j.jneumeth.2008.04.020
   Francart T, 2008, AUDIOL NEURO-OTOL, V13, P309, DOI 10.1159/000124279
   Francart T, 2013, EAR HEARING, V34, P685, DOI 10.1097/AUD.0b013e31829d14cb
   Francart T, 2012, HEARING RES, V294, P114, DOI 10.1016/j.heares.2012.09.002
   Francart T, 2011, J ACOUST SOC AM, V130, P2817, DOI 10.1121/1.3641414
   Francart T, 2009, JARO-J ASSOC RES OTO, V10, P131, DOI 10.1007/s10162-008-0145-8
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   GREENWOOD DD, 1991, HEARING RES, V54, P164, DOI 10.1016/0378-5955(91)90117-R
   Holube I, 2010, INT J AUDIOL, V49, P891, DOI 10.3109/14992027.2010.506889
   Hoth S, 2007, EUR ARCH OTO-RHINO-L, V264, P129, DOI 10.1007/s00405-006-0159-y
   Kates James M, 2005, Trends Amplif, V9, P45, DOI 10.1177/108471380500900202
   KATES JM, 2005, EURASIP J APPL SIG P, V18, P3003
   Krishnamoorthi H, 2008, INT CONF ACOUST SPEE, P361, DOI 10.1109/ICASSP.2008.4517621
   McDermott Hugh J, 2002, J Am Acad Audiol, V13, P14
   McKay CM, 2003, J ACOUST SOC AM, V113, P2054, DOI 10.1121/1.1558378
   Moore BCJ, 1997, AUDIT NEUROSCI, V3, P289
   Moore BCJ, 2004, HEARING RES, V188, P70, DOI 10.1016/S0378-5955(03)00347-2
   MOORE BCJ, 1983, J ACOUST SOC AM, V74, P750, DOI 10.1121/1.389861
   Stone MA, 1999, J ACOUST SOC AM, V106, P3603, DOI 10.1121/1.428213
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Theelen-vandenHoek FL, 2016, INT J AUDIOL, V2027, P1
   Van den Bogaert T, 2006, J ACOUST SOC AM, V119, P515, DOI 10.1121/1.2139653
   van Wieringen A, 2008, INT J AUDIOL, V47, P348, DOI 10.1080/14992020801895144
   Veugen LCE, 2015, EAR HEARING
   Ward D, 2013, IEEE WORK APPL SIG
   Yoon YS, 2012, J SPEECH LANG HEAR R, V55, P105, DOI 10.1044/1092-4388(2011/10-0325)
NR 42
TC 2
Z9 2
U1 0
U2 2
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD APR 4
PY 2018
VL 13
IS 4
AR e0195412
DI 10.1371/journal.pone.0195412
PG 20
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GB6SR
UT WOS:000429203800083
PM 29617421
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Magnuson, JS
   Mirman, D
   Luthra, S
   Strauss, T
   Harris, HD
AF Magnuson, James S.
   Mirman, Daniel
   Luthra, Sahil
   Strauss, Ted
   Harris, Harlan D.
TI Interaction in Spoken Word Recognition Models: Feedback Helps
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE psycholinguistics; spoken word recognition; computational models; speech
   perception; Bayesian models; simulations
ID GRANGER CAUSALITY ANALYSIS; SPEECH-PERCEPTION; TIME-COURSE;
   NEURAL-NETWORKS; BAYESIAN MODELS; LEXICAL ACCESS; TRACE MODEL;
   INFORMATION; RESTORATION; ACTIVATION
AB Human perception, cognition, and action requires fast integration of bottom-up signals with top-down knowledge and context. A key theoretical perspective in cognitive science is the interactive activation hypothesis: forward and backward flow in bidirectionally connected neural networks allows humans and other biological systems to approximate optimal integration of bottom-up and top-down information under real-world constraints. An alternative view is that online feedback is neither necessary nor helpful; purely feed forward alternatives can be constructed for any feedback system, and online feedback could not improve processing and would preclude veridical perception. In the domain of spoken word recognition, the latter view was apparently supported by simulations using the interactive activation model, TRACE, with and without feedback: as many words were recognized more quickly without feedback as were recognized faster with feedback, However, these simulations used only a small set of words and did not address a primary motivation for interaction: making a model robust in noise. We conducted simulations using hundreds of words, and found that the majority were recognized more quickly with feedback than without. More importantly, as we added noise to inputs, accuracy and recognition times were better with feedback than without. We follow these simulations with a critical review of recent arguments that online feedback in interactive activation models like TRACE is distinct from other potentially helpful forms of feedback. We conclude that in addition to providing the benefits demonstrated in our simulations, online feedback provides a plausible means of implementing putatively distinct forms of feedback, supporting the interactive activation hypothesis.
C1 [Magnuson, James S.; Luthra, Sahil; Harris, Harlan D.] Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
   [Magnuson, James S.; Luthra, Sahil; Harris, Harlan D.] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
   [Mirman, Daniel] Univ Alabama Birmingham, Dept Psychol, Birmingham, AL 35294 USA.
   [Strauss, Ted] McGill Univ, McConnell Brain Imaging Ctr, Montreal, PQ, Canada.
   [Harris, Harlan D.] WayUp, New York, NY USA.
RP Magnuson, JS (corresponding author), Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.; Magnuson, JS (corresponding author), Univ Connecticut, Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
EM james.magnuson@uconn.edu
RI Mirman, Daniel/ABA-6318-2020
OI Mirman, Daniel/0000-0001-5472-0220; Luthra, Sahil/0000-0002-3517-2609;
   Magnuson, James/0000-0003-0158-2367
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [DC-005765]; NSFNational Science
   Foundation (NSF) [0748684]; NIHUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [P01-HD00199];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC005765, R01DC005765, R01DC005765,
   R01DC005765, R01DC005765, R01DC005765] Funding Source: NIH RePORTER
FX This work was supported by National Institute on Deafness and Other
   Communication Disorders Grant DC-005765, NSF CAREER 0748684 to JM, and
   NIH P01-HD00199 to Haskins Laboratories (J. Rueckl, PI).
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Borsky S, 1998, J ACOUST SOC AM, V103, P2670, DOI 10.1121/1.422787
   Chater N, 2010, WIRES COGN SCI, V1, P811, DOI 10.1002/wcs.79
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   COLE RA, 1973, PERCEPT PSYCHOPHYS, V13, P153, DOI 10.3758/BF03207252
   Cooper RP, 2015, TOP COGN SCI, V7, P243, DOI 10.1111/tops.12132
   CUTLER A, 1987, COGNITIVE PSYCHOL, V19, P141, DOI 10.1016/0010-0285(87)90010-7
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Frauenfelder UH, 1998, SCI PSYCH S, P101
   Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Geisler WS, 2009, VISUAL NEUROSCI, V26, P1, DOI 10.1017/S0952523808081005
   Geisler Wilson S., 2003, VISUAL NEUROSCIENCES, V10, P825
   Gow DW, 2016, LANG COGN NEUROSCI, V31, P841, DOI 10.1080/23273798.2015.1029498
   Gow DW, 2015, J MEM LANG, V82, P41, DOI 10.1016/j.jml.2015.03.004
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027
   Griffiths TL, 2008, CAMB HANDB PSYCHOL, P59
   Grossberg S, 2003, J PHONETICS, V31, P423, DOI 10.1016/S0095-4470(03)00051-2
   Guediche S, 2013, J COGNITIVE NEUROSCI, V25, P706, DOI 10.1162/jocn_a_00351
   Hernandez L, 2002, NEUROIMAGE, V17, P1018, DOI 10.1006/nimg.2001.1017
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Khaitan P., 2010, P 32 ANN M COGN SCI
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Knill DC, 1996, PERCEPTION BAYESIAN, DOI [10.1017/CBO9780511984037, DOI 10.1017/CBO9780511984037]
   Krawczyk DC, 2002, NEUROSCI BIOBEHAV R, V26, P631, DOI 10.1016/S0149-7634(02)00021-0
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Lee TS, 2001, P NATL ACAD SCI USA, V98, P1907, DOI 10.1073/pnas.031579998
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Luce R.D., 1959, INDIVIDUAL CHOICE BE
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   Magnuson J. S., 2012, CAMBRIDGE HDB PSYCHO, P76, DOI DOI 10.1017/CB09781139029377.008
   Magnuson J. S., 2013, OXFORD HDB COGNITIVE, P412, DOI DOI 10.1093/OXFORDHB/9780195376746.013.0027
   Magnuson JS., 2008, SINGLE WORD READING, P377
   Marr D., 1982, VISION
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Mayor J, 2014, J MEM LANG, V71, P89, DOI 10.1016/j.jml.2013.09.009
   McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1, P3, DOI DOI 10.1016/B978-1-4832-1446-7.50010-8
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   McClelland JL, 2014, COGNITIVE SCI, V38, P1139, DOI 10.1111/cogs.12146
   McClelland JL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00503
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375
   MCCLELLAND JL, 1991, COGNITIVE PSYCHOL, V23, P1, DOI 10.1016/0010-0285(91)90002-6
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McQueen JM, 2006, TRENDS COGN SCI, V10, P533, DOI 10.1016/j.tics.2006.10.004
   McQueen JM, 2003, COGNITIVE SCI, V27, P795, DOI 10.1016/S0364-0213(03)00069-7
   Mirman D, 2005, J MEM LANG, V52, P416, DOI 10.1016/j.jml.2005.01.006
   Mirman D, 2017, CUR ISS PSYCHOL LANG, P97
   Mirman D, 2011, BRAIN LANG, V117, P53, DOI 10.1016/j.bandl.2011.01.004
   Movellan JR, 2001, PSYCHOL REV, V108, P113, DOI 10.1037//0033-295X.108.1.113
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   Oaksford M, 2007, BAYESIAN RATIONALITY, DOI [10.1093/acprof:oso/9780198524496.001.0001, DOI 10.1093/ACPROF:OSO/9780198524496.001.0001]
   Pearl J., 1982, P NAT C ART INT, P133, DOI DOI 10.1038/4580
   Samuel AG, 1996, J EXP PSYCHOL GEN, V125, P28, DOI 10.1037/0096-3445.125.1.28
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Samuel AG, 1997, COGNITIVE PSYCHOL, V32, P97, DOI 10.1006/cogp.1997.0646
   Sanborn AN, 2010, PSYCHOL REV, V117, P1144, DOI 10.1037/a0020511
   Seidenberg MS, 1997, SCIENCE, V275, P1599, DOI 10.1126/science.275.5306.1599
   Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104
   Sonderegger M, 2010, COGNITION IN FLUX, P375
   Spivey MJ, 2016, LANG COGN NEUROSCI, V31, P856, DOI 10.1080/23273798.2016.1140788
   Spivey MJ, 2005, P NATL ACAD SCI USA, V102, P10393, DOI 10.1073/pnas.0503903102
   Strauss T. J., 2006, TECHNICAL REPORT TRA
   Strauss TJ, 2007, BEHAV RES METHODS, V39, P19, DOI 10.3758/BF03192840
   Travis KE, 2013, CEREB CORTEX, V23, P2370, DOI 10.1093/cercor/bhs228
NR 79
TC 5
Z9 5
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD APR 3
PY 2018
VL 9
AR 369
DI 10.3389/fpsyg.2018.00369
PG 18
WC Psychology, Multidisciplinary
SC Psychology
GA GB4UJ
UT WOS:000429056500001
PM 29666593
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Russeler, J
   Ye, Z
   Gerth, I
   Szycik, GR
   Munte, TF
AF Ruesseler, Jascha
   Ye, Zheng
   Gerth, Ivonne
   Szycik, Gregor R.
   Muente, Thomas F.
TI Audio-visual speech perception in adult readers with dyslexia: an fMRI
   study
SO BRAIN IMAGING AND BEHAVIOR
LA English
DT Article
DE Developmental dyslexia; Audio-visual processing; Event-related fMRI;
   Independent component analysis
ID INDEPENDENT COMPONENT ANALYSIS; AUDITORY-VISUAL SPEECH; MULTISENSORY
   INTEGRATION; DEVELOPMENTAL DYSLEXIA; READING-DISABILITY; HEARING LIPS;
   NEURAL BASIS; SCHIZOPHRENIA; BRAIN; NETWORKS
AB Developmental dyslexia is a specific deficit in reading and spelling that often persists into adulthood. In the present study, we used slow event-related fMRI and independent component analysis to identify brain networks involved in perception of audio-visual speech in a group of adult readers with dyslexia (RD) and a group of fluent readers (FR). Participants saw a video of a female speaker saying a disyllabic word. In the congruent condition, audio and video input were identical whereas in the incongruent condition, the two inputs differed. Participants had to respond to occasionally occurring animal names. The independent components analysis (ICA) identified several components that were differently modulated in FR and RD. Two of these components including fusiform gyrus and occipital gyrus showed less activation in RD compared to FR possibly indicating a deficit to extract face information that is needed to integrate auditory and visual information in natural speech perception. A further component centered on the superior temporal sulcus (STS) also exhibited less activation in RD compared to FR. This finding is corroborated in the univariate analysis that shows less activation in STS for RD compared to FR. These findings suggest a general impairment in recruitment of audiovisual processing areas in dyslexia during the perception of natural speech.
C1 [Ruesseler, Jascha] Otto Friedrich Univ Bamberg, Dept Psychol, Bamberg, Germany.
   [Ye, Zheng] Chinese Acad Sci, Inst Psychol, Beijing, Peoples R China.
   [Gerth, Ivonne] Klinikum Magdeburg, Neurol, Magdeburg, Germany.
   [Szycik, Gregor R.] Hannover Med Sch, Dept Psychiat, Hannover, Germany.
   [Muente, Thomas F.] Univ Lubeck, Dept Neurol, Ratzeburger Allee 160, D-23562 Lubeck, Germany.
   [Muente, Thomas F.] Univ Lubeck, Inst Psychol 2, Lubeck, Germany.
RP Munte, TF (corresponding author), Univ Lubeck, Dept Neurol, Ratzeburger Allee 160, D-23562 Lubeck, Germany.; Munte, TF (corresponding author), Univ Lubeck, Inst Psychol 2, Lubeck, Germany.
EM thomas.muente@neuro.uni-luebeck.de
RI Szycik, Gregor/C-2069-2019; Ye, Zheng/V-9575-2019
OI Szycik, Gregor/0000-0001-9339-1191; Ye, Zheng/0000-0003-1912-6992
FU BMBF grantsFederal Ministry of Education & Research (BMBF) [01GJ1303A,
   01AB074401]
FX Supported by BMBF grants 01GJ1303A to TFM and 01AB074401 to JR.
CR Baart M, 2012, ACTA PSYCHOL, V140, P91, DOI 10.1016/j.actpsy.2012.03.003
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Baumgart F, 1998, MED PHYS, V25, P2068, DOI 10.1118/1.598368
   Beauchamp MS, 2005, CURR OPIN NEUROBIOL, V15, P145, DOI 10.1016/j.conb.2005.03.011
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   BIRCH HG, 1964, AM J ORTHOPSYCHIAT, V34, P852, DOI 10.1111/j.1939-0025.1964.tb02240.x
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Brefczynski-Lewis J, 2009, BRAIN TOPOGR, V21, P193, DOI 10.1007/s10548-009-0093-6
   Brunswick N, 1999, BRAIN, V122, P1901, DOI 10.1093/brain/122.10.1901
   Calhoun VD, 2001, HUM BRAIN MAPP, V14, P140, DOI 10.1002/hbm.1048
   Calhoun VD, 2008, HUM BRAIN MAPP, V29, P828, DOI 10.1002/hbm.20581
   Calhoun VD, 2009, NEUROIMAGE, V45, pS163, DOI 10.1016/j.neuroimage.2008.10.057
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Cohen L, 2002, BRAIN, V125, P1054, DOI 10.1093/brain/awf094
   de Gelder B, 1998, BRAIN LANG, V64, P269, DOI 10.1006/brln.1998.1973
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Froyen D, 2008, NEUROSCI LETT, V430, P23, DOI 10.1016/j.neulet.2007.10.014
   Froyen D, 2011, DEVELOPMENTAL SCI, V14, P635, DOI 10.1111/j.1467-7687.2010.01007.x
   Froyen DJW, 2009, J COGNITIVE NEUROSCI, V21, P567, DOI 10.1162/jocn.2009.21061
   Goswami U, 2000, Dyslexia, V6, P133, DOI 10.1002/(SICI)1099-0909(200004/06)6:2<133::AID-DYS160>3.0.CO;2-A
   Habib M, 2013, HAND CLINIC, V111, P229, DOI 10.1016/B978-0-444-52891-9.00023-3
   Hahn N, 2014, NEUROSCI BIOBEHAV R, V47, P384, DOI 10.1016/j.neubiorev.2014.09.007
   Hayes EA, 2003, NEUROSCI LETT, V351, P46, DOI 10.1016/S0304-3940(03)00971-6
   Kast M, 2011, BRAIN LANG, V119, P136, DOI 10.1016/j.bandl.2011.04.002
   Kere J, 2014, BIOCHEM BIOPH RES CO, V452, P236, DOI 10.1016/j.bbrc.2014.07.102
   Kersting M., 2004, RT RECHTSCHREIBUNGST
   Kim DI, 2009, HUM BRAIN MAPP, V30, P3795, DOI 10.1002/hbm.20807
   Kim DI, 2009, SCHIZOPHRENIA BULL, V35, P67, DOI 10.1093/schbul/sbn133
   Kochan NA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023960
   Kronschnabel J, 2014, NEUROPSYCHOLOGIA, V62, P245, DOI 10.1016/j.neuropsychologia.2014.07.024
   Landi N, 2013, READ WRIT Q, V29, P145, DOI 10.1080/10573569.2013.758566
   Langer N, 2015, CEREB CORTEX, V25, P1441, DOI 10.1093/cercor/bht330
   Lee H, 2011, J NEUROSCI, V31, P11338, DOI 10.1523/JNEUROSCI.6510-10.2011
   Li YO, 2007, HUM BRAIN MAPP, V28, P1251, DOI 10.1002/hbm.20359
   Linder M, 2000, ZURCHER LESETEST ZLT
   Mak L. E., 2016, BRAIN CONNECT
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Megnin-Viggars O, 2013, BRAIN LANG, V124, P165, DOI 10.1016/j.bandl.2012.12.002
   Mittag M, 2013, CLIN NEUROPHYSIOL, V124, P315, DOI 10.1016/j.clinph.2012.08.003
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Nestor A, 2013, CEREB CORTEX, V23, P1673, DOI 10.1093/cercor/bhs158
   Pekkola J, 2006, NEUROIMAGE, V29, P797, DOI 10.1016/j.neuroimage.2005.09.069
   Peterson RL, 2012, LANCET, V379, P1997, DOI 10.1016/S0140-6736(12)60198-6
   Raichle ME, 2015, ANNU REV NEUROSCI, V38, P433, DOI 10.1146/annurev-neuro-071013-014030
   Ramirez J, 2005, J ACOUST SOC AM, V118, P1122, DOI 10.1121/1.1940509
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Raskind WH, 2013, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00601
   Richlan F, 2011, NEUROIMAGE, V56, P1735, DOI 10.1016/j.neuroimage.2011.02.040
   Richlan F, 2009, HUM BRAIN MAPP, V30, P3299, DOI 10.1002/hbm.20752
   Russeler J, 2015, NEUROSCIENCE, V287, P55, DOI 10.1016/j.neuroscience.2014.12.023
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Shaywitz SE, 2008, DEV PSYCHOPATHOL, V20, P1329, DOI 10.1017/S0954579408000631
   SHAYWITZ SE, 1990, JAMA-J AM MED ASSOC, V264, P998, DOI 10.1001/jama.264.8.998
   Sigurdardottir HM, 2015, NEUROPSYCHOLOGY, V29, P739, DOI 10.1037/neu0000188
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Snowling M J, 2001, Dyslexia, V7, P37
   SNOWLING MJ, 1980, J EXP CHILD PSYCHOL, V29, P294, DOI 10.1016/0022-0965(80)90021-1
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Szycik GR, 2013, NEUROSCIENCE, V253, P274, DOI 10.1016/j.neuroscience.2013.08.041
   Szycik GR, 2009, SCHIZOPHR RES, V110, P111, DOI 10.1016/j.schres.2009.03.003
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Szycik GR, 2009, HUM BRAIN MAPP, V30, P1990, DOI 10.1002/hbm.20640
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tree JJ, 2008, CORTEX, V44, P698, DOI 10.1016/j.cortex.2006.11.003
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Widmann A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00060
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Ye Z, 2014, HUM BRAIN MAPP, V35, P367, DOI 10.1002/hbm.22182
NR 71
TC 11
Z9 12
U1 3
U2 23
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1931-7557
EI 1931-7565
J9 BRAIN IMAGING BEHAV
JI Brain Imaging Behav.
PD APR
PY 2018
VL 12
IS 2
BP 357
EP 368
DI 10.1007/s11682-017-9694-y
PG 12
WC Neuroimaging
SC Neurosciences & Neurology
GA GB4KM
UT WOS:000429029000006
PM 28290075
DA 2021-02-24
ER

PT J
AU Lavigne, KM
   Woodward, TS
AF Lavigne, Katie M.
   Woodward, Todd S.
TI Hallucination- and speech-specific hypercoupling in frontotemporal
   auditory and language networks in schizophrenia using combined
   task-based fMRI data: An fBIRN study
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE auditory-verbal hallucinations; auditory oddball; connectivity;
   functional brain networks; speech perception
ID FUNCTIONAL BRAIN NETWORKS; PRINCIPAL COMPONENT ANALYSIS; VERBAL
   HALLUCINATIONS; WORKING-MEMORY; CONNECTIVITY; METAANALYSIS; VOICES;
   ORGANIZATION; INTEGRATION; NUMBER
AB Hypercoupling of activity in speech-perception-specific brain networks has been proposed to play a role in the generation of auditory-verbal hallucinations (AVHs) in schizophrenia; however, it is unclear whether this hypercoupling extends to nonverbal auditory perception. We investigated this by comparing schizophrenia patients with and without AVHs, and healthy controls, on task-based functional magnetic resonance imaging (fMRI) data combining verbal speech perception (SP), inner verbal thought generation (VTG), and nonverbal auditory oddball detection (AO). Data from two previously published fMRI studies were simultaneously analyzed using group constrained principal component analysis for fMRI (group fMRI-CPCA), which allowed for comparison of task-related functional brain networks across groups and tasks while holding the brain networks under study constant, leading to determination of the degree to which networks are common to verbal and nonverbal perception conditions, and which show coordinated hyperactivity in hallucinations. Three functional brain networks emerged: (a) auditory-motor, (b) language processing, and (c) default-mode (DMN) networks. Combining the AO and sentence tasks allowed the auditory-motor and language networks to separately emerge, whereas they were aggregated when individual tasks were analyzed. AVH patients showed greater coordinated activity (deactivity for DMN regions) than non-AVH patients during SP in all networks, but this did not extend to VTG or AO. This suggests that the hypercoupling in AVH patients in speech-perception-related brain networks is specific to perceived speech, and does not extend to perceived nonspeech or inner verbal thought generation.
C1 [Lavigne, Katie M.; Woodward, Todd S.] Univ British Columbia, Dept Psychiat, Vancouver, BC, Canada.
   [Lavigne, Katie M.; Woodward, Todd S.] BC Mental Hlth & Addict Res Inst, Room A3-A117,Translat Res Bldg,3rd Floor, Vancouver, BC V5Z 4H4, Canada.
RP Woodward, TS (corresponding author), BC Mental Hlth & Addict Res Inst, Room A3-A117,Translat Res Bldg,3rd Floor, Vancouver, BC V5Z 4H4, Canada.
EM Todd.S.Woodward@gmail.com
OI Woodward, Todd/0000-0001-8083-0079
FU Michael Smith Foundation for Health ResearchMichael Smith Foundation for
   Health Research [CI-SCH00073]; Canadian Institutes of Health
   ResearchCanadian Institutes of Health Research (CIHR) [MMS8770];
   Function BIRN [U24-RR021992]; National Center for Research Resources at
   the National Institutes of Health, USAUnited States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Center for Research Resources (NCRR) [MOI RR 000827]; NATIONAL CENTER
   FOR RESEARCH RESOURCESUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Center for
   Research Resources (NCRR) [M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, U24RR021992, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, U24RR021992, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, U24RR021992,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, U24RR021992,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, U24RR021992, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, U24RR021992,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   U24RR021992, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, U24RR021992, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, U24RR021992, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, U24RR021992, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, U24RR021992, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, U24RR021992,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, U24RR021992, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, U24RR021992, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, U24RR021992, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, U24RR021992,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, U24RR021992,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827,
   M01RR000827, M01RR000827, M01RR000827, M01RR000827, M01RR000827] Funding
   Source: NIH RePORTER
FX Michael Smith Foundation for Health Research, Grant/Award Number:
   CI-SCH00073; Canadian Institutes of Health Research, Grant/Award Number:
   MMS8770; Function BIRN, Grant/Award Number: U24-RR021992; National
   Center for Research Resources at the National Institutes of Health, USA,
   Grant/Award Number: MOI RR 000827
CR Alderson-Day B, 2016, SCHIZOPHRENIA BULL, V42, P1110, DOI 10.1093/schbul/sbw078
   Aleman A., 2013, BOTTOM TOP COMPONENT, P107
   Allen P., 2012, SCHIZOPHR B
   Andreasen NC, 1984, SCALE ASSESSMENT POS
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011
   CATTELL RB, 1977, MULTIVAR BEHAV RES, V12, P289, DOI 10.1207/s15327906mbr1203_2
   CATTELL RB, 1966, MULTIVAR BEHAV RES, V1, P245, DOI 10.1207/s15327906mbr0102_10
   Curcic-Blake B, 2017, PROG NEUROBIOL, V148, P1, DOI 10.1016/j.pneurobio.2016.11.002
   Ford J. M., 2013, NEUROSCIENCE HALLUCI, P359
   Ford JM, 2007, AM J PSYCHIAT, V164, P458, DOI 10.1176/appi.ajp.164.3.458
   Ford JM, 2009, SCHIZOPHRENIA BULL, V35, P58, DOI 10.1093/schbul/sbn140
   Friedman L, 2008, HUM BRAIN MAPP, V29, P958, DOI 10.1002/hbm.20440
   Hoffman R., 2010, APR 29 COMMENT VERCA
   Hoffman RE, 2011, BRIT J PSYCHIAT, V198, P277, DOI 10.1192/bjp.bp.110.086835
   Hoffman RE, 2011, BIOL PSYCHIAT, V69, P407, DOI 10.1016/j.biopsych.2010.09.050
   Hoffman RE, 1999, ACTA PSYCHIAT SCAND, V99, P89, DOI 10.1111/j.1600-0447.1999.tb05987.x
   Hugdahl K, 2015, WORLD J PSYCHIATR, V5, P193, DOI 10.5498/wjp.v5.i2.193
   Hunter MA, 2002, J EDUC BEHAV STAT, V27, P105, DOI 10.3102/10769986027002105
   Jardri R, 2013, CEREB CORTEX, V23, P1108, DOI 10.1093/cercor/bhs082
   Jardri R, 2011, AM J PSYCHIAT, V168, P73, DOI 10.1176/appi.ajp.2010.09101522
   Keator DB, 2008, IEEE T INF TECHNOL B, V12, P162, DOI 10.1109/TITB.2008.917893
   Kim H, 2014, HUM BRAIN MAPP, V35, P2265, DOI 10.1002/hbm.22326
   Kompus K, 2011, NEUROPSYCHOLOGIA, V49, P3361, DOI 10.1016/j.neuropsychologia.2011.08.010
   Laroi F, 2007, HARVARD REV PSYCHIAT, V15, P109, DOI 10.1080/10673220701401993
   Lavigne KM, 2016, HUM BRAIN MAPP, V37, P4640, DOI 10.1002/hbm.23334
   Lavigne KM, 2015, NEUROIMAGE, V112, P138, DOI 10.1016/j.neuroimage.2015.02.043
   Lavigne KM, 2015, SCHIZOPHRENIA BULL, V41, P259, DOI 10.1093/schbul/sbu004
   Liddle PF, 2002, BRIT J PSYCHIAT, V180, P45, DOI 10.1192/bjp.180.1.45
   Linden DEJ, 2011, CEREB CORTEX, V21, P330, DOI 10.1093/cercor/bhq097
   Magnotta VA, 2006, J DIGIT IMAGING, V19, P140, DOI 10.1007/s10278-006-0264-x
   McLachlan NM, 2013, SCHIZOPHR RES, V150, P380, DOI 10.1016/j.schres.2013.08.039
   Metzak P, 2011, HUM BRAIN MAPP, V32, P856, DOI 10.1002/hbm.21072
   Metzak PD, 2015, NEUROPSYCHOLOGIA, V75, P50, DOI 10.1016/j.neuropsychologia.2015.05.014
   Metzak PD, 2012, SCHIZOPHRENIA BULL, V38, P803, DOI 10.1093/schbul/sbq154
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Rapin LA, 2012, PSYCHIAT RES-NEUROIM, V202, P110, DOI 10.1016/j.pscychresns.2011.12.014
   Ribary U., 2017, NEUROETHICS DEFINING
   Rossell SL, 2005, SCHIZOPHR RES, V78, P95, DOI 10.1016/j.schres.2005.06.002
   Serences JT, 2004, NEUROIMAGE, V21, P1690, DOI 10.1016/j.neuroimage.2003.12.021
   Shinn AK, 2013, SCHIZOPHR RES, V143, P260, DOI 10.1016/j.schres.2012.11.037
   TAKANE Y, 1991, PSYCHOMETRIKA, V56, P97, DOI 10.1007/BF02294589
   Takane Y, 2001, APPL ALGEBR ENG COMM, V12, P391, DOI 10.1007/s002000100081
   Thoma RJ, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00039
   Woodward T.S., 2013, NEUROSCIENCE HALLUCI, P169
   Woodward TS, 2016, PSYCHIAT RES-NEUROIM, V248, P94, DOI 10.1016/j.pscychresns.2016.01.003
   Woodward TS, 2015, HUM BRAIN MAPP, V36, P2948, DOI 10.1002/hbm.22820
   Woodward TS, 2013, NEUROIMAGE, V65, P529, DOI 10.1016/j.neuroimage.2012.09.070
   Woodward TS, 2006, NEUROSCIENCE, V139, P317, DOI 10.1016/j.neuroscience.2005.05.043
   Wynn JK, 2015, NEUROIMAGE-CLIN, V9, P95, DOI 10.1016/j.nicl.2015.07.004
   Yeo BTT, 2011, J NEUROPHYSIOL, V106, P1125, DOI 10.1152/jn.00338.2011
NR 50
TC 10
Z9 10
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD APR
PY 2018
VL 39
IS 4
BP 1582
EP 1595
DI 10.1002/hbm.23934
PG 14
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA FY8LW
UT WOS:000427117300008
PM 29271110
OA Green Published, Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Stevenson, RA
   Sun, SZ
   Hazlett, N
   Cant, JS
   Barense, MD
   Ferber, S
AF Stevenson, Ryan A.
   Sun, Sol Z.
   Hazlett, Naomi
   Cant, Jonathan S.
   Barense, Morgan D.
   Ferber, Susanne
TI Seeing the Forest and the Trees: Default Local Processing in Individuals
   with High Autistic Traits Does Not Come at the Expense of Global
   Attention
SO JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS
LA English
DT Article
DE Autism spectrum disorder; Face recognition; Sensory processing;
   Composite-face effect; Vision; Attention; Global processing; Local
   processing
ID HIGH-FUNCTIONING AUTISM; SPECTRUM QUOTIENT AQ; HOLISTIC FACE PERCEPTION;
   SUPERIOR VISUAL-SEARCH; ASPERGER-SYNDROME; SPEECH-PERCEPTION;
   SPATIAL-FREQUENCIES; SELECTIVE ATTENTION; SENSORY PROFILE; NORMAL ADULTS
AB Atypical sensory perception is one of the most ubiquitous symptoms of autism, including a tendency towards a local-processing bias. We investigated whether local-processing biases were associated with global-processing impairments on a global/local attentional-scope paradigm in conjunction with a composite-face task. Behavioural results were related to individuals' levels of autistic traits, specifically the Attention to Detail subscale of the Autism Quotient, and the Sensory Profile Questionnaire. Individuals showing high rates of Attention to Detail were more susceptible to global attentional-scope manipulations, suggesting that local-processing biases associated with Attention to Detail do not come at the cost of a global-processing deficit, but reflect a difference in default global versus local bias. This relationship operated at the attentional/perceptual level, but not response criterion.
C1 [Stevenson, Ryan A.; Sun, Sol Z.; Hazlett, Naomi; Barense, Morgan D.; Ferber, Susanne] Univ Toronto, Dept Psychol, 100 St George St, Toronto, ON M5S 3G3, Canada.
   [Sun, Sol Z.; Cant, Jonathan S.] Univ Toronto Scarborough, Dept Psychol, Toronto, ON, Canada.
   [Barense, Morgan D.; Ferber, Susanne] Rotman Res Inst Baycrest, Toronto, ON, Canada.
RP Stevenson, RA (corresponding author), Univ Toronto, Dept Psychol, 100 St George St, Toronto, ON M5S 3G3, Canada.
EM ryan.andrew.stevenson@gmail.com
RI Barense, Morgan/H-7451-2019
OI Barense, Morgan/0000-0002-4008-9201
FU NSERC Banting Postdoctoral Fellowship; CIHR Autism Research Training
   programCanadian Institutes of Health Research (CIHR); NSERC CGS-M
   Scholarship; NSERCNatural Sciences and Engineering Research Council of
   Canada (NSERC) [435647-2013, 216203-13]; James S McDonnell Foundation;
   CIHRCanadian Institutes of Health Research (CIHR) [MOP-115148, 106436]
FX R.S.-NSERC Banting Postdoctoral Fellowship, CIHR Autism Research
   Training program; S.S.-NSERC CGS-M Scholarship; J.C.-NSERC Discovery
   Grant 435647-2013; M.B.-Scholar Award from the James S McDonnell
   Foundation, CIHR Grant MOP-115148; S.F.-NSERC Grant 216203-13, CIHR
   Grant 106436.
CR Almeida RA, 2014, VISION RES, V103, P109, DOI 10.1016/j.visres.2014.08.015
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Association A. P., 2000, DIAGN STAT MAN MENT
   BADCOCK JC, 1990, PERCEPTION, V19, P617, DOI 10.1068/p190617
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715
   BaronCohen S, 1997, VIS COGN, V4, P311, DOI 10.1080/713756761
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Behrmann M, 2006, NEUROPSYCHOLOGIA, V44, P110, DOI 10.1016/j.neuropsychologia.2005.04.002
   Behrmann M, 2006, TRENDS COGN SCI, V10, P258, DOI 10.1016/j.tics.2006.05.001
   Bertone A, 2005, BRAIN, V128, P2430, DOI 10.1093/brain/awh561
   Blair RJR, 2002, NEUROPSYCHOLOGIA, V40, P108, DOI 10.1016/S0028-3932(01)00069-0
   Bolte S, 2007, J AUTISM DEV DISORD, V37, P1493, DOI 10.1007/s10803-006-0231-x
   BOUCHER J, 1992, J CHILD PSYCHOL PSYC, V33, P843, DOI 10.1111/j.1469-7610.1992.tb01960.x
   Brown C, 2001, AM J OCCUP THER, V55, P75, DOI 10.5014/ajot.55.1.75
   Brown C., 2002, ADOLESCENT ADULT SEN
   Bruinsma Y, 2004, MENT RETARD DEV D R, V10, P169, DOI 10.1002/mrdd.20036
   Busigny T, 2011, J NEUROPSYCHOL, V5, P1, DOI 10.1348/174866410X500116
   Cheung OS, 2008, J EXP PSYCHOL HUMAN, V34, P1327, DOI 10.1037/a0011752
   De Martino B, 2008, J NEUROSCI, V28, P10746, DOI 10.1523/JNEUROSCI.2895-08.2008
   Deruelle C, 2006, INT J PSYCHOL, V41, P97, DOI 10.1080/00207590500184610
   Deruelle C, 2004, J AUTISM DEV DISORD, V34, P199, DOI 10.1023/B:JADD.0000022610.09668.4c
   Dunn W, 1997, AM J OCCUP THER, V51, P25, DOI 10.5014/ajot.51.1.25
   Ekman P., 1972, NEBRASKA S MOTIVATIO, P207, DOI DOI 10.1037/0022-3514.53.4.712
   ERIKSEN CW, 1986, PERCEPT PSYCHOPHYS, V40, P225, DOI 10.3758/BF03211502
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Foxe J. J., 2013, CEREB CORTEX
   FRITH U, 1994, COGNITION, V50, P115, DOI 10.1016/0010-0277(94)90024-8
   Gao ZF, 2011, ATTEN PERCEPT PSYCHO, V73, P1477, DOI 10.3758/s13414-011-0109-7
   Gauthier I, 2009, VISION RES, V49, P470, DOI 10.1016/j.visres.2008.12.007
   Gepner B, 1996, CHILD NEUROPSYCHOL, V2, P123, DOI 10.1080/09297049608401357
   Goffaux V, 2006, J EXP PSYCHOL HUMAN, V32, P1023, DOI 10.1037/0096-1523.32.4.1023
   Gomot M, 2006, NEUROIMAGE, V29, P475, DOI 10.1016/j.neuroimage.2005.07.027
   Gomot M, 2002, PSYCHOPHYSIOLOGY, V39, P577, DOI 10.1017/S0048577202394058
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Happe FGE, 1996, J CHILD PSYCHOL PSYC, V37, P873, DOI 10.1111/j.1469-7610.1996.tb01483.x
   Harms MB, 2010, NEUROPSYCHOL REV, V20, P290, DOI 10.1007/s11065-010-9138-6
   Hauck M, 1998, CHILD NEUROPSYCHOL, V4, P187, DOI 10.1076/chin.4.3.187.3174
   Hills PJ, 2009, J EXP PSYCHOL HUMAN, V35, P1427, DOI 10.1037/a0015788
   Hoekstra RA, 2008, J AUTISM DEV DISORD, V38, P1555, DOI 10.1007/s10803-008-0538-x
   HUGHES HC, 1984, PERCEPT PSYCHOPHYS, V35, P361, DOI 10.3758/BF03206340
   Hurst RM, 2007, PERS INDIV DIFFER, V43, P1938, DOI 10.1016/j.paid.2007.06.012
   Iarocci G, 2006, J AUTISM DEV DISORD, V36, P77, DOI 10.1007/s10803-005-0044-3
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Jacques C, 2010, BRAIN RES, V1318, P96, DOI 10.1016/j.brainres.2009.12.070
   Jacques C, 2009, J VISION, V9, DOI 10.1167/9.6.8
   Johnson SA, 2010, J MATH PSYCHOL, V54, P53, DOI 10.1016/j.jmp.2009.06.006
   Jolliffe T, 1997, J CHILD PSYCHOL PSYC, V38, P527, DOI 10.1111/j.1469-7610.1997.tb01539.x
   Joseph RM, 2009, DEVELOPMENTAL SCI, V12, P1083, DOI 10.1111/j.1467-7687.2009.00855.x
   Kanner L, 1943, NERV CHILD, V2, P217
   Kemner C, 2008, J AUTISM DEV DISORD, V38, P553, DOI 10.1007/s10803-007-0406-0
   Kenny L, 2016, AUTISM, V20, P442, DOI 10.1177/1362361315588200
   Klin A, 1999, J AUTISM DEV DISORD, V29, P499, DOI 10.1023/A:1022299920240
   Koldewyn K, 2013, J AUTISM DEV DISORD, V43, P1394, DOI 10.1007/s10803-012-1694-6
   Kuefner D, 2010, BRAIN COGNITION, V74, P225, DOI 10.1016/j.bandc.2010.08.001
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lowe MX, 2016, J EXP PSYCHOL HUMAN, V42, P294, DOI 10.1037/xhp0000131
   Maurer D, 2002, TRENDS COGN SCI, V6, P255, DOI 10.1016/S1364-6613(02)01903-4
   Minshew N J, 1997, J Int Neuropsychol Soc, V3, P303
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L, 2003, J CHILD PSYCHOL PSYC, V44, P904, DOI 10.1111/1469-7610.00174
   Muller NG, 2003, J NEUROSCI, V23, P3561
   NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3
   NAVON D, 1981, PSYCHOL RES-PSYCH FO, V43, P1, DOI 10.1007/BF00309635
   Nishimura M, 2008, VIS COGN, V16, P859, DOI 10.1080/13506280701538514
   O'Riordan M, 2001, Q J EXP PSYCHOL-A, V54, P961, DOI 10.1080/02724980042000543
   O'Riordan MA, 2001, J EXP PSYCHOL HUMAN, V27, P719, DOI 10.1037//0096-1523.27.3.719
   O'Riordan MA, 2004, AUTISM, V8, P229, DOI 10.1177/1362361304045219
   Pellicano E, 2005, NEUROPSYCHOLOGIA, V43, P1044, DOI 10.1016/j.neuropsychologia.2004.10.003
   Pellicano E, 2012, TRENDS COGN SCI, V16, P504, DOI 10.1016/j.tics.2012.08.009
   Plaisted K, 1999, J CHILD PSYCHOL PSYC, V40, P733, DOI 10.1111/1469-7610.00489
   Rauschenberger R, 2001, PERCEPT PSYCHOPHYS, V63, P1250, DOI 10.3758/BF03194538
   Richler JJ, 2008, J EXP PSYCHOL LEARN, V34, P1356, DOI 10.1037/a0013080
   Rinehart NJ, 2000, J CHILD PSYCHOL PSYC, V41, P769, DOI 10.1017/S002196309900596X
   Rossion B, 2013, VIS COGN, V21, P139, DOI 10.1080/13506285.2013.772929
   SCAIFE M, 1975, NATURE, V253, P265, DOI 10.1038/253265a0
   Schiltz C, 2010, J VISION, V10, DOI 10.1167/10.2.25
   SHAH A, 1983, J CHILD PSYCHOL PSYC, V24, P613, DOI 10.1111/j.1469-7610.1983.tb00137.x
   SHAH A, 1993, J CHILD PSYCHOL PSYC, V34, P1351, DOI 10.1111/j.1469-7610.1993.tb02095.x
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stewart ME, 2009, PERS INDIV DIFFER, V47, P224, DOI 10.1016/j.paid.2009.03.004
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tanaka JW, 2016, J AUTISM DEV DISORD, V46, P1538, DOI 10.1007/s10803-013-1976-7
   TANAKA JW, 1993, Q J EXP PSYCHOL-A, V46, P225, DOI 10.1080/14640749308401045
   TANTAM D, 1989, J CHILD PSYCHOL PSYC, V30, P623, DOI 10.1111/j.1469-7610.1989.tb00274.x
   Teunisse JP, 2003, BRAIN COGNITION, V52, P285, DOI 10.1016/S0278-2626(03)00042-3
   Van der Hallen R, 2015, PSYCHOL BULL, V141, P549, DOI 10.1037/bul0000004
   Verde MF, 2006, PERCEPT PSYCHOPHYS, V68, P643, DOI 10.3758/BF03208765
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Wallace S, 2008, COGNITION EMOTION, V22, P1353, DOI 10.1080/02699930701782153
   Wang AT, 2004, J AM ACAD CHILD PSY, V43, P481, DOI 10.1097/00004583-200404000-00015
   Williams JHG, 2004, RES DEV DISABIL, V25, P559, DOI 10.1016/j.ridd.2004.01.008
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   YOUNG AW, 1987, PERCEPTION, V16, P747, DOI 10.1068/p160747
NR 98
TC 14
Z9 14
U1 3
U2 30
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0162-3257
EI 1573-3432
J9 J AUTISM DEV DISORD
JI J. Autism Dev. Disord.
PD APR
PY 2018
VL 48
IS 4
SI SI
BP 1382
EP 1396
DI 10.1007/s10803-016-2711-y
PG 15
WC Psychology, Developmental
SC Psychology
GA GA0ER
UT WOS:000427986300037
PM 26861715
OA Green Published
DA 2021-02-24
ER

PT J
AU Sreedharan, RM
   James, JS
   Kesavadas, C
   Thomas, SV
AF Sreedharan, Ruma M.
   James, Jija S.
   Kesavadas, Chandrasekharan
   Thomas, Sanjeev V.
TI Language lateralization in pre-adolescent children: FMRI study using
   visual verb generation and word pair paradigms
SO INDIAN JOURNAL OF RADIOLOGY AND IMAGING
LA English
DT Article
DE Functional magnetic resonance imaging; language lateralization;
   pre-adolescent children
ID WORKING-MEMORY TASK; FUNCTIONAL MRI; PREFRONTAL CORTEX;
   SPEECH-PERCEPTION; BRAIN ACTIVATION; EPILEPSY; CEREBELLUM
AB Background: FMRI is a noninvasive tool for mapping language networks, especially in children. We conducted FMRI studies in children in the age group 8-12 years using 2 different paradigms for assessing language networks and lateralization. Aim: To map language networks in pre-adolescent children and to calculate lateralization index using two different visual paradigms. Methods and Materials: The study was conducted in normal right handed children in the age group 8-12 years. Sixteen normal subjects underwent FMRI using 2 paradigms-visual verb generation (VVG), word pairs paradigm (WPP) to stimulate language areas. FMRI data analysis was done using SPM8 (statistical parametric Mapping) software. Total activated voxels were calculated for each hemispheres in the pre-defined ROIs for both paradigms. Results: FMRI showed left language lateralization in 13 out of 16 children with both VVG and WPP and bilateral language lateralization in two subjects. With VVG there was more significant activation in the left inferior triangular gyrus (ITG) (P < 0.001), left inferior opercular gyrus (IOG) (P < 0.01), left middle frontal gyrus (MFG) (P < 0.05), left and right dorsolateral prefrontal cortex (P < 0.05). Left posterior superior temporal gyrus (STG or WA) (P < 0.001), Left AG (P < 0.03), Left SMG (P < 0.05) were significantly activated with WP paradigm. Conclusion: Our FMRI studies showed that VGP predominantly activated frontal language areas and WPP predominantly activated temperoparietal language areas. Several other brain regions were also involved in language processing apart from the classical language areas.
C1 [Sreedharan, Ruma M.] Govt Med Coll Hosp, Dept Radiol, Trivandrum, Kerala, India.
   [James, Jija S.; Kesavadas, Chandrasekharan] Sree Chitra Thirunal Inst Med Sci & Technol, Dept Imaging Sci, Trivandrum, Kerala, India.
   [James, Jija S.; Kesavadas, Chandrasekharan] Sree Chitra Thirunal Inst Med Sci & Technol, Dept Intervent Radiol, Trivandrum, Kerala, India.
   [Thomas, Sanjeev V.] Sree Chitra Thirunal Inst Med Sci & Technol, Dept Neurol, Thiruvananthapuram, Kerala, India.
RP Thomas, SV (corresponding author), Sree Chitra Thirunal Inst Med Sci & Technol, Dept Neurol, Thiruvananthapuram, Kerala, India.
EM sanjeev.v.thomas@gmail.com
RI Thomas, Sanjeev/ABC-8204-2020; KESAVADAS, CHANDRASEKHARAN/ABG-8488-2020
OI KESAVADAS, CHANDRASEKHARAN/0000-0003-4914-8666
CR Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742
   Aylward EH, 2003, NEUROLOGY, V61, P212, DOI 10.1212/01.WNL.0000068363.05974.64
   Binder JR, 1997, J NEUROSCI, V17, P353
   Byars AW, 2002, J CHILD NEUROL, V17, P885, DOI 10.1177/08830738020170122201
   CASEY BJ, 1995, NEUROIMAGE, V2, P221, DOI 10.1006/nimg.1995.1029
   FRITH CD, 1991, P ROY SOC B-BIOL SCI, V244, P241, DOI 10.1098/rspb.1991.0077
   Hingwala D, 2014, ACTA RADIOL, V55, P107, DOI 10.1177/0284185113492455
   Holland SK, 2007, INT J AUDIOL, V46, P533, DOI 10.1080/14992020701448994
   Holland SK, 2001, NEUROIMAGE, V14, P837, DOI 10.1006/nimg.2001.0875
   Kwon H, 2001, AM J PSYCHIAT, V158, P1040, DOI 10.1176/appi.ajp.158.7.1040
   Liegeois F, 2006, J MAGN RESON IMAGING, V23, P933, DOI 10.1002/jmri.20586
   Mathiak K, 2002, J COGNITIVE NEUROSCI, V14, P902, DOI 10.1162/089892902760191126
   MCCARTHY G, 1994, P NATL ACAD SCI USA, V91, P8690, DOI 10.1073/pnas.91.18.8690
   MILLEN SJ, 1995, LARYNGOSCOPE, V105, P1305, DOI 10.1288/00005537-199512000-00008
   Nagata S, 2001, AM J NEURORADIOL, V22, P985
   OGAWA S, 1990, P NATL ACAD SCI USA, V87, P9868, DOI 10.1073/pnas.87.24.9868
   PARDO JV, 1993, AM J PSYCHIAT, V150, P713
   Rutten GJM, 2002, BRAIN LANG, V80, P421, DOI 10.1006/brln.2001.2600
   Sreedharan RM, 2015, NEURORADIOLOGY, V57, P291, DOI 10.1007/s00234-014-1469-1
   Swanson SJ, 2007, NEUROPSYCHOL REV, V17, P491, DOI 10.1007/s11065-007-9050-x
   Szaflarski JP, 2006, HUM BRAIN MAPP, V27, P202, DOI 10.1002/hbm.20177
   Szaflarski JP, 2002, NEUROLOGY, V59, P238, DOI 10.1212/WNL.59.2.238
   Vingerhoets G, 2004, EPILEPSY BEHAV, V5, pS81, DOI 10.1016/j.yebeh.2003.11.011
   Yerys BE, 2009, HUM BRAIN MAPP, V30, P3426, DOI 10.1002/hbm.20767
NR 24
TC 0
Z9 0
U1 1
U2 2
PU WOLTERS KLUWER MEDKNOW PUBLICATIONS
PI MUMBAI
PA WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2
   VILLAGE MAROL, ANDHERI EAST, MUMBAI, 400059, INDIA
SN 0971-3026
EI 1998-3808
J9 INDIAN J RADIOL IMAG
JI Indian J. Radil. Imaging
PD APR-JUN
PY 2018
VL 28
IS 2
BP 146
EP 151
DI 10.4103/ijri.IJRI_211_17
PG 6
WC Radiology, Nuclear Medicine & Medical Imaging
SC Radiology, Nuclear Medicine & Medical Imaging
GA GL8DY
UT WOS:000437445500003
PM 30050235
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU McFadden, D
   Pasanen, EG
   Maloney, MM
   Leshikar, EM
   Pho, MH
AF McFadden, Dennis
   Pasanen, Edward G.
   Maloney, Mindy M.
   Leshikar, Erin M.
   Pho, Michelle H.
TI Differences in common psychoacoustical tasks by sex, menstrual cycle,
   and race
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPONTANEOUS OTOACOUSTIC EMISSIONS; HEARING-LOSS; INDIVIDUAL-DIFFERENCES;
   SIMULTANEOUS MASKING; COMBINATION TONES; SPEECH-PERCEPTION; FREQUENCY;
   PREVALENCE; OVERSHOOT; HETEROSEXUALS
AB The psychoacoustical literature contains multiple reports about small differences in performance depending upon the sex and phase of the menstrual cycle of the subjects. In an attempt to verify these past reports, a large-scale study was implemented. After extensive training, the performance of about 75 listeners was measured on seven common psychoacoustical tasks. For most tasks, the signal was a 3.0-kHz tone. The initial data analyses failed to confirm some past outcomes. Additional analyses, incorporating the limited information available about the racial background of the listeners, did confirm some of the past reports, with the direction and magnitude of the differences often diverging for the White and Non-White listeners. Sex differences and race differences interacted for six of the seven tasks studied. These interactions suggest that racial background needs to be considered when making generalizations about human auditory performance, and when considering failures of reproducibility across studies. Menstrual differences were small, but generally larger for Whites than Non-Whites. Hormonal effects may be responsible for the sex and cycle differences that do exist, and differences in intra-cochlear melanocytes may account for the race differences. (C) 2018 Acoustical Society of America.
C1 [McFadden, Dennis; Pasanen, Edward G.; Maloney, Mindy M.] Univ Texas Austin, Dept Psychol, 108 East Dean Keeton,A8000, Austin, TX 78712 USA.
   [McFadden, Dennis; Pasanen, Edward G.; Maloney, Mindy M.] Univ Texas Austin, Ctr Perceptual Syst, 108 East Dean Keeton,A8000, Austin, TX 78712 USA.
   [Leshikar, Erin M.; Pho, Michelle H.] Univ Texas Austin, Dept Commun Sci & Disorders, 2504-A Whitis Ave,A1100, Austin, TX 78712 USA.
RP McFadden, D (corresponding author), Univ Texas Austin, Dept Psychol, 108 East Dean Keeton,A8000, Austin, TX 78712 USA.; McFadden, D (corresponding author), Univ Texas Austin, Ctr Perceptual Syst, 108 East Dean Keeton,A8000, Austin, TX 78712 USA.
EM mcfadden@utexas.edu
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [RO1 DC000153]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [K08DC000153] Funding Source: NIH RePORTER
FX This work was supported by a research grant awarded to D.M. by the NIDCD
   (Grant No. RO1 DC000153). The content is solely the responsibility of
   the authors and does not necessarily represent the official views of the
   NIDCD or the National Institutes of Health. We gratefully acknowledge
   the assistance of K. P. Walsh and J. T. Tran during data collection. We
   thank J. Smurzynski and an anonymous reviewer for many helpful comments.
   With the publication of this article and its companion, D.M. has
   published in this journal since 1966.
CR Agrawal Y, 2008, ARCH INTERN MED, V168, P1522, DOI 10.1001/archinte.168.14.1522
   Alexander JM, 2004, J ACOUST SOC AM, V116, P2234, DOI 10.1121/1.1784437
   Bacon SP, 2004, SPR HDB AUD, V17, P1
   Bartels S, 2001, HEARING RES, V154, P116, DOI 10.1016/S0378-5955(01)00213-1
   Bass A. H., 2016, HEARING AND HORMONES
   BELL A, 1992, HEARING RES, V58, P91, DOI 10.1016/0378-5955(92)90012-C
   BILGER RC, 1990, J SPEECH HEAR RES, V33, P418, DOI 10.1044/jshr.3303.418
   Bonaccorsi P, 1965, Ann Laringol Otol Rinol Faringol, V64, P725
   Burns EM, 2017, J ACOUST SOC AM, V142, P1828, DOI 10.1121/1.5005607
   BURNS EM, 1992, J ACOUST SOC AM, V91, P1571, DOI 10.1121/1.402438
   CHAMPLIN CA, 1989, J ACOUST SOC AM, V85, P2005, DOI 10.1121/1.397853
   CHUNG DY, 1983, J ACOUST SOC AM, V73, P1277, DOI 10.1121/1.389276
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Da Costa EA, 2008, INT J AUDIOL, V47, P115, DOI 10.1080/14992020701704776
   DAVIS M J, 1982, Journal of Auditory Research, V22, P173
   DRESCHLER WA, 1985, J ACOUST SOC AM, V78, P1261, DOI 10.1121/1.392895
   ELKINDHIRSCH KE, 1992, HEARING RES, V60, P143, DOI 10.1016/0378-5955(92)90016-G
   Elliott D. N., 1966, ACTA OTO-LARYNGOL, V216, P1
   FESTEN JM, 1981, J ACOUST SOC AM, V70, P356, DOI 10.1121/1.386771
   GARBER SR, 1982, EAR HEARING, V3, P207, DOI 10.1097/00003446-198207000-00004
   Green D. M., 1988, PROFILE ANAL AUDITOR
   GREENWOOD DD, 1971, J ACOUST SOC AM, V50, P502, DOI 10.1121/1.1912668
   HAGGERTY HS, 1993, HEARING RES, V70, P31, DOI 10.1016/0378-5955(93)90050-B
   Hicks ML, 1999, J ACOUST SOC AM, V105, P326, DOI 10.1121/1.424526
   Huyck JJ, 2013, J ACOUST SOC AM, V134, P1172, DOI 10.1121/1.4812258
   KEMP DT, 1978, J ACOUST SOC AM, V64, P1386, DOI 10.1121/1.382104
   KEMP DT, 1979, ARCH OTO-RHINO-LARYN, V224, P37, DOI 10.1007/BF00455222
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   LAFERRIE.KA, 1974, ANN OTO RHINOL LARYN, V83, P685, DOI 10.1177/000348947408300518
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lin FR, 2012, JARO-J ASSOC RES OTO, V13, P109, DOI 10.1007/s10162-011-0298-8
   LINDQUIST N G, 1973, Acta Radiologica Supplementum, V325, P1
   Livingston G., 2017, INTERMARRIAGE US 50, P1
   MCFADDEN D, 1993, HEARING RES, V71, P208, DOI 10.1016/0378-5955(93)90036-Z
   MCFADDEN D, 1995, HEARING RES, V85, P181, DOI 10.1016/0378-5955(95)00045-6
   MCFADDEN D, 1983, ANNU REV PSYCHOL, V34, P95, DOI 10.1146/annurev.ps.34.020183.000523
   McFadden D, 1999, J ACOUST SOC AM, V105, P2403, DOI 10.1121/1.426845
   McFadden D, 1998, DEV NEUROPSYCHOL, V14, P261, DOI 10.1080/87565649809540712
   McFadden D, 2000, HEARING RES, V142, P23, DOI 10.1016/S0378-5955(00)00002-2
   McFadden D, 1998, P NATL ACAD SCI USA, V95, P2709, DOI 10.1073/pnas.95.5.2709
   McFadden D, 2002, ARCH SEX BEHAV, V31, P99, DOI 10.1023/A:1014087319682
   MCFADDEN D, 1993, HEARING RES, V68, P143, DOI 10.1016/0378-5955(93)90118-K
   MCFADDEN D, 1990, J ACOUST SOC AM, V87, P2634, DOI 10.1121/1.399056
   McFadden D, 2006, HORM BEHAV, V50, P274, DOI 10.1016/j.yhbeh.2006.03.012
   McFadden D, 2018, J ACOUST SOC AM, V143, P2355, DOI 10.1121/1.5030999
   McFadden D, 2012, J ACOUST SOC AM, V132, P968, DOI 10.1121/1.4731224
   McFadden D, 2012, HEARING RES, V289, P63, DOI 10.1016/j.heares.2012.04.010
   McFadden D, 2011, FRONT NEUROENDOCRIN, V32, P201, DOI 10.1016/j.yfrne.2011.02.001
   McFadden D, 2010, J ACOUST SOC AM, V128, P1915, DOI 10.1121/1.3480568
   McFadden D, 2009, J ACOUST SOC AM, V125, P239, DOI 10.1121/1.3037231
   McFadden D, 2008, PERSPECT PSYCHOL SCI, V3, P309, DOI 10.1111/j.1745-6924.2008.00082.x
   McFadden D, 2009, HORM BEHAV, V55, P98, DOI 10.1016/j.yhbeh.2008.08.013
   Mills J., 1982, NEW PERSPECTIVES NOI, P249
   Moore BCJ, 1999, J ACOUST SOC AM, V106, P2761, DOI 10.1121/1.428133
   Neff DL, 1996, J ACOUST SOC AM, V100, P2547, DOI 10.1121/1.417364
   Neumann J, 1997, J ACOUST SOC AM, V101, P2778, DOI 10.1121/1.419302
   Patterson R. D., FREQUENCY SELECTIVIT, P123
   Rammsayer TH, 2012, ARCH SEX BEHAV, V41, P583, DOI 10.1007/s10508-011-9880-8
   ROYSTER LH, 1980, J ACOUST SOC AM, V68, P551, DOI 10.1121/1.384769
   Russell A. F., 1992, THESIS
   Shahnaz N, 2008, INT J AUDIOL, V47, P76, DOI 10.1080/14992020701711029
   Shannon R. V., 1976, J ACOUST SOC AM, V88, P741
   Shargorodsky J, 2010, AM J MED, V123, P711, DOI 10.1016/j.amjmed.2010.02.015
   Snihur AWK, 2012, BEHAV NEUROSCI, V126, P325, DOI 10.1037/a0027193
   STRICKLAND EA, 1985, J ACOUST SOC AM, V78, P931, DOI 10.1121/1.392924
   SWANSON SJ, 1988, J SPEECH HEAR RES, V31, P569
   TALMADGE CL, 1993, HEARING RES, V71, P170, DOI 10.1016/0378-5955(93)90032-V
   VANROOIJ JCGM, 1990, J ACOUST SOC AM, V88, P2611, DOI 10.1121/1.399981
   Walsh KR, 2010, HEARING RES, V268, P22, DOI 10.1016/j.heares.2010.04.007
   WHITEHEAD ML, 1993, SCAND AUDIOL, V22, P3, DOI 10.3109/01050399309046012
   Wright B.A., 1994, J ACOUST SOC AM, V95, P2942
   Wright BA, 1996, J ACOUST SOC AM, V100, P1717, DOI 10.1121/1.416068
   Wright BA, 1996, J ACOUST SOC AM, V100, P3295, DOI 10.1121/1.417213
   Zundorf IC, 2011, CORTEX, V47, P741, DOI 10.1016/j.cortex.2010.08.002
   ZWICKER E, 1965, J ACOUST SOC AM, V37, P653, DOI 10.1121/1.1909389
NR 75
TC 4
Z9 4
U1 1
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD APR
PY 2018
VL 143
IS 4
BP 2338
EP 2354
DI 10.1121/1.5030998
PG 17
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GL4BK
UT WOS:000437090600006
PM 29716303
OA Green Published
DA 2021-02-24
ER

PT J
AU Serniclaes, W
   Seck, M
AF Serniclaes, Willy
   Seck, M'ballo
TI Enhanced Sensitivity to Subphonemic Segments in Dyslexia: A New Instance
   of Allophonic Perception
SO BRAIN SCIENCES
LA English
DT Article
DE dyslexia; allophonic theory; speech perception
ID SPEECH-PERCEPTION; CROSS-LANGUAGE; CHILDREN; RISK; SOUNDS; ADULTS; MODE
AB Although dyslexia can be individuated in many different ways, it has only three discernable sources: a visual deficit that affects the perception of letters, a phonological deficit that affects the perception of speech sounds, and an audio-visual deficit that disturbs the association of letters with speech sounds. However, the very nature of each of these core deficits remains debatable. The phonological deficit in dyslexia, which is generally attributed to a deficit of phonological awareness, might result from a specific mode of speech perception characterized by the use of allophonic (i.e., subphonemic) units. Here we will summarize the available evidence and present new data in support of the allophonic theory of dyslexia. Previous studies have shown that the dyslexia deficit in the categorical perception of phonemic features (e.g., the voicing contrast between /t/ and /d/) is due to the enhanced sensitivity to allophonic features (e.g., the difference between two variants of /d/). Another consequence of allophonic perception is that it should also give rise to an enhanced sensitivity to allophonic segments, such as those that take place within a consonant cluster. This latter prediction is validated by the data presented in this paper.
C1 [Serniclaes, Willy] CNRS, Speech Percept Lab, F-75006 Paris, France.
   [Serniclaes, Willy] Paris Descartes Univ, F-75006 Paris, France.
   [Seck, M'ballo] Paris 8 Univ, Human & Artificial Cognit Lab, F-93526 St Denis, France.
RP Serniclaes, W (corresponding author), CNRS, Speech Percept Lab, F-75006 Paris, France.; Serniclaes, W (corresponding author), Paris Descartes Univ, F-75006 Paris, France.
EM willy.serniclaes@gmail.com; m_ballo.seck04@univ-paris8.fr
FU French National Research Agency (ANR) as part of the "Investissements
   d'Avenir" programFrench National Research Agency (ANR)
   [ANR-10-LABX-0083]
FX This work was supported by a public grant overseen by the French
   National Research Agency (ANR) as part of the "Investissements d'Avenir"
   program (reference: ANR-10-LABX-0083), and covered the costs to publish
   in open access. Many thanks to Anne-Sophie Dalmas and Emmanuelle De
   Laubier who helped to access the children with dyslexia and to the
   "Saint-Merri/Renard" and "Chateau des Rentiers" schools who gave us
   access to the control children. Many thanks also to Cecile Houard and
   two anonymous reviewers for their contributions to this paper.
CR Blomert L, 2011, NEUROIMAGE, V57, P695, DOI 10.1016/j.neuroimage.2010.11.003
   Boersma P, PRAAT DOING PHONETIC
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Burnham D., 2003, READ WRIT, V16, P573, DOI DOI 10.1023/A:1025593911070
   Dufor O, 2009, NEUROIMAGE, V46, P241, DOI 10.1016/j.neuroimage.2009.01.035
   Fant G., 1973, SPEECH SOUNDS FEATUR
   Giraud AL, 2013, CURR OPIN NEUROBIOL, V23, P37, DOI 10.1016/j.conb.2012.09.003
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Hamalainen J, 2018, INT J BEHAV DEV, V42, P357, DOI 10.1177/0165025417728582
   Hoonhorst I, 2011, SPEECH COMMUN, V53, P417, DOI 10.1016/j.specom.2010.11.005
   Hoonhorst I, 2009, J EXP CHILD PSYCHOL, V104, P353, DOI 10.1016/j.jecp.2009.07.005
   JONES MR, 1976, PSYCHOL REV, V83, P323, DOI 10.1037/0033-295X.83.5.323
   Landerl K, 1997, COGNITION, V63, P315, DOI 10.1016/S0010-0277(97)00005-X
   Lefavrais P, 1965, TEST DE LALOUETTE
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LIBERMAN IY, 1974, J EXP CHILD PSYCHOL, V18, P201, DOI 10.1016/0022-0965(74)90101-5
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Medina V, 2010, J PHONETICS, V38, P493, DOI 10.1016/j.wocn.2010.06.002
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   MORAIS J, 1986, COGNITION, V24, P45, DOI 10.1016/0010-0277(86)90004-1
   Noordenbos MW, 2012, NEUROPSYCHOLOGIA, V50, P2010, DOI 10.1016/j.neuropsychologia.2012.04.026
   Noordenbos MW, 2012, RES DEV DISABIL, V33, P1469, DOI 10.1016/j.ridd.2012.03.021
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Noordenbos MW, 2013, CLIN NEUROPHYSIOL, V124, P1151, DOI 10.1016/j.clinph.2012.12.044
   Schmidt R., 2012, P CLASIC 2010 SING 2, P721
   Serniclaes W, 2005, COGNITION, V98, pB35, DOI 10.1016/j.cognition.2005.03.002
   Serniclaes W., 2011, COGNITIVE PHYS DEV B, P237
   Serniclaes W, 2015, HDB COMMUNICATION DI, P34, DOI DOI 10.1080/23273798.2014.1002796
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Trask R.L., 1996, DICT PHONETICS PHONO
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
   Zoubrinetzky R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151015
NR 37
TC 3
Z9 3
U1 1
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD APR
PY 2018
VL 8
IS 4
AR 54
DI 10.3390/brainsci8040054
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA GJ3GG
UT WOS:000435178600006
PM 29587419
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Paavilainen, P
   Kaukinen, C
   Koskinen, O
   Kylmala, J
   Rehn, L
AF Paavilainen, Petri
   Kaukinen, Crista
   Koskinen, Oskari
   Kylmala, Julia
   Rehn, Leila
TI Mismatch negativity (MMN) elicited by abstract regularity violations in
   two concurrent auditory streams
SO HELIYON
LA English
DT Article
DE Neuroscience; Psychology
ID HUMAN BRAIN; SEGREGATION; ATTENTION; ORGANIZATION; FEATURES; SOUNDS
AB The study investigated whether violations of abstract regularities in two parallel auditory stimulus streams can elicit the MMN (mismatch negativity) event-related potential. Tone pairs from a low (220-392 Hz) and a high (1319-2349 Hz) stream were delivered in an alternating order either at a fast or a slow pace. With the slow pace, the pairs were perceptually heard as a single stream obeying an alternating low pair-high pair pattern, whereas with the fast pace, an experience of two separate auditory streams, low and high, emerged. Both streams contained standard and deviant pairs. The standard pairs were either in both streams ascending in the direction of the within-pair pitch change or in the one stream ascending and in the other stream descending. The direction of the deviant pairs was opposite to that of the same-stream standard pairs. The participant's task was either to ignore the auditory stimuli or to detect the deviant pairs in the designated stream. The deviant pairs elicited an MMN both when the directions of the standard pairs in the two streams were the same or when they were opposite. The MMN was present irrespective of the pace of stimulation. The results indicate that the preattentive brain mechanisms, reflected by the MMN, can extract abstract regularities from two concurrent streams even when the regularities are opposite in the two streams, and independently of whether there perceptually exists only one stimulus stream or two segregated streams. These results demonstrate the brain's remarkable ability to model various regularities embedded in the auditory environment and update the models when the regularities are violated. The observed phenomena can be related to several aspects of auditory information processing, e.g., music and speech perception and different forms of attention.
C1 [Paavilainen, Petri; Kaukinen, Crista; Koskinen, Oskari; Rehn, Leila] Univ Helsinki, Dept Psychol & Logoped, FIN-00014 Helsinki, Finland.
   [Paavilainen, Petri] Univ Helsinki, Cognit Brain Res Unit, FIN-00014 Helsinki, Finland.
   [Kylmala, Julia] Univ Helsinki, Cognit Sci, FIN-00014 Helsinki, Finland.
RP Paavilainen, P (corresponding author), Univ Helsinki, Dept Psychol & Logoped, FIN-00014 Helsinki, Finland.; Paavilainen, P (corresponding author), Univ Helsinki, Cognit Brain Res Unit, FIN-00014 Helsinki, Finland.
EM petri.paavilainen@helsinki.fi
OI Kaukinen, Crista/0000-0003-2954-0249
CR Carlyon RP, 2004, TRENDS COGN SCI, V8, P465, DOI 10.1016/j.tics.2004.08.008
   Ciocca V, 2008, FRONT BIOSCI-LANDMRK, V13, P148, DOI 10.2741/2666
   Darwin CJ, 1997, TRENDS COGN SCI, V1, P327, DOI 10.1016/S1364-6613(97)01097-8
   Escera C, 2007, J PSYCHOPHYSIOL, V21, P251, DOI 10.1027/0269-8803.21.34.251
   Hiscock M, 2011, BRAIN COGNITION, V76, P263, DOI 10.1016/j.bandc.2011.03.016
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1993, PSYCHOPHYSIOLOGY, V30, P436, DOI 10.1111/j.1469-8986.1993.tb02067.x
   Paavilainen P, 1999, NEUROSCI LETT, V265, P179, DOI 10.1016/S0304-3940(99)00237-2
   Paavilainen P, 1998, PSYCHOPHYSIOLOGY, V35, P483, DOI 10.1017/S0048577298970895
   Paavilainen P, 2001, PSYCHOPHYSIOLOGY, V38, P359, DOI 10.1111/1469-8986.3820359
   PAAVILAINEN P, 1995, J PSYCHOPHYSIOL, V9, P243
   Paavilainen P, 2007, NEUROREPORT, V18, P159, DOI 10.1097/WNR.0b013e328010e2ac
   Paavilainen P, 2013, INT J PSYCHOPHYSIOL, V88, P109, DOI 10.1016/j.ijpsycho.2013.03.015
   SAARINEN J, 1992, NEUROREPORT, V3, P1149, DOI 10.1097/00001756-199212000-00030
   Schroger E, 2014, BRAIN TOPOGR, V27, P565, DOI 10.1007/s10548-013-0334-6
   Shamma SA, 2010, CURR OPIN NEUROBIOL, V20, P361, DOI 10.1016/j.conb.2010.03.009
   Shinozaki N, 2000, NEUROREPORT, V11, P1597, DOI 10.1097/00001756-200006050-00001
   Snyder JS, 2007, PSYCHOL BULL, V133, P780, DOI 10.1037/0033-2909.133.5.780
   Sussman E, 1998, BRAIN RES, V789, P130, DOI 10.1016/S0006-8993(97)01443-1
   Sussman E, 1999, PSYCHOPHYSIOLOGY, V36, P22, DOI 10.1017/S0048577299971056
   Sussman E, 2001, HEARING RES, V153, P108, DOI 10.1016/S0378-5955(00)00261-6
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Winkler I, 2012, PHILOS T R SOC B, V367, P1001, DOI 10.1098/rstb.2011.0359
   WOLDORFF MG, 1991, PSYCHOPHYSIOLOGY, V28, P30, DOI 10.1111/j.1469-8986.1991.tb03384.x
   Yabe H, 2001, BRAIN RES, V897, P222, DOI 10.1016/S0006-8993(01)02224-7
NR 25
TC 2
Z9 2
U1 0
U2 0
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 2405-8440
J9 HELIYON
JI Heliyon
PD APR
PY 2018
VL 4
IS 4
AR e00608
DI 10.1016/j.heliyon.2018.e00608
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GF5VR
UT WOS:000432036400009
PM 29862369
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Tan, AY
   Berg, BG
AF Tan, Alison Y.
   Berg, Bruce G.
TI Level dominance effect and selective attention in a dichotic sample
   discrimination task
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID COMPLEX SOUND; EAR ADVANTAGE; HEMISPHERIC-SPECIALIZATION;
   SPEECH-PERCEPTION; LATERALITY; CHILDREN; LOCALIZATION; LOUDNESS;
   WEIGHTS; TIMBRE
AB Differences in individual listening patterns are reported for a dichotic sample discrimination task. Seven tones were drawn from normal distributions with means of 1000 or 1100 Hz on each trial. Even-numbered tones (2, 4, and 6) and odd-numbered tones (1, 3, 5, and 7) were drawn, respectively, from distributions with a 50-Hz and 200-Hz standard deviation. Task difficulty was manipulated by presenting odd and even tones at different intensities. In easy conditions, high and low informative tones were presented at 70 dB and 50 dB, respectively. In difficult conditions, high informative and low informative tones were presented at 50 dB and 70 dB, respectively. Participants judged whether the sample was from high-or low-mean distribution. Decision weights, efficiency, and sensitivity showed a range of abilities to attend to high informative tones, with d' from 2.4-0.7. Most listeners showed a left-ear advantage, while no listeners showed a right ear advantage. Some listeners, but not all, showed no loudness dominance effect with the ability to selectively attend to quiet tones in difficult conditions. These findings show that the influence of an attentional strategy in dichotic listening can overcome the loudness dominance effect for some listeners. (C) 2018 Acoustical Society of America.
C1 [Tan, Alison Y.; Berg, Bruce G.] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92697 USA.
RP Tan, AY (corresponding author), Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92697 USA.
EM alisontan@usf.edu
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [2 R01 DC001262-24]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC001262, R01DC001262, R01DC001262] Funding Source: NIH
   RePORTER
FX We would like to thank Dr. Michael Lee for his feedback using the
   Bayesian approach. We would also like to thank Dr. Robert Lutfi, Dr.
   Justin Mark, Dr. Allison Shim, and two anonymous reviewers for their
   overall comments to earlier revisions of the manuscript. Work was
   supported in part by the NIDCD 2 R01 DC001262-24.
CR AHONNISKA J, 1993, BRAIN LANG, V45, P127, DOI 10.1006/brln.1993.1039
   ASBJORNSEN AE, 1995, BRAIN LANG, V49, P189, DOI 10.1006/brln.1995.1029
   BERG BG, 1989, J ACOUST SOC AM, V86, P1743, DOI 10.1121/1.398605
   BERG BG, 1990, J ACOUST SOC AM, V88, P149, DOI 10.1121/1.399962
   Berman SM, 2003, NEUROIMAGE, V19, P319, DOI 10.1016/S1053-8119(03)00120-4
   Boucher R, 1997, NEUROPSYCHOLOGIA, V35, P1467, DOI 10.1016/S0028-3932(97)00066-3
   Brancucci A, 1999, NEUROPSYCHOLOGIA, V37, P1445, DOI 10.1016/S0028-3932(99)00065-2
   BROADBENT DE, 1954, J EXP PSYCHOL, V47, P191, DOI 10.1037/h0054182
   BRYDEN MP, 1983, BRAIN LANG, V18, P236, DOI 10.1016/0093-934X(83)90018-4
   BRYDEN MP, 1970, NEUROPSYCHOLOGIA, V8, P443, DOI 10.1016/0028-3932(70)90040-0
   D'Anselmo A, 2016, HEARING RES, V342, P144, DOI 10.1016/j.heares.2016.10.012
   Dittrich K, 2009, J ACOUST SOC AM, V126, P3168, DOI 10.1121/1.3238233
   EFRON R, 1974, NEUROPSYCHOLOGIA, V12, P249, DOI 10.1016/0028-3932(74)90010-4
   Hiscock M, 1999, NEUROPSYCHOLOGY, V13, P404, DOI 10.1037/0894-4105.13.3.404
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   KIMURA D, 1961, CAN J PSYCHOLOGY, V15, P166, DOI 10.1037/h0083219
   LUTFI RA, 1989, J ACOUST SOC AM, V86, P934, DOI 10.1121/1.398728
   LUTFI RA, 1990, J ACOUST SOC AM, V87, P2141, DOI 10.1121/1.399182
   LUTFI RA, 1992, J ACOUST SOC AM, V91, P3391, DOI 10.1121/1.402829
   LUTFI RA, 1990, J ACOUST SOC AM, V88, P2607, DOI 10.1121/1.399980
   Lutfi RA, 2006, J ACOUST SOC AM, V120, P3853, DOI 10.1121/1.2361184
   Lutfi RA, 2008, J ACOUST SOC AM, V124, P3784, DOI 10.1121/1.2998767
   Moncrieff DW, 2011, BRAIN COGNITION, V76, P316, DOI 10.1016/j.bandc.2011.03.013
   Morey RD, 2016, PSYCHON B REV, V23, P103, DOI 10.3758/s13423-015-0947-8
   MORTON LL, 1991, BRAIN LANG, V40, P162, DOI 10.1016/0093-934X(91)90123-I
   Oberfeld D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050184
   Oberfeld D, 2011, ATTEN PERCEPT PSYCHO, V73, P189, DOI 10.3758/s13414-010-0011-8
   Pedersen B, 2008, J ACOUST SOC AM, V123, P963, DOI 10.1121/1.2822883
   Richards VM, 2013, J ACOUST SOC AM, V134, pEL237, DOI 10.1121/1.4813591
   STUDDERTKENNEDY M, 1970, J ACOUST SOC AM, V48, P579, DOI 10.1121/1.1912174
   Turner MD, 2007, J ACOUST SOC AM, V121, P1848, DOI 10.1121/1.2710345
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
NR 32
TC 0
Z9 0
U1 1
U2 5
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD APR
PY 2018
VL 143
IS 4
BP 2119
EP 2127
DI 10.1121/1.5030919
PG 9
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GD5TZ
UT WOS:000430570900020
PM 29716301
OA Green Published
DA 2021-02-24
ER

PT J
AU Righi, G
   Tenenbaum, EJ
   McCormick, C
   Blossom, M
   Amso, D
   Sheinkopf, SJ
AF Righi, Giulia
   Tenenbaum, Elena J.
   McCormick, Carolyn
   Blossom, Megan
   Amso, Dima
   Sheinkopf, Stephen J.
TI Sensitivity to audio-visual synchrony and its relation to language
   abilities in children with and without ASD
SO AUTISM RESEARCH
LA English
DT Article
DE autism; audio-visual synchrony; eye-tracking; language development
ID AUTISM SPECTRUM DISORDERS; SPEECH-PERCEPTION; INFANTS; PATTERNS; FACE;
   SPEAKING; HEAR
AB Autism Spectrum Disorder (ASD) is often accompanied by deficits in speech and language processing. Speech processing relies heavily on the integration of auditory and visual information, and it has been suggested that the ability to detect correspondence between auditory and visual signals helps to lay the foundation for successful language development. The goal of the present study was to examine whether young children with ASD show reduced sensitivity to temporal asynchronies in a speech processing task when compared to typically developing controls, and to examine how this sensitivity might relate to language proficiency. Using automated eye tracking methods, we found that children with ASD failed to demonstrate sensitivity to asynchronies of 0.3s, 0.6s, or 1.0s between a video of a woman speaking and the corresponding audio track. In contrast, typically developing children who were language-matched to the ASD group, were sensitive to both 0.6s and 1.0s asynchronies. We also demonstrated that individual differences in sensitivity to audiovisual asynchronies and individual differences in orientation to relevant facial features were both correlated with scores on a standardized measure of language abilities. Results are discussed in the context of attention to visual language and audio-visual processing as potential precursors to language impairment in ASD. Autism Res2018, 11: 645-653. (c) 2018 International Society for Autism Research, Wiley Periodicals, Inc.
   Lay SummarySpeech processing relies heavily on the integration of auditory and visual information, and it has been suggested that the ability to detect correspondence between auditory and visual signals helps to lay the foundation for successful language development. The goal of the present study was to explore whether children with ASD process audio-visual synchrony in ways comparable to their typically developing peers, and the relationship between preference for synchrony and language ability. Results showed that there are differences in attention to audiovisual synchrony between typically developing children and children with ASD. Preference for synchrony was related to the language abilities of children across groups.
C1 [Righi, Giulia; Tenenbaum, Elena J.; McCormick, Carolyn; Sheinkopf, Stephen J.] Brown Univ, Dept Psychiat & Human Behav, Warren Alpert Med Sch, Providence, RI 02912 USA.
   [Righi, Giulia] Bradley Hosp, Providence, RI USA.
   [Tenenbaum, Elena J.; McCormick, Carolyn; Sheinkopf, Stephen J.] Brown Univ, Women & Infants Hosp, Brown Ctr Study Children Risk, Providence, RI USA.
   [Amso, Dima] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
   [Sheinkopf, Stephen J.] Women & Infants Hosp Rhode Isl, Dept Pediat, Providence, RI USA.
   [McCormick, Carolyn] Purdue Univ, W Lafayette, IN 47907 USA.
   [Blossom, Megan] Castleton Univ, Dept Psychol, Castleton, VT USA.
   [Righi, Giulia; Tenenbaum, Elena J.; McCormick, Carolyn; Sheinkopf, Stephen J.] Rhode Isl Consortium Autism Res & Treatment, East Providence, RI USA.
RP Righi, G (corresponding author), Emma Pendleton Bradley Hosp, 1011 Vet Mem Pkwy, East Providence, RI 02915 USA.
EM giulia.righi@lifespan.org
RI Sheinkopf, Stephen/AAD-9780-2020
OI Sheinkopf, Stephen/0000-0003-3836-4339
FU Autism Science Foundation [11-1013]; Autism Speaks [7897]; NIMHUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of Mental Health (NIMH) [T-32
   5T32MH019927-24]; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Mental Health (NIMH) [T32MH019927,
   T32MH019927, T32MH019927, T32MH019927, T32MH019927] Funding Source: NIH
   RePORTER
FX This research was supported by grants from the Autism Science Foundation
   (11-1013) and Autism Speaks (7897), NIMH T-32 5T32MH019927-24.
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Bahrick L.E., 2012, MULTISENSORY DEV, P183, DOI DOI 10.1093/ACPROF:OSO/9780199586059.003.0008
   Bayley N., 2005, BAYLEY SCALES INFANT
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Chawarska K, 2012, J CHILD PSYCHOL PSYC, V53, P903, DOI 10.1111/j.1469-7610.2012.02538.x
   DiLavore P. C., 2012, AUTISM DIAGNOSTIC OB
   Eigsti IM, 2011, RES AUTISM SPECT DIS, V5, P681, DOI 10.1016/j.rasd.2010.09.001
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   Foster ME, 2007, LANG RESOUR EVAL, V41, P305, DOI 10.1007/s10579-007-9055-3
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   Graf HP, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P396, DOI 10.1109/AFGR.2002.1004186
   Grossman RB, 2015, AUTISM RES, V8, P307, DOI 10.1002/aur.1447
   Guiraud JA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036428
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Johnels JA, 2014, J SPEECH LANG HEAR R, V57, P2246, DOI 10.1044/2014_JSLHR-L-13-0268
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   KUHL PK, 1984, INFANT BEHAV DEV, V7, P361, DOI 10.1016/S0163-6383(84)80050-8
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Norbury CF, 2009, J CHILD PSYCHOL PSYC, V50, P834, DOI 10.1111/j.1469-7610.2009.02073.x
   Patten Elena, 2014, Autism Res Treat, V2014, P678346, DOI 10.1155/2014/678346
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Roid GH, 2003, STANFORD BINET INTEL
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Shic F, 2014, BIOL PSYCHIAT, V75, P231, DOI 10.1016/j.biopsych.2013.07.009
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stevenson RA, 2018, AUTISM, V22, P609, DOI 10.1177/1362361317704413
   Stevenson RA, 2017, AUTISM RES, V10, P1280, DOI 10.1002/aur.1776
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
   Zimmerman I. L., 2011, PRESCHOOL LANGUAGE S
NR 33
TC 13
Z9 13
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-3792
EI 1939-3806
J9 AUTISM RES
JI Autism Res.
PD APR
PY 2018
VL 11
IS 4
BP 645
EP 653
DI 10.1002/aur.1918
PG 9
WC Behavioral Sciences; Psychology, Developmental
SC Behavioral Sciences; Psychology
GA GD0CN
UT WOS:000430167100007
PM 29331093
DA 2021-02-24
ER

PT J
AU Hennequin, A
   Rochet-Capellan, A
   Gerber, S
   Dohen, M
AF Hennequin, Alexandre
   Rochet-Capellan, Amelie
   Gerber, Silvain
   Dohen, Marion
TI Does the Visual Channel Improve the Perception of Consonants Produced by
   Speakers of French With Down Syndrome?
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; AUDIOVISUAL IDENTIFICATION; VISIBLE SPEECH;
   NORMAL-HEARING; YOUNG-PEOPLE; CHILDREN; INTELLIGIBILITY; INFORMATION;
   INTEGRATION; PREVALENCE
AB Purpose: This work evaluates whether seeing the speaker's face could improve the speech intelligibility of adults with Down syndrome (DS). This is not straightforward because DS induces a number of anatomical and motor anomalies affecting the orofacial zone.
   Method: A speech-in-noise perception test was used to evaluate the intelligibility of 16 consonants (Cs) produced in a vowel-consonant-vowel context (Vo = /a/) by 4 speakers with DS and 4 control speakers. Forty-eight naive participants were asked to identify the stimuli in 3 modalities: auditory (A), visual (V), and auditory-visual (AV). The probability of correct responses was analyzed, as well as AV gain, confusions, and transmitted information as a function of modality and phonetic features.
   Results: The probability of correct response follows the trend AV > A > V, with smaller values for the DS than the control speakers in A and AV but not in V. This trend depended on the C: the V information particularly improved the transmission of place of articulation and to a lesser extent of manner, whereas voicing remained specifically altered in DS.
   Conclusions: The results suggest that the V information is intact in the speech of people with DS and improves the perception of some phonetic features in Cs in a similar way as for control speakers. This result has implications for further studies, rehabilitation protocols, and specific training of caregivers.
C1 [Hennequin, Alexandre; Rochet-Capellan, Amelie; Gerber, Silvain; Dohen, Marion] Univ Grenoble Alpes, CNRS, Grenoble INP, GIPSA Lab, F-38000 Grenoble, France.
RP Dohen, M (corresponding author), Univ Grenoble Alpes, CNRS, Grenoble INP, GIPSA Lab, F-38000 Grenoble, France.
EM marion.dohen@gipsa-lab.grenoble-inp.fr
FU European Research Council under the European CommunityEuropean Research
   Council (ERC) [339152]; FIRAH foundation (International Foundation of
   Applied Disability Research)
FX This research has received funding from the European Research Council
   under the European Community's Seventh Framework Programme
   (FP7/2007-2013 Grant Agreement no. 339152 "Speech Unit(e)s," awarded to
   PI Jean-Luc Schwartz) and from the FIRAH foundation (International
   Foundation of Applied Disability Research) awarded to PIs Marion Dohen
   and Amelie Rochet-Capellan. It was approved by the Comite d'Ethique pour
   les Recherches Non Interventionnelles ethics committee of Grenoble Alpes
   University (IRB00010290 COMUE Grenoble Alpes University IRB#1 - approval
   number: 2014-03-11-41) and by the ethical committee of the FIRAH. The
   authors thank the Association pour la Recherche et l'Insertion Sociale
   des Trisomiques (Down Syndrome Research and Social Integration
   Association), the Etablissement et Service d'Aide par le TravailService
   d'Activite de Jour (Institution and Service through Work-Day Activity
   Service), and the speakers who participated in this study and their
   families.
CR Alm M, 2009, J ACOUST SOC AM, V126, P377, DOI 10.1121/1.3129508
   Andrade PA, 2014, J VOICE, V28, P589, DOI 10.1016/j.jvoice.2013.11.004
   Arumugam A, 2016, CLIN ANAT, V29, P568, DOI 10.1002/ca.22672
   Autorite deSante Haute, 2015, LES PERFORMANCES DES
   Barnes E, 2009, J SPEECH LANG HEAR R, V52, P1048, DOI 10.1044/1092-4388(2009/08-0001)
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   BINNIE CA, 1974, J SPEECH HEAR RES, V17, P619, DOI 10.1044/jshr.1704.619
   Bittles AH, 2007, EUR J PUBLIC HEALTH, V17, P221, DOI 10.1093/eurpub/ckl103
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Borghi R. W., 1990, CLIN PERSPECTIVES MA, P147, DOI DOI 10.1007/978-1-4613-9644-4_12
   Borrie SA, 2015, J ACOUST SOC AM, V137, P1473, DOI 10.1121/1.4913770
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Bunton K., 2007, SYNDROME RES PRACTIC, V12, P1, DOI DOI 10.3104/REPORTS.2027
   Bunton K, 2011, CLIN LINGUIST PHONET, V25, P321, DOI 10.3109/02699206.2010.535647
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Carlyon RP, 2001, J EXP PSYCHOL HUMAN, V27, P115, DOI 10.1037/0096-1523.27.1.115
   Chapman R S, 2001, Downs Syndr Res Pract, V7, P1, DOI 10.3104/reviews.108
   Cleland J, 2015, CLIN LINGUIST PHONET, V29, P575, DOI 10.3109/02699206.2015.1016188
   Cleland J, 2010, INT J LANG COMM DIS, V45, P83, DOI 10.3109/13682820902745453
   Connaghan KP, 2013, J SPEECH LANG HEAR R, V56, P123, DOI 10.1044/1092-4388(2012/11-0161)
   CROSLEY PA, 1989, J COMMUN DISORD, V22, P151, DOI 10.1016/0021-9924(89)90013-0
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   Files BT, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00878
   Fournier DA, 2012, OPTIM METHOD SOFTW, V27, P233, DOI 10.1080/10556788.2011.597854
   Grant KW, 2007, J ACOUST SOC AM, V121, P1164, DOI 10.1121/1.2405859
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Guimaraes CVA, 2008, PEDIATR RADIOL, V38, P1062, DOI 10.1007/s00247-008-0941-7
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Hustad KC, 2007, CLIN LINGUIST PHONET, V21, P353, DOI 10.1080/02699200701259150
   Hustad KC, 2003, AM J SPEECH-LANG PAT, V12, P198, DOI 10.1044/1058-0360(2003/066)
   Katz G, 2008, SALUD PUBLICA MEXICO, V50, pS132
   Keintz CK, 2007, AM J SPEECH-LANG PAT, V16, P222, DOI 10.1044/1058-0360(2007/027)
   Kent RD, 2013, J SPEECH LANG HEAR R, V56, P178, DOI 10.1044/1092-4388(2012/12-0148)
   Kumin L., 2012, EARLY COMMUNICATION
   Kumin Libby, 2006, Downs Syndr Res Pract, V10, P10, DOI 10.3104/reports.301
   Latash M., 2008, DOWNS SYNDROME RES P, DOI [10.3104/reviews.2074, DOI 10.3104/REVIEWS.2074]
   Loane M, 2013, EUR J HUM GENET, V21, P27, DOI 10.1038/ejhg.2012.94
   Macho V., 2014, British Journal of Medicine and Medical Research, V4, P5604, DOI 10.9734/BJMMR/2014/12688
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   Massaro DW, 2004, J SPEECH LANG HEAR R, V47, P304, DOI 10.1044/1092-4388(2004/025)
   Menard L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160088
   Meyer C, 2017, INT J SPEECH-LANG PA, V19, P87, DOI 10.1080/17549507.2016.1221454
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Moura CP, 2008, J VOICE, V22, P34, DOI 10.1016/j.jvoice.2006.08.011
   New B, 2001, ANN PSYCHOL, V101, P447
   Parker SE, 2010, BIRTH DEFECTS RES A, V88, P1008, DOI 10.1002/bdra.20735
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Phatak SA, 2008, J ACOUST SOC AM, V124, P1220, DOI 10.1121/1.2913251
   R Core Team, 2017, R LANGUAGE ENV STAT
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Rosin M. M., 1988, J CHILDHOOD COMMUNIC, V12, P49, DOI DOI 10.1177/152574018801200105
   Rupela V, 2016, INT J SPEECH-LANG PA, V18, P483, DOI 10.3109/17549507.2015.1112836
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   SMITH BL, 1983, J SPEECH HEAR DISORD, V48, P114, DOI 10.1044/jshd.4802.114
   Smithson M, 2006, PSYCHOL METHODS, V11, P54, DOI 10.1037/1082-989X.11.1.54
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Sommers R. K., 1988, J CHILDHOOD COMMUNIC, V12, P65, DOI DOI 10.1177/152574018801200106
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Summerfield Q., 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237
   Timmins C, 2011, CLIN LINGUIST PHONET, V25, P1022, DOI 10.3109/02699206.2011.616981
   Timmins C, 2009, CLIN LINGUIST PHONET, V23, P911, DOI 10.3109/02699200903141271
   Togram B, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/707134
   Xue SA, 2010, INT J PEDIATR OTORHI, V74, P378, DOI 10.1016/j.ijporl.2010.01.007
   Zeiliger J., 1994, ACTES XEMES JEP, P287
NR 67
TC 0
Z9 0
U1 0
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD APR
PY 2018
VL 61
IS 4
BP 957
EP 972
DI 10.1044/2017_JSLHR-H-17-0112
PG 16
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GD4BL
UT WOS:000430447400014
PM 29635399
DA 2021-02-24
ER

PT J
AU White, PA
AF White, Peter A.
TI Is conscious perception a series of discrete temporal frames?
SO CONSCIOUSNESS AND COGNITION
LA English
DT Article
DE Conscious perception; Discrete frames; Psychological moment; EEG
   waveforms; Temporal integration
ID EEG ALPHA OSCILLATIONS; ILLUSORY MOTION REVERSAL; GAP-DETECTION
   THRESHOLDS; WAGON WHEEL ILLUSION; EXCITABILITY CYCLES; VISIBLE
   PERSISTENCE; ATTENTIONAL BLINK; SPEECH-PERCEPTION; BAND OSCILLATIONS;
   TIME PERCEPTION
AB This paper reviews proposals that conscious perception consists, in whole or part, of successive discrete temporal frames on the sub-second time scale, each frame containing information registered as simultaneous or static. Although the idea of discrete frames in conscious perception cannot be regarded as falsified, there are many problems. Evidence does not consistently support any proposed duration or range of durations for frames. EEG waveforms provide evidence of periodicity in brain activity, but not necessarily in conscious perception. Temporal properties of perceptual processes are flexible in response to competing processing demands, which is hard to reconcile with the relative inflexibility of regular frames. There are also problems concerning the definition of frames, the need for informational connections between frames, the means by which boundaries between frames are established, and the apparent requirement for a storage buffer for information awaiting entry to the next frame.
C1 [White, Peter A.] Cardiff Univ, Sch Psychol, Tower Bldg,Pk Pl, Cardiff CF10 3YG, S Glam, Wales.
RP White, PA (corresponding author), Cardiff Univ, Sch Psychol, Tower Bldg,Pk Pl, Cardiff CF10 3YG, S Glam, Wales.
EM whitepa@cardiff.ac.uk
CR AIBA TS, 1964, VISION RES, V4, P391, DOI 10.1016/0042-6989(64)90011-2
   Ansbacher HL, 1944, J EXP PSYCHOL, V34, P1, DOI 10.1037/h0061686
   AXELROD S, 1968, J GERONTOL, V23, P191, DOI 10.1093/geronj/23.2.191
   Babkoff H, 2013, ATTEN PERCEPT PSYCHO, V75, P654, DOI 10.3758/s13414-013-0449-6
   Baumgarten TJ, 2015, P NATL ACAD SCI USA, V112, P12187, DOI 10.1073/pnas.1501438112
   Bazanova OM, 2014, NEUROSCI BIOBEHAV R, V44, P94, DOI 10.1016/j.neubiorev.2013.05.007
   BECHTEREVA NP, 1962, ELECTROEN CLIN NEURO, V14, P320, DOI 10.1016/0013-4694(62)90109-8
   BENDER MB, 1968, BRAIN, V91, P321, DOI 10.1093/brain/91.2.321
   BERTELSON P, 1966, Q J EXP PSYCHOL, V18, P153, DOI 10.1080/14640746608400022
   Bishop GH, 1933, AM J PHYSIOL, V103, P213
   Blais C, 2013, COGNITION, V128, P353, DOI 10.1016/j.cognition.2013.04.009
   Blakemore SJ, 2003, CONSCIOUS COGN, V12, P647, DOI 10.1016/j.concog.2003.07.001
   Blakemore SJ, 2002, TRENDS COGN SCI, V6, P237, DOI 10.1016/S1364-6613(02)01907-1
   BRECHER GERHARD A., 1932, ZEITSCHR VERGLEICH PHYSIOL, V18, P204
   BROADBENT DE, 1987, PERCEPT PSYCHOPHYS, V42, P105, DOI 10.3758/BF03210498
   Buonomano DV, 2009, PHILOS T R SOC B, V364, P1865, DOI 10.1098/rstb.2009.0019
   Burr D, 2011, VISION RES, V51, P1431, DOI 10.1016/j.visres.2011.02.008
   Burr DC, 2001, VISION RES, V41, P1891, DOI 10.1016/S0042-6989(01)00072-4
   Busch NA, 2010, P NATL ACAD SCI USA, V107, P16048, DOI 10.1073/pnas.1004801107
   Busch NA, 2009, J NEUROSCI, V29, P7869, DOI 10.1523/JNEUROSCI.0113-09.2009
   CALLAWAY E, 1964, ANN NY ACAD SCI, V112, P421, DOI 10.1111/j.1749-6632.1964.tb26762.x
   Carmel D, 2007, J VISION, V7, DOI 10.1167/7.14.14
   CARR CE, 1993, ANNU REV NEUROSCI, V16, P223, DOI 10.1146/annurev.ne.16.030193.001255
   Cecere R, 2015, CURR BIOL, V25, P231, DOI 10.1016/j.cub.2014.11.034
   Chait M, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00214
   Chakravarthi R, 2012, P NATL ACAD SCI USA, V109, P10599, DOI 10.1073/pnas.1121622109
   CLAY ER, 1882, ALTERNATIVE STUDY PS
   COLTHEART M, 1980, PERCEPT PSYCHOPHYS, V27, P183, DOI 10.3758/BF03204258
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   Craig AD, 2009, PHILOS T R SOC B, V364, P1933, DOI 10.1098/rstb.2009.0008
   Craig AD, 2009, NAT REV NEUROSCI, V10, P59, DOI 10.1038/nrn2555
   Craik KJW, 1947, B J PSYCHOL-GEN SECT, V38, P56, DOI 10.1111/j.2044-8295.1947.tb01141.x
   Crick F, 2003, NAT NEUROSCI, V6, P119, DOI 10.1038/nn0203-119
   Curran S, 1998, HUM PSYCHOPHARM CLIN, V13, P337, DOI 10.1002/(SICI)1099-1077(199807)13:5<337::AID-HUP7>3.3.CO;2-G
   Deary IJ, 2004, NEUROIMAGE, V22, P1466, DOI 10.1016/j.neuroimage.2004.03.047
   DEHAENE S, 1993, PSYCHOL SCI, V4, P264, DOI 10.1111/j.1467-9280.1993.tb00273.x
   Diederich A, 2015, PSYCHOL REV, V122, P232, DOI 10.1037/a0038696
   DILOLLO V, 1977, NATURE, V267, P241, DOI 10.1038/267241a0
   DILOLLO V, 1980, J EXP PSYCHOL GEN, V109, P75, DOI 10.1037/0096-3445.109.1.75
   DILOLLO V, 1978, VISION RES, V18, P1607, DOI 10.1016/0042-6989(78)90251-1
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   DIXON P, 1994, COGNITIVE PSYCHOL, V26, P33, DOI 10.1006/cogp.1994.1002
   Doesburg SM, 2008, CEREB CORTEX, V18, P386, DOI 10.1093/cercor/bhm073
   Drewes J, 2011, J NEUROSCI, V31, P4698, DOI 10.1523/JNEUROSCI.4795-10.2011
   Dubois J, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001056
   Durgin FH, 2002, CONSCIOUS COGN, V11, P284, DOI 10.1006/ccog.2002.0566
   DURGIN FH, 1995, PERCEPTION, V24, P827, DOI 10.1068/p240827
   Dux PE, 2009, ATTEN PERCEPT PSYCHO, V71, P1683, DOI 10.3758/APP.71.8.1683
   EFRON R, 1970, NEUROPSYCHOLOGIA, V8, P37, DOI 10.1016/0028-3932(70)90024-2
   EFRON R, 1970, NEUROPSYCHOLOGIA, V8, P57, DOI 10.1016/0028-3932(70)90025-4
   EFRON R, 1971, AM J PSYCHOL, V84, P365, DOI 10.2307/1420468
   Elhilali M, 2009, NEURON, V61, P317, DOI 10.1016/j.neuron.2008.12.005
   ELLINGSON RJ, 1956, PSYCHOL BULL, V53, P1, DOI 10.1037/h0042562
   Elliott MA, 2007, PSYCHOL RES-PSYCH FO, V71, P687, DOI 10.1007/s00426-006-0057-3
   Elliott MA, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00332
   Elliott MA, 2016, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2075.07905, 10.3389/fpsyg.2015.01905]
   ERIKSEN CW, 1967, J EXP PSYCHOL, V74, P476, DOI 10.1037/h0024765
   Fairhall SL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102248
   FARRELL JE, 1984, J EXP PSYCHOL HUMAN, V10, P502, DOI 10.1037/0096-1523.10.4.502
   Fink M, 2006, BEHAV PROCESS, V71, P344, DOI 10.1016/j.beproc.2005.12.007
   Fiorani Jr M, 2003, FILLING IN PERCEPTUA, P177
   Fostick L, 2011, AUDIOL RES, V1, P16, DOI 10.4081/audiores.2011.e5
   Fostick L, 2013, EXP PSYCHOL, V60, P432, DOI 10.1027/1618-3169/a000216
   Fourneret P, 1998, NEUROPSYCHOLOGIA, V36, P1133, DOI 10.1016/S0028-3932(98)00006-2
   Freeman WJ, 2006, INT J PSYCHOPHYSIOL, V60, P149, DOI 10.1016/j.ijpsycho.2005.12.009
   Freeman WJ, 2004, CLIN NEUROPHYSIOL, V115, P2077, DOI 10.1016/j.clinph.2004.02.029
   Galletti C, 2003, NEUROPSYCHOLOGIA, V41, P1717, DOI 10.1016/S0028-3932(03)00174-X
   Gamache PL, 2010, EUR J NEUROSCI, V31, P1908, DOI 10.1111/j.1460-9568.2010.07197.x
   Geffen G, 2000, J CLIN EXP NEUROPSYC, V22, P219, DOI 10.1076/1380-3395(200004)22:2;1-1;FT219
   Geissler HG, 1999, PERCEPT PSYCHOPHYS, V61, P707, DOI 10.3758/BF03205540
   Geissler HG, 2001, VIS COGN, V8, P679, DOI 10.1080/13506280143000197
   GEORGESON MA, 1985, VISION RES, V25, P1729, DOI 10.1016/0042-6989(85)90145-2
   Geremek A, 2002, VISION RES, V42, P2509, DOI 10.1016/S0042-6989(02)00201-8
   Geysztenkorn D, 2015, SURV OPHTHALMOL, V60, P1, DOI 10.1016/j.survophthal.2014.06.003
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goel A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0460
   Gorea A, 2011, J PHYSIOL-PARIS, V105, P153, DOI 10.1016/j.jphysparis.2011.09.008
   Grothe B, 2003, NAT REV NEUROSCI, V4, P540, DOI 10.1038/nrn1136
   Guski R, 2003, PERCEPT PSYCHOPHYS, V65, P789, DOI 10.3758/BF03194815
   Haber R. N., 1973, PSYCHOL VISUAL PERCE
   HABER RN, 1983, BEHAV BRAIN SCI, V6, P1, DOI 10.1017/S0140525X0001428X
   Hanslmayr S, 2011, BRAIN RES REV, V67, P331, DOI 10.1016/j.brainresrev.2011.04.002
   HARTER MR, 1968, Q J EXP PSYCHOL, V20, P157, DOI 10.1080/14640746808400144
   Heed T, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00076
   Heinrich A, 2006, J ACOUST SOC AM, V119, P2316, DOI 10.1121/1.2173524
   Heinrich A, 2014, J ACOUST SOC AM, V136, P1797, DOI 10.1121/1.4894788
   HENNING GB, 1981, J ACOUST SOC AM, V70, P1669, DOI 10.1121/1.387231
   Herzog MH, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002433
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   HIRSH IJ, 1961, J EXP PSYCHOL, V62, P423, DOI 10.1037/h0045283
   Hogendoorn H, 2016, J COGNITIVE NEUROSCI, V28, P1625, DOI 10.1162/jocn_a_00986
   Hogendoorn H, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00181
   Hubbard TL, 2013, AXIOMATHES, V23, P485, DOI 10.1007/s10516-012-9200-5
   Hubbard TL, 2013, AXIOMATHES, V23, P1, DOI 10.1007/s10516-012-9198-8
   Ihde-Scholl T, 2001, J CLIN PSYCHIAT, V62, P373, DOI 10.4088/JCP.v62n0512a
   Ilhan B, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049287
   ILMBERGER J, 1986, NATURWISSENSCHAFTEN, V73, P743, DOI 10.1007/BF00399249
   Jacob J, 2013, PSYCHON B REV, V20, P1114, DOI 10.3758/s13423-013-0482-4
   James W., 1890, PRINCIPLES PSYCHOL
   Jensen O, 2014, TRENDS NEUROSCI, V37, P357, DOI 10.1016/j.tins.2014.04.001
   Jensen O, 2012, TRENDS COGN SCI, V16, P200, DOI 10.1016/j.tics.2012.03.002
   JOKEIT H, 1990, NATURWISSENSCHAFTEN, V77, P289, DOI 10.1007/BF01131228
   JOLIOT M, 1994, P NATL ACAD SCI USA, V91, P11748, DOI 10.1073/pnas.91.24.11748
   Kanabus M, 2002, ACTA NEUROBIOL EXP, V62, P263
   Kilpatrick ZP, 2012, J COMPUT NEUROSCI, V32, P25, DOI 10.1007/s10827-011-0335-y
   Klimesch W, 2007, BRAIN RES REV, V53, P63, DOI 10.1016/j.brainresrev.2006.06.003
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Kline K, 2004, VISION RES, V44, P2653, DOI 10.1016/j.visres.2004.05.030
   Kline KA, 2006, VISION RES, V46, P1158, DOI 10.1016/j.visres.2005.08.021
   Kosem A, 2016, J NEUROPHYSIOL, V116, P2497, DOI 10.1152/jn.00074.2016
   Kozma R, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00010
   Kranczioch C, 2005, NEUROIMAGE, V24, P704, DOI 10.1016/j.neuroimage.2004.09.024
   KRISTOFFERSON AB, 1967, ACTA PSYCHOL, V27, P93, DOI 10.1016/0001-6918(67)90049-2
   KRISTOFFERSON AB, 1984, ANN NY ACAD SCI, V423, P3, DOI 10.1111/j.1749-6632.1984.tb23413.x
   Lange J, 2014, BEHAV BRAIN RES, V271, P294, DOI 10.1016/j.bbr.2014.06.015
   Lehmann D, 2006, J PHYSIOLOGY-PARIS, V99, P29, DOI 10.1016/j.jphysparis.2005.06.005
   LEHMANN D, 1987, ELECTROEN CLIN NEURO, V67, P271, DOI 10.1016/0013-4694(87)90025-3
   Lehmann D, 1998, INT J PSYCHOPHYSIOL, V29, P1, DOI 10.1016/S0167-8760(97)00098-6
   Lerner Y, 2014, J NEUROPHYSIOL, V111, P2433, DOI 10.1152/jn.00497.2013
   LESHOWITZ B, 1971, J ACOUST SOC AM, V49, P462, DOI 10.1121/1.1912374
   Levichkina E, 2014, PERCEPTION, V43, P295, DOI 10.1068/p7516
   LINDSLEY DB, 1952, ELECTROEN CLIN NEURO, V4, P443, DOI 10.1016/0013-4694(52)90075-8
   Lisman JE, 2013, NEURON, V77, P1002, DOI 10.1016/j.neuron.2013.03.007
   Lister JJ, 2005, J SPEECH LANG HEAR R, V48, P482, DOI 10.1044/1092-4388(2005/033)
   Lloyd D, 2012, CONSCIOUS COGN, V21, P695, DOI 10.1016/j.concog.2011.02.016
   Lotze M, 1999, CORTEX, V35, P89, DOI 10.1016/S0010-9452(08)70787-1
   MARKS LE, 1982, PERCEPT PSYCHOPHYS, V32, P537, DOI 10.3758/BF03204207
   Martens S, 2010, NEUROSCI BIOBEHAV R, V34, P947, DOI 10.1016/j.neubiorev.2009.12.005
   Mathewson KE, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00099
   Matthews WJ, 2012, ATTEN PERCEPT PSYCHO, V74, P1056, DOI 10.3758/s13414-012-0282-3
   Mauk MD, 2004, ANNU REV NEUROSCI, V27, P307, DOI 10.1146/annurev.neuro.27.070203.144247
   McComas AJ, 1999, CLIN NEUROPHYSIOL, V110, P1987, DOI 10.1016/S1388-2457(99)00067-X
   MCKEE SP, 1985, J OPT SOC AM A, V2, P243, DOI 10.1364/JOSAA.2.000243
   Megevand P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071608
   Michotte A., 1963, PERCEPTION CAUSALITY
   Miconi T, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00205
   MILLER GA, 1948, J ACOUST SOC AM, V20, P171, DOI 10.1121/1.1906360
   Milton A, 2016, NEUROIMAGE, V133, P53, DOI 10.1016/j.neuroimage.2016.02.065
   Moutoussis K, 1997, P ROY SOC B-BIOL SCI, V264, P393, DOI 10.1098/rspb.1997.0056
   Moutoussis K, 1997, P ROY SOC B-BIOL SCI, V264, P1407, DOI 10.1098/rspb.1997.0196
   Moutoussis K, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00314
   Myers NE, 2014, J NEUROSCI, V34, P7735, DOI 10.1523/JNEUROSCI.4741-13.2014
   Neri P, 1998, NATURE, V395, P894, DOI 10.1038/27661
   Nishikawa N, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118331
   Nortmann N, 2015, CEREB CORTEX, V25, P1427, DOI 10.1093/cercor/bht318
   Ogmen H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083671
   Ortiz-Mantilla S, 2016, J NEUROSCI, V36, P12095, DOI 10.1523/JNEUROSCI.1162-16.2016
   OSAKA N, 1977, PERCEPT PSYCHOPHYS, V22, P63, DOI 10.3758/BF03206081
   Payne L, 2014, CURR DIR PSYCHOL SCI, V23, P171, DOI 10.1177/0963721414529145
   Pichora-Fuller MK, 2006, J ACOUST SOC AM, V119, P1143, DOI 10.1121/1.2149837
   Pitts Walter, 1947, BULL MATH BIOPHYS, V9, P127, DOI 10.1007/BF02478291
   Poch C, 2014, EUR J NEUROSCI, V40, P2399, DOI 10.1111/ejn.12589
   Pockett S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00377
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poppel E, 1997, TRENDS COGN SCI, V1, P56, DOI 10.1016/S1364-6613(97)01008-5
   Poppel E, 2009, PHILOS T R SOC B, V364, P1887, DOI 10.1098/rstb.2009.0015
   POPPEL E, 1970, PSYCHOL FORSCH, V34, P1, DOI 10.1007/BF00422860
   POPPEL E, 1986, NATURWISSENSCHAFTEN, V73, P267, DOI 10.1007/BF00367781
   POPPEL E, 1990, NATURWISSENSCHAFTEN, V77, P89, DOI 10.1007/BF01131783
   POWESLAND PF, 1959, CAN J PSYCHOLOGY, V13, P155, DOI 10.1037/h0083773
   Purves D, 1996, P NATL ACAD SCI USA, V93, P3693, DOI 10.1073/pnas.93.8.3693
   RAAB DH, 1962, SCIENCE, V135, P42, DOI 10.1126/science.135.3497.42
   Rasanen O, 2013, J ACOUST SOC AM, V134, P407, DOI 10.1121/1.4807499
   RAYMOND JE, 1992, J EXP PSYCHOL HUMAN, V18, P849, DOI 10.1037/0096-1523.18.3.849
   REEVES A, 1986, PSYCHOL REV, V93, P180, DOI 10.1037/0033-295X.93.2.180
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Rimmele JM, 2015, INT J PSYCHOPHYSIOL, V95, P175, DOI 10.1016/j.ijpsycho.2014.06.010
   Roberts BM, 2013, NEUROPSYCHOLOGIA, V51, P349, DOI 10.1016/j.neuropsychologia.2012.10.009
   Ronconi L, 2017, P NATL ACAD SCI USA, V114, P13435, DOI 10.1073/pnas.1714522114
   Ronconi L, 2017, J NEUROSCI, V37, P10636, DOI 10.1523/JNEUROSCI.1704-17.2017
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Samaha J, 2015, CURR BIOL, V25, P2985, DOI 10.1016/j.cub.2015.10.007
   SCHMIDT MW, 1963, SCIENCE, V139, P112, DOI 10.1126/science.139.3550.112
   Schneider BA, 1999, J ACOUST SOC AM, V106, P371, DOI 10.1121/1.427062
   SHALLICE T, 1964, BRIT J STATIST PSYCH, V17, P113, DOI 10.1111/j.2044-8317.1964.tb00254.x
   SIMMONS JA, 1973, J ACOUST SOC AM, V54, P157, DOI 10.1121/1.1913559
   SIMMONS JA, 1979, SCIENCE, V204, P1336, DOI 10.1126/science.451543
   SIMPSON WA, 1994, VISION RES, V34, P2547, DOI 10.1016/0042-6989(94)90241-0
   Simpson WA, 2005, NEUROSCI LETT, V375, P23, DOI 10.1016/j.neulet.2004.10.059
   SNOWDEN RJ, 1991, VISION RES, V31, P907, DOI 10.1016/0042-6989(91)90156-Y
   Sperling G, 1960, PSYCHOL MONOGRAPHS G, V74
   STEVENS JC, 1966, PERCEPT PSYCHOPHYS, V1, P319, DOI 10.3758/BF03207399
   Stroud J. M., 1949, CYBERNETICS CIRCULAR, P27
   Stroud J.M., 1956, INFORM THEORY PSYCHO, P174
   STROUD JM, 1967, ANN NY ACAD SCI, V138, P623, DOI 10.1111/j.1749-6632.1967.tb55012.x
   Struber D, 2002, COGNITIVE BRAIN RES, V14, P370, DOI 10.1016/S0926-6410(02)00139-8
   SWEET AL, 1953, AM J PSYCHOL, V66, P185, DOI 10.2307/1418725
   Tadin D, 2010, VISION RES, V50, P1966, DOI 10.1016/j.visres.2010.07.005
   Tallon-Baudry C, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00397
   ULRICH R, 1987, PERCEPT PSYCHOPHYS, V42, P224, DOI 10.3758/BF03203074
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   VanRullen R, 2006, J NEUROSCI, V26, P502, DOI 10.1523/JNEUROSCI.4654-05.2006
   VanRullen R, 2005, P NATL ACAD SCI USA, V102, P5291, DOI 10.1073/pnas.0409172102
   VanRullen R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00060
   VanRullen R, 2003, TRENDS COGN SCI, V7, P207, DOI 10.1016/S1364-6613(03)00095-0
   VanRullen R., 2014, PHILOS T R SOC B, V369, P1
   VanRullen R, 2007, P NATL ACAD SCI USA, V104, P19204, DOI 10.1073/pnas.0707316104
   VanRullen R, 2016, TRENDS COGN SCI, V20, P723, DOI 10.1016/j.tics.2016.07.006
   VanRullen R, 2012, CURR BIOL, V22, P995, DOI 10.1016/j.cub.2012.03.050
   VENABLES PH, 1960, BRIT J PSYCHOL, V51, P37, DOI 10.1111/j.2044-8295.1960.tb00722.x
   von Baer K. E., 1862, BALTISCHER GEISTESAR, V1, P1
   von Bekesy G, 1936, ANN PHYS-BERLIN, V26, P554
   VORBERG D, 1987, NATURWISSENSCHAFTEN, V74, P446, DOI 10.1007/BF00446104
   VROON PA, 1974, AM J PSYCHOL, V87, P237, DOI 10.2307/1422017
   VROON PA, 1970, ACTA PSYCHOL, V32, P366, DOI 10.1016/0001-6918(70)90110-1
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   WALLACH H, 1949, AM J PSYCHOL, V62, P315, DOI 10.2307/1418275
   Walz JM, 2015, NEUROIMAGE, V113, P153, DOI 10.1016/j.neuroimage.2015.03.028
   WEHRHAHN C, 1992, J NEUROSCI, V12, P2247
   Weisz N, 2011, FRONTIERS PSYCHOL, V2
   Welford AT, 1952, B J PSYCHOL-GEN SECT, V43, P2, DOI 10.1111/j.2044-8295.1952.tb00322.x
   WESTHEIMER G, 1977, VISION RES, V17, P887, DOI 10.1016/0042-6989(77)90062-1
   WHITE PA, 1988, PSYCHOL BULL, V104, P36, DOI 10.1037/0033-2909.104.1.36
   White PA, 2017, PSYCHOL BULL, V143, P735, DOI 10.1037/bul0000104
   Wittmann M, 2011, FRONT INTEGR NEUROSC, V5, DOI 10.3389/fnint.2011.00066
   Wittmann M, 2009, PHILOS T R SOC B, V364, P1955, DOI 10.1098/rstb.2009.0003
   Yamamoto S, 2001, NAT NEUROSCI, V4, P759, DOI 10.1038/89559
   Young ME, 2005, MEM COGNITION, V33, P320, DOI 10.3758/BF03195320
   Yun SH, 2015, J NEURO-OPHTHALMOL, V35, P148, DOI 10.1097/WNO.0000000000000216
   Zeki S, 2015, PHILOS T R SOC B, V370, P103, DOI 10.1098/rstb.2014.0174
   ZERA J, 1993, J ACOUST SOC AM, V93, P1038, DOI 10.1121/1.405552
   ZIHL J, 1983, BRAIN, V106, P313, DOI 10.1093/brain/106.2.313
   Zoefel B, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00651, 10.1038/NATURE11020]
   Zoefel B, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00262
   ZWISLOCKI JJ, 1969, J ACOUST SOC AM, V46, P431, DOI 10.1121/1.1911708
NR 225
TC 17
Z9 18
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8100
EI 1090-2376
J9 CONSCIOUS COGN
JI Conscious. Cogn.
PD APR
PY 2018
VL 60
BP 98
EP 126
DI 10.1016/j.concog.2018.02.012
PG 29
WC Psychology, Experimental
SC Psychology
GA GC2RP
UT WOS:000429630600010
PM 29549714
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Ujiie, Y
   Asai, T
   Wakabayashi, A
AF Ujiie, Yuta
   Asai, Tomohisa
   Wakabayashi, Akio
TI Individual differences and the effect of face configuration information
   in the McGurk effect
SO EXPERIMENTAL BRAIN RESEARCH
LA English
DT Article
DE Autism spectrum quotient; McGurk effect; Thatcher illusion
ID AUTISM SPECTRUM DISORDERS; AUDIOVISUAL SPEECH-PERCEPTION; SUPERIOR
   TEMPORAL SULCUS; QUOTIENT AQ; ASPERGER-SYNDROME; SPATIAL-FREQUENCY;
   CHILDREN; INTEGRATION; RECOGNITION; PHENOTYPE
AB The McGurk effect, which denotes the influence of visual information on audiovisual speech perception, is less frequently observed in individuals with autism spectrum disorder (ASD) compared to those without it; the reason for this remains unclear. Several studies have suggested that facial configuration context might play a role in this difference. More specifically, people with ASD show a local processing bias for faces-that is, they process global face information to a lesser extent. This study examined the role of facial configuration context in the McGurk effect in 46 healthy students. Adopting an analogue approach using the Autism-Spectrum Quotient (AQ), we sought to determine whether this facial configuration context is crucial to previously observed reductions in the McGurk effect in people with ASD. Lip-reading and audiovisual syllable identification tasks were assessed via presentation of upright normal, inverted normal, upright Thatcher-type, and inverted Thatcher-type faces. When the Thatcher-type face was presented, perceivers were found to be sensitive to the misoriented facial characteristics, causing them to perceive a weaker McGurk effect than when the normal face was presented (this is known as the McThatcher effect). Additionally, the McGurk effect was weaker in individuals with high AQ scores than in those with low AQ scores in the incongruent audiovisual condition, regardless of their ability to read lips or process facial configuration contexts. Our findings, therefore, do not support the assumption that individuals with ASD show a weaker McGurk effect due to a difficulty in processing facial configuration context.
C1 [Ujiie, Yuta] Chuo Univ, Res & Dev Initiat, Bunkyo Ku, 1-13-27 Kasuga, Tokyo 1128551, Japan.
   [Ujiie, Yuta] Chiba Univ, Grad Sch Adv Integrat Sci, Inage Ku, 1-33 Yayoi Cho, Chiba 2638522, Japan.
   [Asai, Tomohisa] Adv Telecommun Res Inst Int ATR, Cognit Mech Labs, Kyoto 6190288, Japan.
   [Wakabayashi, Akio] Chiba Univ, Fac Letters, Inage Ku, 1-33 Yayoi Cho, Chiba 2638522, Japan.
RP Ujiie, Y (corresponding author), Chuo Univ, Res & Dev Initiat, Bunkyo Ku, 1-13-27 Kasuga, Tokyo 1128551, Japan.; Ujiie, Y (corresponding author), Chiba Univ, Grad Sch Adv Integrat Sci, Inage Ku, 1-33 Yayoi Cho, Chiba 2638522, Japan.
EM yuta.ujiie.160330@gmail.com
FU [26-8144];  [16H0720]; Grants-in-Aid for Scientific ResearchMinistry of
   Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan
   Society for the Promotion of ScienceGrants-in-Aid for Scientific
   Research (KAKENHI) [16H07207, 16H06526, 17K04309] Funding Source: KAKEN
FX We would like to express our gratitude to Dr. I. Dan and M. K.
   Yamaguchi. We would also like to thank all of the students who
   participated in our experiments. This study was supported by a
   Grant-in-Aid for the Japan Society for the Promotion of Science Fellows
   (Grant No. 26-8144) and Grant-in-Aid for Research Activity Start-up
   (Grant No. 16H0720). The research results have been achieved by
   "Research and development of technology for enhancing functional
   recovery of elderly and disabled people based on non-invasive brain
   imaging and robotic assistive devices", the Commissioned Research of
   National Institute of Information and Communications Technology (NICT),
   Japan.
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Austin EJ, 2005, PERS INDIV DIFFER, V38, P451, DOI 10.1016/j.paid.2004.04.022
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S., 1995, MINDBLINDNESS ESSAY
   Baron-Cohen S, 2009, BRIT J PSYCHIAT, V194, P500, DOI 10.1192/bjp.bp.108.059345
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   De Gelder B, 1991, EUROPEAN J COGNITIVE, V3, P69, DOI DOI 10.1080/09541449108406220
   Deruelle C, 2004, J AUTISM DEV DISORD, V34, P199, DOI 10.1023/B:JADD.0000022610.09668.4c
   Donohue SE, 2012, EXP BRAIN RES, V222, P377, DOI 10.1007/s00221-012-3223-4
   Eskelund K, 2015, NEUROPSYCHOLOGIA, V66, P48, DOI 10.1016/j.neuropsychologia.2014.10.021
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   FRITH U, 1991, AUTISM ASPERGERS SYN
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Hasegawa C, 2015, PSYCHIAT CLIN NEUROS, V69, P136, DOI 10.1111/pcn.12210
   Hietanen JK, 2001, EUR J COGN PSYCHOL, V13, P395, DOI 10.1080/09541440042000025
   Hoekstra RA, 2008, J AUTISM DEV DISORD, V38, P1555, DOI 10.1007/s10803-008-0538-x
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Jordan TR, 2011, ATTEN PERCEPT PSYCHO, V73, P2270, DOI 10.3758/s13414-011-0152-4
   Jordan TR, 1997, J EXP PSYCHOL HUMAN, V23, P388, DOI 10.1037/0096-1523.23.2.388
   Joseph RM, 2002, J CHILD PSYCHOL PSYC, V43, P807, DOI 10.1111/1469-7610.00092
   Kamio Y, 2013, ACTA PSYCHIAT SCAND, V128, P45, DOI 10.1111/acps.12034
   Katsyri J, 2008, NEUROPSYCHOLOGIA, V46, P1888, DOI 10.1016/j.neuropsychologia.2008.01.005
   Kikuchi Y, 2013, JPN PSYCHOL RES, V55, P118, DOI 10.1111/jpr.12000
   Kose S, 2013, PSYCHIAT CLIN NEUROS, V67, P20, DOI 10.1111/pcn.12005
   Lau WYP, 2013, J AUTISM DEV DISORD, V43, P2807, DOI 10.1007/s10803-013-1827-6
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Palmer CJ, 2013, NEUROPSYCHOLOGIA, V51, P1942, DOI 10.1016/j.neuropsychologia.2013.06.020
   Paton B, 2012, J AUTISM DEV DISORD, V42, P1870, DOI 10.1007/s10803-011-1430-7
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   Reed P, 2011, PERS INDIV DIFFER, V51, P732, DOI 10.1016/j.paid.2011.06.016
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Rosenblum LD, 2000, J EXP PSYCHOL HUMAN, V26, P806, DOI 10.1037//0096-1523.26.2.806
   Rosenblum LD, 2002, PERCEPT PSYCHOPHYS, V64, P220, DOI 10.3758/BF03195788
   Rouse H, 2004, J CHILD PSYCHOL PSYC, V45, P1246, DOI 10.1111/j.1469-7610.2004.00317.x
   Russell-Smith SN, 2012, J AUTISM DEV DISORD, V42, P2420, DOI 10.1007/s10803-012-1506-z
   Rutherford MD, 2007, VISION RES, V47, P2099, DOI 10.1016/j.visres.2007.01.029
   Saalasti S, 2012, J AUTISM DEV DISORD, V42, P1606, DOI 10.1007/s10803-011-1400-0
   Saalasti S, 2011, EXP BRAIN RES, V213, P283, DOI 10.1007/s00221-011-2751-7
   Sekiyama K., 1994, Journal of the Acoustical Society of Japan (E), V15, P143
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P303, DOI DOI 10.1111/J.1467-7687.2008.00677
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stewart ME, 2008, COGNITION, V109, P157, DOI 10.1016/j.cognition.2008.07.010
   Suda M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020021
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Taylor N, 2010, J AUTISM DEV DISORD, V40, P1403, DOI 10.1007/s10803-010-1000-4
   Teunisse JP, 2003, BRAIN COGNITION, V52, P285, DOI 10.1016/S0278-2626(03)00042-3
   Thomas SM, 2004, J EXP PSYCHOL HUMAN, V30, P873, DOI 10.1037/0096-1523.30.5.873
   THOMPSON P, 1980, PERCEPTION, V9, P483, DOI 10.1068/p090483
   Ujiie Y., 2015, INT J PSYCHOL STUD, V7, P195, DOI [10.5539/ijps.v7n2p195, DOI 10.5539/IJPS.V7N2P195]
   Ujiie Y, 2015, LETT EVOL BEHAV SCI, V6, P9
   Ujiie Y, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00891
   Wakabayashi A, 2006, J AUTISM DEV DISORD, V36, P263, DOI 10.1007/s10803-005-0061-2
   Williams JHG, 2004, RES DEV DISABIL, V25, P559, DOI 10.1016/j.ridd.2004.01.008
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Zilbovicius M, 2006, TRENDS NEUROSCI, V29, P359, DOI 10.1016/j.tins.2006.06.004
NR 63
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0014-4819
EI 1432-1106
J9 EXP BRAIN RES
JI Exp. Brain Res.
PD APR
PY 2018
VL 236
IS 4
BP 973
EP 984
DI 10.1007/s00221-018-5188-4
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA GB8QW
UT WOS:000429341400006
PM 29383400
DA 2021-02-24
ER

PT J
AU Boersma, T
   Baker, A
   Rispens, J
   Weerman, F
AF Boersma, Tiffany
   Baker, Anne
   Rispens, Judith
   Weerman, Fred
TI The effects of phonological skills and vocabulary on morphophonological
   processing
SO FIRST LANGUAGE
LA English
DT Article
DE Language acquisition; morphophonology; phonological processing skills;
   speech perception and production; vocabulary
ID ENGLISH PAST TENSE; NONWORD REPETITION; CHILDRENS PRODUCTION; WORD
   RECOGNITION; LANGUAGE; ACQUISITION; FREQUENCY; MEMORY; PRODUCTIVITY;
   SENSITIVITY
AB Morphophonological processing involves the phonological analysis of morphemes. Item-specific phonological characteristics have been shown to influence morphophonological skills in children. This study investigates the relative contributions of broad phonological skills and vocabulary to production and judgement accuracies of the Dutch past tense and diminutive, two morphophonological processes. Typically developing children (age 5;0-10;0, N = 114) were asked to produce and judge real and nonce diminutives and regular past tenses. Phonological processing skills were measured using a phonological awareness, digit span and nonword repetition task; vocabulary using the PPVT. Phonological skills and vocabulary contributed significantly to the production and judgement of the past tense and diminutive. The results underline the relation between phonological skills and the lexicon and the processing of morphophonology. These findings go further than showing the importance of the item-specific phonological context of the stem and suffix: they indicate that more general skills in the domain of phonology and vocabulary are involved.
C1 [Boersma, Tiffany; Baker, Anne; Rispens, Judith; Weerman, Fred] Univ Amsterdam, Amsterdam, Netherlands.
   [Baker, Anne] Stellenbosch Univ, Stellenbosch, South Africa.
RP Boersma, T (corresponding author), Univ Amsterdam, ACLC, Spuistr 134, NL-1012 VB Amsterdam, Netherlands.
EM t.a.boersma@uva.nl
CR Adriaans F., 2006, PHONOTACTOOLS
   Archibald LMD, 2008, Z PSYCHOL, V216, P161, DOI 10.1027/0044-3409.216.3.161
   Astheimer L, 2014, DEV COGN NEUROS-NETH, V7, P1, DOI 10.1016/j.dcn.2013.10.005
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Blom E, 2013, J SPEECH LANG HEAR R, V56, P281, DOI 10.1044/1092-4388(2012/11-0112)
   Blom E, 2012, LANG LEARN, V62, P965, DOI 10.1111/j.1467-9922.2012.00715.x
   Boersma T., DUTCH J APPL LINGUIS
   Brus B. T., 1979, EMT ONE MINUTE REAL
   Buckler H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00540
   Damhuis R., 1992, WOORDENLIJST 4 6 JAR
   De Bree E., 2016, LANGUAGE LEARNING DE, V13, P215
   Demuth K, 2016, FIRST LANG, V36, P265, DOI 10.1177/0142723715626066
   Den Os E., 1987, NIEUWE TAALGIDS, V80, P240
   Fikkert P, 2006, CATALAN J LINGUIST, V5, P83
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940
   Gathercole SE, 2006, APPL PSYCHOLINGUIST, V27, P513, DOI 10.1017/S0142716406060383
   Jarmulowicz L, 2006, J SPEECH LANG HEAR R, V49, P294, DOI 10.1044/1092-4388(2006/024)
   Jarmulowicz L, 2008, READ WRIT, V21, P275, DOI 10.1007/s11145-007-9073-y
   Jarmulowicz L, 2009, LANG SPEECH HEAR SER, V40, P299, DOI 10.1044/0161-1461(2008/08-0006)
   Kerkhoff A. O., 2007, THESIS
   KERNAN KT, 1966, ANTHROPOL LINGUIST, V8, P1
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643
   Kidd E, 2011, LANG COGNITIVE PROC, V26, P794, DOI 10.1080/01690965.2010.493735
   LINEBARGER MC, 1983, COGNITION, V13, P361, DOI 10.1016/0010-0277(83)90015-X
   Marchman VA, 1997, COGNITIVE SCI, V21, P283
   Marchman VA, 2004, BRAIN LANG, V88, P202, DOI 10.1016/S0093-934X(03)00099-3
   MARCHMAN VA, 1994, J CHILD LANG, V21, P339, DOI 10.1017/S0305000900009302
   Marshall CR, 2006, COGNITION, V100, P302, DOI 10.1016/j.cognition.2005.06.001
   Matthews DE, 2006, COGNITIVE SCI, V30, P1027, DOI 10.1207/s15516709cog0000_66
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Oetting JB, 1997, J SPEECH LANG HEAR R, V40, P62, DOI 10.1044/jslhr.4001.62
   Oostdijk Nelleke, 2000, P 2 INT C LANG RES E, V2, P887
   Peelaerts C., 2008, VAN KLEINE BOO UNPUB
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Raven J., 2003, MANUAL RAVENS PROGR
   Rice ML, 1999, J SPEECH LANG HEAR R, V42, P943, DOI 10.1044/jslhr.4204.943
   Rispens J, 2004, J NEUROLINGUIST, V17, P333, DOI 10.1016/j.jneuroling.2003.09.001
   Rispens J, 2015, J SPEECH LANG HEAR R, V58, P78, DOI 10.1044/2014_JSLHR-L-12-0393
   Rispens J, 2012, J SPEECH LANG HEAR R, V55, P683, DOI 10.1044/1092-4388(2011/10-0263)
   Rispens JE, 2014, J CHILD LANG, V41, P200, DOI 10.1017/S0305000912000542
   Royle P, 2013, J CHILD LANG, V40, P945, DOI 10.1017/S0305000912000414
   RStudio Team (2015), 2015, RSTUDIO INT DEV R RS
   Schlichting L., 2005, PEABODY PICTURE VOCA
   Semel E, 2010, CLIN EVALUATION LANG
   Song JY, 2009, J SPEECH LANG HEAR R, V52, P623, DOI 10.1044/1092-4388(2008/07-0258)
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Tabachnick B. G., 2013, USING MULTIVARIATE S
   Tomas E, 2017, FIRST LANG, V37, P453, DOI 10.1177/0142723717698839
   Tomas E, 2015, INT J LANG COMM DIS, V50, P516, DOI 10.1111/1460-6984.12152
   Van Den Bos K. P., 1994, KLEPEL 2 MINUTE PSEU
   WINDSOR J, 1994, J SPEECH HEAR RES, V37, P408, DOI 10.1044/jshr.3702.408
   Zamuner TS, 2012, APPL PSYCHOLINGUIST, V33, P481, DOI 10.1017/S0142716411000440
NR 54
TC 1
Z9 1
U1 0
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0142-7237
EI 1740-2344
J9 FIRST LANG
JI First Lang.
PD APR
PY 2018
VL 38
IS 2
BP 147
EP 174
DI 10.1177/0142723717725430
PG 28
WC Psychology, Developmental; Linguistics; Language & Linguistics
SC Psychology; Linguistics
GA GC5CQ
UT WOS:000429803400003
PM 30443094
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Saltzman, D
   Myers, E
AF Saltzman, David
   Myers, Emily
TI Listeners are maximally flexible in updating phonetic beliefs over time
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Speech perception; Spoken word recognition
ID INDIVIDUAL-DIFFERENCES; VISUAL RECALIBRATION; SPEECH-PERCEPTION;
   IDENTIFICATION; ABILITY; SLEEP
AB Perceptual learning serves as a mechanism for listenexrs to adapt to novel phonetic information. Distributional tracking theories posit that this adaptation occurs as a result of listeners accumulating talker-specific distributional information about the phonetic category in question (Kleinschmidt & Jaeger, 2015, Psychological Review, 122). What is not known is how listeners build these talker-specific distributions; that is, if they aggregate all information received over a certain time period, or if they rely more heavily upon the most recent information received and down-weight older, consolidated information. In the present experiment, listeners were exposed to four interleaved blocks of a lexical decision task and a phonetic categorization task in which the lexical decision blocks were designed to bias perception in opposite directions along a "s"-"sh" continuum. Listeners returned several days later and completed the identical task again. Evidence was consistent with listeners using a relatively short temporal window of integration at the individual session level. Namely, in each individual session, listeners' perception of a "s"-"sh" contrast was biased by the information in the immediately preceding lexical decision block, and there was no evidence that listeners summed their experience with the talker over the entire session. Similarly, the magnitude of the bias effect did not change between sessions, consistent with the idea that talker-specific information remains flexible, even after consolidation. In general, results suggest that listeners are maximally flexible when considering how to categorize speech from a novel talker.
C1 [Saltzman, David; Myers, Emily] Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,Unit 1085, Storrs, CT 06269 USA.
RP Myers, E (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,Unit 1085, Storrs, CT 06269 USA.
EM emily.myers@uconn.edu
OI /0000-0002-9475-764X
FU NIH NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01 DC013064]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC013064, R01DC013064, R01DC013064, R01DC013064, R01DC013064]
   Funding Source: NIH RePORTER
FX This work was supported by NIH NIDCD grant R01 DC013064 to EBM. The
   views expressed here reflect those of the authors and not the NIH or the
   NIDCD. We would like to thank Rachel Theodore for very helpful comments
   on an earlier version of this manuscript, and Julia Drouin for her
   contributions to the acoustic analysis.
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma P., 2018, PRAAT DOING PHONETIC
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Drouin JR, 2016, J ACOUST SOC AM, V140, pEL307, DOI 10.1121/1.4964468
   Earle FS, 2015, J EXP PSYCHOL HUMAN, V41, P1680, DOI 10.1037/xhp0000113
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Fenn KM, 2003, NATURE, V425, P614, DOI 10.1038/nature01951
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Granena G, 2013, LANG LEARN, V63, P665, DOI 10.1111/lang.12018
   Grey S, 2015, LEARN INDIVID DIFFER, V38, P44, DOI 10.1016/j.lindif.2015.01.019
   Hamrick P, 2015, LEARN INDIVID DIFFER, V44, P9, DOI 10.1016/j.lindif.2015.10.003
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Myers EB, 2014, J MEM LANG, V76, P80, DOI 10.1016/j.jml.2014.06.007
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Pajak B., 2016, LANG LEARN, V10, P900
   Siegelman N, 2015, J MEM LANG, V81, P105, DOI 10.1016/j.jml.2015.02.001
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
NR 28
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD APR
PY 2018
VL 25
IS 2
BP 718
EP 724
DI 10.3758/s13423-017-1376-7
PG 7
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA GD0RC
UT WOS:000430206900024
PM 28924946
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Olmstead, AJ
   Viswanathan, N
AF Olmstead, Annie J.
   Viswanathan, Navin
TI Lexical exposure to native language dialects can improve non-native
   phonetic discrimination
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Speech perception; Perceptual learning
ID SPEECH-PERCEPTION; FLEXIBILITY; ADAPTATION; CATEGORIES; SPEAKERS
AB Nonnative phonetic learning is an area of great interest for language researchers, learners, and educators alike. In two studies, we examined whether nonnative phonetic discrimination of Hindi dental and retroflex stops can be improved by exposure to lexical items bearing the critical nonnative stops. We extend the lexical retuning paradigm of Norris, McQueen, and Cutler (Cognitive Psychology, 47, 204-238, 2003) by having naive American English (AE)-speaking participants perform a pretest-training-posttest procedure. They performed an AXB discrimination task with the Hindi retroflex and dental stops before and after transcribing naturally produced words from an Indian English speaker that either contained these tokens or not. Only those participants who heard words with the critical nonnative phones improved in their posttest discrimination. This finding suggests that exposure to nonnative phones in native lexical contexts supports learning of difficult nonnative phonetic discrimination.
C1 [Olmstead, Annie J.; Viswanathan, Navin] Univ Kansas, Dept Speech Language Hearing, Lawrence, KS 66045 USA.
   [Viswanathan, Navin] Haskins Labs Inc, New Haven, CT USA.
RP Olmstead, AJ (corresponding author), Univ Kansas, Dept Speech Language Hearing, Lawrence, KS 66045 USA.
EM anne.j.olmstead@ku.edu
FU NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [NICHD P01
   HD001004-96]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH
   & HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994] Funding
   Source: NIH RePORTER; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH &HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994] Funding Source: NIH RePORTER
FX NV was partially supported by NICHD Grant # NICHD P01 HD001004-96
   awarded to Haskins Laboratories.
CR Best C. T., 1994, DEV SPEECH PERCEPTIO, V167, P233
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Flege J, 1995, SPEECH PERCEPTION LI, P233
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Olmstead A. J., 2016, INT M PSYCH SOC
   Pruitt J. S., 1998, J ACOUST SOC AM, V103, P3091
   Pruitt JS, 2006, J ACOUST SOC AM, V119, P1684, DOI 10.1121/1.2161427
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   Sailaja P., 2009, INDIAN ENGLISH
   Sjerps MJ, 2010, J EXP PSYCHOL HUMAN, V36, P195, DOI 10.1037/a0016803
   TEES RC, 1984, CAN J PSYCHOL, V38, P579, DOI 10.1037/h0080868
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Xie X, 2017, J EXP PSYCHOL HUMAN, V43, P206, DOI 10.1037/xhp0000285
NR 19
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD APR
PY 2018
VL 25
IS 2
BP 725
EP 731
DI 10.3758/s13423-017-1396-3
PG 7
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA GD0RC
UT WOS:000430206900025
PM 29086159
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Tsukada, K
   Cox, F
   Hajek, J
   Hirata, Y
AF Tsukada, Kimiko
   Cox, Felicity
   Hajek, John
   Hirata, Yukari
TI Non-native Japanese learners' perception of consonant length in Japanese
   and Italian
SO SECOND LANGUAGE RESEARCH
LA English
DT Article
DE cross-language speech perception; consonant length contrasts; Japanese;
   Italian; non-native Japanese learners; singleton; geminate
ID VOWEL LENGTH; CROSS-LANGUAGE; SPEAKING RATE; STOPS; ACQUISITION;
   ENGLISH; GEMINATE; SPEECH; SINGLE; THAI
AB Learners of a foreign language (FL) typically have to learn to process sounds that do not exist in their first language (L1). As this is known to be difficult for adults, in particular, it is important for FL pedagogy to be informed by phonetic research. This study examined the role of FL learners' previous linguistic experience in the processing of a contrast absent in the L1. The FLs under investigation are Japanese and Italian, which both use contrastive consonant length. Two groups of non-native Japanese (NNJ) learners - L1 Australian English (OZ) and L1 Korean - participated in the consonant length identification task. Neither OZ nor Korean has an underlying consonant length contrast, but Korean has non-contrastive lengthening of tense obstruents with corresponding shorter preceding vowels, which may be beneficial in perceiving consonant length in an FL. We have taken a novel, two-stage approach. First, we compared the perception of Japanese long/geminate and short/singleton consonants by the two groups of NNJ learners. Second, we investigated whether FL Japanese learning by the two groups transfers to the processing of consonant length in an unknown language, Italian. Native speakers of Japanese (NJ) and Italian (NI) were included as controls. They were familiar with contrastive consonant length in their L1, but were naive to the other language. The NJ and NI groups accurately identified the consonant length category in their L1 but were slightly less accurate in the unknown language. The two NNJ groups were generally accurate (> 80%) in perceiving consonant length not only in Japanese, but also in Italian. However, the direction of NNJ learners' misperception (i.e. singleton as geminate or geminate as singleton) varied, suggesting that some learners, according to their L1, may categorize length in Japanese and Italian differently rather than uniformly applying the concept of [+/- long].
C1 [Tsukada, Kimiko; Cox, Felicity] Macquarie Univ, N Ryde, NSW 2109, Australia.
   [Hajek, John] Univ Melbourne, Melbourne, Vic, Australia.
   [Hirata, Yukari] Colgate Univ, Hamilton, NY 13346 USA.
RP Tsukada, K (corresponding author), Macquarie Univ, N Ryde, NSW 2109, Australia.
EM kimiko.tsukada@gmail.com
RI Hajek, John/AAH-6419-2020; Tsukada, Kimiko/I-6398-2019
OI Tsukada, Kimiko/0000-0001-6365-3322; Cox, Felicity/0000-0001-8479-7624
FU Macquarie University research grants; 11th Hakuho Foundation Japanese
   Research Fellowship [2016-17]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by Macquarie University research grants and the 11th
   Hakuho Foundation Japanese Research Fellowship (2016-17).
CR Altmann H, 2012, SECOND LANG RES, V28, P387, DOI 10.1177/0267658312456544
   Amaro JC, 2016, INT J MULTILING, V13, P395, DOI 10.1080/14790718.2016.1217601
   Antoniou M, 2015, BILING-LANG COGN, V18, P683, DOI 10.1017/S1366728914000777
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   de Bot K, 2015, BILING-LANG COGN, V18, P130, DOI 10.1017/S1366728913000448
   Esposito A, 1999, J ACOUST SOC AM, V106, P2051, DOI 10.1121/1.428056
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Fujisaki H., 1973, ANN B RES I LOGOPEDI, V7, P45
   del Puerto FG, 2007, INT J MULTILING, V4, P1, DOI 10.2167/ijm042.0
   Gut U, 2010, INT J MULTILING, V7, P19, DOI 10.1080/14790710902972248
   Ham W. H., 2001, PHONETIC PHONOLOGICA
   HAN MS, 1992, PHONETICA, V49, P102, DOI 10.1159/000261906
   Harada T, 2006, STUD SECOND LANG ACQ, V28, P601, DOI 10.1017/S0272263106060281
   Hirata Y, 2004, J PHONETICS, V32, P565, DOI 10.1016/j.wocn.2004.02.004
   Hirata Y, 2009, PHONETICA, V66, P129, DOI 10.1159/000235657
   Hume E., 1999, P 14 INT C PHON SCI, P2069
   Hung H.-yi, 2012, J PHONETIC SOC JAPAN, V16, P15
   Idemaru K, 2008, J INT PHON ASSOC, V38, P167, DOI 10.1017/S0025100308003459
   Johnson K, 1995, OHIO STATE U WORKING, V45, P85
   Kato A, 2011, P 17 ICPHS, P1038
   Kato A, 2006, P 11 AUSTR INT C SPE, P170
   Kawahara S, 2015, HANDB JAPAN LANG, V2, P43
   Kawahara S, 2014, J INT PHON ASSOC, V44, P237, DOI 10.1017/S0025100314000085
   Kubozono H, 2013, J EAST ASIAN LINGUIS, V22, P303, DOI 10.1007/s10831-013-9109-z
   Kubozono Haruo, 2011, P 17 INT C PHON SCI, P1150
   Lee J, 2011, LINGUIST RES, V28, P75
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Llama R, 2010, INT J MULTILING, V7, P39, DOI 10.1080/14790710902972255
   Lu S, 2016, PERCEPT MOTOR SKILL, V122, P67, DOI 10.1177/0031512516630018
   Maddieson Ian, 1985, PHONETIC LINGUISTICS, P203
   Marx N, 2010, INT J MULTILING, V7, P4, DOI 10.1080/14790710902972271
   MIN KANG DAE, 2007, [Journal of Power System Engineering, 동력시스템공학회지], V11, P58
   Minagawa Y., 1996, ANN B RES I LOGOPEDI, V30, P23
   Minagawa-Kawai Y., 1998, P 5 INT C SPOK LANG
   Najoan FR, 2012, J PHONETIC SOC JAPAN, V16, P15
   Ofuka Etsuko, 2003, J PHONETIC SOC JAPAN, V7, P70
   Pajak B, 2014, J PHONETICS, V46, P147, DOI 10.1016/j.wocn.2014.07.001
   Payne Elinor, 2005, J INT PHON ASSOC, V35, P153, DOI DOI 10.1017/S0025100305002240
   Ramirez M, 2017, INT J BILINGUAL, DOI [10.1177/1367006916688334)., DOI 10.1177/1367006916688334).]
   Ridouane R, 2010, LAB PHONOLOGY, P61, DOI DOI 10.1515/9783110224917.1.61
   Rogers D., 2004, J INT PHON ASSOC, V34, P117, DOI DOI 10.1017/S0025100304001628
   Rothman Jason, 2013, CAMBRIDGE HDB 2 LANG, P372, DOI DOI 10.1017/CBO9781139051729.023
   Smith S., 1997, USER MANUAL UAB SOFT
   Sonu M, 2013, J EAST ASIAN LINGUIS, V22, P373, DOI 10.1007/s10831-013-9107-1
   The Japan Foundation, 2012, SURV REP JAP LANG ED
   Thomson Chihiro Kinoshita, 2010, OTEMON J AUSTR STUDI, V36, P157
   Toda T, 2003, J PHONETIC SOC JAPAN, V7, P73
   Toda T., 2007, J PHONETIC SOC JAPAN, V11, P35
   Tsukada K, 2006, BILING-LANG COGN, V9, P309, DOI 10.1017/S1366728906002653
   Tsukada K, 2012, SECOND LANG RES, V28, P151, DOI 10.1177/0267658311435870
   Tsukada K, 2008, J INT PHON ASSOC, V38, P325, DOI 10.1017/S0025100308003575
   Tsurutani C., 2007, REV ASIAN PACIFIC ST, V32, P25
   Tsurutani C, 2008, JPN STUD, V28, P305, DOI 10.1080/10371390802446869
   Uchida T, 1993, JAPANESE J ED PSYCHO, V41, P414
   Vance Timothy J., 2008, SOUNDS JAPANESE
   Webster G., 2007, P INT C PHON SCI ICP, V16, P1057
   Wrembel M, 2010, INT J MULTILING, V7, P75, DOI 10.1080/14790710902972263
NR 62
TC 1
Z9 1
U1 1
U2 4
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0267-6583
EI 1477-0326
J9 SECOND LANG RES
JI Second Lang. Res.
PD APR
PY 2018
VL 34
IS 2
BP 179
EP 200
DI 10.1177/0267658317719494
PG 22
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA GC6YE
UT WOS:000429938100002
DA 2021-02-24
ER

PT J
AU Scott, M
   Idrissi, A
AF Scott, Mark
   Idrissi, Ali
TI Audiovisual perception of gemination and pharyngealization in Arabic
SO SPEECH COMMUNICATION
LA English
DT Article
DE Audiovisual; Perception; Geminate; Pharyngealization; Emphasis; Arabic;
   McGurk
ID EMPHASIS SPREAD; DURATION; VISION; SOUNDS; CLOCK
AB This paper addresses a gap in the literature on audiovisual speech perception. Existing literature has largely examined the degree to which the audiovisual perception of primary place of articulation is influenced by visual information. Visual influences on the audiovisual categorization of a consonant as long (geminate) or short (singleton) have not, however, previously been examined. Furthermore, no experiment, to the authors' knowledge, has examined audiovisual perception of the presence or absence of the secondary articulation of pharyngealization. The experiments reported in this article fill this gap by demonstrating that the audiovisual perception, by Arabic speakers, of both singleton versus geminate and pharyngealized versus non-pharyngealized is susceptible to visual influence. These experiments also serve to address the general lack of research on audiovisual speech processing in Arabic. Finally, these experiments provide a methodological advance in dealing with temporal asynchrony when investigating audiovisual speech perception.
C1 [Scott, Mark; Idrissi, Ali] Qatar Univ, Dept English Literature & Linguist, United Arab Emirates Univ, Dept Linguist, Doha, Qatar.
RP Scott, M (corresponding author), Qatar Univ, Dept English Literature & Linguist, United Arab Emirates Univ, Dept Linguist, Doha, Qatar.
EM mark.a.j.scott@gmail.com; ali.idrissi@gmail.com
FU UAEU [31h076]
FX This research was supported by UAEU Grant 31h076 (College of Humanities
   and Social Sciences) to Mark Scott and Ali Idrissi. We would like to
   thank our Research Assistant, Souad Al Helou, and our native speaker,
   Hamdha Saleh Salem Alkarbi.
CR Al-Tamimi J., 2011, P INT C PHON SCI 17, P17
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Burr D., 2005, PROG BRAIN RES
   Burr D, 2009, EXP BRAIN RES, V198, P49, DOI 10.1007/s00221-009-1933-z
   CORNSWEET TN, 1962, AM J PSYCHOL, V75, P485, DOI 10.2307/1419876
   DAVIS S, 1995, LINGUIST INQ, V26, P465
   Davis S., 2014, PERSPECTIVES ARABIC, V1, P3
   Droit-Volet S, 2004, Q J EXP PSYCHOL-A, V57, P797, DOI 10.1080/02724980343000495
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   GEBHARD JW, 1959, AM J PSYCHOL, V72, P521, DOI 10.2307/1419493
   Goldstone S., 1974, PERCEPT MOTOR SKILL, P63
   Grant K. W., 2003, AVSP 2003 INT C AUD
   Grant KW, 1996, J ACOUST SOC AM, V100, P2415, DOI 10.1121/1.417950
   Holes C., 2004, MODERN ARABIC STRUCT
   JACK CE, 1973, PERCEPT MOTOR SKILL, V37, P967, DOI 10.2466/pms.1973.37.3.967
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kitagawa N, 2002, NATURE, V416, P172, DOI 10.1038/416172a
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Kubozono H, 2002, PHONOL PHONET, V4-1, P171
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Ladefoged Peter, 1975, COURSE PHONETICS
   LAUFER A, 1988, LANG SPEECH, V31, P181, DOI 10.1177/002383098803100205
   Lawrence M. A., 2013, EZ EASY ANAL VISUALI
   LEHN W, 1963, LANGUAGE, V39, P29, DOI 10.2307/410760
   Lehn W., 1978, READINGS ARABIC LING, P305
   Maiworm M., 2011, Tsinghua Science and Technology, V16, P121, DOI 10.1016/S1007-0214(11)70019-0
   Massaro DW, 1996, J ACOUST SOC AM, V100, P1777, DOI 10.1121/1.417342
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Munhall K.G., 2004, HDB MULTISENSORY PRO, P177
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Ortega L, 2009, BEHAV PROCESS, V81, P270, DOI 10.1016/j.beproc.2009.02.009
   Ortega L, 2014, ATTEN PERCEPT PSYCHO, V76, P1485, DOI 10.3758/s13414-014-0663-x
   Ouni S., 2007, AVSP, V1, P212
   Ouni S., 2007, INTERSPEECH 2007
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Penney TB, 2000, J EXP PSYCHOL HUMAN, V26, P1770, DOI 10.1037//0096-1523.26.6.1770
   R Core Team, 2014, R LANG ENV STAT COMP
   Rose S., 1979, 14 INT C SAL LANG W, P31
   ROSENBLUM LD, 1992, PERCEPT PSYCHOPHYS, V52, P461, DOI 10.3758/BF03206706
   Scott M., 2005, THEOR APPL LINGUIST, V8, P133
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Shahin K., 1997, PERSPECTIVES ARABIC, P215
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Shi ZH, 2016, GLOB ECON HIST SER, V12, P1, DOI [10.1163/9789004307339_002, 10.1016/j.cobeha.2016.02.014]
   Shi ZH, 2013, TRENDS COGN SCI, V17, P556, DOI 10.1016/j.tics.2013.09.009
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Vidal M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172028
   Wada Y, 2003, INT J PSYCHOPHYSIOL, V50, P117, DOI 10.1016/S0167-8760(03)00128-4
   WARREN DH, 1981, PERCEPT PSYCHOPHYS, V30, P557, DOI 10.3758/BF03202010
   Watson JCE, 1999, LINGUIST INQ, V30, P289, DOI 10.1162/002438999554066
   Wearden JH, 1998, Q J EXP PSYCHOL-B, V51, P97
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Welch RB, 1986, HDB PERCEPTION HUMAN
   Zawaydah B. A., 1999, PHONETICS PHONOLOGY
NR 57
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD APR
PY 2018
VL 98
BP 17
EP 27
DI 10.1016/j.specom.2018.01.009
PG 11
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA GC8FS
UT WOS:000430029100002
DA 2021-02-24
ER

PT J
AU Demos, AP
   Chaffin, R
AF Demos, Alexander P.
   Chaffin, Roger
TI HOW MUSIC MOVES US: ENTRAINING TO MUSICIANS' MOVEMENTS
SO MUSIC PERCEPTION
LA English
DT Article
DE synchronization; entrainment; postural sway; music performance; music
   listening
ID INTERPERSONAL SYNCHRONY; SPEECH-PERCEPTION; MOTOR THEORY; TIME;
   NONLINEARITY; COORDINATION; CONSTRAINTS; NEURONS; HEARING; SOUNDS
AB WE MEASURED THE POSTURAL SWAY OF TWO trombonists as they each recorded multiple performances of two solo pieces in each of three different expressive styles (normal, expressive, non-expressive). We then measured the postural sway of 29 nontrombonist listeners as they moved their arms and body, "air-conducting'' the recorded sound as if to draw out the emotion from the performance (Experiment 1), and of the two trombonists as they played along with the same recorded performances (Experiment 2). In both experiments, the velocity of listeners' postural sway was more like that of the performer than expected by chance. Listeners entrained more to back-and-forth than to side-to-side sway in Experiment 1 and only to back-and-forth sway in Experiment 2. Entrainment was not due entirely to performer and listener both swaying to the musical pulse in the same way. Listeners in Experiment 1 rated performances as more expressive when they entrained more, suggesting that entrainment enhanced their aesthetic experience of the music. The whole body appears to contribute to unpacking the expressive content of musical communication.
C1 [Demos, Alexander P.; Chaffin, Roger] Univ Connecticut, Storrs, CT USA.
   [Demos, Alexander P.] Univ Illinois, Dept Psychol, Chicago, IL 60680 USA.
RP Demos, AP (corresponding author), Dept Psychol, 1007 W Harrison St,MC 285, Chicago, IL 60607 USA.
EM ademos@uic.edu
RI Demos, Alexander/J-3337-2019
OI Demos, Alexander/0000-0001-7964-7808
CR AHMED A., 2012, WIILAB MATLAB TOOLB
   Balasubramaniam R, 2000, GAIT POSTURE, V11, P12, DOI 10.1016/S0966-6362(99)00051-X
   Bardy BG, 2015, ANN NY ACAD SCI, V1337, P94, DOI 10.1111/nyas.12650
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boothby EJ, 2014, PSYCHOL SCI, V25, P2209, DOI 10.1177/0956797614551162
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Burger B, 2018, PSYCHOL RES-PSYCH FO, V82, P1195, DOI 10.1007/s00426-017-0894-2
   Burger B, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00903
   Clark RA, 2010, GAIT POSTURE, V31, P307, DOI 10.1016/j.gaitpost.2009.11.012
   Clarke Eric F., 2001, MUSIC SCI, V5, P213, DOI DOI 10.1177/102986490100500205
   Clayton M, 2007, ASIAN MUSIC, V38, P71, DOI 10.1353/amu.2007.0032
   COOK N., 2013, BEYOND THE SCORE MUS
   Cross I, 2001, ANN NY ACAD SCI, V930, P28, DOI 10.1111/j.1749-6632.2001.tb05723.x
   Dahl S, 2014, J NEW MUSIC RES, V43, P214, DOI 10.1080/09298215.2014.884144
   DAVIDSON J. W., 2016, OXFORD HDB MUSIC PSY, P615
   Davidson J.W., 2009, OXFORD HDB MUSIC PSY, P364
   Davidson J. W., 1994, J HUMAN MOVEMENT STU, V26, P279
   Dean RT, 2016, BEHAV RES METHODS, V48, P783, DOI 10.3758/s13428-015-0611-2
   Demos A. P., 2017, MUSICAE SCI
   DEMOS A. P., 2014, FRONTIERS PSYCHOL, V477
   Demos AP, 2017, ROUTLEDGE COMPANION TO EMBODIED MUSIC INTERACTION, P341
   Demos AP, 2012, J EXP PSYCHOL GEN, V141, P49, DOI 10.1037/a0023843
   Efron B, 1994, INTRO BOOTSTRAP
   Flaig NK, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00072
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   GAVER WW, 1993, ECOL PSYCHOL, V5, P1, DOI 10.1207/s15326969eco0501_1
   GodOy Rolf Inge, 2010, MUSICAL GESTURES SOU
   Hasson U, 2012, TRENDS COGN SCI, V16, P114, DOI 10.1016/j.tics.2011.12.007
   Hove MJ, 2009, SOC COGNITION, V27, P949, DOI 10.1521/soco.2009.27.6.949
   Keller P. E., 2012, ART IN MOTION, P115
   Keller PE, 2010, MUSIC PERCEPT, V28, P27, DOI 10.1525/MP.2010.28.1.27
   Kim DO, 2015, J NEUROSCI, V35, P5360, DOI 10.1523/JNEUROSCI.3798-14.2015
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kohler E, 2002, SCIENCE, V297, P846, DOI 10.1126/science.1070311
   Large EW, 2000, HUM MOVEMENT SCI, V19, P527, DOI 10.1016/S0167-9457(00)00026-9
   Leman M, 2009, MUSIC PERCEPT, V26, P263, DOI 10.1525/MP.2009.26.3.263
   London J., 2012, HEARING TIME PSYCHOL
   MacRitchie J, 2013, MUSIC SCI, V17, P86, DOI 10.1177/1029864912467632
   Marsh K. L., 2013, PEOPLE WATCHING SOCI, P236
   Marsh K. L., 2010, GROUNDING SOCIALITY, P43
   Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029
   Novembre G, 2014, SOC COGN AFFECT NEUR, V9, P1062, DOI 10.1093/scan/nst086
   Paxton A, 2013, Q J EXP PSYCHOL, V66, P2092, DOI 10.1080/17470218.2013.853089
   Pecker M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01037
   Phillips-Silver J, 2007, COGNITION, V105, P533, DOI 10.1016/j.cognition.2006.11.006
   Pikovsky A, 2001, SYNCHRONIZATION A UN
   Pinheiro J., 2000, MIXED EFFECTS MODELS
   Ramsay J. O., 2006, FUNCTIONAL DATA ANAL
   Repp B. H., 1993, PSYCHOL MUSIC, V21/1, P48, DOI DOI 10.1177/030573569302100104
   Repp BH, 2013, PSYCHON B REV, V20, P403, DOI 10.3758/s13423-012-0371-2
   Riley MA, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00038
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Rochut J., 1928, MELODIOUS ETUDES TRO
   Rosenblum LD, 2017, J COGN PSYCHOL, V29, P65, DOI 10.1080/20445911.2016.1181691
   Schmidt RC, 2011, HUM MOVEMENT SCI, V30, P834, DOI 10.1016/j.humov.2010.05.014
   Schreiber T, 1996, PHYS REV LETT, V77, P635, DOI 10.1103/PhysRevLett.77.635
   Schreiber T, 2000, PHYSICA D, V142, P346, DOI 10.1016/S0167-2789(00)00043-9
   Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009
   Shockley K, 2003, J EXP PSYCHOL HUMAN, V29, P326, DOI 10.1037/0096-1523.29.2.326
   Shockley K, 2007, J EXP PSYCHOL HUMAN, V33, P201, DOI 10.1037/0096-1523.33.1.201
   Shove P., 1995, PRACTICE PERFORMANCE, P55, DOI [10.1017/CBO9780511552366.004, DOI 10.1017/CBO9780511552366.004]
   Sofianidis G, 2012, HUM MOVEMENT SCI, V31, P553, DOI 10.1016/j.humov.2011.07.007
   Steenson C., 2015, OPEN PSYCHOL J, V8, P174, DOI [10.2174/1874350101508010174, DOI 10.2174/1874350101508010174]
   Stins JF, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-83
   TARR B., 2014, FRONT PSYCHOL, V1096, P5
   TEIXEIRA E. C., 2016, J ACOUST SOC AM, V138, P121
   THEILER J, 1992, PHYSICA D, V58, P77, DOI 10.1016/0167-2789(92)90102-S
   Todd NPM, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00444
   Toiviainen P, 2010, MUSIC PERCEPT, V28, P59, DOI 10.1525/MP.2010.28.1.59
   Toiviainen P, 2009, COGN PROCESS, V10, pS325, DOI 10.1007/s10339-009-0304-9
   Verga L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01316
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   Wanderley MM, 2005, J NEW MUSIC RES, V34, P97, DOI 10.1080/09298210500124208
   Wanderley MM, 2004, P IEEE, V92, P632, DOI 10.1109/JPROC.2004.825882
   Wiltermuth SS, 2009, PSYCHOL SCI, V20, P1, DOI 10.1111/j.1467-9280.2008.02253.x
   Winter DA, 1996, J NEUROPHYSIOL, V75, P2334
   Zbikowski LM, 2009, APPL COGN LINGUIST, V11, P359
NR 79
TC 1
Z9 1
U1 0
U2 4
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD APR
PY 2018
VL 35
IS 4
BP 405
EP 424
DI 10.1525/MP.2018.35.4.405
PG 20
WC Music; Psychology, Experimental
SC Music; Psychology
GA GA9DT
UT WOS:000428642200001
DA 2021-02-24
ER

PT J
AU Peet, A
AF Peet, Andrew
TI Etiology, understanding, and testimonial belief
SO SYNTHESE
LA English
DT Article
DE Testimony; Etiology; Testimonial justification; Cognitive penetration
ID SPEECH-PERCEPTION; JUSTIFICATION; RELIABILITY; EXPERIENCE; DEFENSE
AB The etiology of a perceptual belief can seemingly affect its epistemic status. There are cases in which perceptual beliefs seem to be unjustified because the perceptual experiences on which they are based are caused, in part, by wishful thinking, or irrational prior beliefs. It has been argued that this is problematic for many internalist views in the epistemology of perception, especially those which postulate immediate perceptual justification. Such views are unable to account for the impact of an experience's etiology on its justificational status (see Markie (2005, 2006, 2013), McGrath (2013), Siegel (2012, 2013a, b), and Vahid (2014)). Our understanding of what we have been told can also be affected by, for example, wishful thinking or irrational background beliefs. I argue that testimonial beliefs based on such states of understanding can thus be rendered unjustified. This is problematic not only for internalist immediate justification views of testimony, but also for some externalist views, such as the form of proper functionalism endorsed by Burge (1993), and Graham (2010). The testimonial version of the argument from etiology, unlike the perceptual variant, does not rest on the controversial hypothesis that perception is cognitively penetrable. Furthermore, there is a stronger case for the claim that testimonial justification can be undermined by etiological effects since, I argue, testimonial beliefs can be based on the background mental states which affect our understanding of what is said, and our states of understanding are rationally assessable.
EM andrewpeet123@gmail.com
CR Bergmann M, 2004, NOUS, P35
   Bezuidenhout AL, 1997, NOUS, V31, P197, DOI 10.1111/0029-4624.00042
   Borg E., 2004, MINIMAL SEMANTICS
   Burge T, 2003, PHILOS PHENOMEN RES, V67, P503, DOI 10.1111/j.1933-1592.2003.tb00307.x
   BURGE T, 1993, PHILOS REV, V102, P457, DOI 10.2307/2185680
   Byrne A., 2013, PHILOS Q, V59, P429
   Cappelen H., 2004, INSENSITIVE SEMANTIC
   Carston R., 2002, THOUGHTS UTTERANCES
   David Marion, 2002, ACTA ANAL, V17, P103, DOI DOI 10.1007/BF03177510
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Fauconnier G., 2002, THE WAY WE THINK
   Fricker E., 2003, EPISTEMOLOGY LANGUAG, P325
   Fricker E, 2006, PHILOS PHENOMEN RES, V72, P618, DOI 10.1111/j.1933-1592.2006.tb00587.x
   Fumerton R., 2006, EPISTEMOLOGY TESTIMO, P77, DOI DOI 10.1093/ACPROF:OSO/9780199276011.001.0001
   Fumerton R, 2013, PHILOS STUD, V162, P733, DOI 10.1007/s11098-012-0058-6
   Gluer K., 2013, MIND LANG, V24, P297
   Goldberg S., 2006, PHILOS PHENOMENOLOGI, V72, P576, DOI DOI 10.1111/J.1933-1592.2006.TB00586.X
   Graham P., 2010, SOC EPISTEMOL, P148
   Graham P, 2006, EPISTEMOLOGY TESTIMO, P93
   Huemer M, 2013, PHILOS STUD, V162, P741, DOI 10.1007/s11098-012-0056-8
   Keysar B, 2002, PSYCHOL SCI, V13, P207, DOI 10.1111/1467-9280.00439
   Lyons J., 2006, AUSTRALAS J PHILOS, V75, P163
   Lyons J, 2011, NOUS, P289
   Markie P, 2005, PHILOS STUD, V126, P347, DOI 10.1007/s11098-004-7795-0
   Markie P, 2013, SEEMINGS JUSTIFICATI, P248
   Markie PJ, 2006, NOUS, V40, P118, DOI 10.1111/j.0029-4624.2006.00603.x
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCGRATH M., 2013, SEEMINGS JUSTIFICATI, P225, DOI DOI 10.1093/ACPROF:OSO/9780199899494.003.0010
   McGrath M., PHILOS REV
   Michaelian K, 2010, SYNTHESE, V176, P399, DOI 10.1007/s11229-009-9573-1
   Peet A., SYNTHESE, P1
   Recanati F., 2015, SCI MEANING
   Shogenji T, 2006, NOUS, V40, P331, DOI 10.1111/j.0029-4624.2006.00612.x
   Siegel S., 2013, OXFORD STUDIES EPIST, Viv, P240, DOI DOI 10.1093/ACPROF:OSO/9780199672707.001.0001
   Siegel S, 2013, PHILOS STUD, V162, P697, DOI 10.1007/s11098-012-0059-5
   Siegel S, 2012, NOUS, V46, P201, DOI 10.1111/j.1468-0068.2010.00786.x
   Sperber D., 1986, RELEVANCE COMMUNICAT
   Stanley J., 2005, P ARISTOTELIAN SOC S, V79, P131, DOI DOI 10.1111/J.0309-7013.2005.00129.X
   Vahid H, 2014, PHILOS ISSUES, V24, P439, DOI 10.1111/phis.12042
NR 39
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0039-7857
EI 1573-0964
J9 SYNTHESE
JI Synthese
PD APR
PY 2018
VL 195
IS 4
SI SI
BP 1547
EP 1567
DI 10.1007/s11229-016-1281-z
PG 21
WC History & Philosophy Of Science; Philosophy
SC History & Philosophy of Science; Philosophy
GA FY8DA
UT WOS:000427092100010
DA 2021-02-24
ER

PT J
AU Choi, JY
   Hu, ER
   Perrachione, TK
AF Choi, Ja Young
   Hu, Elly R.
   Perrachione, Tyler K.
TI Varying acoustic-phonemic ambiguity reveals that talker normalization is
   obligatory in speech processing
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Categorization
ID SPOKEN WORD RECOGNITION; SPEAKING RATE; STIMULUS VARIABILITY;
   TIME-COURSE; VOWEL; INFORMATION; MODEL; IDENTIFICATION; REPRESENTATION;
   DEPENDENCIES
AB The nondeterministic relationship between speech acoustics and abstract phonemic representations imposes a challenge for listeners to maintain perceptual constancy despite the highly variable acoustic realization of speech. Talker normalization facilitates speech processing by reducing the degrees of freedom for mapping between encountered speech and phonemic representations. While this process has been proposed to facilitate the perception of ambiguous speech sounds, it is currently unknown whether talker normalization is affected by the degree of potential ambiguity in acoustic-phonemic mapping. We explored the effects of talker normalization on speech processing in a series of speeded classification paradigms, parametrically manipulating the potential for inconsistent acoustic-phonemic relationships across talkers for both consonants and vowels. Listeners identified words with varying potential acoustic-phonemic ambiguity across talkers (e.g., beet/boat vs. boot/boat) spoken by single or mixed talkers. Auditory categorization of words was always slower when listening to mixed talkers compared to a single talker, even when there was no potential acoustic ambiguity between target sounds. Moreover, the processing cost imposed by mixed talkers was greatest when words had the most potential acoustic-phonemic overlap across talkers. Models of acoustic dissimilarity between target speech sounds did not account for the pattern of results. These results suggest (a) that talker normalization incurs the greatest processing cost when disambiguating highly confusable sounds and (b) that talker normalization appears to be an obligatory component of speech perception, taking place even when the acoustic-phonemic relationships across sounds are unambiguous.
C1 [Choi, Ja Young; Hu, Elly R.; Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
   [Choi, Ja Young] Harvard Univ, Program Speech & Hearing Biosci & Technol, Cambridge, MA 02138 USA.
RP Perrachione, TK (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
EM tkp@bu.edu
FU NIDCD of the National Institutes of HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R03DC014045]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R03DC014045, R03DC014045,
   R03DC014045] Funding Source: NIH RePORTER
FX We thank Sara Dougherty and Terri Scott for their assistance. Research
   reported in this article was supported by the NIDCD of the National
   Institutes of Health under award number R03DC014045. The content is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health.
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   CARRELL TD, 1981, PERCEPT PSYCHOPHYS, V29, P1, DOI 10.3758/BF03198833
   Chandrasekaran B, 2011, J COGNITIVE NEUROSCI, V23, P2690, DOI 10.1162/jocn.2011.21631
   Cutler A, 2011, 17 M INT C PHON SCI
   Fant G., 1973, SPEECH SOUNDS FEATUR
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Garner W., 1974, PROCESSING INFORM ST
   GOLDINGER SD, 1991, J EXP PSYCHOL LEARN, V17, P152, DOI 10.1037/0278-7393.17.1.152
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Green KP, 1997, PERCEPT PSYCHOPHYS, V59, P675, DOI 10.3758/BF03206015
   Hickok G., 2016, NEUROBIOLOGY LANGUAG, P195
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Holt LL, 2006, J ACOUST SOC AM, V119, P4016, DOI 10.1121/1.2195119
   Huettel SA, 1999, PERCEPT PSYCHOPHYS, V61, P1624, DOI 10.3758/BF03213123
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Kaganovich N, 2006, BRAIN RES, V1114, P161, DOI 10.1016/j.brainres.2006.07.049
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Luce P. A., 2003, RETHINKING IMPLICIT, P197, DOI DOI 10.1093/ACPROF:OSO/9780192632326.003.0009
   Luce PA, 2005, BLACKW HBK LINGUIST, P591
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   MELARA RD, 1994, PERCEPT PSYCHOPHYS, V56, P73, DOI 10.3758/BF03211692
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   Morton JR, 2015, J ACOUST SOC AM, V137, P1443, DOI 10.1121/1.4913456
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Mullennix JW, 1999, PERCEPT MOTOR SKILL, V89, P447, DOI 10.2466/PMS.89.6.447-457
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nusbaum H.C., 1997, TALKER VARIABILITY S, P109
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Sjerps MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P576, DOI 10.3758/s13414-012-0408-7
   SOMMERS MS, 1994, J ACOUST SOC AM, V96, P1314, DOI 10.1121/1.411453
   STRANGE W, 1976, J ACOUST SOC AM, V60, P213, DOI 10.1121/1.381066
   Stuart-Smith J, 2015, LAB PHONOL, V6, P505, DOI 10.1515/lp-2015-0015
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Theodore RM, 2015, ATTEN PERCEPT PSYCHO, V77, P1674, DOI 10.3758/s13414-015-0854-0
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   Tomiak G. R., 1991, J ACOUST SOC AM, V90, P2363
   VOLAITIS LE, 1992, J ACOUST SOC AM, V92, P723, DOI 10.1121/1.403997
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Zhang C., 2013, NEUROIMAGE, V124, P536
   Zhang CC, 2016, J EXP PSYCHOL HUMAN, V42, P1252, DOI 10.1037/xhp0000216
NR 61
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD APR
PY 2018
VL 80
IS 3
BP 784
EP 797
DI 10.3758/s13414-017-1395-5
PG 14
WC Psychology; Psychology, Experimental
SC Psychology
GA FY4YK
UT WOS:000426833000014
PM 29417449
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Cooper, A
   Fecher, N
   Johnson, EK
AF Cooper, Angela
   Fecher, Natalie
   Johnson, Elizabeth K.
TI Toddlers' comprehension of adult and child talkers: Adult targets versus
   vocal tract similarity
SO COGNITION
LA English
DT Article
DE Developmental speech perception; Speech production; Word recognition;
   Indexical variation; Talker familiarity
ID SPOKEN WORD RECOGNITION; SPEECH-PERCEPTION
AB How do children represent words? If lexical representations are based on encoding the indexical characteristics of frequently-heard speakers, this predicts that speakers like a child's own mother should be best understood. Alternatively, if they are based on the child's own motor productions, this predicts an own-voice advantage in word recognition. Here, we address this question by presenting 2.5-year-olds with recordings of their own voice, another child's voice, their own mother's voice, and another mother's voice in a child-friendly eye-tracking procedure. No own-voice or own-mother advantage was observed. Rather, children uniformly performed better on adult voices than child voices, even performing better for unfamiliar adult voices than own voices. We conclude that children represent words not in the form of own-voice motor codes or frequently heard speakers, but on the basis of adult speech targets.
C1 [Cooper, Angela; Fecher, Natalie; Johnson, Elizabeth K.] Univ Toronto, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L106, Canada.
RP Cooper, A (corresponding author), Univ Toronto, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L106, Canada.
EM angela.cooper@utoronto.ca; natalie.fecher@utoronto.ca;
   elizabeth.johnson@utoronto.ca
OI Johnson, Elizabeth Kay/0000-0002-9941-9949
FU Social Sciences and Humanities Research CouncilSocial Sciences and
   Humanities Research Council of Canada (SSHRC); Natural Sciences and
   Engineering Research CouncilNatural Sciences and Engineering Research
   Council of Canada (NSERC); Canada Research Chairs programCanada Research
   Chairs
FX Thanks to Yazad Bhathena and Lisa Hotson, and the members of the Child
   Language and Speech Studies Lab for their support. This work was
   supported by grants from the Social Sciences and Humanities Research
   Council, Natural Sciences and Engineering Research Council, and the
   Canada Research Chairs program. Portions of this work were presented at
   the 3rd Workshop for Infant Language Development in Bilbao (June 2016).
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bernier D. E., 2017, P BOST U C LANG DEV, P88
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Choi JY, 2017, P NATL ACAD SCI USA, V114, P7307, DOI 10.1073/pnas.1706405114
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Creel SC, 2014, J MEM LANG, V73, P81, DOI 10.1016/j.jml.2014.03.001
   Cutler A., 2005, A FIGURE OF SPEECH, P64
   Delle Luche C, 2015, INFANT BEHAV DEV, V40, P151, DOI 10.1016/j.infbeh.2015.05.005
   Frank M. C., 2016, J CHILD LANG, V18, P1
   Hazan V, 2004, J ACOUST SOC AM, V116, P3108, DOI 10.1121/1.1806826
   Hollich G, 2005, SUPERCODER PROGRAM C
   JERGER S, 1993, PERCEPT PSYCHOPHYS, V54, P310, DOI 10.3758/BF03205266
   Knightly LM, 2003, J ACOUST SOC AM, V114, P465, DOI 10.1121/1.1577560
   Knoblich G, 2002, Q J EXP PSYCHOL-A, V55, P1027, DOI 10.1080/02724980143000631
   Knoblich G, 2001, PSYCHOL SCI, V12, P467, DOI 10.1111/1467-9280.00387
   MacDonald EN, 2012, CURR BIOL, V22, P113, DOI 10.1016/j.cub.2011.11.052
   Masapollo M, 2016, DEVELOPMENTAL SCI, V19, P318, DOI 10.1111/desc.12298
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Polka L, 2014, PSYCHOL SCI, V25, P1448, DOI 10.1177/0956797614533571
   Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551
   Repp BH, 2004, PSYCHOL SCI, V15, P604, DOI 10.1111/j.0956-7976.2004.00727.x
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Schmale R, 2010, INFANCY, V15, P650, DOI 10.1111/j.1532-7078.2010.00032.x
   Schuerman WL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129731
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Tye-Murray N., 2014, PSYCHONOMIC B REV, P1
   Tye-Murray N, 2013, PSYCHON B REV, V20, P115, DOI 10.3758/s13423-012-0328-5
   VIHMAN MM, 1993, J PHONETICS, V21, P61, DOI 10.1016/S0095-4470(19)31321-X
   Zamuner TS, 2016, J MEM LANG, V89, P55, DOI 10.1016/j.jml.2015.10.003
NR 31
TC 4
Z9 4
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD APR
PY 2018
VL 173
BP 16
EP 20
DI 10.1016/j.cognition.2017.12.013
PG 5
WC Psychology, Experimental
SC Psychology
GA FW8HG
UT WOS:000425571700003
PM 29287204
DA 2021-02-24
ER

PT J
AU Dupoux, E
AF Dupoux, Emmanuel
TI Cognitive science in the era of artificial intelligence: A roadmap for
   reverse-engineering the infant language-learner
SO COGNITION
LA English
DT Article
DE Artificial intelligence; Speech psycholinguistics; Computational
   modeling; Corpus analysis; Early language acquisition; Infant
   development; Language bootstrapping; Machine learning
ID DEEP NEURAL-NETWORKS; SPEECH-PERCEPTION; SOUND PATTERNS; DISTRIBUTIONAL
   INFORMATION; 1ST YEAR; ACQUISITION; CHILD; DISCRIMINATION; MODELS; UNITS
AB Spectacular progress in the information processing sciences (machine learning, wearable sensors) promises to revolutionize the study of cognitive development. Here, we analyse the conditions under which 'reverse engineering' language development, i.e., building an effective system that mimics infant's achievements, can contribute to our scientific understanding of early language development. We argue that, on the computational side, it is important to move from toy problems to the full complexity of the learning situation, and take as input as faithful reconstructions of the sensory signals available to infants as possible. On the data side, accessible but privacy-preserving repositories of home data have to be setup. On the psycholinguistic side, specific tests have to be constructed to benchmark humans and machines at different linguistic levels. We discuss the feasibility of this approach and present an overview of current results.
C1 [Dupoux, Emmanuel] PSL Res Univ, CNRS, INRIA, EHESS,ENS, Paris, France.
RP Dupoux, E (corresponding author), PSL Res Univ, CNRS, INRIA, EHESS,ENS, Paris, France.
EM errunanuel.dupoux@ens.fr
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [ERC-2011-AdG-295810 BOOTPHON]; Agence Nationale pour la
   RechercheFrench National Research Agency (ANR) [ANR-10-LABX-0087 IEC,
   ANR-10-IDEX-0001-02 PSL*]; Fondation de FranceFondation de France; Ecole
   de Neurosciences de Paris; Region Ile de France (DIM cerveau et
   pensee)Region Ile-de-France
FX This paper would not have come to light without numerous inspiring
   discussions with Paul Smolensky and Alex Cristia. It also benefitted
   from insightful comments by Paul Bloom, Emmanuel Chemla, Ewan Dunbar,
   Michael Frank, Giorgio Magri, Steven Pinker, Thomas Schatz, Gabriel
   Synnaeve, the members of the Cognitive Machine Learning team of the
   Laboratoire de Sciences Cognitives et Psycholinguistique, and three
   anonymous Cognition reviewers. This work was supported by the European
   Research Council (ERC-2011-AdG-295810 BOOTPHON), the Agence Nationale
   pour la Recherche (ANR-10-LABX-0087 IEC, ANR-10-IDEX-0001-02 PSL*), the
   Fondation de France, the Ecole de Neurosciences de Paris, and the Region
   Ile de France (DIM cerveau et pensee).
CR Abend O, 2017, COGNITION, V164, P116, DOI 10.1016/j.cognition.2017.02.009
   Abrams K, 1978, CHAP RELATION MOTH A, V4a
   Allen J, 1999, CARN S COGN, P115
   Amodei D., 2016, P INT C MACH LEARN, P173, DOI DOI 10.1007/978-3-030-14596-5_12
   Anderson J. R, 1975, INFORM PROCESSING CO
   Angluin D, 1988, IDENTIFYING LANGUAGE
   Antetomaso S, 2017, P 41 ANN BOST U C LA, P32
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Badino L, 2014, INT CONF ACOUST SPEE
   Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238
   Bates E., 1987, MECH LANGUAGE ACQUIS, P157
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   BERTONCINI J, 1987, J ACOUST SOC AM, V82, P31, DOI 10.1121/1.395570
   Berwick Robert, 1985, ACQUISITION SYNTACTI
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Bloom P., 2000, CHILDREN LEARN MEANI
   Botha J. A., 2013, P 2013 C EMP METH NA, P345
   Boves L, 2007, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P349, DOI 10.1109/COGINF.2007.4341909
   Brent M. R., 1996, 4OMPUTATIONAL APPROA
   Brent MR, 1996, COGNITION, V61, P1, DOI 10.1016/S0010-0277(96)00779-2
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Bruni E., 2012, P ACL
   Cadieu C. F., 2014, ARXIV14063284
   Casillas M., 2016, BOSTON U CHILD LANGU
   Chia-ying Lee, 2012, P 50 ANN M ASS COMP, V1, P40
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Chouinard MM, 2003, J CHILD LANG, V30, P637, DOI 10.1017/S0305000903005701
   Christiansen M. H., 2005, LANG ACQUIS, P205
   Christodoulopoulos C., 2010, P 2010 C EMP METH NA, P575
   Christophe A, 2008, LANG SPEECH, V51, P61, DOI 10.1177/00238309080510010501
   Cichy R. M., 2016, ARXIV160102970
   Clark A., 2011, LINGUISTIC NATIVISM
   Clark Alexander, 2013, P 4 ANN WORKSH COGN, P28
   Connor M., 2013, COGNITIVE ASPECTS CO, P257
   CRAIN S, 1991, BEHAV BRAIN SCI, V14, P597, DOI 10.1017/S0140525X00071491
   Cristia A., 2017, CHILD DEV
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Cutler A, 2012, NATIVE LISTENING LAN
   D'Ulizia A, 2011, ARTIF INTELL REV, V36, P1, DOI 10.1007/s10462-010-9199-1
   Daland R, 2011, COGNITIVE SCI, V35, P119, DOI 10.1111/j.1551-6709.2010.01160.x
   de Marcken Carl, 1996, THESIS
   DEHAENELAMBERTZ G, 1994, NATURE, V370, P292, DOI 10.1038/370292a0
   Devlin J, 2015, ARXIV150504467
   DRESHER BE, 1990, COGNITION, V34, P137, DOI 10.1016/0010-0277(90)90042-I
   Dunbar E., 2017, P ASRU
   Dupoux E., 2016, EVALUATING MODELS LA
   EILERS RE, 1979, CHILD DEV, V50, P14
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E
   ELMAN JL, 1988, J ACOUST SOC AM, V83, P1615, DOI 10.1121/1.395916
   Elsner M., 2012, P 50 ANN M ASS COMP
   Evans N, 2009, BEHAV BRAIN SCI, V32, P429, DOI 10.1017/S0140525X0999094X
   Fahad A, 2014, IEEE T EMERG TOP COM, V2, P267, DOI 10.1109/TETC.2014.2330519
   Feldman N, 2011, PROC ANN BUCLD, P197
   Fernald A, 2000, PHONETICA, V57, P242, DOI 10.1159/000028477
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Fiscus J. G., 2007, P SPEC INT GROUP INF, V7, P51
   Foppolo F, 2012, LANG LEARN DEV, V8, P365, DOI 10.1080/15475441.2011.626386
   Fourtassi A., 2014, P 18 C COMP NAT LANG
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   Frank M. C., 2017, INFANCY
   Frank MC, 2010, COGNITION, V117, P107, DOI 10.1016/j.cognition.2010.07.005
   Frank MC, 2009, PSYCHOL SCI, V20, P578, DOI 10.1111/j.1467-9280.2009.02335.x
   Gershman SJ, 2015, SCIENCE, V349, P273, DOI 10.1126/science.aac6076
   GIBSON E, 1994, LINGUIST INQ, V25, P407
   Gilmore RO, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0128
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gish H., 2013, COMPUTER SPEECH LANG
   Gleitman Lelia, 1990, LANG ACQUIS, V1, P3, DOI DOI 10.1207/S15327817LA0101_2
   GLEITMAN LR, 1972, COGNITION, V1, P137, DOI 10.1016/0010-0277(72)90016-9
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Goldin-Meadow S., 2005, HEARING GESTURE OUR
   Goldwater S. J, 2007, THESIS
   GOLINKOFF RM, 1987, J CHILD LANG, V14, P23, DOI 10.1017/S030500090001271X
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gracia C, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P299, DOI 10.1109/ICMLA.2013.139
   Gregory R. J., 2004, PSYCHOL TESTING HIST
   Grimshaw Jane., 1981, LOGICAL PROBLEM LANG, P165
   Guevara-Rukoz A., 2017, ARE WORDS INFANT DIR
   Hannun A, 2014, ARXIV14125567
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hart B., 1995, MEANINGFUL DIFFERENC
   Harwath D., 2017, ARXIV170107481
   Harwath D., 2016, ADV NEURAL INFORM PR, P1858
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Hayes B, 2008, LINGUIST INQ, V39, P379, DOI 10.1162/ling.2008.39.3.379
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   HIRSHPASEK K, 1987, COGNITION, V26, P269, DOI 10.1016/S0010-0277(87)80002-1
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Hoff E, 2012, RES METHODS CHILD LA
   Hollich G., 2000, MONOGR SOC RES CHILD, V65, P3, DOI [10.1111/1540-5834.00090., DOI 10.1111/1540-5834.00090]
   Huttenlocher J, 2010, COGNITIVE PSYCHOL, V61, P343, DOI 10.1016/j.cogpsych.2010.08.002
   Jackendoff R., 1997, ARCHITECTURE LANGUAG, V28
   Jager G, 2012, PHILOS T R SOC B, V367, P1956, DOI 10.1098/rstb.2012.0077
   Jansen A., 2011, 7 INT
   Jansen A, 2013, INT CONF ACOUST SPEE, P8111, DOI 10.1109/ICASSP.2013.6639245
   Johnson elvin, 2016, ARXIV161104558
   Johnson K, 2004, PHILOS SCI, V71, P571, DOI 10.1086/423752
   Johnson M., 2008, P 46 ANN M ASS COMP, P398
   JUSCZYK P. W., 1997, DISCOVERY SPOKEN LAN
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   JUSCZYK PW, 1992, COGNITIVE PSYCHOL, V24, P252, DOI 10.1016/0010-0285(92)90009-Q
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Katsos N, 2011, COGNITION, V120, P67, DOI 10.1016/j.cognition.2011.02.015
   Kelley K, 1967, P3719 RAND CORP
   Kheradpisheh SR, 2016, SCI REP-UK, V6, DOI 10.1038/srep32672
   Kiela D., 2014, P 2014 C EMP METH NA, P36, DOI DOI 10.3115/V1/D14-1005
   KOHONEN T, 1988, COMPUTER, V21, P11, DOI 10.1109/2.28
   Koller D., 2009, PROBABILISTIC GRAPHI
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097, DOI [10.1145/3065386, DOI 10.1145/3065386]
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Kwiatkowski T., 2012, P 13 C EUR CHAPT ACL, P234
   Lake B. M., 2016, ARXIV160400289
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Langley P., 1987, MECH LANGUAGE ACQUIS, P115
   Larsen E., 2017, P INT
   Lau JH, 2017, COGNITIVE SCI, V41, P1202, DOI 10.1111/cogs.12414
   Levesque H. J., 2011, AAAI SPRING S LOG FO
   LIANG P, 2011, HLT 11, V1, P590
   Lidz J, 2002, COGNITION, V84, P113, DOI 10.1016/S0010-0277(02)00013-6
   Lidz J, 2015, ANNU REV LINGUIST, V1, P333, DOI 10.1146/annurev-linguist-030514-125236
   Ludusan B., 2014, P LREC
   Ludusan B., 2015, C EMP METH NAT LANG, P93
   MacWhinney B., 2000, COMPUT LINGUIST, VI, P657, DOI DOI 10.1162/C0LI.2000.26.4.657
   MacWhinney B, 1978, P ACM ANN C, P421
   MacWhinney B, 1987, COMPETITION MODEL
   Magri G., 2015, J LOGIC COMPUTATION
   MANDEL DR, 1995, PSYCHOL SCI, V6, P314, DOI 10.1111/j.1467-9280.1995.tb00517.x
   MARCUS GF, 1993, COGNITION, V46, P53, DOI 10.1016/0010-0277(93)90022-N
   Martin A, 2015, PSYCHOL SCI, V26, P341, DOI 10.1177/0956797614562453
   Martin A, 2013, COGNITIVE SCI, V37, P103, DOI 10.1111/j.1551-6709.2012.01267.x
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Mazuka R., 2006, 200616 TL, V106
   Mazuka R, 2011, DEVELOPMENTAL SCI, V14, P693, DOI 10.1111/j.1467-7687.2010.01015.x
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Meltzoff AN, 2009, SCIENCE, V325, P284, DOI 10.1126/science.1175626
   Mikolov T, 2013, P WORKSH ICLR
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Morgan J., 1996, SIGNAL SYNTAX BOOTST
   Muscariello A., 2009, INTERSPEECH 2009
   Ngon C, 2013, DEVELOPMENTAL SCI, V16, P24, DOI 10.1111/j.1467-7687.2012.01189.x
   Nguyen A., 2014, ARXIV14121897
   Olivier D. C., 1968, THESIS
   Ondel L, 2016, PROCEDIA COMPUT SCI, V81, P80, DOI 10.1016/j.procs.2016.04.033
   Oord A.v.d., 2016, ARXIV160903499
   Pan BA, 2005, CHILD DEV, V76, P763, DOI 10.1111/j.1467-8624.2005.00876.x
   Park AS, 2008, IEEE T AUDIO SPEECH, V16, P186, DOI 10.1109/TASL.2007.909282
   Pearl J., 1997, PROBABILISTIC REASON
   Pearl L., 2016, EVALUATING LANGUAGE
   Peters A. M, 1983, UNITS LANGUAGE ACQUI, V1
   Pinker S, 1994, LANGUAGE INSTINCT
   Pinker S., 1984, LANGUAGE LEARNABILIT
   Pinker S., 1989, LEARNABILITY COGNITI
   Pinker Steven, 1987, MECH LANGUAGE ACQUIS, P399
   Podesva RJ, 2007, J SOCIOLING, V11, P478, DOI 10.1111/j.1467-9841.2007.00334.x
   Poizner H., 1987, WHAT HAND REVEALS BR
   Rahmani H., 2016, ARXIV160200828
   Rasanen O, 2012, SPEECH COMMUN, V54, P975, DOI 10.1016/j.specom.2012.05.001
   Rowe ML, 2009, SCIENCE, V323, P951, DOI 10.1126/science.1167025
   Roy BC, 2015, P NATL ACAD SCI USA, V112, P12663, DOI 10.1073/pnas.1419773112
   Roy D., 2009, P INT BRIGHT ENGL
   Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4
   Rumelhart D. E., 1987, MECH LANGUAGE ACQUIS
   Sachs J., 1983, CHILDRENS LANGUAGE, P1
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sakas WG, 2012, LANG ACQUIS, V19, P83, DOI 10.1080/10489223.2012.660553
   Sangwan A, 2015, 2015 IEEE SIGNAL PROCESSING AND SIGNAL PROCESSING EDUCATION WORKSHOP (SP/SPE), P49, DOI 10.1109/DSP-SPE.2015.7369526
   Saon  George, 2017, ARXIV170302136
   Saxton M, 1997, J CHILD LANG, V24, P139, DOI 10.1017/S030500099600298X
   Schatz T, 2013, INTERSPEECH, P1780
   Seidl A, 2015, DEVELOPMENTAL SCI, V18, P155, DOI 10.1111/desc.12182
   Shneidman LA, 2012, DEVELOPMENTAL SCI, V15, P659, DOI 10.1111/j.1467-7687.2012.01168.x
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   Siklossy L., 1968, TECH REP
   Silberer C., 2016, IEEE T PATTERN ANAL
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Silverman D., 1995, ANTHROPOL LINGUIST, V37, P70
   Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7
   Smith K, 2011, COGNITIVE SCI, V35, P480, DOI 10.1111/j.1551-6709.2010.01158.x
   Smith LB, 2015, J COGN DEV, V16, P407, DOI 10.1080/15248372.2014.933430
   Smolensky P., 2000, LEARNABILITY OPTIMAL
   Song J. J., 2010, OXFORD HDB LINGUISTI
   Sprouse J, 2013, LINGUA, V134, P219, DOI 10.1016/j.lingua.2013.07.002
   Stark R., 1980, STAGES DEV 1 YEAR LI
   Steedman M, 2014, PHYS LIFE REV, V11, P382, DOI 10.1016/j.plrev.2014.06.010
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Tal L., 2016, T ASS COMPUT LINGUIS, V4, P521, DOI DOI 10.1162/tacl_a_00115
   Tang X, 2014, ARXIV14043840
   ten Bosch L., 2007, P INTERSPEECH, P1481
   Tesar B, 1998, LINGUIST INQ, V29, P229, DOI 10.1162/002438998553734
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Thiolliere R., 2015, INTERSPEECH 2015
   THOMAS DG, 1981, CHILD DEV, V52, P798, DOI 10.2307/1129079
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tomasello M., 2003, CONSTRUCTING LANGUAG
   Trueswell JC, 2016, COGNITION, V148, P117, DOI 10.1016/j.cognition.2015.11.002
   Tsividis P. A., 2017, AAAI 2017 SPRING S S
   Tsuji S, 2014, PERSPECT PSYCHOL SCI, V9, P661, DOI 10.1177/1745691614552498
   Turing A., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Van Cleve JV, 2004, GENETICS, DISABILITY, AND DEAFNESS, pVII
   VanDam M, 2016, SEMIN SPEECH LANG, V37, P128, DOI 10.1055/s-0036-1580745
   Varadarajan B., 2008, P 46 ANN M ASS COMP, P165, DOI DOI 10.3115/1557690.1557736
   Versteegh M, 2016, SLTU 2016
   Versteegh M, 2015, INTERSPEECH 2015
   VILLIERS PA, 1972, J PSYCHOLINGUIST RES, V1, P299, DOI 10.1007/BF01067785
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wu Y., 2016, ARXIV160908144
   Xiong W., 2016, ARXIV161005256
   Xu D., 2008, WOCCI, P20
   Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111
   Yang C. D., 2002, KNOWLEDGE LEARNING N
   Yu C, 2007, PSYCHOL SCI, V18, P414, DOI 10.1111/j.1467-9280.2007.01915.x
NR 228
TC 11
Z9 11
U1 3
U2 49
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD APR
PY 2018
VL 173
BP 43
EP 59
DI 10.1016/j.cognition.2017.11.008
PG 17
WC Psychology, Experimental
SC Psychology
GA FW8HG
UT WOS:000425571700007
PM 29324240
DA 2021-02-24
ER

PT J
AU Vouloumanos, A
AF Vouloumanos, Athena
TI Voulez-vous jouer avec moi? Twelve-month-olds understand that foreign
   languages can communicate
SO COGNITION
LA English
DT Article
DE Language acquisition; Non-native language; Infant cognitive development;
   Communication; Speech perception
ID 1ST YEAR; PERCEPTUAL REORGANIZATION; SPEECH-PERCEPTION; LEXICAL TONE;
   INFANTS; DISCRIMINATION; EXPERIENCE; ACQUISITION; RHYTHM; LIFE
AB Infants understand that speech in their native language allows speakers to communicate. Is this understanding limited to their native language or does it extend to non-native languages with which infants have no experience? Twelve-month-old infants saw an actor, the Communicator, repeatedly select one of two objects. When the Communicator could no longer reach the target but a Recipient could, the Communicator vocalized a nonsense phrase either in English (infants' native language), Spanish (rhythmically different), or Russian (phonotactically different), or hummed (a non-speech vocalization). Across all three languages, native and non-native, but not humming, infants looked longer when the Recipient gave the Communicator the non-target object. Although, by 12 months, infants do not readily map non-native words to objects or discriminate most non-native speech contrasts, they understand that non-native languages can transfer information to others. Understanding language as a tool for communication extends beyond infants' native language: By 12 months, infants view language as a universal mechanism for transferring and acquiring new information.
C1 [Vouloumanos, Athena] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
RP Vouloumanos, A (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM athena.vouloumanos@nyu.edu
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   Development of the National Institutes of HealthUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD072018]; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD072018, R01HD072018, R01HD072018, R01HD072018,
   R01HD072018] Funding Source: NIH RePORTER
FX We thank all the parents and infants who participated in our study. We
   thank the members of the NYU infant cognition and communication lab,
   especially Christopher Cantwell and Casey Pitts, Kathey Silva and Elena
   Luchlcina. This project was supported by the Eunice Kennedy Shriver
   National Institute of Child Health and Human Development of the National
   Institutes of Health under Award Number R01HD072018.
CR Baillargeon R., 2005, BABY EXPT SOFTWARE P
   Beier JS, 2014, DEV PSYCHOL, V50, P889, DOI 10.1037/a0034171
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   CAMPOS JJ, 1992, PSYCHOL SCI, V3, P61, DOI 10.1111/j.1467-9280.1992.tb00259.x
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fisher C, 2002, COGNITION, V82, P259, DOI 10.1016/S0010-0277(01)00159-7
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Henderson AME, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00332
   Hollich G., 2008, SUPERCODER PROGRAM C
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kretch KS, 2013, CHILD DEV, V84, P226, DOI 10.1111/j.1467-8624.2012.01842.x
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   MacKenzie H, 2012, CHILD DEV, V83, P1129, DOI 10.1111/j.1467-8624.2012.01764.x
   Mandler JM, 2000, J COGN DEV, V1, P3, DOI 10.1207/S15327647JCD0101N_2
   Martin A, 2012, COGNITION, V123, P50, DOI 10.1016/j.cognition.2011.12.003
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2003, SPEECH COMMUN, V41, P233, DOI 10.1016/S0167-6393(02)00106-1
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Scott JC, 2013, DEV PSYCHOL, V49, P2102, DOI 10.1037/a0031981
   Siperstein G., 1970, 3 S OR SENS PERC MOU, P313
   Smith LB, 2000, BECOMING WORD LEARNE, P51, DOI [10.1093/acprof:oso/9780195130324.003.003, DOI 10.1093/ACPROF:OSO/9780195130324.001.0001]
   Thorgrimsson GB, 2015, INFANT BEHAV DEV, V39, P53, DOI 10.1016/j.infbeh.2015.02.002
   Tomasello M, 2002, COGNITION, V83, P207, DOI 10.1016/S0010-0277(01)00172-X
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Vouloumanos A, 2014, DEVELOPMENTAL SCI, V17, P872, DOI 10.1111/desc.12170
   Vouloumanos A, 2012, P NATL ACAD SCI USA, V109, P12933, DOI 10.1073/pnas.1121057109
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   Waxman S. R., 2002, BLACKWELL HDB CHILDH, P102, DOI DOI 10.1002/9780470996652.CH5
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Woodward AL, 1998, COGNITION, V69, P1, DOI 10.1016/S0010-0277(98)00058-4
NR 37
TC 6
Z9 6
U1 2
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD APR
PY 2018
VL 173
BP 87
EP 92
DI 10.1016/j.cognition.2018.01.002
PG 6
WC Psychology, Experimental
SC Psychology
GA FW8HG
UT WOS:000425571700010
PM 29358091
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Lin, JFL
   Imada, T
   Kuhl, PK
   Lin, FH
AF Lin, Jo-Fu Lotus
   Imada, Toshiaki
   Kuhl, Patricia K.
   Lin, Fa-Hsuan
TI Incongruent pitch cues are associated with increased activation and
   functional connectivity in the frontal areas
SO SCIENTIFIC REPORTS
LA English
DT Article
ID HUMAN AUDITORY-CORTEX; BOLD HEMODYNAMIC-RESPONSES; WORKING-MEMORY;
   RELATIVE PITCH; MUSICAL PITCH; HUMAN BRAIN; HESCHLS GYRUS; NEURAL BASIS;
   TONE CHROMA; PERCEPTION
AB Pitch plays a crucial role in music and speech perception. Pitch perception is characterized by multiple perceptual dimensions, such as pitch height and chroma. Information provided by auditory signals that are related to these perceptual dimensions can be either congruent or incongruent. To create conflicting cues for pitch perception, we modified Shepard tones by varying the pitch height and pitch chroma dimensions in either the same or opposite directions. Our behavioral data showed that most listeners judged pitch changes based on pitch chroma, instead of pitch height, when incongruent information was provided. The reliance on pitch chroma resulted in a stable percept of upward or downward pitch shift, rather than alternating between two different percepts. Across the incongruent and congruent conditions, consistent activation was found in the bilateral superior temporal and inferior frontal areas. In addition, significantly stronger activation was observed in the inferior frontal areas during the incongruent compared to congruent conditions. Enhanced functional connectivity was found between the left temporal and bilateral frontal areas in the incongruent than congruent conditions. Increased intra-hemispheric and inter-hemispheric connectivity was also observed in the frontal areas. Our results suggest the involvement of the frontal lobe in top-down and bottom-up processes to generate a stable percept of pitch change with conflicting perceptual cues.
C1 [Lin, Jo-Fu Lotus; Lin, Fa-Hsuan] Natl Taiwan Univ, Inst Biomed Engn, Taipei, Taiwan.
   [Imada, Toshiaki; Kuhl, Patricia K.] Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
   [Imada, Toshiaki; Kuhl, Patricia K.] Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.
RP Lin, FH (corresponding author), Natl Taiwan Univ, Inst Biomed Engn, Taipei, Taiwan.
EM fhlin@ntu.edu.tw
RI Lin, Fa-Hsuan/G-6988-2012
OI Lin, Fa-Hsuan/0000-0002-9539-1731
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [MOST 103-2628-B-002-002-MY3, MOST
   106-2314-B-002-141-MY3]; National Health Research Institute,
   TaiwanNational Health Research Institutes - Taiwan [NHRI-EX107-10727EI]
FX The authors thank the anonymous reviewers for their valuable comments
   and suggestions. The authors also thank Dr. Lynne Werner and Dr. Waka
   Fujisaki for inspiring discussions, Woan-Chyi Wang, Ruo-Ning Sun, and
   Dr. Shang-Yueh Tsai for assistance during data collection. This work was
   supported by the Ministry of Science and Technology, Taiwan (MOST
   103-2628-B-002-002-MY3, MOST 106-2314-B-002-141-MY3) and National Health
   Research Institute, Taiwan (NHRI-EX107-10727EI).
CR Aguirre GK, 1998, NEUROIMAGE, V8, P360, DOI 10.1006/nimg.1998.0369
   Allen EJ, 2017, J NEUROSCI, V37, P1284, DOI 10.1523/JNEUROSCI.2336-16.2016
   Allen EJ, 2014, J ACOUST SOC AM, V135, P1371, DOI 10.1121/1.4863269
   Bachem A, 1950, ACTA PSYCHOL, V7, P80, DOI 10.1016/0001-6918(50)90004-7
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Beckmann CF, 2003, NEUROIMAGE, V20, P1052, DOI 10.1016/S1053-8119(03)00435-X
   BURNS EM, 1978, J ACOUST SOC AM, V63, P456, DOI 10.1121/1.381737
   BURNS EM, 1981, PERCEPT PSYCHOPHYS, V30, P467, DOI 10.3758/BF03204843
   Caclin A, 2005, J ACOUST SOC AM, V118, P471, DOI 10.1121/1.1929229
   Cisler JM, 2014, NEUROIMAGE, V84, P1042, DOI 10.1016/j.neuroimage.2013.09.018
   Coffey EBJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152374
   DEMANY L, 1984, J ACOUST SOC AM, V76, P57, DOI 10.1121/1.391006
   DEUTSCH D, 1991, MUSIC PERCEPT, V8, P335
   DEUTSCH D, 1986, MUSIC PERCEPT, V3, P275
   Deutsch D., 2010, ACOUSTICS TODAY, V7, P8, DOI [DOI 10.1121/1.3488670, 10.1121/1.3488670]
   Deutsch D, 2008, J ACOUST SOC AM, V124, P589, DOI 10.1121/1.2931957
   Elmer S, 2015, J NEUROSCI, V35, P366, DOI 10.1523/JNEUROSCI.3009-14.2015
   Friston KJ, 1997, NEUROIMAGE, V6, P218, DOI 10.1006/nimg.1997.0291
   Gaab N, 2003, NEUROREPORT, V14, P2291, DOI 10.1097/00001756-200312190-00001
   GREY JM, 1977, J ACOUST SOC AM, V61, P1270, DOI 10.1121/1.381428
   Griffiths TD, 1999, NEUROREPORT, V10, P3825, DOI 10.1097/00001756-199912160-00019
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Handwerker DA, 2004, NEUROIMAGE, V21, P1639, DOI 10.1016/j.neuroimage.2003.11.029
   HOUTSMA AJM, 1991, J ACOUST SOC AM, V90, P1674, DOI 10.1121/1.401911
   Jonides J, 2005, CURR DIR PSYCHOL SCI, V14, P2, DOI 10.1111/j.0963-7214.2005.00323.x
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   KRUMHANSL CL, 1979, COGNITIVE PSYCHOL, V11, P346, DOI 10.1016/0010-0285(79)90016-1
   Kuriki S, 2016, HEARING RES, V339, P23, DOI 10.1016/j.heares.2016.06.004
   MCADAMS S, 1995, PSYCHOL RES-PSYCH FO, V58, P177, DOI 10.1007/BF00419633
   McDermott JH, 2008, PSYCHOL SCI, V19, P1263, DOI 10.1111/j.1467-9280.2008.02235.x
   McLaren DG, 2012, NEUROIMAGE, V61, P1277, DOI 10.1016/j.neuroimage.2012.03.068
   Micheyl C, 2010, J ACOUST SOC AM, V128, P1930, DOI 10.1121/1.3478786
   Moerel M, 2015, NEUROIMAGE, V106, P161, DOI 10.1016/j.neuroimage.2014.11.044
   Nebel K, 2005, HUM BRAIN MAPP, V24, P130, DOI 10.1002/hbm.20075
   Nichols T, 2005, NEUROIMAGE, V25, P653, DOI 10.1016/j.neuroimage.2004.12.005
   Peter B, 2015, J VOICE, V29, DOI 10.1016/j.jvoice.2014.06.011
   Petitti E. M., 18 INT C PHON SCI
   Pfordresher PQ, 2009, ATTEN PERCEPT PSYCHO, V71, P1385, DOI 10.3758/APP.71.6.1385
   POLLACK I, 1978, J ACOUST SOC AM, V63, P202, DOI 10.1121/1.381714
   Price CJ, 1997, NEUROIMAGE, V5, P261, DOI 10.1006/nimg.1997.0269
   Schneider P, 2005, NAT NEUROSCI, V8, P1241, DOI 10.1038/nn1530
   Schneider P, 2009, CONTEMP MUSIC REV, V28, P315, DOI 10.1080/07494460903404402
   Schonwiesner M, 2007, J NEUROPHYSIOL, V97, P2075, DOI 10.1152/jn.01083.2006
   Seither-Preisler A, 2007, J EXP PSYCHOL HUMAN, V33, P743, DOI 10.1037/0096-1523.33.3.743
   Seymour K, 2008, NEUROREPORT, V19, P1769, DOI 10.1097/WNR.0b013e328318ed82
   SHEPARD RN, 1982, PSYCHOL REV, V89, P305, DOI 10.1037/0033-295X.89.4.305
   SHEPARD RN, 1964, J ACOUST SOC AM, V36, P2346, DOI 10.1121/1.1919362
   Sheu YS, 2016, CORTEX, V85, P13, DOI 10.1016/j.cortex.2016.09.018
   Shimizu Y, 2007, BRAIN RES, V1186, P113, DOI 10.1016/j.brainres.2007.09.097
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   SMOORENBURG GF, 1970, J ACOUST SOC AM, V48, P924, DOI 10.1121/1.1912232
   Sterzer P, 2007, P NATL ACAD SCI USA, V104, P323, DOI 10.1073/pnas.0609006104
   TERHARDT E, 1974, J ACOUST SOC AM, V55, P1061, DOI 10.1121/1.1914648
   TERVANIEMI M, 1994, NEUROREPORT, V5, P844, DOI 10.1097/00001756-199403000-00027
   Tillmann B, 2003, COGNITIVE BRAIN RES, V16, P145, DOI 10.1016/S0926-6410(02)00245-8
   Trainor LJ, 2012, SPRINGER HANDB AUDIT, V42, P223, DOI 10.1007/978-1-4614-1421-6_8
   UEDA K, 1987, J ACOUST SOC AM, V82, P1193, DOI 10.1121/1.395255
   von Helmholtz H. L. F., 1885, SENSATIONS TONE
   Warren JD, 2003, P NATL ACAD SCI USA, V100, P10038, DOI 10.1073/pnas.1730682100
   Wendelken C, 2009, COGN AFFECT BEHAV NE, V9, P434, DOI 10.3758/CABN.9.4.434
   Woolrich M, 2008, NEUROIMAGE, V41, P286, DOI 10.1016/j.neuroimage.2008.02.042
   Woolrich MW, 2004, NEUROIMAGE, V21, P1732, DOI 10.1016/j.neuroimage.2003.12.023
   Worsley KJ, 2001, FUNCTIONAL MRI INTRO, P251, DOI DOI 10.1093/ACPROF:OSO/9780192630711.003.0014
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
NR 65
TC 0
Z9 0
U1 0
U2 1
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 26
PY 2018
VL 8
AR 5206
DI 10.1038/s41598-018-23287-5
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GA3NC
UT WOS:000428235200010
PM 29581445
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Katz, J
   Fricke, M
AF Katz, Jonah
   Fricke, Melinda
TI Auditory disruption improves word segmentation: A functional basis for
   lenition phenomena
SO GLOSSA-A JOURNAL OF GENERAL LINGUISTICS
LA English
DT Article
DE lenition; word segmentation; spirantization; statistical learning;
   phonetics; phonology
ID CLOSURE DURATION; CROSS-LANGUAGE; CUES; PERCEPTION; STOPS; VOICE
AB This paper presents evidence that spirantization, a cross-linguistically common lenition process, affects English listeners' ease of segmenting novel "words" in an artificial language. The cross-linguistically common spirantization pattern of initial stops and medial continuants (e.g. [gu beta a]) results in improved word segmentation compared to the inverse "anti-lenition" pattern of initial continuants and medial stops (e.g. [vuba]). The study also tests the effect of obstruent voicing, another common lenition pattern, but finds no significant differences in segmentation performance. There are several points of broader interest in these studies. Most of the phonetic factors influencing word segmentation in past studies have been language-specific and/or prosodic in nature: stress, intonation, final lengthening, etc. Spirantization, while often prosodically conditioned, is different from all of these patterns in that it concerns a segmental alternation. Moreover, the effects reported here are for speakers of a language, American English, that only sporadically displays spirantization, and not in the phonological contexts used in the experiment. This suggests that the results may reflect more general properties of speech perception and word boundary detection, rather than a perceptual processing strategy transferred directly from English. As such, the studies offer partial support for theories of lenition rooted in notions of perceptual-acoustic continuity and disruption.
C1 [Katz, Jonah] West Virginia Univ, Morgantown, WV 26506 USA.
   [Fricke, Melinda] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
RP Katz, J (corresponding author), West Virginia Univ, Morgantown, WV 26506 USA.
EM katzlinguist@gmail.com
OI Katz, Jonah/0000-0002-1057-7052
CR Armstrong BC, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0047
   Bagou Odile, 2002, SPEECH PROS AIX EN P
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BAUER L, 1988, J LINGUIST, V24, P381, DOI 10.1017/S002222670001183X
   Borgman Donald M., 1990, HDB AMAZONIAN LANGUA, V2, P15
   Bouavichith D, 2013, PHONETICA, V70, P182, DOI 10.1159/000355635
   Bouavichith Dominique, 2014, SEGMENTAL PROSODIC E
   Chong AJ, 2011, AUST J LINGUIST, V31, P473, DOI 10.1080/07268602.2011.625601
   COOPER FS, 1952, J ACOUST SOC AM, V24, P597, DOI 10.1121/1.1906940
   De Jong Kenneth, 2011, BLACKWELL COMPANION, P2711, DOI [10.1002/9781444335262.wbctp0113, DOI 10.1002/9781444335262.WBCTP0113]
   Donegan Patricia Jane, 1979, CURRENT APPROACHES P, P126
   Ennever T, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.18
   Fisher C, 1996, CHILD DEV, V67, P3192, DOI 10.1111/j.1467-8624.1996.tb01909.x
   Frank MC, 2010, COGNITION, V117, P107, DOI 10.1016/j.cognition.2010.07.005
   Gleitman L. R., 1982, LANG ACQUIS, P3
   Gurevich Naomi, 2003, FUNCTIONAL CONSTRAIN
   Harris John, 2003, P 15 INT C PHON SCI, V1, P281
   Haugen Einar, 1938, DIALECT NOTES, V6, P627
   Hayes Bruce, 1995, METRICAL STRESS THEO
   Hayes J. R., 1970, COGNITION DEV LANGUA, P221
   Honeybone P, 2008, STUD GENERAT GRAMM, V99, P9
   Hualde Jose Ignacio, 2011, LAB PHONOLOGY, V2, P301, DOI DOI 10.1515/LABPH0N.2011.011
   Hunyadi Laszlo, 2006, ARGUMENTUM, V2, P67
   Hyman Larry, 1972, PHONOLOGICAL STUDY F
   Jeon HS, 2013, J ACOUST SOC AM, V133, P3039, DOI 10.1121/1.4798663
   Johnson EK, 2001, J MEM LANG, V44, P548, DOI 10.1006/jmla.2000.2755
   Jusczyk PW, 1999, PERCEPT PSYCHOPHYS, V61, P1465, DOI 10.3758/BF03213111
   Kahn D., 1976, SYLLABLE BASED GEN E
   Katz J, 2016, PHONOLOGY, V33, P43, DOI 10.1017/S0952675716000038
   Kawahara S, 2006, LANGUAGE, V82, P536, DOI 10.1353/lan.2006.0146
   Keating P., 2006, SPEECH PRODUCTION MO, P167
   Kentner G, 2013, LINGUIST REV, V30, P277, DOI 10.1515/tlr-2013-0009
   Kim S., 2004, ROLE PROSODIC PHRASI
   Kingston John, 2008, SEL P 3 C LAB APPR S, P1
   Kirchner R., 1998, EFFORT BASED APPROAC
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   Ladd D. Robert, 2003, PAPERS LAB PHONOLOGY, P164
   Lavoie L., 2001, CONSONANT STRENGTH P
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lisker L, 1978, SR54 HASK LAB STAT R, P127
   LUCE PA, 1985, J ACOUST SOC AM, V78, P1949, DOI 10.1121/1.392651
   Mareschal D, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0057
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   NAKATANI LH, 1977, J ACOUST SOC AM, V62, P714, DOI 10.1121/1.381583
   Parker Steve, 2002, QUANTIFYING SONORITY
   Priva UC, 2017, LANGUAGE, V93, P569, DOI 10.1353/lan.2017.0037
   Romero Joaquin, 1996, GESTURAL ORG SPANISH
   Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Segeral P, 2008, STUD GENERAT GRAMM, V99, P131
   Sharf D. J., 1960, AM SPEECH, V35, P105, DOI DOI 10.2307/453733
   Sheldon D. R., 1973, J PHONETICS, V1, P339
   Smith JL, 2008, STUD GENERAT GRAMM, V99, P519
   Szigetvari P, 2008, STUD GENERAT GRAMM, V99, P93
   Trager George L., 1951, OUTLINE ENGLISH STRU
   Turk Alice, 1992, CORNELL WORKING PAP, V7, P103
   Tyler MD, 2009, J ACOUST SOC AM, V126, P367, DOI 10.1121/1.3129127
   UMEDA N, 1977, J ACOUST SOC AM, V61, P846, DOI 10.1121/1.381374
   Walter Mary Ann, 2007, REPETITION AVOIDANCE
   Warner N, 2011, J ACOUST SOC AM, V130, P1606, DOI 10.1121/1.3621306
   Wertheimer M., 1938, SOURCE BOOK GESTALT, P71, DOI DOI 10.1037/11496-005
   WIGHTMAN CW, 1992, J ACOUST SOC AM, V91, P1707, DOI 10.1121/1.402450
   ZUE VW, 1979, J ACOUST SOC AM, V66, P1039, DOI 10.1121/1.383323
NR 65
TC 3
Z9 3
U1 0
U2 2
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 2397-1835
J9 GLOSSA-UK
JI Glossa
PD MAR 23
PY 2018
VL 3
IS 1
AR 38
DI 10.5334/gjgl.443
PG 25
WC Linguistics; Language & Linguistics
SC Linguistics
GA GP5BQ
UT WOS:000440887800001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Yu, YH
   Shafer, VL
   Sussman, ES
AF Yu, Yan H.
   Shafer, Valerie L.
   Sussman, Elyse S.
TI The Duration of Auditory Sensory Memory for Vowel Processing:
   Neurophysiological and Behavioral Measures
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE sensory memory decay; vowel processing; mismatch negativity; late
   negativity; event-related potentials; speech perception; interstimulus
   interval; P3a novelty
ID EVENT-RELATED POTENTIALS; MISMATCH NEGATIVITY MMN; INVOLUNTARY
   ATTENTION; TONOTOPIC ORGANIZATION; SELECTIVE-ATTENTION; BRAIN
   POTENTIALS; RESPONSES REVEAL; BASIC RESEARCH; LANGUAGE; PERCEPTION
AB Speech perception behavioral research suggests that rates of sensory memory decay are dependent on stimulus properties at more than one level (e.g., acoustic level, phonemic level). The neurophysiology of sensory memory decay rate has rarely been examined in the context of speech processing. In a lexical tone study, we showed that long-term memory representation of lexical tone slows the decay rate of sensory memory for these tones. Here, we tested the hypothesis that long-term memory representation of vowels slows the rate of auditory sensory memory decay in a similar way to that of lexical tone. Event-related potential (ERP) responses were recorded to Mandarin non-words contrasting the vowels /i/vs. /u/ and /y/vs. /u/ from first-language (L1) Mandarin and L1 American English participants under short and long interstimulus interval (ISI) conditions (short ISI: an average of 575 ms, long ISI: an average of 2675 ms). Results revealed poorer discrimination of the vowel contrasts for English listeners than Mandarin listeners, but with different patterns for behavioral perception and neural discrimination. As predicted, English listeners showed the poorest discrimination and identification for the vowel contrast /y/ vs. /u/, and poorer performance in the long ISI condition. In contrast to Yu et al. (2017), however, we found no effect of ISI reflected in the neural responses, specifically the mismatch negativity (MMN), P3a and late negativity ERP amplitudes. We did see a language group effect, with Mandarin listeners generally showing larger MMN and English listeners showing larger P3a. The behavioral results revealed that native language experience plays a role in echoic sensory memory trace maintenance, but the failure to find an effect of ISI on the ERP results suggests that vowel and lexical tone memory traces decay at different rates.
   Highlights:
   We examined the interaction between auditory sensory memory decay and language experience.
   We compared MMN, P3a, LN and behavioral responses in short vs. long interstimulus intervals.
   We found that different from lexical tone contrast, MMN, P3a, and LN changes to vowel contrasts are not influenced by lengthening the ISI to 2.6 s.
   We also found that the English listeners discriminated the non-native vowel contrast with lower accuracy under the long ISI condition.
C1 [Yu, Yan H.] St Johns Univ, Dept Commun Sci & Disorders, Queens, NY 11439 USA.
   [Shafer, Valerie L.] CUNY, Grad Ctr, PhD Program Speech Language Hearing Sci, New York, NY USA.
   [Sussman, Elyse S.] Albert Einstein Coll Med, Dominick P Purpura Dept Neurosci, New York, NY USA.
RP Yu, YH (corresponding author), St Johns Univ, Dept Commun Sci & Disorders, Queens, NY 11439 USA.
EM yuy1@stjohns.edu
RI YU, YAN/Y-8898-2018
OI YU, YAN/0000-0001-6322-4800; Shafer, Valerie/0000-0001-8551-1878
FU Rees Dissertation Fellowship at the Graduate Center, City University of
   New York; National Institutes of HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA
   [HD46193, DC004263]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH &HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD046193, R01HD046193, R01HD046193, R01HD046193, R01HD046193,
   R01HD046193] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC004263, R01DC004263, R01DC004263, R01DC004263, R01DC004263,
   R01DC004263, R01DC004263, R01DC004263, R01DC004263, R01DC004263,
   R01DC004263, R01DC004263, R55DC004263, R01DC004263, R01DC004263,
   R01DC004263] Funding Source: NIH RePORTER
FX This project was funded by Rees Dissertation Fellowship to YY at the
   Graduate Center, City University of New York. This project was also
   funded by the National Institutes of Health (#HD46193 to VS and
   #DC004263 to ES).
CR AALTONEN O, 1987, BIOL PSYCHOL, V24, P197, DOI 10.1016/0301-0511(87)90002-0
   AALTONEN O, 1994, J ACOUST SOC AM, V96, P1489, DOI 10.1121/1.410291
   Addis L, 2010, GENES BRAIN BEHAV, V9, P545, DOI 10.1111/j.1601-183X.2010.00583.x
   Amenedo E, 2000, EUR J NEUROSCI, V12, P2570, DOI 10.1046/j.1460-9568.2000.00114.x
   Barry JG, 2008, BRAIN LANG, V104, P75, DOI 10.1016/j.bandl.2007.02.006
   Barry JG, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006270
   Bartha-Doering L, 2015, PSYCHOPHYSIOLOGY, V52, P1115, DOI 10.1111/psyp.12459
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bishop DVM, 2010, J NEUROSCI, V30, P15578, DOI 10.1523/JNEUROSCI.2217-10.2010
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   BOTTCHERGANDOR C, 1992, PSYCHOPHYSIOLOGY, V29, P546, DOI 10.1111/j.1469-8986.1992.tb02028.x
   Bouchard KE, 2014, J NEUROSCI, V34, P12662, DOI 10.1523/JNEUROSCI.1219-14.2014
   Bullmore ET, 2012, NAT REV NEUROSCI, V13, P336, DOI 10.1038/nrn3214
   Burnham D, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2514, DOI 10.1109/ICSLP.1996.607325
   Ceponiene R, 1998, EVOKED POTENTIAL, V108, P345, DOI 10.1016/S0168-5597(97)00081-6
   Ceponiene R, 1999, DEV PSYCHOL, V35, P709, DOI 10.1037//0012-1649.35.3.709
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Choudhury NA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138160
   COWAN N, 1984, PSYCHOL BULL, V96, P341, DOI 10.1037/0033-2909.96.2.341
   COWAN N, 1988, PSYCHOL BULL, V104, P163, DOI 10.1037/0033-2909.104.2.163
   CZIGLER I, 1992, BIOL PSYCHOL, V33, P195, DOI 10.1016/0301-0511(92)90031-O
   Datta H, 2010, J SPEECH LANG HEAR R, V53, P757, DOI 10.1044/1092-4388(2009/08-0123)
   Dehaene-Lambertz G, 1998, NEUROREPORT, V9, P1885, DOI 10.1097/00001756-199806010-00040
   DehaeneLambertz G, 1997, NEUROREPORT, V8, P919, DOI 10.1097/00001756-199703030-00021
   Escera C, 2000, AUDIOL NEURO-OTOL, V5, P151, DOI 10.1159/000013877
   Escera C, 1998, J COGNITIVE NEUROSCI, V10, P590, DOI 10.1162/089892998562997
   Escera C, 2001, EUR J NEUROSCI, V14, P877, DOI 10.1046/j.0953-816x.2001.01707.x
   Escera C., 2003, COGNITIVE NEUROSCIEN, P63
   Escera C, 2007, J PSYCHOPHYSIOL, V21, P251, DOI 10.1027/0269-8803.21.34.251
   Friedman D, 2001, NEUROSCI BIOBEHAV R, V25, P355, DOI 10.1016/S0149-7634(01)00019-7
   Gomes H, 1999, DEV PSYCHOL, V35, P294, DOI 10.1037/0012-1649.35.1.294
   Hao YC, 2018, LANG SPEECH, V61, P135, DOI 10.1177/0023830917717759
   Horvath J, 2008, BIOL PSYCHOL, V79, P139, DOI 10.1016/j.biopsycho.2008.04.001
   Horvath J, 2008, PSYCHOPHYSIOLOGY, V45, P60, DOI 10.1111/j.1469-8986.2007.00599.x
   Howie J.M., 1976, ACOUSTICAL STUDIES M
   Igor Pro, 2017, WAV
   IMADA T, 1993, ELECTROEN CLIN NEURO, V87, P144, DOI 10.1016/0013-4694(93)90120-K
   Javitt DC, 1998, EVOKED POTENTIAL, V108, P143, DOI 10.1016/S0168-5597(97)00073-7
   Kaan E, 2007, BRAIN RES, V1148, P113, DOI 10.1016/j.brainres.2007.02.019
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426
   Lang H., 1990, PSYCHOPHYSIOLOGICAL, P294
   Lee W-S., 2003, J INT PHON ASSOC, V33, P109, DOI DOI 10.1017/S0025100303001208
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   MANTYSALO S, 1987, BIOL PSYCHOL, V24, P183, DOI 10.1016/0301-0511(87)90001-9
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434
   Ortiz-Mantilla S, 2010, BRAIN RES, V1362, P78, DOI 10.1016/j.brainres.2010.09.031
   PANTEV C, 1988, ELECTROEN CLIN NEURO, V69, P160, DOI 10.1016/0013-4694(88)90211-8
   Patterson RD, 2002, NEURON, V36, P767, DOI 10.1016/S0896-6273(02)01060-7
   Penagos H, 2004, J NEUROSCI, V24, P6810, DOI 10.1523/JNEUROSCI.0383-04.2004
   Pinheiro J., 2017, NLME LINEAR NONLINEA, DOI DOI 10.5194/TC-10-2291-2016
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   POLICH J, 1988, J CLIN NEUROPHYSIOL, V5, P287, DOI 10.1097/00004691-198807000-00004
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   R Core Team, 2016, R LANG ENV STAT COMP
   Rinne T, 2006, BRAIN RES, V1077, P135, DOI 10.1016/j.brainres.2006.01.043
   Ritter W, 1999, PSYCHOPHYSIOLOGY, V36, P835
   ROMANI GL, 1982, SCIENCE, V216, P1339, DOI 10.1126/science.7079770
   RStudio Team, 2016, RSTUDIO INTEGRATED D
   SAMS M, 1993, J COGNITIVE NEUROSCI, V5, P363, DOI 10.1162/jocn.1993.5.3.363
   SAMS M, 1985, ELECTROEN CLIN NEURO, V62, P437, DOI 10.1016/0168-5597(85)90054-1
   SAMS M, 1983, BIOL PSYCHOL, V17, P41, DOI 10.1016/0301-0511(83)90065-0
   Schroger E, 1996, J COGNITIVE NEUROSCI, V8, P527, DOI 10.1162/jocn.1996.8.6.527
   Schroger E, 1998, COGNITIVE BRAIN RES, V7, P71, DOI 10.1016/S0926-6410(98)00013-5
   Schroger E, 1998, NEUROREPORT, V9, P3355, DOI 10.1097/00001756-199810260-00003
   Shafer VL, 2005, J COGNITIVE NEUROSCI, V17, P1168, DOI 10.1162/0898929054475217
   Shafer VL, 2004, COGNITIVE BRAIN RES, V18, P242, DOI 10.1016/j.cogbrainres.2003.10.007
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Shestakova A, 2003, CLIN NEUROPHYSIOL, V114, P1507, DOI 10.1016/S1388-2457(03)00134-2
   Shestakova A, 2004, COGNITIVE BRAIN RES, V21, P342, DOI 10.1016/j.cogbrainres.2004.06.011
   SQUIRES NK, 1975, ELECTROEN CLIN NEURO, V38, P387, DOI 10.1016/0013-4694(75)90263-1
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Strange W, 2009, J ACOUST SOC AM, V126, P1461, DOI 10.1121/1.3179666
   Sussman E, 2008, HEARING RES, V236, P61, DOI 10.1016/j.heares.2007.12.001
   Sussman E, 2003, PSYCHON B REV, V10, P630, DOI 10.3758/BF03196525
   Sussman E, 2004, HEARING RES, V190, P128, DOI 10.1016/S0378-5955(04)00016-4
   Talavage TM, 2004, J NEUROPHYSIOL, V91, P1282, DOI 10.1152/jn.01125.2002
   TIITINEN H, 1994, NEUROREPORT, V6, P190, DOI 10.1097/00001756-199412300-00048
   Wang XG, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00114
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   Winkler I, 2005, EXP PSYCHOL, V52, P3, DOI 10.1027/1618-3169.52.1.3
   Winkler I, 1996, J COGNITIVE NEUROSCI, V8, P403, DOI 10.1162/jocn.1996.8.5.403
   Winkler I, 1998, NEUROSCI LETT, V242, P49, DOI 10.1016/S0304-3940(98)00022-6
   Yago E, 2001, NEUROREPORT, V12, P4093, DOI 10.1097/00001756-200112210-00046
   Yu YH, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00095
   Zevin JD, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00212
NR 96
TC 2
Z9 2
U1 0
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAR 22
PY 2018
VL 9
AR 335
DI 10.3389/fpsyg.2018.00335
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA GA1KV
UT WOS:000428075400001
PM 29623054
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wedekind, A
   Tavora-Vieira, D
   Rajan, GP
AF Wedekind, Andre
   Tavora-Vieira, Dayse
   Rajan, Gunesh P.
TI Cortical auditory evoked responses in cochlear implant users with
   early-onset single-sided deafness: indicators of the development of
   bilateral auditory pathways
SO NEUROREPORT
LA English
DT Article
DE binaural hearing; cochlear implant; cortical auditory evoked potentials;
   single-sided deafness
ID BRAIN-STEM RESPONSES; UNILATERAL DEAFNESS; SPEECH-PERCEPTION; POTENTIALS
   CAEPS; AURAL PREFERENCE; CHILDREN; HEARING; MATURATION; CORTEX;
   PLASTICITY
AB Cochlear implantation (CI) for early-onset single-sided deafness (SSD) provides a unique insight into the development and cortical reorganization of binaural pathways. This case series aimed to investigate the impact of duration of deafness on CI outcomes as measured by cortical evoked auditory potentials (CAEPs). Four adults with early-onset SSD were studied after CI. The adults had a duration of deafness of 22, 24, 42, and 38 years before implantation. CAEPs and speech perception in noise were used to investigate binaural cortical pathways and function. Our four patients lost their hearing at the ages of 3, 6, 5, and 6 (S1, S2, S3, and S4, respectively). CAEPs were present bilaterally in S2, S3, and S4. S1's, who had the least experience with a CI, cortical responses at 1 month after CI activation showed cortical responses from the CI ipsilateral pathway, but no responses from the CI contralateral pathway. At 3 and 6 months, S1 showed significant cortical responses from the CI contralateral pathway for two speech tokens. An improvement in speech perception in noise testing was observed in all four participants. This case series indicates that long duration of deafness for early-onset SSD is not a contraindication for CI and may not impact the long-term outcomes in this population. The electrical stimulation from the CI integrates with the normal-hearing ear to produce bilateral cortical projections and functional improvement in speech perception in noise. These early data provide surprisingly positive results and call for larger scale research to be carried out.
C1 [Wedekind, Andre; Tavora-Vieira, Dayse; Rajan, Gunesh P.] Univ Western Australia, Sch Surg, Dept Otolaryngol Head & Neck Surg, Perth, WA, Australia.
   [Tavora-Vieira, Dayse; Rajan, Gunesh P.] Fiona Stanley Hosp, Murdoch, WA, Australia.
RP Wedekind, A (corresponding author), Med Audiol Serv, 51 Colin St, Perth 6005, Australia.
EM andre.wedekind@gmail.com
OI Tavora-Vieira, Dayse/0000-0001-6249-7268
CR Arndt S, 2015, AUDIOL NEURO-OTOL, V20, P21, DOI 10.1159/000380744
   Arndt S, 2010, OTOL NEUROTOL, V31, P67, DOI 10.1097/MAO.0b013e3181c0e972
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bilecen D, 2000, NEUROLOGY, V54, P765, DOI 10.1212/WNL.54.3.765
   Buechner A, 2010, OTOL NEUROTOL, V31, P1381, DOI 10.1097/MAO.0b013e3181e3d353
   Carter L, 2013, J AM ACAD AUDIOL, V24, P807, DOI 10.3766/jaaa.24.9.5
   Chadha NK, 2011, OTOL NEUROTOL, V32, P1057, DOI 10.1097/MAO.0b013e3182267de7
   de Heyning PV, 2008, ANN OTO RHINOL LARYN, V117, P645, DOI 10.1177/000348940811700903
   Dorman MF, 2007, J COMMUN DISORD, V40, P284, DOI 10.1016/j.jcomdis.2007.03.007
   Finke M, 2016, AUDIOL NEURO-OTOL, V21, P305, DOI 10.1159/000452123
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Firszt JB, 2012, OTOL NEUROTOL, V33, P1339, DOI 10.1097/MAO.0b013e318268d52d
   Golding M, 2009, INT J AUDIOL, V48, P833, DOI 10.3109/14992020903140928
   Gordon K. A., 2011, COCHLEAR IMPLANTS IN, V12, P14
   Gordon K, 2015, PEDIATRICS, V136, P141, DOI 10.1542/peds.2014-3520
   Gordon KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00719
   Gordon KA, 2013, BRAIN, V136, P1609, DOI 10.1093/brain/awt052
   Gordon KA, 2009, OTOL NEUROTOL, V30, P319, DOI 10.1097/MAO.0b013e31819a8f4c
   GORGA MP, 1989, J SPEECH HEAR RES, V32, P281, DOI 10.1044/jshr.3202.281
   Graham John, 2009, Cochlear Implants Int, V10, P119, DOI 10.1179/cim.2009.10.3.119
   Green KMJ, 2005, HEARING RES, V205, P184, DOI 10.1016/j.heares.2005.03.016
   Kral A, 2002, CEREB CORTEX, V12, P797, DOI 10.1093/cercor/12.8.797
   Kral A, 2015, AUDIOL NEURO-OTOL, V20, P7, DOI 10.1159/000380742
   Kral A, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00093
   Kral A, 2013, BRAIN, V136, P180, DOI 10.1093/brain/aws305
   KUTTNER K, 1991, HNO, V39, P32
   LASKA M, 1992, EUR ARCH OTO-RHINO-L, V249, P325, DOI 10.1007/BF00179382
   Lee JS, 2003, J NUCL MED, V44, P1435
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   O'Neil JN, 2010, J COMP NEUROL, V518, P2382, DOI 10.1002/cne.22339
   Peters BR, 2007, OTOL NEUROTOL, V28, P649, DOI 10.1097/01.mao.0000281807.89938.60
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Ponton CW, 2001, HEARING RES, V154, P32, DOI 10.1016/S0378-5955(01)00214-3
   Punte AK, 2011, COCHLEAR IMPLANTS IN, V12, pS1 29
   SALAMY A, 1984, J CLIN NEUROPHYSIOL, V1, P293, DOI 10.1097/00004691-198407000-00003
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Schramm D, 2002, OTOL NEUROTOL, V23, P698, DOI 10.1097/00129492-200209000-00016
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Stelzig Yvonne, 2011, J Med Case Rep, V5, P343, DOI 10.1186/1752-1947-5-343
   Stuermer KJ, 2017, INT J PEDIATR OTORHI, V95, P39, DOI 10.1016/j.ijporl.2017.01.029
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tavora-Vieira D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193081
   Tavora-Vieira D, 2015, OTOL NEUROTOL, V36, P430, DOI 10.1097/MAO.0000000000000707
   Tavora-Vieira D, 2015, OTOL NEUROTOL, V36, P235, DOI 10.1097/MAO.0000000000000677
   Tavora-Vieira D, 2013, NEUROREPORT, V24, P724, DOI 10.1097/WNR.0b013e3283642a93
   Van Deun L, 2009, AUDIOL NEURO-OTOL, V14, P240, DOI 10.1159/000190402
   Vermeire K, 2009, AUDIOL NEURO-OTOL, V14, P163, DOI 10.1159/000171478
   Wang XC, 2016, SCI REP-UK, V6, DOI 10.1038/srep25811
NR 48
TC 4
Z9 4
U1 0
U2 4
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0959-4965
EI 1473-558X
J9 NEUROREPORT
JI Neuroreport
PD MAR 21
PY 2018
VL 29
IS 5
BP 408
EP 416
DI 10.1097/WNR.0000000000000984
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA GA2UM
UT WOS:000428181100012
PM 29489587
DA 2021-02-24
ER

PT J
AU Liu, LQ
   Ong, JH
   Tuninetti, A
   Escudero, P
AF Liu, Liquan
   Ong, Jia Hoong
   Tuninetti, Alba
   Escudero, Paola
TI One Way or Another: Evidence for Perceptual Asymmetry in Pre-attentive
   Learning of Non-native Contrasts
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE electroencephalography; mismatch negativity; speech processing; tone;
   pitch direction; learning; perceptual asymmetry
ID MISMATCH NEGATIVITY MMN; SPEECH-PERCEPTION; TONE PERCEPTION;
   NATIVE-LANGUAGE; LEXICAL TONE; VOWEL PERCEPTION; MANDARIN TONES; HUMAN
   BRAIN; CATEGORICAL PERCEPTION; PHONETIC PERCEPTION
AB Research investigating listeners' neural sensitivity to speech sounds has largely focused on segmental features. We examined Australian English listeners' perception and learning of a supra-segmental feature, pitch direction in a non-native tonal contrast, using a passive oddball paradigm and electroencephalography. The stimuli were two contours generated from naturally produced high-level and high-falling tones in Mandarin Chinese, differing only in pitch direction (Liu and Kager, 2014). While both contours had similar pitch onsets, the pitch offset of the falling contour was lower than that of the level one. The contrast was presented in two orientations (standard and deviant reversed) and tested in two blocks with the order of block presentation counterbalanced. Mismatch negativity (MMN) responses showed that listeners discriminated the non-native tonal contrast only in the second block, reflecting indications of learning through exposure during the first block. In addition, listeners showed a later MMN peak for their second block of test relative to listeners who did the same block first, suggesting linguistic (as opposed to acoustic) processing or a misapplication of perceptual strategies from the first to the second block. The results also showed a perceptual asymmetry for change in pitch direction: listeners who encountered a falling tone deviant in the first block had larger frontal MMN amplitudes than listeners who encountered a level tone deviant in the first block. The implications of our findings for second language speech and the developmental trajectory for tone perception are discussed.
C1 [Liu, Liquan] Western Sydney Univ, Sch Social Sci & Psychol, Penrith, NSW, Australia.
   [Liu, Liquan; Tuninetti, Alba; Escudero, Paola] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.
   [Liu, Liquan; Ong, Jia Hoong; Tuninetti, Alba; Escudero, Paola] Australian Res Council, Ctr Excellence Dynam Language, Canberra, ACT, Australia.
   [Ong, Jia Hoong] Nanyang Technol Univ, Sch Humanities, Div Linguist & Multilingual Studies, Singapore, Singapore.
RP Liu, LQ (corresponding author), Western Sydney Univ, Sch Social Sci & Psychol, Penrith, NSW, Australia.; Liu, LQ (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.; Liu, LQ (corresponding author), Australian Res Council, Ctr Excellence Dynam Language, Canberra, ACT, Australia.
EM l.liu@westernsydney.edu.au
RI Escudero, Paola/Q-5310-2019
OI Escudero, Paola/0000-0002-8071-7663; Liu, Liquan/0000-0001-8671-5098;
   Ong, Jia Hoong/0000-0003-1503-8311; Tuninetti, Alba/0000-0002-0087-7756
FU Transdisciplinary and Innovation Research Grant from the Australian
   Research Council (ARC) Centre of Excellence for the Dynamics of Language
   [CE140100041]; ARC Centre of Excellence for the Dynamics of
   LanguageAustralian Research Council
FX This project was funded by a Transdisciplinary and Innovation Research
   Grant from the Australian Research Council (ARC) Centre of Excellence
   for the Dynamics of Language [CE140100041], which was awarded to LL. JO,
   AT, and PE's work and the publication of this research were also
   supported by the ARC Centre of Excellence for the Dynamics of Language.
CR Best C. T., 1994, DEV SPEECH PERCEPTIO, V167, P233
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2009, PRAAT DOING PHONETIC
   Bonte ML, 2005, CLIN NEUROPHYSIOL, V116, P2765, DOI 10.1016/j.clinph.2005.08.012
   Brandmeyer A, 2012, NEUROREPORT, V23, P653, DOI 10.1097/WNR.0b013e32835542cd
   Brown-Schmidt S, 2004, J PSYCHOLINGUIST RES, V33, P103, DOI 10.1023/B:JOPR.0000017223.98667.10
   Burnham D., 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI [10.1017/S0142716414000496, DOI 10.1017/S0142716414000496]
   Burnham D, 2015, PSYCHOL MUSIC, V43, P881, DOI 10.1177/0305735614546359
   Cabrera L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01290
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Chen A, 2016, LANG COGN NEUROSCI, V31, P751, DOI 10.1080/23273798.2016.1156715
   Chen A, 2015, LANG SCI, V48, P62, DOI 10.1016/j.langsci.2014.12.002
   Cheng YY, 2013, DEV NEUROPSYCHOL, V38, P281, DOI 10.1080/87565641.2013.799672
   Cheour M, 2002, NEUROSCI LETT, V325, P187, DOI 10.1016/S0304-3940(02)00269-0
   Colin C, 2009, CLIN NEUROPHYSIOL, V120, P51, DOI 10.1016/j.clinph.2008.10.002
   Content A., 2011, P 17 INT C PHON SCI
   Cornell SA, 2013, J EXP PSYCHOL HUMAN, V39, P757, DOI 10.1037/a0030862
   Cruttenden A, 1997, INTONATION, DOI [10.1017/CBO9781139166973, DOI 10.1017/CBO9781139166973]
   D'Imperio M., 1997, P EUROSPEECH 97, V1, P251
   de Jonge M.J.I., 2015, P 18 INT C PHON SCI
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dittinger E, 2016, J COGNITIVE NEUROSCI, V28, P1584, DOI 10.1162/jocn_a_00997
   Escera C, 1998, J COGNITIVE NEUROSCI, V10, P590, DOI 10.1162/089892998562997
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   ESCUDERO P., 2005, THESIS, P348
   Escudero P, 2014, COGNITION, V133, P408, DOI 10.1016/j.cognition.2014.07.002
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL206, DOI 10.1121/1.3629144
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Gandour J, 2004, NEUROIMAGE, V23, P344, DOI 10.1016/j.neuroimage.2004.06.004
   Gandour J, 1998, NEUROREPORT, V9, P2115, DOI 10.1097/00001756-199806220-00038
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gandour J, 2000, J COGNITIVE NEUROSCI, V12, P207, DOI 10.1162/089892900561841
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Gaskell MG, 2003, J PHONETICS, V31, P447, DOI 10.1016/S0095-4470(03)00012-3
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Hestvik A, 2016, BRAIN LANG, V152, P28, DOI 10.1016/j.bandl.2015.10.007
   Hirst D., 1998, INTONATION SYSTEMS S
   Horvath J, 2008, PSYCHOPHYSIOLOGY, V45, P60, DOI 10.1111/j.1469-8986.2007.00599.x
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   HUME E, 2001, ROLE SPEECH PERCEPTI, P3
   Ikeda K, 2002, NEUROSCI LETT, V321, P133, DOI 10.1016/S0304-3940(01)02408-9
   Kaan E, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-53
   KRAUS N, 1995, EAR HEARING, V16, P19, DOI 10.1097/00003446-199502000-00003
   KRAUS N, 1995, J COGNITIVE NEUROSCI, V7, P25, DOI 10.1162/jocn.1995.7.1.25
   Kriengwatana BP, 2017, J SPEECH LANG HEAR R, V60, P1088, DOI 10.1044/2016_JSLHR-H-16-0050
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kuipers JR, 2012, DEV COGN NEUROS-NETH, V2, P97, DOI 10.1016/j.dcn.2011.08.002
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Lany J, 2013, COMPREHENSIVE DEVELOPMENTAL NEUROSCIENCE: NEURAL CIRCUIT DEVELOPMENT AND FUNCTION IN THE HEALTHY AND DISEASED BRAIN, P231, DOI 10.1016/B978-0-12-397267-5.00034-0
   Law SP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054396
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   LINDAU M, 1986, J ACOUST SOC AM, V80, P757, DOI 10.1121/1.393950
   Lipski SC, 2012, PSYCHOPHYSIOLOGY, V49, P638, DOI 10.1111/j.1469-8986.2011.01347.x
   Liu L, 2014, EFFECTS BILINGUALISM
   Liu L., 2017, LANG LINGUIST, V18
   Liu L, 2017, RISK, RELIABILITY AND SAFETY: INNOVATING THEORY AND PRACTICE, P10
   Liu LQ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00117
   Liu LQ, 2017, J EXP CHILD PSYCHOL, V164, P192, DOI 10.1016/j.jecp.2017.05.013
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Liu LQ, 2016, INT J BILINGUAL, V20, P335, DOI 10.1177/1367006914566082
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Liu R, 2011, J COGNITIVE NEUROSCI, V23, P683, DOI 10.1162/jocn.2009.21392
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Maddieson Ian, 2005, WORLD ATLAS LANGUAGE, P58
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   MYERS S, 1999, P 14 INT C PHON SCI, P1981
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Ong JH, 2017, J EXP PSYCHOL LEARN, V43, P150, DOI 10.1037/xlm0000286
   Ong JH, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01189
   Peter V, 2016, SCI REP-UK, V6, DOI 10.1038/srep34273
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   Politzer-Ahles S, 2016, J EXP PSYCHOL HUMAN, V42, P1547, DOI 10.1037/xhp0000242
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Ramachers S, 2018, J CHILD LANG, V45, P290, DOI 10.1017/S0305000917000228
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   SAMS M, 1984, PSYCHOPHYSIOLOGY, V21, P434, DOI 10.1111/j.1469-8986.1984.tb00223.x
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Schluter K, 2016, LANG COGN NEUROSCI, V31, P728, DOI 10.1080/23273798.2016.1151058
   Schluter KT, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00746
   Shafer VL, 2011, J PHONETICS, V39, P527, DOI 10.1016/j.wocn.2010.11.010
   Shafer VL, 2004, COGNITIVE BRAIN RES, V18, P242, DOI 10.1016/j.cogbrainres.2003.10.007
   Shi RS, 2017, INFANCY, V22, P790, DOI 10.1111/infa.12191
   Shi RS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01117
   Shtyrov Y, 2002, NEUROREPORT, V13, P521, DOI 10.1097/00001756-200203250-00033
   Singh L, 2018, CHILD DEV, V89, pe397, DOI 10.1111/cdev.12852
   Singh L, 2016, J PHONETICS, V55, P109, DOI 10.1016/j.wocn.2015.12.005
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   Sun KC, 2012, J EAST ASIAN LINGUIS, V21, P305, DOI 10.1007/s10831-012-9092-9
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   Tsuji S, 2015, COGNITION, V134, P252, DOI 10.1016/j.cognition.2014.10.009
   Tuninetti A, 2017, BRAIN LANG, V174, P42, DOI 10.1016/j.bandl.2017.07.001
   Tuninetti A, 2015, Q J EXP PSYCHOL, V68, P568, DOI 10.1080/17470218.2014.961934
   Tyler MD, 2014, DEV PSYCHOBIOL, V56, P210, DOI 10.1002/dev.21195
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Wang Y, 2003, J COGNITIVE NEUROSCI, V15, P1019, DOI 10.1162/089892903770007407
   Werker JF, 2002, INFANT BEHAV DEV, V25, P121, DOI 10.1016/S0163-6383(02)00093-0
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   Wichmann A., 2000, INTONATION TEXT DISC
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Wu Xianghua, 2008, J CHINESE LANG COMPU, V18, P175
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Xu YS, 2006, NEUROREPORT, V17, P1601, DOI 10.1097/01.wnr.0000236865.31705.3a
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip Moira, 2002, TONE, DOI [10.1017/CBO9781139164559, DOI 10.1017/CBO9781139164559]
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
   Zerbian S, 2010, LANG LINGUIST COMPAS, V4, P874, DOI 10.1111/j.1749-818x.2010.00233.x
NR 125
TC 3
Z9 3
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAR 20
PY 2018
VL 9
AR 162
DI 10.3389/fpsyg.2018.00162
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA FZ8WH
UT WOS:000427890700001
PM 29615941
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Yu, ZY
   Schwieter, JW
AF Yu, Ziying
   Schwieter, John W.
TI Recognizing the Effects of Language Mode on the Cognitive Advantages of
   Bilingualism
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE language mode; language activation; cognitive benefits of bilingualism;
   language control; multilingualism
ID INTERLINGUAL HOMOGRAPHS; CONTEXT; INTERFERENCE; RECOGNITION; ACTIVATION
AB For bilinguals, it is argued that a cognitive advantage can be linked to the constant management and need for conflict resolution that occurs when the two languages are co-activated (Bialystok, 2015). Language mode (Grosjean, 1998, 2001) is a significant variable that defines and shapes the language experiences of bilinguals and consequently, the cognitive advantages of bilingualism. Previous work, however, has not sufficiently tested the effects of language mode on the bilingual experience. In this brief conceptual analysis, we discuss the significance of language mode in bilingual work on speech perception, production, and reading. We offer possible explanations for conflicting findings and ways in which future work should control for its modulating effects.
C1 [Yu, Ziying] Fudan Univ, Dept English Language & Literature, Shanghai, Peoples R China.
   [Yu, Ziying] Univ Calif Santa Barbara, Dept Linguist, Santa Barbara, CA 93106 USA.
   [Schwieter, John W.] Wilfrid Laurier Univ, Language Acquisit Multilingualism & Cognit Lab, Waterloo, ON, Canada.
   [Schwieter, John W.] Univ Calif Santa Barbara, Bilingualism Translat & Cognit Lab, Santa Barbara, CA 93106 USA.
RP Yu, ZY (corresponding author), Fudan Univ, Dept English Language & Literature, Shanghai, Peoples R China.; Yu, ZY (corresponding author), Univ Calif Santa Barbara, Dept Linguist, Santa Barbara, CA 93106 USA.; Schwieter, JW (corresponding author), Wilfrid Laurier Univ, Language Acquisit Multilingualism & Cognit Lab, Waterloo, ON, Canada.; Schwieter, JW (corresponding author), Univ Calif Santa Barbara, Bilingualism Translat & Cognit Lab, Santa Barbara, CA 93106 USA.
EM ziying_yu@umail.ucsb.edu; jschwieter@wlu.ca
CR Abutalebi J, 2007, J NEUROLINGUIST, V20, P242, DOI 10.1016/j.jneuroling.2006.10.003
   Barac R, 2014, EARLY CHILD RES Q, V29, P699, DOI 10.1016/j.ecresq.2014.02.003
   Bialystok E, 2015, CHILD DEV PERSPECT, V9, P117, DOI 10.1111/cdep.12116
   Bialystok E, 2012, TRENDS COGN SCI, V16, P240, DOI 10.1016/j.tics.2012.03.001
   Blom E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00552
   Boukadi M, 2015, CAN J EXP PSYCHOL, V69, P297, DOI 10.1037/cep0000063
   Canseco-Gonzalez E, 2010, LANG COGNITIVE PROC, V25, P669, DOI 10.1080/01690960903474912
   Colome A, 2001, J MEM LANG, V45, P721
   Colome A, 2010, J EXP PSYCHOL LEARN, V36, P96, DOI 10.1037/a0017677
   Costa A, 2000, J EXP PSYCHOL LEARN, V26, P1283, DOI 10.1037//0278-7393.26.5.1283
   de Groot AMB, 2000, Q J EXP PSYCHOL-A, V53, P397, DOI 10.1080/713755891
   Dijkstra T., 2000, BILING-LANG COGN, V3, P69, DOI DOI 10.1017/S1366728900000146
   Dijkstra Ton, 2005, HDB BILINGUALISM PSY, P179
   Dunn AL, 2014, INT J BILINGUAL, V18, P605, DOI 10.1177/1367006912454509
   Duyck W, 2007, J EXP PSYCHOL LEARN, V33, P663, DOI 10.1037/0278-7393.33.4.663
   Elston-Guttler KE, 2005, COGNITIVE BRAIN RES, V25, P57, DOI 10.1016/j.cogbrainres.2005.04.007
   Festman J., 2015, CAMBRIDGE HDB BILING, P527, DOI DOI 10.1017/CBO9781107447257
   Green D. W., 1998, BILING-LANG COGN, V1, P67, DOI [10.1017/S1366728998000133, DOI 10.1017/S1366728998000133]
   Green DW, 2014, LANG COGN NEUROSCI, V29, P499, DOI 10.1080/23273798.2014.882515
   Green DW, 2013, J COGN PSYCHOL, V25, P515, DOI 10.1080/20445911.2013.796377
   Green DW, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00103
   Grosjean F., 1998, BILING-LANG COGN, V1, P131, DOI DOI 10.1017/S136672899800025X
   GROSJEAN F, 2001, ONE MIND 2 LANGUAGES, P1
   Hermans D, 2011, LANG COGNITIVE PROC, V26, P1687, DOI 10.1080/01690965.2010.530411
   Hilchey MD, 2011, PSYCHON B REV, V18, P625, DOI 10.3758/s13423-011-0116-7
   Incera S, 2018, INT J BILINGUAL, V22, P88, DOI 10.1177/1367006916644688
   Jared D, 2001, J MEM LANG, V44, P2, DOI 10.1006/jmla.2000.2747
   Khachatryan E, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167194
   Lemhofer K, 2004, MEM COGNITION, V32, P533, DOI 10.3758/BF03195845
   Lemhofer K, 2009, EXP PSYCHOL, V56, P41, DOI 10.1027/1618-3169.56.1.41
   Luk G, 2013, J COGN PSYCHOL, V25, P605, DOI 10.1080/20445911.2013.795574
   Marian V., 2003, BILING-LANG COGN, V6, P97, DOI DOI 10.1017/S1366728903001068
   Paap KR, 2015, CORTEX, V69, P265, DOI 10.1016/j.cortex.2015.04.014
   Prior A, 2011, J INT NEUROPSYCH SOC, V17, P682, DOI 10.1017/S1355617711000580
   Schwieter J. W, 2016, COGNITIVE CONTROL CO, V2, P193
   SOARES C, 1984, MEM COGNITION, V12, P380, DOI 10.3758/BF03198298
   Spivey MJ, 1999, PSYCHOL SCI, V10, P281, DOI 10.1111/1467-9280.00151
   van Hell JG, 2002, PSYCHON B REV, V9, P780, DOI 10.3758/BF03196335
   van Heuven WJB, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00374
NR 39
TC 5
Z9 5
U1 2
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAR 20
PY 2018
VL 9
AR 366
DI 10.3389/fpsyg.2018.00366
PG 6
WC Psychology, Multidisciplinary
SC Psychology
GA FZ8WO
UT WOS:000427891400001
PM 29615949
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Elmer, S
   Albrecht, J
   Valizadeh, SA
   Francois, C
   Rodriguez-Fornells, A
AF Elmer, Stefan
   Albrecht, Joelle
   Valizadeh, Seyed Abolfazl
   Francois, Clement
   Rodriguez-Fornells, Antoni
TI Theta Coherence Asymmetry in the Dorsal Stream of Musicians Facilitates
   Word Learning
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SEMANTIC MEMORY NETWORKS; WHITE-MATTER PLASTICITY; VERBAL
   WORKING-MEMORY; HUMAN BRAIN; EPISODIC MEMORY; CONDUCTION APHASIA;
   PREFRONTAL CORTEX; SPEECH-PERCEPTION; AUDITORY-CORTEX; MOTOR THEORY
AB Word learning constitutes a human faculty which is dependent upon two anatomically distinct processing streams projecting from posterior superior temporal (pST) and inferior parietal (IP) brain regions toward the prefrontal cortex (dorsal stream) and the temporal pole (ventral stream). The ventral stream is involved in mapping sensory and phonological information onto lexical-semantic representations, whereas the dorsal stream contributes to sound-to-motor mapping, articulation, complex sequencing in the verbal domain, and to how verbal information is encoded, stored, and rehearsed from memory. In the present source-based EEG study, we evaluated functional connectivity between the IP lobe and Broca's area while musicians and non-musicians learned pseudowords presented in the form of concatenated auditory streams. Behavioral results demonstrated that musicians outperformed non-musicians, as reflected by a higher sensitivity index (d'). This behavioral superiority was paralleled by increased left-hemispheric theta coherence in the dorsal stream, whereas non-musicians showed stronger functional connectivity in the right hemisphere. Since no between-group differences were observed in a passive listening control condition nor during rest, results point to a task-specific intertwining between musical expertise, functional connectivity, and word learning.
C1 [Elmer, Stefan; Francois, Clement; Rodriguez-Fornells, Antoni] Bellvitge Biomed Res Inst, Cognit & Brain Plast Grp, Barcelona 08097, Spain.
   [Albrecht, Joelle; Valizadeh, Seyed Abolfazl] Univ Zurich, Inst Psychol, Div Neuropsychol, ARGZ, Zurich, Switzerland.
   [Valizadeh, Seyed Abolfazl] Swiss Fed Inst Technol, Inst Robot & Intelligence Syst, Sensory Motor Syst Lab, Zurich, Switzerland.
   [Francois, Clement; Rodriguez-Fornells, Antoni] Univ Barcelona, Dept Cognit Dev & Educ Psychol, Campus Bellvitge, Barcelona 08097, Spain.
   [Rodriguez-Fornells, Antoni] ICREA, Barcelona 08010, Spain.
   [Francois, Clement] Hosp St Joan de Deu, Inst Recerca Pediat, Barcelona, Spain.
RP Elmer, S (corresponding author), Bellvitge Biomed Res Inst, Cognit & Brain Plast Grp, Barcelona 08097, Spain.
EM s.elmer@psychologie.uzh.ch
RI Valizadeh, Seyed Abolfazl/S-5593-2017; Elmer, Stefan/F-7840-2011;
   Francois, Clement/F-7133-2013
OI Valizadeh, Seyed Abolfazl/0000-0003-0856-8541; Elmer,
   Stefan/0000-0003-1721-450X; Francois, Clement/0000-0003-2271-6942
FU Swiss National Science Foundation (SNF)Swiss National Science Foundation
   (SNSF) [320030_ 163149]; Spanish MINECO project [PSI2015-69132P];
   Catalan Government (Generalitat de Catalunya)Generalitat de Catalunya
   [PERIS2017]
FX This research was supported by the Swiss National Science Foundation
   (SNF, grant nr. 320030_ 163149 to Lutz Jancke). CF was supported by a
   Spanish MINECO project (PSI2015-69132P) and by the Catalan Government
   (Generalitat de Catalunya, PERIS2017). We would like to thank Lutz
   Jancke for having provided the necessary infrastructure and technology
   for the study as well as for his financial support. No conflicts of
   interest are declared.
CR Albouy P, 2017, NEURON, V94, P193, DOI 10.1016/j.neuron.2017.03.015
   Anderson S, 2010, J AM ACAD AUDIOL, V21, P575, DOI 10.3766/jaaa.21.9.3
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Bakker I, 2015, J COGNITIVE NEUROSCI, V27, P1286, DOI 10.1162/jocn_a_00801
   Balaguer RD, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001175
   Baldo JV, 2008, BRAIN LANG, V105, P134, DOI 10.1016/j.bandl.2007.12.007
   Bangert M, 2006, EUR J NEUROSCI, V24, P1832, DOI 10.1111/j.1460-9568.2006.05031.x
   Bastiaansen MCM, 2002, NEUROSCI LETT, V323, P13, DOI 10.1016/S0304-3940(01)02535-6
   Bastos AM, 2016, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00175
   Ben-Soussan TD, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055023
   Bengtsson SL, 2005, NAT NEUROSCI, V8, P1148, DOI 10.1038/nn1516
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Berti S, 2006, EXP PSYCHOL, V53, P111, DOI 10.1027/1618-3169.53.2.111
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bornkessel-Schlesewsky I, 2013, BRAIN LANG, V125, P60, DOI 10.1016/j.bandl.2013.01.010
   Brett M, 2002, NAT REV NEUROSCI, V3, P243, DOI 10.1038/nrn756
   Buchsbaum BR, 2011, BRAIN LANG, V119, P119, DOI 10.1016/j.bandl.2010.12.001
   Cabeza R, 2002, NEUROIMAGE, V16, P317, DOI 10.1006/nimg.2002.1063
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Catani M, 2002, NEUROIMAGE, V17, P77, DOI 10.1006/nimg.2002.1136
   Catani M, 2007, P NATL ACAD SCI USA, V104, P17163, DOI 10.1073/pnas.0702116104
   Chen YY, 2017, J COGNITIVE NEUROSCI, V29, P183, DOI 10.1162/jocn_a_01033
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   DAMASIO H, 1980, BRAIN, V103, P337, DOI 10.1093/brain/103.2.337
   de Diego-Balaguer R, 2011, J COGNITIVE NEUROSCI, V23, P3105, DOI 10.1162/jocn.2011.21636
   Deschamps I, 2014, NEUROPSYCHOLOGIA, V53, P39, DOI 10.1016/j.neuropsychologia.2013.10.015
   Dittinger E., 2016, J COGNITIVE NEUROSCI
   Dittinger E., 2017, HUM BRAIN MAPP
   Dittinger E, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00233
   Eickhoff SB, 2009, PHILOS T R SOC A, V367, P2399, DOI 10.1098/rsta.2008.0287
   Elmer S., 2013, CORTEX
   Elmer S, 2017, NEUROPSYCHOLOGIA, V104, P64, DOI 10.1016/j.neuropsychologia.2017.08.001
   Elmer S, 2016, BRAIN STRUCT FUNCT, V221, P331, DOI 10.1007/s00429-014-0910-x
   Elmer S, 2015, J NEUROSCI, V35, P366, DOI 10.1523/JNEUROSCI.3009-14.2015
   Elmer S, 2012, CEREB CORTEX, V22, P650, DOI 10.1093/cercor/bhr142
   Engel A, 2014, HUM BRAIN MAPP, V35, P2483, DOI 10.1002/hbm.22343
   Fedorenko E, 2012, CURR BIOL, V22, P2059, DOI 10.1016/j.cub.2012.09.011
   Foster NEV, 2013, NEUROIMAGE, V75, P27, DOI 10.1016/j.neuroimage.2013.02.044
   Foster NEV, 2010, CEREB CORTEX, V20, P1350, DOI 10.1093/cercor/bhp199
   Francois C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101340
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Francois C, 2011, CEREB CORTEX, V21, P2357, DOI 10.1093/cercor/bhr022
   Frei E, 2001, HUM BRAIN MAPP, V14, P152, DOI 10.1002/hbm.1049
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Garrido MI, 2007, P NATL ACAD SCI USA, V104, P20961, DOI 10.1073/pnas.0706274105
   George EM, 2011, NEUROPSYCHOLOGIA, V49, P1083, DOI 10.1016/j.neuropsychologia.2011.02.001
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golestani N, 2002, NEURON, V35, P997, DOI 10.1016/S0896-6273(02)00862-0
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013
   Halwani GF, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00156
   Helmstadter C., 2001, VERBALER LERN MERKFA
   Herman AB, 2013, J NEUROSCI, V33, P5439, DOI 10.1523/JNEUROSCI.1472-12.2013
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Holler-Wallscheid MS, 2017, P NATL ACAD SCI USA, V114, pE830, DOI 10.1073/pnas.1601983114
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Imfeld A, 2009, NEUROIMAGE, V46, P600, DOI 10.1016/j.neuroimage.2009.02.025
   Inostroza M, 2013, J NEUROSCI, V33, P17749, DOI 10.1523/JNEUROSCI.0957-13.2013
   Jancke L, 2012, ANN NY ACAD SCI, V1252, P246, DOI 10.1111/j.1749-6632.2011.06416.x
   Jancke L, 2009, RESTOR NEUROL NEUROS, V27, P521, DOI 10.3233/RNN-2009-0519
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Kerns JG, 2006, NEUROIMAGE, V33, P399, DOI 10.1016/j.neuroimage.2006.06.012
   Klein C, 2016, HUM BRAIN MAPP, V37, P536, DOI 10.1002/hbm.23045
   Klingberg T, 1997, CEREB CORTEX, V7, P465, DOI 10.1093/cercor/7.5.465
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kuhnis J, 2014, J COGNITIVE NEUROSCI, V26, P2750, DOI 10.1162/jocn_a_00674
   Kuhnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Kuhnis J, 2013, BRAIN TOPOGR, V26, P110, DOI 10.1007/s10548-012-0237-y
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   Lehmann D, 2006, J PHYSIOLOGY-PARIS, V99, P29, DOI 10.1016/j.jphysparis.2005.06.005
   Li JM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085373
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lopez-Barroso D, 2013, P NATL ACAD SCI USA, V110, P13168, DOI 10.1073/pnas.1301696110
   Macher K, 2014, J NEUROSCI, V34, P5029, DOI 10.1523/JNEUROSCI.0106-14.2014
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Marie C, 2012, CORTEX, V48, P447, DOI 10.1016/j.cortex.2010.11.006
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P294, DOI 10.1162/jocn.2010.21413
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Mazziotta J, 2001, PHILOS T R SOC B, V356, P1293, DOI 10.1098/rstb.2001.0915
   Mestres-Misse A, 2008, J COGNITIVE NEUROSCI, V20, P2153, DOI 10.1162/jocn.2008.20150
   Meyer L, 2015, CORTEX, V71, P205, DOI 10.1016/j.cortex.2015.06.027
   Meyer L, 2014, NEUROPSYCHOLOGIA, V61, P190, DOI 10.1016/j.neuropsychologia.2014.06.014
   Meyer L, 2012, NEUROIMAGE, V62, P1987, DOI 10.1016/j.neuroimage.2012.05.052
   Mulert C, 2004, NEUROIMAGE, V22, P83, DOI 10.1016/j.neuroimage.2003.10.051
   Munte TF, 2002, NAT REV NEUROSCI, V3, P473, DOI 10.1038/nrn843
   Newman SD, 2001, HUM BRAIN MAPP, V14, P39, DOI 10.1002/hbm.1040
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Nilakantan AS, 2017, CURR BIOL, V27, P465, DOI 10.1016/j.cub.2016.12.042
   Nolte G, 2004, CLIN NEUROPHYSIOL, V115, P2292, DOI 10.1016/j.clinph.2004.04.029
   Oechslin MS, 2018, CEREB CORTEX, V28, P1209, DOI 10.1093/cercor/bhx033
   Oechslin MS, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/neuro.09.076.2009
   Oswald W. D., 1987, HANDANWEISUNG
   Otten LJ, 2002, NAT NEUROSCI, V5, P1339, DOI 10.1038/nn967
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Pantev C, 2001, NEUROREPORT, V12, P169, DOI 10.1097/00001756-200101220-00041
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P91
   Pascual-Marqui RD, 2011, PHILOS T R SOC A, V369, P3768, DOI 10.1098/rsta.2011.0081
   Paulesu E, 2009, NEUROIMAGE, V45, P1368, DOI 10.1016/j.neuroimage.2008.12.043
   Polania R, 2012, CURR BIOL, V22, P1314, DOI 10.1016/j.cub.2012.05.021
   Price CJ, 2000, J ANAT, V197, P335, DOI 10.1046/j.1469-7580.2000.19730335.x
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rilling JK, 2008, NAT NEUROSCI, V11, P426, DOI 10.1038/nn2072
   Rodriguez-Fornells A, 2009, PHILOS T R SOC B, V364, P3711, DOI 10.1098/rstb.2009.0130
   Rottschy C, 2012, NEUROIMAGE, V60, P830, DOI 10.1016/j.neuroimage.2011.11.050
   Rugg MD, 2002, PHILOS T R SOC B, V357, P1097, DOI 10.1098/rstb.2002.1102
   Rugg MD, 2008, PROG BRAIN RES, V169, P339, DOI 10.1016/S0079-6123(07)00021-0
   Sarnthein J, 1998, P NATL ACAD SCI USA, V95, P7092, DOI 10.1073/pnas.95.12.7092
   SCHLAUG G, 1995, NEUROPSYCHOLOGIA, V33, P1047, DOI 10.1016/0028-3932(95)00045-5
   Schneider P, 2005, ANN NY ACAD SCI, V1060, P387, DOI 10.1196/annals.1360.033
   Scholz S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171913
   Schon D, 2010, NEUROIMAGE, V51, P450, DOI 10.1016/j.neuroimage.2010.02.023
   Schulze K, 2012, P NATL ACAD SCI USA, V109, P7121, DOI 10.1073/pnas.1204717109
   Schulze K, 2012, ANN NY ACAD SCI, V1252, P229, DOI 10.1111/j.1749-6632.2012.06447.x
   Sierpowska J, 2017, J NEUROSURG, V126, P435, DOI 10.3171/2016.2.JNS151592
   SIMON JR, 1969, J EXP PSYCHOL, V81, P174, DOI 10.1037/h0027448
   Sinclair B, 2015, NEUROIMAGE, V121, P243, DOI 10.1016/j.neuroimage.2015.07.048
   Stam CJ, 2012, NEUROIMAGE, V62, P1415, DOI 10.1016/j.neuroimage.2012.05.050
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Steele CJ, 2013, J NEUROSCI, V33, P1282, DOI 10.1523/JNEUROSCI.3578-12.2013
   Takashima A B. I, 2016, BRAIN LANGUAGE
   Takashima A, 2017, BRAIN LANG, V167, P44, DOI 10.1016/j.bandl.2016.05.009
   Takashima A, 2014, NEUROIMAGE, V84, P265, DOI 10.1016/j.neuroimage.2013.08.023
   Tervaniemi M, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01900
   Tervaniemi M, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00496
   Thompson PM, 2001, NAT NEUROSCI, V4, P1253, DOI 10.1038/nn758
   Tian X, 2016, CORTEX, V77, P1, DOI 10.1016/j.cortex.2016.01.002
   Waldmann HC, 2008, DIAGNOSTICA, V54, P202, DOI 10.1026/0012-1924.54.4.202
   Ward LM, 2003, TRENDS COGN SCI, V7, P553, DOI 10.1016/j.tics.2003.10.012
   Weiss S, 2005, INT J PSYCHOPHYSIOL, V57, P129, DOI 10.1016/j.ijpsycho.2005.03.013
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Wong PCM, 2017, NEUROPSYCHOLOGIA, V98, P192, DOI 10.1016/j.neuropsychologia.2016.10.002
   Zuk J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099868
NR 137
TC 3
Z9 3
U1 3
U2 11
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 15
PY 2018
VL 8
AR 4565
DI 10.1038/s41598-018-22942-1
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FZ3AQ
UT WOS:000427458300001
PM 29545619
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Liu, LQ
   Kager, R
AF Liu, Liquan
   Kager, Rene
TI Monolingual and Bilingual Infants' Ability to Use Non-native Tone for
   Word Learning Deteriorates by the Second Year After Birth
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE label-object mapping; lexical tone; bilingualism; interpretive
   narrowing; perceptual assimilation
ID MODIFIED MANDARIN TONES; LEXICAL-TONE; SPEECH-PERCEPTION; PHONETIC
   DETAIL; NATIVE LANGUAGE; 1ST YEAR; VOCABULARY DEVELOPMENT;
   DISCRIMINATION; ENGLISH; SOUNDS
AB Previous studies reported a non-native word learning advantage for bilingual infants at around 18 months. We investigated developmental changes in infant interpretation of sounds that aid in object mapping. Dutch monolingual and bilingual (exposed to Dutch and a second non-tone-language) infants' word learning ability was examined on two novel label-object pairings using syllables differing in Mandarin tones as labels (flat vs. falling). Infants aged 14-15 months, regardless of language backgrounds, were sensitive to violations in the label-objects pairings when lexical tones were switched compared to when they were the same as habituated. Conversely at 17-18 months, neither monolingual nor bilingual infants demonstrated learning. Linking with existing literature, infants' ability to associate non-native tones with meanings may be related to tonal acoustic properties and/or perceptual assimilation to native prosodic categories. These findings provide new insights into the relation between infant tone perception, learning, and interpretative narrowing from a developmental perspective.
C1 [Liu, Liquan] Western Sydney Univ, Sch Social Sci & Psychol, Sydney, NSW, Australia.
   [Liu, Liquan; Kager, Rene] Univ Utrecht, Utrecht Inst Linguist OTS, Utrecht, Netherlands.
   [Liu, Liquan] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
   [Liu, Liquan] Australian Res Council, Ctr Excellence Dynam Language, Canberra, ACT, Australia.
RP Liu, LQ (corresponding author), Western Sydney Univ, Sch Social Sci & Psychol, Sydney, NSW, Australia.; Liu, LQ (corresponding author), Univ Utrecht, Utrecht Inst Linguist OTS, Utrecht, Netherlands.; Liu, LQ (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.; Liu, LQ (corresponding author), Australian Res Council, Ctr Excellence Dynam Language, Canberra, ACT, Australia.
EM l.liu@westernsydney.edu.au
OI Liu, Liquan/0000-0001-8671-5098; Kager, Rene/0000-0002-5811-839X
FU Utrecht Institute of Linguistics, Utrecht University; School of Social
   Sciences and Psychology, Western Sydney University
FX LL received an international Ph.D. grant from Utrecht Institute of
   Linguistics, Utrecht University to carry out this research, and a
   Start-up grant from School of Social Sciences and Psychology, Western
   Sydney University for open access publication.
CR Albareda-Castellot B, 2011, DEVELOPMENTAL SCI, V14, P395, DOI 10.1111/j.1467-7687.2010.00989.x
   Anderson JL, 2003, LANG SPEECH, V46, P155, DOI 10.1177/00238309030460020601
   Bergelson E, 2013, COGNITION, V127, P391, DOI 10.1016/j.cognition.2013.02.011
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Bernhardt B. M., 2007, FIRST LANG, V27, P315, DOI DOI 10.1177/0142723707081652
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bialystok E, 2010, BILING-LANG COGN, V13, P525, DOI 10.1017/S1366728909990423
   Bijeljac-Babic R, 2009, INFANT BEHAV DEV, V32, P476, DOI 10.1016/j.infbeh.2009.06.003
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Burnham D., 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI [10.1017/S0142716414000496, DOI 10.1017/S0142716414000496]
   Burnham D, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02190
   Burnham D, 2015, PSYCHOL MUSIC, V43, P881, DOI 10.1177/0305735614546359
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Byers-Heinlein K, 2013, BILING-LANG COGN, V16, P198, DOI 10.1017/S1366728912000417
   Byers-Heinlein K, 2013, BILING-LANG COGN, V16, P32, DOI 10.1017/S1366728912000120
   Byers-Heinlein K, 2009, DEVELOPMENTAL SCI, V12, P815, DOI 10.1111/j.1467-7687.2009.00902.x
   Cabrera L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01290
   Cabrera L, 2014, J ACOUST SOC AM, V136, P877, DOI 10.1121/1.4887444
   Chen A, 2015, LANG SCI, V48, P62, DOI 10.1016/j.langsci.2014.12.002
   Conboy BT, 2006, DEVELOPMENTAL SCI, V9, pF1, DOI 10.1111/j.1467-7687.2005.00453.x
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   De Houwer A, 2014, APPL PSYCHOLINGUIST, V35, P1189, DOI 10.1017/S0142716412000744
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Fennell CT, 2007, CHILD DEV, V78, P1510, DOI 10.1111/j.1467-8624.2007.01080.x
   Fennell CT, 2012, INFANCY, V17, P339, DOI 10.1111/j.1532-7078.2011.00080.x
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Friedrich M, 2004, J COGNITIVE NEUROSCI, V16, P1465, DOI 10.1162/0898929042304705
   Gandour J, 2000, J COGNITIVE NEUROSCI, V12, P207, DOI 10.1162/089892900561841
   Gauthier K, 2011, CHILD DEV, V82, P887, DOI 10.1111/j.1467-8624.2011.01578.x
   Grosjean F., 2010, BILINGUAL, DOI [10.4159/9780674056459, DOI 10.4159/9780674056459]
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Hay J., 2012, 37 BOST U C LANG DEV
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   HIRSHPASEK K, 2000, BECOMING WORD LEARNE, P136, DOI DOI 10.1093/ACPROF:OSO/9780195130324.003.006
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   Jongman A, 2017, J ACOUST SOC AM, V142, pEL163, DOI 10.1121/1.4995526
   Junker DA, 2002, AM J SPEECH-LANG PAT, V11, P381, DOI 10.1044/1058-0360(2002/042)
   Jusczyk PW, 1997, SCIENCE, V277, P1984, DOI 10.1126/science.277.5334.1984
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Kaan E, 2007, BRAIN RES, V1148, P113, DOI 10.1016/j.brainres.2007.02.019
   Kaan E, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-53
   Kaushanskaya M, 2009, PSYCHON B REV, V16, P705, DOI 10.3758/PBR.16.4.705
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lee CY, 2008, J PHONETICS, V36, P537, DOI 10.1016/j.wocn.2008.01.002
   Lee CY, 2010, LANG SPEECH, V53, P217, DOI 10.1177/0023830909357160
   Liu L., 2017, IS IT WISE RAISE YOU
   Liu L, 2017, RISK, RELIABILITY AND SAFETY: INNOVATING THEORY AND PRACTICE, P10
   Liu LQ, 2017, DUTCH J APPL LINGUIS, V6, P41, DOI 10.1075/dujal.6.1.03liu
   Liu LQ, 2017, J EXP CHILD PSYCHOL, V164, P192, DOI 10.1016/j.jecp.2017.05.013
   Liu LQ, 2017, INT J MULTILING, V14, P366, DOI 10.1080/14790718.2016.1216120
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Liu LQ, 2016, INT J BILINGUAL, V20, P335, DOI 10.1177/1367006914566082
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Liu LQ, 2011, PROC ANN BUCLD, P404
   MacKenzie H, 2012, CHILD DEV, V83, P1129, DOI 10.1111/j.1467-8624.2012.01764.x
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P249, DOI 10.1111/j.1467-7687.2010.00975.x
   Mani N, 2008, DEVELOPMENTAL SCI, V11, P53, DOI 10.1111/j.1467-7687.2007.00645.x
   Marchman VA, 2010, J CHILD LANG, V37, P817, DOI 10.1017/S0305000909990055
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Mattock K, 2010, DEVELOPMENTAL SCI, V13, P229, DOI 10.1111/j.1467-7687.2009.00891.x
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Namy LL, 2001, INFANCY, V2, P73, DOI 10.1207/S15327078IN0201_5
   Namy LL, 1998, CHILD DEV, V69, P295, DOI 10.1111/j.1467-8624.1998.tb06189.x
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   PEARSON BZ, 1994, LANG LEARN, V44, P617, DOI 10.1111/j.1467-1770.1994.tb00633.x
   PEARSON BZ, 1993, LANG LEARN, V43, P93, DOI 10.1111/j.1467-1770.1993.tb00174.x
   PEARSON BZ, 1995, J CHILD LANG, V22, P345, DOI 10.1017/S030500090000982X
   Petitto L.-A., 2003, LEARNING LANGUAGES, V8, P5
   Ramachers S, 2018, J CHILD LANG, V45, P290, DOI 10.1017/S0305000917000228
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Saffran J, 2014, LANG LEARN, V64, P106, DOI 10.1111/lang.12057
   Sansavini A, 1997, DEV PSYCHOL, V33, P3, DOI 10.1037/0012-1649.33.1.3
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Shi RS, 2017, INFANCY, V22, P790, DOI 10.1111/infa.12191
   Shi RS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01117
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   Singh L, 2018, CHILD DEV, V89, pE183, DOI 10.1111/cdev.12747
   Singh L, 2018, CHILD DEV, V89, pe397, DOI 10.1111/cdev.12852
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Singh L, 2012, COGNITION, V124, P128, DOI 10.1016/j.cognition.2012.05.008
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Soderstrom M, 2011, INFANT BEHAV DEV, V34, P107, DOI 10.1016/j.infbeh.2010.10.003
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swain M., 1972, THESIS
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Thordardottir E., 2006, J MULTILINGUAL COMMU, V4, P1, DOI [10.1177/1367006911403202, DOI 10.1080/14769670500215647]
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   TSAO FM, 2000, 12 BIENN INT C INF S
   Tsushima T., 1994, P 3 INT C SPOK LANG
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Veenker T. J. G., 2007, COMPUTER PROGRAM
   Vihman MM, 2007, APPL PSYCHOLINGUIST, V28, P475, DOI 10.1017/S0142716407070269
   VIHMAN MM, 1985, J CHILD LANG, V12, P297, DOI 10.1017/S0305000900006450
   Watson TL, 2014, DEV PSYCHOBIOL, V56, P1454, DOI 10.1002/dev.21243
   Werker J. F., 2009, HDB CROSS CULTURAL D, P89
   Werker JF, 2008, TRENDS COGN SCI, V12, P144, DOI 10.1016/j.tics.2008.01.008
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Woodward AL, 1999, CHILD DEV, V70, P65, DOI 10.1111/1467-8624.00006
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip Moira, 2002, TONE, DOI [10.1017/CBO9781139164559, DOI 10.1017/CBO9781139164559]
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
NR 122
TC 7
Z9 7
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAR 15
PY 2018
VL 9
AR 117
DI 10.3389/fpsyg.2018.00117
PG 12
WC Psychology, Multidisciplinary
SC Psychology
GA FZ4BC
UT WOS:000427535100001
PM 29599730
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Billig, AJ
   Davis, MH
   Carlyon, RP
AF Billig, Alexander J.
   Davis, Matthew H.
   Carlyon, Robert P.
TI Neural Decoding of Bistable Sounds Reveals an Effect of Intention on
   Perceptual Organization
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE auditory streaming; intention; MEG; multivariate classification;
   perceptual organization; stream segregation
ID AUDITORY STREAM SEGREGATION; BRAIN POTENTIALS; SELECTIVE-ATTENTION;
   TEMPORAL DYNAMICS; SPEECH-PERCEPTION; SCENE ANALYSIS; CORTEX;
   REPRESENTATIONS; DISCRIMINATION; INTEGRATION
AB Auditory signals arrive at the ear as a mixture that the brain must decompose into distinct sources based to a large extent on acoustic properties of the sounds. An important question concerns whether listeners have voluntary control over how many sources they perceive. This has been studied using pure high (H) and low (L) tones presented in the repeating pattern HLH-HLH-, which can form a bistable percept heard either as an integrated whole (HLH-) or as segregated into high (H-H-) and low (-L-) sequences. Although instructing listeners to try to integrate or segregate sounds affects reports of what they hear, this could reflect a response bias rather than a perceptual effect. We had human listeners (15 males, 12 females) continuously report their perception of such sequences and recorded neural activity using MEG. During neutral listening, a classifier trained on patterns of neural activity distinguished between periods of integrated and segregated perception. In other conditions, participants tried to influence their perception by allocating attention either to the whole sequence or to a subset of the sounds. They reported hearing the desired percept for a greater proportion of time than when listening neutrally. Critically, neural activity supported these reports; stimulus-locked brain responses in auditory cortex were more likely to resemble the signature of segregation when participants tried to hear segregation than when attempting to perceive integration. These results indicate that listeners can influence how many sound sources they perceive, as reflected in neural responses that track both the input and its perceptual organization.
C1 [Billig, Alexander J.; Davis, Matthew H.; Carlyon, Robert P.] Univ Cambridge, Cognit & Brain Sci Unit, MRC, Cambridge CB2 7EF, England.
RP Billig, AJ (corresponding author), UCL Ear Inst, 332 Grays Inn Rd, London WC1X 8EE, England.
EM ajbillig@gmail.com
RI Billig, Alexander J/AAI-1871-2019
OI Billig, Alexander J/0000-0002-4531-8616; Davis,
   Matt/0000-0003-2239-0778; Carlyon, Robert/0000-0002-6166-501X
FU Medical Research CouncilUK Research & Innovation (UKRI)Medical Research
   Council UK (MRC) [1223833] Funding Source: researchfish; Medical
   Research CouncilUK Research & Innovation (UKRI)Medical Research Council
   UK (MRC)European Commission [MC_UU_00005/3, MC_UU_00005/5] Funding
   Source: Medline
CR Ahveninen J, 2011, P NATL ACAD SCI USA, V108, P4182, DOI 10.1073/pnas.1016134108
   Billig AJ, 2016, J EXP PSYCHOL HUMAN, V42, P339, DOI 10.1037/xhp0000146
   Billig AJ, 2013, CURR BIOL, V23, P1585, DOI 10.1016/j.cub.2013.06.042
   Bode S, 2017, DECISION DECODING TO
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Carlyon RP, 2010, NEUROPHYSIOLOGICAL BASES OF AUDITORY PERCEPTION, P507, DOI 10.1007/978-1-4419-5686-6_47
   Carlyon RP, 2003, PERCEPTION, V32, P1393, DOI 10.1068/p5035
   Carlyon RP, 2001, J EXP PSYCHOL HUMAN, V27, P115, DOI 10.1037/0096-1523.27.1.115
   Cusack R, 2005, J COGNITIVE NEUROSCI, V17, P641, DOI 10.1162/0898929053467541
   DAI HP, 1991, J ACOUST SOC AM, V89, P2837, DOI 10.1121/1.400721
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Denham S. L., 2013, LEARN PERCEPT, V5, P73, DOI DOI 10.1556/LP.5.2013.SUPPL2.6
   DIVENYI PL, 1977, PERCEPT PSYCHOPHYS, V21, P125, DOI 10.3758/BF03198716
   Farkas D, 2016, J ACOUST SOC AM, V139, P1762, DOI 10.1121/1.4945720
   Firestone C, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X15000965
   Fishman YI, 2001, HEARING RES, V151, P167, DOI 10.1016/S0378-5955(00)00224-0
   Fodor J., 1983, MODULARITY MIND
   Fritz JB, 2007, HEARING RES, V229, P186, DOI 10.1016/j.heares.2007.01.009
   Gandras K, 2017, NEUROSCIENC IN PRESS
   Green D. M., 1966, SIGNAL DETECTION THE
   Gross S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00221
   Gutschalk A, 2005, J NEUROSCI, V25, P5382, DOI 10.1523/JNEUROSCI.0347-05.2005
   Gutschalk A, 2014, HEARING RES, V307, P98, DOI 10.1016/j.heares.2013.08.003
   Haufe S, 2014, NEUROIMAGE, V87, P96, DOI 10.1016/j.neuroimage.2013.10.067
   Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736
   Hill KT, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00158
   Hill KT, 2011, BMC NEUROSCI, V12, DOI 10.1186/1471-2202-12-85
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Kashino M, 2012, PHILOS T R SOC B, V367, P977, DOI 10.1098/rstb.2011.0370
   Kogo N, 2015, VISION RES, V106, P7, DOI 10.1016/j.visres.2014.10.029
   Kondo HM, 2009, J NEUROSCI, V29, P12695, DOI 10.1523/JNEUROSCI.1549-09.2009
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   Lupyan G, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00553
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Micheyl C, 2010, JARO-J ASSOC RES OTO, V11, P709, DOI 10.1007/s10162-010-0227-2
   Mill RW, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002925
   Moore BCJ, 2012, PHILOS T R SOC B, V367, P919, DOI 10.1098/rstb.2011.0355
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   ORNE MT, 1962, AM PSYCHOL, V17, P776, DOI 10.1037/h0043424
   Pressnitzer D, 2006, CURR BIOL, V16, P1351, DOI 10.1016/j.cub.2006.05.054
   Puvvada KC, 2017, J NEUROSCI, V37, P9189, DOI 10.1523/JNEUROSCI.0938-17.2017
   Pylyshyn Z, 1999, BEHAV BRAIN SCI, V22, P341, DOI 10.1017/S0140525X99002022
   Rankin J, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004555
   Reichert C, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00116
   Schadwinkel S, 2011, J NEUROPHYSIOL, V105, P1977, DOI 10.1152/jn.00461.2010
   Snyder JS, 2009, PSYCHOPHYSIOLOGY, V46, P1208, DOI 10.1111/j.1469-8986.2009.00870.x
   Snyder JS, 2006, J COGNITIVE NEUROSCI, V18, P1, DOI 10.1162/089892906775250021
   Spielmann M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00534
   Spielmann MI, 2014, PSYCHOL RES-PSYCH FO, V78, P361, DOI 10.1007/s00426-014-0547-7
   Sussman E, 1999, PSYCHOPHYSIOLOGY, V36, P22, DOI 10.1017/S0048577299971056
   Sussman E, 2002, COGNITIVE BRAIN RES, V13, P393, DOI 10.1016/S0926-6410(01)00131-8
   Sussman ES, 2014, BRAIN TOPOGR, V27, P553, DOI 10.1007/s10548-013-0326-6
   Szalardy O, 2013, BIOL PSYCHOL, V93, P97, DOI 10.1016/j.biopsycho.2013.01.015
   Szalardy O, 2013, PSYCHOPHYSIOLOGY, V50, P1239, DOI 10.1111/psyp.12139
   van Ee R, 2005, VISION RES, V45, P41, DOI 10.1016/j.visres.2004.07.030
   van Noorden L. P. A. S, 1975, TEMPORAL COHERENCE P
   Wilbertz G, 2017, NEUROSCI CONSCIOUS, V3, P1, DOI 10.1093/nc/nix013
   Winkler I, 2006, EUR J NEUROSCI, V24, P625, DOI 10.1111/j.1460-9568.2006.04925.x
NR 60
TC 7
Z9 7
U1 0
U2 4
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
J9 J NEUROSCI
JI J. Neurosci.
PD MAR 14
PY 2018
VL 38
IS 11
BP 2844
EP 2853
DI 10.1523/JNEUROSCI.3022-17.2018
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA FZ6ES
UT WOS:000427690900016
PM 29440556
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Borghini, G
   Hazan, V
AF Borghini, Giulia
   Hazan, Valerie
TI Listening Effort During Sentence Processing Is Increased for Non-native
   Listeners: A Pupillometry Study
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE non-native speech perception; pupillometry; listening effort; speech
   perception in noise; cognitive load
ID PUPIL-DILATION; SPEECH; RECOGNITION; NOISE; ACQUISITION; PERCEPTION;
   IMPACT; LOAD; AGE
AB Current evidence demonstrates that even though some non-native listeners can achieve native-like performance for speech perception tasks in quiet, the presence of a background noise is much more detrimental to speech intelligibility for non-native compared to native listeners. Even when performance is equated across groups, it is likely that greater listening effort is required for non-native listeners. Importantly, the added listening effort might result in increased fatigue and a reduced ability to successfully perform multiple tasks simultaneously. Task-evoked pupil responses have been demonstrated to be a reliable measure of cognitive effort and can be useful in clarifying those aspects. In this study we compared the pupil response for 23 native English speakers and 27 Italian speakers of English as a second language. Speech intelligibility was tested for sentences presented in quiet and in background noise at two performance levels that were matched across groups. Signal-to-noise levels corresponding to these sentence intelligibility levels were pre-determined using an adaptive intelligibility task. Pupil response was significantly greater in non-native compared to native participants across both intelligibility levels. Therefore, for a given intelligibility level, a greater listening effort is required when listening in a second language in order to understand speech in noise. Results also confirmed that pupil response is sensitive to speech intelligibility during language comprehension, in line with previous research. However, contrary to our predictions, pupil response was not differentially modulated by intelligibility levels for native and non-native listeners. The present study corroborates that pupillometry can be deemed as a valid measure to be used in speech perception investigation, because it is sensitive to differences both across participants, such as listener type, and across conditions, such as variations in the level of speech intelligibility. Importantly, pupillometry offers us the possibility to uncover differences in listening effort even when those do not emerge in the performance level of individuals.
C1 [Borghini, Giulia; Hazan, Valerie] UCL, Fac Brain Sci, Dept Speech Hearing & Phonet Sci, London, England.
RP Borghini, G (corresponding author), UCL, Fac Brain Sci, Dept Speech Hearing & Phonet Sci, London, England.
EM giulia.borghini.13@ucl.ac.uk
RI Hazan, Valerie L/C-9722-2009
OI Hazan, Valerie L/0000-0001-6572-6679
FU Economic and Social Research CouncilUK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [ES/J500185/1]
FX This work was supported by the Economic and Social Research Council
   [ES/J500185/1].
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Besser J, 2013, TRENDS AMPLIF, V17, P75, DOI 10.1177/1084713813495459
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Broersma M, 2011, Q J EXP PSYCHOL, V64, P74, DOI 10.1080/17470218.2010.499174
   Byers-Heinlein K, 2017, P NATL ACAD SCI USA, V114, P9032, DOI 10.1073/pnas.1703220114
   Calandruccio L, 2012, J SPEECH LANG HEAR R, V55, P1342, DOI 10.1044/1092-4388(2012/11-0260)
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cutler A, 2006, J PHONETICS, V34, P269, DOI 10.1016/j.wocn.2005.06.002
   Cutler A, 2008, J ACOUST SOC AM, V124, P1264, DOI 10.1121/1.2946707
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940
   Granholm E, 1996, PSYCHOPHYSIOLOGY, V33, P457, DOI 10.1111/j.1469-8986.1996.tb01071.x
   HYONA J, 1995, Q J EXP PSYCHOL-A, V48, P598
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Koelewijn Thomas, 2012, Int J Otolaryngol, V2012, P865731, DOI 10.1155/2012/865731
   Koelewijn T, 2012, EAR HEARING, V33, P291, DOI 10.1097/AUD.0b013e3182310019
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Li P, 2014, BILING-LANG COGN, V17, P673, DOI 10.1017/S1366728913000606
   Mackersie CL, 2011, J AM ACAD AUDIOL, V22, P113, DOI 10.3766/jaaa.22.2.6
   MacMahon M., 1991, JIPA, V21, P29
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Mattys SL, 2010, SPEECH COMMUN, V52, P887, DOI 10.1016/j.specom.2010.01.005
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Ohlenforst B, 2017, HEARING RES, V351, P68, DOI 10.1016/j.heares.2017.05.012
   Piquado T, 2010, PSYCHOPHYSIOLOGY, V47, P560, DOI 10.1111/j.1469-8986.2009.00947.x
   R Core Team, 2017, R LANG ENV STAT COMP
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Scharenborg O, 2018, J EXP PSYCHOL LEARN, V44, P233, DOI 10.1037/xlm0000441
   Schmidtke J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00137
   Spivey MJ, 1999, PSYCHOL SCI, V10, P281, DOI 10.1111/1467-9280.00151
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   Wechsler D., 2008, WAIS 4 WECHSLER ADUL
   Winn MB, 2015, EAR HEARING, V36, pe153, DOI 10.1097/AUD.0000000000000145
   Zekveld AA, 2014, NEUROIMAGE, V101, P76, DOI 10.1016/j.neuroimage.2014.06.069
   Zekveld AA, 2014, PSYCHOPHYSIOLOGY, V51, P277, DOI 10.1111/psyp.12151
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
NR 40
TC 18
Z9 17
U1 0
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD MAR 13
PY 2018
VL 12
AR 152
DI 10.3389/fnins.2018.00152
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA FZ0UQ
UT WOS:000427289300001
PM 29593489
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Psomiades, M
   Mondino, M
   Fonteneau, C
   Bation, R
   Haesebaert, F
   Suaud-Chagny, MF
   Brunelin, J
AF Psomiades, Marion
   Mondino, Marine
   Fonteneau, Clara
   Bation, Remy
   Haesebaert, Frederic
   Suaud-Chagny, Marie-Francoise
   Brunelin, Jerome
TI N-Acetyl-Aspartate in the dorsolateral prefrontal cortex in men with
   schizophrenia and auditory verbal hallucinations: A 1.5T Magnetic
   Resonance Spectroscopy Study
SO SCIENTIFIC REPORTS
LA English
DT Article
ID BIPOLAR DISORDER; ARCUATE FASCICULUS; H-1 MRS; METAANALYSIS; GLUTAMATE;
   CONNECTIVITY; SPEECH
AB Auditory verbal hallucinations (AVH) in patients with schizophrenia are linked to abnormalities within a large cerebral network including frontal and temporal regions. Whilst abnormalities of frontal speech production and temporal speech perception regions have been extensively studied, alterations of the dorsolateral prefrontal cortex (DLPFC), a region critically involved in the pathophysiology of schizophrenia, have rarely been studied in relation to AVH. Using 1.5T proton magnetic resonance spectroscopy, this study examined the relationship between right and left DLPFCs N-AcetylAspartate (NAA) levels and the severity of AVH in patients with schizophrenia. Twenty-seven male patients with schizophrenia were enrolled in this study, 15 presented daily treatment-resistant AVH (AVH+) and 12 reported no AVH (no-AVH). AVH+ patients displayed higher NAA levels in the right DLPFC than no-AVH patients (p = 0.033). In AVH+ patients, NAA levels were higher in the right DLPFC than in the left (p = 0.024). No difference between the right and left DLPFC was observed in no-AVH patients. There was a positive correlation between NAA levels in the right DLPFC and the severity of AVH (r = 0.404, p = 0.037). Despite limited by magnetic field strength, these results suggest that AVH may be associated with increased NAA levels in the right DLPFC in schizophrenia.
C1 [Psomiades, Marion; Mondino, Marine; Fonteneau, Clara; Bation, Remy; Haesebaert, Frederic; Suaud-Chagny, Marie-Francoise; Brunelin, Jerome] INSERM, U1028, F-69000 Lyon, France.
   [Psomiades, Marion; Mondino, Marine; Fonteneau, Clara; Bation, Remy; Haesebaert, Frederic; Suaud-Chagny, Marie-Francoise; Brunelin, Jerome] CNRS, UMR5292, F-69000 Lyon, France.
   [Psomiades, Marion; Mondino, Marine; Fonteneau, Clara; Bation, Remy; Haesebaert, Frederic; Suaud-Chagny, Marie-Francoise; Brunelin, Jerome] Lyon Neurosci Res Ctr, Psychiat Disorders Resistance Response Team, F-69000 Lyon, France.
   [Psomiades, Marion; Mondino, Marine; Fonteneau, Clara; Bation, Remy; Haesebaert, Frederic; Suaud-Chagny, Marie-Francoise; Brunelin, Jerome] Univ Lyon 1, F-69000 Villeurbanne, France.
   [Psomiades, Marion; Mondino, Marine; Fonteneau, Clara; Bation, Remy; Haesebaert, Frederic; Suaud-Chagny, Marie-Francoise; Brunelin, Jerome] Ctr Hosp Le Vinatier, Bron, France.
RP Brunelin, J (corresponding author), INSERM, U1028, F-69000 Lyon, France.; Brunelin, J (corresponding author), CNRS, UMR5292, F-69000 Lyon, France.; Brunelin, J (corresponding author), Lyon Neurosci Res Ctr, Psychiat Disorders Resistance Response Team, F-69000 Lyon, France.; Brunelin, J (corresponding author), Univ Lyon 1, F-69000 Villeurbanne, France.; Brunelin, J (corresponding author), Ctr Hosp Le Vinatier, Bron, France.
EM jerome.brunelin@ch-le-vinatier.fr
RI Fonteneau, Clara/AAK-2770-2020; Haesebaert, Frederic/D-9264-2018;
   Mondino, Marine/J-2501-2019
OI Fonteneau, Clara/0000-0003-2808-3867; Haesebaert,
   Frederic/0000-0002-6813-9012; Mondino, Marine/0000-0003-3175-8503;
   Bation, Remy/0000-0003-1598-982X; Suaud-Chagny,
   Marie-Francoise/0000-0002-2587-0681; BRUNELIN,
   Jerome/0000-0001-5479-5628
FU CSR of CH Le Vinatier
FX The Authors thanks the CERMEP - Imagerie du vivant for their help in the
   acquisition of MRS spectra. The study was supported by a grant from CSR
   of CH Le Vinatier.
CR Allen P, 2007, INT REV PSYCHIATR, V19, P409, DOI 10.1080/09540260701486498
   Andreasen NC, 2005, AM J PSYCHIAT, V162, P441, DOI 10.1176/appi.ajp.162.3.441
   Baslow M.H., 2012, BIOENERG OPEN ACCESS, V1, P102, DOI [10.4172/2167-7662, DOI 10.4172/2167-7662]
   Bhakoo K. K., 2012, ADV NEUROBIOLOGY, P1075, DOI 10.1007/978-1-4614-1788-0_38
   Birur B, 2017, NPJ SCHIZOPHR, V3, DOI 10.1038/s41537-017-0013-9
   Brambilla P, 2004, NEUROPSYCHOPHARMACOL, V29, P1918, DOI 10.1038/sj.npp.1300520
   Callicott JH, 2000, AM J PSYCHIAT, V157, P1646, DOI 10.1176/appi.ajp.157.10.1646
   Clos M, 2014, BRAIN STRUCT FUNCT, V219, P581, DOI 10.1007/s00429-013-0519-5
   Coughlin JM, 2015, CURR MOL MED, V15, P176, DOI 10.2174/1566524015666150303104811
   Cui LBA, 2017, RADIOLOGY, V283, P809, DOI 10.1148/radiol.2016160938
   Cui LB, 2016, SCHIZOPHR RES, V173, P13, DOI 10.1016/j.schres.2016.02.039
   Curcic-Blake B, 2017, PROG NEURO-PSYCHOPH, V78, P132, DOI 10.1016/j.pnpbp.2017.05.020
   Ford JM, 2005, INT J PSYCHOPHYSIOL, V58, P179, DOI 10.1016/j.ijpsycho.2005.01.014
   Geoffroy PA, 2014, SCHIZOPHR RES, V159, P234, DOI 10.1016/j.schres.2014.07.014
   Jardri R, 2011, AM J PSYCHIAT, V168, P73, DOI 10.1176/appi.ajp.2010.09101522
   Kalayci D, 2012, PROG NEURO-PSYCHOPH, V37, P176, DOI 10.1016/j.pnpbp.2012.01.010
   KANE JM, 1988, PSYCHOPHARMACOL BULL, V24, P62
   Kraguljac NV, 2012, NEUROPSYCHOPHARMACOL, V37, P2635, DOI 10.1038/npp.2012.126
   Kraguljac NV, 2012, PSYCHIAT RES-NEUROIM, V203, P111, DOI 10.1016/j.pscychresns.2012.02.003
   Lawrie SM, 2002, BIOL PSYCHIAT, V51, P1008, DOI 10.1016/S0006-3223(02)01316-1
   Moffett J. R., 2013, FRONT NEUROENERGETIC, V26, P5
   Mondino Marine, 2013, Front Psychiatry, V4, P99, DOI 10.3389/fpsyt.2013.00099
   Ongur D, 2009, PSYCHIAT RES-NEUROIM, V172, P44, DOI 10.1016/j.pscychresns.2008.06.002
   Psomiades M, 2016, NEUROIMAGE-CLIN, V12, P970, DOI 10.1016/j.nicl.2016.04.013
   Sigmundsson T, 2003, SCHIZOPHR RES, V64, P63, DOI 10.1016/S0920-9964(02)00533-9
   Sommer IE, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043516
   Steen RG, 2005, NEUROPSYCHOPHARMACOL, V30, P1949, DOI 10.1038/sj.npp.1300850
   Steinmann S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00055
   Szulc A, 2013, CURR MED CHEM, V20, P414
   Wijtenburg SA, 2015, NEUROSCI BIOBEHAV R, V51, P276, DOI 10.1016/j.neubiorev.2015.01.007
   Wolf ND, 2011, J PSYCHIATR NEUROSCI, V36, P366, DOI 10.1503/jpn.110008
   Zong XF, 2015, SCI REP-UK, V5, DOI 10.1038/srep09109
NR 32
TC 6
Z9 6
U1 1
U2 5
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 7
PY 2018
VL 8
AR 4133
DI 10.1038/s41598-018-22597-y
PG 7
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FY4RS
UT WOS:000426814000031
PM 29515172
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Jones, C
   Sharma, M
   Harkus, S
   McMahon, C
   Taumoepeau, M
   Demuth, K
   Mattock, K
   Rosas, L
   Wing, R
   Pawar, S
   Hampshire, A
AF Jones, Caroline
   Sharma, Mridula
   Harkus, Samantha
   McMahon, Catherine
   Taumoepeau, Mele
   Demuth, Katherine
   Mattock, Karen
   Rosas, Lee
   Wing, Raelene
   Pawar, Sulabha
   Hampshire, Anne
TI A program to respond to otitis media in remote Australian Aboriginal
   communities: a qualitative investigation of parent perspectives
SO BMC PEDIATRICS
LA English
DT Article
DE Hearing loss; Indigenous; Interventions; Otitis media; Qualitative
ID SENSORINEURAL HEARING-LOSS; RISK-FACTORS; SPEECH-PERCEPTION; LANGUAGE;
   HEALTH; STUDENTS; BURDEN
AB Background: Indigenous infants and children in Australia, especially in remote communities, experience early and chronic otitis media (OM) which is difficult to treat and has lifelong impacts in health and education. The LiTTLe Program (Learning to Talk, Talking to Learn) aimed to increase infants' access to spoken language input, teach parents to manage health and hearing problems, and support children's school readiness. This paper aimed to explore caregivers' views about this inclusive, parent-implemented early childhood program for 0-3 years in an Aboriginal community health context.
   Methods: Data from in-depth, semi-structured interviews with 9 caregivers of 12 children who had participated in the program from one remote Aboriginal community in the Northern Territory are presented. Data were analysed thematically. Caregivers provided overall views on the program. In addition, three key areas of focus in the program are also presented here: speech and language, hearing health, and school readiness.
   Results: Caregivers were positive about the interactive speech and language strategies in the program, except for some strategies which some parents found alien or difficult: such as talking slowly, following along with the child's topic, using parallel talk, or baby talk. Children's hearing was considered by caregivers to be important for understanding people, enjoying music, and detecting environmental sounds including signs of danger. Caregivers provided perspectives on the utility of sign language and its benefits for communicating with infants and young children with hearing loss, and the difficulty of getting young community children to wear a conventional hearing aid. Caregivers were strongly of the opinion that the program had helped prepare children for school through familiarising their child with early literacy activities and resources, as well as school routines. But caregivers differed as to whether they thought the program should have been located at the school itself.
   Conclusions: The caregivers generally reported positive views about the LiTTLe Program, and also drew attention to areas for improvement. The perspectives gathered may serve to guide other cross-sector collaborations across health and education to respond to OM among children at risk for OM-related disability in speech and language development.
C1 [Jones, Caroline; Mattock, Karen; Rosas, Lee] Western Sydney Univ, ARC Ctr Excellence Dynam Language, MARCS Inst, Locked Bag 1797, Penrith, NSW 2751, Australia.
   [Jones, Caroline; Demuth, Katherine] Macquarie Univ, ARC Ctr Excellence Cognit & Its Disorders, Sydney, NSW, Australia.
   [Sharma, Mridula; McMahon, Catherine] Macquarie Univ, Dept Linguist, Audiol Program, HEARing CRC, Sydney, NSW, Australia.
   [Harkus, Samantha] Australian Hearing, Sydney, NSW, Australia.
   [Taumoepeau, Mele] Univ Otago, Dept Psychol, Dunedin, New Zealand.
   [Demuth, Katherine] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
   [Wing, Raelene] Sunrise Hlth Serv, Katherine, NT, Australia.
   [Pawar, Sulabha; Hampshire, Anne] Smith Family, Sydney, NSW, Australia.
RP Jones, C (corresponding author), Western Sydney Univ, ARC Ctr Excellence Dynam Language, MARCS Inst, Locked Bag 1797, Penrith, NSW 2751, Australia.; Jones, C (corresponding author), Macquarie Univ, ARC Ctr Excellence Cognit & Its Disorders, Sydney, NSW, Australia.
EM caroline.jones@westernsydney.edu.au
OI Sharma, Mridula/0000-0002-0448-6429; McMahon,
   Catherine/0000-0001-7312-6593; Demuth, Katherine/0000-0003-3884-8886
FU Australian Research CouncilAustralian Research Council [140100468]
FX The current study was funded by the Australian Research Council (Linkage
   Grant 140100468). The funder has had no role in the study design or the
   data analysis, interpretation and writing.
CR Aithal Sreedevi, 2008, Australian and New Zealand Journal of Audiology, V30, P1, DOI 10.1375/audi.30.1.1
   [Anonymous], 2016, COMM AUSTR CANB
   [Anonymous], 2008, CLOS GAP GEN HLTH EQ
   [Anonymous], 2016, 2011 CENS QUICKSTATS
   Australian Bureau of Statistics, AUSTR BUR STAT PUBL
   Australian Institute of Health and Welfare, 2011, NAT OUTC MEAS EARL C
   BOSWELL JB, 1995, ANN OTO RHINOL LARYN, V104, P542, DOI 10.1177/000348949510400708
   Bowes J., 2014, 8 AUSTR I HLTH WELF
   Burrow S, REV ED OTHER APPROAC
   Casby MW, 2001, AM J SPEECH-LANG PAT, V10, P65, DOI 10.1044/1058-0360(2001/009)
   Deggouj N, 2012, B-ENT, V8, P105
   DiGiacomo M, 2013, INT J EQUITY HEALTH, V12, DOI 10.1186/1475-9276-12-7
   Jacoby P, 2011, PEDIATR INFECT DIS J, V30, P480, DOI 10.1097/INF.0b013e318217dc6e
   Jesic SD, 2012, OTOL NEUROTOL, V33, P934, DOI 10.1097/MAO.0b013e318259b885
   Joglekar S, 2010, ACTA OTO-LARYNGOL, V130, P472, DOI 10.3109/00016480903311252
   Jones C., 2013, EVALUATION REPORT SU
   Jones C, 2013, LINGUA, V134, P170, DOI 10.1016/j.lingua.2013.07.004
   Klein JO, 2000, VACCINE, V19, pS2, DOI 10.1016/S0264-410X(00)00271-1
   Kolo ES, 2012, INDIAN J OTOLARYNGOL, V64, P59, DOI 10.1007/s12070-011-0251-5
   Kong K, 2009, MED J AUSTRALIA, V191, pS39
   Lehmann D, 2008, PAEDIATR PERINAT EP, V22, P60, DOI 10.1111/j.1365-3016.2007.00891.x
   Liberman MC, 2015, PLOS ONE
   Luntz M, 2013, ACTA OTO-LARYNGOL, V133, P1173, DOI 10.3109/00016489.2013.814154
   Melody SM, 2016, INT J ENVIRON HEAL R, V26, P525, DOI 10.1080/09603123.2016.1194384
   Monasta L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036226
   Morris Peter S, 2005, BMC Pediatr, V5, P27, DOI 10.1186/1471-2431-5-27
   O'Mara P, 2010, MED J AUSTRALIA, V192, P546, DOI 10.5694/j.1326-5377.2010.tb03631.x
   Paradise JL, 2000, PEDIATRICS, V105, P1119, DOI 10.1542/peds.105.5.1119
   Pennie RA, 1998, CAN FAM PHYSICIAN, V44, P1850
   Roberts J, 2004, J DEV BEHAV PEDIATR, V25, P110, DOI 10.1097/00004703-200404000-00007
   Roberts JE, 2002, PEDIATRICS, V110, P696, DOI 10.1542/peds.110.4.696
   Rovers MM, 2004, LANCET, V363, P465, DOI 10.1016/S0140-6736(04)15495-0
   SAGGERS S, 1993, AUSTR OCCUPATIONAL T, V40, P153
   Saint-Georges C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078103
   SANDELOWSKI M, 1995, RES NURS HEALTH, V18, P179, DOI 10.1002/nur.4770180211
   Schultze-Berndt Eva, 2013, ATLAS PIDGIN CREOLE, V1, P241
   Shriberg LD, 2000, J SPEECH LANG HEAR R, V43, P100, DOI 10.1044/jslhr.4301.100
   Shriberg LD, 2000, J SPEECH LANG HEAR R, V43, P79, DOI 10.1044/jslhr.4301.79
   Solomon DC, 2013, BABY KNOWS BEST RAIS
   Sparrow K, 2016, J LARYNGOLOGY OTO S1, V130, P11
   State of Queensland Australia, 2016, STATE QUEENSLAND AUS
   Topping K, 2013, EDUC PSYCHOL-UK, V33, P391, DOI 10.1080/01443410.2012.744159
   Turpin M., 2014, LANGUAGE DESCRIPTION, V147, P49
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Williams CJ, 2009, MED J AUSTRALIA, V191, pS69
   Pham X, 2012, AUST J RURAL HEALTH, V20, P113, DOI 10.1111/j.1440-1584.2012.01268.x
   Yehudai N, 2015, INT J PEDIATR OTORHI, V79, P26, DOI 10.1016/j.ijporl.2014.10.025
   Yiengprugsawan V, 2013, BMC PEDIATR, V13, DOI 10.1186/1471-2431-13-28
NR 48
TC 3
Z9 3
U1 0
U2 18
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1471-2431
J9 BMC PEDIATR
JI BMC Pediatr.
PD MAR 6
PY 2018
VL 18
AR 99
DI 10.1186/s12887-018-1081-3
PG 13
WC Pediatrics
SC Pediatrics
GA FY2NI
UT WOS:000426652200001
PM 29510680
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Archila-Melendez, ME
   Valente, G
   Correia, JM
   Rouhl, RPW
   van Kranen-Mastenbroek, VH
   Jansma, BM
AF Archila-Melendez, Mario E.
   Valente, Giancarlo
   Correia, Joao M.
   Rouhl, Rob P. W.
   van Kranen-Mastenbroek, Vivianne H.
   Jansma, Bernadette M.
TI Sensorimotor Representation of Speech Perception. Cross-Decoding of
   Place of Articulation Features during Selective Attention to Syllables
   in 7T fMRI
SO ENEURO
LA English
DT Article
DE 7T fMRI; MVPA-based cross-decoding; place of articulation; selective
   attention; sensorimotor; speech perception
ID PHONOLOGICAL FEATURES; IMAGE-ANALYSIS; ORGANIZATION; OSCILLATIONS;
   PATTERN; SYSTEM; CLASSIFICATION; IMPLEMENTATION; SEGMENTATION; INSULA
AB Sensorimotor integration, the translation between acoustic signals and motoric programs, may constitute a crucial mechanism for speech. During speech perception, the acoustic-motoric translations include the recruitment of cortical areas for the representation of speech articulatory features, such as place of articulation. Selective attention can shape the processing and performance of speech perception tasks. Whether and where sensorimotor integration takes place during attentive speech perception remains to be explored. Here, we investigate articulatory feature representations of spoken consonant-vowel (CV) syllables during two distinct tasks. Fourteen healthy humans attended to either the vowel or the consonant within a syllable in separate delayed-match-to-sample tasks. Single-trial fMRI blood oxygenation level-dependent (BOLD) responses from perception periods were analyzed using multivariate pattern classification and a searchlight approach to reveal neural activation patterns sensitive to the processing of place of articulation (i.e., bilabial/ labiodental vs. alveolar). To isolate place of articulation representation from acoustic covariation, we applied a cross-decoding (generalization) procedure across distinct features of manner of articulation (i.e., stop, fricative, and nasal). We found evidence for the representation of place of articulation across tasks and in both tasks separately: for attention to vowels, generalization maps included bilateral clusters of superior and posterior temporal, insular, and frontal regions; for attention to consonants, generalization maps encompassed clusters in temporoparietal, insular, and frontal regions within the right hemisphere only. Our results specify the cortical representation of place of articulation features generalized across manner of articulation during attentive syllable perception, thus supporting sensorimotor integration during attentive speech perception and demonstrating the value of generalization.
C1 [Archila-Melendez, Mario E.; Valente, Giancarlo; Correia, Joao M.; Jansma, Bernadette M.] Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, NL-6229 EV Maastricht, Netherlands.
   [Archila-Melendez, Mario E.; Valente, Giancarlo; Correia, Joao M.; Jansma, Bernadette M.] Maastricht Univ, M BIC, NL-6229 EV Maastricht, Netherlands.
   [Rouhl, Rob P. W.] Maastricht Univ, Med Ctr, Dept Neurol, NL-6202 AZ Maastricht, Netherlands.
   [Rouhl, Rob P. W.; van Kranen-Mastenbroek, Vivianne H.] Maastricht Univ, Sch Mental Hlth & Neurosci MHeNS, NL-6200 MD Maastricht, Netherlands.
   [Archila-Melendez, Mario E.; van Kranen-Mastenbroek, Vivianne H.] Maastricht Univ, Med Ctr, Dept Clin Neurophysiol, NL-6229 HX Maastricht, Netherlands.
   [Archila-Melendez, Mario E.; Valente, Giancarlo; Correia, Joao M.; Rouhl, Rob P. W.; van Kranen-Mastenbroek, Vivianne H.; Jansma, Bernadette M.] Maastricht Univ, CIN, NL-6200 MD Maastricht, Netherlands.
   [Rouhl, Rob P. W.; van Kranen-Mastenbroek, Vivianne H.] Maastricht Univ, Med Ctr, Acad Ctr Epileptol Kempenhaeghe, NL-6202 AZ Maastricht, Netherlands.
RP Archila-Melendez, ME (corresponding author), Maastricht Univ, Dept Cognit Neurosci, Oxfordlaan 55, NL-6229 EV Maastricht, Netherlands.
EM m.archilamelendez@maastrichtuniversity.nl
OI Archila-Melendez, Mario Eduardo/0000-0002-2994-3067; Jansma, Bernadette
   M./0000-0002-2925-0244; Correia, Joao/0000-0001-6624-7012
FU Colombian Administrative Department of Science, Technology and
   Innovation (COLCIENCIAS)Departamento Administrativo de Ciencia,
   Tecnologia e Innovacion Colciencias [568]; University Fund
   Limburg/Stichting Wetenschappelijk Onderwijs Limburg (SWOL)
FX This work was supported by the Colombian Administrative Department of
   Science, Technology and Innovation (COLCIENCIAS), Call Number 568, and
   by the University Fund Limburg/Stichting Wetenschappelijk Onderwijs
   Limburg (SWOL).
CR Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018
   Baldauf D, 2014, SCIENCE, V344, P424, DOI 10.1126/science.1247003
   Baldo JV, 2011, CORTEX, V47, P800, DOI 10.1016/j.cortex.2010.07.001
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Bles M, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-20
   Bonte M, 2014, J NEUROSCI, V34, P4548, DOI 10.1523/JNEUROSCI.4339-13.2014
   Clemens B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025453
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Di Salle F, 2003, MAGN RESON IMAGING, V21, P1213, DOI 10.1016/j.mri.2003.08.023
   Dosenbach NUF, 2006, NEURON, V50, P799, DOI 10.1016/j.neuron.2006.04.031
   Downer JD, 2015, J NEUROSCI, V35, P7565, DOI 10.1523/JNEUROSCI.4094-14.2015
   Dronkers NF, 2004, COGNITION, V92, P145, DOI 10.1016/j.cognition.2003.11.002
   Dronkers NF, 1996, NATURE, V384, P159, DOI 10.1038/384159a0
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Evans S, 2016, J COGNITIVE NEUROSCI, V28, P483, DOI 10.1162/jocn_a_00913
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Friederici AD, 2015, TRENDS COGN SCI, V19, P329, DOI 10.1016/j.tics.2015.03.012
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Frost MA, 2012, NEUROIMAGE, V59, P1369, DOI 10.1016/j.neuroimage.2011.08.035
   Fuster JM, 2001, NEURON, V30, P319, DOI 10.1016/S0896-6273(01)00285-9
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goebel R, 2006, HUM BRAIN MAPP, V27, P392, DOI 10.1002/hbm.20249
   Good P., 2005, PERMUTATION PARAMETR
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Humphries C, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00406
   Hyafil A, 2015, ELIFE, V4, DOI 10.7554/eLife.06213
   J Obleser, 2003, BRAIN, P1643
   Jean T., 1988, COPLANAR STEREOTAXIC
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Ladefoged Peter, 2010, COURSE PHONETICS
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Marques JP, 2010, NEUROIMAGE, V49, P1271, DOI 10.1016/j.neuroimage.2009.10.002
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   Mesgarani N, 2008, J ACOUST SOC AM, V123, P899, DOI 10.1121/1.2816572
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Moeller S, 2010, MAGN RESON MED, V63, P1144, DOI 10.1002/mrm.22361
   Mur M, 2009, SOC COGN AFFECT NEUR, V4, P101, DOI 10.1093/scan/nsn044
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nelson SM, 2010, BRAIN STRUCT FUNCT, V214, P669, DOI 10.1007/s00429-010-0260-2
   Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Ontivero-Ortega M, 2017, NEUROIMAGE, V163, P471, DOI 10.1016/j.neuroimage.2017.09.001
   Polimeni JR, 2010, NEUROIMAGE, V52, P1334, DOI 10.1016/j.neuroimage.2010.05.005
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Sadaghiani S, 2010, J NEUROSCI, V30, P10243, DOI 10.1523/JNEUROSCI.1004-10.2010
   Scharinger M, 2016, BRAIN LANG, V163, P42, DOI 10.1016/j.bandl.2016.09.002
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schutz K, 2007, CONSCIOUS COGN, V16, P520, DOI 10.1016/j.concog.2006.09.001
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Setsompop K, 2012, MAGN RESON MED, V67, P1210, DOI 10.1002/mrm.23097
   Smith EE, 1999, SCIENCE, V283, P1657, DOI 10.1126/science.283.5408.1657
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Turken AU, 2011, FRONT SYST NEUROSCI, V5, DOI 10.3389/fnsys.2011.00001
   Vaughan JT, 2001, MAGN RESON MED, V46, P24, DOI 10.1002/mrm.1156
   Yacoub E, 2001, MAGN RESON MED, V45, P588, DOI 10.1002/mrm.1080
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
NR 61
TC 4
Z9 4
U1 2
U2 3
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
EI 2373-2822
J9 ENEURO
JI eNeuro
PD MAR-APR
PY 2018
VL 5
IS 2
AR UNSP e0252-17.2018
DI 10.1523/ENEURO.0252-17.2018
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA GC8BE
UT WOS:000430017100004
PM 29610768
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Huang, D
   Yu, LD
   Wang, XY
   Fan, YB
   Wang, SP
   Zhang, Y
AF Huang, Dan
   Yu, Luodi
   Wang, Xiaoyue
   Fan, Yuebo
   Wang, Suiping
   Zhang, Yang
TI Distinct patterns of discrimination and orienting for temporal
   processing of speech and nonspeech in Chinese children with autism: an
   event-related potential study
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE autism; mismatch negativity; perceptual weighting; speech perception;
   temporal processing
ID EARLY LANGUAGE-ACQUISITION; SPECTRUM DISORDERS; MISMATCH NEGATIVITY;
   ASPERGER-SYNDROME; FUNCTIONING INDIVIDUALS; AUDITORY-STIMULI; UNIQUE
   WINDOW; PERCEPTION; ADULTS; DEFICITS
AB Although many studies have reported domain-general impaired duration perception for speech and nonspeech sounds in children with autism, it remained unclear whether this phenomenon is universally applicable regardless of language background. In some languages such as Finnish and Japanese, vowel duration serves a phonemic role that can signify semantic distinction, and in others (e.g., Mandarin Chinese), vowel duration does not carry this phonemic function. The present event-related potential study investigated neural sensitivity to duration contrasts in speech and nonspeech contexts in Mandarin-speaking children with autism and a control group of age-matched typically developing (TD) children. A passive oddball paradigm was adopted to elicit the mismatch negativity (MMN) and involuntary orienting response (P3a) for change detection. A pure tone condition and a vowel condition were used. The MMN results showed that the autism group had diminished response amplitude and delayed latency in the pure tone condition compared to the TD group, whereas no group difference was found in the vowel condition. The P3a results showed no significant between-group MMN difference in the pure tone condition. In the vowel condition, the autism group had smaller P3a than the TD group. Together, the distinct patterns of discrimination and orienting responses for duration contrasts in pure tones and vowels are consistent with the allophonic perception' theory for autism, which may reflect a compromised perceptual weighting system for speech learning.
C1 [Huang, Dan; Yu, Luodi; Wang, Xiaoyue; Wang, Suiping] South China Normal Univ, Sch Psychol, Guangzhou 510631, Guangdong, Peoples R China.
   [Huang, Dan; Fan, Yuebo] Guangzhou Cana Sch, Guangzhou Rehabil & Res Ctr Children Autism, Guangzhou, Guangdong, Peoples R China.
   [Yu, Luodi; Zhang, Yang] Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
   [Wang, Suiping] South China Normal Univ, Ctr Studies Psychol Applicat, Guangzhou, Guangdong, Peoples R China.
   [Wang, Suiping] South China Normal Univ, Guangdong Prov Key Lab Mental Hlth & Cognit Sci, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Yang] Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN USA.
RP Wang, SP (corresponding author), South China Normal Univ, Sch Psychol, Guangzhou 510631, Guangdong, Peoples R China.; Zhang, Y (corresponding author), Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
EM wangsuiping@m.scnu.edu.cn; zhanglab@umn.edu
RI Zhang, Yang/Q-1780-2015
OI Zhang, Yang/0000-0001-6777-3487
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [NSFC 31571136, NSFC 31728009]; Key Project of National
   Social Science Foundation of China [15AZD048]; Key Project of National
   Natural Science Foundation of Guangdong Province, China
   [2014A030311016]; University of Minnesota's Grand Challenges Exploratory
   Research Grant Award; Brain Imaging Research Award from the College of
   Liberal Arts
FX This work was supported by grants from the Natural Science Foundation of
   China (NSFC 31571136), Key Project of National Social Science Foundation
   of China (15AZD048), as well as Key Project of National Natural Science
   Foundation of Guangdong Province, China (2014A030311016) to Suiping
   Wang. Zhang was additionally supported by the Natural Science Foundation
   of China (NSFC 31728009), University of Minnesota's Grand Challenges
   Exploratory Research Grant Award and Brain Imaging Research Award from
   the College of Liberal Arts. We thank Yang Fan, Guiwen He, Xiaoyun Wu,
   and Kai Fan for their assistance.
CR Alcantara JI, 2004, J CHILD PSYCHOL PSYC, V45, P1107, DOI 10.1111/j.1469-7610.2004.t01-1-00303.x
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Brodeur DA, 2014, AUTISM RES, V7, P237, DOI 10.1002/aur.1364
   Ceponiene R, 2003, P NATL ACAD SCI USA, V100, P5567, DOI 10.1073/pnas.0835631100
   Chen Y, 2012, NEUROPSYCHOLOGIA, V50, P733, DOI 10.1016/j.neuropsychologia.2012.01.007
   Dawson M, 2007, PSYCHOL SCI, V18, P657, DOI 10.1111/j.1467-9280.2007.01954.x
   Falter CM, 2012, Q J EXP PSYCHOL, V65, P2093, DOI 10.1080/17470218.2012.690770
   Ferri R, 2003, CLIN NEUROPHYSIOL, V114, P1671, DOI 10.1016/S1388-2457(03)00153-6
   Foss-Feig JH, 2012, INT REV RES DEV DISA, V43, P87, DOI 10.1016/B978-0-12-398261-2.00003-9
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Gage NM, 2003, NEUROREPORT, V14, P2047, DOI 10.1097/00001756-200311140-00008
   Gilliam JE, 2006, GARS 2 GILLIAM AUTIS
   Gomot M, 2002, PSYCHOPHYSIOLOGY, V39, P577, DOI 10.1017/S0048577202394058
   Gomot M, 2011, J AUTISM DEV DISORD, V41, P705, DOI 10.1007/s10803-010-1091-y
   Groen WB, 2009, J AUTISM DEV DISORD, V39, P742, DOI 10.1007/s10803-008-0682-3
   Haesen B, 2011, RES AUTISM SPECT DIS, V5, P701, DOI 10.1016/j.rasd.2010.11.006
   Heaton P, 2005, J AUTISM DEV DISORD, V35, P787, DOI 10.1007/s10803-005-0024-7
   Hitoglou M, 2010, PEDIATR NEUROL, V42, P309, DOI 10.1016/j.pediatrneurol.2009.10.009
   Huang AX, 2013, J AUTISM DEV DISORD, V43, P1991, DOI 10.1007/s10803-012-1722-6
   Jansson-Verkasalo E, 2003, NEUROSCI LETT, V338, P197, DOI 10.1016/S0304-3940(02)01405-2
   Jarvinen-Pasley A, 2008, DEVELOPMENTAL SCI, V11, P109, DOI 10.1111/j.1467-7687.2007.00644.x
   Jarvinen-Pasley A, 2007, DEVELOPMENTAL SCI, V10, P786, DOI 10.1111/j.1467-7687.2007.00637.x
   Jiang J, 2015, J AUTISM DEV DISORD, V45, P2067, DOI 10.1007/s10803-015-2370-4
   Kasai K, 2005, CLIN NEUROPHYSIOL, V116, P1655, DOI 10.1016/j.clinph.2005.03.007
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Kujala T, 2007, BIOL PSYCHOL, V75, P109, DOI 10.1016/j.biopsycho.2006.12.007
   Kujala T, 2013, NEUROSCI BIOBEHAV R, V37, P697, DOI 10.1016/j.neubiorev.2013.01.006
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lepisto T, 2008, BIOL PSYCHOL, V77, P25, DOI 10.1016/j.biopsycho.2007.08.010
   Lepisto T, 2006, CLIN NEUROPHYSIOL, V117, P2161, DOI 10.1016/j.clinph.2006.06.709
   Lepisto T, 2005, BRAIN RES, V1066, P147, DOI 10.1016/j.brainres.2005.10.052
   Lepisto T, 2007, NEUROSCI LETT, V414, P136, DOI 10.1016/j.neulet.2006.12.009
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Maister L, 2011, DEVELOPMENTAL SCI, V14, P1311, DOI 10.1111/j.1467-7687.2011.01077.x
   Martin JS, 2010, J AUTISM DEV DISORD, V40, P640, DOI 10.1007/s10803-009-0904-3
   Naatanen R, 2012, CLIN NEUROPHYSIOL, V123, P424, DOI 10.1016/j.clinph.2011.09.020
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Pallett PM, 2014, J AUTISM DEV DISORD, V44, P1039, DOI 10.1007/s10803-013-1955-z
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Raven J. C., 1998, RAVENS PROGR MATRICE
   Roberts TPL, 2011, BIOL PSYCHIAT, V70, P263, DOI 10.1016/j.biopsych.2011.01.015
   Samson F, 2006, J AUTISM DEV DISORD, V36, P65, DOI 10.1007/s10803-005-0043-4
   Samson F, 2011, NEUROPSYCHOLOGIA, V49, P546, DOI 10.1016/j.neuropsychologia.2010.12.033
   Shtyrov Y, 1999, NEUROREPORT, V10, P2189, DOI 10.1097/00001756-199907130-00034
   Sun X, 2013, MOL AUTISM, V4, DOI 10.1186/2040-2392-4-7
   Szelag E, 2004, BRIT J PSYCHOL, V95, P269, DOI 10.1348/0007126041528167
   Wang XY, 2017, SCI REP-UK, V7, P1, DOI 10.1038/srep43254
   Yip M., 2002, TONE
   You RS, 2017, RES DEV DISABIL, V61, P158, DOI 10.1016/j.ridd.2016.12.009
   Yu LD, 2015, J AUTISM DEV DISORD, V45, P3656, DOI 10.1007/s10803-015-2510-x
   Zhang Y, 2005, NEUROIMAGE, V26, P703, DOI 10.1016/j.neuroimage.2005.02.040
   Zhang Y, 2009, NEUROIMAGE, V46, P226, DOI 10.1016/j.neuroimage.2009.01.028
NR 58
TC 7
Z9 7
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD MAR
PY 2018
VL 47
IS 6
SI SI
BP 662
EP 668
DI 10.1111/ejn.13657
PG 7
WC Neurosciences
SC Neurosciences & Neurology
GA GA4TN
UT WOS:000428325800016
PM 28833760
DA 2021-02-24
ER

PT J
AU Zuk, J
   Iuzzini-Seigel, J
   Cabbage, K
   Green, JR
   Hogan, TP
AF Zuk, Jennifer
   Iuzzini-Seigel, Jenya
   Cabbage, Kathryn
   Green, Jordan R.
   Hogan, Tiffany P.
TI Poor Speech Perception Is Not a Core Deficit of Childhood Apraxia of
   Speech: Preliminary Findings
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID CLASSIFICATION-SYSTEM SDCS; LANGUAGE-IMPAIRED CHILDREN; DEVELOPMENTAL
   APRAXIA; AUDITORY-DISCRIMINATION; GRAMMATICAL MORPHOLOGY;
   DIFFERENTIAL-DIAGNOSIS; PHONOLOGICAL DISORDER; PHONETIC PERCEPTION;
   GENETICS RESEARCH; LEARNING-PROBLEMS
AB Purpose: Childhood apraxia of speech ( CAS) is hypothesized to arise from deficits in speech motor planning and programming, but the influence of abnormal speech perception in CAS on these processes is debated. This study examined speech perception abilities among children with CAS with and without language impairment compared to those with language impairment, speech delay, and typically developing peers.
   Method: Speech perception was measured by discrimination of synthesized speech syllable continua that varied in frequency (/da/-/ga/). Groups were classified by performance on speech and language assessments and compared on syllable discrimination thresholds. Within-group variability was also evaluated.
   Results: Children with CAS without language impairment did not significantly differ in syllable discrimination compared to typically developing peers. In contrast, those with CAS and language impairment showed significantly poorer syllable discrimination abilities compared to children with CAS only and typically developing peers. Children with speech delay and language impairment also showed significantly poorer discrimination abilities, with appreciable within-group variability.
   Conclusions: These findings suggest that speech perception deficits are not a core feature of CAS but rather occur with co-occurring language impairment in a subset of children with CAS. This study establishes the significance of accounting for language ability in children with CAS.
C1 [Zuk, Jennifer; Cabbage, Kathryn; Green, Jordan R.; Hogan, Tiffany P.] MGH Inst Hlth Profess, Dept Commun Sci & Disorders, Boston, MA 02129 USA.
   [Zuk, Jennifer; Green, Jordan R.] Harvard Univ, Div Med Sci, Program Speech & Hearing Biosci & Technol, Boston, MA 02115 USA.
   [Iuzzini-Seigel, Jenya] Marquette Univ, Dept Speech Pathol & Audiol, Harriet Barker Cramer Hall, Milwaukee, WI 53233 USA.
   [Cabbage, Kathryn] Brigham Young Univ, Dept Commun Disorders, Provo, UT 84602 USA.
RP Hogan, TP (corresponding author), MGH Inst Hlth Profess, Dept Commun Sci & Disorders, Boston, MA 02129 USA.
EM thogan@mghihp.edu
RI Iuzzini-Seigel, Jenya/ABG-6788-2020; Green, Jordan/N-3585-2019;
   Iuzzini-Seigel, Jenya/ABG-6801-2020
OI Green, Jordan/0000-0002-1464-1373; Iuzzini-Seigel,
   Jenya/0000-0002-7679-2556
FU University of Nebraska Health Research Consortium; National Institutes
   of HealthUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R03 DC9667]; Childhood Apraxia of
   Speech Association of North America; Barkley Memorial Trust; National
   Institute of Health Institutional National Research Service Award [NIH
   T32 DC000038-22]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R03DC009667, T32DC000038,
   T32DC000038, T32DC000038, T32DC000038, T32DC000038, T32DC000038,
   T32DC000038, T32DC000038, T32DC000038, T32DC000038, T32DC000038,
   T32DC000038, T32DC000038, T32DC000038, T32DC000038, T32DC000038,
   T32DC000038, T32DC000038, T32DC000038, T32DC000038, T32DC000038,
   T32DC000038, R03DC009667, T32DC000038, T32DC000038, T32DC000038,
   T32DC000038, T32DC000038, T32DC000038, T32DC000038, R03DC009667,
   R03DC009667, T32DC000038, T32DC000038] Funding Source: NIH RePORTER
FX This research was supported by the University of Nebraska Health
   Research Consortium (Hogan & Green), the National Institutes of Health
   (R03 DC9667 to Hogan), the Childhood Apraxia of Speech Association of
   North America (Iuzzini), the Barkley Memorial Trust, and the National
   Institute of Health Institutional National Research Service Award (NIH
   T32 DC000038-22 to Zuk).
CR American Speech-Language-Hearing Association, 2007, TECHNICAL REPORT
   American Speech-Language-Hearing Association Audiologic Assessment Panel, 1996, GUID AUD SCREEN
   Aram DMNJE, 1982, CHILD LANGUAGE DISOR
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Benjamini Y, 2001, BEHAV BRAIN RES, V125, P279, DOI 10.1016/S0166-4328(01)00297-2
   BIRD J, 1995, J SPEECH HEAR RES, V38, P446, DOI 10.1044/jshr.3802.446
   BRIDGEMAN E, 1988, BRIT J DISORD COMMUN, V23, P245
   BROEN PA, 1983, J SPEECH HEAR RES, V26, P601, DOI 10.1044/jshr.2604.601
   Cabbage K. L., 2013, PERCEPTUAL SKILLS UN
   Carrell TD, 1999, EAR HEARING, V20, P175, DOI 10.1097/00003446-199904000-00008
   Centanni TM, 2015, AM J MED GENET B, V168, P536, DOI 10.1002/ajmg.b.32325
   Centanni TM, 2015, FRONT GENET, V6, DOI 10.3389/fgene.2015.00272
   Davis BL, 1998, CLIN LINGUIST PHONET, V12, P25, DOI 10.3109/02699209808985211
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Edwards J, 2002, J SPEECH LANG HEAR R, V45, P231, DOI 10.1044/1092-4388(2002/018)
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   ELLIOTT LL, 1989, J SPEECH HEAR RES, V32, P112, DOI 10.1044/jshr.3201.112
   Evans JL, 2002, J SPEECH LANG HEAR R, V45, P494, DOI 10.1044/1092-4388(2002/039)
   FELSENFELD S, 1992, J SPEECH HEAR RES, V35, P1114, DOI 10.1044/jshr.3505.1114
   Froud K, 2012, AM J SPEECH-LANG PAT, V21, P302, DOI 10.1044/1058-0360(2012/11-0003)
   FRUMKIN B, 1980, NEUROPSYCHOLOGIA, V18, P443, DOI 10.1016/0028-3932(80)90147-5
   Goldman R, 2000, GOLDMAN FRISTOE TEST
   Green D. M., 1966, SIGNAL DETECTION THE
   Groenen P, 1996, J SPEECH HEAR RES, V39, P468, DOI 10.1044/jshr.3903.468
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   HOFFMAN PR, 1983, J SPEECH HEAR DISORD, V48, P210, DOI 10.1044/jshd.4802.210
   HOFFMAN PR, 1985, J SPEECH HEAR DISORD, V50, P46, DOI 10.1044/jshd.5001.46
   HOITDALGAARD J, 1983, BRAIN LANG, V20, P329, DOI 10.1016/0093-934X(83)90048-2
   Iuzzini J, 2010, CLIN LINGUIST PHONET, V24, P335, DOI 10.3109/02699200903581083
   Iuzzini-Seigel J, 2017, J SPEECH LANG HEAR R, V60, P1194, DOI 10.1044/2016_JSLHR-S-15-0184
   Iuzzini-Seigel J, 2015, J COMMUN DISORD, V54, P32, DOI 10.1016/j.jcomdis.2015.01.002
   Jusczyk PW, 1997, SCIENCE, V277, P1984, DOI 10.1126/science.277.5334.1984
   Kenney MK, 2006, BRAIN LANG, V96, P178, DOI 10.1016/j.bandl.2005.04.002
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Kraus N, 1996, SCIENCE, V273, P971, DOI 10.1126/science.273.5277.971
   KUHL PK, 1993, J PHONETICS, V21, P125
   LEONARD LB, 1992, J SPEECH HEAR RES, V35, P1076, DOI 10.1044/jshr.3505.1076
   Leonard LB, 2014, CHILDREN WITH SPECIFIC LANGUAGE IMPAIRMENT, 2ND EDITION, P1
   Levelt WJ, 1989, SPEAKING INTENTION A
   Lewis BA, 2004, LANG SPEECH HEAR SER, V35, P122, DOI 10.1044/0161-1461(2004/014)
   Lof G. L., 1997, CONT ISSUES COMMUNIC, V24, P63
   Maassen B, 2003, CLIN LINGUIST PHONET, V17, P447, DOI 10.1080/0269920031000070821
   Munson B, 2005, TOP LANG DISORD, V25, P190, DOI 10.1097/00011363-200507000-00003
   Murray E, 2015, J SPEECH LANG HEAR R, V58, P43, DOI 10.1044/2014_JSLHR-S-12-0358
   Nijland L, 2003, CLIN LINGUIST PHONET, V17, P1, DOI 10.1080/0269920021000050662
   Nijland L, 2009, CLIN LINGUIST PHONET, V23, P222, DOI 10.1080/02699200802399947
   Perkell J. S., 1980, LANGUAGE PRODUCTION, V1, P337
   Reynolds C., 2003, REYNOLDS INTELLECTUA
   RICE ML, 1991, J SPEECH HEAR RES, V34, P1299, DOI 10.1044/jshr.3406.1299
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   Semel E.M., 2004, CLIN EVALUATION LANG
   Semel E. M., 2003, CLIN EVALUATION LANG
   Shriberg LD, 2012, CLIN LINGUIST PHONET, V26, P445, DOI 10.3109/02699206.2012.655841
   Shriberg LD, 2011, J SPEECH LANG HEAR R, V54, P487, DOI 10.1044/1092-4388(2010/10-0068)
   Shriberg LD, 2010, CLIN LINGUIST PHONET, V24, P795, DOI 10.3109/02699206.2010.503006
   SHRIBERG LD, 1993, J SPEECH HEAR RES, V36, P105, DOI 10.1044/jshr.3601.105
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P723, DOI 10.1044/jslhr.4004.723
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P273, DOI 10.1044/jslhr.4002.273
   Silverman FH, 1989, LANG SPEECH HEAR SER, V20, P219
   Stark RE, 1996, J SPEECH HEAR RES, V39, P860, DOI 10.1044/jshr.3904.860
   SUSSMAN JE, 1993, J SPEECH HEAR RES, V36, P1286, DOI 10.1044/jshr.3606.1286
   Sussman JE, 2001, J ACOUST SOC AM, V109, P1173, DOI 10.1121/1.1349428
   Sutherland D, 2005, LANG SPEECH HEAR SER, V36, P294, DOI 10.1044/0161-1461(2005/030)
   TALLAL P, 1980, NEUROPSYCHOLOGIA, V18, P273, DOI 10.1016/0028-3932(80)90123-2
   TAYLOR MM, 1967, J ACOUST SOC AM, V41, P782, DOI 10.1121/1.1910407
   Terband H, 2010, FOLIA PHONIATR LOGO, V62, P134, DOI 10.1159/000287212
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   van der Merwe A., 2009, CLIN MANAGEMENT SENS
NR 71
TC 14
Z9 14
U1 0
U2 15
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAR
PY 2018
VL 61
IS 3
BP 583
EP 592
DI 10.1044/2017_JSLHR-S-16-0106
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GA3TG
UT WOS:000428251900009
PM 29450502
OA Green Published
DA 2021-02-24
ER

PT J
AU Celik, M
   Karatas, E
   Kanlikama, M
AF Celik, Mustafa
   Karatas, Erkan
   Kanlikama, Muzaffer
TI Outcomes of cochlear implantation in children with and without inner ear
   malformations
SO PAKISTAN JOURNAL OF MEDICAL SCIENCES
LA English
DT Article
DE Cochlear implantation; Congenital inner ear anomaly; Sensorineural
   hearing loss; Auditory performance; Speech development
ID AUDIOLOGICAL PERFORMANCE; SPEECH-PERCEPTION; DEAF-CHILDREN;
   CLASSIFICATION; SCHOOLS; TURKEY
AB Objective: To evaluate the auditory functions and progress of speech development in children with and without cochlear anomalies who underwent cochlear implantation due to prelingual profound sensorineural hearing loss (SNHL).
   Methods: This study was conducted at Gaziantep University Faculty of Medicine Ear-Nose-Throat Department, between October 2006 and December 2007. A total of 69 children (aged 6 to 24 months) diagnosed with profound SNHL were included. Patients were divided into two groups with respect to the presence of inner ear anomalies: Group-1 consisted of 41 children without inner ear anomaly, whereas Group-2 was composed of 28 patients with inner ear anomalies. The auditory performance was assessed using Listening Progress Profile Test (LPPT) and Monosyllabic Trochee Polysyllabic Test (MTP), the subsections of Evaluation of Auditory Responses to Speech (EARS) test battery.
   Results: Preoperative LPPT scores were 5 (12%) in both groups. Mean LPPT values after fitting in Group-1 and Group-2 on 1st, 3rd and 6th months were 18.5 (44.1%) and 19 (45.6%); 27 (64.2%) and 28 (67.3%); 31 (75%) and 34 (83%), respectively. Postoperatively, MTP scores in Group-1 and Group-2 were 7.5 (62%) and 7.7 (64%) for 3-words set; 10.4 (58%) and 10.6 (59%) for 6-words set; 14.3 (60%) and 14 (59%) for 12-words set, respectively. The rate of stimulation for electrodes was 1345 q/u (quick/unit) in Group-1 and 1310 q/u in Group-2. No statistically significant difference was detected between groups for variables under investigation.
   Conclusion: Cochlear implantation is an effective treatment in children with prelingual profound SNHL. Auditory performance and advancement of speech are similar for children with and without inner ear anomalies.
C1 [Celik, Mustafa] Harran Univ, Med Fac, Dept Otorhinolaryngol, Sanliurfa, Turkey.
   [Karatas, Erkan] Inonu Univ, Med Fac, Dept Otorhinolaryngol, Malatya, Turkey.
   [Kanlikama, Muzaffer] Gaziantep Univ, Med Fac, Dept Otorhinolaryngol, Gaziantep, Turkey.
RP Celik, M (corresponding author), Harran Univ, Sch Med, Dept Otorhinolaryngol, Sanliurfa, Turkey.
EM mustafareyhan@yahoo.com
RI Kanlikama, Muzaffer/AAG-8311-2020
OI Kanlikama, Muzaffer/0000-0002-3537-7778
CR Arnoldner C, 2004, INT J PEDIATR OTORHI, V68, P457, DOI 10.1016/j.ijporl.2003.11.018
   Balkany TJ, 2002, ACTA OTO-LARYNGOL, V122, P356, DOI 10.1080/00016480260000012
   Belgin E, 1991, P 2 INT M AUD MED CO, P181
   BROOKHOUSER PE, 1990, LARYNGOSCOPE, V100, P349
   Daya H, 1999, INT J PEDIATR OTORHI, V49, P135, DOI 10.1016/S0165-5876(99)00112-3
   Gstoettner WK, 2000, ACTA OTO-LARYNGOL, V120, P209
   JACKLER RK, 1987, LARYNGOSCOPE, V97, P2
   Karatas E, 2006, J NATL MED ASSOC, V98, P204
   Ozturk O, 2005, INT J PEDIATR OTORHI, V69, P367, DOI 10.1016/j.ijporl.2004.11.001
   Pradhananga R, 2015, INT ARCH OTORHINOLAR, V19, P359, DOI 10.1055/s-0034-1395791
   Rachovitsas D, 2012, INT J PEDIATR OTORHI, V76, P1370, DOI 10.1016/j.ijporl.2012.06.009
   Sainz M, 2003, ORL J OTO-RHINO-LARY, V65, P91, DOI 10.1159/000070772
   Sennaroglu L, 2002, LARYNGOSCOPE, V112, P2230, DOI 10.1097/00005537-200212000-00019
   Silan F, 2004, INT J PEDIATR OTORHI, V68, P1399, DOI 10.1016/j.ijporl.2004.05.007
   SLATTERY WH, 1995, LARYNGOSCOPE, V105, P1184, DOI 10.1288/00005537-199511000-00008
   van Wermeskerken GKA, 2007, ACTA OTO-LARYNGOL, V127, P252, DOI 10.1080/00016480600895060
   Weber BP, 1997, AM J OTOL, V18, pS64
   Zhou H, 2014, B-ENT, V10, P265
NR 18
TC 6
Z9 6
U1 0
U2 6
PU PROFESSIONAL MEDICAL PUBLICATIONS
PI SADDAR
PA PANORAMA CENTRE, RM 522, 5TH FLOOR, BLDG 2, RAJA GHAZANFAR ALI RD, PO
   BOX 8766, SADDAR, KARACHI 00000, PAKISTAN
SN 1682-024X
J9 PAK J MED SCI
JI Pak. J. Med. Sci.
PD MAR-APR
PY 2018
VL 34
IS 2
BP 380
EP 384
DI 10.12669/pjms.342.14066
PG 5
WC Medicine, General & Internal
SC General & Internal Medicine
GA GH0SV
UT WOS:000433113200027
PM 29805412
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Nkyekyer, J
   Meyer, D
   Blamey, PJ
   Pipingas, A
   Bhar, S
AF Nkyekyer, Joanna
   Meyer, Denny
   Blamey, Peter J.
   Pipingas, Andrew
   Bhar, Sunil
TI Investigating the Impact of Hearing Aid Use and Auditory Training on
   Cognition, Depressive Symptoms, and Social Interaction in Adults With
   Hearing Loss: Protocol for a Crossover Trial
SO JMIR RESEARCH PROTOCOLS
LA English
DT Article
DE sensorineural hearing loss; hearing aids; crossover design
ID OLDER-ADULTS; UNITED-STATES; FOLLOW-UP; IMPAIRMENT; DECLINE; DEMENTIA;
   PERFORMANCE; POPULATION; SPEECH
AB Background: Sensorineural hearing loss is the most common sensory deficit among older adults. Some of the psychosocial consequences of this condition include difficulty in understanding speech, depression, and social isolation. Studies have shown that older adults with hearing loss show some age-related cognitive decline. Hearing aids have been proven as successful interventions to alleviate sensorineural hearing loss. In addition to hearing aid use, the positive effects of auditory training-formal listening activities designed to optimize speech perception-are now being documented among adults with hearing loss who use hearing aids, especially new hearing aid users. Auditory training has also been shown to produce prolonged cognitive performance improvements. However, there is still little evidence to support the benefits of simultaneous hearing aid use and individualized face-to-face auditory training on cognitive performance in adults with hearing loss.
   Objective: This study will investigate whether using hearing aids for the first time will improve the impact of individualized face-to-face auditory training on cognition, depression, and social interaction for adults with sensorineural hearing loss. The rationale for this study is based on the hypothesis that, in adults with sensorineural hearing loss, using hearing aids for the first time in combination with individualized face-to-face auditory training will be more effective for improving cognition, depressive symptoms, and social interaction rather than auditory training on its own.
   Methods: This is a crossover trial targeting 40 men and women between 50 and 90 years of age with either mild or moderate symmetric sensorineural hearing loss. Consented, willing participants will be recruited from either an independent living accommodation or via a community database to undergo a 6-month intensive face-to-face auditory training program (active control). Participants will be assigned in random order to receive hearing aid (intervention) for either the first 3 or last 3 months of the 6-month auditory training program. Each participant will be tested at baseline, 3, and 6 months using a neuropsychological battery of computer-based cognitive assessments, together with a depression symptom instrument and a social interaction measure. The primary outcome will be cognitive performance with regard to spatial working memory. Secondary outcome measures include other cognition performance measures, depressive symptoms, social interaction, and hearing satisfaction.
   Results: Data analysis is currently under way and the first results are expected to be submitted for publication in June 2018.
   Conclusions: Results from the study will inform strategies for aural rehabilitation, hearing aid delivery, and future hearing loss intervention trials.
C1 [Nkyekyer, Joanna] Swinburne Univ Technol, Fac Sci Engn & Technol, Australian Res Council Training Ctr Biodevices, John St Hawthorn,Mail H11,POB 218, Hawthorn, Vic 3122, Australia.
   [Meyer, Denny] Swinburne Univ Technol, Dept Stat Data Sci & Epidemiol, Hawthorn, Vic, Australia.
   [Blamey, Peter J.] Blamey & Saunders Hearing Pty Ltd, Melbourne, Vic, Australia.
   [Pipingas, Andrew] Swinburne Univ Technol, Ctr Human Psychopharmacol, Hawthorn, Vic, Australia.
   [Bhar, Sunil] Swinburne Univ Technol, Dept Psychol Sci, Hawthorn, Vic, Australia.
RP Nkyekyer, J (corresponding author), Swinburne Univ Technol, Fac Sci Engn & Technol, Australian Res Council Training Ctr Biodevices, John St Hawthorn,Mail H11,POB 218, Hawthorn, Vic 3122, Australia.
EM jnkyekyer@swin.edu.au
RI Meyer, Denny/H-6266-2016
OI Meyer, Denny/0000-0002-9902-0858; Blamey, Peter/0000-0002-7579-2255;
   Bhar, Sunil/0000-0001-9260-7368
FU Australian Research Council and Blamey and Saunders Hearing Pty Ltd
   under the Industry Transformation Training Centre Scheme (ARC)
   [IC140100023]
FX This investigation is funded by the Australian Research Council and
   Blamey and Saunders Hearing Pty Ltd under the Industry Transformation
   Training Centre Scheme (ARC Project No. IC140100023). The authors are
   grateful to the clinicians at Blamey and Saunders Hearing Pty Ltd and
   all the aged care facilities in Melbourne who will be participating in
   this research study.
CR Acar B, 2011, ARCH GERONTOL GERIAT, V52, P250, DOI 10.1016/j.archger.2010.04.013
   Amieva H, 2015, J AM GERIATR SOC, V63, P2099, DOI 10.1111/jgs.13649
   [Anonymous], 2014, HEARING LOSS HLTH AG
   Bamford J, 1981, Br J Audiol, V15, P75, DOI 10.3109/03005368109081418
   BERKMAN LF, 1979, AM J EPIDEMIOL, V109, P186, DOI 10.1093/oxfordjournals.aje.a112674
   Blamey P, 1994, RES AUDITORY TRAININ
   Blamey PJ, 2015, J TELEMED TELECARE, V21, P474, DOI 10.1177/1357633X15611568
   Boothroyd A, 2010, J AM ACAD AUDIOL, V21, P601, DOI 10.3766/jaaa.21.9.6
   BROOKS D N, 1989, British Journal of Audiology, V23, P3, DOI 10.3109/03005368909077813
   BROOKS D N, 1985, British Journal of Audiology, V19, P211, DOI 10.3109/03005368509078975
   Brooks D N, 1979, Scand Audiol, V8, P101, DOI 10.3109/01050397909076308
   Burk MH, 2008, J SPEECH LANG HEAR R, V51, P759, DOI 10.1044/1092-4388(2008/054)
   Burke W J, 1991, J Geriatr Psychiatry Neurol, V4, P173, DOI 10.1177/089198879100400310
   Cacciatore F, 1999, GERONTOLOGY, V45, P323, DOI 10.1159/000022113
   Chien W, 2012, ARCH INTERN MED, V172, P292, DOI 10.1001/archinternmed.2011.1408
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   Deal JA, 2015, AM J EPIDEMIOL, V181, P680, DOI 10.1093/aje/kwu333
   DEFILIPPO CL, 1978, J ACOUST SOC AM, V63, P1186, DOI 10.1121/1.381827
   Ferguson MA, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.00556, 10.3389/fpg.2015.00556]
   Ferguson MA, 2014, EAR HEARING, V35, pE110, DOI 10.1097/AUD.0000000000000020
   Fu QJ, 2011, SPRINGER HANDB AUDIT, V39, P257, DOI 10.1007/978-1-4419-9434-9_11
   Gupta Sandeep K, 2011, Perspect Clin Res, V2, P109, DOI 10.4103/2229-3485.83221
   Harris E, 2012, HUM PSYCHOPHARM CLIN, V27, P370, DOI 10.1002/hup.2236
   Henshaw H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062836
   Humes LE, 2009, EAR HEARING, V30, P613, DOI 10.1097/AUD.0b013e3181b00d90
   Keidser G, 2011, AUDIOL RES, V1, P88, DOI 10.4081/audiores.2011.e24
   Kiely KM, 2012, J GERONTOL A-BIOL, V67, P997, DOI 10.1093/gerona/gls066
   Kilimann I, 2015, Z GERONTOL GERIATR, V48, P440, DOI 10.1007/s00391-014-0808-5
   Lin FR, 2014, AGING MENT HEALTH, V18, P671, DOI 10.1080/13607863.2014.915924
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2012, JAMA-J AM MED ASSOC, V307, P1147, DOI 10.1001/jama.2012.321
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Macpherson H, 2012, PSYCHOPHARMACOLOGY, V220, P351, DOI 10.1007/s00213-011-2481-3
   Mathers CD, 2001, B WORLD HEALTH ORGAN, V79, P1076
   Meister H, 2015, CLIN INTERV AGING, V10, DOI 10.2147/CIA.S77096
   Moore DR, 2009, PHILOS T R SOC B, V364, P409, DOI 10.1098/rstb.2008.0187
   MULROW CD, 1990, ANN INTERN MED, V113, P188, DOI 10.7326/0003-4819-113-3-188
   Olson Anne D., 2015, Seminars in Hearing, V36, P284, DOI 10.1055/s-0035-1564461
   Olson AD, 2013, J AM ACAD AUDIOL, V24, P214, DOI 10.3766/jaaa.24.3.7
   Pipingas A, 2010, ASSESSING EFFICACY N
   Pipingas A, 2008, PHYTOTHER RES, V22, P1168, DOI 10.1002/ptr.2388
   Saunders GH, 2016, EAR HEARING, V37, P381, DOI 10.1097/AUD.0000000000000283
   SHEIKH J I, 1986, Clinical Gerontologist, V5, P165
   Simpson T, 2012, IMPROVED PROCESSING, DOI [10.1080/03601277.2011.559858, DOI 10.1080/03601277.2011.559858]
   Stecker GC, 2006, J REHABIL RES DEV, V43, P537, DOI 10.1682/JRRD.2005.11.0171
   Stough CK, 2012, NUTR J, V11, DOI 10.1186/1475-2891-11-11
   Strawbridge WJ, 2000, GERONTOLOGIST, V40, P320, DOI 10.1093/geront/40.3.320
   Sweetow Robert, 2005, J Am Acad Audiol, V16, P494, DOI 10.3766/jaaa.16.7.9
   Sweetow RW, 2006, J AM ACAD AUDIOL, V17, P538, DOI 10.3766/jaaa.17.8.2
   Sweetow RW, 2010, J AM ACAD AUDIOL, V21, P586, DOI 10.3766/jaaa.21.9.4
   Tay T, 2006, GERONTOLOGY, V52, P386, DOI 10.1159/000095129
   Valentijn SAM, 2005, J AM GERIATR SOC, V53, P374, DOI 10.1111/j.1532-5415.2005.53152.x
   van Hooren SAH, 2005, INT J AUDIOL, V44, P265, DOI 10.1080/14992020500060370
   van Velzen EJJ, 2008, J PROTEOME RES, V7, P4483, DOI 10.1021/pr800145j
   Wahl HW, 2013, GERONTOLOGIST, V53, P950, DOI 10.1093/geront/gnt013
   WEINSTEIN BE, 1982, J SPEECH HEAR RES, V25, P593, DOI 10.1044/jshr.2504.593
   Wellek S, 2012, DTSCH ARZTEBL INT, V109, P276, DOI 10.3238/arztebl.2012.0276
   YESAVAGE JA, 1983, J PSYCHIATR RES, V17, P37, DOI 10.1016/0022-3956(82)90033-4
   Zhang T, 2012, EAR HEARING, V33, pE70, DOI 10.1097/AUD.0b013e318259e5dd
NR 61
TC 3
Z9 3
U1 1
U2 14
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA
SN 1929-0748
J9 JMIR RES PROTOC
JI JMIR RES. Protoc.
PD MAR
PY 2018
VL 7
IS 3
AR e85
DI 10.2196/resprot.8936
PG 11
WC Health Care Sciences & Services
SC Health Care Sciences & Services
GA GG7ZF
UT WOS:000432916400007
PM 29572201
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rogers, CS
   Payne, L
   Maharjan, S
   Wingfield, A
   Sekuler, R
AF Rogers, Chad S.
   Payne, Lisa
   Maharjan, Sujala
   Wingfield, Arthur
   Sekuler, Robert
TI Older Adults Show Impaired Modulation of Attentional Alpha Oscillations:
   Evidence From Dichotic Listening
SO PSYCHOLOGY AND AGING
LA English
DT Article
DE alpha modulation; speech perception; attention; aging; EEG
ID AUDITORY SELECTIVE ATTENTION; TERM-MEMORY TASK; SPEECH-PERCEPTION;
   WORKING-MEMORY; INDIVIDUAL-DIFFERENCES; SPATIAL ATTENTION;
   AGE-DIFFERENCES; COCKTAIL PARTY; HEARING-LOSS; RECOGNITION
AB Auditory attention is critical for selectively listening to speech from a single talker in a multitalker environment (e.g., Cherry, 1953). Listening in such situations is notoriously more difficult and more poorly encoded to long-term memory in older than in young adults (Tun, O'Kane, & Wingfield, 2002). Recent work by Payne, Rogers, Wingfield, and Sekuler (2017) in young adults demonstrated a neural correlate of auditory attention in the directed dichotic listening task (DDLT), where listeners attend to one ear while ignoring the other. Measured using electroencephalography, differences in alpha band power (8-14 Hz) between left and right hemisphere parietal regions mark the direction to which auditory attention is focused. Little prior research has been conducted on alpha power modulations in older adults, particularly with regard to auditory attention directed toward speech stimuli. In the current study, an older adult sample was administered the DDLT and delayed recognition procedures used by Payne et al. (2017). Compared to young adults, older adults showed reduced selective attention in the DDLT, evidenced by a higher rate of intrusions from the unattended ear. Moreover, older adults did not exhibit attention-related alpha modulation evidenced by young adults, nor did their event-related potentials (ERPs) to recognition probes differentiate between attended or unattended probes. Older adults' delayed recognition did not reveal a pattern of suppression of unattended items evidenced by young adults. These results serve as evidence for an age-related decline in selective auditory attention, potentially mediated by age-related decline in the ability to modulate alpha oscillations.
C1 [Rogers, Chad S.; Payne, Lisa; Maharjan, Sujala; Wingfield, Arthur; Sekuler, Robert] Brandeis Univ, Volen Natl Ctr Complex Syst, Waltham, MA 02254 USA.
   [Payne, Lisa] Swarthmore Coll, Dept Psychol, Swarthmore, PA 19081 USA.
RP Rogers, CS (corresponding author), Brandeis Univ, Volen Natl Ctr Complex Syst, Waltham, MA 02254 USA.; Rogers, CS (corresponding author), Union Coll, Dept Psychol, 807 Union St, Schenectady, NY 12308 USA.
EM Chad.S.Rogers@gmail.com
FU CELEST, an NSF Science of Learning Center [NSF SBE-0354378,
   SMA-0835976)]; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [T32 NS07292, R01
   AG019714]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKEUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of Neurological Disorders &
   Stroke (NINDS) [T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292, T32NS007292, T32NS007292,
   T32NS007292, T32NS007292, T32NS007292] Funding Source: NIH RePORTER;
   NATIONAL INSTITUTE ON AGINGUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Aging (NIA) [R01AG019714, R01AG019714, R01AG019714, R01AG019714,
   R01AG019714, R01AG019714, R01AG019714, R01AG019714, R01AG019714,
   R01AG019714, R01AG019714, R01AG019714, R01AG019714, R01AG019714,
   R01AG019714, R01AG019714, R01AG019714] Funding Source: NIH RePORTER
FX This research was supported in part by CELEST, an NSF Science of
   Learning Center (NSF SBE-0354378 and SMA-0835976), NIH T32 NS07292, and
   NIH R01 AG019714. The principal investigator for NINDS T32 NS007292 is
   Eve Marder.
CR Ahveninen J, 2013, J COGNITIVE NEUROSCI, V25, P1926, DOI 10.1162/jocn_a_00452
   Balota D.A, 2000, OXFORD HDB MEMORY, P395, DOI DOI 10.1037/A0015086
   BENTIN S, 1995, J EXP PSYCHOL HUMAN, V21, P54, DOI 10.1037/0096-1523.21.1.54
   Braver TS, 2002, NEUROSCI BIOBEHAV R, V26, P809, DOI 10.1016/S0149-7634(02)00067-2
   Bregman AS., 1994, AUDITORY SCENE ANAL
   Chait M, 2010, NEUROPSYCHOLOGIA, V48, P3262, DOI 10.1016/j.neuropsychologia.2010.07.007
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Choi I, 2014, HEARING RES, V314, P10, DOI 10.1016/j.heares.2014.04.008
   Craik FIM, 2012, NEUROSCI BIOBEHAV R, V36, P1729, DOI 10.1016/j.neubiorev.2011.11.007
   CRAIK FIM, 1965, Q J EXP PSYCHOL, V17, P227, DOI 10.1080/17470216508416436
   Crites SL, 2000, PSYCHOPHYSIOLOGY, V37, P850, DOI 10.1111/1469-8986.3760850
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Danker JF, 2008, PSYCHOPHYSIOLOGY, V45, P784, DOI 10.1111/j.1469-8986.2008.00672.x
   Della-Maggiore V, 2000, J NEUROSCI, V20, P8410, DOI 10.1523/JNEUROSCI.20-22-08410.2000
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dey A, 2015, PSYCHOL AGING, V30, P634, DOI 10.1037/pag0000033
   Dupoux E, 2003, J EXP PSYCHOL HUMAN, V29, P172, DOI 10.1037/0096-1523.29.1.172
   Faust ME, 1999, PSYCHOL BULL, V125, P777, DOI 10.1037/0033-2909.125.6.777
   Frey JN, 2014, J NEUROSCI, V34, P6634, DOI 10.1523/JNEUROSCI.4813-13.2014
   Getzmann S, 2012, J PSYCHOPHYSIOL, V26, P132, DOI 10.1027/0269-8803/a000076
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Green DM., 1988, SIGNAL DETECTION THE
   Hasher Lynn, 1988, PSYCHOL LEARN MOTIV, V22, P193, DOI DOI 10.1016/S0079-7421(08)60041-9
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   Hong XF, 2015, NEUROIMAGE, V106, P353, DOI 10.1016/j.neuroimage.2014.11.019
   Hornsby BWY, 2013, EAR HEARING, V34, P523, DOI 10.1097/AUD.0b013e31828003d8
   Humes L E, 1996, J Am Acad Audiol, V7, P161
   Jacoby LL, 2005, J MEM LANG, V52, P493, DOI 10.1016/j.jml.2005.01.007
   KALCHER J, 1995, ELECTROEN CLIN NEURO, V94, P381, DOI 10.1016/0013-4694(95)00040-6
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Kong LQ, 2014, CEREB CORTEX, V24, P773, DOI 10.1093/cercor/bhs359
   Kramer AF, 1999, ACTA PSYCHOL, V101, P339, DOI 10.1016/S0001-6918(99)00011-6
   Kucera H., 1967, COMPUTATIONAL ANALYS
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   Leenders MP, 2016, CEREB CORTEX, V28, P21
   Lustig C., 2007, PLACE INHIBITION COG, P145, DOI DOI 10.1037/11587-008
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Milham MP, 2002, BRAIN COGNITION, V49, P277, DOI 10.1006/brcg.2001.1501
   Mok RM, 2016, CEREB CORTEX, V26, P1831, DOI 10.1093/cercor/bhw011
   MORAIS J, 1975, J EXP PSYCHOL HUMAN, V1, P253, DOI 10.1037/0096-1523.1.3.253
   Mueller H., 1997, PURE TONE AUDIOMETRY, P78
   Obleser J, 2012, J NEUROSCI, V32, P12376, DOI 10.1523/JNEUROSCI.4908-11.2012
   Ohlenforst B, 2017, HEARING RES, V351, P68, DOI 10.1016/j.heares.2017.05.012
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Passow S, 2014, CEREB CORTEX, V24, P249, DOI 10.1093/cercor/bhs306
   Payne L, 2017, PSYCHOPHYSIOLOGY, V54, P528, DOI 10.1111/psyp.12815
   Payne L, 2014, CURR DIR PSYCHOL SCI, V23, P171, DOI 10.1177/0963721414529145
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Rugg MD, 2007, TRENDS COGN SCI, V11, P251, DOI 10.1016/j.tics.2007.04.004
   Rugg Michael D., 1995, P789
   Salthouse T. A., 1994, NEUROPSYCHOLOGY, V8, P535, DOI [10.1037/0894-4105.8.4.535, DOI 10.1037/0894-4105.8.4.535]
   Sander MC, 2012, NEUROIMAGE, V59, P646, DOI 10.1016/j.neuroimage.2011.06.092
   Shinn-Cunningham B., 2009, HEARING J, V62, P10, DOI DOI 10.1097/01
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   STUDDERTKENNEDY M, 1970, J ACOUST SOC AM, V48, P579, DOI 10.1121/1.1912174
   Thomas RC, 2012, J EXP PSYCHOL LEARN, V38, P30, DOI 10.1037/a0024882
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   TUN PA, 1995, AGING COGNITION, V2, P39, DOI 10.1080/13825589508256588
   Tun PA, 2008, DEV PSYCHOL, V44, P1421, DOI 10.1037/a0012845
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Vaden RJ, 2012, NEUROIMAGE, V63, P1127, DOI 10.1016/j.neuroimage.2012.07.050
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   WEISZ N, 2011, FRONT PSYCHOL, V2
   Wingfield A, 2016, EAR HEARING, V37, p35S, DOI 10.1097/AUD.0000000000000310
   Wostmann M, 2016, P NATL ACAD SCI USA, V113, P3873, DOI 10.1073/pnas.1523357113
   Wostmann M, 2015, J COGNITIVE NEUROSCI, V27, P988, DOI 10.1162/jocn_a_00761
   Wostmann M, 2015, J NEUROSCI, V35, P1458, DOI 10.1523/JNEUROSCI.3250-14.2015
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
NR 74
TC 2
Z9 2
U1 0
U2 8
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0882-7974
EI 1939-1498
J9 PSYCHOL AGING
JI Psychol. Aging
PD MAR
PY 2018
VL 33
IS 2
BP 246
EP 258
DI 10.1037/pag0000238
PG 13
WC Gerontology; Psychology, Developmental
SC Geriatrics & Gerontology; Psychology
GA GF4GX
UT WOS:000431922300004
PM 29658746
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Sung, E
AF Sung, Eunkyung
TI Compensation for phonological assimilation: Obstruent nasalization and
   coronal place assimilation
SO LINGUISTIC RESEARCH
LA English
DT Article
DE compensation; obstruent nasalization; coronal place assimilation;
   discrimination; detection rate
ID SPOKEN WORD RECOGNITION; SPEECH-PERCEPTION; REPRESENTATION; MECHANISMS;
   INFERENCE; LEXICON
AB This paper investigates whether native English, Korean, and Chinese listeners show language-specific compensation mechanisms for phonological assimilation processes. To this end, two different assimilation rules, obstruent nasalization and coronal place assimilation, were tested. Fourteen Korean listeners, eleven English listeners, and fourteen Chinese listeners listened to 540 items of Korean stimuli and 540 items of English stimuli prompted by the PsychoPy software. For each item, a target token was presented with one of three contexts (i.e. no change, unviable change, and viable change). The participants indicated whether a target token was the same as the first syllable or the first word in a compound word (e.g. "main", "mai[m] body"). The results of detection rates showed that Korean listeners compensated for nasalization in a highly context-sensitive way, and their sensitivity to context was also revealed in place assimilation. The other two listener groups did not show sensitivity to context for either nasalization or place assimilation. Overall, the results of this study were supported by language-specific compensation mechanisms. Basic processing was controlled by language experience with assimilation rules. However, language-independent mechanism such as perceptual salience of segments was also at play. In addition, it seems that the status of a phonological rule in a native language and realization of segments in native speech also played an important role in compensation for assimilation. Lexical status of words did not seem to affect compensation patterns.
C1 [Sung, Eunkyung] Cyber Hankuk Univ Foreign Studies, Dept English, 107 Imun Ro, Seoul 02450, South Korea.
RP Sung, E (corresponding author), Cyber Hankuk Univ Foreign Studies, Dept English, 107 Imun Ro, Seoul 02450, South Korea.
EM eks@cufs.ac.kr
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of KoreaNational Research Foundation of Korea
   [NRF-2017S1A5A2A01027443]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea
   (NRF-2017S1A5A2A01027443). I would like to thank the two reviewers for
   their insightful comments and suggestions on this paper.
CR Boersma Paul, 2012, PRAAT DOING PHONETIC
   Darcy Isabelle, 2009, VARIATION GRADIENCE
   Dilley LC, 2007, J ACOUST SOC AM, V122, P2340, DOI 10.1121/1.2772226
   Ernestus M, 2006, J ACOUST SOC AM, V120, P1040, DOI 10.1121/1.2211548
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gaskell MG, 1998, J EXP PSYCHOL HUMAN, V24, P380, DOI 10.1037/0096-1523.24.2.380
   Gaskell MG, 2001, J MEM LANG, V44, P325, DOI 10.1006/jmla.2000.2741
   Gow DW, 2004, J MEM LANG, V51, P279, DOI 10.1016/j.jml.2004.05.004
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   Jun J., 2004, PHONETICALLY BASED P, P58, DOI [DOI 10.1017/CBO9780511486401.003, 10.1017/CBO9780511486401.003]
   Kang Sikjin, 2010, CHINESE STUDIES, V36, P1
   Key Michael, 2008, LABPH 11
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   LAHIRI A, 1999, P 14 INT C PHON SCI, P715
   Lahiri Aditi, 2001, LAB PHONOLOGY, V7, P637
   Lee S, 2017, LINGUIST RES, V34, P247, DOI 10.17250/khisli.34.2.201706.005
   Lee Shinsook, 2008, PHONOLOGICAL INFEREN
   Mitterer H, 2003, PERCEPT PSYCHOPHYS, V65, P956, DOI 10.3758/BF03194826
   Mitterer H., 2003, P 15 INT C PHON SCI, P2321
   Otake T, 1996, J ACOUST SOC AM, V100, P3831, DOI 10.1121/1.417239
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Quene Hugo, 1998, P 5 INT C SPOK LANG, V3, P871
   Sohn H., 1999, KOREAN LANGUAGE
   Wheeldon L, 2004, BRAIN LANG, V90, P401, DOI 10.1016/S0093-934X(03)00451-6
   이신숙, 2005, [Studies in Phonetics, Phonology, and Morphology, 음성음운형태론연구], V11, P105
NR 26
TC 0
Z9 0
U1 0
U2 2
PU KYUNGHEE UNIV, INST STUDY LANGUAGE & INFORMATION
PI SEOUL
PA 1 HOEGI-DONG, DONGDAEMUN-GU, SEOUL, 130-701, SOUTH KOREA
SN 1229-1374
J9 LINGUIST RES
JI Linguist. Res.
PD SPR
PY 2018
VL 35
IS 1
BP 145
EP 178
DI 10.17250/khisli.35.1.201803.006
PG 34
WC Language & Linguistics
SC Linguistics
GA GE8AP
UT WOS:000431454500006
OA Other Gold
DA 2021-02-24
ER

PT J
AU Erdener, D
   Burnham, D
AF Erdener, Dogu
   Burnham, Denis
TI Auditory-visual speech perception in three- and four-year-olds and its
   relationship to perceptual attunement and receptive vocabulary
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
ID LANGUAGE-DEVELOPMENT; CHILDREN; INFANTS; DISCRIMINATION; INTEGRATION;
   ADULTS; LIFE
AB Despite the body of research on auditory-visual speech perception in infants and schoolchildren, development in the early childhood period remains relatively uncharted. In this study, English-speaking children between three and four years of age were investigated for: (i) the development of visual speech perception - lip-reading and visual influence in auditory-visual integration; (ii) the development of auditory speech perception and native language perceptual attunement; and (iii) the relationship between these and a language skill relevant at this age, receptive vocabulary. Visual speech perception skills improved even over this relatively short time period. However, regression analyses revealed that vocabulary was predicted by auditory-only speech perception, and native language attunement, but not by visual speech perception ability. The results suggest that, in contrast to infants and schoolchildren, in three-to four-year-olds the relationship between speech perception and language ability is based on auditory and not visual or auditory-visual speech perception ability. Adding these results to existing findings allows elaboration of a more complete account of the developmental course of auditory-visual speech perception.
C1 [Erdener, Dogu] Middle East Tech Univ, Psychol Program, Northern Cyprus Campus,Kktc Via Mersin Turkey, Guzelyurt Morphou, Northern Cyprus, Turkey.
   [Burnham, Denis] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.
RP Erdener, D (corresponding author), Middle East Tech Univ, Psychol Program, Northern Cyprus Campus,Kktc Via Mersin Turkey, Guzelyurt Morphou, Northern Cyprus, Turkey.
EM vdogu@metu.edu.tr; d.erdener@gmail.com
RI Erdener, Dogu/D-1328-2010
OI Erdener, Dogu/0000-0001-5547-4228; Burnham, Denis/0000-0002-1980-3458
FU Australian Postgraduate Award from the University of Western Sydney;
   Australian Research Council Discovery grantAustralian Research Council
   [DP0558698]
FX This research was partially supported by an Australian Postgraduate
   Award from the University of Western Sydney, and by an Australian
   Research Council Discovery grant (DP0558698) to the second author. The
   authors express their gratitude to Ms Amanda Reid for her invaluable
   contribution to the manuscript and analyses as well as the children and
   their parents, without whom this study would not have been possible.
CR Bates TC, 2003, BEHAV RES METH INS C, V35, P565, DOI 10.3758/BF03195535
   Bundgaard-Nielsen RL, 2012, APPL PSYCHOLINGUIST, V33, P643, DOI 10.1017/S0142716411000518
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   Bundgaard-Nielsen RL, 2011, APPL PSYCHOLINGUIST, V32, P51, DOI 10.1017/S0142716410000287
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Burnham D., 1998, ADV PSYCHOL SPEECHRE, P27
   Burnham D., 1998, ADV INFANCY RES, V12, P170
   Burnham D., 2003, READ WRIT, V16, P573, DOI DOI 10.1023/A:1025593911070
   Burnham D., 2012, AUDIOVISUAL SPEECH P, P62
   BURNHAM DK, 1991, J CHILD LANG, V18, P231, DOI 10.1017/S0305000900011041
   CAMPBELL R, 1998, HEARING EYE 2 ADV PS
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   DODD B, 1988, VOLTA REV, V90, P45
   Dodd B, 2008, CLIN LINGUIST PHONET, V22, P69, DOI 10.1080/02699200701660100
   Dunn L.M., 1997, PPVT 3 PEABODY PICTU
   ELLIOTT LL, 1989, J SPEECH HEAR RES, V32, P112, DOI 10.1044/jshr.3201.112
   Erdener D, 2013, J EXP CHILD PSYCHOL, V116, P120, DOI 10.1016/j.jecp.2013.03.003
   Hockley N., 1994, J ACOUST SOC AM, V96, P3309, DOI DOI 10.1121/1.410782
   Horlyck S, 2012, SCI STUD READ, V16, P218, DOI 10.1080/10888438.2010.546460
   Jerger S, 2014, J EXP CHILD PSYCHOL, V126, P295, DOI 10.1016/j.jecp.2014.05.003
   Jerger S, 2009, J EXP CHILD PSYCHOL, V102, P40, DOI 10.1016/j.jecp.2008.08.002
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   MASSARO DW, 1984, CHILD DEV, V55, P1777, DOI 10.1111/j.1467-8624.1984.tb00420.x
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Vance M, 2009, INT J AUDIOL, V48, P708, DOI 10.1080/14992020902930550
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
NR 34
TC 2
Z9 2
U1 4
U2 10
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD MAR
PY 2018
VL 45
IS 2
BP 273
EP 289
DI 10.1017/S0305000917000174
PG 17
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA GD8CD
UT WOS:000430739000001
PM 28585512
DA 2021-02-24
ER

PT J
AU Ramachers, S
   Brouwer, S
   Fikkert, P
AF Ramachers, Stefanie
   Brouwer, Susanne
   Fikkert, Paula
TI No perceptual reorganization for Limburgian tones? A cross-linguistic
   investigation with 6-to 12-month-old infants
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
ID LEXICAL PITCH-ACCENT; LANGUAGE EXPERIENCE; PHONETIC PERCEPTION;
   SPEECH-PERCEPTION; 1ST YEAR; DISCRIMINATION; VOWEL; CONTRASTS; ENGLISH;
   FRENCH
AB Despite the fact that many of the world's languages use lexical tone, the majority of language acquisition studies has focused on non-tone languages. Research on tone languages has typically investigated well-known tone languages such as Mandarin and Cantonese Chinese. The current study looked at a Limburgian dialect of Dutch that uses lexical pitch differences, albeit in a rather restricted way. Using a visual habituation paradigm, 6- to 12-month-old Limburgian and Dutch infants were tested for their ability to discriminate Limburgian tones. The results showed that both Limburgian and Dutch infants discriminate the Limburgian tones throughout their first year of life. The role of linguistic experience, acoustic salience, and the degree of similarity to the native prosodic system are discussed.
C1 [Ramachers, Stefanie; Brouwer, Susanne; Fikkert, Paula] Radboud Univ Nijmegen, Nijmegen, Netherlands.
RP Ramachers, S (corresponding author), Erasmuspl 1, NL-6500 HD Nijmegen, Netherlands.
EM s.ramachers@let.ru.nl
OI Obadiah, Asir/0000-0001-8131-8771
FU Netherlands Organization for Scientific ResearchNetherlands Organization
   for Scientific Research (NWO) [322-75-001]
FX This research was supported by a grant from the Netherlands Organization
   for Scientific Research (322-75-001) to the first author, and appears as
   part of the first author's dissertation. Thanks to all participating
   parents and their infants from Nijmegen and Roermond, the Baby Research
   Center in Nijmegen, daycare center 'Ot en Sien' in Roermond, and GGD
   Limburg Noord in Roermond. We also thank Carlos Gussenhoven for his
   helpful knowledge and advice on the Limburgian tones and on stimuli
   preparation, as well as for his feedback on earlier drafts of this
   paper. Thanks also to the research group First Language Acquisition at
   Radboud University Nijmegen for valuable discussion, and to two
   anonymous reviewers for helpful comments on an earlier draft of this
   paper.
CR Alexander Werth, 2011, PERZEPTIONSPHONOLOGI
   Bakker F., 2012, TAAL TONGVAL, V64, P159, DOI [10.5117/TET2012.2.BAKK, DOI 10.5117/TET2012.2.BAKK]
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1998, INFANT BEHAV DEV, V21, P295, DOI [10.1016/S0163, DOI 10.1016/S0163, DOI 10.1016/S0163-6383(98)91508-9]
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Blom E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00552
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bosch L, 2011, J PHONETICS, V39, P514, DOI 10.1016/j.wocn.2011.02.001
   Braun B, 2011, J PHONETICS, V39, P585, DOI 10.1016/j.wocn.2011.06.002
   Bruce G., 1977, SWEDISH WORD ACCENTS
   Chen A, 2016, INFANT CHILD DEV, V25, P426, DOI 10.1002/icd.1944
   Cornips L., 2014, 3 FACTORS SOCIO SYNT, V14, P1
   Dobrovolsky M., 2001, CONT LINGUISTICS
   Driessen G., 2006, TOEGEPASTE TAALWETEN, V75, P103, DOI [10.1075/ttwia.75.10dri, DOI 10.1075/TTWIA.75.10DRI]
   Duanmu S., 2000, PHONOLOGY STANDARD C
   Dunn LM, 2005, PEABODY PICTURE VOCA
   Durrant S, 2015, J CHILD LANG, V42, P447, DOI 10.1017/S0305000914000063
   Fennell C. T., 2016, BILINGUALISM LIFESPA, P43, DOI DOI 10.1037/14939-004
   Fernald A., 2006, DEVELOPMENTAL SCI, V9, P33
   Fournier R, 2006, J PHONETICS, V34, P29, DOI 10.1016/j.wocn.2005.03.002
   Fournier R, 2010, BRAIN RES, V1328, P79, DOI 10.1016/j.brainres.2010.02.053
   Fournier Rachel, 2008, THESIS
   Frota S, 2014, INFANCY, V19, P194, DOI 10.1111/infa.12037
   Geffen S., 2011, ONL SUPPL P 36 BOST
   Goss S., 2015, THESIS
   Gussenhoven C, 1999, J LINGUIST, V35, P99, DOI 10.1017/S0022226798007324
   Gussenhoven C., 2004, TRADITIONAL PHONOLOG, P129
   Gussenhoven C, 2000, PROSODY THEORY EXPT, P129, DOI DOI 10.1007/978-94-015-9413-4
   Gussenhoven C., 2000, ANALOGY LEVELLING MA, P215, DOI DOI 10.1515/9783110899917.215
   Gussenhoven C., 2005, PROSODIC TYPOLOGY PH, P118
   Gussenhoven C., 2008, NEDERLANDSE TAALKUND, V13, P87
   Gussenhoven C, 1999, WORD PROSODIC SYSTEM, P233
   Gussenhoven Carlos, 2001, INT ENCY SOCIAL BEHA
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   HEIJMANS L, 2003, DEV PROSODIC SYSTEMS, P7, DOI DOI 10.1515/9783110894530.7
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   HOROWITZ FD, 1975, MONOGRAPHS SOC RES C, V39
   Houston DM, 2007, INFANCY, V12, P119, DOI 10.1111/j.1532-7078.2007.tb00237.x
   Hyman LM, 2009, LANG SCI, V31, P213, DOI 10.1016/j.langsci.2008.12.007
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   Kats J. C., 1985, REMUNJS WOARDEBOOK
   Kohnlein B, 2016, PHONOLOGY, V33, P87, DOI 10.1017/S095267571600004X
   Kristoffersen G., 2000, PHONOLOGY NORWEGIAN
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Meints K., 2008, LINCOLN INFANT LAB P
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Ota M, 2003, CAN J LING/REV CAN L, V48, P357, DOI 10.1353/cjl.2004.0032
   Picton TW, 2000, AUDIOL NEURO-OTOL, V5, P111, DOI 10.1159/000013875
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Quam C, 2010, J MEM LANG, V62, P135, DOI 10.1016/j.jml.2009.09.003
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   Riad T., 2013, PHONOLOGY SWEDISH
   Sato Y, 2010, J COGNITIVE NEUROSCI, V22, P2503, DOI 10.1162/jocn.2009.21377
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Schaefer V, 2014, LAB PHONOL, V5, P489, DOI 10.1515/lp-2014-0016
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Singh L, 2016, CHILD DEV, V87, P834, DOI 10.1111/cdev.12512
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Skoruppa K, 2009, DEVELOPMENTAL SCI, V12, P914, DOI 10.1111/j.1467-7687.2009.00835.x
   SNOW CE, 1977, J CHILD LANG, V4, P1, DOI 10.1017/S0305000900000453
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Soderstrom M, 2011, INFANT BEHAV DEV, V34, P107, DOI 10.1016/j.infbeh.2010.10.003
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Tamaoka K, 2014, J NEUROLINGUIST, V27, P31, DOI 10.1016/j.jneuroling.2013.08.001
   Tsao F.-M., 2008, CHINESE J PSYCHOL, V50, P111, DOI [10.6129/CJP.2008.5002.01, DOI 10.6129/CJP.2008.5002.01]
   Tsushima T., 1994, P INT C SPOK LANG PR, P1695
   Turk A., 2006, METHODS EMPIRICAL PR, P1, DOI [DOI 10.1515/9783110914641.1, 10.1515/9783110914641.1]
   van Bezooijen R., 1999, LINGUISTICS NETHERLA, V16, P1
   van de Weijer J., 2001, P EARL LANG ACQ ELA2
   van de Wijngaard T., 2007, RIEK KLANK INLEIDING, P15
   VOORHOEVE J, 1973, STUDIES AFRICAN LING, V4, P1
   Wang Y, 2004, APPL PSYCHOLINGUIST, V25, P449, DOI 10.1017/S0142716404001213
   WERKER JF, 1992, ANNU REV NEUROSCI, V15, P377, DOI 10.1146/annurev.ne.15.030192.002113
   Wetterlin A., 2007, THESIS
   Wittenburg Peter, 2006, P 5 INT C LANG RES E
   Wu XH, 2012, APPL PSYCHOLINGUIST, V33, P623, DOI 10.1017/S0142716411000506
   WU Z, 2000, P INT C SPOK LANG PR, V1, pB1
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE
NR 90
TC 8
Z9 8
U1 1
U2 5
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD MAR
PY 2018
VL 45
IS 2
BP 290
EP 318
DI 10.1017/S0305000917000228
PG 29
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA GD8CD
UT WOS:000430739000002
PM 28615089
DA 2021-02-24
ER

PT J
AU Fritz, T
   Mueller, K
   Guha, A
   Gouws, A
   Levita, L
   Andrews, TJ
   Slocombe, KE
AF Fritz, Thomas
   Mueller, Karsten
   Guha, Anika
   Gouws, Andre
   Levita, Liat
   Andrews, Timothy J.
   Slocombe, Katie E.
TI Human behavioural discrimination of human, chimpanzee and macaque
   affective vocalisations is reflected by the neural response in the
   superior temporal sulcus
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Auditory; FMRI; Affective; Vocalisation
ID HUMAN AUDITORY-CORTEX; ACOUSTIC PARAMETERS; SPEECH-PERCEPTION; MERE
   EXPOSURE; RECOGNITION; EMOTION; FMRI; EXPRESSION; SOUNDS; AREAS
AB Accurate perception of the emotional content of vocalisations is essential for successful social communication and interaction. However, it is not clear whether our ability to perceive emotional cues from vocal signals is specific to human signals, or can be applied to other species' vocalisations. Here, we address this issue by evaluating the perception and neural response to affective vocalisations from different primate species (humans, chimpanzees and macaques). We found that the ability of human participants to discriminate emotional valence varied as a function of phylogenetic distance between species. Participants were most accurate at discriminating the emotional valence of human vocalisations, followed by chimpanzee vocalisations. They were, however, unable to accurately discriminate the valence of macaque vocalisations. Next, we used fMRI to compare human brain responses to human, chimpanzee and macaque vocalisations. We found that regions in the superior temporal lobe that are closely associated with the perception of complex auditory signals, showed a graded response to affective vocalisations from different species with the largest response to human vocalisations, an intermediate response to chimpanzees, and the smallest response to macaques. Together, these results suggest that neural correlates of differences in the perception of different primate affective vocalisations are found in auditory regions of the human brain and correspond to the phylogenetic distances between the species.
C1 [Fritz, Thomas; Mueller, Karsten; Guha, Anika] Max Planck Inst Human Cognit & Brain Sci, Dept Neurol, Leipzig, Germany.
   [Gouws, Andre; Andrews, Timothy J.; Slocombe, Katie E.] Univ York, Dept Psychol, York, N Yorkshire, England.
   [Levita, Liat] Univ Sheffield, Dept Psychol, Sheffield, S Yorkshire, England.
   [Fritz, Thomas] Univ Ghent, IPEM, Ghent, Belgium.
RP Andrews, TJ (corresponding author), Univ York, Dept Psychol, York, N Yorkshire, England.
EM timothy.andrews@york.ac.uk
OI Levita, Liat/0000-0001-6002-6817; Guha, Anika/0000-0002-4576-5037
CR Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2008, P ROY SOC B-BIOL SCI, V275, P473, DOI 10.1098/rspb.2007.1460
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   BORNSTEIN RF, 1992, J PERS SOC PSYCHOL, V63, P545, DOI 10.1037//0022-3514.63.4.545
   Buccino G, 2004, J COGNITIVE NEUROSCI, V16, P114, DOI 10.1162/089892904322755601
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   Darwin C., 1872, EXPRESSION EMOTIONS
   Dehaene-Lambertz G, 2005, NEUROIMAGE, V24, P21, DOI 10.1016/j.neuroimage.2004.09.039
   EKMAN P, 1980, J PERS SOC PSYCHOL, V39, P1125, DOI 10.1037/h0077722
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Fecteau S, 2004, NEUROIMAGE, V23, P840, DOI 10.1016/j.neuroimage.2004.09.019
   Fritz T., 2013, EVOLUTION EMOTIONAL
   Fritz T, 2009, CURR BIOL, V19, P573, DOI 10.1016/j.cub.2009.02.058
   HEFFNER HE, 1984, SCIENCE, V226, P75, DOI 10.1126/science.6474192
   Joly O, 2012, NEUROIMAGE, V62, P1376, DOI 10.1016/j.neuroimage.2012.05.070
   LINNANKOSKI I, 1994, LANG COMMUN, V14, P183, DOI 10.1016/0271-5309(94)90012-4
   McComb K, 2009, CURR BIOL, V19, pR507, DOI 10.1016/j.cub.2009.05.033
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   Mottonen R, 2006, NEUROIMAGE, V30, P563, DOI 10.1016/j.neuroimage.2005.10.002
   Pongracz P, 2005, J COMP PSYCHOL, V119, P136, DOI 10.1037/0735-7036.119.2.136
   Pongracz P, 2006, APPL ANIM BEHAV SCI, V100, P228, DOI 10.1016/j.applanim.2005.12.004
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   Sauter DA, 2007, MOTIV EMOTION, V31, P192, DOI 10.1007/s11031-007-9065-x
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Shultz S, 2012, J COGNITIVE NEUROSCI, V24, P1224, DOI 10.1162/jocn_a_00208
   Wiethoff S, 2008, NEUROIMAGE, V39, P885, DOI 10.1016/j.neuroimage.2007.09.028
   ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848
NR 29
TC 2
Z9 2
U1 0
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD MAR
PY 2018
VL 111
BP 145
EP 150
DI 10.1016/j.neuropsychologia.2018.01.026
PG 6
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA GD6UQ
UT WOS:000430644300018
PM 29366950
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Clunies-Ross, KL
   Campbell, C
   Ohan, JL
   Anderson, M
   Reid, C
   Fox, AM
AF Clunies-Ross, Karen L.
   Campbell, Catherine
   Ohan, Jeneva L.
   Anderson, Mike
   Reid, Corinne
   Fox, Allison M.
TI Hemispheric asymmetries in rapid temporal processing at age 7 predict
   subsequent phonemic decoding 2 years later: A longitudinal event-related
   potential (ERP) study
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Tb; Asymmetric sampling in time; Temporal integration; Hemispheric
   asymmetry; Event-related potential; Auditory processing; Phonemic
   decoding; Children
ID AUDITORY-EVOKED POTENTIALS; CLINICAL-APPLICATION; SPEECH-PERCEPTION;
   SYSTEM ACTIVITY; YOUNG-CHILDREN; T-COMPLEX; MATURATION; LANGUAGE;
   SPECIALIZATION; INTEGRATION
AB The asymmetric sampling in time hypothesis (AST) suggests that the left and right secondary auditory areas process auditory stimuli according to different sampling rates (Poeppel, 2003). We investigated whether asymmetries consistent with the AST are observable in children at age 7 and whether they become more pronounced at age 9. Data were collected from 50 children who attended a 2-day research program at age 7 and were followed up 2 years later. At both time points, children were presented with tone-pairs, each composed of two 50 ms, 1000 Hz, sinusoidal tones separated by inter-stimulus intervals (ISIS) of 25, 50, 100, or 200 ms. Stimuli were presented binaurally whilst the EEG was recorded. The Ta and Tb, which are components of the auditory event-related potential (ERP), were used as electrophysiological indices of auditory processing. There was no significant effect of age on Ta or Tb responses. Tb responses to the second tone of tone-pairs indicated a left-hemisphere preference for rapidly presented stimuli (50 ms ISI) and a right hemisphere preference for more slowly presented stimuli (100 and 200 ms ISI). The results provide evidence that auditory areas of the left hemisphere preferentially respond to fast temporal rates, and those of the right hemisphere preferentially respond to slow temporal rates in children at age 7 and 9. In 7-year-old children, leftward lateralisation of responses to rapidly presented tones predicted better phonemic decoding ability 2 years later, which suggests that hemispheric specialisation may be a precursor for subsequent phonemic decoding skills.
C1 [Clunies-Ross, Karen L.; Campbell, Catherine; Ohan, Jeneva L.; Anderson, Mike; Reid, Corinne; Fox, Allison M.] Univ Western Australia, Sch Psychol Sci, Neurocognit Dev Unit, M304,35 Stirling Highway, Perth, WA 6009, Australia.
   [Campbell, Catherine] King Edward Mem Hosp, Neonatal Clin Care Unit, POB 134, Perth, WA 6904, Australia.
   [Campbell, Catherine] Univ Western Australia, Sch Paediat & Child Hlth, Ctr Neonatal Res & Educ, GPO Box D184, Perth, WA 6840, Australia.
   [Reid, Corinne] Univ Edinburgh, Sch Hlth SocialSci, Sch Med, Doorway 6,Room 2-3,Teviot Pl, Edinburgh EH8 9AG, Midlothian, Scotland.
RP Clunies-Ross, KL (corresponding author), Univ Western Australia, Sch Psychol Sci, Neurocognit Dev Unit, M304,35 Stirling Highway, Perth, WA 6009, Australia.
EM Karen.clunies.ross@graduate.uwa.edu.au
RI Fox, Allison M/H-9218-2014
OI Fox, Allison M/0000-0001-5189-6271; Ohan, Jeneva/0000-0002-4801-4239
FU Australian Research CouncilAustralian Research Council [DP0665616];
   School of Psychological Science, The University of Western Australia;
   Australian Government Research Training Program ScholarshipAustralian
   GovernmentDepartment of Industry, Innovation and Science
FX This work was supported by the Australian Research Council [grant number
   DP0665616]; the School of Psychological Science, The University of
   Western Australia; The Australian Government Research Training Program
   Scholarship.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Albrecht R, 2000, CLIN NEUROPHYSIOL, V111, P2268, DOI 10.1016/S1388-2457(00)00464-8
   Bishop DVM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018993
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Campbell Julia, 2011, Seminars in Hearing, V32, P147, DOI 10.1055/s-0031-1277236
   Clunies-Ross KL, 2015, NEUROPSYCHOLOGIA, V68, P201, DOI 10.1016/j.neuropsychologia.2015.01.018
   Espy KA, 2004, ANN DYSLEXIA, V54, P9, DOI 10.1007/s11881-004-0002-3
   Fox AM, 2012, DEVELOPMENTAL SCI, V15, P204, DOI 10.1111/j.1467-7687.2011.01117.x
   Fox AM, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-49
   George D., 2010, SPSS WINDOWS STEP ST, V10th ed.
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Hakvoort B, 2015, CORTEX, V63, P90, DOI 10.1016/j.cortex.2014.08.013
   Irimia A, 2012, NEUROIMAGE, V59, P2464, DOI 10.1016/j.neuroimage.2011.08.104
   Jamison HL, 2006, CEREB CORTEX, V16, P1266, DOI 10.1093/cercor/bhj068
   LANG AH, 1995, EAR HEARING, V16, P118, DOI 10.1097/00003446-199502000-00009
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   Mahajan Y, 2013, INT J DEV NEUROSCI, V31, P1, DOI 10.1016/j.ijdevneu.2012.10.002
   Marinus E, 2013, AUST J LEARN DIFFIC, V18, P199, DOI 10.1080/19404158.2013.852981
   McArthur GM, 2003, BEHAV RES METH INS C, V35, P329, DOI 10.3758/BF03202561
   NAATANEN R, 1995, EAR HEARING, V16, P6
   Okamoto H, 2009, CEREB CORTEX, V19, P2290, DOI 10.1093/cercor/bhn245
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7
   Ruhnau P, 2011, NEUROIMAGE, V58, P630, DOI 10.1016/j.neuroimage.2011.06.050
   Sable JJ, 2004, PSYCHOPHYSIOLOGY, V41, P636, DOI 10.1111/j.1469-8986.2004.00192.x
   SEMLITSCH HV, 1986, PSYCHOPHYSIOLOGY, V23, P695, DOI 10.1111/j.1469-8986.1986.tb00696.x
   Shafer VL, 2015, INT J PSYCHOPHYSIOL, V95, P77, DOI 10.1016/j.ijpsycho.2014.08.1390
   Shafer VL, 2011, CLIN NEUROPHYSIOL, V122, P1137, DOI 10.1016/j.clinph.2010.10.046
   Steinbrink J, 2009, J NEUROSCI, V29, P14726, DOI [10.1523/1256, DOI 10.1523/1256]
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x
   Tallal P, 2006, TRENDS NEUROSCI, V29, P382, DOI 10.1016/j.tins.2006.06.003
   Tanna N., 2009, J OCCUP PSYCHOL, V11, P45
   Thompson EC, 2016, SCI REP-UK, V6, DOI 10.1038/srep19737
   Tonnquist-Uhlen I, 2003, CLIN NEUROPHYSIOL, V114, P685, DOI 10.1016/S1388-2457(03)00005-1
   Torgeson J., 1999, TEST WORD READING EF
   Vandewalle E, 2012, RES DEV DISABIL, V33, P635, DOI 10.1016/j.ridd.2011.11.005
   Vanvooren S, 2014, J NEUROSCI, V34, P1523, DOI 10.1523/JNEUROSCI.3209-13.2014
   Wagner M, 2017, J SPEECH LANG HEAR R, V60, P2105, DOI 10.1044/2017_JSLHR-H-16-0056
   Wagner M, 2013, BRAIN RES, V1522, P31, DOI 10.1016/j.brainres.2013.04.045
   WOLDORFF MG, 1993, PSYCHOPHYSIOLOGY, V30, P98, DOI 10.1111/j.1469-8986.1993.tb03209.x
   Wolf M., 1998, PSYCHOLINGUISTICS, V2, P409
   Zaehle T, 2004, EUR J NEUROSCI, V20, P2447, DOI 10.1111/j.1460-9568.2004.03687.x
NR 46
TC 0
Z9 0
U1 1
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD MAR
PY 2018
VL 111
BP 252
EP 260
DI 10.1016/j.neuropsychologia.2018.01.035
PG 9
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA GD6UQ
UT WOS:000430644300029
PM 29410292
DA 2021-02-24
ER

PT J
AU Lam, A
   Hodgson, M
   Prodi, N
   Visentin, C
AF Lam, Alice
   Hodgson, Murray
   Prodi, Nicola
   Visentin, Chiara
TI Effects of classroom acoustics on speech intelligibility and response
   time: A comparison between native and non-native listeners
SO BUILDING ACOUSTICS
LA English
DT Article
DE Speech intelligibility; response time; cross-language speech perception;
   subjective testing; classroom acoustics
ID PERCEPTION; NOISE; CHILDREN; HEARING
AB This study evaluates the speech reception performance of native (L1) and non-native (L2) normal-hearing young adults in acoustical conditions containing varying amounts of reverberation and background noise. Two metrics were used and compared: the intelligibility score and the response time, taken as a behavioral measure of listening effort. Listening tests were conducted in auralized acoustical environments with L1 and L2 English-speaking university students. It was found that even though the two groups achieved the same, close to the maximum accuracy, L2 participants manifested longer response times in every acoustical condition, suggesting an increased involvement of cognitive resources in the speech reception process.
C1 [Lam, Alice; Hodgson, Murray] Univ British Columbia, Vancouver, BC, Canada.
   [Prodi, Nicola; Visentin, Chiara] Univ Ferrara, Engn Dept, Via Saragat 1, I-44122 Ferrara, Italy.
RP Visentin, C (corresponding author), Univ Ferrara, Engn Dept, Via Saragat 1, I-44122 Ferrara, Italy.
EM chiara.visentin@unife.it
OI Prodi, Nicola/0000-0002-2654-6445
CR [Anonymous], S12602010 ANSI ASA
   [Anonymous], 99212003 ISO
   [Anonymous], S322009 ANSI
   [Anonymous], 60268162011 EN
   Broersma M, 2008, SYSTEM, V36, P22, DOI 10.1016/j.system.2007.11.003
   Darcy I, 2012, J PHONETICS, V40, P568, DOI 10.1016/j.wocn.2012.05.001
   Florentine M, 1985, P INT 85, V85, P1021
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Hallgren M, 2001, J Am Acad Audiol, V12, P357
   Houben R, 2013, INT J AUDIOL, V52, P753, DOI 10.3109/14992027.2013.832415
   Kilman L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00651
   Kjellberg A, 2004, Noise Health, V7, P11
   Lewis D, 2016, J SPEECH LANG HEAR R, V59, P1218, DOI 10.1044/2016_JSLHR-H-15-0207
   McCarthy KM, 2014, CHILD DEV, V85, P1965, DOI 10.1111/cdev.12275
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Mealings KT, 2015, J SPEECH LANG HEAR R, V58, P1350, DOI 10.1044/2015_JSLHR-H-14-0332
   NORRIS D, 1995, J EXP PSYCHOL LEARN, V21, P1209, DOI 10.1037/0278-7393.21.5.1209
   Pals C, 2015, J ACOUST SOC AM, V138, pEL187, DOI 10.1121/1.4929614
   Peng ZE, 2016, J ACOUST SOC AM, V139, P2772, DOI 10.1121/1.4948564
   Prodi N, 2013, J ACOUST SOC AM, V133, P255, DOI 10.1121/1.4770259
   Prodi N, 2010, J ACOUST SOC AM, V128, P172, DOI 10.1121/1.3436563
   R Core Team, 2017, R LANG ENV STAT COMP
   Steeneken HJM, 1992, MEASURING PREDICTING, P162
   Uslar VN, 2013, J ACOUST SOC AM, V134, P3039, DOI 10.1121/1.4818760
   van den Tillaart-Haverkate M, 2017, TRENDS HEAR, V21, P1, DOI 10.1177/2331216517716844
   van Wijngaarden SJ, 2002, J ACOUST SOC AM, V111, P1906, DOI 10.1121/1.1456928
   van Wijngaarden SJ, 2004, J ACOUST SOC AM, V115, P1281, DOI 10.1121/1.1647145
NR 27
TC 3
Z9 3
U1 4
U2 11
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1351-010X
EI 2059-8025
J9 BUILD ACOUST
JI Build. Acoustics
PD MAR
PY 2018
VL 25
IS 1
BP 35
EP 42
DI 10.1177/1351010X18758477
PG 8
WC Acoustics
SC Acoustics
GA GC4QA
UT WOS:000429768700003
DA 2021-02-24
ER

PT J
AU Hay-McCutcheon, MJ
   Peterson, NR
   Pisoni, DB
   Kirk, KI
   Yang, X
   Parton, J
AF Hay-McCutcheon, Marcia J.
   Peterson, Nathaniel R.
   Pisoni, David B.
   Kirk, Karen Iler
   Yang, Xin
   Parton, Jason
TI Performance variability on perceptual discrimination tasks in profoundly
   deaf adults with cochlear implants
SO JOURNAL OF COMMUNICATION DISORDERS
LA English
DT Article
DE Cochlear implants; Bimodal hearing; Speech discrimination
ID SPEECH-PERCEPTION; TEMPORAL CUES; ACOUSTIC STIMULATION; ELECTRIC
   HEARING; AMERICAN-ENGLISH; LOW-FREQUENCY; RECOGNITION; LISTENERS; USERS;
   IDENTIFICATION
AB Objectives: The purpose of this study was to evaluate performance on two challenging listening tasks, talker and regional accent discrimination, and to assess variables that could have affected the outcomes.
   Study design: A prospective study using 35 adults with one cochlear implant (CI) or a CI and a contralateral hearing aid (bimodal hearing) was conducted. Adults completed talker and regional accent discrimination tasks.
   Methods: Two-alternative forced-choice tasks were used to assess talker and accent discrimination in a group of adults who ranged in age from 30 years old to 81 years old.
   Results: A large amount of performance variability was observed across listeners for both discrimination tasks. Three listeners successfully discriminated between talkers for both listening tasks, 14 participants successfully completed one discrimination task and 18 participants were not able to discriminate between talkers for either listening task. Some adults who used bimodal hearing benefitted from the addition of acoustic cues provided through a HA but for others the HA did not help with discrimination abilities. Acoustic speech feature analysis of the test signals indicated that both the talker speaking rate and the fundamental frequency (FO) helped with talker discrimination. For accent discrimination, findings suggested that access to more salient spectral cues was important for better discrimination performance.
   Conclusions: The ability to perform challenging discrimination tasks successfully likely involves a number of complex interactions between auditory and non-auditory pre- and post-implant factors. To understand why some adults with CIs perform similarly to adults with normal hearing and others experience difficulty discriminating between talkers, further research will be required with larger populations of adults who use unilateral CIs, bilateral CIs and bimodal hearing.
C1 [Hay-McCutcheon, Marcia J.] Univ Alabama, Dept Commun Disorders, Speech & Hearing Ctr, Box 870242, Tuscaloosa, AL 35487 USA.
   [Peterson, Nathaniel R.] Loma Linda Univ, Med Ctr, Loma Linda, CA USA.
   [Pisoni, David B.] Indiana Univ, Dept Psychol & Brain Sci, Bloomington, IN 47405 USA.
   [Kirk, Karen Iler] Univ Illinois, Dept Commun Sci & Disorders, Champaign, IL USA.
   [Yang, Xin; Parton, Jason] Univ Alabama, Informat Syst, Management Sci, Stat, Tuscaloosa, AL 35487 USA.
RP Hay-McCutcheon, MJ (corresponding author), Univ Alabama, Dept Commun Disorders, Speech & Hearing Ctr, Box 870242, Tuscaloosa, AL 35487 USA.
EM mhaymccu@ua.edu
RI Hay-McCutcheon, Marcia/O-7375-2019
FU NIH/NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R03 DC008383, T32 DC00012]; Psi
   Iota XI Philanthropic Organization; NATIONAL INSTITUTE ON DEAFNESS AND
   OTHER COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R03DC008383,
   T32DC000012, T32DC000012, T32DC000012, T32DC000012, T32DC000012,
   T32DC000012, T32DC000012, T32DC000012, T32DC000012, T32DC000012,
   T32DC000012, R03DC008383, T32DC000012, T32DC000012, T32DC000012,
   T32DC000012, T32DC000012, T32DC000012, T32DC000012, T32DC000012,
   R03DC008383, T32DC000012, T32DC000012, T32DC000012, T32DC000012,
   T32DC000012, T32DC000012, R03DC008383, T32DC000012] Funding Source: NIH
   RePORTER
FX Funding for this study was provided by the NIH/NIDCD (R03 DC008383 to
   the first author and T32 DC00012 to the third author) and by the Psi
   Iota XI Philanthropic Organization.
CR Bierer JA, 2016, TRENDS HEAR, V20, P1
   Blamey P, 1996, Audiol Neurootol, V1, P293
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Blamey PJ, 2015, EAR HEARING, V36, P408, DOI 10.1097/AUD.0000000000000150
   Brown CA, 2009, J ACOUST SOC AM, V125, P1658, DOI 10.1121/1.3068441
   Ching T Y C, 2007, Trends Amplif, V11, P161, DOI 10.1177/1084713807304357
   Choi SJ, 2016, LARYNGOSCOPE, V126, P2817, DOI 10.1002/lary.26014
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Firszt JB, 2012, EAR HEARING, V33, P521, DOI 10.1097/AUD.0b013e31824b9dfc
   Fisher W., 1986, P DARPA WORKSH SPEEC, P93
   Francis HW, 2005, EAR HEARING, V26, p7S, DOI 10.1097/00003446-200508001-00003
   Fu QJ, 2005, J ACOUST SOC AM, V118, P1711, DOI 10.1121/1.1985024
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   GANTZ BJ, 1993, ANN OTO RHINOL LARYN, V102, P909, DOI 10.1177/000348949310201201
   Gifford RH, 2010, EAR HEARING, V31, P186, DOI 10.1097/AUD.0b013e3181c6b831
   Gomaa NA, 2003, EAR HEARING, V24, P539, DOI 10.1097/01.AUD.0000100208.26628.2D
   Hay-McCutcheon MJ, 2014, AM J AUDIOL, V23, P57, DOI 10.1044/1059-0889(2013/13-0009)
   Heydebrand G, 2007, AUDIOL NEURO-OTOL, V12, P254, DOI 10.1159/000101473
   Holden LK, 2016, OTOL NEUROTOL, V37, P1662, DOI 10.1097/MAO.0000000000001241
   Illg A, 2014, OTOL NEUROTOL, V35, pE240, DOI 10.1097/MAO.0000000000000529
   Incerti PV, 2013, TRENDS AMPLIF, V17, P3, DOI 10.1177/1084713813480857
   Ji CL, 2013, EAR HEARING, V34, P313, DOI 10.1097/AUD.0b013e31826fe79e
   KIRK KI, 2002, ASS RES OT 25 MIDW M
   Kong YY, 2012, EAR HEARING, V33, P645, DOI 10.1097/AUD.0b013e318252caae
   Kong YY, 2005, J ACOUST SOC AM, V117, P1351, DOI 10.1121/1.1857526
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Krull V, 2012, J ACOUST SOC AM, V131, P3069, DOI 10.1121/1.3688533
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Li TH, 2010, HEARING RES, V270, P81, DOI 10.1016/j.heares.2010.09.005
   Li YG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111707
   Li YX, 2011, J ACOUST SOC AM, V129, pEL242, DOI 10.1121/1.3582148
   MacMillan N. A., 2005, DETECTION THEORY USE
   Marx M, 2015, EAR HEARING, V36, P239, DOI 10.1097/AUD.0000000000000105
   Moberly AC, 2016, OTOL NEUROTOL, V37, P1522, DOI 10.1097/MAO.0000000000001211
   Moberly AC, 2016, EAR HEARING, V37, P14, DOI 10.1097/AUD.0000000000000204
   Mulhern Laura, 2014, Cochlear Implants Int, V15, P101, DOI 10.1179/1754762813Y.0000000057
   Nie K, 2006, EAR HEARING, V27, P208, DOI 10.1097/01.aud.0000202312.31837.25
   Pisoni D. B., 2017, EAR HEARING
   Reiss LAJ, 2016, JARO-J ASSOC RES OTO, V17, P341, DOI 10.1007/s10162-016-0570-z
   Schvartz KC, 2008, J ACOUST SOC AM, V124, P3972, DOI 10.1121/1.2997434
   Stickney GS, 2006, HEARING RES, V211, P33, DOI 10.1016/j.heares.2005.08.008
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
   Xu L, 2008, HEARING RES, V242, P132, DOI 10.1016/j.heares.2007.12.010
   Yoon Yang-Soo, 2015, Cochlear Implants Int, V16, P159, DOI 10.1179/1754762814Y.0000000101
   Yoon YS, 2012, J SPEECH LANG HEAR R, V55, P105, DOI 10.1044/1092-4388(2011/10-0325)
   Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102
NR 48
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0021-9924
EI 1873-7994
J9 J COMMUN DISORD
JI J. Commun. Disord.
PD MAR-APR
PY 2018
VL 72
BP 122
EP 135
DI 10.1016/j.jcomdis.2018.01.005
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GC2RA
UT WOS:000429629100011
PM 29395103
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Saito, K
   van Poeteren, K
AF Saito, Kazuya
   van Poeteren, Kim
TI The perception-production link revisited: The case of Japanese learners'
   English /r/ performance
SO INTERNATIONAL JOURNAL OF APPLIED LINGUISTICS
LA English
DT Article
DE English /r/; pronunciation; second language phonetics; speech
   perception; speech production
ID L-VERTICAL-BAR; AGE-OF-ONSET; AMERICAN ENGLISH; TALKER VARIABILITY;
   NATIVE SPEAKERS; L2 SPEECH; ACQUISITION; VOWELS; ADULTS; PRONUNCIATION
AB The current study re-examines how second language speech perception and production are related in the context of the acquisition of English /r/ by 45 adult Japanese learners with various proficiency levels. Perception was evaluated using a two-alternative forced choice identification task, while pronunciation performance was assessed via multiple task/analysis contexts. Overall, the participants' perception performance was correlated with the global qualities (accuracy, intelligibility) of their production ability both at controlled and spontaneous speech levels. In light of the results of acoustic analyses, however, their perception ability was only significantly predictive of their redeployment of existing articulatory parameters (i.e., lower F2 for the rate and degree of tongue retraction), not the acquisition of new articulatory parameters (i.e., lower F3 for labial, palatal, and pharyngeal constrictions).
C1 [Saito, Kazuya] Birkbeck Univ London, London, England.
   [van Poeteren, Kim] Bartlett Univ Coll London, London, England.
RP Saito, K (corresponding author), Birkbeck Univ London, Dept Appl Linguist & Commun, Room 334,25 Russell Sq, London WC1B 5DQ, England.
EM k.saito@bbk.ac.uk
OI Saito, Kazuya/0000-0002-4718-2943
CR Abrahamsson N, 2012, STUD SECOND LANG ACQ, V34, P187, DOI 10.1017/S0272263112000022
   Abrahamsson N, 2009, LANG LEARN, V59, P249, DOI 10.1111/j.1467-9922.2009.00507.x
   Baker W., 2006, IRAL-INT REV APPL LI, V44, P231, DOI [10.1515/IRAL.2006.010, DOI 10.1515/IRAL.2006.010]
   Baker W, 2008, LANG SPEECH, V51, P317, DOI 10.1177/0023830908099068
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bohn O.-S., 1997, 2 LANGUAGE SPEECH ST, P53
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Brinton L., 2000, CAMBRIDGE HIST ENGLI, P422
   Bundgaard-Nielsen RL, 2012, APPL PSYCHOLINGUIST, V33, P643, DOI 10.1017/S0142716411000518
   Cardoso W, 2011, SECOND LANG RES, V27, P433, DOI 10.1177/0267658311413540
   CHAMBERS JK, 1973, CAN J LING/REV CAN L, V18, P113
   Cobb T, 2010, COMPLEAT LEXICAL TUT
   DELATTRE P, 1968, LINGUISTICS, P29
   Derwing T., 2003, APPL LANGUAGE LEARNI, V13, P1
   Espy-Wilson CY, 2000, J ACOUST SOC AM, V108, P343, DOI 10.1121/1.429469
   ESPYWILSON CY, 1992, J ACOUST SOC AM, V92, P736, DOI 10.1121/1.403998
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   FLEGE JE, 1995, LANG SPEECH, V38, P25, DOI 10.1177/002383099503800102
   Flege JE, 1996, J ACOUST SOC AM, V99, P1161, DOI 10.1121/1.414884
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Granena G, 2013, SECOND LANG RES, V29, P311, DOI 10.1177/0267658312461497
   Hardison DM, 2003, APPL PSYCHOLINGUIST, V24, P495, DOI 10.1017/S0142716403000250
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Lambacher SG, 2005, APPL PSYCHOLINGUIST, V26, P227, DOI 10.1017/S0142716405050150
   Larson-Hall J, 2006, LANG SPEECH, V49, P521, DOI 10.1177/00238309060490040401
   Lee AH, 2016, STUD SECOND LANG ACQ, V38, P35, DOI 10.1017/S0272263115000194
   Lee B, 2006, STUD SECOND LANG ACQ, V28, P487, DOI 10.1017/S0272263106060207
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Lotto A. J., 2004, SOUND SENSE 50 YEARS, pC381
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   MAJOR Roy C., 2008, PHONOLOGY 2 LANGUAGE, P63, DOI DOI 10.1075/SIBIL.36.05MAJ
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   Munro M. J., 1998, STUDIES 2 LANGUAGE A, V20, P139, DOI DOI 10.1017/S0272263198002022
   Munro M.J., 2013, P 4 PRON 2 LANG LEAR
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   Rau DV, 2009, LANG LEARN, V59, P581, DOI 10.1111/j.1467-9922.2009.00518.x
   Saito K, 2014, INT J APPL LINGUIST, V24, P250, DOI 10.1111/ijal.12026
   Saito K, 2015, APPL PSYCHOLINGUIST, V36, P377, DOI 10.1017/S0142716413000271
   Saito K, 2014, STUD SECOND LANG ACQ, V36, P647, DOI 10.1017/S0272263114000114
   Saito K, 2013, J MEM LANG, V69, P546, DOI 10.1016/j.jml.2013.07.003
   Saito K, 2013, BILING-LANG COGN, V16, P847, DOI 10.1017/S1366728912000703
   Saito K, 2012, LANG AWARE, V21, P369, DOI 10.1080/09658416.2011.643891
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Thomson RI, 2012, LANG LEARN, V62, P1231, DOI 10.1111/j.1467-9922.2012.00724.x
   Trofimovich P, 2006, STUD SECOND LANG ACQ, V28, P1, DOI 10.1017/S0272263106060013
   Trofimovich P, 2009, STUD SECOND LANG ACQ, V31, P609, DOI 10.1017/S0272263109990040
   UNDERBAKKE M, 1988, J ACOUST SOC AM, V84, P90, DOI 10.1121/1.396878
   Zampini M. L., 2001, ONE MIND 2 LANGUAGES, P23
   Zhang Y, 2009, NEUROIMAGE, V46, P226, DOI 10.1016/j.neuroimage.2009.01.028
NR 56
TC 5
Z9 5
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0802-6106
EI 1473-4192
J9 INT J APPL LINGUIST
JI Int. J. Appl. Linguist.
PD MAR
PY 2018
VL 28
IS 1
BP 3
EP 17
DI 10.1111/ijal.12175
PG 15
WC Education & Educational Research; Linguistics; Language & Linguistics
SC Education & Educational Research; Linguistics
GA GA4UG
UT WOS:000428328100001
DA 2021-02-24
ER

PT J
AU Holzgrefe-Lang, J
   Wellmann, C
   Hohle, B
   Wartenburger, I
AF Holzgrefe-Lang, Julia
   Wellmann, Caroline
   Hoehle, Barbara
   Wartenburger, Isabell
TI Infants' Processing of Prosodic Cues: Electrophysiological Evidence for
   Boundary Perception beyond Pause Detection
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Language acquisition; speech perception; event-related potentials;
   prosody processing; prosodic boundary cues
ID EVENT-RELATED POTENTIALS; PHRASE BOUNDARY; CLAUSE SEGMENTATION;
   LANGUAGE; GERMAN; DURATION; ERP; ACQUISITION; SYNTAX; LIFE
AB Infants as young as six months are sensitive to prosodic phrase boundaries marked by three acoustic cues: pitch change, final lengthening, and pause. Behavioral studies suggest that a language-specific weighting of these cues develops during the first year of life; recent work on German revealed that eight-month-olds, unlike six-month-olds, are capable of perceiving a prosodic boundary on the basis of pitch change and final lengthening only. The present study uses Event-Related Potentials (ERPs) to investigate the neuro-cognitive development of prosodic cue perception in German-learning infants. In adults' ERPs, prosodic boundary perception is clearly reflected by the so-called Closure Positive Shift (CPS). To date, there is mixed evidence on whether an infant CPS exists that signals early prosodic cue perception, or whether the CPS emerges only later-the latter implying that infantile brain responses to prosodic boundaries reflect acoustic, low-level pause detection.
   We presented six-and eight-month-olds with stimuli containing either no boundary cues, only a pitch cue, or a combination of both pitch change and final lengthening. For both age groups, responses to the former two conditions did not differ, while brain responses to prosodic boundaries cued by pitch change and final lengthening showed a positivity that we interpret as a CPS-like infant ERP component. This hints at an early sensitivity to prosodic boundaries that cannot exclusively be based on pause detection. Instead, infants' brain responses indicate an early ability to exploit subtle, relational prosodic cues in speech perception-presumably even earlier than could be concluded from previous behavioral results.
C1 [Holzgrefe-Lang, Julia; Wellmann, Caroline; Hoehle, Barbara; Wartenburger, Isabell] Univ Potsdam, Potsdam, Germany.
RP Holzgrefe-Lang, J (corresponding author), Univ Potsdam, Dept Linguist, Cognit Sci, Karl Liebknecht Str 24-25, D-14476 Potsdam, Germany.
EM holzgref@uni-potsdam.de
RI Wartenburger, Isabell/A-2820-2013
OI Wartenburger, Isabell/0000-0001-5116-4441; Hohle,
   Barbara/0000-0002-9240-6117
FU German Science Foundation (Deutsche Forschungsgemeinschaft, DFG)German
   Research Foundation (DFG) [SPP 1234, FR 2865/2-1, HO 1960/13-1]
FX This research was funded by a grant from the German Science Foundation
   (Deutsche Forschungsgemeinschaft, DFG), priority program SPP 1234, to
   Isabell Wartenburger and Barbara Hohle (FR 2865/2-1; HO 1960/13-1).
CR Aasland WA, 2003, BRAIN LANG, V87, P385, DOI 10.1016/S0093-934X(03)00138-X
   American Clinical Neurophysiology Society, 2006, J Clin Neurophysiol, V23, P107
   BEACH CM, 1991, J MEM LANG, V30, P644, DOI 10.1016/0749-596X(91)90030-N
   Boersma P., 2010, PRAAT DOING PHONETIC
   Bogels S, 2011, LANG LINGUIST COMPAS, V5, P424, DOI 10.1111/j.1749-818x.2011.00291.x
   Bogels S, 2010, J COGNITIVE NEUROSCI, V22, P1036, DOI 10.1162/jocn.2009.21269
   Brugos A., 2014, P SPEECH PROSODY, P388
   Cumming R, 2011, J PHONETICS, V39, P375, DOI 10.1016/j.wocn.2011.01.004
   Cumming RE, 2010, PHONETICA, V67, P219, DOI 10.1159/000324132
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   Downing Bruce T., 1970, THESIS
   Friederici AD, 2007, CURR BIOL, V17, P1208, DOI 10.1016/j.cub.2007.06.011
   Gollhardt A., 2010, P 3 EL SYST INT TECH, P1
   Gout A, 2004, J MEM LANG, V51, P548, DOI 10.1016/j.jml.2004.07.002
   HIRSHPASEK K, 1987, COGNITION, V26, P269, DOI 10.1016/S0010-0277(87)80002-1
   HIRST D, 1998, INTONATION SYSTEMS S, P1
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   Holzgrefe-Lang J., 2016, LANG COGN NEUROSCI, P1
   Huynh H., 1976, J EDUC STATIST, V1, P69, DOI [10.3102/10769986001001069, DOI 10.3102/10769986001001069]
   Johnson EK, 2008, INFANCY, V13, P440, DOI 10.1080/15250000802329321
   Kushnerenko E, 2002, NEUROREPORT, V13, P47, DOI 10.1097/00001756-200201210-00014
   LEHISTE I, 1976, J ACOUST SOC AM, V60, P1199, DOI 10.1121/1.381180
   Mannel C, 2016, BRAIN RES, V1632, P27, DOI 10.1016/j.brainres.2015.12.009
   Mannel C, 2013, DEV COGN NEUROS-NETH, V5, P86, DOI 10.1016/j.dcn.2013.01.003
   Mannel C, 2008, DEVELOPMENTAL PSYCHOLINGUISTICS: ON-LINE METHODS IN CHILDREN'S LANGUAGE PROCESSING, P29
   Mannel C, 2011, DEVELOPMENTAL SCI, V14, P786, DOI 10.1111/j.1467-7687.2010.01025.x
   Mannel C, 2009, J COGNITIVE NEUROSCI, V21, P1988, DOI 10.1162/jocn.2009.21221
   MORRONGIELLO BA, 1987, J EXP CHILD PSYCHOL, V44, P413, DOI 10.1016/0022-0965(87)90043-9
   Nazzi T, 2000, INFANCY, V1, P123, DOI 10.1207/S15327078IN0101_11
   Nespor Marina, 1986, PROSODIC PHONOLOGY
   Pannekamp A, 2005, J COGNITIVE NEUROSCI, V17, P407, DOI 10.1162/0898929053279450
   Pannekamp A, 2006, NEUROREPORT, V17, P675, DOI 10.1097/00001756-200604240-00024
   Pauker E, 2011, J COGNITIVE NEUROSCI, V23, P2731, DOI 10.1162/jocn.2011.21610
   Peter V, 2014, BMC NEUROSCI, V15, DOI 10.1186/s12868-014-0129-z
   Peters B., 2005, PROSODIC STRUCTURES, P203
   Schmitz M., 2008, PERCEPTION CLAUSES 6
   SCOTT DR, 1982, J ACOUST SOC AM, V71, P996, DOI 10.1121/1.387581
   Seidl A, 2008, DEVELOPMENTAL SCI, V11, P596, DOI 10.1111/j.1467-7687.2008.00704.x
   Seidl A, 2007, J MEM LANG, V57, P24, DOI 10.1016/j.jml.2006.10.004
   Selkirk E, 2005, PHONOL PHONET, V9, P11, DOI 10.1515/9783110197587.1.11
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   Soderstrom M, 2003, J MEM LANG, V49, P249, DOI 10.1016/S0749-596X(03)00024-X
   Speer SR, 2009, LANG LINGUIST COMPAS, V3, P90, DOI 10.1111/j.1749-818x.2008.00103.x
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   STREETER LA, 1978, J ACOUST SOC AM, V64, P1582, DOI 10.1121/1.382142
   Truckenbrodt Hubert, 2005, LINGUISTISCHE BERICH, V203, P273
   Vaissiere J., 1983, PROSODY MODELS MEASU, P53, DOI [10.1007/978-3-642-69103-45, DOI 10.1007/978-3-642-69103-4_5]
   Wellmann C., PROSODIC BOUND UNPUB
   Wellmann C, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00580
   WIGHTMAN CW, 1992, J ACOUST SOC AM, V91, P1707, DOI 10.1121/1.402450
   Yang XH, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102166
   Yu Alan C. L., 2010, LAB PHONOLOGY, V10, P151, DOI DOI 10.1515/9783110224917.2.151
   Zhang X., 2012, THESIS
NR 53
TC 2
Z9 2
U1 0
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD MAR
PY 2018
VL 61
IS 1
BP 153
EP 169
DI 10.1177/0023830917730590
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA GB5FP
UT WOS:000429089400009
PM 28937300
DA 2021-02-24
ER

PT J
AU Luttke, CS
   Perez-Bellido, A
   de Lange, FP
AF Luttke, Claudia S.
   Perez-Bellido, Alexis
   de lange, Floris P.
TI Rapid recalibration of speech perception after experiencing the McGurk
   illusion
SO ROYAL SOCIETY OPEN SCIENCE
LA English
DT Article
DE perceptual learning; McGurk illusion; audiovisual integration;
   recalibration; signal detection theory
ID SELECTIVE ADAPTATION; VISUAL RECALIBRATION; AUDITORY SPEECH; LIPREAD
   SPEECH; INTEGRATION; INFORMATION; CATEGORIES; ATTENTION; BIASES; TOUCH
AB The human brain can quickly adapt to changes in the environment. One example is phonetic recalibration: a speech sound is interpreted differently depending on the visual speech and this interpretation persists in the absence of visual information. Here, we examined the mechanisms of phonetic recalibration. Participants categorized the auditory syllables /aba/ and /ada/, which were sometimes preceded by the so-called McGurk stimuli (in which an /aba/ sound, due to visual /aga/ input, is often perceived as 'ada'). We found that only one trial of exposure to the McGurk illusion was sufficient to induce a recalibration effect, i.e. an auditory /aba/ stimulus was subsequently more often perceived as 'ada'. Furthermore, phonetic recalibration took place only when auditory and visual inputs were integrated to 'ada' (McGurk illusion). Moreover, this recalibration depended on the sensory similarity between the preceding and current auditory stimulus. Finally, signal detection theoretical analysis showed that McGurk-induced phonetic recalibration resulted in both a criterion shift towards /ada/ and a reduced sensitivity to distinguish between /aba/ and /ada/ sounds. The current study shows that phonetic recalibration is dependent on the perceptual integration of audiovisual information and leads to a perceptual shift in phoneme categorization.
C1 [Luttke, Claudia S.; Perez-Bellido, Alexis; de lange, Floris P.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP de Lange, FP (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM floris.delange@donders.ru.nl
RI de Lange, Floris/D-2860-2009
OI de Lange, Floris/0000-0002-6730-1452; Perez-Bellido,
   Alexis/0000-0002-5027-9455
FU Donders Institute, Radboud University Nijmegen, The Netherlands; N.W.O.
   (Vidi grant)Netherlands Organization for Scientific Research (NWO)
   [452-13-016]; European Union Horizon Programme (ERC Starting grant)
   [678286]
FX C.S.L. was funded by an internal grant from the Donders Institute,
   Radboud University Nijmegen, The Netherlands. A.P.-B. and F.P.L. were
   supported by grants from N.W.O. (Vidi grant no. 452-13-016) and the
   European Union Horizon 2020 Programme (ERC Starting grant no. 678286,
   'Contextvision'), both awarded to F.P.L.
CR Abrahamyan A, 2016, P NATL ACAD SCI USA, V113, pE3548, DOI 10.1073/pnas.1518786113
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bruns P, 2011, EXP BRAIN RES, V209, P333, DOI 10.1007/s00221-011-2543-0
   Burr D, 2014, CURR BIOL, V24, pR1096, DOI 10.1016/j.cub.2014.10.002
   Clarke-Davidson CM, 2008, PERCEPT PSYCHOPHYS, V70, P604, DOI 10.3758/PP.70.4.604
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Frund I, 2014, J VISION, V14, DOI 10.1167/14.7.9
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   Gau R, 2016, NEUROIMAGE, V124, P876, DOI 10.1016/j.neuroimage.2015.09.045
   Green D. M., 1966, SIGNAL DETECTION THE
   Keetels M, 2015, COGNITION, V141, P121, DOI 10.1016/j.cognition.2015.04.019
   Kleinschmidt D. F., 2011, ACL HLT 2011, P10
   Luttke CS, 2016, SCI REP-UK, V6, DOI 10.1038/srep32891
   MacMillan N. A., 2005, DETECTION THEORY USE
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mitchel AD, 2016, J PHONETICS, V56, P66, DOI 10.1016/j.wocn.2016.02.003
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Samuel AG, 2014, J EXP PSYCHOL, V30, P1740, DOI [10.3174/ajnr.A1650.Side, DOI 10.3174/AJNR.A1650.SIDE]
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Tuomainen J, 2005, COGNITION, V96, pB13, DOI 10.1016/j.cognition.2004.10.004
   Van der Burg E, 2015, P ROY SOC B-BIOL SCI, V282, DOI 10.1098/rspb.2014.3083
   Van der Burg E, 2013, J NEUROSCI, V33, P14633, DOI 10.1523/JNEUROSCI.1182-13.2013
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, COGNITION, V110, P254, DOI 10.1016/j.cognition.2008.10.015
   Witt JK, 2015, PERCEPTION, V44, P289, DOI 10.1068/p7908
   Wozny DR, 2011, J NEUROSCI, V31, P4607, DOI 10.1523/JNEUROSCI.6079-10.2011
   Zaidel A, 2011, J NEUROSCI, V31, P13949, DOI 10.1523/JNEUROSCI.2732-11.2011
NR 40
TC 4
Z9 4
U1 0
U2 2
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 2054-5703
J9 ROY SOC OPEN SCI
JI R. Soc. Open Sci.
PD MAR
PY 2018
VL 5
IS 3
AR 170909
DI 10.1098/rsos.170909
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GB2IF
UT WOS:000428874600002
PM 29657743
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Keitel, A
   Gross, J
   Kayser, C
AF Keitel, Anne
   Gross, Joachim
   Kayser, Christoph
TI Perceptually relevant speech tracking in auditory and motor cortex
   reflects distinct linguistic features
SO PLOS BIOLOGY
LA English
DT Article
ID LOW-FREQUENCY OSCILLATIONS; CORTICAL OSCILLATIONS; COMPUTATIONAL
   PRINCIPLES; TEMPORAL STRUCTURE; ACTIVATES MOTOR; PREMOTOR CORTEX;
   ENTRAINMENT; PERCEPTION; COMPREHENSION; RESPONSES
AB During online speech processing, our brain tracks the acoustic fluctuations in speech at different timescales. Previous research has focused on generic timescales (for example, delta or theta bands) that are assumed to map onto linguistic features such as prosody or syllables. However, given the high intersubject variability in speaking patterns, such a generic association between the timescales of brain activity and speech properties can be ambiguous. Here, we analyse speech tracking in source-localised magnetoencephalographic data by directly focusing on timescales extracted from statistical regularities in our speech material. This revealed widespread significant tracking at the timescales of phrases (0.6-1.3 Hz), words (1.8-3 Hz), syllables (2.8-4.8 Hz), and phonemes (8-12.4 Hz). Importantly, when examining its perceptual relevance, we found stronger tracking for correctly comprehended trials in the left premotor (PM) cortex at the phrasal scale as well as in left middle temporal cortex at the word scale. Control analyses using generic bands confirmed that these effects were specific to the speech regularities in our stimuli. Furthermore, we found that the phase at the phrasal timescale coupled to power at beta frequency (13-30 Hz) in motor areas. This cross-frequency coupling presumably reflects top-down temporal prediction in ongoing speech perception. Together, our results reveal specific functional and perceptually relevant roles of distinct tracking and cross-frequency processes along the auditory-motor pathway.
C1 [Keitel, Anne; Gross, Joachim; Kayser, Christoph] Univ Glasgow, Inst Neurosci & Psychol, Glasgow, Lanark, Scotland.
   [Gross, Joachim] Univ Munster, Inst Biomagnetism & Biosignalanal, Munster, Germany.
   [Kayser, Christoph] Bielefeld Univ, Cognit Neurosci, Bielefeld, Germany.
RP Keitel, A (corresponding author), Univ Glasgow, Inst Neurosci & Psychol, Glasgow, Lanark, Scotland.
EM anne.keitel@glasgow.ac.uk
RI Gross, Joachim/C-5886-2009; Kayser, Christoph/A-3203-2012; Keitel,
   Anne/I-4992-2019
OI Gross, Joachim/0000-0002-3994-1006; Kayser,
   Christoph/0000-0001-7362-5704; Keitel, Anne/0000-0003-4498-0146
FU BBSRCUK Research & Innovation (UKRI)Biotechnology and Biological
   Sciences Research Council (BBSRC) [BB/L027534/1]; European Research
   CouncilEuropean Research Council (ERC)European Commission [646657];
   Wellcome TrustWellcome TrustEuropean Commission [098433]
FX BBSRC http://www.bbsrc.ac.uk/ (grant number BB/L027534/1) to CK and JG.
   The funder had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript. European Research
   Council https://erc.europa.eu/ (grant number 646657) to CK. The funder
   had no role in study design, data collection and analysis, decision to
   publish, or preparation of the manuscript. Wellcome Trust
   https://wellcome.ac.uk/ (grant number 098433) to JG. The funder had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Bengtsson SL, 2009, CORTEX, V45, P62, DOI 10.1016/j.cortex.2008.07.002
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bieniek MM, 2016, EUR J NEUROSCI, V44, P1804, DOI 10.1111/ejn.13100
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bouton S, 2018, P NATL ACAD SCI US
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Breska A, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001665
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cravo AM, 2011, J NEUROPHYSIOL, V106, P2964, DOI 10.1152/jn.00157.2011
   Cummins F, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00364
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00481
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Ghitza O, 2017, LANG COGN NEUROSCI, V32, P545, DOI 10.1080/23273798.2016.1232419
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Giordano BL, 2017, ELIFE, V6, DOI 10.7554/eLife.24763
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goswami U, 2013, LAB PHONOL, V4, P67, DOI 10.1515/lp-2013-0004
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893
   Grahn JA, 2013, CEREB CORTEX, V23, P913, DOI 10.1093/cercor/bhs083
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Iacoboni M, 2008, J PHYSIOL-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003
   Ince RAA, 2017, HUM BRAIN MAPP, V38, P1541, DOI 10.1002/hbm.23471
   Kayser C, 2015, J NEUROSCI, V35, P7750, DOI 10.1523/JNEUROSCI.0268-15.2015
   Kayser SJ, 2015, J NEUROSCI, V35, P14691, DOI 10.1523/JNEUROSCI.2243-15.2015
   Keitel A, 2018, DRYAD DIGITAL REPOSI
   Keitel A, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002498
   Keitel A, 2017, NEUROIMAGE, V147, P32, DOI 10.1016/j.neuroimage.2016.11.062
   Keitel C, 2017, NEUROIMAGE, V146, P58, DOI 10.1016/j.neuroimage.2016.11.043
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   KOIKE KJ, 1994, OTOLARYNG HEAD NECK, V111, P625, DOI 10.1016/S0194-5998(94)70531-3
   Kosem A, 2017, LANG COGN NEUROSCI, V32, P536, DOI 10.1080/23273798.2016.1238495
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lehiste I., 1976, CONT ISSUES EXPT PHO, V225, P239
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Luo H, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000445
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Meyer L, 2016, CEREB CORTEX
   Molinaro N, 2018, EUROPEAN J NEUROSCIE
   Morillon B, 2017, P NATL ACAD SCI USA
   Morillon B, 2015, CURR OPIN NEUROBIOL, V31, P230, DOI 10.1016/j.conb.2014.12.005
   Morillon B, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6255
   Nolte G, 2003, PHYS MED BIOL, V48, P3637, DOI 10.1088/0031-9155/48/22/002
   Obleser J, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00250
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pefkou M, 2017, J NEUROSCI, V37, P7930, DOI 10.1523/JNEUROSCI.2882-16.2017
   Pellegrino F, 2011, LANGUAGE, V87, P539
   Pena M, 2012, J COGNITIVE NEUROSCI, V24, P1149, DOI 10.1162/jocn_a_00144
   Poldrack RA, 2017, NAT REV NEUROSCI, V18, P115, DOI 10.1038/nrn.2016.167
   Saleh M, 2010, NEURON, V65, P461, DOI 10.1016/j.neuron.2010.02.001
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Schubotz RI, 2007, TRENDS COGN SCI, V11, P211, DOI 10.1016/j.tics.2007.02.006
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Strauss A, 2017, LANG COGN NEUROSCI, V32, P562, DOI 10.1080/23273798.2016.1253852
   ten Oever S, 2017, J NEUROSCI, V37, P4903, DOI 10.1523/JNEUROSCI.3658-16.2017
   Tsunada J, 2016, NAT NEUROSCI, V19, P135, DOI 10.1038/nn.4195
   Vaissiere J., 1983, PROSODY MODELS MEASU, P53, DOI [10.1007/978-3-642-69103-45, DOI 10.1007/978-3-642-69103-4_5]
   Vaissiere J, 2005, BLACKW HBK LINGUIST, P236, DOI 10.1002/9780470757024.ch10
   VanVeen BD, 1997, IEEE T BIO-MED ENG, V44, P867, DOI 10.1109/10.623056
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
   Zoefel B, 2015, J NEUROSCI, V35, P1954, DOI 10.1523/JNEUROSCI.3484-14.2015
NR 85
TC 47
Z9 49
U1 2
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1544-9173
EI 1545-7885
J9 PLOS BIOL
JI PLoS. Biol.
PD MAR
PY 2018
VL 16
IS 3
AR e2004473
DI 10.1371/journal.pbio.2004473
PG 19
WC Biochemistry & Molecular Biology; Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics
GA GB3VK
UT WOS:000428987600014
PM 29529019
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Koeritzer, MA
   Rogers, CS
   Van Engen, KJ
   Peelle, JE
AF Koeritzer, Margaret A.
   Rogers, Chad S.
   Van Engen, Kristin J.
   Peelle, Jonathan E.
TI The Impact of Age, Background Noise, Semantic Ambiguity, and Hearing
   Loss on Recognition Memory for Spoken Sentences
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID ADVERSE LISTENING CONDITIONS; OLDER-ADULTS; WORKING-MEMORY;
   WORD-RECOGNITION; SPEECH-PERCEPTION; LANGUAGE COMPREHENSION; DIVIDED
   ATTENTION; CONTEXT; ACUITY; INTELLIGIBILITY
AB Purpose: The goal of this study was to determine how background noise, linguistic properties of spoken sentences, and listener abilities (hearing sensitivity and verbal working memory) affect cognitive demand during auditory sentence comprehension.
   Method: We tested 30 young adults and 30 older adults. Participants heard lists of sentences in quiet and in 8-talker babble at signal-to-noise ratios of +15 dB and +5 dB, which increased acoustic challenge but left the speech largely intelligible. Half of the sentences contained semantically ambiguous words to additionally manipulate cognitive challenge. Following each list, participants performed a visual recognition memory task in which they viewed written sentences and indicated whether they remembered hearing the sentence previously.
   Results: Recognition memory (indexed by d') was poorer for acoustically challenging sentences, poorer for sentences containing ambiguous words, and differentially poorer for noisy high-ambiguity sentences. Similar patterns were observed for Z-transformed response time data. There were no main effects of age, but age interacted with both acoustic clarity and semantic ambiguity such that older adults' recognition memory was poorer for acoustically degraded high-ambiguity sentences than the young adults'. Within the older adult group, exploratory correlation analyses suggested that poorer hearing ability was associated with poorer recognition memory for sentences in noise, and better verbal working memory was associated with better recognition memory for sentences in noise.
   Conclusions: Our results demonstrate listeners' reliance on domain-general cognitive processes when listening to acoustically challenging speech, even when speech is highly intelligible. Acoustic challenge and semantic ambiguity both reduce the accuracy of listeners' recognition memory for spoken sentences.
C1 [Koeritzer, Margaret A.] Washington Univ, Program Audiol & Commun Sci, St Louis, MO USA.
   [Rogers, Chad S.; Peelle, Jonathan E.] Washington Univ, Dept Otolaryngol, St Louis, MO 63130 USA.
   [Van Engen, Kristin J.] Washington Univ, Dept Psychol & Brain Sci, St Louis, MO USA.
   [Van Engen, Kristin J.] Washington Univ, Program Linguist, St Louis, MO USA.
RP Peelle, JE (corresponding author), Washington Univ, Dept Otolaryngol, St Louis, MO 63130 USA.
EM jpeelle@wustl.edu
RI Peelle, Jonathan/AAA-8299-2020
OI Peelle, Jonathan/0000-0001-9194-854X; Van Engen,
   Kristin/0000-0001-9069-5464
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01DC014281]; Dana Foundation;
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC014281, R01DC014281, R01DC014281,
   R01DC014281, R01DC014281, R01DC014281] Funding Source: NIH RePORTER
FX The work reported here was supported by NIH Grant R01DC014281 and the
   Dana Foundation, both awarded to Jonathan E. Peelle. We thank Antje
   Heinrich for providing the multitalker babble. We are grateful to
   Brianne Noud, Sarah McConkey, Carol Iskiwitch, and Nina Punyamurthy for
   their help in data collection and to our volunteers for their
   participation.
CR ANDERSON JR, 1974, MEM COGNITION, V2, P406, DOI 10.3758/BF03196896
   Awh E, 2006, NEUROSCIENCE, V139, P201, DOI 10.1016/j.neuroscience.2005.08.023
   BALOTA DA, 1980, J EXP PSYCHOL-HUM L, V6, P576
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Cousins KAQ, 2014, MEM COGNITION, V42, P622, DOI 10.3758/s13421-013-0377-7
   Craik FIM, 1996, J EXP PSYCHOL GEN, V125, P159, DOI 10.1037/0096-3445.125.2.159
   Davis MH, 2007, P NATL ACAD SCI USA, V104, P16032, DOI 10.1073/pnas.0701309104
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   Davis MH, 2003, J NEUROSCI, V23, P3423
   DeCaro R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00236
   Dubno JR, 2000, J ACOUST SOC AM, V107, P538, DOI 10.1121/1.428322
   Eckert MA, 2009, HUM BRAIN MAPP, V30, P2530, DOI 10.1002/hbm.20688
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   Faust ME, 1999, PSYCHOL BULL, V125, P777, DOI 10.1037/0033-2909.125.6.777
   Fernandes MA, 2000, J EXP PSYCHOL GEN, V129, P155, DOI 10.1037/0096-3445.129.2.155
   Gazzaley A, 2012, TRENDS COGN SCI, V16, P129, DOI 10.1016/j.tics.2011.11.014
   Gilbert RC, 2014, J ACOUST SOC AM, V135, P389, DOI 10.1121/1.4838975
   Gordon-Salant S, 2004, J ACOUST SOC AM, V115, P1808, DOI 10.1121/1.1645249
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kemper S, 2001, PSYCHOL AGING, V16, P312, DOI 10.1037//0882-7974.16.2.312
   Kuchinsky SE, 2016, EXP AGING RES, V42, P64, DOI 10.1080/0361073X.2016.1108712
   Kuchinsky SE, 2013, PSYCHOPHYSIOLOGY, V50, P23, DOI 10.1111/j.1469-8986.2012.01477.x
   Lash A, 2013, EXP AGING RES, V39, P235, DOI 10.1080/0361073X.2013.779175
   MacMillan N. A., 2005, DETECTION THEORY USE
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Miller P, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00014
   Murphy DR, 2000, PSYCHOL AGING, V15, P323, DOI 10.1037/0882-7974.15.2.323
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Obleser J, 2014, LANG LINGUIST COMPAS, V8, P646, DOI 10.1111/lnc3.12098
   Oswald FL, 2015, BEHAV RES METHODS, V47, P1343, DOI 10.3758/s13428-014-0543-2
   Peelle J. E., 2017, EAR HEARING
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Piquado T, 2012, INT J AUDIOL, V51, P576, DOI 10.3109/14992027.2012.684403
   Piquado T, 2010, BRAIN RES, V1365, P48, DOI 10.1016/j.brainres.2010.09.070
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Rodd JM, 2012, CEREB CORTEX, V22, P1761, DOI 10.1093/cercor/bhr252
   Rodd JM, 2010, BRAIN LANG, V115, P182, DOI 10.1016/j.bandl.2010.07.005
   Rodd JM, 2010, NEUROPSYCHOLOGIA, V48, P1324, DOI 10.1016/j.neuropsychologia.2009.12.035
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Rogersa CS, 2015, J ACOUST SOC AM, V138, pEL26, DOI 10.1121/1.4922363
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rudner M, 2011, J AM ACAD AUDIOL, V22, P156, DOI 10.3766/jaaa.22.3.4
   Schneider BA, 2000, PSYCHOL AGING, V15, P110, DOI 10.1037/0882-7974.15.1.110
   Strand J, 2014, MEM COGNITION, V42, P676, DOI 10.3758/s13421-013-0378-6
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Vaden KI, 2017, NEUROIMAGE, V157, P381, DOI 10.1016/j.neuroimage.2017.06.028
   Vaden KI, 2015, J NEUROSCI, V35, P3929, DOI 10.1523/JNEUROSCI.2908-14.2015
   Vaden KI, 2013, J NEUROSCI, V33, P18979, DOI 10.1523/JNEUROSCI.1417-13.2013
   van Casteren M, 2007, BEHAV RES METHODS, V39, P973, DOI 10.3758/BF03192992
   Van Engen KJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043753
   Verhaeghen P, 2003, PSYCHOL AGING, V18, P332, DOI 10.1037/0882-7974.18.2.332
   Ward CM, 2016, EXP AGING RES, V42, P126, DOI 10.1080/0361073X.2016.1108785
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   WINGFIELD A, 1991, J GERONTOL, V46, pP127, DOI 10.1093/geronj/46.3.P127
   Wingfield A, 2006, J AM ACAD AUDIOL, V17, P487, DOI 10.3766/jaaa.17.7.4
   Yonelinas AP, 2012, MEM COGNITION, V40, P663, DOI 10.3758/s13421-012-0205-5
   Yonelinas AP, 2002, J MEM LANG, V46, P441, DOI 10.1006/jmla.2002.2864
   Zachary RA., 1986, SHIPLEY I LIVING SCA
   Zekveld AA, 2014, PSYCHOPHYSIOLOGY, V51, P277, DOI 10.1111/psyp.12151
NR 72
TC 9
Z9 9
U1 0
U2 17
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAR
PY 2018
VL 61
IS 3
BP 740
EP 751
DI 10.1044/2017_JSLHR-H-17-0077
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GA3TG
UT WOS:000428251900020
PM 29450493
OA Green Published
DA 2021-02-24
ER

PT J
AU Zekveld, AA
   Pronk, M
   Danielsson, H
   Ronnberg, J
AF Zekveld, Adriana A.
   Pronk, Marieke
   Danielsson, Henrik
   Roennberg, Jerker
TI Reading Behind the Lines: The Factors Affecting the Text Reception
   Threshold in Hearing Aid Users
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID WORKING-MEMORY; SPEECH RECEPTION; INDIVIDUAL-DIFFERENCES;
   COGNITIVE-FACTORS; PUPIL RESPONSE; NOISE; RECOGNITION; ABILITIES;
   INTELLIGIBILITY; COMPREHENSION
AB Purpose: The visual Text Reception Threshold (TRT) test (Zekveld et al., 2007) has been designed to assess modality-general factors relevant for speech perception in noise. In the last decade, the test has been adopted in audiology labs worldwide. The 1st aim of this study was to examine which factors best predict interindividual differences in the TRT. Second, we aimed to assess the relationships between the TRT and the speech reception thresholds (SRTs) estimated in various conditions.
   Method: First, we reviewed studies reporting relationships between the TRT and the auditory and/or cognitive factors and formulated specific hypotheses regarding the TRT predictors. These hypotheses were tested using a prediction model applied to a rich data set of 180 hearing aid users. In separate association models, we tested the relationships between the TRT and the various SRTs and subjective hearing difficulties, while taking into account potential confounding variables.
   Results: The results of the prediction model indicate that the TRT is predicted by the ability to fill in missing words in incomplete sentences, by lexical access speed, and by working memory capacity. Furthermore, in line with previous studies, a moderate association between higher age, poorer pure-tone hearing acuity, and poorer TRTs was observed. Better TRTs were associated with better SRTs for the correct perception of 50% of Hagerman matrix sentences in a 4-talker babble, as well as with better subjective ratings of speech perception. Age and pure-tone hearing thresholds significantly confounded these associations. The associations of the TRT with SRTs estimated in other conditions and with subjective qualities of hearing were not statistically significant when adjusting for age and pure-tone average.
   Conclusions: We conclude that the abilities tapped into by the TRT test include processes relevant for speeded lexical decision making when completing partly masked sentences and that these processes require working memory capacity. Furthermore, the TRT is associated with the SRT of hearing aid users as estimated in a challenging condition that includes informational masking and with experienced difficulties with speech perception in daily-life conditions. The current results underline the value of using the TRT test in studies involving speech perception and aid in the interpretation of findings acquired using the test.
C1 [Zekveld, Adriana A.; Danielsson, Henrik; Roennberg, Jerker] Linkoping Univ, Dept Behav Sci & Learning, Linkoping, Sweden.
   [Zekveld, Adriana A.; Danielsson, Henrik; Roennberg, Jerker] Swedish Inst Disabil Res, Linnaeus Ctr HEAD, Linkoping, Sweden.
   [Zekveld, Adriana A.; Pronk, Marieke] Vrije Univ Amsterdam Med Ctr, Amsterdam Publ Hlth Res Inst, Dept Otolaryngol Head & Neck Surg, Sect Ear & Hearing, Amsterdam, Netherlands.
RP Zekveld, AA (corresponding author), Linkoping Univ, Dept Behav Sci & Learning, Linkoping, Sweden.; Zekveld, AA (corresponding author), Swedish Inst Disabil Res, Linnaeus Ctr HEAD, Linkoping, Sweden.; Zekveld, AA (corresponding author), Vrije Univ Amsterdam Med Ctr, Amsterdam Publ Hlth Res Inst, Dept Otolaryngol Head & Neck Surg, Sect Ear & Hearing, Amsterdam, Netherlands.
EM aa.zekveld@vumc.nl
RI Pronk, Marieke/AAY-5839-2020
OI Pronk, Marieke/0000-0001-8472-4900; Zekveld, Adriana/0000-0003-1320-6908
FU Linnaeus Centre HEAD excellence center Grant from the Swedish Research
   Council [349-2007-8654]; FORTESwedish Research CouncilSwedish Research
   Council for Health Working Life & Welfare (Forte) [2012-1693]
FX This research was supported by a Linnaeus Centre HEAD excellence center
   Grant 349-2007-8654 from the Swedish Research Council and by a program
   grant from FORTE (Grant 2012-1693), awarded to Jerker Ronnberg.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Andersson U., 2001, J DEAF STUD DEAF EDU, V6, P103, DOI DOI 10.1093/DEAFED/6.2.103
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   BADDELEY A, 1985, J MEM LANG, V24, P119, DOI 10.1016/0749-596X(85)90019-1
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Besser J, 2013, TRENDS AMPLIF, V17, P75, DOI 10.1177/1084713813495459
   Besser J, 2012, J SPEECH LANG HEAR R, V55, P194, DOI 10.1044/1092-4388(2011/11-0008)
   BRAND T, 2000, ANAL OPTIMIZATION PS
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Classon E, 2013, J COMMUN DISORD, V46, P17, DOI 10.1016/j.jcomdis.2012.10.001
   DANEMAN M, 1983, J EXP PSYCHOL LEARN, V9, P561, DOI 10.1037/0278-7393.9.4.561
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   George ELJ, 2007, J ACOUST SOC AM, V121, P2362, DOI 10.1121/1.2642072
   Goverts ST, 2011, J SPEECH LANG HEAR R, V54, P1702, DOI 10.1044/1092-4388(2011/09-0268)
   GRAYSON DA, 1987, AM J EPIDEMIOL, V126, P546, DOI 10.1093/oxfordjournals.aje.a114687
   HAGERMAN B, 1995, SCAND AUDIOL, V24, P71, DOI 10.3109/01050399509042213
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203
   Hallgren M, 2006, INT J AUDIOL, V45, P227, DOI 10.1080/14992020500429583
   Hannon B, 2001, J EDUC PSYCHOL, V93, P103, DOI 10.1037/0022-0663.93.1.103
   Haumann S, 2012, AUDIOL RES, V2, P55, DOI 10.4081/audiores.2012.e12
   Heinrich A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00576
   Humes LE, 2007, J AM ACAD AUDIOL, V18, P590, DOI 10.3766/jaaa.18.7.6
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   International Organization for Standardization, 2000, 7029 ISO
   Koelewijn T, 2014, J ACOUST SOC AM, V135, P1596, DOI 10.1121/1.4863198
   Koelewijn Thomas, 2012, Int J Otolaryngol, V2012, P865731, DOI 10.1155/2012/865731
   Kramer SE, 2009, SCAND J PSYCHOL, V50, P507, DOI 10.1111/j.1467-9450.2009.00747.x
   Krull V, 2013, EAR HEARING, V34, pE14, DOI 10.1097/AUD.0b013e31826d0c27
   Le Goff N., 2015, CISC VIS NETW IND GL
   Logan Gordon D., 1994, P189
   Lunner T, 2007, J AM ACAD AUDIOL, V18, P604, DOI 10.3766/jaaa.18.7.7
   LYXELL B, 1994, SCAND AUDIOL, V23, P179, DOI 10.3109/01050399409047505
   LYXELL B, 1987, British Journal of Audiology, V21, P13, DOI 10.3109/03005368709077769
   LYXELL B, 1989, British Journal of Audiology, V23, P339, DOI 10.3109/03005368909076523
   Mishra S, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00096
   Mishra S, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00096
   Mishra S, 2013, J SPEECH LANG HEAR R, V56, P1120, DOI 10.1044/1092-4388(2012/12-0033)
   Miyake Akira, 2000, Seminars in Speech and Language, V21, P169, DOI 10.1055/s-2000-7563
   Moons KGM, 2015, ANN INTERN MED, V162, pW1, DOI 10.7326/M14-0698
   Moradi S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00359
   MORRIS N, 1990, BRIT J PSYCHOL, V81, P111, DOI 10.1111/j.2044-8295.1990.tb02349.x
   Nation K, 2004, J RES READ, V27, P342, DOI 10.1111/j.1467-9817.2004.00238.x
   Ng EHN, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514558688
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Noble W, 2006, INT J AUDIOL, V45, P172, DOI 10.1080/14992020500376933
   Pichora-Fuller M. K., 2007, HEARING CARE ADULTS, P71
   Plomp R., 2001, INTELLIGENT EAR NATU
   R Core Team, 2017, R LANG ENV STAT COMP
   RONNBERG J, 1989, J SPEECH HEAR RES, V32, P725, DOI 10.1044/jshr.3204.725
   Ronnberg J, 2003, INT J AUDIOL, V42, pS68
   Ronnberg J., 1990, EUROPEAN J COGNITIVE, V2, P253, DOI [10.1080/09541449008406207, DOI 10.1080/09541449008406207]
   Ronnberg J, 2016, INT J AUDIOL, V55, P623, DOI 10.1080/14992027.2016.1219775
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, J SPEECH LANG HEAR R, V54, P705, DOI 10.1044/1092-4388(2010/09-0088)
   Sauerbrei W, 1999, J ROY STAT SOC C-APP, V48, P313, DOI 10.1111/1467-9876.00155
   Schoof T, 2015, J ACOUST SOC AM, V138, pEL181, DOI 10.1121/1.4929627
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   Steyerberg EW, 2008, CLIN PREDICTION MODE
   Venables W. N, 2002, MODERN APPL STAT S
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   YNTEMA DB, 1963, HUM FACTORS, V5, P7, DOI 10.1177/001872086300500102
   Zekveld AA, 2007, J SPEECH LANG HEAR R, V50, P576, DOI 10.1044/1092-4388(2007/040)
   Zekveld AA, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00088
   Zekveld AA, 2013, J SPEECH LANG HEAR R, V56, P1364, DOI 10.1044/1092-4388(2013/12-0268)
   Zekveld AA, 2011, EAR HEARING, V32, pE16, DOI 10.1097/AUD.0b013e318228036a
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
   Zekveld AA, 2009, EAR HEARING, V30, P262, DOI 10.1097/AUD.0b013e3181987063
NR 70
TC 4
Z9 4
U1 0
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAR
PY 2018
VL 61
IS 3
BP 762
EP 775
DI 10.1044/2017_JSLHR-H-17-0196
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GA3TG
UT WOS:000428251900022
PM 29450534
DA 2021-02-24
ER

PT J
AU Tamura, S
   Ito, K
   Hirose, N
   Mori, S
AF Tamura, Shunsuke
   Ito, Kazuhito
   Hirose, Nobuyuki
   Mori, Shuji
TI Psychophysical Boundary for Categorization of Voiced-Voiceless Stop
   Consonants in Native Japanese Speakers
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID ONSET TIME CONTINUUM; SPEECH-PERCEPTION; CATEGORICAL PERCEPTION; VOICING
   PERCEPTION; CROSS-LANGUAGE; INITIAL STOPS; IDENTIFICATION; CHINCHILLA;
   INFANTS; HUMANS
AB Purpose: The purpose of this study was to investigate the psychophysical boundary used for categorization of voiced-voiceless stop consonants in native Japanese speakers.
   Method: Twelve native Japanese speakers participated in the experiment. The stimuli were synthetic stop consonant-vowel stimuli varying in voice onset time (VOT) with manipulation of the amplitude of the initial noise portion and the first formant (F1) frequency of the periodic portion. There were 3 tasks, namely, speech identification to either /d/ or /t/, detection of the noise portion, and simultaneity judgment of onsets of the noise and periodic portions.
   Results: The VOT boundaries of /d/-/t/ were close to the shortest VOT values that allowed for detection of the noise portion but not to those for perceived nonsimultaneity of the noise and periodic portions. The slopes of noise detection functions along VOT were as sharp as those of voiced-voiceless identification functions. In addition, the effects of manipulating the amplitude of the noise portion and the F1 frequency of the periodic portion on the detection of the noise portion were similar to those on voiced-voiceless identification.
   Conclusion: The psychophysical boundary of perception of the initial noise portion masked by the following periodic portion may be used for voiced-voiceless categorization by Japanese speakers.
C1 [Tamura, Shunsuke] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Fukuoka, Japan.
   [Ito, Kazuhito; Hirose, Nobuyuki; Mori, Shuji] Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka, Japan.
RP Tamura, S (corresponding author), Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Fukuoka, Japan.
EM tamuras@cog.inf.kyushu-u.ac.jp
FU Japan Society for the Promotion of Science for Scientific
   ResearchMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for
   Scientific Research (KAKENHI) [JP25240023]; Grants-in-Aid for Scientific
   ResearchMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for
   Scientific Research (KAKENHI) [25240023, 16K00208] Funding Source: KAKEN
FX The research was supported by a Grant-in-Aid of the Japan Society for
   the Promotion of Science for Scientific Research (A) JP25240023 to Shuji
   Mori.
CR Boersma P, 2015, PRAAT DOING PHONETIC
   Diehl RL, 2008, PHILOS T R SOC B, V363, P965, DOI 10.1098/rstb.2007.2153
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Elangovan S, 2008, EAR HEARING, V29, P761, DOI 10.1097/AUD.0b013e318185ddd2
   Elangovan S, 2011, NEUROSCI LETT, V490, P140, DOI 10.1016/j.neulet.2010.12.044
   ELLIOTT LL, 1971, AUDIOLOGY, V10, P65
   Hay J., 2005, ISCA WORKSH PLAST SP, P223
   HILLENBRAND J, 1984, J ACOUST SOC AM, V76, P18, DOI 10.1121/1.391094
   Holt LL, 2004, J ACOUST SOC AM, V116, P1763, DOI 10.1121/1.1778838
   Kishon-Rabin Liat, 2002, Journal of Basic and Clinical Physiology and Pharmacology, V13, P117
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Kuhl P. K., 2009, PERCEPTION SPEECH SO, P103
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lisker L., 1970, P 6 INT C PHON SCI P, P563
   MathWorks, 2014, MATLAB VERS 8 3 COMP
   Medina V, 2010, J PHONETICS, V38, P493, DOI 10.1016/j.wocn.2010.06.002
   MILLER JL, 1994, COGNITION, V50, P271, DOI 10.1016/0010-0277(94)90031-0
   PARKER EM, 1988, J ACOUST SOC AM, V83, P1597, DOI 10.1121/1.395914
   PISONI DB, 1977, J ACOUST SOC AM, V61, P1352, DOI 10.1121/1.381409
   Repp B. H., 1984, SR7778 HASK LAB, P31
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   REPP BH, 1979, LANG SPEECH, V22, P173, DOI 10.1177/002383097902200207
   Shimizu K., 1977, STUDIO PHONOLOGICA, V11, P25
   Shimizu K., 1999, J PHONETIC SOC JAPAN, V3, P4
   SIMON C, 1978, J ACOUST SOC AM, V63, P925, DOI 10.1121/1.381772
   Simos PG, 1998, COGNITIVE BRAIN RES, V7, P215, DOI 10.1016/S0926-6410(98)00037-8
   Simos PG, 1998, COGNITIVE BRAIN RES, V6, P285, DOI 10.1016/S0926-6410(98)00006-8
   Steinschneider M, 2005, CEREB CORTEX, V15, P170, DOI 10.1093/cercor/bhh120
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   SUMMERFIELD Q, 1982, J ACOUST SOC AM, V72, P51, DOI 10.1121/1.388024
NR 36
TC 3
Z9 3
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAR
PY 2018
VL 61
IS 3
BP 789
EP 796
DI 10.1044/2017_JSLHR-H-17-0131
PG 8
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GA3TG
UT WOS:000428251900024
PM 29516081
DA 2021-02-24
ER

PT J
AU Spinu, L
AF Spinu, Laura
TI Investigating the status of a rare cross-linguistic contrast: The case
   of Romanian palatalized postalveolars
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID LANGUAGE SPEECH-PERCEPTION; ENGLISH; WORD; CUES; CONSTRAINTS
AB This study examines a rare cross-linguistic contrast, that between plain and secondarily palatalized postalveolar fricatives, through (i) an acoustic analysis of the production of 31 Romanian speakers, and (ii) a perception experiment with a different group of 31 native speakers. Evidence of acoustic separation between plain and palatalized forms was found for 27 of the subjects, suggesting that the contrast is produced by the majority. This is consistent with previous reports of native speakers collected in 1961. These findings were supported by the results of the perceptual experiment, which showed that native speakers exhibit moderate sensitivity to this contrast. An examination of each of the two genders' production separately suggests that a process of neutralization may be in progress, more strongly realized by males compared to females. Aside from documenting this phenomenon in Romanian, an explanation is sought for its longevity, and it is proposed that grammatical restructuring offers the best account for the observed facts. (C) 2018 Acoustical Society of America.
C1 [Spinu, Laura] CUNY, Kingsborough Community Coll, Dept Commun & Performing Arts, 2001 Oriental Blvd,Room E313, Brooklyn, NY 11235 USA.
RP Spinu, L (corresponding author), CUNY, Kingsborough Community Coll, Dept Commun & Performing Arts, 2001 Oriental Blvd,Room E313, Brooklyn, NY 11235 USA.
EM lspinu@kbcc.cuny.edu
FU National Science FoundationNational Science Foundation (NSF) [0720231]
FX This research was supported in part by doctoral dissertation research
   improvement Grant No. 0720231 from the National Science Foundation.
   Special thanks are owed to Jason Lilley and Florin Spinu for helping
   with some of the analyses. The author is also indebted to two anonymous
   reviewers for their generous contribution.
CR Arbour J., 2012, THESIS
   Archibald LMD, 2011, J EXP PSYCHOL HUMAN, V37, P1275, DOI 10.1037/a0023506
   Arciuli J, 2009, SCI STUD READ, V13, P73, DOI 10.1080/10888430802633508
   ASLIN RN, 1998, HDB CHILD PSYCHOL, V2, P147
   Bateman Nicoleta, 2007, THESIS
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Beck M., 1999, Conference Proceedings. Eleventh International Conference on Indium Phosphide and Related Materials (IPRM'99) (Cat. No.99CH36362), P199, DOI 10.1109/ICIPRM.1999.773668
   Bhat D. N. S., 1978, UNIVERSALS HUMAN LAN, V2, P47
   Binder JR, 2005, NEUROIMAGE, V27, P677, DOI 10.1016/j.neuroimage.2005.04.029
   Browman C. P., 1995, MIND MOTION, P175
   Bunnell H. T., 2004, P INT 04 JEJ ISL KOR, P1313
   CAMPBELL L, 1974, LANGUAGE, V50, P52, DOI 10.2307/412009
   Carlton T. R., 1990, INTRO PHONOLOGICAL H, P461
   Chitoran I., 2002, PHONOLOGY ROMANIAN C, P292
   Deller JR, 1993, DISCRETE TIME PROCES
   Dieterman J., 2008, SECONDARY PALATALIZA
   Ferragne E, 2010, J PHONETICS, V38, P526, DOI 10.1016/j.wocn.2010.07.002
   FUJIMURA O, 1978, LANG SPEECH, V21, P337, DOI 10.1177/002383097802100408
   Gregoire S., 2006, GENDER LANGUAGE CHAN
   Hall T. A., 1997, PHONOLOGY CORONALS, P176
   Halle M., 1959, SOUND PATTERN RUSSIA, P206
   Haskell TR, 2003, J MEM LANG, V48, P760, DOI 10.1016/S0749-596X(03)00010-X
   Hawkins S, 2010, LAB PHONOLOGY, V10, P479
   Hayes Bruce, 2004, PHONETICALLY BASED P, P1, DOI DOI 10.1017/CBO9780511486401
   Janke V, 2015, SECOND LANG RES, V31, P137, DOI 10.1177/0267658314545836
   Jesus Luis M T, 2008, Computational Processing of the Portuguese Language. 8th International Conference, PROPOR 2008, P11, DOI 10.1007/978-3-540-85980-2_2
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kavitskaya Darya, 2006, LAB PHONOLOGY, V8, P589
   Kochetov A., 1998, P 1 HIGH DES STUD C, P43
   Kochetov A., 1999, TORONTO WORKING PAPE, V17, P171
   Kochetov A., 2002, PRODUCTION PERCEPTIO
   Kochetov A, 2017, J INT PHON ASSOC, V47, P321, DOI 10.1017/S0025100317000019
   Kochetov A, 2011, CAN J LING/REV CAN L, V56, P345, DOI 10.1353/cjl.2011.0028
   Kong YY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095001
   Labov W., 2001, PRINCIPLES LINGUISTI, V2, P592
   Lampitelli N, 2014, LINGUA, V140, P158, DOI 10.1016/j.lingua.2013.12.011
   Lavoie L. M., 2001, CONSONANT STRENGTH P, P214
   Lee JY, 2012, NEUROPSYCHOLOGIA, V50, P666, DOI 10.1016/j.neuropsychologia.2012.01.003
   Leminen A, 2016, J NEUROLINGUIST, V38, P26, DOI 10.1016/j.jneuroling.2015.10.003
   Litvin N., 2014, THESIS
   Mallinson G., 1986, ROMANCE LANGUAGES, P391
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   MESTER RA, 1989, LANGUAGE, V65, P258, DOI 10.2307/415333
   Nevalainen T., 2003, HIST SOCIOLINGUISTIC, P260
   Ohala J. J., 1990, PAPERS LABORATORY PH, P258, DOI DOI 10.1017/CBO9780511627736.014
   Operstein N., 2010, CONSONANT STRUCTURE, P234
   Padgett J., 2001, ROLE SPEECH PERCEPTI, P187
   Pearlmutter NJ, 1999, J MEM LANG, V41, P427, DOI 10.1006/jmla.1999.2653
   PIERREHUMBERT J, 1990, J PHONETICS, V18, P375, DOI 10.1016/S0095-4470(19)30380-8
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   R Core Team, 2012, R LANG ENV STAT COMP
   Rabiner L. R., 2011, THEORY APPL DIGITAL
   Ruhlen M., 1973, THESIS
   Sarlin M., 2014, ROMANIAN GRAMMAR, P378
   SCHANE SA, 1971, LANGUAGE, V47, P503, DOI 10.2307/412375
   Scharinger M, 2010, J NEUROLINGUIST, V23, P383, DOI 10.1016/j.jneuroling.2010.02.005
   Shin N. L., 2013, P 6 INT WORKSH SPAN, P135
   Spinu L., 2007, ROM LING 2006 36 LIN, P277
   Spinu L., 2010, THESIS
   Spinu L, 2016, J PHONETICS, V57, P40, DOI 10.1016/j.wocn.2016.05.002
   Spinu L, 2012, J PHONETICS, V40, P54, DOI 10.1016/j.wocn.2011.08.001
   Steriade D., 1999, UCLA WORKING PAPERS, V2, P25
   Stevens K., 1986, S INV VAR SPEECH PRO, P426
   Stevens KN, 2010, J PHONETICS, V38, P10, DOI 10.1016/j.wocn.2008.10.004
   Suteu V., 1961, STUDII SI CERCETARI, V12, P293
   Tan LH, 2001, NEUROREPORT, V12, P83, DOI 10.1097/00001756-200101220-00024
   Timberlake A., 2004, REFERENCE GRAMMAR RU, P503
   Trubetzkoy N., 1969, PRINCIPLES PHONOLOGY, P344
   Van der Weijer J., 2011, BLACKWELL COMPANION, P694
   Vance T. J., 1987, INTRO JAPANESE PHONO, P226
   Vasilescu I., 2014, P SLTU 2014, P161
   Vermeiren A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031595
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Wickens T., 2002, ELEMENTARY SIGNAL DE, P288
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
   Yarrington D., 2008, P ACL 08 HLT DEM SES, P28
   Zsiga EC, 2000, J PHONETICS, V28, P69, DOI 10.1006/jpho.2000.0109
   Zygis M., 2003, P 15 INT C PHON SCI, P395
NR 82
TC 1
Z9 1
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAR
PY 2018
VL 143
IS 3
BP 1235
EP 1251
DI 10.1121/1.5024350
PG 17
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FZ2JY
UT WOS:000427405300010
PM 29604669
OA Bronze
DA 2021-02-24
ER

PT J
AU Lemaitre, G
   Pyles, JA
   Halpern, AR
   Navolio, N
   Lehet, M
   Heller, LM
AF Lemaitre, Guillaume
   Pyles, John A.
   Halpern, Andrea R.
   Navolio, Nicole
   Lehet, Matthew
   Heller, Laurie M.
TI Who's that Knocking at My Door? Neural Bases of Sound Source
   Identification
SO CEREBRAL CORTEX
LA English
DT Article
DE action sounds; auditory cognition; dorsal and ventral pathways; sound
   identification
ID HUMAN AUDITORY-SYSTEM; ENVIRONMENTAL SOUNDS; DEFAULT MODE; HUMAN BRAIN;
   MANIPULATABLE OBJECTS; BIOLOGICAL MOTION; SPEECH-PERCEPTION;
   PATTERN-ANALYSIS; CEREBRAL-CORTEX; NEGATIVE BOLD
AB When hearing knocking on a door, a listener typically identifies both the action (forceful and repeated impacts) and the object (a thick wooden board) causing the sound. The current work studied the neural bases of sound source identification by switching listeners' attention toward these different aspects of a set of simple sounds during functional magnetic resonance imaging scanning: participants either discriminated the action or the material that caused the sounds, or they simply discriminated meaningless scrambled versions of them. Overall, discriminating action and material elicited neural activity in a left-lateralized frontoparietal network found in other studies of sound identification, wherein the inferior frontal sulcus and the ventral premotor cortex were under the control of selective attention and sensitive to task demand. More strikingly, discriminating materials elicited increased activity in cortical regions connecting auditory inputs to semantic, motor, and even visual representations, whereas discriminating actions did not increase activity in any regions. These results indicate that discriminating and identifying material requires deeper processing of the stimuli than discriminating actions. These results are consistent with previous studies suggesting that auditory perception is better suited to comprehend the actions than the objects producing sounds in the listeners' environment.
C1 [Lemaitre, Guillaume; Pyles, John A.; Navolio, Nicole; Lehet, Matthew; Heller, Laurie M.] Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
   [Lemaitre, Guillaume; Pyles, John A.; Navolio, Nicole; Lehet, Matthew; Heller, Laurie M.] Carnegie Mellon Univ, Ctr Neural Basis Cognit, Pittsburgh, PA 15213 USA.
   [Halpern, Andrea R.] Bucknell Univ, Dept Psychol, Lewisburg, PA 17837 USA.
   [Lemaitre, Guillaume] Ircam, One Pl Stravinsky, F-75004 Paris, France.
RP Lemaitre, G (corresponding author), Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.; Lemaitre, G (corresponding author), Carnegie Mellon Univ, Ctr Neural Basis Cognit, Pittsburgh, PA 15213 USA.; Lemaitre, G (corresponding author), Ircam, One Pl Stravinsky, F-75004 Paris, France.
EM GuillaumeJLemaitre@gmail.com
FU University Iuav of Venice; Rothberg Research Award in Human Brain
   Imaging; Ircam
FX Rothberg Research Award in Human Brain Imaging to GL. The writing of the
   article was partially supported by the University Iuav of Venice and
   Ircam.
CR Adams RB, 2002, NEUROIMAGE, V16, P361, DOI 10.1006/nimg.2002.1088
   Aglioti SM, 2010, EXP BRAIN RES, V206, P141, DOI 10.1007/s00221-010-2344-x
   Ahveninen J, 2006, P NATL ACAD SCI USA, V103, P14608, DOI 10.1073/pnas.0510480103
   Alain C, 2001, P NATL ACAD SCI USA, V98, P12301, DOI 10.1073/pnas.211209098
   Amedi A, 2005, EXP BRAIN RES, V166, P559, DOI 10.1007/s00221-005-2396-5
   Amedi A, 2007, NAT NEUROSCI, V10, P687, DOI 10.1038/nn1912
   Arnott SR, 2004, NEUROIMAGE, V22, P401, DOI 10.1016/j.neuroimage.2004.01.014
   Arnott SR, 2008, NEUROIMAGE, V43, P368, DOI 10.1016/j.neuroimage.2008.07.033
   Arnott SR, 2011, NEUROSCI BIOBEHAV R, V35, P2162, DOI 10.1016/j.neubiorev.2011.04.005
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Beauchamp MS, 2004, NAT NEUROSCI, V7, P1190, DOI 10.1038/nn1333
   Beauchamp MS, 2003, J COGNITIVE NEUROSCI, V15, P991, DOI 10.1162/089892903770007380
   Beauchamp MS, 2002, NEURON, V34, P149, DOI 10.1016/S0896-6273(02)00642-6
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bidet-Caulet A, 2005, NEUROIMAGE, V28, P132, DOI 10.1016/j.neuroimage.2005.06.018
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Bluvas EC, 2013, HEARING RES, V305, P10, DOI 10.1016/j.heares.2013.08.007
   Borst G, 2011, AM PSYCHOL, V66, P624, DOI 10.1037/a0024038
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Cant JS, 2007, CEREB CORTEX, V17, P713, DOI 10.1093/cercor/bhk022
   Carello C., 2005, MOVING IMAGE THEORY, P79
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen G, 2013, NEUROIMAGE, V73, P176, DOI 10.1016/j.neuroimage.2013.01.047
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Davis T, 2014, NEUROIMAGE, V97, P271, DOI 10.1016/j.neuroimage.2014.04.037
   Doehrmann O, 2008, NEUROPSYCHOLOGIA, V46, P2776, DOI 10.1016/j.neuropsychologia.2008.05.011
   Engel LR, 2009, NEUROIMAGE, V47, P1778, DOI 10.1016/j.neuroimage.2009.05.041
   Falkenberg LE, 2011, BRAIN COGNITION, V76, P276, DOI 10.1016/j.bandc.2011.02.006
   Fritz JB, 2007, CURR OPIN NEUROBIOL, V17, P437, DOI 10.1016/j.conb.2007.07.011
   Gazzola V, 2006, CURR BIOL, V16, P1824, DOI 10.1016/j.cub.2006.07.072
   Giordano BL, 2013, CEREB CORTEX, V23, P2025, DOI 10.1093/cercor/bhs162
   Giordano BL, 2010, BRAIN COGNITION, V73, P7, DOI 10.1016/j.bandc.2010.01.005
   Goll JC, 2011, NEUROPSYCHOLOGIA, V49, P2755, DOI 10.1016/j.neuropsychologia.2011.06.004
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Greenberg AS, 2010, J NEUROSCI, V30, P14330, DOI 10.1523/JNEUROSCI.4248-09.2010
   Grossman ED, 2005, VISION RES, V45, P2847, DOI 10.1016/j.visres.2005.05.027
   Houix O, 2012, J EXP PSYCHOL-APPL, V18, P52, DOI 10.1037/a0026240
   James TW, 2011, NEUROPSYCHOLOGIA, V49, P1807, DOI 10.1016/j.neuropsychologia.2011.03.004
   Kaplan Jonas T, 2007, Cogn Process, V8, P103, DOI 10.1007/s10339-007-0165-z
   Keysers C, 2003, EXP BRAIN RES, V153, P628, DOI 10.1007/s00221-003-1603-5
   Kiefer M, 2012, BRAIN LANG, V122, P120, DOI 10.1016/j.bandl.2012.05.007
   Klatzky RL, 2000, PRESENCE-TELEOP VIRT, V9, P399, DOI 10.1162/105474600566907
   Kunkler-Peck AJ, 2000, J EXP PSYCHOL HUMAN, V26, P279, DOI 10.1037/0096-1523.26.1.279
   Lakatos S, 1997, PERCEPT PSYCHOPHYS, V59, P1180, DOI 10.3758/BF03214206
   Laurienti PJ, 2004, J COGNITIVE NEUROSCI, V16, P1481, DOI 10.1162/0898929042568596
   Lehet M, NEURAL BIAS PR UNPUB
   Lemaitre G, 2013, EXP BRAIN RES, V226, P253, DOI 10.1007/s00221-013-3430-7
   Lemaitre G, 2012, J ACOUST SOC AM, V131, P1337, DOI 10.1121/1.3675946
   Lemaitre G, 2010, J EXP PSYCHOL-APPL, V16, P16, DOI 10.1037/a0018762
   Lewis JW, 2006, NEUROSCIENTIST, V12, P211, DOI 10.1177/1073858406288327
   Lewis JW, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00027
   Lewis JW, 2010, MULTISENSORY OBJECT PERCEPTION IN THE PRIMATE BRAIN, P155, DOI 10.1007/978-1-4419-5615-6_10
   Lewis JW, 2011, J COGNITIVE NEUROSCI, V23, P2079, DOI 10.1162/jocn.2010.21570
   Lewis JW, 2005, J NEUROSCI, V25, P5148, DOI 10.1523/JNEUROSCI.0419-05.2005
   Lewis JW, 2004, CEREB CORTEX, V14, P1008, DOI 10.1093/cercor/bhh061
   Lipschutz B, 2002, NEUROIMAGE, V17, P643, DOI 10.1006/nimg.2002.1184
   McAdams S, 2010, J ACOUST SOC AM, V128, P1401, DOI 10.1121/1.3466867
   McIntosh RD, 2009, NEUROPSYCHOLOGIA, V47, P1391, DOI 10.1016/j.neuropsychologia.2009.02.009
   Merabet L, 2004, NEURON, V42, P173, DOI 10.1016/S0896-6273(04)00147-3
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Nestor A, 2011, P NATL ACAD SCI USA, V108, P9998, DOI 10.1073/pnas.1102433108
   Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005
   Paltoglou AE, 2011, EUR J NEUROSCI, V33, P1733, DOI 10.1111/j.1460-9568.2011.07656.x
   Petersen SE, 2012, ANNU REV NEUROSCI, V35, P73, DOI 10.1146/annurev-neuro-062111-150525
   Pugh KR, 1996, NEUROIMAGE, V4, P159, DOI 10.1006/nimg.1996.0067
   Raichle ME, 2015, ANNU REV NEUROSCI, V38, P433, DOI 10.1146/annurev-neuro-071013-014030
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Shin YK, 2010, PSYCHOL BULL, V136, P943, DOI 10.1037/a0020541
   Shmuel A, 2002, NEURON, V36, P1195, DOI 10.1016/S0896-6273(02)01061-9
   Shomstein S, 2006, J NEUROSCI, V26, P435, DOI 10.1523/JNEUROSCI.4408-05.2006
   Shulman GL, 1997, J COGNITIVE NEUROSCI, V9, P648, DOI 10.1162/jocn.1997.9.5.648
   Vetter P, 2014, CURR BIOL, V24, P1256, DOI 10.1016/j.cub.2014.04.020
   Wade AR, 2002, NEURON, V36, P993, DOI 10.1016/S0896-6273(02)01138-8
   Zatorre RJ, 2004, J NEUROSCI, V24, P3637, DOI 10.1523/JNEUROSCI.5458-03.2004
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152
NR 76
TC 5
Z9 5
U1 0
U2 5
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD MAR
PY 2018
VL 28
IS 3
BP 805
EP 818
DI 10.1093/cercor/bhw397
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA FY4SZ
UT WOS:000426817600001
PM 28052922
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Beste, C
   Arning, L
   Gerding, WM
   Epplen, JT
   Mertins, A
   Roder, MC
   Bless, JJ
   Hugdahl, K
   Westerhausen, R
   Gunturkun, O
   Ocklenburg, S
AF Beste, Christian
   Arning, Larissa
   Gerding, Wanda M.
   Epplen, Joerg T.
   Mertins, Alexandra
   Roeder, Melanie C.
   Bless, Josef J.
   Hugdahl, Kenneth
   Westerhausen, Rene
   Guentuerkuen, Onur
   Ocklenburg, Sebastian
TI Cognitive Control Processes and Functional Cerebral Asymmetries:
   Association with Variation in the Handedness-Associated Gene LRRTM1
SO MOLECULAR NEUROBIOLOGY
LA English
DT Article
DE Cognitive control; Dichotic listening; Cerebral asymmetries; LRRTM1;
   Genetics; Smartphone
ID AUDITORY HALLUCINATIONS; LANGUAGE LATERALIZATION; SPEECH-PERCEPTION;
   NEURAL MECHANISMS; SCHIZOPHRENIA; ATTENTION; INVENTORY; PARADIGM
AB Cognitive control processes play an essential role not only in controlling actions but also in guiding attentional selection processes. Interestingly, these processes are strongly affected by organizational principles of the cerebral cortex and related functional asymmetries, but the neurobiological foundations are elusive. We ask whether neurobiological mechanisms that affect functional cerebral asymmetries will also modulate effects of top-down control processes on functional cerebral asymmetries. To this end, we examined potential effects of the imprinted gene leucine-rich repeat transmembrane neuronal 1 (LRRTM1) on attentional biasing processes in a forced attention dichotic listening task in 983 healthy adult participants of Caucasian descent using the "iDichotic smartphone app." The results show that functional cerebral asymmetries in the language domain are associated with the rs6733871 LRRTM1 polymorphism when cognitive control and top-down attentional mechanisms modulate processes in bottom-up attentional selection processes that are dependent on functional cerebral asymmetries. There is no evidence for an effect of LRRTM1 on functional cerebral asymmetries in the language domain unrelated to cognitive control processes. The results suggest that cognitive control processes are an important factor to consider when being interested in the molecular genetic basis of functional cerebral architecture.
C1 [Beste, Christian] Tech Univ Dresden, Fac Med, Dept Child & Adolescent Psychiat, Cognit Neurophysiol, Schubertstr 42, D-01309 Dresden, Germany.
   [Beste, Christian] Natl Inst Mental Hlth, Expt Neurobiol, Klecany, Czech Republic.
   [Arning, Larissa; Gerding, Wanda M.; Epplen, Joerg T.] Ruhr Univ Bochum, Dept Human Genet, Bochum, Germany.
   [Mertins, Alexandra; Roeder, Melanie C.] Ruhr Univ Bochum, Inst Cognit Neurosci, Dept Psychol, Biopsychol, Bochum, Germany.
   [Bless, Josef J.; Hugdahl, Kenneth] Univ Bergen, Dept Biol & Med Psychol, Bergen, Norway.
   [Hugdahl, Kenneth] Univ Oslo, NORMENT Ctr Excellence, Oslo, Norway.
   [Westerhausen, Rene] Univ Oslo, Dept Psychol, Oslo, Norway.
   [Hugdahl, Kenneth] Haukekland Univ Hosp, Dept Psychiat, Bergen, Norway.
RP Beste, C (corresponding author), Tech Univ Dresden, Fac Med, Dept Child & Adolescent Psychiat, Cognit Neurophysiol, Schubertstr 42, D-01309 Dresden, Germany.; Beste, C (corresponding author), Natl Inst Mental Hlth, Expt Neurobiol, Klecany, Czech Republic.
EM christian.beste@uniklinikum-dresden.de
RI Westerhausen, Rene/D-2441-2013; Ocklenburg, Sebastian/O-5867-2017
OI Westerhausen, Rene/0000-0001-7107-2712; Ocklenburg,
   Sebastian/0000-0001-5882-3200; Gunturkun, Onur/0000-0003-4173-5233;
   Hugdahl, Kenneth/0000-0002-0008-4326; Epplen, Joerg
   T./0000-0002-6087-3327
FU Deutsche Forschungsgemeinschaft (DFG)German Research Foundation (DFG)
   [Gu227/16-1, BE4045/26-1]
FX This work was funded by grants from the Deutsche Forschungsgemeinschaft
   (DFG) Gu227/16-1 and BE4045/26-1.
CR Beste C, 2016, BRAIN STRUCT FUNCT, V221, P2487, DOI 10.1007/s00429-015-1051-6
   Beste C, 2012, CURR BIOL, V22, P1914, DOI 10.1016/j.cub.2012.08.012
   Beste C, 2011, CURR BIOL, V21, P876, DOI 10.1016/j.cub.2011.03.065
   Bless JJ, 2015, LATERALITY, V20, P434, DOI 10.1080/1357650X.2014.997245
   Bless JJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00042
   BRYDEN MP, 1983, BRAIN LANG, V18, P236, DOI 10.1016/0093-934X(83)90018-4
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Dragovic M, 2004, LATERALITY, V9, P411, DOI 10.1080/13576500342000248
   Edlin JM, 2015, BRAIN COGNITION, V94, P44, DOI 10.1016/j.bandc.2015.01.003
   Ehlers CL, 2016, GENES BRAIN BEHAV, V15, P568, DOI 10.1111/gbb.12297
   Francks C, 2007, MOL PSYCHIATR, V12, P1129, DOI 10.1038/sj.mp.4002053
   GREEN MF, 1994, AM J PSYCHIAT, V151, P357
   Hjelmervik H, 2012, PSYCHONEUROENDOCRINO, V37, P1866, DOI 10.1016/j.psyneuen.2012.03.021
   HUGDAHL K, 1986, CORTEX, V22, P417, DOI 10.1016/S0010-9452(86)80005-3
   Hugdahl K, 2003, BIOL PSYCHIAT, V53, P609, DOI 10.1016/S0006-3223(02)01598-6
   Hugdahl K, 2016, NEUROPSYCHOLOGIA, V93, P466, DOI 10.1016/j.neuropsychologia.2015.12.011
   Hugdahl K, 2009, SCAND J PSYCHOL, V50, P553, DOI 10.1111/j.1467-9450.2009.00775.x
   Hugdahl K, 2009, SCAND J PSYCHOL, V50, P11, DOI 10.1111/j.1467-9450.2008.00676.x
   Kask M, 2011, BIOCHEM BIOPH RES CO, V411, P56, DOI 10.1016/j.bbrc.2011.06.085
   Knudsen EI, 2007, ANNU REV NEUROSCI, V30, P57, DOI 10.1146/annurev.neuro.30.051606.094256
   Kompus K, 2012, BRAIN LANG, V121, P240, DOI 10.1016/j.bandl.2012.03.004
   Ludwig KU, 2009, MOL PSYCHIATR, V14, P743, DOI 10.1038/mp.2009.28
   Ocklenburg S, 2016, BRAIN COGNITION, V109, P34, DOI 10.1016/j.bandc.2016.09.003
   Ocklenburg S, 2014, NEUROSCI BIOBEHAV R, V43, P191, DOI 10.1016/j.neubiorev.2014.04.008
   Ocklenburg S, 2013, BRAIN LANG, V126, P279, DOI 10.1016/j.bandl.2013.07.001
   Ocklenburg S, 2013, J INT NEUROPSYCH SOC, V19, P410, DOI 10.1017/S1355617712001476
   Ocklenburg S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053643
   Ocklenburg S, 2011, NEUROIMAGE, V55, P1771, DOI 10.1016/j.neuroimage.2011.01.035
   Oie M, 2008, SCHIZOPHR RES, V106, P29, DOI 10.1016/j.schres.2007.11.036
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Passow S, 2014, CEREB CORTEX, V24, P249, DOI 10.1093/cercor/bhs306
   Takashima N, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022716
   Westerhausen R, 2008, NEUROSCI BIOBEHAV R, V32, P1044, DOI 10.1016/j.neubiorev.2008.04.005
   Westerhausen R, 2015, DEV PSYCHOL, V51, P806, DOI 10.1037/dev0000014
   Westerhausen R, 2010, NEUROPSYCHOLOGIA, V48, P2075, DOI 10.1016/j.neuropsychologia.2010.03.028
NR 37
TC 4
Z9 4
U1 1
U2 6
PU HUMANA PRESS INC
PI TOTOWA
PA 999 RIVERVIEW DRIVE SUITE 208, TOTOWA, NJ 07512 USA
SN 0893-7648
EI 1559-1182
J9 MOL NEUROBIOL
JI Mol. Neurobiol.
PD MAR
PY 2018
VL 55
IS 3
BP 2268
EP 2274
DI 10.1007/s12035-017-0485-7
PG 7
WC Neurosciences
SC Neurosciences & Neurology
GA FY5TG
UT WOS:000426897800036
PM 28321770
DA 2021-02-24
ER

PT J
AU Perszyk, DR
   Ferguson, B
   Waxman, SR
AF Perszyk, Danielle R.
   Ferguson, Brock
   Waxman, Sandra R.
TI Maturation constrains the effect of exposure in linking language and
   thought: evidence from healthy preterm infants
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID FULL-TERM INFANTS; FACILITATE OBJECT CATEGORIZATION; SPEECH-PERCEPTION;
   1ST YEAR; DEVELOPMENTAL TRAJECTORIES; ATTENTIONAL PREFERENCE; PHONETIC
   PERCEPTION; RECOGNITION MEMORY; MODEL SELECTION; VISUAL FUNCTION
AB The power of human language rests upon its intricate links to human cognition. By 3 months of age, listening to language supports infants' ability to form object categories, a building block of cognition. Moreover, infants display a systematic shift between 3 and 4 months - a shift from familiarity to novelty preferences - in their expression of this link between language and core cognitive processes. Here, we capitalize on this tightly-timed developmental shift in fullterm infants to assess (a) whether it also appears in preterm infants and (b) whether it reflects infants' maturational status or the duration of their postnatal experience. Healthy late preterm infants (N = 22) participated in an object categorization task while listening to language. Their performance, coupled with that of fullterm infants, reveals that this developmental shift is evident in preterm infants and unfolds on the same maturational timetable as in their fullterm counterparts.
C1 [Perszyk, Danielle R.; Ferguson, Brock; Waxman, Sandra R.] Northwestern Univ, Dept Psychol, Evanston, IL USA.
   [Waxman, Sandra R.] Northwestern Univ, Inst Policy Res, Evanston, IL USA.
RP Perszyk, DR (corresponding author), 2029 Sheridan Rd, Evanston, IL 60208 USA.
EM danielleperszyk2017@u.northwestern.edu
FU National Institute of Child Health and Human Development of the National
   Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD08310]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH
   & HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD083310, R01HD083310, R01HD083310, R01HD083310, R01HD083310,
   R01HD083310] Funding Source: NIH RePORTER; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH &HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [F32HD008310, F32HD008310, F32HD008310]
   Funding Source: NIH RePORTER
FX National Institute of Child Health and Human Development of the National
   Institutes of Health, Grant/Award Number: R01HD08310
CR Agyei SB, 2016, NEUROPSYCHOLOGIA, V84, P89, DOI 10.1016/j.neuropsychologia.2016.02.001
   Aslin RN, 2007, DEVELOPMENTAL SCI, V10, P48, DOI 10.1111/j.1467-7687.2007.00563.x
   Balaban MT, 1997, J EXP CHILD PSYCHOL, V64, P3, DOI 10.1006/jecp.1996.2332
   Baron IS, 2012, NEUROPSYCHOL REV, V22, P438, DOI 10.1007/s11065-012-9210-5
   Barre N, 2011, J PEDIATR-US, V158, P766, DOI 10.1016/j.jpeds.2010.10.032
   Benasich AA, 2002, BEHAV BRAIN RES, V136, P31, DOI 10.1016/S0166-4328(02)00098-0
   Best C.T., 1991, DEV SPEECH PERCEPTIO, P167
   Bosch L, 2011, PROG BRAIN RES, V189, P239, DOI 10.1016/B978-0-444-53884-0.00028-2
   Bosworth RG, 2009, J VISION, V9, DOI 10.1167/9.13.15
   Boyle JD, 2013, ARCH DIS CHILD-FETAL, V98, pF85, DOI 10.1136/archdischild-2011-300535
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Caskey M, 2011, PEDIATRICS, V128, P910, DOI 10.1542/peds.2011-0609
   Celik IH, 2013, J MATERN-FETAL NEO M, V26, P459, DOI 10.3109/14767058.2012.735994
   Clements KM, 2007, PEDIATRICS, V119, pE866, DOI 10.1542/peds.2006-1729
   Colombo J, 2002, CURR DIR PSYCHOL SCI, V11, P196, DOI 10.1111/1467-8721.00199
   COLOMBO J, 1983, INFANT BEHAV DEV, V6, P305, DOI 10.1016/S0163-6383(83)80039-3
   Connell AM, 2006, INFANT CHILD DEV, V15, P609, DOI 10.1002/icd.481
   deRegnier RA, 2002, DEV PSYCHOBIOL, V41, P216, DOI 10.1002/dev.10070
   Ferguson B, 2016, COGNITION, V146, P185, DOI 10.1016/j.cognition.2015.09.020
   Ferguson B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01319
   Ferry AL, 2013, P NATL ACAD SCI USA, V110, P15231, DOI 10.1073/pnas.1221166110
   Ferry AL, 2010, CHILD DEV, V81, P472, DOI 10.1111/j.1467-8624.2009.01408.x
   Frick JE, 2000, INFANCY, V1, P375, DOI 10.1207/S15327078IN0103_6
   Fulkerson AL, 2007, COGNITION, V105, P218, DOI 10.1016/j.cognition.2006.09.005
   Gonzalez-Gomez N, 2012, DEVELOPMENTAL SCI, V15, P885, DOI 10.1111/j.1467-7687.2012.01186.x
   Harijan P, 2012, SEMIN FETAL NEONAT M, V17, P159, DOI 10.1016/j.siny.2012.02.002
   Havy M., CHILD DEV IN PRESS
   Hensch TK, 2004, ANNU REV NEUROSCI, V27, P549, DOI 10.1146/annurev.neuro.27.070203.144327
   Hirsh-Pasek K, 2006, MERRILL PALMER QUART, V52, P449, DOI 10.1353/mpq.2006.0027
   Hitzert MM, 2015, EARLY HUM DEV, V91, P89, DOI 10.1016/j.earlhumdev.2014.12.006
   HUNT JM, 1970, J GENET PSYCHOL, V117, P99, DOI 10.1080/00221325.1970.10533940
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jando G, 2012, P NATL ACAD SCI USA, V109, P11049, DOI 10.1073/pnas.1203096109
   Jansson-Verkasalo E, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-88
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   Kavsek M, 2010, RES DEV DISABIL, V31, P951, DOI 10.1016/j.ridd.2010.04.016
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lipkind HS, 2012, AM J OBSTET GYNECOL, V206, DOI 10.1016/j.ajog.2012.01.007
   Mash C., 1998, DEVELOPMENTAL SCI, V1, P84
   Matthews A, 1996, CHILD DEV, V67, P2658, DOI 10.2307/1131745
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   Nepomnyaschy L, 2012, MATERN CHILD HLTH J, V16, P1612, DOI 10.1007/s10995-011-0853-2
   Newport E. L., 2001, LANGUAGE BRAIN COGNI, P481, DOI DOI 10.1067/MHN.2001.115372
   NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1016/0364-0213(90)90024-Q
   Odd DE, 2012, DEV MED CHILD NEUROL, V54, P704, DOI 10.1111/j.1469-8749.2012.04315.x
   Pena M, 2002, SCIENCE, V298, P604, DOI 10.1126/science.1072901
   Pena M, 2014, PSYCHOL SCI, V25, P1884, DOI 10.1177/0956797614544307
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Perone S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00648
   Perszyk DR, 2016, COGNITION, V153, P175, DOI 10.1016/j.cognition.2016.05.004
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   Reynolds GD, 2016, FRONT SYST NEUROSCI, V10, DOI 10.3389/fnsys.2016.00015
   Ricci D, 2008, PEDIATRICS, V122, pE1193, DOI 10.1542/peds.2008-1888
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Roder BJ, 2000, INFANCY, V1, P491, DOI 10.1207/S15327078IN0104_9
   Romeo DM, 2012, EARLY HUM DEV, V88, P301, DOI 10.1016/j.earlhumdev.2011.08.024
   Rose SA, 2004, DEV REV, V24, P74, DOI 10.1016/j.dr.2003.09.004
   Rose SA, 2002, DEV PSYCHOL, V38, P895, DOI 10.1037//0012-1649.38.6.895
   Schwichtenberg AJ, 2011, J DEV BEHAV PEDIATR, V32, P8, DOI 10.1097/DBP.0b013e3181fa57e4
   Shinskey JL, 2010, DEVELOPMENTAL SCI, V13, P378, DOI 10.1111/j.1467-7687.2009.00899.x
   Slater A, 2004, INFANT CHILD DEV, V13, P353, DOI 10.1002/icd.356
   Stolarova M, 2003, INFANCY, V4, P437, DOI 10.1207/S15327078IN0403_07
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   UZGIRIS IC, 1970, J GENET PSYCHOL, V117, P109, DOI 10.1080/00221325.1970.10533941
   VANHOFVANDUIN J, 1986, VISION RES, V26, P909, DOI 10.1016/0042-6989(86)90149-5
   Vouloumanos A, 2004, DEVELOPMENTAL SCI, V7, P270, DOI 10.1111/j.1467-7687.2004.00345.x
   Vouloumanos A, 2014, TRENDS COGN SCI, V18, P642, DOI 10.1016/j.tics.2014.10.001
   Vrieze SI, 2012, PSYCHOL METHODS, V17, P228, DOI 10.1037/a0027127
   Waxman S. R., 2006, HDB CHILD PSYCHOL, P299, DOI DOI 10.1002/9780470147658.CHPSY0207/FULL
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   WEIZMANN F, 1971, DEV PSYCHOL, V4, P149, DOI 10.1037/h0030432
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   WETHERFORD MJ, 1973, CHILD DEV, V44, P416, DOI 10.2307/1127994
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 83
TC 4
Z9 4
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD MAR
PY 2018
VL 21
IS 2
AR e12522
DI 10.1111/desc.12522
PG 9
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA FY6XM
UT WOS:000427006200005
PM 28032433
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Westerhausen, R
   Poldver, N
   Naar, R
   Radziun, D
   Kaarep, MS
   Kreegipuu, K
   Hugdahl, K
   Lippus, P
   Kompus, K
AF Westerhausen, Rene
   Poldver, Nele
   Naar, Richard
   Radziun, Dominika
   Kaarep, Maria Silvia
   Kreegipuu, Kairi
   Hugdahl, Kenneth
   Lippus, Partel
   Kompus, Kristiina
TI Effect of voicing on perceptual auditory laterality in Estonian and
   Norwegian native speakers
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
DE brain asymmetry; dichotic listening; experiential differences;
   perceptual auditory laterality; voicing
ID CONSONANT-VOWEL SYLLABLES; RIGHT-EAR ADVANTAGE; SPEECH-PERCEPTION; BRAIN
   ASYMMETRY; STIMULUS DOMINANCE; ONSET-TIME; ATTENTION; FMRI; CHILDREN;
   AGE
AB As a reliable and valid measures of perceptual auditory laterality, dichotic listening has been successfully applied in studies in many countries and languages. However, languages differ in the linguistic relevance of change in initial phoneme of words (e.g., for word identification). In the present cross-language study, we examine the effect of these differences on dichotic-listening task performance to establish how characteristics of one's native language affect the perception of nonnative phonological features. We compared 33 native speakers of Norwegian, a language characterized by a clear distinction between voiced and unvoiced initial plosive consonants, with 30 native speakers of Estonian, a language that has exclusively unvoiced initial phonemes. Using a free-report dichotic-listening paradigm utilizing pairs of voiced (/ba/, /da/, /ga/) and unvoiced (/pa/, /ta/, /ka/) stop-consonant vowels as stimulus material, the Norwegian native speakers were found to be more sensitive to the voicing of the initial plosive than the Estonian group. Voicing explained 69% and 18% of the variance in the perceptual auditory laterality in the Norwegian and the Estonian sample, respectively. This indicates that experiential differences, likely during acquisition of the mother tongue in early development, permanently shape the sensitivity to the voicing contrast.
C1 [Westerhausen, Rene; Radziun, Dominika] Univ Oslo, Oslo, Norway.
   [Poldver, Nele; Naar, Richard; Kaarep, Maria Silvia; Kreegipuu, Kairi; Lippus, Partel] Univ Tartu, Tartu, Estonia.
   [Hugdahl, Kenneth; Kompus, Kristiina] Univ Bergen, Bergen, Norway.
   [Hugdahl, Kenneth] Haukeland Hosp, Bergen, Norway.
   [Kompus, Kristiina] Tallinn Univ, Tallinn, Estonia.
RP Westerhausen, R (corresponding author), Univ Oslo, Dept Psychol, Res Grp Lifespan Changes Brain & Cognit, POB 1094, N-0317 Oslo, Norway.
EM rene.westerhausen@psykologi.uio.no
RI Poldver, Nele/AAR-2230-2020; Westerhausen, Rene/D-2441-2013; Kreegipuu,
   Kairi/H-8480-2018; Lippus, Partel/B-7420-2011
OI Westerhausen, Rene/0000-0001-7107-2712; Kreegipuu,
   Kairi/0000-0002-0953-7264; Lippus, Partel/0000-0003-4407-811X; Hugdahl,
   Kenneth/0000-0002-0008-4326; Poldver, Nele/0000-0001-7307-544X
FU Norwegian Financial Mechanism through the Norwegian-Estonian Research
   Cooperation Programme [EMP180]; Department of Psychology, University of
   Oslo
FX This work was supported by funding from Norwegian Financial Mechanism
   2009-2014 through the Norwegian-Estonian Research Cooperation Programme
   Grant EMP180 and by internal funding from the Department of Psychology,
   University of Oslo.
CR Andersson M, 2008, CHILD NEUROPSYCHOL, V14, P470, DOI 10.1080/09297040701756925
   Arciuli J, 2010, LATERALITY, V15, P343, DOI 10.1080/13576500902799671
   Asu EL, 2009, J INT PHON ASSOC, V39, P367, DOI 10.1017/S002510030999017X
   Bayazit O, 2009, NEUROPSYCHOLOGIA, V47, P536, DOI 10.1016/j.neuropsychologia.2008.10.002
   BERLIN CI, 1973, J ACOUST SOC AM, V53, P699, DOI 10.1121/1.1913381
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Bless JJ, 2015, LATERALITY, V20, P434, DOI 10.1080/1357650X.2014.997245
   Bless JJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00042
   Brancucci A, 2008, HUM BRAIN MAPP, V29, P253, DOI 10.1002/hbm.20385
   Bryden M. P., 1988, HDB DICHOTIC LISTENI, DOI DOI 10.1002/ACP.2350040307
   CUTTING JE, 1976, PSYCHOL REV, V83, P114, DOI 10.1037/0033-295X.83.2.114
   European Commission , 2012, EUR THEIR LANG FACTS
   Fernandes MA, 2006, BRAIN LANG, V96, P106, DOI 10.1016/j.bandl.2005.06.006
   Gadea M, 2009, BRAIN LANG, V110, P101, DOI 10.1016/j.bandl.2009.03.006
   Galle ME, 2014, PSYCHON B REV, V21, P884, DOI 10.3758/s13423-013-0569-y
   GERBER SE, 1971, J ACOUST SOC AM, V49, P1163, DOI 10.1121/1.1912478
   Hellige J. B., 1993, HEMISPHERIC ASYMMETR
   Hirnstein M, 2013, CORTEX, V49, P1910, DOI 10.1016/j.cortex.2012.08.002
   Hiscock M, 1999, NEUROPSYCHOLOGY, V13, P404, DOI 10.1037/0894-4105.13.3.404
   Hiscock M, 2011, BRAIN COGNITION, V76, P263, DOI 10.1016/j.bandc.2011.03.016
   HUGDAHL K, 1986, CORTEX, V22, P417, DOI 10.1016/S0010-9452(86)80005-3
   Hugdahl K, 2003, ASYMMETRICAL BRAIN, P441
   Hugdahl K, 2011, BRAIN COGNITION, V76, P211, DOI 10.1016/j.bandc.2011.03.006
   Hugdahl K, 2009, SCAND J PSYCHOL, V50, P11, DOI 10.1111/j.1467-9450.2008.00676.x
   Kompus K, 2012, BRAIN LANG, V121, P240, DOI 10.1016/j.bandl.2012.03.004
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Rimol LM, 2006, NEUROPSYCHOLOGIA, V44, P191, DOI 10.1016/j.neuropsychologia.2005.05.006
   Sandmann P, 2007, RESTOR NEUROL NEUROS, V25, P227
   SPEAKS C, 1981, J SPEECH HEAR RES, V24, P430, DOI 10.1044/jshr.2403.430
   Takio F, 2009, DEV NEUROPSYCHOL, V34, P225, DOI 10.1080/87565640902805669
   Tanaka S, 1999, NEUROPSYCHOLOGIA, V37, P869, DOI 10.1016/S0028-3932(98)00144-4
   Tervaniemi M, 2003, BRAIN RES REV, V43, P231, DOI 10.1016/j.brainresrev.2003.08.004
   Toga AW, 2003, NAT REV NEUROSCI, V4, P37, DOI 10.1038/nrn1009
   Van der Haegen L, 2013, NEUROPSYCHOLOGIA, V51, P91, DOI 10.1016/j.neuropsychologia.2012.11.002
   Voyer D, 2011, BRAIN COGNITION, V76, P245, DOI 10.1016/j.bandc.2011.02.001
   Voyer D, 2009, J PHONETICS, V37, P162, DOI 10.1016/j.wocn.2008.12.001
   Westerhausen R, 2006, NEUROPSYCHOLOGY, V20, P272, DOI 10.1037/0894-4105.20.3.272
   Westerhausen R, 2014, NEUROIMAGE, V84, P962, DOI 10.1016/j.neuroimage.2013.09.074
   Westerhausen R, 2013, BRAIN COGNITION, V83, P288, DOI 10.1016/j.bandc.2013.09.006
   Westerhausen R, 2010, DEV NEUROPSYCHOL, V35, P752, DOI 10.1080/87565641.2010.508551
   WEXLER BE, 1983, NEUROPSYCHOLOGIA, V21, P59, DOI 10.1016/0028-3932(83)90100-8
   WEXLER BE, 1988, HDB DICHOTIC LISTENI, P85
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 44
TC 1
Z9 1
U1 0
U2 17
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD MAR
PY 2018
VL 39
IS 2
BP 259
EP 273
DI 10.1017/S0142716417000170
PG 15
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA FY2RO
UT WOS:000426663700001
DA 2021-02-24
ER

PT J
AU Burgering, MA
   ten Cate, C
   Vroomen, J
AF Burgering, Merel A.
   ten Cate, Carel
   Vroomen, Jean
TI Mechanisms underlying speech sound discrimination and categorization in
   humans and zebra finches
SO ANIMAL COGNITION
LA English
DT Article
DE Categorization; Speech perception; Comparative cognition; Songbirds;
   Zebra finch; Human
ID AUDITORY CATEGORIZATION; FUNDAMENTAL-FREQUENCY; GENDER CATEGORIZATION;
   PERCEPTION; VOWELS; ACQUISITION; CLASSIFICATION; PROTOTYPES; EXEMPLARS;
   EXPLICIT
AB Speech sound categorization in birds seems in many ways comparable to that by humans, but it is unclear what mechanisms underlie such categorization. To examine this, we trained zebra finches and humans to discriminate two pairs of edited speech sounds that varied either along one dimension (vowel or speaker sex) or along two dimensions (vowel and speaker sex). Sounds could be memorized individually or categorized based on one dimension or by integrating or combining both dimensions. Once training was completed, we tested generalization to new speech sounds that were either more extreme, more ambiguous (i.e., close to the category boundary), or within-category intermediate between the trained sounds. Both humans and zebra finches learned the one-dimensional stimulus-response mappings faster than the two-dimensional mappings. Humans performed higher on the trained, extreme and within-category intermediate test-sounds than on the ambiguous ones. Some individual birds also did so, but most performed higher on the trained exemplars than on the extreme, within-category intermediate and ambiguous test-sounds. These results suggest that humans rely on rule learning to form categories and show poor performance when they cannot apply a rule. Birds rely mostly on exemplar-based memory with weak evidence for rule learning.
C1 [Burgering, Merel A.; Vroomen, Jean] Tilburg Univ, Dept Cognit Neuropsychol, Warandelaan 2,POB 90153, NL-5000 LE Tilburg, Netherlands.
   [Burgering, Merel A.; ten Cate, Carel] Leiden Univ, IBL, POB 9505, NL-2300 RA Leiden, Netherlands.
   [ten Cate, Carel] Leiden Univ, LIBC, Leiden, Netherlands.
RP Burgering, MA (corresponding author), Tilburg Univ, Dept Cognit Neuropsychol, Warandelaan 2,POB 90153, NL-5000 LE Tilburg, Netherlands.; Burgering, MA (corresponding author), Leiden Univ, IBL, POB 9505, NL-2300 RA Leiden, Netherlands.
EM m.a.burgering@tilburguniversity.edu
RI Vroomen, Jean/K-1033-2013
OI Vroomen, Jean/0000-0001-5923-5988
FU Language in Interaction Consortium from Netherlands Organization for
   Scientific Research [024.001.006]
FX This research was supported by Gravitation Grant 024.001.006 of the
   Language in Interaction Consortium from Netherlands Organization for
   Scientific Research.
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Anderson B, 2006, VISION RES, V46, P1804, DOI 10.1016/j.visres.2005.11.023
   Ashby EG, 2005, ANNU REV PSYCHOL, V56, P149, DOI 10.1146/annurev.psych.56.091103.070217
   Ashby FG, 2002, MEM COGNITION, V30, P666, DOI 10.3758/BF03196423
   Ashby FG, 1999, PERCEPT PSYCHOPHYS, V61, P1178, DOI 10.3758/BF03207622
   Bizley JK, 2013, J ACOUST SOC AM, V133, P365, DOI 10.1121/1.4768798
   DEWSON JH, 1964, SCIENCE, V144, P555, DOI 10.1126/science.144.3618.555
   DOOLING RJ, 1990, PERCEPT PSYCHOPHYS, V47, P568, DOI 10.3758/BF03203109
   DOOLING RJ, 1992, 9 INT S HEAR AUD PHY, P407
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Erickson MA, 1998, J MATH PSYCHOL, V42, P483
   Eriksson JL, 2006, BEHAV PROCESS, V73, P348, DOI 10.1016/j.beproc.2006.08.005
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   GOTTWALD RL, 1972, PERCEPT PSYCHOPHYS, V11, P179, DOI 10.3758/BF03210371
   Goudbeek M, 2009, J EXP PSYCHOL HUMAN, V35, P1913, DOI 10.1037/a0015781
   Goudbeek M, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P1301
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   HIENZ RD, 1981, J ACOUST SOC AM, V70, P699, DOI 10.1121/1.386933
   HIENZ RD, 1988, J ACOUST SOC AM, V84, P186, DOI 10.1121/1.396963
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   KAWAHARA H, 2008, 33 IEEE INT C AC SPE, P3933
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   KLUENDER KR, 1987, SCIENCE, V237, P1195, DOI 10.1126/science.3629235
   Kriengwatana B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01243
   Kriengwatana B, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01543
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   KUHL PK, 1982, PERCEPT PSYCHOPHYS, V32, P542, DOI 10.3758/BF03204208
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   Maddox WT, 2004, BEHAV PROCESS, V66, P309, DOI 10.1016/j.beproc.2004.03.011
   Massida Z, 2013, J SPEECH LANG HEAR R, V56, P1389, DOI 10.1044/1092-4388(2013/12-0132)
   Mercado E, 2005, J COMP PSYCHOL, V119, P90, DOI 10.1037/0735-7036.119.1.90
   Minda JP, 2001, J EXP PSYCHOL LEARN, V27, P775, DOI 10.1037//0278-7393.27.3.775
   Ohms VR, 2012, ANIM COGN, V15, P155, DOI 10.1007/s10071-011-0441-2
   Ohms VR, 2010, P ROY SOC B-BIOL SCI, V277, P1003, DOI 10.1098/rspb.2009.1788
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   POSNER MI, 1968, J EXP PSYCHOL, V77, P353, DOI 10.1037/h0025953
   Skuk VG, 2015, J ACOUST SOC AM, V138, P1180, DOI 10.1121/1.4927696
   Skuk VG, 2014, J SPEECH LANG HEAR R, V57, P285, DOI 10.1044/1092-4388(2013/12-0314)
   Smith JD, 2014, PSYCHON B REV, V21, P312, DOI 10.3758/s13423-013-0506-0
   Smith JD, 2012, NEUROSCI BIOBEHAV R, V36, P2355, DOI 10.1016/j.neubiorev.2012.09.003
   Smith JD, 2011, PSYCHON B REV, V18, P414, DOI 10.3758/s13423-010-0047-8
   Smith JD, 1999, J EXP PSYCHOL LEARN, V25, P69, DOI 10.1037/h0090333
   SMITH JD, 2016, BEHAV SCI, V6, P24
   Spierings MJ, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00345
   ten Cate C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00730
   TENCATE C, 2017, AVIAN COGNITION
   Wills AJ, 2009, J COMP PSYCHOL, V123, P391, DOI 10.1037/a0016216
NR 51
TC 4
Z9 4
U1 2
U2 10
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1435-9448
EI 1435-9456
J9 ANIM COGN
JI Anim. Cogn.
PD MAR
PY 2018
VL 21
IS 2
BP 285
EP 299
DI 10.1007/s10071-018-1165-3
PG 15
WC Behavioral Sciences; Zoology
SC Behavioral Sciences; Zoology
GA FW7UW
UT WOS:000425532500010
PM 29435769
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Kim, D
   Clayards, M
   Goad, H
AF Kim, Donghyun
   Clayards, Meghan
   Goad, Heather
TI A longitudinal study of individual differences in the acquisition of new
   vowel contrasts
SO JOURNAL OF PHONETICS
LA English
DT Article
DE L2 speech perception; Individual differences; Cue weighting;
   Longitudinal study; Vowel contrasts; Korean; English
ID R-VERTICAL-BAR; LANGUAGE-ACQUISITION; JAPANESE ADULTS; ENGLISH VOWELS;
   ACOUSTIC CUES; PERCEPTION; DURATION; EXPERIENCE; LEARNERS; CHILDREN
AB This study explores how individuals' second language cue weighting strategies change over time and across different contrasts. The study investigates the developmental changes in perceptual cue weighting of two English vowel contrasts (/i/-/I/ and /epsilon/-/ae/) by adult and child Korean learners of English during their first year of immersion in Canada. Longitudinal results revealed that adult learners had an initial advantage in L2 perceptual acquisition over children at least for the /i/-/I/ contrast, but after one year some children showed greater improvements especially on the more difficult /epsilon/-/ae/ contrast. Both groups of Korean learners showed different acquisition patterns between the two vowel contrasts: they used both spectral and duration cues to distinguish /i/-/I/ but generally only duration to distinguish /epsilon/-/ae/. By examining cue weights over time, this study partially confirmed the hypothesized developmental stages for the acquisition of L2 vowels first proposed by Escudero (2000) for Spanish learners of English. However, some unpredicted patterns were also identified. Most importantly, the longitudinal results suggest that individual differences in cue weighting are not merely random variability in the learner's response patterns, but are systematically associated with the developmental trajectories of individual learners and those trajectories vary according to vowel contrast. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Kim, Donghyun; Clayards, Meghan; Goad, Heather] McGill Univ, Dept Linguist, 1085 Dr Penfield, Montreal, PQ H3A 1A7, Canada.
   [Clayards, Meghan] McGill Univ, Sch Commun Sci & Disorders, McGill Coll 8th Floor, Montreal, PQ H3A 1G1, Canada.
RP Kim, D (corresponding author), McGill Univ, Dept Linguist, 1085 Dr Penfield, Montreal, PQ H3A 1A7, Canada.
EM donghyun.kim@mail.mcgill.ca
OI Kim, Donghyun/0000-0003-1972-2508
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2016-0747, 435-2015-0490]; FRQSC [2016-SE-188196]
FX This work was supported by SSHRC grant 435-2016-0747 to Meghan Clayards
   and 435-2015-0490 to Heather Goad and Lydia White, and by FRQSC grant
   2016-SE-188196 to Lydia White, Heather Goad and colleagues.
CR Abrahamsson N, 1999, LANG LEARN, V49, P473, DOI 10.1111/0023-8333.00097
   Abrahamsson N., 2003, STUDIES 2 LANGUAGE A, V25, P313, DOI DOI 10.1017/S0272263103000147
   Amengual M, 2016, APPL PSYCHOLINGUIST, V37, P1221, DOI 10.1017/S0142716415000557
   Amengual M, 2016, INT J BILINGUAL, V20, P133, DOI 10.1177/1367006914544988
   Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Aoyama K., 2008, IRAL-INT REV APPL LI, V46, P61, DOI DOI 10.1515/IRAL.2008.003
   Baker W, 2002, PROC ANN BUCLD, P36
   Baker W, 2008, LANG SPEECH, V51, P317, DOI 10.1177/0023830908099068
   Baptista BO, 2006, STUD BILINGUAL, V31, P19
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   BENNETT DC, 1968, LANG SPEECH, V11, P65, DOI 10.1177/002383096801100201
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bion RAH, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1363
   Boberg Charles, 2010, ENGLISH LANGUAGE CAN
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Casillas JV, 2015, PHONETICA, V72, P182, DOI 10.1159/000431101
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cutler A, 2012, NATIVE LISTENING LAN
   Darcy I, 2015, LEARN INDIVID DIFFER, V40, P63, DOI 10.1016/j.lindif.2015.04.005
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   ESCUDERO P., 2005, THESIS, P348
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL277, DOI 10.1121/1.3632043
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Escudero Paola., 2000, THESIS
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Fridland V, 2014, J ACOUST SOC AM, V136, P341, DOI 10.1121/1.4883599
   Gerrits E., 2001, THESIS
   Giannakopoulou A, 2017, PEERJ, V5, DOI 10.7717/peerj.3209
   Giannakopoulou A, 2013, CHILD LANG TEACH THE, V29, P201, DOI 10.1177/0265659012467473
   Golestani N, 2009, BRAIN LANG, V109, P55, DOI 10.1016/j.bandl.2008.01.005
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Heeren WFL, 2010, J PHONETICS, V38, P594, DOI 10.1016/j.wocn.2010.08.005
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Hisagi M, 2015, BILING-LANG COGN, V18, P271, DOI 10.1017/S1366728914000170
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Ingram JCL, 1997, J PHONETICS, V25, P343, DOI 10.1006/jpho.1997.0048
   Ioup G., 2008, PHONOLOGY 2 LANGUAGE, P41
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Jia G, 2006, J ACOUST SOC AM, V119, P1118, DOI 10.1121/1.2151806
   Kawahara H., 2009, P AS PAC SIGN INF PR, P111
   Kim D, 2017, LINGUIST VANGUARD, V3, DOI 10.1515/lingvan-2016-0025
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Kondaurova MV, 2010, J PHONETICS, V38, P569, DOI 10.1016/j.wocn.2010.08.003
   Kondaurova MV, 2008, J ACOUST SOC AM, V124, P3959, DOI 10.1121/1.2999341
   Kong E. J., 2015, P 18 INT C PHON SCI
   Lee Ji-Yeon, 2009, [Phonetics and Speech Sciences, 말소리와 음성과학], V1, P39
   Lengeris A., 2009, THESIS
   Li DF, 1998, TESOL QUART, V32, P677, DOI 10.2307/3588000
   Lipski SC, 2012, PSYCHOPHYSIOLOGY, V49, P638, DOI 10.1111/j.1469-8986.2011.01347.x
   Mayo C, 2005, J ACOUST SOC AM, V118, P1730, DOI 10.1121/1.1979451
   Mayo C, 2003, J SPEECH LANG HEAR R, V46, P1184, DOI 10.1044/1092-4388(2003/092)
   Mayr R, 2010, BILING-LANG COGN, V13, P279, DOI 10.1017/S1366728909990022
   Morrison GS, 2009, J ACOUST SOC AM, V126, P2159, DOI 10.1121/1.3216917
   Morrison GS, 2008, LANG SPEECH, V51, P285, DOI 10.1177/0023830908099067
   Morrison GS, 2005, STUD SECOND LANG ACQ, V27, P597, DOI 10.1017/S0272263105050266
   Morrison GS, 2007, SEGMENTAL PROSODIC I, P219
   Nittrouer S, 2010, J ACOUST SOC AM, V127, P1624, DOI 10.1121/1.3298435
   Nixon J, 2014, THESIS
   Oh GE, 2011, J PHONETICS, V39, P156, DOI 10.1016/j.wocn.2011.01.002
   Ortega L., 2005, ANNU REV APPL LINGUI, V25, P26, DOI DOI 10.1017/S0267190505000024
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   R Core Team, 2008, R LANG ENV STAT COMP
   Schertz J, 2016, ATTEN PERCEPT PSYCHO, V78, P355, DOI 10.3758/s13414-015-0987-1
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Schertz Jessamyn, 2014, THESIS
   Sebastian-Galles N, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P279
   Shinohara Y., 2015, P 18 INT C PHON SCI
   Shinohara Y., 2013, P M AC, V19
   SNOW CE, 1978, CHILD DEV, V49, P1114, DOI 10.2307/1128751
   SNOW CE, 1977, LANG SPEECH, V20, P357, DOI 10.1177/002383097702000407
   Son G., 2008, THESIS
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Tsukada K, 2005, J PHONETICS, V33, P263, DOI 10.1016/j.wocn.2004.10.002
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Wanrooij K, 2013, J PHONETICS, V41, P307, DOI 10.1016/j.wocn.2013.03.005
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Ylinen S, 2010, J COGNITIVE NEUROSCI, V22, P1319, DOI 10.1162/jocn.2009.21272
   윤관희, 2014, [Studies in Phonetics, Phonology, and Morphology, 음성음운형태론연구], V20, P161
   김지은, 2010, [Phonetics and Speech Sciences, 말소리와 음성과학], V2, P51
NR 89
TC 5
Z9 5
U1 1
U2 13
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2018
VL 67
BP 1
EP 20
DI 10.1016/j.wocn.2017.11.003
PG 20
WC Linguistics; Language & Linguistics
SC Linguistics
GA FW8HF
UT WOS:000425571600001
DA 2021-02-24
ER

PT J
AU Franich, K
AF Franich, Kathryn
TI Tonal and morphophonological effects on the location of perceptual
   centers (p-centers): Evidence from a Bantu language
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Rhythm; Speech perception; Speech timing; Tone; Morphology; Phonology
ID SPEECH; SYNCHRONIZATION; RHYTHM; WORDS
AB Perceptual centers (or 'p-centers') correspond to the perceptual moment of occurrence of a syllable or word, and are crucial in the perception of speech rhythm. A metronome alignment task was used to investigate how tone and prenasalization-two elements which affect speech timing and which also interact acoustically-influenced p-center location in Medumba, a Grassfields Bantu language. Plain CV words bearing low tones were found to have p-centers which were later (farther from consonant releases and closer to vowel onsets) than those bearing high tones, but the observed effect was not present in prenasalized words. We attribute this difference to the effects of tone depression and slope leveling in prenasalized forms. While prenasalization generally led to earlier p-centers (mirroring effects found for onset clusters in other languages), forms with morphologically-derived prenasal onsets behaved more like plain CV forms, suggesting that nasal prefixes do not contribute to p-center timing. Our findings for derived prenasal sequences parallel similar articulatory findings for languages with simplex onset coordination, where consonant 'clusters' actually behave as separate timing units. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Franich, Kathryn] Univ Chicago, Dept Linguist, 1115 E 58th St,Rosenwald Hall,Room 224, Chicago, IL 60637 USA.
RP Franich, K (corresponding author), Univ Chicago, Dept Linguist, 1115 E 58th St,Rosenwald Hall,Room 224, Chicago, IL 60637 USA.
EM kfranich@uchicago.edu
FU National Science Foundation Linguistics Program [BCS-1423865]
FX This work was supported by National Science Foundation Linguistics
   Program Grant No. BCS-1423865 (co-Pls: Kathryn Franich and Alan C.L.
   Yu). The National Science Foundation does not necessarily endorse the
   ideas and claims in this paper. I thank the Medumba speakers who
   participated in the study for generously sharing their time and
   linguistic knowledge. I am deeply grateful to Dr. Ange Bergson Lendja
   for helping me to develop stimuli and recruit subjects. Thanks to Josh
   Falk, Jacob Phillips, Betsy Pillion, Anisia Popescu, and Alan Yu for
   helpful feedback. Thanks also to Fred Cummins and two anonymous
   reviewers for very insightful comments and suggestions. All remaining
   errors are of course my own.
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Abercrombie David, 1965, STUDIES PHONETICS LI
   ALLEN GD, 1972, LANG SPEECH, V15, P72, DOI 10.1177/002383097201500110
   Arvaniti A, 2012, J PHONETICS, V40, P351, DOI 10.1016/j.wocn.2012.02.003
   Arvaniti A, 2009, PHONETICA, V66, P46, DOI 10.1159/000208930
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Barbosa Plinio A., 2005, P 9 EUR C SPEECH COM, P1441
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bloch B, 1950, LANGUAGE, V26, P86, DOI 10.2307/410409
   Bolinger Dwight, 1965, FORMS ENGLISH ACCENT
   Browman C., 1988, PLUMETIAZ, V45
   Browman C., 2000, B COMMUNICATION PARL, V5
   Browman C. P., 1998, COMMUNICATION
   BROWMAN CP, 1990, J PHONETICS, V18, P299, DOI 10.1016/S0095-4470(19)30376-6
   Brown M., 2011, P 33 ANN C COGN SCI
   Cho T, 2001, PHONETICA, V58, P129, DOI 10.1159/000056196
   Chow I, 2015, J PHONETICS, V49, P55, DOI 10.1016/j.wocn.2014.10.006
   Cibelli E., 2015, PHONETICS PHONOLOGY, P171
   COOPER AM, 1988, J PHONETICS, V16, P231, DOI 10.1016/S0095-4470(19)30489-9
   COOPER AM, 1986, PERCEPT PSYCHOPHYS, V39, P187, DOI 10.3758/BF03212490
   Dauer Rebecca M., 1987, P 11 INT C PHON SCI, P447
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   de Jong K., 1994, PERCEPTION PSYCHOPHY, V15
   DELATTRE P, 1966, IRAL-INT REV APPL LI, V4, P183, DOI 10.1515/iral.1966.4.1-4.183
   Dellwo Volker, 2006, LANGUAGE LANGUAGE PR, P231
   Dilley L., 2012, LANGUAGE CONTEXT COG, P237
   Dilley LC, 2008, J MEM LANG, V59, P294, DOI 10.1016/j.jml.2008.06.006
   Dilley LC, 2010, J MEM LANG, V63, P274, DOI 10.1016/j.jml.2010.06.003
   DUANMU S, 1994, LINGUIST INQ, V25, P555
   Fowler C. A., 1981, ATTENTION PERFORMANC, VIX
   FOWLER CA, 1983, J EXP PSYCHOL GEN, V112, P386, DOI 10.1037/0096-3445.112.3.386
   FOWLER CA, 1979, PERCEPT PSYCHOPHYS, V25, P375, DOI 10.3758/BF03199846
   Franich KH, 2016, J ACOUST SOC AM, V140, pEL107, DOI 10.1121/1.4955003
   Gao M., 2008, COMMUNICATION
   Goldstein L., 2007, P 16 INT C PHON SCI, P241
   Gordon M, 2001, STUD LANG, V25, P423, DOI 10.1075/sl.25.3.03gor
   Grabe Esther, 2002, PAPERS LAB PHONOLOGY, V7, P515
   Gussenhoven C, 2013, INTERSPEECH, P1364
   Harsin CA, 1997, PERCEPT PSYCHOPHYS, V59, P243, DOI 10.3758/BF03211892
   Hermes A., 2011, 9 INT SEM SPEECH PRO, P1
   Hoequist C. E., 1983, LANG SPEECH, V26, P375
   HOWELL P, 1988, PERCEPT PSYCHOPHYS, V43, P90, DOI 10.3758/BF03208978
   Howell P., 1984, P 10 INT C PHON SCI, P429
   HYMAN L, 1997, STUDIES AFRICAN LING, V26, P131
   Hyman LM, 2008, LINGUISTICS, V46, P309, DOI 10.1515/LING.2008.012
   Kawasaki M, 2013, SCI REP-UK, V3, DOI 10.1038/srep01692
   Lehiste Ilse, 1977, J PHONETICS, V5, P253, DOI 10.1016/S0095-4470(19)31139-8
   Maddieson Ian, 2009, J INT PHON ASSOC, V19, P57
   MARCUS SM, 1981, PERCEPT PSYCHOPHYS, V30, P247, DOI 10.3758/BF03214280
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405
   Patel A. D., 1999, P 14 INT C PHON SCI, P405
   Pike Kenneth, 1945, INTONATION AM ENGLIS
   POMPINOMARSCHALL B, 1989, J PHONETICS, V17, P175, DOI 10.1016/S0095-4470(19)30428-0
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Rapp-Holmgren K., 1971, PAPERS I LINGUISTICS, V12, P14
   Riehl Anastasia K., 2008, THESIS
   Roach P., 1982, LINGUISTIC CONTROVER, P73
   Scott S., 1992, J ACOUST SOC AM, V94, P2443
   Scott SK, 1998, PSYCHOL RES-PSYCH FO, V61, P4, DOI 10.1007/PL00008162
   Shaw J, 2009, PHONOLOGY, V26, P187, DOI 10.1017/S0952675709001754
   Shen Y., 1962, ISOCHRONISM ENGLISH, P1
   Sturm P, 2016, J PHONETICS, V55, P38, DOI 10.1016/j.wocn.2015.11.003
   TILSEN S, 2012, CORNELL WORKING PAPE, V2012, P51
   Villing RC, 2011, ATTEN PERCEPT PSYCHO, V73, P1614, DOI 10.3758/s13414-011-0110-1
   Voorhoeve Jan, 1971, J AFR LANG LINGUIST, V20, P44
   Welmers W., 1978, AFRICAN LANGUAGE STR
   Xu Y., 2004, LANGUAGE LINGUISTICS, V5, P757
   Xu Y, 2006, ITAL J LINGUIST, V18, P125
   Xu Y, 2009, LINGUA, V119, P906, DOI 10.1016/j.lingua.2007.09.015
   Yip M., 1991, TONAL PHONOLOGY CHIN
   Yu Alan C. L., 2010, LAB PHONOLOGY, V10, P151, DOI DOI 10.1515/9783110224917.2.151
   Zhang J., 2002, THESIS
NR 72
TC 1
Z9 1
U1 2
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2018
VL 67
BP 21
EP 33
DI 10.1016/j.wocn.2017.11.001
PG 13
WC Linguistics; Language & Linguistics
SC Linguistics
GA FW8HF
UT WOS:000425571600002
DA 2021-02-24
ER

PT J
AU Llompart, M
   Reinisch, E
AF Llompart, Miguel
   Reinisch, Eva
TI Acoustic cues, not phonological features, drive vowel perception:
   Evidence from height, position and tenseness contrasts in German vowels
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Vowels; Pre-lexical units; Phonological features; Acoustic cues; Speech
   perception; Selective adaptation
ID SELECTIVE ADAPTATION; SPEECH-PERCEPTION; PRECEDING LIQUID; MENTAL
   LEXICON; MOTOR THEORY; IDENTIFICATION; DETECTORS; REPRESENTATIONS;
   DISCRIMINATION; INFORMATION
AB Phonological features have frequently been singled out as the units of perception, especially for vowels. Evidence of the use of features has been provided for vowel height and vowel position, which have one acoustic correlate only. However, findings on acoustically complex features such as tenseness are less clear. The present study assessed the role of phonological features in perception using the selective adaptation paradigm. Selective adaptation effects on German vowel contrasts differing in vowel height (Experiment 1), position (Experiment 2) and tenseness (Experiment 3) were examined. We tested how the categorization of each vowel contrast was affected by adaptation to words containing vowels that differently resembled or diverged from the vowels in the critical contrast acoustically and in terms of their phonological feature specifications. Results showed that selective adaptation patterns could be predicted by the vowels' phonological features for the height and position contrasts, but not for the tenseness contrast. However, adaptation patterns for the latter can be explained by the relationship between adaptors and continuum endpoints in each of the relevant acoustic cues to the contrast. This suggests that vowel perception may be dependent on these acoustic cues rather than phonological features. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Llompart, Miguel; Reinisch, Eva] Ludwig Maximilian Univ Munich, Schellingstr 3, D-80799 Munich, Germany.
RP Llompart, M (corresponding author), Ludwig Maximilian Univ Munich, Schellingstr 3, D-80799 Munich, Germany.
EM M.Llompart@phonetik.uni-muenchen.de
RI Llompart, Miquel/ABF-3326-2020; Reinisch, Eva/R-1646-2016
OI Llompart, Miquel/0000-0002-2002-8778; Reinisch, Eva/0000-0002-1400-5473
FU German Research Foundation (DFG)German Research Foundation (DFG) [RE
   3047/1-1]
FX We would like to thank Rosa Franzke for her help with testing
   participants, Matthias Sjerps and Hans Rutger Bosker for helpful
   discussion, and Holger Mitterer and Joseph V. Casillas for comments on a
   previous version of the paper. This project was funded by a grant from
   the German Research Foundation (DFG; grant nr. RE 3047/1-1) to the
   second author. Parts of the results were presented at the "International
   Workshop on Abstraction, Diversity and Speech Dynamics", May 2017,
   Herrsching am Ammersee, Germany.
CR ADES AE, 1974, PERCEPT PSYCHOPHYS, V16, P61, DOI 10.3758/BF03203251
   AINSWORTH WA, 1977, PERCEPT PSYCHOPHYS, V21, P365, DOI 10.3758/BF03199488
   Bakovic E., 2000, THESIS
   Boersma P., 2010, PRAAT DOING PHONETIC
   Boersma P., 2011, P 17 ICPHS, P328
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bowers JS, 2016, J MEM LANG, V87, P71, DOI 10.1016/j.jml.2015.11.002
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Browman CP., 1989, PHONOLOGY, V6, P201, DOI [10.1017/S0952675700001019, DOI 10.1017/S0952675700001019]
   Calabrese A., 2000, CURRENT ISSUES LINGU, V59
   Chistovich L., 1966, Q PROGR STATUS REPOR, V2, P1
   Chladkova K., 2014, THESIS
   Chladkova K., 2015, P 18 INT C PHON SCI
   Chladkova K, 2017, J EXP PSYCHOL HUMAN, V43, P414, DOI 10.1037/xhp0000333
   Chomslcy N., 1968, SOUND PATTERN ENGLIS
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clopper CG, 2014, J ACOUST SOC AM, V136, P1, DOI 10.1121/1.4883478
   Clopper Cynthia G., 2010, J ACOUST SOC AM, V127
   COOPER WE, 1974, PERCEPT PSYCHOPHYS, V15, P591, DOI 10.3758/BF03199307
   COOPER WE, 1974, J PHONETICS, V2, P303
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   DIEHL RL, 1985, J EXP PSYCHOL HUMAN, V11, P209
   DIEHL RL, 1980, J EXP PSYCHOL HUMAN, V6, P24, DOI 10.1037/0096-1523.6.1.24
   DIEHL RL, 1978, J EXP PSYCHOL HUMAN, V4, P599, DOI 10.1037/0096-1523.4.4.599
   DIEHL RL, 1975, PERCEPT PSYCHOPHYS, V17, P48, DOI 10.3758/BF03203996
   Draxler Christoph, 2004, P 4 INT C LANG RES E, P559
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   EIMAS PD, 1963, LANG SPEECH, V6, P206, DOI 10.1177/002383096300600403
   Ettlinger M, 2009, PHONETICA, V66, P222, DOI 10.1159/000298584
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   FISCHERJORGENSEN E, 1990, PHONETICA, V47, P99, DOI 10.1159/000261858
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FOREIT KG, 1977, PERCEPT PSYCHOPHYS, V21, P347, DOI 10.3758/BF03199485
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   GODFREY JJ, 1980, PERCEPT PSYCHOPHYS, V28, P103, DOI 10.3758/BF03204334
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   HALLE M, 1977, LINGUIST INQ, V8, P611
   HALLE M, 1985, LINGUIST INQ, V16, P57
   Halle M, 1969, Q PROGR REPORT MIT R, V94, P209
   Harnad S., 1987, CATEGORICAL PERCEPTI, P199
   HEALY AF, 1982, J EXP PSYCHOL HUMAN, V8, P68, DOI 10.1037/0096-1523.8.1.68
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Jakobson R., 1952, PRELIMINANES SPEECH
   JONGMAN A, 1989, LANG SPEECH, V32, P221
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kingston J, 2003, LANG SPEECH, V46, P295, DOI 10.1177/00238309030460020201
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kroos C., 1996, J ACOUST SOC AM, V100, P2691
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   LINDAU M, 1978, LANGUAGE, V54, P541, DOI 10.2307/412786
   Lindau M., 1972, UCLA WORKING PAPERS, P76
   Llompart M., 2017, LANGUAGE SPEECH
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Maddieson I., 1992, UCLA PHONOLOGICAL SE
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   Massaro DW, 2008, PSYCHON B REV, V15, P453, DOI 10.3758/PBR.15.2.453
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McQueen J. M, 2005, HDB COGNITION, P255, DOI DOI 10.4135/9781848608177.N11
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   MEHLER J, 1981, J VERB LEARN VERB BE, V20, P298, DOI 10.1016/S0022-5371(81)90450-3
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   MILLER JL, 1983, J ACOUST SOC AM, V73, P2124, DOI 10.1121/1.389455
   Mitterer H, 2006, PHONETICA, V63, P209, DOI 10.1159/000097306
   Mitterer H, 2006, Q J EXP PSYCHOL, V59, P1395, DOI 10.1080/17470210500198726
   Mitterer H, 2018, J MEM LANG, V98, P77, DOI 10.1016/j.jml.2017.09.005
   Mitterer H, 2017, LANG COGN NEUROSCI, V32, P1133, DOI 10.1080/23273798.2017.1286361
   Mitterer H, 2016, J PHONETICS, V56, P110, DOI 10.1016/j.wocn.2016.03.001
   Mitterer H, 2013, COGNITION, V129, P356, DOI 10.1016/j.cognition.2013.07.011
   Mitterer H, 2011, J EXP PSYCHOL HUMAN, V37, P496, DOI 10.1037/a0020989
   MORSE PA, 1976, PERCEPT PSYCHOPHYS, V19, P137, DOI 10.3758/BF03204220
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   PISONI DB, 1975, PERCEPT PSYCHOPHYS, V18, P401, DOI 10.3758/BF03204112
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   Samuel AG, 1996, J EXP PSYCHOL HUMAN, V22, P676
   Samuel AG, 1997, COGNITIVE PSYCHOL, V32, P97, DOI 10.1006/cogp.1997.0646
   Savela J., 2009, THESIS
   SAWUSCH JR, 1981, J EXP PSYCHOL HUMAN, V7, P408, DOI 10.1037/0096-1523.7.2.408
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Scharinger M, 2011, J COGNITIVE NEUROSCI, V23, P3972, DOI 10.1162/jocn_a_00056
   TARTTER VC, 1975, PERCEPT PSYCHOPHYS, V18, P293, DOI 10.3758/BF03199377
   WICKELGR.WA, 1969, PSYCHOL REV, V76, P1, DOI 10.1037/h0026823
NR 89
TC 0
Z9 0
U1 1
U2 4
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2018
VL 67
BP 34
EP 48
DI 10.1016/j.wocn.2017.12.001
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA FW8HF
UT WOS:000425571600003
DA 2021-02-24
ER

PT J
AU Dar, M
   Keren-Portnoy, T
   Vihman, M
AF Dar, Mariam
   Keren-Portnoy, Tamar
   Vihman, Marilyn
TI An order effect in English infants' discrimination of an Urdu affricate
   contrast
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Urdu voiceless affricate contrast; Order effect in consonant
   discrimination; Perceptual narrowing
ID LANGUAGE SPEECH-PERCEPTION; NONNATIVE CONSONANT CONTRASTS; CATEGORICAL
   PERCEPTION; LEARNING INFANTS; 1ST YEAR; DEVELOPMENTAL-CHANGES; VOWEL
   DISCRIMINATION; PHONETIC CATEGORIES; FRICATIVE CONTRASTS; INTERNAL
   STRUCTURE
AB An order effect was found in English infants' discrimination of an Urdu contrast. In Experiment 17- and 11-month-old English infants were tested on the Urdu contrast between the affricates /t integral(h)/ and /t integral/. The order of presentation was counterbalanced: At each age half the infants were habituated to the aspirated and tested on the unaspirated affricate, the other half habituated to the unaspirated and tested on the aspirated. As expected, younger infants discriminated the contrast whereas older infants did not, showing the expected decline in discrimination. Order of presentation seemed to affect the older infants' response. Experiment 2 tested the order effect directly. The results showed no asymmetry in the performance of 7-month olds but clear asymmetry in that of 11-month-olds, who discriminated the contrast only when the non-English-like aspirated affricate was presented first. Experiment 3 tested adult native-speakers of both Urdu and English. Although the English listeners showed a reduced sensitivity to the contrast, there was no effect due to order of presentation of the stimuli in either adult group. The finding of an asymmetry in the infants suggests that infants' perceptual narrowing for speech sounds may be a more complex phenomenon than has generally been assumed. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Dar, Mariam; Keren-Portnoy, Tamar; Vihman, Marilyn] Univ York, York YO10 5DD, N Yorkshire, England.
RP Dar, M (corresponding author), 75 Muscot Dr, Stoney Creek, ON L8J 1Y8, Canada.
EM md738@york.ac.uk
CR Alshangiti W, 2015, THESIS
   Altvater-Mackensen N, 2010, LINGUA, V120, P1898, DOI 10.1016/j.lingua.2010.02.010
   Aslin R. N., 1980, CHILD PHONOLOGY, V2, P67
   Beach E., 2008, 9 ANN C INT SPEECH C
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   BEST CT, 1993, NATO ADV SCI INST SE, V69, P289
   Bohn OS, 2001, J ACOUST SOC AM, V110, P504, DOI 10.1121/1.1380415
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   CARNEY AE, 1977, J ACOUST SOC AM, V62, P961, DOI 10.1121/1.381590
   Conboy BT, 2008, DEV PSYCHOL, V44, P1505, DOI 10.1037/a0012975
   COWAN N, 1986, J ACOUST SOC AM, V79, P500, DOI 10.1121/1.393537
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Damper RI, 2000, PERCEPT PSYCHOPHYS, V62, P843, DOI 10.3758/BF03206927
   Docherty G., 1992, TIMING VOICING BRIT
   EILERS RE, 1975, J SPEECH HEAR RES, V18, P158, DOI 10.1044/jshr.1801.158
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   GRIESER D, 1989, DEV PSYCHOL, V25, P577, DOI 10.1037/0012-1649.25.4.577
   GUENTHER FH, 1995, PSYCHOL REV, V102, P594, DOI 10.1037/0033-295X.102.3.594
   Harris K., 1995, PRODUCING SPEECH
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   HOWELL P, 1983, SPEECH COMMUN, V2, P159, DOI 10.1016/0167-6393(83)90017-1
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Johnson K, 2010, J PHONETICS, V38, P127, DOI 10.1016/j.wocn.2009.11.001
   JONAS N., 1984, J ACOUST SOC AM, V75, pS66
   Keating P., 2005, DPRIME ANAL
   Kleber F, 2012, LANG SPEECH, V55, P383, DOI 10.1177/0023830911422194
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   KUHL PK, 1986, INVARIANCE VARIABILI, P19
   LEVITT A, 1988, J EXP PSYCHOL HUMAN, V14, P361
   Livingston KR, 1998, J EXP PSYCHOL LEARN, V24, P732, DOI 10.1037/0278-7393.24.3.732
   MacKain K., 1982, J CHILD LANGUAGE, V9
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   Medin D., 1987, CATEGORICAL PERCEPTI, P445
   Miller JL, 1997, LANG COGNITIVE PROC, V12, P865, DOI 10.1080/016909697386754
   MILLER JL, 1994, COGNITION, V50, P271, DOI 10.1016/0010-0277(94)90031-0
   Mugitani R, 2009, DEV PSYCHOL, V45, P236, DOI 10.1037/a0014043
   Nam YJ, 2016, COGNITION, V155, P57, DOI 10.1016/j.cognition.2016.06.005
   NITTROUER S, 1987, J SPEECH HEAR RES, V30, P319, DOI 10.1044/jshr.3003.319
   PEGG JE, 1992, INFANT BEHAV DEV, V15, P325, DOI 10.1016/0163-6383(92)80003-D
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   PISONI DB, 1974, J ACOUST SOC AM, V55, P328, DOI 10.1121/1.1914506
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   REPP BH, 1990, J ACOUST SOC AM, V88, P2080, DOI 10.1121/1.400105
   REPP BH, 1979, J EXP PSYCHOL HUMAN, V5, P129, DOI 10.1037/0096-1523.5.1.129
   Rivera-Gaxiola M, 2005, NEUROREPORT, V16, P495, DOI 10.1097/00001756-200504040-00015
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P532, DOI 10.1016/0010-0285(75)90021-3
   Segal O, 2016, INFANT BEHAV DEV, V42, P86, DOI 10.1016/j.infbeh.2015.10.002
   Stevens KN, 2010, J PHONETICS, V38, P10, DOI 10.1016/j.wocn.2008.10.004
   Suzuki N., 2001, J ACOUST SOC AM, V110, P2656
   Taylor J. R., 2008, HDB COGNITIVE LINGUI, P39
   Ting J., 2006, 15 BIENN INT C INF S
   Tsao F., 2000, M INT SOC INF STUD E
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Tsuji S, 2015, COGNITION, V134, P252, DOI 10.1016/j.cognition.2014.10.009
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Tsushima T., 2003, Acoustical Science and Technology, V24, P410, DOI 10.1250/ast.24.410
   Tsushima T., 2005, 1 AC SOC AM WO UNPUB
   Tsushima T., 2007, J JAPAN SOC SPEECH S, V8, P45
   Tsushima T., 2011, J COMMUNICATION STUD, V33, P267
   Tversky A., 1978, COGNITION CATEGORIZA, P79
   VIHMAN M, 1996, PHONOLOGICAL DEV
   Wanrooij K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00077
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Werker JF, 2002, INFANT BEHAV DEV, V25, P121, DOI 10.1016/S0163-6383(02)00093-0
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
NR 83
TC 2
Z9 2
U1 1
U2 6
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2018
VL 67
BP 49
EP 64
DI 10.1016/j.wocn.2017.12.002
PG 16
WC Linguistics; Language & Linguistics
SC Linguistics
GA FW8HF
UT WOS:000425571600004
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Delvaux, V
   Huet, K
   Piccaluga, M
   Harmegnies, B
AF Delvaux, Veronique
   Huet, Kathy
   Piccaluga, Myriam
   Harmegnies, Bernard
TI The perception of anticipatory labial coarticulation by blind listeners
   in noise: A comparison with sighted listeners in audio-only, visual-only
   and audiovisual conditions
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Audiovisual speech perception; Anticipatory coarticulation; Gating;
   Blind; French
ID EARLY ACQUIRED BLINDNESS; SPEECH-PERCEPTION; CONGENITALLY BLIND;
   VOICE-RECOGNITION; INFORMATION; IDENTIFICATION; DISCRIMINATION;
   LANGUAGE; TACTILE; HEARING
AB This study investigates the time course of the perception of the /i-y/ contrast by French-speaking blind listeners using a gating paradigm. The performances of the blind listeners in discrimination and identification are compared with the range of performances exhibited by sighted perceivers when stimuli are presented auditorily, visually and audiovisually, whether in acoustically non degraded or in noisy conditions. Results provide evidence in favor of partial compensation for visual deprivation in speech perception. Blind listeners outperformed sighted participants in discriminating between auditorily-presented gated stimuli, particularly in noisy conditions. But this small advantage allowed them to compensate only partially for their inability to exploit visual information in order to process coarticulated speech as quickly and efficiently as sighted controls. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Delvaux, Veronique] Fonds Rech Sci FNRS, 5 Rue Egmont, B-1000 Brussels, Belgium.
   [Delvaux, Veronique; Huet, Kathy; Piccaluga, Myriam; Harmegnies, Bernard] Univ Mons, Inst Rech Sci & Technol Langage, 20 Pl Parc, B-7000 Mons, Belgium.
RP Delvaux, V (corresponding author), Univ Mons, Inst Rech Sci & Technol Langage, 20 Pl Parc, B-7000 Mons, Belgium.
EM Veronique.Delvaux@umons.ac.be
CR ABRY C, 1996, NATO ASI SERIES F, V150, P247
   Alsius A., 2013, OXFORD HDB COGNITIVE, V1
   Amedi A, 2004, NAT NEUROSCI, V7, P1266, DOI 10.1038/nn1328
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Bedny M, 2012, BRAIN LANG, V122, P162, DOI 10.1016/j.bandl.2011.10.005
   Bedny M, 2011, P NATL ACAD SCI USA, V108, P4429, DOI 10.1073/pnas.1014818108
   BERGESON T, 2005, VOLTA REV, V103, P347
   BERNSTEIN LE, 2004, HDB MULTISENSORY PRO, P203
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Braun A, 2012, INT J SPEECH LANG LA, V19, P159, DOI 10.1558/ijsll.v19i2.159
   BULL R, 1983, PERCEPTION, V12, P223, DOI 10.1068/p120223
   Burton H, 2003, J NEUROPHYSIOL, V90, P1965, DOI 10.1152/jn.00279.2003
   Cathiard M.-A., 1994, THESIS
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chen MS, 2015, PR INT ASIA CONF IND, P133, DOI 10.2991/978-94-6239-100-0_25
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Dias JW, 2016, J PHONETICS, V56, P75, DOI 10.1016/j.wocn.2016.02.004
   Dietrich S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00701
   Dufour A, 2005, EXP BRAIN RES, V165, P515, DOI 10.1007/s00221-005-2329-3
   Erdener D, 2016, LANG LEARN J, V44, P124, DOI 10.1080/09571736.2012.724080
   Escudier P., 1990, J ACOUST SOC AM, V87, pS126
   Fieger A, 2006, J COGNITIVE NEUROSCI, V18, P149, DOI 10.1162/089892906775783697
   Gagne J.-P., 2010, HEARING CARE ADULTS, P165
   Gerrits E, 2004, PERCEPT PSYCHOPHYS, V66, P363, DOI 10.3758/BF03194885
   Gick B, 2008, J ACOUST SOC AM, V123, pEL72, DOI 10.1121/1.2884349
   Gordon-Salant S, 2011, J SPEECH LANG HEAR R, V54, P622, DOI 10.1044/1092-4388(2010/10-0052)
   Gougoux F, 2005, PLOS BIOL, V3, P324, DOI 10.1371/journal.pbio.0030027
   Gougoux F, 2004, NATURE, V430, P309, DOI 10.1038/430309a
   Gougoux F, 2009, NEUROPSYCHOLOGIA, V47, P2967, DOI 10.1016/j.neuropsychologia.2009.06.027
   Granstrom B., 1999, P INT C PHON SCI, V1, P655
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Guiraud JA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036428
   GUNZBURGER D, 1987, LANG SPEECH, V30, P47
   Hambye P., 2009, PHONOLOGIE VARIATION, P95
   Hamilton RH, 2004, NEUROREPORT, V15, P803, DOI 10.1097/00001756-200404090-00012
   Hazan V, 2006, J ACOUST SOC AM, V119, P1740, DOI 10.1121/1.2166611
   Hickson Louise, 2004, Australian and New Zealand Journal of Audiology, V26, P3, DOI 10.1375/audi.26.1.3.55988
   Hirsch F., 2011, INT SEM SPEECH PROD
   Hirsch F., 2010, MONS BELG ACT 28 JOU, P141
   Hugdahl K, 2004, COGNITIVE BRAIN RES, V19, P28, DOI 10.1016/j.cogbrainres.2003.10.015
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209
   Lewkowicz DJ, 2013, INT J BEHAV DEV, V37, P90, DOI 10.1177/0165025412467582
   Leybaert J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00422
   Liew A.W.C., 2009, VISUAL SPEECH RECOGN
   Menard L, 2015, FOLIA PHONIATR LOGO, V67, P83, DOI 10.1159/000434719
   Menard L, 2009, J ACOUST SOC AM, V126, P1406, DOI 10.1121/1.3158930
   Mitchel AD, 2016, J PHONETICS, V56, P66, DOI 10.1016/j.wocn.2016.02.003
   MUCHNIK C, 1991, SCAND AUDIOL, V20, P19, DOI 10.3109/01050399109070785
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   NIEMEYER W, 1981, AUDIOLOGY, V20, P510
   Occelli V, 2013, PSYCHOL BULL, V139, P189, DOI 10.1037/a0028416
   Ortega-Llebaria M., 2001, SPEECH HEAR IN PRESS, V13, P39
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Poirier C, 2006, NEUROIMAGE, V31, P279, DOI 10.1016/j.neuroimage.2005.11.036
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Roder B, 1999, NATURE, V400, P162, DOI 10.1038/22106
   Roder B, 2002, EUR J NEUROSCI, V16, P930, DOI 10.1046/j.1460-9568.2002.02147.x
   Roder B, 1996, COGNITIVE BRAIN RES, V4, P77, DOI 10.1016/0926-6410(96)00024-9
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Roy JP, 2012, CAN J LING/REV CAN L, V57, P109, DOI 10.1353/cjl.2012.0023
   Sato M, 2010, NEUROPSYCHOLOGIA, V48, P3683, DOI 10.1016/j.neuropsychologia.2010.08.017
   Scarbel L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00568
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   SEKIYAMA K, 2003, P INT C AUD VIS SPEE, P43
   Sekiyama K., 2014, FRONTIERS PSYCHOL LA, V5, P12
   Smeds H., 2015, THESIS
   STARLINGER I, 1981, AUDIOLOGY, V20, P503
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Teng S, 2012, EXP BRAIN RES, V216, P483, DOI 10.1007/s00221-011-2951-1
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Traunmuller H, 2007, J PHONETICS, V35, P244, DOI 10.1016/j.wocn.2006.03.002
   Troille E, 2010, SPEECH COMMUN, V52, P513, DOI 10.1016/j.specom.2009.12.005
   TROUVAIN J, 2007, SAARLAND WORKING PAP, V1, P5
   Wan CY, 2010, NEUROPSYCHOLOGIA, V48, P344, DOI 10.1016/j.neuropsychologia.2009.08.016
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   Wayne RV, 2012, J EXP PSYCHOL-APPL, V18, P419, DOI 10.1037/a0031042
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
   WINOGRAD E, 1984, AM J PSYCHOL, V97, P57, DOI 10.2307/1422547
   Woodhouse L, 2009, INT J LANG COMM DIS, V44, P253, DOI 10.1080/13682820802090281
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
   Zwiers MP, 2001, J NEUROSCI, V21, part. no., DOI 10.1523/JNEUROSCI.21-09-j0002.2001
NR 90
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2018
VL 67
BP 65
EP 77
DI 10.1016/j.wocn.2018.01.001
PG 13
WC Linguistics; Language & Linguistics
SC Linguistics
GA FW8HF
UT WOS:000425571600005
DA 2021-02-24
ER

PT J
AU Jiang, T
   Liang, RY
   Wang, QY
   Bao, YQ
AF Jiang, Tao
   Liang, Ruiyu
   Wang, Qinqyun
   Bao, Yongqiang
TI Speech Noise Reduction Algorithm in Digital Hearing Aids Based on an
   Improved Sub-band SNR Estimation
SO CIRCUITS SYSTEMS AND SIGNAL PROCESSING
LA English
DT Article
DE Multi-channel hearing aids; Sub-band noise reduction; Sub-band SNR
   estimation; Time complexity
ID OLDER-ADULTS; SPECTRAL SUBTRACTION; ENHANCEMENT
AB To improve the speech intelligibility in noisy environments for persons with hearing impairments, a new method for reducing noise, based on improved sub-band signal-to-noise ratio (SNR) estimation, is proposed. First, the input signal is decomposed into several sub-band signals with an analysis filter bank. Then, under the assumption of a Gaussian model, maximum a posterior probability is applied to estimate the information embedded in adjacent frames in each sub-band, which is in the form of a joint probability density function, and the minimum of the noise spectrum is tracked to estimate the noise. Subsequently, the gain of each sub-band, which changes with the noise in the corresponding sub-band, is calculated with a linear proportional gain function. The obtained gains of the sub-bands are multiplied by the sub-band noisy signals to obtain the enhanced sub-band speech signals. Finally, all the sub-band signals are spliced to obtain the estimated speech signals. In this algorithm, the gains are calculated in the time domain, which avoids the process of the inverse Fourier transform and leads to a decrease in computational complexity. Compared with the traditional spectral subtraction and basic Wiener filtering method, the delay in this algorithm is reduced by 40.4 and 60.6%, respectively. It is also compared with the modulation depth integrated into hearing aids under an experimental simulation and a real scenario. The results indicate that the output SNR is improved by 1 dB under the software simulation and 3.1 dB in the real scenario when the input SNR is set as 10 dB. Compared with the simulation environment, the proposed algorithm only fell by 1.5% in the real scenario. Furthermore, the distance of the logarithmic spectrum and quality of speech perception are improved by 20.6 and 9.3%, respectively.
C1 [Jiang, Tao; Liang, Ruiyu; Wang, Qinqyun; Bao, Yongqiang] Nanjing Inst Technol, Sch Commun Engn, Nanjing 211167, Jiangsu, Peoples R China.
   [Jiang, Tao; Liang, Ruiyu] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
RP Liang, RY (corresponding author), Nanjing Inst Technol, Sch Commun Engn, Nanjing 211167, Jiangsu, Peoples R China.; Liang, RY (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM 18351966578@163.com; lly1711@163.com; wangqingyun@vip.163.com;
   jybyq@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61673108, 61375028]; China Postdoctoral
   Science FoundationChina Postdoctoral Science Foundation [2016M601696];
   Qing Lan Project of Jiangsu Province; Six Talent Peaks Project in
   Jiangsu Province [2016-DZXX-023]; Jiangsu Planned Projects for
   Postdoctoral Research Funds [1601011B]; High-level Scientific Research
   Foundation of NJIT [YKJ201526]; open fund of Guangdong lighting and
   audio video engineering research center [KF201601, KF201602]
FX The work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61673108 and 61375028, China Postdoctoral Science
   Foundation funded Project under Grant No. 2016M601696, Qing Lan Project
   of Jiangsu Province, Six Talent Peaks Project in Jiangsu Province under
   Grant No. 2016-DZXX-023, Jiangsu Planned Projects for Postdoctoral
   Research Funds under Grant No. 1601011B, the High-level Scientific
   Research Foundation of NJIT under Grant No. YKJ201526 and the open fund
   of Guangdong lighting and audio video engineering research center under
   Grant Nos. KF201601 and KF201602. The authors would like to thank the
   reviewers for their valuable suggestions and comments.
CR Abd El-Fattah MA, 2014, INT J SPEECH TECHNOL, V17, P53, DOI 10.1007/s10772-013-9205-5
   Acar B, 2011, ARCH GERONTOL GERIAT, V52, P250, DOI 10.1016/j.archger.2010.04.013
   Aggarwal Rajeev, 2011, IJCA, V20, P14
   Ben Messaoud MA, 2015, J AUDIO ENG SOC, V63, P990
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Chong KS, 2006, IEEE T CIRCUITS-II, V53, P853, DOI 10.1109/TCSII.2006.881821
   Chou R, 2011, ANN INTERN MED, V154, P347, DOI 10.7326/0003-4819-154-5-201103010-00009
   Chung King, 2004, Trends Amplif, V8, P83, DOI 10.1177/108471380400800302
   Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544
   Cummins K. L., 1989, ADAPTIVE PROGRAMMABL
   Edwards Brent, 2007, Trends Amplif, V11, P31, DOI 10.1177/1084713806298004
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   Fang X., 2004, NOISE REDUCTION APPA
   Gopinath B, 2011, ANN EPIDEMIOL, V21, P497, DOI 10.1016/j.annepidem.2011.03.005
   Hogan A, 2009, J AGING HEALTH, V21, P1098, DOI 10.1177/0898264309347821
   Islam MT, 2017, SPEECH COMMUN, V86, P64, DOI 10.1016/j.specom.2016.11.002
   Jiang Y, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P692, DOI 10.1109/ICSPCC.2014.6986284
   Kamath S, 2002, INT CONF ACOUST SPEE, P4164
   Katahira H, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0301-3
   Kay S. M., 1993, FUNDAMENTALS STAT SI, P342, DOI [10.2307/1269750, DOI 10.2307/1269750]
   Killion M. C., 2000, HEAR J, V53, P46
   Laplante-Levesque A, 2010, J AGING HEALTH, V22, P143, DOI 10.1177/0898264309352731
   Lei JJ, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL II, PROCEEDINGS, P306, DOI 10.1109/IITA.2008.202
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915
   Mavaddaty S, 2017, COMPUT SPEECH LANG, V44, P22, DOI 10.1016/j.csl.2017.01.009
   Ou Shi-feng, 2007, Acta Electronica Sinica, V35, P2007
   Peled Y, 2012, J ACOUST SOC AM, V132, P1473, DOI 10.1121/1.4742698
   Seok JW, 1997, INT CONF ACOUST SPEE, P1323, DOI 10.1109/ICASSP.1997.596190
   Tseng H. W., 2015, 2015 IEEE INT C AC S
   Wang Q, 2018, IEEE T DEPEND SECURE, V15, P496, DOI 10.1109/TDSC.2016.2593444
   Wouters J, 2001, EAR HEARING, V22, P420, DOI 10.1097/00003446-200110000-00006
   Wyrsch S, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, P29, DOI 10.1109/ISCAS.1999.778777
   Yang Gui, 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P732
   Yang Li-chun, 2013, Journal of Zhejiang University. Engineering Science, V47, P1493, DOI 10.3785/j.issn.1008-973X.2013.08.0025
   Zhang Y, 2013, SPEECH COMMUN, V55, P509, DOI 10.1016/j.specom.2012.09.005
NR 36
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER BIRKHAUSER
PI NEW YORK
PA 233 SPRING STREET, 6TH FLOOR, NEW YORK, NY 10013 USA
SN 0278-081X
EI 1531-5878
J9 CIRC SYST SIGNAL PR
JI Circuits Syst. Signal Process.
PD MAR
PY 2018
VL 37
IS 3
BP 1243
EP 1267
DI 10.1007/s00034-017-0605-7
PG 25
WC Engineering, Electrical & Electronic
SC Engineering
GA FW0OP
UT WOS:000424994900018
DA 2021-02-24
ER

PT J
AU Ettinger, RE
   Kung, TA
   Wombacher, N
   Berger, M
   Newman, MH
   Buchman, SR
   Kasten, SJ
AF Ettinger, Russell E.
   Kung, Theodore A.
   Wombacher, Natalie
   Berger, Mary
   Newman, M. Haskell
   Buchman, Steven R.
   Kasten, Steven J.
TI Timing of Furlow Palatoplasty for Patients With Submucous Cleft Palate
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
LA English
DT Article
DE palatoplasty; resonance; soft palate; speech perception
ID PHARYNGEAL FLAP SURGERY; OBSTRUCTIVE SLEEP-APNEA; SURGICAL-CORRECTION;
   REPAIR; PHARYNGOPLASTY; COMPLICATION; OUTCOMES; CLOSURE
AB Background: Submucous cleft palate (SMCP) is the most common form of cleft involving the posterior palate, resulting in variable degrees of velar dysfunction and speech disturbance. Although early surgical intervention is indicated for patients with true cleft palate, the indications for palatoplasty and timing of surgical intervention for patients with SMCP remain controversial.
   Methods: Twenty-nine patients with SMCP were retrospectively reviewed. Patients treated with Furlow palatoplasty were dichotomized based on patient age at the time of surgical correction into early speech development and late speech development. Primary outcome measures included standardized assessments of hypernasal resonance and quantitative pre- and postoperative nasometry scores. Patients managed nonoperatively were included for comparison of early and late speech outcomes.
   Results: Both early and late groups demonstrated improvement in qualitative assessment of hypernasal resonance following Furlow palatoplasty. Early and late groups also had significant improvement in pre- to postoperative nasometry scores from 7.4 to 2.3 SD from norm (P = .01) and 6.0 to 3.6 SD from norm (P = .02), respectively. There was no difference in postoperative nasometry scores between early and late groups, 2.3 and 3.6 SD (P = .12).
   Conclusion: Furlow palatoplasty significantly improves the degree of hypernasality in patients with SMCP based on pre- and postoperative nasometry scores and on qualitative assessment of hypernasality. There were no differences in speech outcomes based on early compared with late operative intervention. Therefore, early palatal repair is not obligatory for optimal speech outcomes in children with SMCP and palatoplasty should be deferred until the emergence of overt velopharyngeal insufficiency.
C1 [Ettinger, Russell E.; Kung, Theodore A.; Newman, M. Haskell; Buchman, Steven R.; Kasten, Steven J.] Univ Michigan, Sect Plast Surg, Ann Arbor, MI 48109 USA.
   [Wombacher, Natalie; Berger, Mary; Buchman, Steven R.; Kasten, Steven J.] Univ Michigan, Craniofacial Anomalies Program, Ann Arbor, MI 48109 USA.
   [Buchman, Steven R.] Univ Michigan, CS Mott Childrens Hosp, Pediat Plast Surg, Ann Arbor, MI 48109 USA.
   [Kasten, Steven J.] Univ Michigan, CS Mott Childrens Hosp, Ann Arbor, MI 48109 USA.
RP Ettinger, RE (corresponding author), 1500 E Med Ctr Dr,2130 Taubman, Ann Arbor, MI 48109 USA.
EM retting@med.umich.edu
CR Abdel-Aziz M, 2012, INT J PEDIATR OTORHI, V76, P1012, DOI 10.1016/j.ijporl.2012.03.021
   ABYHOLM FE, 1976, SCAND J PLAST RECONS, V10, P209, DOI 10.3109/02844317609012970
   CALNAN J, 1954, BRIT J PLAST SURG, V6, P264
   Chen PKT, 1996, PLAST RECONSTR SURG, V97, P1136, DOI 10.1097/00006534-199605000-00007
   DORF DS, 1982, PLAST RECONSTR SURG, V70, P74, DOI 10.1097/00006534-198207000-00015
   Ettinger RE, 2012, J CRANIOFAC SURG, V23, P1974, DOI 10.1097/SCS.0b013e31825b3ba9
   Fara M, 1977, RECONSTRUCTIVE PLAST
   Henningsson G, 2008, CLEFT PALATE-CRAN J, V45, P1, DOI 10.1597/06-086.1
   Hoopes J E, 1970, Cleft Palate J, V7, P443
   JACKSON P, 1976, PLAST RECONSTR SURG, V58, P184, DOI 10.1097/00006534-197608000-00007
   KRAVATH RE, 1980, J PEDIATR-US, V96, P645, DOI 10.1016/S0022-3476(80)80730-X
   Kummer A.W., 2005, MACKAY KUMMER SNAP T
   MCWILLIAMS BJ, 1991, CLEFT PALATE-CRAN J, V28, P247, DOI 10.1597/1545-1569(1991)028<0247:SCOTPH>2.3.CO;2
   Mori Y, 2013, BRIT J ORAL MAX SURG, V51, pE220, DOI 10.1016/j.bjoms.2013.01.015
   ORR WC, 1987, PLAST RECONSTR SURG, V80, P226, DOI 10.1097/00006534-198708000-00010
   Park S, 2000, SCAND J PLAST RECONS, V34, P131
   PENSLER JM, 1988, PLAST RECONSTR SURG, V82, P765, DOI 10.1097/00006534-198811000-00006
   PORTERFIELD HW, 1976, PLAST RECONSTR SURG, V58, P60, DOI 10.1097/00006534-197607000-00010
   Pryor LS, 2006, CLEFT PALATE-CRAN J, V43, P222, DOI 10.1597/04-115.1
   Rohrich RJ, 2000, PLAST RECONSTR SURG, V106, P413, DOI 10.1097/00006534-200008000-00026
   Rohrich RJ, 2000, PLAST RECONSTR SURG, V106, P427, DOI 10.1097/00006534-200008000-00029
   Roux J, 1825, MEMIOR STAPHYLORRAPI
   SIROIS M, 1994, PLAST RECONSTR SURG, V93, P943, DOI 10.1097/00006534-199404001-00007
   Sommerlad BC, 2004, CLEFT PALATE-CRAN J, V41, P114, DOI 10.1597/02-102
   Sullivan SR, 2011, CLEFT PALATE-CRAN J, V48, P561, DOI 10.1597/09-127
   THURSTON JB, 1980, CLEFT PALATE J, V17, P148
   VALNICEK SM, 1994, PLAST RECONSTR SURG, V93, P954, DOI 10.1097/00006534-199404001-00009
   WEATHERL.RC, 1972, PLAST RECONSTR SURG, V49, P297, DOI 10.1097/00006534-197203000-00010
   YSUNZA A, 1993, CLEFT PALATE-CRAN J, V30, P387, DOI 10.1597/1545-1569(1993)030<0387:OSASTS>2.3.CO;2
   Ysunza A, 2001, PLAST RECONSTR SURG, V107, P9, DOI 10.1097/00006534-200101000-00002
NR 30
TC 5
Z9 5
U1 0
U2 2
PU ALLIANCE COMMUNICATIONS GROUP DIVISION ALLEN PRESS
PI LAWRENCE
PA 810 EAST 10TH STREET, LAWRENCE, KS 66044 USA
SN 1055-6656
EI 1545-1569
J9 CLEFT PALATE-CRAN J
JI Cleft Palate-Craniofac. J.
PD MAR
PY 2018
VL 55
IS 3
BP 430
EP 436
DI 10.1177/1055665617726989
PG 7
WC Dentistry, Oral Surgery & Medicine; Surgery
SC Dentistry, Oral Surgery & Medicine; Surgery
GA FW1NE
UT WOS:000425065100015
PM 29437520
DA 2021-02-24
ER

PT J
AU Uddin, S
   Heald, SLM
   Van Hedger, SC
   Klos, S
   Nusbaum, HC
AF Uddin, Sophia
   Heald, Shannon L. M.
   Van Hedger, Stephen C.
   Klos, Serena
   Nusbaum, Howard C.
TI Understanding environmental sounds in sentence context
SO COGNITION
LA English
DT Article
DE Constraint; Language; Recognition; Context; Speech perception;
   Environmental sound perception
ID SPOKEN-WORD RECOGNITION; LANGUAGE COMPREHENSION; ONLINE TASK; TRACE
   MODEL; TIME-COURSE; ACTIVATION; INFORMATION; PREDICTIONS; PERCEPTION;
   CONSTRAINT
AB There is debate about how individuals use context to successfully predict and recognize words. One view argues that context supports neural predictions that make use of the speech motor system, whereas other views argue for a sensory or conceptual level of prediction. While environmental sounds can convey clear referential meaning, they are not linguistic signals, and are thus neither produced with the vocal tract nor typically encountered in sentence context. We compared the effect of spoken sentence context on recognition and comprehension of spoken words versus nonspeech, environmental sounds. In Experiment 1, sentence context decreased the amount of signal needed for recognition of spoken words and environmental sounds in similar fashion. In Experiment 2, listeners judged sentence meaning in both high and low contextually constraining sentence frames, when the final word was present or replaced with a matching environmental sound. Results showed that sentence constraint affected decision time similarly for speech and nonspeech, such that high constraint sentences (i.e., frame plus completion) were processed faster than low constraint sentences for speech and nonspeech Linguistic context facilitates the recognition and understanding of nonspeech sounds in much the same way as for spoken words. This argues against a simple form of a speech-motor explanation of predictive coding in spoken language understanding, and suggests support for conceptual-level predictions.
C1 [Uddin, Sophia; Heald, Shannon L. M.; Van Hedger, Stephen C.; Klos, Serena; Nusbaum, Howard C.] Univ Chicago, Dept Psychol, 5848 S Univ Ave, Chicago, IL 60637 USA.
RP Uddin, S (corresponding author), Univ Chicago, Dept Psychol, 5848 S Univ Ave, Chicago, IL 60637 USA.
EM sophiauddin@uchicago.edu
RI Van Hedger, Stephen/V-3248-2019
OI Van Hedger, Stephen/0000-0002-2448-9088
FU Multidisciplinary University Research Initiatives (MURI) Program of the
   Office of Naval Research [DOD/ONR N00014-13-1-0205]; University of
   Chicago MSTP Training Grant [T32GM007281]; NATIONAL INSTITUTE OF GENERAL
   MEDICAL SCIENCESUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of General Medical Sciences (NIGMS) [T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281, T32GM007281, T32GM007281, T32GM007281, T32GM007281,
   T32GM007281] Funding Source: NIH RePORTER
FX This research was supported by the Multidisciplinary University Research
   Initiatives (MURI) Program of the Office of Naval Research through
   grant, DOD/ONR N00014-13-1-0205, and by the University of Chicago MSTP
   Training Grant (T32GM007281).
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Ballas JA, 1991, HUM PERFORM, V4, P199, DOI DOI 10.1207/S15327043HUP0403_3
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bonhage CE, 2015, CORTEX, V68, P33, DOI 10.1016/j.cortex.2015.04.011
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Chambers CG, 2004, J EXP PSYCHOL LEARN, V30, P687, DOI 10.1037/0278-7393.30.3.687
   Chen YC, 2011, J EXP PSYCHOL HUMAN, V37, P1554, DOI 10.1037/a0024329
   COTTON S, 1984, PERCEPT PSYCHOPHYS, V35, P41, DOI 10.3758/BF03205923
   Cummings A, 2006, BRAIN RES, V1115, P92, DOI 10.1016/j.brainres.2006.07.050
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504
   Dick F., 2016, NEUROBIOLOGY LANGUAG, P1121
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660
   Frey A, 2014, BRAIN COGNITION, V84, P141, DOI 10.1016/j.bandc.2013.11.013
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Heald SLM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00698
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Hedger SC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076744
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hutchison KA, 2013, BEHAV RES METHODS, V45, P1099, DOI 10.3758/s13428-012-0304-z
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jurafsky D., 2000, SPEECH LANGUAGE PROC
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Leech R, 2011, BRAIN LANG, V116, P83, DOI 10.1016/j.bandl.2010.11.001
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Lupyan G, 2015, CURR DIR PSYCHOL SCI, V24, P279, DOI 10.1177/0963721415570732
   Magnuson JS, 2008, COGNITION, V108, P866, DOI 10.1016/j.cognition.2008.06.005
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   McRae K, 2005, MEM COGNITION, V33, P1174, DOI 10.3758/BF03193221
   Meteyard L, 2007, PSYCHOL SCI, V18, P1007, DOI 10.1111/j.1467-9280.2007.02016.x
   Metusalem R, 2012, J MEM LANG, V66, P545, DOI 10.1016/j.jml.2012.01.001
   MEYER DE, 1971, J EXP PSYCHOL, V90, P227, DOI 10.1037/h0031564
   Mirman D, 2006, PSYCHON B REV, V13, P958, DOI 10.3758/BF03213909
   Morris AL, 2002, J EXP PSYCHOL LEARN, V28, P962, DOI 10.1037//0278-7393.28.5.962
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Nusbaum H.C., 1997, TALKER VARIABILITY S, P109
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   OLDFIELD RC, 1965, Q J EXP PSYCHOL, V17, P273, DOI 10.1080/17470216508416445
   Orgs G, 2007, INT J PSYCHOPHYSIOL, V65, P162, DOI 10.1016/j.ijpsycho.2007.03.003
   Orgs G, 2006, BRAIN COGNITION, V62, P267, DOI 10.1016/j.bandc.2006.05.003
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   POTTER MC, 1986, J EXP PSYCHOL GEN, V115, P281, DOI 10.1037/0096-3445.115.3.281
   Revill KP, 2008, P NATL ACAD SCI USA, V105, P13111, DOI 10.1073/pnas.0807054105
   Saygin AP, 2005, BEHAV RES METHODS, V37, P99, DOI 10.3758/BF03206403
   Saygin AP, 2003, BRAIN, V126, P928, DOI 10.1093/brain/awg082
   Schneider TR, 2008, EXP PSYCHOL, V55, P121, DOI 10.1027/1618-3169.55.2.121
   SHILLCOCK RC, 1993, COGNITIVE MODELS OF SPEECH PROCESSING: THE SECOND SPERLONGA MEETING, P163
   Shintel H, 2007, COGNITION, V105, P681, DOI 10.1016/j.cognition.2006.11.005
   Shintel H, 2006, J MEM LANG, V55, P167, DOI 10.1016/j.jml.2006.03.002
   SIMPSON GB, 1989, J EXP PSYCHOL LEARN, V15, P88
   Staub A, 2015, J MEM LANG, V82, P1, DOI 10.1016/j.jml.2015.02.004
   Strauss TJ, 2007, BEHAV RES METHODS, V39, P19, DOI 10.3758/BF03192840
   SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tyler L. K., 1996, 18 ANN C COGN SCI SO
   TYLER LK, 1985, PERCEPT PSYCHOPHYS, V38, P217, DOI 10.3758/BF03207148
   TYLER LK, 1986, J MEM LANG, V25, P741, DOI 10.1016/0749-596X(86)90047-1
   TYLER LK, 1983, PERCEPT PSYCHOPHYS, V34, P409, DOI 10.3758/BF03203056
   Van Hedger SC, 2015, J ACOUST SOC AM, V138, P436, DOI 10.1121/1.4922952
   VANPETTEN C, 1995, NEUROPSYCHOLOGIA, V33, P485, DOI 10.1016/0028-3932(94)00133-A
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Yantis S, 2003, CURR OPIN NEUROBIOL, V13, P187, DOI 10.1016/S0959-4388(03)00033-3
   Zwaan RA, 2002, PSYCHOL SCI, V13, P168, DOI 10.1111/1467-9280.00430
   Zwaan RA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051382
NR 74
TC 3
Z9 3
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD MAR
PY 2018
VL 172
BP 134
EP 143
DI 10.1016/j.cognition.2017.12.009
PG 10
WC Psychology, Experimental
SC Psychology
GA FU9MP
UT WOS:000424180300012
PM 29272740
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Kang, O
   Thomson, RI
   Moran, M
AF Kang, Okim
   Thomson, Ron I.
   Moran, Meghan
TI Empirical Approaches to Measuring the Intelligibility of Different
   Varieties of English in Predicting Listener Comprehension
SO LANGUAGE LEARNING
LA English
DT Article
DE intelligibility; nonnative; English varieties; comprehension; listening;
   assessment
ID MUTUAL INTELLIGIBILITY; SPEECH-INTELLIGIBILITY; SEMANTIC CONTEXT;
   FOREIGN ACCENT; L2 SPEECH; 2ND-LANGUAGE; PROFICIENCY; CHINESE;
   SUPRASEGMENTALS; PERCEPTION
AB This study compared five research-based intelligibility measures as they were applied to six varieties of English. The objective was to determine which approach to measuring intelligibility would be most reliable for predicting listener comprehension, as measured through a listening comprehension test similar to the Test of English as a Foreign Language. The speakers included 18 English users representing six distinct varieties. These speakers' speech was evaluated by 60 listeners, users of the same English varieties who completed the listening comprehension test as well as five intelligibility tasks, all recorded by the speakers. The five measures of intelligibility included responses to true/false statements, scalar ratings of speech, perception of nonsense sentences, perception of filtered sentences, and transcription of speech; these measures were compared in terms of their relationship to listening comprehension scores using linear mixed-effects models. Results showed that the measure of intelligibility based on listeners' responses to nonsense sentences was the strongest predictor of the listening comprehension scores.
C1 [Kang, Okim; Moran, Meghan] No Arizona Univ, Flagstaff, AZ 86011 USA.
   [Thomson, Ron I.] Brock Univ, St Catharines, ON, Canada.
RP Kang, O (corresponding author), No Arizona Univ, Dept English, Flagstaff, AZ 86011 USA.
EM okim.kang@nau.edu
FU Educational Testing Service
FX This research was supported by a grant from the Educational Testing
   Service.
CR ANDERSONHSIEH J, 1994, TESOL QUART, V28, P807, DOI 10.2307/3587566
   Behrman A, 2013, J SPEECH LANG HEAR R, V56, P1567, DOI 10.1044/1092-4388(2013/12-0192)
   Benoit C, 1996, SPEECH COMMUN, V18, P381, DOI 10.1016/0167-6393(96)00026-X
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Brazil D., 1997, COMMUNICATIVE VALUE
   Brown Adam, 1991, TEACHING ENGLISH PRO, P221
   Catford J. C., 1987, CURRENT PERSPECTIVES, P87
   Chaoju T, 2009, LINGUA, V119, P709, DOI 10.1016/j.lingua.2008.10.001
   Cutler A, 2012, NATIVE LISTENING LAN
   Derwing T, 2001, APPL LINGUIST, V22, P324, DOI 10.1093/applin/22.3.324
   Derwing T.M., 1997, STUDIES 2 LANGUAGE A, V19, P1, DOI [10.1017/s0272263197001010, DOI 10.1017/S0272263197001010]
   Derwing TM, 2005, TESOL QUART, V39, P379, DOI 10.2307/3588486
   FAYER JM, 1987, LANG LEARN, V37, P313, DOI 10.1111/j.1467-1770.1987.tb00573.x
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407
   Ghanem R, 2018, ASSESSMENT IN SECOND LANGUAGE PRONUNCIATION, P115
   Gooskens C., 2013, HDB SOCIOLINGUISTICS, P195
   Gooskens C, 2010, SPEECH COMMUN, V52, P1022, DOI 10.1016/j.specom.2010.06.005
   Hahn LD, 2004, TESOL QUART, V38, P201, DOI 10.2307/3588378
   Harding L., 2011, ACCENT LISTENING ASS
   Harding L, 2012, LANG TEST, V29, P163, DOI 10.1177/0265532211421161
   Isaacs T, 2008, CAN MOD LANG REV, V64, P555, DOI 10.3138/cmlr.64.4.555
   Kachru B.B., 1992, OTHER TONGUE ENGLISH
   Kang O., 2013, COMPANION LANGUAGE A, P1047, DOI DOI 10.1002/9781118411360.WBCLA056
   Kang O., 2017, THRESHOLDS INTELLIGI
   Kang O, 2014, TESOL QUART, V48, P176, DOI 10.1002/tesq.152
   Kang O, 2012, LANG ASSESS Q, V9, P249, DOI 10.1080/15434303.2011.642631
   Kang O, 2010, SYSTEM, V38, P301, DOI 10.1016/j.system.2010.01.005
   Kang O, 2010, MOD LANG J, V94, P554, DOI 10.1111/j.1540-4781.2010.01091.x
   Kennedy S, 2008, CAN MOD LANG REV, V64, P459, DOI 10.3138/cmlr.64.3.459
   Knoll MA, 2009, SPEECH COMMUN, V51, P210, DOI 10.1016/j.specom.2008.08.001
   Kormos J., 2004, SYSTEM, V32, P145, DOI DOI 10.1016/J.SYSTEM.2004.01.001
   LANE H, 1963, MOD LANG J, V47, P154
   Lee Y, 2014, CLIN LINGUIST PHONET, V28, P785, DOI 10.3109/02699206.2014.904443
   Levis JM, 2005, TESOL QUART, V39, P369, DOI 10.2307/3588485
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Major RC, 2002, TESOL QUART, V36, P173, DOI 10.2307/3588329
   Munro M. J., 2001, STUDIES 2 LANGUAGE A, V23, P159
   Munro M. J., 2018, ROUTLEDGE HDB CONT E, P413
   Munro M. J., 2006, SYSTEM, V34, P520, DOI DOI 10.1016/J.SYSTEM.2006.09.004
   Munro M. J., 1998, LANG LEARN, V48, P451
   Munro MJ, 1999, LANG LEARN, V49, P285, DOI 10.1111/0023-8333.49.s1.8
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   MUNRO MJ, 1995, STUDIES 2 LANGUAGE A, V17, P17, DOI DOI 10.1017/S0272263100013735
   Nye P, 1974, HASKINS LAB STAT REP, V37, P169
   PICHENY MA, 1985, J SPEECH HEAR RES, V28, P96, DOI 10.1044/jshr.2801.96
   Pickering L, 2001, TESOL QUART, V35, P233, DOI 10.2307/3587647
   POLLACK I, 1948, J ACOUST SOC AM, V20, P259, DOI 10.1121/1.1906369
   Rogers CL, 2004, LANG SPEECH, V47, P139, DOI 10.1177/00238309040470020201
   Sakiey E., 1979, 3000 INSTANT WORDS
   Smith L. E., 1985, WORLD ENGLISH, V4, P333, DOI DOI 10.1111/J.1467-971X.1985.TB00423.X
   Stevens J.P., 1992, APPL MULTIVARIATE ST
   Thomson R, 2018, ASSESSMENT IN SECOND LANGUAGE PRONUNCIATION, P11
   Trofimovich P, 2006, STUD SECOND LANG ACQ, V28, P1, DOI 10.1017/S0272263106060013
   Trofimovich P, 2012, BILING-LANG COGN, V15, P905, DOI 10.1017/S1366728912000168
   van Bezooijen Renee, 1997, HDB STANDARDS RESOUR, P481
   Vanderplank R., 1993, ELT J, V47, P117
   VANELS T, 1987, MOD LANG J, V71, P147, DOI 10.2307/327199
   vansBoeschoten J. A., 1989, THESIS
   vansHeuven V. J., 2008, INT J HUMANITIES ART, V2, P39
   WANG H., 2015, EURASIP J WIREL COMM, V2015, P1, DOI DOI 10.1016/J.TPLANTS.2015.04.003
   Wang H. J., 2007, THESIS
   Wang HY, 2013, INTERSPEECH, P431
   Zielinski BW, 2008, SYSTEM, V36, P69, DOI 10.1016/j.system.2007.11.004
NR 64
TC 14
Z9 14
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD MAR
PY 2018
VL 68
IS 1
BP 115
EP 146
DI 10.1111/lang.12270
PG 32
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA FU4MD
UT WOS:000423826300004
DA 2021-02-24
ER

PT J
AU Noguchi, M
   Kam, CLH
AF Noguchi, Masaki
   Kam, Carla L. Hudson
TI The Emergence of the Allophonic Perception of Unfamiliar Speech Sounds:
   The Effects of Contextual Distribution and Phonetic Naturalness
SO LANGUAGE LEARNING
LA English
DT Article
DE allophone perception; distributional learning; constraints; language
   learning; phonetic naturalness
ID PHONOLOGICAL ALTERNATIONS; HUMAN INFANTS; EFFECT SIZE; ACQUISITION;
   INFORMATION; VARIABILITY; STATISTICS; LANGUAGE; SENSITIVITY; CLUSTERS
AB In human languages, different speech sounds can be contextual variants of a single phoneme, called allophones. Learning which sounds are allophones is an integral part of the acquisition of phonemes. Whether given sounds are separate phonemes or allophones in a listener's language affects speech perception. Listeners tend to be less sensitive to acoustic differences between sounds that are allophones. This study investigated the mechanisms behind the learning of allophones by looking at adults' sensitivity to acoustic differences between two unfamiliar sounds when they were exposed to input in which the sounds behave like separate phonemes versus allophones in terms of their contextual distribution. The results of two experiments showed that adults became less sensitive to acoustic differences between two unfamiliar sounds after being exposed to input in which the sounds were in complementary distribution and that the emergence of allophonic perception was constrained by the phonetic naturalness of complementary distribution.
C1 [Noguchi, Masaki; Kam, Carla L. Hudson] Univ British Columbia, Vancouver, BC, Canada.
RP Noguchi, M (corresponding author), Totem Field Studies, 2613 West Mall, Vancouver, BC V6T 1Z4, Canada.
EM mskngch@gmail.com
OI Hudson Kam, Carla/0000-0002-7638-3656
FU NSERCNatural Sciences and Engineering Research Council of Canada (NSERC)
FX This research was funded by a NSERC Discovery Grant (Individual) to
   Carla L. Hudson Kam entitled Constraints on Language Acquisition and How
   They Change (or Don't) With Age.
CR Archer SL, 2011, INFANT BEHAV DEV, V34, P534, DOI 10.1016/j.infbeh.2011.07.001
   Aslin R. N., 1980, CHILD PHONOLOGY, V2, P67
   Aslin RN, 2012, CURR DIR PSYCHOL SCI, V21, P170, DOI 10.1177/0963721412436806
   Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707
   BEDDOR PS, 1982, J ACOUST SOC AM, V71, P1551, DOI 10.1121/1.387809
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boomershine A, 2008, PHONOL PHONET, V13, P145
   Byrd D, 1996, J PHONETICS, V24, P263, DOI 10.1006/jpho.1996.0014
   Carpenter AC, 2010, PHONOLOGY, V27, P345, DOI 10.1017/S0952675710000199
   Chambers KE, 2003, COGNITION, V87, pB69, DOI 10.1016/S0010-0277(02)00233-0
   Creel SC, 2004, J EXP PSYCHOL LEARN, V30, P1119, DOI 10.1037/0278-7393.30.5.1119
   Erickson LC, 2015, DEV REV, V37, P66, DOI 10.1016/j.dr.2015.05.002
   Feldman N, 2011, PROC ANN BUCLD, P197
   Feldman NH, 2013, COGNITION, V127, P427, DOI 10.1016/j.cognition.2013.02.007
   Fenn KM, 2003, NATURE, V425, P614, DOI 10.1038/nature01951
   Fiser J, 2002, J EXP PSYCHOL LEARN, V28, P458, DOI 10.1037//0278-7393.28.3.458
   Gerken L, 2008, LANG LEARN DEV, V4, P228, DOI 10.1080/15475440802143117
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476
   Hall Kathleen Currie, 2009, THESIS
   Hao Y, 2012, THESIS
   Harnsberger JD, 2001, J PHONETICS, V29, P303, DOI 10.1006/jpho.2001.0140
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   HOHNE EA, 1994, PERCEPT PSYCHOPHYS, V56, P613, DOI 10.3758/BF03208355
   Johnson K, 2010, J PHONETICS, V38, P127, DOI 10.1016/j.wocn.2009.11.001
   JOnES dAnIEL, 1950, PHONEME ITS NATURE U
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Li F., 2007, P 16 INT C PHON SCI, P917
   MacMillan N. A., 2005, DETECTION THEORY USE
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J. C., 2000, THESIS
   McGuire G. L., 2007, THESIS
   McGuire Grant, 2007, UC BERK PHON ANN REP, V2007, P391
   Moreton E, 2012, LANG LINGUIST COMPAS, V6, P702, DOI 10.1002/lnc3.366
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2
   Noguchi M., 2015, CANADIAN ACOUSTICS, V43, P1
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434
   Onishi KH, 2002, COGNITION, V83, pB13, DOI 10.1016/S0010-0277(01)00165-2
   Pajak B., 2012, THESIS
   Peperkamp S, 2003, PROC ANN BUCLD, P650
   Peperkamp S, 2006, PROC ANN BUCLD, P464
   Peperkamp S, 2006, COGNITION, V101, pB31, DOI 10.1016/j.cognition.2005.10.006
   R Core Team, 2014, R LANG ENV STAT COMP
   Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   SCHANE SA, 1975, COGNITION, V3, P351
   Seidl A, 2009, LANG LEARN DEV, V5, P191, DOI 10.1080/15475440902754326
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Toda M., 2003, INT SEM SPEECH PROD
   Trubetzkoy N., 1969, PRINCIPLES PHONOLOGY
   Twaddell WF, 1936, LANGUAGE, V12, P53, DOI 10.2307/409020
   Whalen DH, 1997, J PHONETICS, V25, P501, DOI 10.1006/jpho.1997.0058
   White J, 2014, COGNITION, V133, P85, DOI 10.1016/j.cognition.2014.05.020
   White KS, 2008, COGNITION, V107, P238, DOI 10.1016/j.cognition.2007.11.012
   Wilson C, 2006, COGNITIVE SCI, V30, P945, DOI 10.1207/s15516709cog0000_89
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
NR 63
TC 1
Z9 1
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD MAR
PY 2018
VL 68
IS 1
BP 147
EP 176
DI 10.1111/lang.12267
PG 30
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA FU4MD
UT WOS:000423826300005
DA 2021-02-24
ER

PT J
AU Nagle, CL
AF Nagle, Charles L.
TI Examining the Temporal Structure of the Perception-Production Link in
   Second Language Acquisition: A Longitudinal Study
SO LANGUAGE LEARNING
LA English
DT Article
DE pronunciation; longitudinal; mixed-effects modeling; speech perception;
   speech production; Spanish
ID INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION; VOICING CONTRAST; L2
   PERCEPTION; INFANTS SHOW; LANGUAGE; ENGLISH; SPANISH; LISTENERS; VOWELS
AB Most studies on the perception-production link have assumed a synchronous relationship according to which gains in perception transfer to production rapidly and efficiently. However, time-lagged and asymptotic relationships are also possible, where perception would guide production at a later stage or production would improve only once perception has reached a high level of accuracy. This study investigated the temporal dynamics of the perception-production link by modeling English speakers' ability to perceive and produce second language (L2) Spanish stops over time. Mixed-effects modeling of the d perception and voice onset time (VOT) production data demonstrated significant development in both areas. Time-lagged change models indicated a change in d significantly related to decreasing VOT in L2 /p/ at the following testing time, but no significant relationships emerged between perception and production of L2 /b/. Multiple patterns among individuals emerged. Results are interpreted in light of contemporary models of L2 speech learning.
C1 [Nagle, Charles L.] Iowa State Univ, Ames, IA USA.
RP Nagle, CL (corresponding author), 3102G Pearson Hall,505 Morrill Rd, Ames, IA 50011 USA.
EM cnagle@iastate.edu
RI Nagle, Charles/AAY-4198-2020
OI Nagle, Charles/0000-0003-2712-2705
CR Baese-Berk MM, 2016, J MEM LANG, V89, P23, DOI 10.1016/j.jml.2015.10.008
   Baker W., 2006, IRAL-INT REV APPL LI, V44, P231, DOI [10.1515/IRAL.2006.010, DOI 10.1515/IRAL.2006.010]
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Benki J. R., 2005, P 4 INT S BIL, P240
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2015, PRAAT DOING PHONETIC
   Boersma P, 2008, PHONOL PHONET, V13, P271
   BORDEN G, 1983, LANG LEARN, V33, P499, DOI 10.1111/j.1467-1770.1983.tb00946.x
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Casillas J. V., 2016, THESIS
   Castenada Vicente M. L., 1986, ESTUDIOS FONETICA EX, V2, P92
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Chladkova K, 2011, J ACOUST SOC AM, V130, pEL186, DOI 10.1121/1.3629135
   Cunnings I, 2015, SECOND LANG ACQUIS R, P159
   Curtin S., 1998, SECOND LANG RES, V14, P289
   Deuchar M, 1996, J PHONETICS, V24, P351, DOI 10.1006/jpho.1996.0019
   Escudero P, 2006, PHONOLOGY IN CONTEXT, P109
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1982, J PHONETICS, V10, P177, DOI 10.1016/S0095-4470(19)30956-8
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Freed BF, 2004, STUD SECOND LANG ACQ, V26, P349, DOI 10.1017/S0272263104062096
   Gambi C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00340
   GASS S, 1984, APPL PSYCHOLINGUIST, V5, P51, DOI 10.1017/S0142716400004835
   Hanulikova A, 2012, LANG LEARN, V62, P79, DOI 10.1111/j.1467-9922.2012.00707.x
   Hao YC, 2016, J PHONETICS, V54, P151, DOI 10.1016/j.wocn.2015.10.003
   Hitchcock ER, 2013, J SPEECH LANG HEAR R, V56, P441, DOI 10.1044/1092-4388(2012/11-0175)
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Kartushina N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01246
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Linck JA, 2015, LANG LEARN, V65, P185, DOI 10.1111/lang.12117
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   MACKEN MA, 1980, J CHILD LANG, V7, P433, DOI 10.1017/S0305000900002774
   MacMillan N. A., 2005, DETECTION THEORY USE
   Mayr R, 2010, BILING-LANG COGN, V13, P279, DOI 10.1017/S1366728909990022
   Nagle C., 2017, J 2 LANGUAGE PRONUNC, V3, P219
   Nagle C., 2017, LONGITUDINAL STUDY V
   Ohala John J., 1997, P 4 SEOUL INT C LING, P92
   Peperkamp S., 2011, P INTERSPEECH, V12, P161
   R Core Team, 2016, R LANG ENV STAT COMP
   Rochet B. L., 1995, SPEECH PERCEPTION LI, P379
   Rosner BS, 2000, J PHONETICS, V28, P217, DOI 10.1006/jpho.2000.0113
   Sakai M., 2017, APPL PSYCHOLINGUISTI
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Smith B.L., 1978, GLOSSA, V12, P163
   Smith LC, 2001, PAST, PRESENT, AND FUTURE OF SECOND LANGUAGE RESEARCH, PROCEEDINGS, P3
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Vasiliev P, 2014, HDB SPANISH 2 LANGUA, P130
   Werker J. F., 1985, PERCEPT PSYCHOPHYS, V37, P278
   WESTBURY JR, 1986, J LINGUIST, V22, P145, DOI 10.1017/S0022226700010598
   Williams L., 1977, J PHONETICS, V5, P169
   WILLIAMS L, 1980, CHILD PHONOLOGY, V2, P185
   Zampini M., 1998, TEXAS PAPERS FOREIGN, V3, P85
   Zampini M. L., 2001, ONE MIND 2 LANGUAGES, P23
NR 63
TC 9
Z9 9
U1 2
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD MAR
PY 2018
VL 68
IS 1
BP 234
EP 270
DI 10.1111/lang.12275
PG 37
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA FU4MD
UT WOS:000423826300008
DA 2021-02-24
ER

PT J
AU Ozker, M
   Yoshor, D
   Beauchamp, MS
AF Ozker, Muge
   Yoshor, Daniel
   Beauchamp, Michael S.
TI Frontal cortex selects representations of the talker's mouth to aid in
   speech perception
SO ELIFE
LA English
DT Article
ID SURFACE-BASED ANALYSIS; VISUAL-CORTEX; AUDITORY-CORTEX; ATTENTION;
   MECHANISMS; BRAIN; RESPONSES; LANGUAGE; SIGNALS; STREAMS
AB Human faces contain multiple sources of information. During speech perception, visual information from the talker's mouth is integrated with auditory information from the talker's voice. By directly recording neural responses from small populations of neurons in patients implanted with subdural electrodes, we found enhanced visual cortex responses to speech when auditory speech was absent (rendering visual speech especially relevant). Receptive field mapping demonstrated that this enhancement was specific to regions of the visual cortex with retinotopic representations of the mouth of the talker. Connectivity between frontal cortex and other brain regions was measured with trial-by-trial power correlations. Strong connectivity was observed between frontal cortex and mouth regions of visual cortex; connectivity was weaker between frontal cortex and non-mouth regions of visual cortex or auditory cortex. These results suggest that top-down selection of visual information from the talker's mouth by frontal cortex plays an important role in audiovisual speech perception.
C1 [Ozker, Muge; Yoshor, Daniel; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
   [Yoshor, Daniel] Michael E DeBakey VA Med Ctr, Houston, TX USA.
RP Ozker, M; Beauchamp, MS (corresponding author), Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
EM mozker@gmail.com; michael.beauchamp@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934
FU Veterans Administration Clinical Science Research and Development
   [1I01CX000325]; National Institutes of HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA
   [R01NS065395, U01NS098976]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS
   AND STROKEUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Neurological
   Disorders & Stroke (NINDS) [R01NS065395, R01NS065395, U01NS098976,
   R01NS065395, R01NS065395, U01NS098976, R01NS065395, U01NS098976,
   R01NS065395, R01NS065395, R01NS065395, R01NS065395, R01NS065395,
   U01NS098976] Funding Source: NIH RePORTER; Veterans AffairsUS Department
   of Veterans Affairs [I01CX001122, I01CX001122, I01CX001122, I01CX001122]
   Funding Source: NIH RePORTER
FX Veterans Administration Clinical Science Research and Development Merit
   Award Number 1I01CX000325 Daniel Yoshor; National Institutes of Health
   R01NS065395 Michael S Beauchamp; National Institutes of Health
   U01NS098976 Michael S Beauchamp
CR Argall BD, 2006, HUM BRAIN MAPP, V27, P14, DOI 10.1002/hbm.20158
   Bates D., 2014, FITTING LINEAR MIXED
   Callan DE, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00389
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Canolty RT, 2007, FRONT NEUROSCI-SWITZ, V1, P185, DOI 10.3389/neuro.01.1.1.014.2007
   Catani M, 2008, CORTEX, V44, P953, DOI 10.1016/j.cortex.2008.04.002
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Crone NE, 2001, CLIN NEUROPHYSIOL, V112, P565, DOI 10.1016/S1388-2457(00)00545-9
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   Foster BL, 2015, NEURON, V86, P578, DOI 10.1016/j.neuron.2015.03.018
   Gregoriou GG, 2012, NEURON, V73, P581, DOI 10.1016/j.neuron.2011.12.019
   Gunduz A, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00089
   Hall DA, 2005, J COGNITIVE NEUROSCI, V17, P939, DOI 10.1162/0898929054021175
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hipp JF, 2012, NAT NEUROSCI, V15, P884, DOI 10.1038/nn.3101
   Jacques C, 2016, NEUROPSYCHOLOGIA, V83, P14, DOI 10.1016/j.neuropsychologia.2015.07.024
   Kastner S, 2000, ANNU REV NEUROSCI, V23, P315, DOI 10.1146/annurev.neuro.23.1.315
   Kirchner H, 2009, J NEUROSCI, V29, P7599, DOI 10.1523/JNEUROSCI.1233-09.2009
   Lee H, 2011, J NEUROSCI, V31, P11338, DOI 10.1523/JNEUROSCI.6510-10.2011
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Miller EK, 2013, CURR OPIN NEUROBIOL, V23, P216, DOI 10.1016/j.conb.2012.11.011
   Mukamel R, 2005, SCIENCE, V309, P951, DOI 10.1126/science.1110913
   Nir Y, 2007, CURR BIOL, V17, P1275, DOI 10.1016/j.cub.2007.06.066
   Okada K, 2009, NEUROSCI LETT, V452, P219, DOI 10.1016/j.neulet.2009.01.060
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Popov T, 2017, J NEUROSCI, V37, P4117, DOI 10.1523/JNEUROSCI.3015-16.2017
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Ray S, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1000610
   Schepers IM, 2015, CEREB CORTEX, V25, P4103, DOI 10.1093/cercor/bhu127
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Yi A, 2013, J SPEECH LANG HEAR R, V56, P471, DOI 10.1044/1092-4388(2012/10-0288)
   Yoshor D, 2007, CEREB CORTEX, V17, P2293, DOI 10.1093/cercor/bhl138
NR 37
TC 6
Z9 6
U1 0
U2 3
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD FEB 27
PY 2018
VL 7
AR e30387
DI 10.7554/eLife.30387
PG 14
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA FX7DO
UT WOS:000426247700001
PM 29485404
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kang, S
   Woo, J
   Park, H
   Brown, CJ
   Hong, SH
   Moon, IJ
AF Kang, Soojin
   Woo, Jihwan
   Park, Heesung
   Brown, Carolyn J.
   Hong, Sung Hwa
   Moon, Il Joon
TI Objective Test of Cochlear Dead Region: Electrophysiologic Approach
   using Acoustic Change Complex
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEECH-PERCEPTION ABILITIES; CORTICAL EVOKED-POTENTIALS; EVENT-RELATED
   POTENTIALS; AUDITORY CHANGE COMPLEX; DISCRIMINATION; SPECTRUM; CHILDREN;
   INTELLIGIBILITY; DIAGNOSIS; VERSION
AB The goal of this study was to develop an objective and neurophysiologic method of identifying the presence of cochlear dead region (CDR) by combining acoustic change complex (ACC) responses with threshold-equalizing noise (TEN) test. The goal of the first study was to confirm whether ACC could be evoked with TEN stimuli and to also optimize the test conditions. The goal of the second study was to determine whether the TEN-ACC test is capable of detecting CDR(s). The ACC responses were successfully recorded from all study participants. Both behaviorally and electrophysiologically obtained masked thresholds (TEN threshold and TEN-ACC threshold) were similar and below 10 and 12 dB SNR in NH listeners, respectively. HI listeners were divided into HI (non-CDR) and CDR groups based on the behavioral TEN test. For the non-CDR group, TEN-ACC thresholds were below 12 dB which were similar to NH listeners. However, for the CDR group, TEN-ACC thresholds were significantly higher (>= 12 dB SNR) than those in the NH and HI groups, indicating that CDR(s) can be objectively detected using the ACC. Results of this study demonstrate that it is possible to detect the presence of CDR using an electrophysiologic method.
C1 [Kang, Soojin; Park, Heesung; Moon, Il Joon] Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
   [Kang, Soojin; Woo, Jihwan] Univ Ulsan, Sch Elect Engn, Biomed Engn, Ulsan, South Korea.
   [Brown, Carolyn J.] Univ Iowa, Dept Speech Pathol, Iowa City, IA 52242 USA.
   [Brown, Carolyn J.] Univ Iowa, Dept Audiol, Iowa City, IA 52242 USA.
   [Hong, Sung Hwa] Sungkyunkwan Univ, Samsung Changwon Hosp, Sch Med, Dept Otorhinolaryngol Head & Neck Surg, Chang Won, South Korea.
RP Moon, IJ (corresponding author), Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.; Hong, SH (corresponding author), Sungkyunkwan Univ, Samsung Changwon Hosp, Sch Med, Dept Otorhinolaryngol Head & Neck Surg, Chang Won, South Korea.
EM hongsh@skku.edu; moonij@skku.edu
OI kang, soojin/0000-0003-3070-8125
FU National Research Foundation of Korea(NRF) grant - Korea
   government(MSIP; Ministry of Science, ICT & Future Planning)
   [2017R1C1B5016610]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIP; Ministry of
   Science, ICT & Future Planning) (No. 2017R1C1B5016610).
CR Backus BC, 2006, J ACOUST SOC AM, V119, P2889, DOI 10.1121/1.2169918
   Baer T, 2002, J ACOUST SOC AM, V112, P1133, DOI 10.1121/1.1498853
   Brown CJ, 2008, EAR HEARING, V29, P704, DOI 10.1097/AUD.0b013e31817a98af
   Dimitrijevic A, 2008, CLIN NEUROPHYSIOL, V119, P2111, DOI 10.1016/j.clinph.2008.06.002
   Halpin Chris, 2002, Am J Audiol, V11, P56, DOI 10.1044/1059-0889(2002/016)
   Harris KC, 2007, HEARING RES, V228, P58, DOI 10.1016/j.heares.2007.01.021
   He S., 2014, EAR HEARING
   He SM, 2014, EAR HEARING, V35, pE63, DOI 10.1097/01.aud.0000436605.92129.1b
   He SM, 2013, EAR HEARING, V34, P733, DOI 10.1097/AUD.0b013e3182944bb5
   He SM, 2012, INT J AUDIOL, V51, P771, DOI 10.3109/14992027.2012.699198
   HUMES LE, 1984, J SPEECH HEAR RES, V27, P206, DOI 10.1044/jshr.2702.206
   Kim JR, 2009, EAR HEARING, V30, P320, DOI 10.1097/AUD.0b013e31819c42b7
   KLEIN AJ, 1981, J ACOUST SOC AM, V69, P760, DOI 10.1121/1.385576
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Lister JJ, 2007, EAR HEARING, V28, P862, DOI 10.1097/AUD.0b013e3181576cba
   Mackersie Carol L, 2004, J Am Acad Audiol, V15, P498, DOI 10.3766/jaaa.15.7.4
   Malicka AN, 2013, EAR HEARING, V34, P458, DOI 10.1097/AUD.0b013e3182775982
   Martin BA, 1999, EAR HEARING, V20, P33, DOI 10.1097/00003446-199902000-00004
   Martin BA, 2000, J ACOUST SOC AM, V107, P2155, DOI 10.1121/1.428556
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   Martin BA, 2010, EAR HEARING, V31, P356, DOI 10.1097/AUD.0b013e3181ce6355
   Martinez Amy S., 2013, Seminars in Hearing, V34, P278, DOI 10.1055/s-0033-1356640
   Michalewski HJ, 2005, CLIN NEUROPHYSIOL, V116, P669, DOI 10.1016/j.clinph.2004.09.027
   Moore B C, 2001, Trends Amplif, V5, P1, DOI 10.1177/108471380100500102
   Moore BCJ, 2000, BRIT J AUDIOL, V34, P205, DOI 10.3109/03005364000000131
   Moore BCJ, 2004, EAR HEARING, V25, P478, DOI 10.1097/01.aud.0000145992.31135.89
   Moore BCJ, 2004, EAR HEARING, V25, P98, DOI 10.1097/01.AUD.0000120359.49711.D7
   Moore BCJ, 2003, INT J AUDIOL, V42, P465, DOI 10.3109/14992020309081516
   Moore BCJ, 2012, EAR HEARING, V33, P554, DOI 10.1097/AUD.0b013e31824b9e43
   Ostroff JM, 1998, EAR HEARING, V19, P290, DOI 10.1097/00003446-199808000-00004
   PARVING A, 1982, SCAND AUDIOL, V11, P173, DOI 10.3109/01050398209076214
   Santhanakrishnan A, 2013, INT J ARTIF ORGANS, V36, P892, DOI 10.5301/ijao.5000259
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Vickers DA, 2001, J ACOUST SOC AM, V110, P1164, DOI 10.1121/1.1381534
   Vinay, 2008, J ACOUST SOC AM, V123, P606, DOI 10.1121/1.2823497
   Vinay, 2007, J ACOUST SOC AM, V122, P542, DOI 10.1121/1.2722055
NR 36
TC 1
Z9 1
U1 0
U2 2
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD FEB 26
PY 2018
VL 8
AR 3645
DI 10.1038/s41598-018-21754-7
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FX4KW
UT WOS:000426045700066
PM 29483598
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Tavora-Vieira, D
   Wedekind, A
   Marino, R
   Purdy, SC
   Rajan, GP
AF Tavora-Vieira, Dayse
   Wedekind, Andre
   Marino, Roberta
   Purdy, Suzanne C.
   Rajan, Gunesh P.
TI Using aided cortical assessment as an objective tool to evaluate
   cochlear implant fitting in users with single-sided deafness
SO PLOS ONE
LA English
DT Article
ID AUDITORY-EVOKED POTENTIALS; ELECTRIC-ACOUSTIC STIMULATION; SENSORINEURAL
   HEARING-LOSS; UNILATERAL DEAFNESS; SPEECH-PERCEPTION; BINAURAL HEARING;
   TINNITUS; OUTCOMES; NEUROPATHY; INFANTS
AB Objectives
   To assess the use of cortical auditory evoked potentials (CAEPs) to verify, and if necessary, optimize the cochlear implant (CI) fitting of adult CI users with postlingual single-sided deafness (SSD).
   Methods
   Sound field cortical responses to the speech tokens /m/, /g/, /t/, and /s/ were recorded from input to the CI while the normal hearing ear was masked. Responses were evaluated by visual inspection and classified as presence or absence of the CAEPs components P1, N1, P2. In case of an absence fitting was adjusted accordingly. After fitting, subjects were asked to use their new setting for 2-3 weeks for acclimatization purposes and then return for retesting. At retesting, new CAEP recordings were performed to objectively ensure that the new fitting maps effectively activated the auditory cortex.
   Results
   In 14/19 subjects, as per visual inspection, clear CAEPs were recorded by each speech token and were, therefore, not refit. In the other 5 subjects, CAEPs could not be evoked for at least one speech token. The fitting maps in these subjects were adjusted until clear CAEPs were evoked for all 4 speech tokens.
   Conclusions
   CAEP can be used to quickly and objectively verify the suitability of CI fitting in experienced adult CI users with SSD. If used in the early post-implantation stage, this method could help CI users derive greater benefit for CI use and, therefore, be more committed to auditory training.
C1 [Tavora-Vieira, Dayse; Wedekind, Andre; Marino, Roberta; Rajan, Gunesh P.] Univ Western Australia, Otolaryngol Head & Neck Surg, Sch Surg, Perth, WA, Australia.
   [Tavora-Vieira, Dayse; Marino, Roberta] Fiona Stanley Hosp, Perth, WA, Australia.
   [Purdy, Suzanne C.] Univ Auckland, Sch Physhol, Fac Sci, Auckland, New Zealand.
   [Purdy, Suzanne C.] Eisdell Moore Ctr, Hearing & Balance Res, Auckland, New Zealand.
RP Tavora-Vieira, D (corresponding author), Univ Western Australia, Otolaryngol Head & Neck Surg, Sch Surg, Perth, WA, Australia.; Tavora-Vieira, D (corresponding author), Fiona Stanley Hosp, Perth, WA, Australia.
EM dayse.tavora@gmail.com
RI Purdy, Suzanne C/F-2050-2010
OI Purdy, Suzanne C/0000-0001-9978-8173; Tavora-Vieira,
   Dayse/0000-0001-6249-7268
CR Alvarenga KF, 2012, INT J PEDIATR OTORHI, V76, P1332, DOI 10.1016/j.ijporl.2012.06.001
   Arndt S, 2017, HNO
   Arndt S, 2011, OTOL NEUROTOL, V32, P39, DOI 10.1097/MAO.0b013e3181fcf271
   Buechner A, 2010, OTOL NEUROTOL, V31, P1381, DOI 10.1097/MAO.0b013e3181e3d353
   Carter L, J AM ACAD AUDIOL, V21, P346
   Carter L, 2013, J AM ACAD AUDIOL, V24, P807, DOI 10.3766/jaaa.24.9.5
   Chang HW, 2012, INT J AUDIOL, V51, P663, DOI 10.3109/14992027.2012.690076
   Ching Teresa Y. C., 2016, Seminars in Hearing, V37, P25, DOI 10.1055/s-0035-1570332
   de Heyning PV, 2008, ANN OTO RHINOL LARYN, V117, P645, DOI 10.1177/000348940811700903
   Firszt Jill B., 2002, Ear and Hearing, V23, P516, DOI 10.1097/00003446-200212000-00003
   Firszt JB, 2012, OTOL NEUROTOL, V33, P1339, DOI 10.1097/MAO.0b013e318268d52d
   Gardner-Berry K, 2015, INT J AUDIOL, V54, P524, DOI 10.3109/14992027.2015.1007214
   Glista D, 2012, INT J OTOLARYNGOL, V2012, DOI DOI 10.1155/2012/982894
   Golding M, 2007, J AM ACAD AUDIOL, V18, P117, DOI 10.3766/jaaa.18.2.4
   Golding M, 2009, INT J AUDIOL, V48, P833, DOI 10.3109/14992020903140928
   GRAVEL JS, 1989, SEMIN HEAR, V10, P272
   Gstoettner WK, 2008, ACTA OTO-LARYNGOL, V128, P968, DOI 10.1080/00016480701805471
   Hansen MR, 2013, OTOL NEUROTOL, V34, P1681, DOI 10.1097/MAO.0000000000000102
   Korczak PA, 2005, EAR HEARING, V26, P165, DOI 10.1097/00003446-200504000-00005
   Martin B, 2007, AUITORY EVOKED POTEN, P497
   Mertens G, 2017, EAR HEARING, V38, P117, DOI 10.1097/AUD.0000000000000359
   Mertens G, 2015, AUDIOL NEURO-OTOL, V20, P67, DOI 10.1159/000380751
   Munro KJ, 2011, EAR HEARING, V32, P782, DOI 10.1097/AUD.0b013e318220377e
   National Acoustics Laboratories, 2010, HEARLAB SYST OP MAN
   Peterson NR, 2010, RESTOR NEUROL NEUROS, V28, P237, DOI 10.3233/RNN-2010-0535
   Purdy S, 2005, SOUND FDN EARLY AMPL, P115
   Purdy S. C., 2001, NZ AUDIOLOGICAL SOC, V11, P16
   Rajan GP, 2012, LARYNGOSCOPE, V122, P190, DOI 10.1002/lary.22142
   Rance G, 2002, EAR HEARING, V23, P239, DOI 10.1097/00003446-200206000-00008
   Sharma Anu, 2005, J Am Acad Audiol, V16, P564, DOI 10.3766/jaaa.16.8.5
   Skarzynski Henryk, 2003, Med Sci Monit, V9, pCS20
   Stelzig Yvonne, 2011, J Med Case Rep, V5, P343, DOI 10.1186/1752-1947-5-343
   Tavora-Vieira D, 2015, OTOL NEUROTOL, V36, P430, DOI 10.1097/MAO.0000000000000707
   Tavora-Vieira D, 2013, NEUROREPORT, V24, P724, DOI 10.1097/WNR.0b013e3283642a93
   Tavora-Vieira D, 2013, LARYNGOSCOPE, V123, P1251, DOI 10.1002/lary.23764
   Van de Heyning P, 2016, AUDIOL NEURO-OTOL, V21, P391, DOI 10.1159/000455058
   Vermeire K, 2009, AUDIOL NEURO-OTOL, V14, P163, DOI 10.1159/000171478
   von Ilberg C, 1999, ORL J OTO-RHINO-LARY, V61, P334, DOI 10.1159/000027695
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
NR 39
TC 3
Z9 4
U1 0
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD FEB 22
PY 2018
VL 13
IS 2
AR e0193081
DI 10.1371/journal.pone.0193081
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FX1SB
UT WOS:000425831000032
PM 29470548
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Boerrigter, M
   Vermeulen, A
   Marres, H
   Langereis, M
AF Boerrigter, Merle
   Vermeulen, Anneke
   Marres, Henri
   Langereis, Margreet
TI Personality Traits of Profoundly Hearing Impaired Adolescents with
   Cochlear Implants - A Comparison with Normal Hearing Peers
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE cochlear implant; hearing loss; personality; adolescence; speech
   perception; language comprehension
ID SOCIAL-EMOTIONAL DEVELOPMENT; MENTAL-HEALTH PROBLEMS;
   SCHOOL-AGE-CHILDREN; DEAF-CHILDREN; LANGUAGE-DEVELOPMENT;
   SPEECH-PERCEPTION; YOUNG-CHILDREN; SELF-CONCEPT; SKILLS; PERSPECTIVE
AB The aim of this study was to compare the personality traits of adolescents with cochlear implants (CIs) to a reference group (normal-hearing peers). In the past, the personality development of hearing impaired adolescents was severely compromised. Improved speech perception with CI significantly increased their perspectives. In addition, differences between the reference group and CI users were investigated on personality traits according to level of speech perception skills (high/low) and level of language comprehension (adequate/poor). A cohort of 59 adolescents was assessed 10 years after CI implantation. Personality traits were measured using the standardized Dutch Personality Questionnaire, which consists of 5 scales: Inadequacy, Social Inadequacy, Recalcitrance (RE), Perseverance, and Dominance. Speech perception and language comprehension were tested with standardized tests. The distributions of personality scores, in the clinical or non-clinical range, for the CI group were compared to the reference group using the Chi-Square test for Goodness of Fit. Adolescents with CI showed normal or favorable distributions on all personality scales except for the RE scale. There was a significant influence of speech perception and language comprehension on this scale. Consequently, adolescents with CI who demonstrated high speech perception and adequate language comprehension scores showed similar distribution patterns as the reference group on all personality scales. In conclusion; personality traits that reflect social relations, self-conscience, and school-and task orientation in adolescents with CI are similar to those in normal-hearing peers. This holds, despite variations in speech perception ability and language comprehension levels, for the CI group. On the RE scale, the adolescents with CI with low speech perception and poor language comprehension scores are more likely to score in the clinical deviant range and are at risk.
C1 [Boerrigter, Merle; Vermeulen, Anneke; Marres, Henri; Langereis, Margreet] Radboud Univ Nijmegen, Med Ctr, Dept Otorhinolaryngol, Nijmegen, Netherlands.
   [Boerrigter, Merle; Vermeulen, Anneke; Marres, Henri; Langereis, Margreet] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Boerrigter, M (corresponding author), Radboud Univ Nijmegen, Med Ctr, Dept Otorhinolaryngol, Nijmegen, Netherlands.; Boerrigter, M (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM merle.boerrigter@radboudumc.nl
RI Marres, H.A.M./H-8071-2014; Boerrigter, Merle S./E-4013-2016
OI Boerrigter, Merle S./0000-0003-4983-9336
FU Cochlear Benelux
FX This study was financially supported by Cochlear Benelux.
CR Aarnoutse C. A. J., 1988, PEDAGOG STUD, V65, P45
   Aarnoutse C. A. J., 1990, BEGRIJPEND LEESTEST
   Akeroyd MA, 2006, INT J AUDIOL, V45, pS25, DOI 10.1080/14992020600782626
   Bat-Chava Y, 2005, J CHILD PSYCHOL PSYC, V46, P1287, DOI 10.1111/j.1469-7610.2005.01426.x
   Boons T, 2013, RES DEV DISABIL, V34, P3833, DOI 10.1016/j.ridd.2013.07.033
   Boons T, 2013, RES DEV DISABIL, V34, P2008, DOI 10.1016/j.ridd.2013.03.003
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Calderon R., 2003, OXFORD HDB DEAF STUD, P177
   Cambra C, 1996, AM ANN DEAF, V141, P24, DOI 10.1353/aad.2012.0007
   Chilosi AM, 2013, EAR HEARING, V34, pE28, DOI 10.1097/AUD.0b013e31827ad687
   de Graaf R, 2002, PSYCHOSOM MED, V64, P61, DOI 10.1097/00006842-200201000-00009
   De Jong P.F., 2002, SCI STUD READ, V6, P51, DOI [DOI 10.1207/S1532799XSSR0601_03, 10.1207/S1532799XSSR0601_03]
   De Raeve L, 2015, AUDIOL NEURO-OTOL, V20, P261, DOI 10.1159/000381003
   De Raeve L, 2010, OTOL NEUROTOL, V31, P1261, DOI 10.1097/MAO.0b013e3181f1cde3
   Denham SA, 2009, J EPIDEMIOL COMMUN H, V63, pI37, DOI 10.1136/jech.2007.070797
   duFeu M., 2014, MENTAL HLTH DEAFNESS
   Dunn LM, 2005, PEABODY PICTURE VOCA
   Durkin K, 2010, CHILD LANG TEACH THE, V26, P107, DOI 10.1177/0265659010368750
   Filipo R, 1999, INT J PEDIATR OTORHI, V49, pS183
   Geers AE, 2013, EAR HEARING, V34, P562, DOI 10.1097/AUD.0b013e31828d2bd6
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   HINDLEY PA, 1994, J CHILD PSYCHOL PSYC, V35, P917, DOI 10.1111/j.1469-7610.1994.tb02302.x
   Holwell A, 2011, ADV PSYCHIAT TREATME, V17, P54, DOI DOI 10.1192/APT.BP.109.006718
   Huber M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00953
   Im-Bolter N, 2007, PEDIATR CLIN N AM, V54, P525, DOI 10.1016/j.pcl.2007.02.008
   Jacobs E, 2016, RES DEV DISABIL, V58, P104, DOI 10.1016/j.ridd.2016.08.016
   Ketelaar L, 2015, EUR CHILD ADOLES PSY, V24, P1369, DOI 10.1007/s00787-015-0688-2
   Ketelaar L, 2013, LARYNGOSCOPE, V123, P518, DOI 10.1002/lary.23544
   Kluwin T. N., 2002, J DEAF STUD DEAF EDU, V7, P200, DOI DOI 10.1093/DEAFED/7.3.200
   Kral A, 2010, NEW ENGL J MED, V363, P1438, DOI 10.1056/NEJMra0911225
   Lovett RES, 2010, ARCH DIS CHILD, V95, P107, DOI 10.1136/adc.2009.160325
   LUTEIJN F, 2005, NPV J JUNIOR NEDERLA
   Marschark M, 1996, READING COMPREHENSION DIFFICULTIES, P279
   Mitchell Ross, 2004, SIGN LANGUAGE STUDIE, V4, P138, DOI DOI 10.1353/SLS.2004.0005
   Nasralla H. R., 2009, INT ARCH OTORHINOLAR, V13, P400
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Norbury CF, 2001, J SPEECH LANG HEAR R, V44, P165, DOI 10.1044/1092-4388(2001/015)
   Percy-Smith L, 2008, INT J PEDIATR OTORHI, V72, P1113, DOI 10.1016/j.ijporl.2008.03.028
   Pinquart M, 2014, AM ANN DEAF, V159, P257, DOI 10.1353/aad.2014.0023
   Polat F., 2003, J DEAF STUD DEAF EDU, V8, P325, DOI [10.1093/deafed/eng018, DOI 10.1093/DEAFED/ENG018]
   Roberts BW, 2000, PSYCHOL BULL, V126, P3, DOI 10.1037/0033-2909.126.1.3
   Sarant J, 2014, EAR HEARING, V35, P396, DOI 10.1097/AUD.0000000000000022
   Sawyer SM, 2012, LANCET, V379, P1630, DOI 10.1016/S0140-6736(12)60072-5
   Sparreboom M, 2015, RES DEV DISABIL, V36, P328, DOI 10.1016/j.ridd.2014.10.030
   Sparreboom M, 2012, INT J PEDIATR OTORHI, V76, P339, DOI 10.1016/j.ijporl.2011.12.004
   Stevenson J, 2010, J CHILD PSYCHOL PSYC, V51, P77, DOI 10.1111/j.1469-7610.2009.02124.x
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Theunissen SCPM, 2014, EUR CHILD ADOLES PSY, V23, P187, DOI 10.1007/s00787-013-0444-4
   Toppelberg CO, 2000, J AM ACAD CHILD PSY, V39, P143, DOI 10.1097/00004583-200002000-00011
   Vaccari C, 1997, J CHILD PSYCHOL PSYC, V38, P793, DOI 10.1111/j.1469-7610.1997.tb01597.x
   Van Eldik T, 2004, AM ANN DEAF, V148, P390, DOI 10.1353/aad.2004.0002
   van Gent T, 2012, J DEAF STUD DEAF EDU, V17, P333, DOI 10.1093/deafed/ens002
   van Gent T, 2011, J CHILD PSYCHOL PSYC, V52, P720, DOI 10.1111/j.1469-7610.2011.02392.x
   Vermeulen AM, 2007, J DEAF STUD DEAF EDU, V12, P283, DOI 10.1093/deafed/enm017
   Wheeler A, 2007, J DEAF STUD DEAF EDU, V12, P303, DOI 10.1093/deafed/enm018
   Wiefferink CH, 2012, INT J PEDIATR OTORHI, V76, P883, DOI 10.1016/j.ijporl.2012.02.065
   Yew SGK, 2013, J CHILD PSYCHOL PSYC, V54, P516, DOI 10.1111/jcpp.12009
NR 57
TC 1
Z9 1
U1 0
U2 8
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 20
PY 2018
VL 9
AR 161
DI 10.3389/fpsyg.2018.00161
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA FW7XA
UT WOS:000425539700001
PM 29515485
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Tryfon, A
   Foster, NEV
   Sharda, M
   Hyde, KL
AF Tryfon, Ana
   Foster, Nicholas E. V.
   Sharda, Megha
   Hyde, Krista L.
TI Speech perception in autism spectrum disorder: An activation likelihood
   estimation meta-analysis
SO BEHAVIOURAL BRAIN RESEARCH
LA English
DT Article
DE Autism spectrum disorder; Activation likelihood estimation; Speech
   perception; Functional magnetic resonance imaging (fMRI)
ID LANGUAGE; CHILDREN; COMPREHENSION; VOICE; FMRI; ADOLESCENTS; PROSODY;
   CORTEX; CONNECTIVITY; PATTERNS
AB Autism spectrum disorder (ASD) is often characterized by atypical language profiles and auditory and speech processing. These can contribute to aberrant language and social communication skills in ASD. The study of the neural basis of speech perception in ASD can serve as a potential neurobiological marker of ASD early on, but mixed results across studies renders it difficult to find a reliable neural characterization of speech processing in ASD. To this aim, the present study examined the functional neural basis of speech perception in ASD versus typical development (TD) using an activation likelihood estimation (ALE) meta-analysis of 18 qualifying studies. The present study included separate analyses for TD and ASD, which allowed us to examine patterns of within group brain activation as well as both common and distinct patterns of brain activation across the ASD and TD groups. Overall, ASD and TD showed mostly common brain activation of speech processing in bilateral superior temporal gyrus (STG) and left inferior frontal gyms (IFG). However, the results revealed trends for some distinct activation in the TD group showing additional activation in higher-order brain areas including left superior frontal gyrus (SFG), left medial frontal gyrus (MFG), and right IFG. These results provide a more reliable neural characterization of speech processing in ASD relative to previous single neuroimaging studies and motivate future work to investigate how these brain signatures relate to behavioral measures of speech processing in ASD.
C1 [Tryfon, Ana; Foster, Nicholas E. V.; Sharda, Megha; Hyde, Krista L.] Univ Montreal, Int Lab Brain Mus & Sound Res BRAMS, Dept Psychol, Pavillon 1420 Mt Royal,CP 6128,Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.
   [Tryfon, Ana; Hyde, Krista L.] McGill Univ, Fac Med, McIntyre Med Bldg,3655 Sir William Osler, Montreal, PQ H3G 1Y6, Canada.
RP Tryfon, A (corresponding author), Univ Montreal, Int Lab Brain Mus & Sound Res BRAMS, Dept Psychol, Pavillon 1420 Mt Royal,CP 6128,Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.
EM ana.tryfon@mail.mcgill.ca
OI Foster, Nicholas/0000-0002-5406-3109
FU CIHRCanadian Institutes of Health Research (CIHR)
FX The authors would like to thank CIHR for providing funding support for
   this study. There are no conflicts of interest to declare.
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Anderson JS, 2010, AM J NEURORADIOL, V31, P131, DOI 10.3174/ajnr.A1789
   Beaucousin V, 2007, CEREB CORTEX, V17, P339, DOI 10.1093/cercor/bhj151
   Binder JR, 2008, EPILEPSIA, V49, P1980, DOI 10.1111/j.1528-1167.2008.01683.x
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Blasi A, 2015, CORTEX, V71, P122, DOI 10.1016/j.cortex.2015.06.015
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Colich NL, 2012, METAPHOR SYMBOL, V27, P70, DOI 10.1080/10926488.2012.638856
   Dapretto M, 2006, NAT NEUROSCI, V9, P28, DOI 10.1038/nn1611
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Doyle-Thomas Krissy A R, 2013, Front Psychiatry, V4, P48, DOI 10.3389/fpsyt.2013.00048
   Eickhoff SB, 2012, NEUROIMAGE, V59, P2349, DOI 10.1016/j.neuroimage.2011.09.017
   Eickhoff SB, 2011, NEUROIMAGE, V57, P938, DOI 10.1016/j.neuroimage.2011.05.021
   Eickhoff SB, 2009, HUM BRAIN MAPP, V30, P2907, DOI 10.1002/hbm.20718
   Eigsti IM, 2012, CHILD NEUROPSYCHOL, V18, P600, DOI 10.1080/09297049.2011.639757
   Eyler LT, 2012, BRAIN, V135, P949, DOI 10.1093/brain/awr364
   Gebauer L, 2014, NEUROIMAGE-CLIN, V6, P370, DOI 10.1016/j.nicl.2014.08.025
   Gervais H, 2004, NAT NEUROSCI, V7, P801, DOI 10.1038/nn1291
   Groen WB, 2010, CEREB CORTEX, V20, P1937, DOI 10.1093/cercor/bhp264
   Herringshaw AJ, 2016, AUTISM RES, V9, P1046, DOI 10.1002/aur.1599
   Hesling I, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011571
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok Gregory, 2015, Handb Clin Neurol, V129, P149, DOI 10.1016/B978-0-444-62630-1.00008-1
   Hubbard AL, 2012, BRAIN BEHAV, V2, P606, DOI 10.1002/brb3.81
   Hugdahl K, 2003, BRAIN LANG, V85, P37, DOI 10.1016/S0093-934X(02)00500-X
   Jochaut D, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3339/fnhum.2015.00171, 10.3389/fnhum.2015.00171]
   Just MA, 2004, BRAIN, V127, P1811, DOI 10.1093/brain/awh199
   LaCroix AN, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01138
   Lai G, 2012, BRAIN, V135, P961, DOI 10.1093/brain/awr335
   Laird AR, 2005, HUM BRAIN MAPP, V25, P155, DOI 10.1002/hbm.20136
   Lancaster JL, 2007, HUM BRAIN MAPP, V28, P1194, DOI 10.1002/hbm.20345
   Lattner S, 2005, HUM BRAIN MAPP, V24, P11, DOI 10.1002/hbm.20065
   Merrill J, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00076
   Mody M, 2013, NEUROPSYCHIATRY-LOND, V3, P223, DOI 10.2217/NPY.13.19
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1371/journal.pmed.1000097, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535]
   Muller RA, 1999, J AUTISM DEV DISORD, V29, P19, DOI 10.1023/A:1025914515203
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008
   Otsuka Y, 2009, NEUROSCI LETT, V463, P150, DOI 10.1016/j.neulet.2009.07.064
   Pochon JB, 2001, CEREB CORTEX, V11, P260, DOI 10.1093/cercor/11.3.260
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Raemaekers M, 2007, NEUROIMAGE, V36, P532, DOI 10.1016/j.neuroimage.2007.03.061
   Rapin I, 2003, BRAIN DEV-JPN, V25, P166, DOI 10.1016/S0387-7604(02)00191-2
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Redcay E, 2008, BIOL PSYCHIAT, V64, P589, DOI 10.1016/j.biopsych.2008.05.020
   Samson F, 2015, J PSYCHIATR RES, V68, P285, DOI 10.1016/j.jpsychires.2015.05.011
   Schelinski S, 2016, SOC COGN AFFECT NEUR, V11, P1812, DOI 10.1093/scan/nsw089
   Schulte-Ruther M, 2008, NEUROIMAGE, V42, P393, DOI 10.1016/j.neuroimage.2008.04.180
   Sharda M, 2015, AUTISM RES, V8, P174, DOI 10.1002/aur.1437
   Sperdin HF, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00393
   Tesink CMJY, 2011, NEUROPSYCHOLOGIA, V49, P1095, DOI 10.1016/j.neuropsychologia.2011.01.018
   Turkeltaub PE, 2002, NEUROIMAGE, V16, P765, DOI 10.1006/nimg.2002.1131
   Turkeltaub PE, 2012, HUM BRAIN MAPP, V33, P1, DOI 10.1002/hbm.21186
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   Wang AT, 2007, ARCH GEN PSYCHIAT, V64, P698, DOI 10.1001/archpsyc.64.6.698
   Wang AT, 2006, BRAIN, V129, P932, DOI 10.1093/brain/awl032
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Zhang LJ, 2010, HUM BRAIN MAPP, V31, P1106, DOI 10.1002/hbm.20922
NR 58
TC 11
Z9 11
U1 3
U2 66
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0166-4328
EI 1872-7549
J9 BEHAV BRAIN RES
JI Behav. Brain Res.
PD FEB 15
PY 2018
VL 338
BP 118
EP 127
DI 10.1016/j.bbr.2017.10.025
PG 10
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA FQ2VW
UT WOS:000418217100015
PM 29074403
DA 2021-02-24
ER

PT J
AU Shahin, AJ
   Backer, KC
   Rosenblum, LD
   Kerlin, JR
AF Shahin, Antoine J.
   Backer, Kristina C.
   Rosenblum, Lawrence D.
   Kerlin, Jess R.
TI Neural Mechanisms Underlying Cross-Modal Phonetic Encoding
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE audiovisual integration; auditory evoked potentials; cross-modal
   perception; McGurk illusion; speech perception
ID SUPERIOR TEMPORAL SULCUS; SPEECH-PERCEPTION; AUDITORY-CORTEX;
   VISUAL-SPEECH; MULTISENSORY INTEGRATION; ELECTROPHYSIOLOGICAL EVIDENCE;
   AUDIOVISUAL PERCEPTION; EVOKED-RESPONSE; TALKING FACES; ACTIVATION
AB Audiovisual (AV) integration is essential for speech comprehension, especially in adverse listening situations. Divergent, but not mutually exclusive, theories have been proposed to explain the neural mechanisms underlying AV integration. One theory advocates that this process occurs via interactions between the auditory and visual cortices, as opposed to fusion of AV percepts in a multisensory integrator. Building upon this idea, we proposed that AV integration in spoken language reflects visually induced weighting of phonetic representations at the auditory cortex. EEG was recorded while male and female human subjects watched and listened to videos of a speaker uttering consonant vowel (CV) syllables /ba/ and /fa/, presented in Auditory-only, AV congruent or incongruent contexts. Subjects reported whether they heard /ba/ or /fa/. We hypothesized that vision alters phonetic encoding by dynamically weighting which phonetic representation in the auditory cortex is strengthened or weakened. That is, when subjects are presented with visual /fa/ and acoustic /ba/ and hear /fa/(illusion-fa), the visual input strengthens the weighting of the phone /f/ representation. When subjects are presented with visual /ba/ and acoustic /fa/ and hear /ba/(illusion-ba), the visual input weakens the weighting of the phone /f/ representation. Indeed, we found an enlarged N1 auditory evoked potential when subjects perceived illusion-ba, and a reduced N1 when they perceived illusion-fa, mirroring the N1 behavior for /ba/ and /fa/ in Auditory-only settings. These effects were especially pronounced in individuals with more robust illusory perception. These findings provide evidence that visual speech modifies phonetic encoding at the auditory cortex.
C1 [Shahin, Antoine J.; Backer, Kristina C.; Kerlin, Jess R.] Univ Calif Davis, Ctr Mind & Brain, 267 Cousteau Pl, Davis, CA 95618 USA.
   [Rosenblum, Lawrence D.] Univ Calif Riverside, Dept Psychol, Riverside, CA 92521 USA.
RP Shahin, AJ (corresponding author), Univ Calif Davis, Ctr Mind & Brain, 267 Cousteau Pl, Davis, CA 95618 USA.
EM ajshahin@ucdavis.edu
FU National Institute of Health/National Institute on Deafness and Other
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01-DC013543];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC013543, R01DC013543, R01DC013543,
   R01DC013543, R01DC013543, R01DC013543] Funding Source: NIH RePORTER
FX This work was supported by National Institute of Health/National
   Institute on Deafness and Other Communication Disorders Grant
   R01-DC013543 to A.J.S. The original data for this study can be accessed
   at https://data.mendeley.com/datasets/yydw84284f/1. We thank Hannah
   Shatzer and Dr. Mark Pitt for providing the audiovisual stimuli.
CR Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Alsius A, 2013, PSYCHOL SCI, V24, P423, DOI 10.1177/0956797612457378
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Baart M, 2015, J MEM LANG, V85, P42, DOI 10.1016/j.jml.2015.06.008
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Bernstein LE, 2002, NEUROREPORT, V13, P311, DOI 10.1097/00001756-200203040-00013
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Besle J, 2008, J NEUROSCI, V28, P14301, DOI 10.1523/JNEUROSCI.2875-08.2008
   Bhat J, 2015, J NEUROPHYSIOL, V113, P1437, DOI 10.1152/jn.00200.2014
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Blank H, 2013, NEUROIMAGE, V65, P109, DOI 10.1016/j.neuroimage.2012.09.047
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Carpenter AL, 2013, NEUROSCI LETT, V544, P56, DOI 10.1016/j.neulet.2013.03.041
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Ghazanfar AA, 2005, J NEUROSCI, V25, P5004, DOI 10.1523/JNEUROSCI.0799-05.2005
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hall DA, 2005, J COGNITIVE NEUROSCI, V17, P939, DOI 10.1162/0898929054021175
   Hazan V, 2010, SPEECH COMMUN, V52, P996, DOI 10.1016/j.specom.2010.05.003
   Herrmann B, 2014, J NEUROSCI, V34, P327, DOI 10.1523/JNEUROSCI.3974-13.2014
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hocking J, 2008, CEREB CORTEX, V18, P2439, DOI 10.1093/cercor/bhn007
   Jones SJ, 1998, EVOKED POTENTIAL, V108, P131, DOI 10.1016/S0168-5597(97)00077-4
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   Kayser C, 2010, CURR BIOL, V20, P19, DOI 10.1016/j.cub.2009.10.068
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Molholm S, 2006, J NEUROPHYSIOL, V96, P721, DOI 10.1152/jn.00285.2006
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Okada K, 2013, PLOS ONE, V8, P1
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Ostroff JM, 1998, EAR HEARING, V19, P290, DOI 10.1097/00003446-199808000-00004
   Pearl D, 2009, COMPR PSYCHIAT, V50, P186, DOI 10.1016/j.comppsych.2008.06.004
   Pekkola J, 2005, NEUROREPORT, V16, P125, DOI 10.1097/00001756-200502080-00010
   Pereira O, 2016, J ACOUST SOC AM, V140, P3217
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Proverbio AM, 2016, SCI REP-UK, V6, DOI 10.1038/srep30423
   Romero YR, 2015, J NEUROPHYSIOL, V113, P2342, DOI 10.1152/jn.00783.2014
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Scherg M, 1989, J Cogn Neurosci, V1, P336, DOI 10.1162/jocn.1989.1.4.336
   Schroeder CE, 2005, CURR OPIN NEUROBIOL, V15, P454, DOI 10.1016/j.conb.2005.06.008
   Setti A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00575
   Shahin AJ, 2012, NEUROIMAGE, V60, P530, DOI 10.1016/j.neuroimage.2011.11.097
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Smith E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073148
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Venezia JH, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00174
   White TP, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00565
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
   Zouridakis G, 1998, BRAIN TOPOGR, V10, P183, DOI 10.1023/A:1022246825461
NR 64
TC 10
Z9 10
U1 1
U2 17
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
J9 J NEUROSCI
JI J. Neurosci.
PD FEB 14
PY 2018
VL 38
IS 7
BP 1835
EP 1849
DI 10.1523/JNEUROSCI.1566-17.2017
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA FW0LX
UT WOS:000424987700018
PM 29263241
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Earle, FS
   Landi, N
   Myers, EB
AF Earle, F. Sayako
   Landi, Nicole
   Myers, Emily B.
TI Adults with Specific Language Impairment fail to consolidate speech
   sounds during sleep
SO NEUROSCIENCE LETTERS
LA English
DT Article
DE Specific Language Impairment; Memory; Sleep; Speech perception; Event
   related potentials
ID KINDERGARTEN-CHILDREN; PERCEPTION; MEMORY; IDENTIFICATION; ACQUISITION;
   PERFORMANCE; DEFICIT; WORDS
AB Specific Language Impairment (SLI) is a common learning disability that is associated with poor speech sound representations. These differences in representational quality are thought to impose a burden on spoken language processing. The underlying mechanism to account for impoverished speech sound representations remains in debate. Previous findings that implicate sleep as important for building speech representations, combined with reports of atypical sleep in SLI, motivate the current investigation into a potential consolidation mechanism as a source of impoverished representations in SLI. In the current study, we trained individuals with SLI on a new (nonnative) set of speech sounds, and tracked their perceptual accuracy and neural responses to these sounds over two days. Adults with SLI achieved comparable performance to typical controls during training, however demonstrated a distinct lack of overnight gains on the next day. We propose that those with SLI may be impaired in the consolidation of acoustic-phonetic information.
C1 [Earle, F. Sayako; Myers, Emily B.] Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT USA.
   [Earle, F. Sayako] Univ Delaware, Commun Sci & Disorders Program, Newark, DE USA.
   [Landi, Nicole] Univ Connecticut, Dept Psychol, Storrs, CT USA.
   [Landi, Nicole; Myers, Emily B.] Haskins Labs Inc, New Haven, CT USA.
RP Earle, FS (corresponding author), Univ Delaware, STAR Hlth Sci Complex, 540 S Coll Ave,Ste 210BB, Newark, DE 19713 USA.
EM fsearle@udel.edu
RI landi, nicole/ABG-5374-2020; Landi, Nicole/P-2954-2014
OI /0000-0002-9475-764X; Landi, Nicole/0000-0003-2890-2519
FU NIH NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01 DC013064, F31 DC014194]; NIH
   NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [P01 HD001994];
   ASH Foundation scholarship; University of Connecticut; EUNICE KENNEDY
   SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child
   Health & Human Development (NICHD) [P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994] Funding Source: NIH RePORTER;
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH &HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC013064,
   R01DC013064, R01DC013064, F31DC014194, R01DC013064, R01DC013064,
   F31DC014194] Funding Source: NIH RePORTER
FX This work was supported by NIH NIDCD grants R01 DC013064 to EBM, F31
   DC014194 to FSE, and NIH NICHD grant P01 HD001994 (Rueckl, PI). FSE was
   supported by an ASH Foundation scholarship, and the Fund for Innovation
   in Science Education at the University of Connecticut. The content is
   the responsibility of the author and does not necessarily represent
   official views of our funding sources.
CR Adi-Japha E, 2014, AM J SPEECH-LANG PAT, V23, P696, DOI 10.1044/2014_AJSLP-13-0031
   Adi-Japha E, 2011, RES DEV DISABIL, V32, P2963, DOI 10.1016/j.ridd.2011.05.005
   Atienza M, 2004, J COGNITIVE NEUROSCI, V16, P53, DOI 10.1162/089892904322755557
   AUTRET A, 1992, J CHILD NEUROL, V7, P422, DOI 10.1177/088307389200700418
   BERNSTEIN LE, 1985, J SPEECH HEAR DISORD, V50, P21, DOI 10.1044/jshd.5001.21
   DENCKLA MB, 1976, NEUROPSYCHOLOGIA, V14, P471, DOI 10.1016/0028-3932(76)90075-0
   Dumay N, 2007, PSYCHOL SCI, V18, P35, DOI 10.1111/j.1467-9280.2007.01845.x
   Earle FS, 2017, NEUROSCI LETT, V636, P77, DOI 10.1016/j.neulet.2016.10.044
   Earle FS, 2015, J EXP PSYCHOL HUMAN, V41, P1680, DOI 10.1037/xhp0000113
   Earle FS, 2015, J ACOUST SOC AM, V137, pEL91, DOI 10.1121/1.4903918
   Fidler LJ, 2011, AM J SPEECH-LANG PAT, V20, P2, DOI 10.1044/1058-0360(2010/09-0096)
   Gallinat E, 2014, J SPEECH LANG HEAR R, V57, P1363, DOI 10.1044/2014_JSLHR-L-12-0363
   Gomez RL, 2006, PSYCHOL SCI, V17, P670, DOI 10.1111/j.1467-9280.2006.01764.x
   Gomez RL, 2011, SLEEP MED CLIN, V6, P45, DOI 10.1016/j.jsmc.2010.12.002
   Gottselig JM, 2004, LEARN MEMORY, V11, P162, DOI 10.1101/lm.63304
   Hedenius M, 2011, RES DEV DISABIL, V32, P2362, DOI 10.1016/j.ridd.2011.07.026
   JASP Team, 2017, JASP VERS 0 8 4
   Joanisse MF, 1998, TRENDS COGN SCI, V2, P240, DOI 10.1016/S1364-6613(98)01186-3
   Joanisse MF, 2003, BRAIN LANG, V86, P40, DOI 10.1016/S0093-934X(02)00533-3
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Leonard LB, 1997, J SPEECH LANG HEAR R, V40, P741, DOI 10.1044/jslhr.4004.741
   MacMillan NA, 1991, DETECTION THEORY USE
   MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419
   McGregor K, 2017, INT J SPEECH-LANG PA, V19, P43, DOI 10.3109/17549507.2016.1159337
   McGregor KK, 2013, J SPEECH LANG HEAR R, V56, P1845, DOI 10.1044/1092-4388(2013/12-0233)
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Picard A, 1998, DEV MED CHILD NEUROL, V40, P595
   Poll GH, 2015, J COMMUN DISORD, V53, P84, DOI 10.1016/j.jcomdis.2015.01.004
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Roth R.M., 2005, BRIEF BEHAV RATING I
   Sallinen M, 1996, J SLEEP RES, V5, P220, DOI 10.1111/j.1365-2869.1996.00220.x
   Shambroom JR, 2012, J SLEEP RES, V21, P221, DOI 10.1111/j.1365-2869.2011.00944.x
   Stark RE, 1996, J SPEECH HEAR RES, V39, P676, DOI 10.1044/jshr.3904.676
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Torgesen J, 1999, TEST WORD READING EF
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Tucker MA, 2008, SLEEP, V31, P197, DOI 10.1093/sleep/31.2.197
   Wechsler D, 1999, WASI WECHSLER ABBREV
   Wechsler D., 2008, WECHSLER ADULT INTEL
   Wolf M., 2005, RAPID AUTOMATIZED NA
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
NR 41
TC 9
Z9 10
U1 2
U2 6
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0304-3940
EI 1872-7972
J9 NEUROSCI LETT
JI Neurosci. Lett.
PD FEB 14
PY 2018
VL 666
BP 58
EP 63
DI 10.1016/j.neulet.2017.12.030
PG 6
WC Neurosciences
SC Neurosciences & Neurology
GA FX6ZB
UT WOS:000426234700011
PM 29253604
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Higy, B
   Mereta, A
   Metta, G
   Badino, L
AF Higy, Bertrand
   Mereta, Alessio
   Metta, Giorgio
   Badino, Leonardo
TI Speech Recognition for the iCub Platform
SO FRONTIERS IN ROBOTICS AND AI
LA English
DT Article
DE automatic speech recognition; yarp; tensorflow; code: python; code:
   matlab; code: C++
AB This paper describes open source software (available at https://github.com/robotology/natural-speech) to build automatic speech recognition (ASR) systems and run them within the YARP platform. The toolkit is designed (i) to allow non-ASR experts to easily create their own ASR system and run it on iCub and (ii) to build deep learning-based models specifically addressing the main challenges an ASR system faces in the context of verbal human-iCub interactions. The toolkit mostly consists of Python, C++ code and shell scripts integrated in YARP. As additional contribution, a second codebase (written in Matlab) is provided for more expert ASR users who want to experiment with bio-inspired and developmental learning-inspired ASR systems. Specifically, we provide code for two distinct kinds of speech recognition: "articulatory" and "unsupervised" speech recognition. The first is largely inspired by influential neurobiological theories of speech perception which assume speech perception to be mediated by brain motor cortex activities. Our articulatory systems have been shown to outperform strong deep learning-based baselines. The second type of recognition systems, the "unsupervised" systems, do not use any supervised information (contrary to most ASR systems, including our articulatory systems). To some extent, they mimic an infant who has to discover the basic speech units of a language by herself. In addition, we provide resources consisting of pre-trained deep learning models for ASR, and a 2.5-h speech dataset of spoken commands, the VoCub dataset, which can be used to adapt an ASR system to the typical acoustic environments in which iCub operates.
C1 [Higy, Bertrand; Metta, Giorgio] Ist Italiano Tecnol, ICub Facil, Genoa, Italy.
   [Higy, Bertrand] Univ Genoa, Genoa, Italy.
   [Mereta, Alessio] European Space Agcy, Adv Concepts Team, Noordwijk, Netherlands.
   [Badino, Leonardo] Ist Italiano Tecnol, Ctr Translat Neurophysiol Speech & Commun, Ferrara, Italy.
RP Badino, L (corresponding author), Ist Italiano Tecnol, Ctr Translat Neurophysiol Speech & Commun, Ferrara, Italy.
EM leonardo.badino@iit.it
FU European Commission project POETICON++European CommissionEuropean
   Commission Joint Research Centre [288382]; ECOMODE [644096]
FX The authors acknowledge the support of the European Commission project
   POETICON++ (grant agreement No. 288382) and ECOMODE (grant agreement No.
   644096).
CR Abadi M.AgarwalA.BarhamP.BrevdoE.ChenZ.CitroC.CorradoG.S.DavisA.DeanJ.DevinM.GhemawatS.GoodfellowI.HarpA.IrvingG.IsardM.JiaY.JozefowiczR.KaiserL.KudlurM.LevenbergJ.ManePRIME, 2015, ARXIV160304467
   Badino L., 2012, P IEEE SLT MIAM FL
   Badino L., 2015, P INT
   Badino L., 2016, P INT
   Badino L., 2014, P IEEE ICASSP FLOR I
   Badino L, 2016, COMPUT SPEECH LANG, V36, P173, DOI 10.1016/j.csl.2015.05.005
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Garofolo J, 1993, CSR 1 WSJ0 COMPLETE
   Garofolo J. S., 1993, NASA STI RECON TECHN, V93
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Lungarella M, 2003, CONNECT SCI, V15, P151, DOI 10.1080/09540090310001655110
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Richmond K., 2011, P INT FLOR IT
   Seltzer Michael, 2013, P ICASSP
   Versteegh M., 2015, P INT
   Vertanen K., 2006, TECHNICAL REPORT
   Vincent E, 2017, COMPUT SPEECH LANG, V46, P535, DOI 10.1016/j.csl.2016.11.005
   WOODLAND PC, 1994, INT CONF ACOUST SPEE, P125
   Young S., 2015, HTK BOOK HTK VERSION
NR 20
TC 0
Z9 0
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-9144
J9 FRONT ROBOT AI
JI Front. Robot. AI
PD FEB 12
PY 2018
VL 5
AR 10
DI 10.3389/frobt.2018.00010
PG 6
WC Robotics
SC Robotics
GA FV8AX
UT WOS:000424808300001
PM 33500897
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Balari, S
   Lorenzo, G
AF Balari, Sergio
   Lorenzo, Guillermo
TI The internal, the external and the hybrid: The state of the art and a
   new characterization of language as a natural object
SO GLOSSA-A JOURNAL OF GENERAL LINGUISTICS
LA English
DT Article
DE I-Language; E-Language; developmental hybrids; language development;
   Biolinguistics
ID SPEECH-PERCEPTION; ACQUISITION; INNATENESS; EVOLUTION; CHILDREN;
   FACULTY; TRANSMISSION; GRAMMAR; SYNTAX; BRAIN
AB The state of the art of the debate between externalist and internalist concepts of language is reviewed in this paper, and a new conceptualization of language as a "developmental hybrid" is suggested that entails that it equally comprises environmental and organism-internal component pieces, in an ultimately non dissociable way. The key for understanding this hybrid status is to be found in development, for when individually evolving, a general dynamic is observed in which organism-internal facilities selectively apply to certain designated aspects of the environmental stimulus, which in their turn have a facilitatory impact on these very same facilities. These kinds of loops inspire the conclusion that the internal and the external compose a single, integrated developmental unit.
C1 [Balari, Sergio] Univ Autonoma Barcelona, Edifici B, E-08193 Barcelona, Spain.
   [Lorenzo, Guillermo] Univ Oviedo, Campus Humanidades, E-33011 Oviedo, Spain.
RP Lorenzo, G (corresponding author), Univ Oviedo, Campus Humanidades, E-33011 Oviedo, Spain.
EM glorenzo@uniovi.es
RI Balari, Sergio/N-8703-2019
OI Balari, Sergio/0000-0002-2531-2161
FU grant of the Generalitat de CatalunyaGeneralitat de Catalunya
   [2014-SGR-1013]; grant of the Spanish Government [FFI2017-87699-P]
FX This paper has benefitted from a grant of the Generalitat de Catalunya
   (2014-SGR-1013) to the Centre de Linguistica Teorica (Universitat
   Autonoma de Barcelona) (SB) and a grant of the Spanish Government
   (FFI2017-87699-P) (SB and GL).
CR Anderson Stephen R., 2002, LANGUAGE ORGAN LINGU, DOI [10.1017/CBO9780511613869, DOI 10.1017/CB09780511613869]
   Asoulin E, 2016, GLOSSA, V1, DOI 10.5334/gjgl.34
   Baker M., 2001, ATOMS LANGUAGE MINDS
   Baker Mark, 2015, CASE ITS PRINCIPLES, DOI [10.1017/CBO9781107295186, DOI 10.1017/CBO9781107295186]
   Balari S, 2015, BIOLINGUISTICS, V9, P8
   Balari Sergio, 2015, Biology Theory, V10, P60, DOI 10.1007/s13752-014-0180-0
   Balari Sergio, 2013, COMPUTATIONAL PHENOT, DOI [10.1093/acprof:oso/9780199665464.001.0001, DOI 10.1093/ACPR0F:0S0/9780199665464.001.0001]
   Barany Andras, 2015, THESIS
   Barlow Michael, 1988, AGREEMENT NATURAL LA
   Bates E, 1999, CARN S COGN, P29
   Bateson P., 2011, PLASTICITY ROBUSTNES, DOI [10.1017/CBO9780511842382, DOI 10.1017/CBO9780511842382]
   Bedore LM, 2001, J SPEECH LANG HEAR R, V44, P905, DOI 10.1044/1092-4388(2001/072)
   Berwick RC, 2016, WHY ONLY US: LANGUAGE AND EVOLUTION, P1
   Biberauer T., 2017, CAMBRIDGE HDB HIST S, P134, DOI DOI 10.1017/9781107279070.008
   Bickerton D., 2014, MORE NATURE NEEDS LA, DOI [10.4159/9780674728523, DOI 10.4159/9780674728523]
   Blake Barry J., 1994, CASE, DOI [10.1017/CBO9781139164894, DOI 10.1017/CB09781139164894]
   Bloom P., 2000, CHILDREN LEARN MEANI
   Bloomfield L., 1933, LANGUAGE
   Boeckx C., 2012, LANGUAGE BIOL POINT, P23
   Boeckx C, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01324
   Boeckx C, 2014, TEOREMA, V33, P83
   Boeckx Cedric, 2012, CAMBRIDGE HDB BIOLIN
   Bolhuis JJ, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001934
   Borer H., 1987, PARAMETER SETTING, P123, DOI [10.1007/978-94-009-3727-7_6, DOI 10.1007/978-94-009-3727-7_6]
   Bortolini U, 1997, J SPEECH LANG HEAR R, V40, P809, DOI 10.1044/jslhr.4004.809
   Charbonneau M, 2015, BIOL PHILOS, V30, P527, DOI 10.1007/s10539-015-9487-x
   Charbonneau Mathieu, 2016, EVOLUTIONARY DEV BIO, DOI [10.1007/978-3-319-33038-9_47-1, DOI 10.1007/978-3-319-33038-9_]
   Chierchia G, 1998, STUD LINGUIST PHILOS, V70, P53
   Chomsky N, 2005, LINGUIST INQ, V36, P1, DOI 10.1162/0024389052993655
   CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334
   CHOMSKY N, 1967, SYNTHESE, V17, P2, DOI 10.1007/BF00485013
   Chomsky N., 1986, KNOWLEDGE LANGUAGE I
   Chomsky N., 2004, CARTOGRAPHY SYNTACTI, V3, P104
   Chomsky N., 1995, MINIMALIST PROGRAM
   Chomsky N., 1975, REFLECTIONS LANGUAGE
   Chomsky N., 2002, NATURE LANGUAGE, DOI [10.1017/CBO9780511613876, DOI 10.1017/CB09780511613876]
   Chomsky N., 1968, LANG MIND, DOI [10.1037/e400082009-004, DOI 10.1037/E400082009-004]
   Chomsky N, 2007, INT J PHILOS STUD, V15, P1, DOI 10.1080/09672550601143078
   Chomsky N, 2017, PSYCHON B REV, V24, P200, DOI 10.3758/s13423-016-1078-6
   Chomsky N, 2013, LINGUA, V130, P33, DOI 10.1016/j.lingua.2012.12.003
   Chomsky N, 2007, STUD GENERAT GRAMM, V89, P1
   Chomsky Noam, 1980, RULES REPRESENTATION
   Chomsky Noam, 2017, GEN SYNT QUEST CROSS
   Chomsky Noam, 2016, WHAT KING CREATUERS
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Chomsky Noam, 2010, EVOLUTION LANGUAGE B, P13, DOI [10.1017/CBO9780511817755.003, DOI 10.1017/CB09780511817755.003]
   Chomsky Noam, 2000, STEP STEP, P69
   Christa G, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2013.2493
   Christiansen MH, 2016, CREATING LANGUAGE: INTEGRATING EVOLUTION, ACQUISITION, AND PROCESSING, P1
   Christiansen MH, 2008, BEHAV BRAIN SCI, V31, P489, DOI 10.1017/S0140525X08004998
   Christiansen Morten H., 2015, COGNITIVE NEUROSCIEN, P675
   Clahsen H, 1997, J NEUROLINGUIST, V10, P151, DOI 10.1016/S0911-6044(97)00006-7
   CLAHSEN H, 1986, LINGUISTICS, V24, P79, DOI 10.1515/ling.1986.24.1.79
   Clahsen H, 1997, INHERITANCE INNATENE, P141
   Clahsen Harald, 1992, ACQUISITION VERB PLA, P181
   Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096
   Clark A., 1997, BEING THERE PUTTING
   Corbett GG, 2009, AGREEMENT
   Cornips Leonie, 2005, SYNTAX VARIATION REC, DOI [10.1075/cilt.265, DOI 10.1075/CILT.265]
   CRAIN S, 1987, LANGUAGE, V63, P522, DOI 10.2307/415004
   Craver Carl F., 2013, SEARCH MECH DISCOVER, DOI [10.7208/chi-cago/9780226039824.001.0001, DOI 10.7208/CHI-CAG0/9780226039824.001.0001]
   Croft W., 2004, COGN LINGUIST, DOI [10.1017/CBO9780511803864, DOI 10.1017/CBO9780511803864]
   Danchin E, 2011, NAT REV GENET, V12, P475, DOI 10.1038/nrg3028
   de Saussure Ferdinand, 1916, COURS LINGUISTIQUE G
   Deacon T., 1997, SYMBOLIC SPECIES COE
   Dehaene S, 2015, NEURON, V88, P2, DOI 10.1016/j.neuron.2015.09.019
   Dove G, 2012, BIOL PHILOS, V27, P615, DOI 10.1007/s10539-012-9324-4
   Dummet Michael, 1989, REFLECTIONS CHOMSKY, P191
   Durkheim E., 1894, REGLES METHODE SOCIO
   Edelman GM, 2001, P NATL ACAD SCI USA, V98, P13763, DOI 10.1073/pnas.231499798
   Embick David, 2007, OXFORD HDB LINGUISTI, P289, DOI DOI 10.1093/OXFORDHB/9780199247455.013.0010
   Epstein SD, 2016, BIOLINGUISTICS, V10, P197
   Fitch W. T., 2011, BIOLINGUISTIC ENTERP, P135
   Fodor J., 1983, MODULARITY MIND
   Fodor J.A., 1981, REPRESENTATIONS PHIL
   Fodor JA., 1998, CONCEPTS COGNITIVE S, DOI [10.1093/0198236360.001.0001, DOI 10.1093/0198236360.001.0001]
   Gallistel C. R., 2000, COGNITIVE NEUROSCIEN, P1179
   Gallistel Charles R., 2010, CHOMSKY NOTEBOOK, P19, DOI [10.7312/bric14474-009, DOI 10.7312/BRIC14474-009]
   Gervain J, 2012, J COGNITIVE NEUROSCI, V24, P564, DOI 10.1162/jocn_a_00157
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Gottlieb G., 1992, INDIVIDUAL DEV EVOLU
   Griesemer J, 2014, TOWARDS A THEORY OF DEVELOPMENT, P183
   Griesemer JR, 2014, VIENNA SER THEOR BIO, P23
   Griffiths PE, 1998, PHILOS SCI, V65, P253, DOI 10.1086/392636
   Guasti M. T., 2002, LANGUAGE ACQUISITION
   Halle M., 1993, VIEW BUILDING 20 ESS, P111
   Hamann C, 2006, CATALAN J LINGUIST, V5, P143
   Hauser MD, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00401
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Hawkins J. A., 1994, PERFORMANCE THEORY O
   Hawkins John A., 2004, EFFICIENCY COMPLEXIT, DOI [10.1093/acprof:oso/9780199252695.001.0001, DOI 10.1093/ACPR0F:0S0/9780199252695.001.0001]
   Hirsh-Pasek K, 1996, ORIGINS GRAMMAR EVID
   Hornstein Norbert, 2005, UNDERSTANDING MINIMA, DOI [10.1017/CBO9780511840678, DOI 10.1017/CB09780511840678]
   Hyams Nina, 1986, LANG ACQUIS, DOI [10.1007/978-94-009-4638-5, DOI 10.1007/978-94-009-4638-5]
   Jackendoff R, 2005, COGNITION, V97, P211, DOI 10.1016/j.cognition.2005.04.006
   Jackendoff R., 2010, EVOLUTION HUMAN LANG, P63, DOI DOI 10.1017/CB09780511817755.004
   Katz Jerrold J., 1981, LANGUAGE OTHER ABSTR
   Kirby S, 2007, P NATL ACAD SCI USA, V104, P5241, DOI 10.1073/pnas.0608222104
   Knudsen EI, 2004, J COGNITIVE NEUROSCI, V16, P1412, DOI 10.1162/0898929042304796
   Koster J, 2009, BIOLINGUISTICS, V3, P61
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Labov W, 2007, LANGUAGE, V83, P344, DOI 10.1353/lan.2007.0082
   Lashley K. S., 1951, CEREBRAL MECH BEHAV, P112, DOI DOI 10.1093/RFS/HHQ153
   Lassiter D, 2010, BIOLINGUISTICS, V4, P138
   Lau Joe, 2016, STANFORD ENCY PHILOS
   Lewis D., 1975, MINNESOTA STUDIES PH, P3
   Lightfoot D., 1999, DEV LANGUAGE ACQUISI
   Locke JL, 1997, BRAIN LANG, V58, P265, DOI 10.1006/brln.1997.1791
   LOCKE JOHN L., 1993, CHILDS PATH SPOKEN L
   Lohndal T, 2009, BIOLINGUISTICS, V3, P321
   Longa Victor M., 2012, LANGUAGE BIOL POINT, P52
   Gonzalez GL, 2013, TEOREMA, V32, P29
   Lorenzo G, 2009, LINGUA, V119, P1300, DOI 10.1016/j.lingua.2009.02.003
   Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77
   Mehler J., 1974, LUNITE DE LHOMME, P25
   MICHEL GF, 1995, DEV PSYCHOBIOLOGY AN
   MILLS AE, 1985, CROSSLINGUISTIC STUD, V1, P141
   Minelli Alessandro, 2003, DEV ANIMAL FORM, DOI [10.1017/CBO9780511541476, DOI 10.1017/CB09780511541476]
   Minelli Alessandro, 2014, THEORY DEV, DOI [10.1093/acprof:oso/9780199671427.001.0001, DOI 10.1093/ACPR0F:0S0/9780199671427.001.0001]
   Nevins A, 2011, NAT LANG LINGUIST TH, V29, P939, DOI 10.1007/s11049-011-9150-4
   Oppenheim R.W., 1981, MATURATION DEV BIOL, P73
   Oppenheim Ronald W., 1984, CONTINUITY NEURAL FU, P16
   Oyama S., 2000, EVOLUTIONS EYE SYSTE, DOI [10.1215/9780822380658, DOI 10.1215/9780822380658]
   PIAGET J, 1962, B MENNINGER CLIN, V26, P120
   Pinker S, 2005, COGNITION, V95, P201, DOI 10.1016/j.cognition.2004.08.004
   Poeppel D, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P103
   Preminger O, 2014, AGREEMENT ITS FAILUR, DOI [10.7551/mitpress/9780262027403.001.0001, DOI 10.7551/MITPRESS/9780262027403.001.0001]
   PUTNAM H, 1967, SYNTHESE, V17, P12, DOI 10.1007/BF00485014
   QUINE WV, 1970, SYNTHESE, V21, P386, DOI 10.1007/BF00484806
   Ramchand Gillian, 2008, LIMITS SYNTACTIC VAR, P219, DOI [10.1075/la.132.08ram, DOI 10.1075/LA.132.08RAM]
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Robert J. S., 2004, EMBRYOLOGY EPIGENESI, DOI [10.1017/CB09780511498541, DOI 10.1017/CB09780511498541]
   Rossello Joana, 2016, BIOLINGUISTIC INVEST, P55, DOI [10.1075/la.235.03ros, DOI 10.1075/LA.235.03R0S]
   Rumpho ME, 2011, J EXP BIOL, V214, P303, DOI 10.1242/jeb.046540
   Rupert Robert D., 2009, COGNITIVE SYSTEMS EX, DOI [10.1093/acprof:oso/9780195379457.001.0001, DOI 10.1093/ACPR0F:0S0/9780195379457.001.0001]
   Simon HA., 1996, SCI ARTIFICIAL, V3
   Skinner B. F., 1957, VERBAL BEHAV, DOI [10.1037/11256-000, DOI 10.1037/11256-000]
   SOAMES S, 1984, LINGUIST PHILOS, V7, P155, DOI 10.1007/BF00630811
   Sultan SE, 2015, ORGANISM AND ENVIRONMENT: ECOLOGICAL DEVELOPMENT, NICHE CONSTRUCTION, AND ADAPTATION, P1
   Tallerman M., 2012, OXFORD HDB LANGUAGE, P1, DOI DOI 10.1093/0XF0RDHB/9780199541119.013.0001
   TOMASELLO M, 2001, CULTURAL ORIGINS HUM
   Trettenbrein Patrick C, 2015, Front Psychol, V6, P1507, DOI 10.3389/fpsyg.2015.01507
   Ullman M. T., 2001, BILING-LANG COGN, V4, P105, DOI DOI 10.1017/S1366728901000220
   van der Lely HKJ, 2003, LANGUAGE, V79, P153, DOI 10.1353/lan.2003.0089
   Vares E., 2017, THESIS
   VYGOTSKY LS, 1986, THOUGHT LANGUAGE
   Waddington C., 1957, STRATEGY GENES
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   WEXLER K, 1990, DEV PSYCHOBIOL, V23, P645, DOI 10.1002/dev.420230708
   Wiltschko M, 2008, NAT LANG LINGUIST TH, V26, P639, DOI 10.1007/s11049-008-9046-0
   Wimsatt W. C., 1986, INTEGRATING SCI DISC, P185, DOI DOI 10.1007/978-94-010-9435-1_
   Yang C. D., 2002, KNOWLEDGE LEARNING N
NR 153
TC 4
Z9 5
U1 0
U2 2
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 2397-1835
J9 GLOSSA-UK
JI Glossa
PD FEB 8
PY 2018
VL 3
IS 1
AR 22
DI 10.5334/gjgl.330
PG 33
WC Linguistics; Language & Linguistics
SC Linguistics
GA GC2PW
UT WOS:000429626100003
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Simeon, KM
   Bicknell, K
   Grieco-Calub, TM
AF Simeon, Katherine M.
   Bicknell, Klinton
   Grieco-Calub, Tina M.
TI Belief Shift or Only Facilitation: How Semantic Expectancy Affects
   Processing of Speech Degraded by Background Noise
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE semantic expectancy; ideal observer; lexical processing; speech
   perception; background noise
ID ACOUSTIC DISTORTION; COMPLETION NORMS; WORD RECOGNITION; SPOKEN
   LANGUAGE; CONTEXT; INFORMATION; YOUNGER; PERCEPTION
AB Individuals use semantic expectancy - applying conceptual and linguistic knowledge to speech input - to improve the accuracy and speed of language comprehension. This study tested how adults use semantic expectancy in quiet and in the presence of speech-shaped broadband noise at 7 and 12 dB signal-to-noise ratio. Twenty-four adults (22.1 +/- 3.6 years, mean +/- SD) were tested on a four-alternative-forced-choice task whereby they listened to sentences and were instructed to select an image matching the sentence-final word. The semantic expectancy of the sentences was unrelated to (neutral), congruent with, or conflicting with the acoustic target. Congruent expectancy improved accuracy and conflicting expectancy decreased accuracy relative to neutral, consistent with a theory where expectancy shifts beliefs toward likely words and away from unlikely words. Additionally, there were no significant interactions of expectancy and noise level when analyzed in log-odds, supporting the predictions of ideal observer models of speech perception.
C1 [Simeon, Katherine M.; Grieco-Calub, Tina M.] Northwestern Univ, Roxelyn & Richard Pepper Dept Commun Sci & Disord, Evanston, IL 60208 USA.
   [Bicknell, Klinton] Northwestern Univ, Dept Linguist, Evanston, IL USA.
   [Grieco-Calub, Tina M.] Northwestern Univ, Hugh Knowles Hearing Ctr, Evanston, IL USA.
RP Simeon, KM (corresponding author), Northwestern Univ, Roxelyn & Richard Pepper Dept Commun Sci & Disord, Evanston, IL 60208 USA.
EM ksimeon@u.northwestern.edu
OI Simeon, Katherine/0000-0002-0170-5585
CR Aydelott J, 2006, PSYCHOPHYSIOLOGY, V43, P454, DOI 10.1111/j.1469-8986.2006.00448.x
   Bates D., 2015, LME4 LINEAR MIXED EF
   Benichov J, 2012, EAR HEARING, V33, P262, DOI 10.1097/AUD.0b013e31822f680f
   Bicknell K, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X15000734
   Block CK, 2010, BEHAV RES METHODS, V42, P665, DOI 10.3758/BRM.42.3.665
   BLOOM PA, 1980, MEM COGNITION, V8, P631, DOI 10.3758/BF03213783
   Borsky S, 1998, J ACOUST SOC AM, V103, P2670, DOI 10.1121/1.422787
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   CONNINE CM, 1987, J MEM LANG, V26, P527, DOI 10.1016/0749-596X(87)90138-0
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   DUFFY SA, 1989, J EXP PSYCHOL LEARN, V15, P791, DOI 10.1037/0278-7393.15.5.791
   Fallon M, 2002, J ACOUST SOC AM, V111, P2242, DOI 10.1121/1.1466873
   Ferreira VS, 2003, PSYCHOL SCI, V14, P86, DOI 10.1111/1467-9280.01424
   Goy H, 2013, J SPEECH LANG HEAR R, V56, P1715, DOI 10.1044/1092-4388(2013/12-0053)
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x
   Lash A, 2013, EXP AGING RES, V39, P235, DOI 10.1080/0361073X.2013.779175
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2016, EAR HEARING, V37, pe37, DOI 10.1097/AUD.0000000000000207
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   MILLER JL, 1984, PERCEPT PSYCHOPHYS, V36, P329, DOI 10.3758/BF03202785
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   R Core Team, 2016, R LANG ENV STAT COMP
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rigler H, 2015, DEV PSYCHOL, V51, P1690, DOI 10.1037/dev0000044
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, TRENDS AMPLIF, V15, P140, DOI 10.1177/1084713811409762
   Rosenberg H, 2014, J INT NEUROPSYCH SOC, V20, P994, DOI 10.1017/S1355617714000940
   Sheldon S, 2008, J ACOUST SOC AM, V123, P489, DOI 10.1121/1.2783762
   Smiljanic R, 2013, J SPEECH LANG HEAR R, V56, P1085, DOI 10.1044/1092-4388(2012/12-0097)
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
NR 35
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 8
PY 2018
VL 9
AR 116
DI 10.3389/fpsyg.2018.00116
PG 10
WC Psychology, Multidisciplinary
SC Psychology
GA FV3QQ
UT WOS:000424484000001
PM 29472883
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zoefel, B
   Archer-Boyd, A
   Davis, MH
AF Zoefel, Benedikt
   Archer-Boyd, Alan
   Davis, Matthew H.
TI Phase Entrainment of Brain Oscillations Causally Modulates Neural
   Responses to Intelligible Speech
SO CURRENT BIOLOGY
LA English
DT Article
ID DIRECT-CURRENT STIMULATION; ALTERNATING-CURRENT STIMULATION;
   TRANSCRANIAL DIRECT; NEURONAL OSCILLATIONS; CORTICAL OSCILLATIONS;
   PERCEPTUAL CENTERS; ELECTRIC-FIELD; FREQUENCY; COMPREHENSION; INCREASE
AB Due to their periodic nature, neural oscillations might represent an optimal "tool'' for the processing of rhythmic stimulus input [1-3]. Indeed, the alignment of neural oscillations to a rhythmic stimulus, often termed phase entrainment, has been repeatedly demonstrated [4-7]. Phase entrainment is central to current theories of speech processing [8-10] and has been associated with successful speech comprehension [11-17]. However, typical manipulations that reduce speech intelligibility (e.g., addition of noise and time reversal [11, 12, 14, 16, 17]) could destroy critical acoustic cues for entrainment (such as "acoustic edges'' [7]). Hence, the association between phase entrainment and speech intelligibility might only be "epiphenomenal''; i.e., both decline due to the same manipulation, without any causal link between the two [18]. Here, we use transcranial alternating current stimulation (tACS [19]) to manipulate the phase lag between neural oscillations and speech rhythm while measuring neural responses to intelligible and unintelligible vocoded stimuli with sparse fMRI. We found that this manipulation significantly modulates the BOLD response to intelligible speech in the superior temporal gyrus, and the strength of BOLD modulation is correlated with a phasic modulation of performance in a behavioral task. Importantly, these findings are absent for unintelligible speech and during sham stimulation; we thus demonstrate that phase entrainment has a specific, causal influence on neural responses to intelligible speech. Our results not only provide an important step toward understanding the neural foundation of human abilities at speech comprehension but also suggest new methods for enhancing speech perception that can be explored in the future.
C1 [Zoefel, Benedikt; Archer-Boyd, Alan; Davis, Matthew H.] Univ Cambridge, MRC Cognit & Brain Sci Unit, 15 Chaucer Rd, Cambridge CB2 7EF, England.
RP Zoefel, B (corresponding author), Univ Cambridge, MRC Cognit & Brain Sci Unit, 15 Chaucer Rd, Cambridge CB2 7EF, England.
EM benedikt.zoefel@mrc-cbu.cam.ac.uk
OI Davis, Matt/0000-0003-2239-0778
FU German Academic Exchange Service (DAAD)Deutscher Akademischer Austausch
   Dienst (DAAD); Medical Research Council UKUK Research & Innovation
   (UKRI)Medical Research Council UK (MRC) [SUAG/008/RG91365]; Medical
   Research CouncilUK Research & Innovation (UKRI)Medical Research Council
   UK (MRC) [MC_UU_00005/5] Funding Source: researchfish
FX This work was supported by the German Academic Exchange Service (DAAD)
   and the Medical Research Council UK (grant number SUAG/008/RG91365). The
   authors thank Gary Chandler and Johan Carlin for technical support;
   Flavio Frohlich, Rufin VanRullen, Malte Wostmann, Charlie Schroeder, and
   Peter Lakatos for fruitful discussions; and Christoph Herrmann for
   helpful comments on the manuscript.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Ali MM, 2013, J NEUROSCI, V33, P11262, DOI 10.1523/JNEUROSCI.5867-12.2013
   Andersson JLR, 2001, NEUROIMAGE, V13, P903, DOI 10.1006/nimg.2001.0746
   Antal A, 2014, NEUROIMAGE, V85, P1040, DOI 10.1016/j.neuroimage.2012.10.026
   Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bosker HR, 2017, INTERSPEECH, P2416, DOI 10.21437/Interspeech.2017-73
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Busch NA, 2009, J NEUROSCI, V29, P7869, DOI 10.1523/JNEUROSCI.0113-09.2009
   Calderone DJ, 2014, TRENDS COGN SCI, V18, P300, DOI 10.1016/j.tics.2014.02.005
   Capilla A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014543
   Cousineau D, 2005, TUTOR QUANT METHODS, V1, P42, DOI 10.20982/tqmp.01.1.p042
   Cusack R, 2015, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00090
   Davis M.H., 2016, NEUROBIOLOGY LANGUAG, P541
   Davis MH, 2003, J NEUROSCI, V23, P3423
   de Berker AO, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00613
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   FOWLER CA, 1979, PERCEPT PSYCHOPHYS, V25, P375, DOI 10.3758/BF03199846
   Frohlich F, 2015, PROG BRAIN RES, V222, P41, DOI 10.1016/bs.pbr.2015.07.025
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Heimrath K, 2016, BMC NEUROSCI, V17, DOI 10.1186/s12868-016-0241-3
   Herrmann CS, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00279
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   Ho KA, 2016, BRAIN STIMUL, V9, P1, DOI 10.1016/j.brs.2015.08.003
   Jackson MP, 2016, CLIN NEUROPHYSIOL, V127, P3425, DOI 10.1016/j.clinph.2016.08.016
   Keitel C, 2014, J NEUROSCI, V34, P10137, DOI 10.1523/JNEUROSCI.1904-14.2014
   Krause B, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00025
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Logothetis NK, 2002, PHILOS T R SOC B, V357, P1003, DOI 10.1098/rstb.2002.1114
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Macmillan N, 2004, DETECTION THEORY USE
   Moliadze V, 2010, CLIN NEUROPHYSIOL, V121, P2165, DOI 10.1016/j.clinph.2010.04.033
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405
   Neuling T, 2012, NEUROIMAGE, V63, P771, DOI 10.1016/j.neuroimage.2012.07.024
   Neuling T, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00161
   Nitsche MA, 2007, J NEUROPHYSIOL, V97, P3109, DOI 10.1152/jn.01312.2006
   Opitz A, 2015, NEUROIMAGE, V109, P140, DOI 10.1016/j.neuroimage.2015.01.033
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Parkin BL, 2015, NEURON, V87, P932, DOI 10.1016/j.neuron.2015.07.032
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Penny W., 2006, STAT PARAMETRIC MAPP
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Rampersad SM, 2014, IEEE T NEUR SYS REH, V22, P441, DOI 10.1109/TNSRE.2014.2308997
   Ress D, 2003, NAT NEUROSCI, V6, P414, DOI 10.1038/nn1024
   Riecke L, 2015, BRAIN STIMUL, V8, P777, DOI 10.1016/j.brs.2015.04.004
   Sadaghiani S, 2009, J NEUROSCI, V29, P13410, DOI 10.1523/JNEUROSCI.2592-09.2009
   Saturnino GB, 2015, NEUROIMAGE, V120, P25, DOI 10.1016/j.neuroimage.2015.06.067
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   ten Oever S, 2015, P NATL ACAD SCI USA, V112, P15833, DOI 10.1073/pnas.1517519112
   Underwood E, 2016, SCIENCE, V352, P397, DOI 10.1126/science.352.6284.397
   VanRullen R, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0214
   Veniero D, 2015, FRONT CELL NEUROSCI, V9, DOI 10.3389/fncel.2015.00477
   Vossen A, 2015, BRAIN STIMUL, V8, P499, DOI 10.1016/j.brs.2014.12.004
   Vosskuhl J, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00257
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Woods AJ, 2016, CLIN NEUROPHYSIOL, V127, P1031, DOI 10.1016/j.clinph.2015.11.012
   Zoefel B, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00296
   Zoefel B, 2017, LANG COGN NEUROSCI, V32, P910, DOI 10.1080/23273798.2016.1247970
   Zoefel B, 2017, NEUROIMAGE, V150, P344, DOI 10.1016/j.neuroimage.2017.02.014
   Zoefel B, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00651, 10.1038/NATURE11020]
   Zoefel B, 2015, J NEUROSCI, V35, P1954, DOI 10.1523/JNEUROSCI.3484-14.2015
NR 70
TC 43
Z9 43
U1 0
U2 8
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD FEB 5
PY 2018
VL 28
IS 3
BP 401
EP +
DI 10.1016/j.cub.2017.11.071
PG 13
WC Biochemistry & Molecular Biology; Biology; Cell Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA FU8AX
UT WOS:000424075300023
PM 29358073
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hallam, GP
   Thompson, HE
   Hymers, M
   Millman, RE
   Rodd, JM
   Ralph, MAL
   Smallwood, J
   Jefferies, E
AF Hallam, Glyn P.
   Thompson, Hannah E.
   Hymers, Mark
   Millman, Rebecca E.
   Rodd, Jennifer M.
   Ralph, Matthew A. Lambon
   Smallwood, Jonathan
   Jefferies, Elizabeth
TI Task-based and resting-state fMRI reveal compensatory network changes
   following damage to left inferior frontal gyrus
SO CORTEX
LA English
DT Article
DE Semantic control; fMRI; Resting-state connectivity; Sentence processing;
   Functional compensation
ID MIDDLE TEMPORAL GYRUS; VENTROLATERAL PREFRONTAL CORTEX; SEMANTIC
   COGNITION; STROKE APHASIA; ANGULAR GYRUS; DISTRIBUTED NETWORK;
   CONVERGING EVIDENCE; WERNICKES APHASIA; NEURAL MECHANISMS;
   SPEECH-PERCEPTION
AB Damage to left inferior prefrontal cortex in stroke aphasia is associated with semantic deficits reflecting poor control over conceptual retrieval, as opposed to loss of knowledge. However, little is known about how functional recruitment within the semantic network changes in patients with executive-semantic deficits. The current study acquired functional magnetic resonance imaging (fMRI) data from 14 patients with semantic aphasia, who had difficulty with flexible semantic retrieval following left prefrontal damage, and 16 healthy age-matched controls, allowing us to examine activation and connectivity in the semantic network. We examined neural activity while participants listened to spoken sentences that varied in their levels of lexical ambiguity and during rest. We found group differences in two regions thought to be good candidates for functional compensation: ventral anterior temporal lobe (vATL), which is strongly implicated in comprehension, and posterior middle temporal gyrus (pMTG), which is hypothesized to work together with left inferior prefrontal cortex to support controlled aspects of semantic retrieval. The patients recruited both of these sites more than controls in response to meaningful sentences. Subsequent analysis identified that, in control participants, the recruitment of pMTG to ambiguous sentences was inversely related to functional coupling between pMTG and anterior superior temporal gyrus (aSTG) at rest, while the patients showed the opposite pattern. Moreover, stronger connectivity between pMTG and aSTG in patients was associated with better performance on a test of verbal semantic association, suggesting that this temporal lobe connection supports comprehension in the face of damage to left inferior prefrontal cortex. These results characterize network changes in patients with executive-semantic deficits and converge with studies of healthy participants in providing evidence for a distributed system underpinning semantic control that includes pMTG in addition to left inferior prefrontal cortex. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Hallam, Glyn P.; Hymers, Mark; Smallwood, Jonathan; Jefferies, Elizabeth] Univ York, Dept Psychol, York, N Yorkshire, England.
   [Hallam, Glyn P.; Hymers, Mark; Smallwood, Jonathan; Jefferies, Elizabeth] Univ York, York Neuroirnaging Ctr, York, N Yorkshire, England.
   [Millman, Rebecca E.] Univ Manchester, Sch Hlth Sci, Manchester Ctr Audiol & Deafness, Fac Biol Med & Hlth, Manchester, Lancs, England.
   [Rodd, Jennifer M.] UCL, Dept Expt Psychol, London, England.
   [Ralph, Matthew A. Lambon] Univ Manchester, Sch Biol Sci, Div Neurosci & Expt Psychol, NARU, Manchester, Lancs, England.
   [Hallam, Glyn P.] Univ Huddersfield, Sch Human & Hlth Sci, Dept Psychol, Huddersfield, W Yorkshire, England.
   [Thompson, Hannah E.] Univ Surrey, Sch Psychol, Guildford, Surrey, England.
RP Hallam, GP (corresponding author), Univ Huddersfield, Sch Human & Hlth Sci, Dept Psychol, Huddersfield, W Yorkshire, England.
EM g.hallam@hud.ac.uk
RI Rodd, Jennifer M/F-2711-2011; Smallwood, Jonathan/ABE-8365-2020;
   Smallwood, Jonathan/AAF-4116-2019; Jefferies, Elizabeth/A-7981-2011
OI Rodd, Jennifer M/0000-0002-8608-7244; Smallwood,
   Jonathan/0000-0002-7298-2459; Hallam, Glyn Paul/0000-0002-8956-9054;
   Jefferies, Elizabeth/0000-0002-3826-4330; Millman,
   Rebecca/0000-0001-8606-0167
FU Stroke Association [TSA/12/02]; BBSRCUK Research & Innovation
   (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)
   [BB/J006963/1]; European Research CouncilEuropean Research Council
   (ERC)European Commission [SEMBIND - 283530, WANDERINGMINDS - 646927];
   MRC programmeUK Research & Innovation (UKRI)Medical Research Council UK
   (MRC) [MR/J0004146/1]
FX We thank the patients and their carers for their generous assistance
   with this study. GH was supported by a Stroke Association project grant
   (TSA/12/02). EJ was supported by grants from BBSRC (BB/J006963/1) and
   the European Research Council (SEMBIND - 283530), JS was supported by
   European Research Council (WANDERINGMINDS - 646927) and M.A.L by an MRC
   programme grant (MR/J0004146/1). Funders had no role in study design,
   collection, analysis and interpretation of data, writing the report, or
   decision to submit the article for publication.
CR Baayen R., 1995, CELEX2 LDC96L14
   Badre D, 2005, NEURON, V47, P907, DOI 10.1016/j.neuron.2005.07.023
   Beckmann CF, 2003, NEUROIMAGE, V20, P1052, DOI 10.1016/S1053-8119(03)00435-X
   Behzadi Y, 2007, NEUROIMAGE, V37, P90, DOI 10.1016/j.neuroimage.2007.04.042
   Berthier ML, 2001, APHASIOLOGY, V15, P99, DOI 10.1080/02687040042000179
   Binder J. R., 2011, NEUROIMAGE
   Binney RJ, 2010, CEREB CORTEX, V20, P2728, DOI 10.1093/cercor/bhq019
   Binney RJ, 2016, CEREBRAL CORTEX
   BLESSER B, 1972, J SPEECH HEAR RES, V15, P5, DOI 10.1044/jshr.1501.05
   Bozeat S, 2000, NEUROPSYCHOLOGIA, V38, P1207, DOI 10.1016/S0028-3932(00)00034-8
   Brownsett SLE, 2014, BRAIN, V137, P242, DOI 10.1093/brain/awt289
   Burgess P.W., 1997, HAYLING BRIXTON TEST
   Corbett F, 2011, J COGNITIVE NEUROSCI, V23, P1125, DOI 10.1162/jocn.2010.21539
   Crinion J., 2007, NEUROIMAGE
   Davey J, 2016, NEUROIMAGE, V137, P165, DOI 10.1016/j.neuroimage.2016.05.051
   Davey J, 2015, J NEUROSCI, V35, P15230, DOI 10.1523/JNEUROSCI.4705-14.2015
   Davey J, 2015, BRAIN LANG, V142, P24, DOI 10.1016/j.bandl.2015.01.002
   Devlin JT, 2000, NEUROIMAGE, V11, P589, DOI 10.1006/nimg.2000.0595
   Duncan J, 2010, TRENDS COGN SCI, V14, P172, DOI 10.1016/j.tics.2010.01.004
   Friedman L., 2006, NEUROIMAGE
   Friston KJ, 1998, NEUROIMAGE, V7, P30, DOI 10.1006/nimg.1997.0306
   Geranmayeh F, 2014, BRAIN, V137, P2632, DOI 10.1093/brain/awu163
   Gold BT, 2006, J NEUROSCI, V26, P6523, DOI 10.1523/JNEUROSCI.0808-06.2006
   Goodglass H., 1983, ASSESSMENT APHASIA R
   Gorgolewski KJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097176
   Hall D. A., 2000, MAGNETIC RESONANCE M
   Hallam GP, 2016, NEUROPSYCHOLOGIA, V93, P40, DOI 10.1016/j.neuropsychologia.2016.09.012
   Hoffman P, 2011, J COGNITIVE NEUROSCI, V23, P2432, DOI 10.1162/jocn.2011.21614
   Hoffman P, 2010, J NEUROSCI, V30, P15450, DOI 10.1523/JNEUROSCI.3783-10.2010
   Hymers M, 2015, NEUROIMAGE, V108, P225, DOI 10.1016/j.neuroimage.2014.12.010
   Jackson R. L., 2016, J NEUROSCIENCE
   Jefferies E, 2007, NEUROPSYCHOLOGIA, V45, P1065, DOI 10.1016/j.neuropsychologia.2006.09.009
   Jefferies E, 2006, BRAIN, V129, P2132, DOI 10.1093/brain/awl153
   Jefferies E, 2013, CORTEX, V49, P611, DOI 10.1016/j.cortex.2012.10.008
   Jefferies E, 2010, NEUROPSYCHOLOGIA, V48, P248, DOI 10.1016/j.neuropsychologia.2009.09.011
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   Jenkinson M, 2001, MED IMAGE ANAL, V5, P143, DOI 10.1016/S1361-8415(01)00036-6
   Jung J, 2016, CEREB CORTEX, V26, P3580, DOI 10.1093/cercor/bhw149
   Kay J., 1992, PSYCHOLINGUISTIC ASS
   Mueller K, 2011, NEUROIMAGE, V54, P337, DOI 10.1016/j.neuroimage.2010.08.029
   Murphy C., 2017, NEUROIMAGE
   Murphy K, 2009, NEUROIMAGE, V44, P893, DOI 10.1016/j.neuroimage.2008.09.036
   Nachev P, 2008, NEUROIMAGE, V39, P1215, DOI 10.1016/j.neuroimage.2007.10.002
   Noonan KA, 2013, J COGNITIVE NEUROSCI, V25, P1824, DOI 10.1162/jocn_a_00442
   Nooner KB, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00152
   Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277
   Pobric G, 2010, NEUROPSYCHOLOGIA, V48, P1336, DOI 10.1016/j.neuropsychologia.2009.12.036
   Price AR, 2015, J NEUROSCI, V35, P3276, DOI 10.1523/JNEUROSCI.3446-14.2015
   Ralph MAL, 2017, NAT REV NEUROSCI, V18, P42, DOI 10.1038/nrn.2016.150
   Ralph MAL, 2010, BRAIN, V133, P3243, DOI 10.1093/brain/awq264
   Raven J.C, 1962, COLOURED PROGR MATRI
   Robson H, 2014, BRAIN, V137, P931, DOI 10.1093/brain/awt373
   Rodd JM, 2015, BRAIN LANG, V141, P89, DOI 10.1016/j.bandl.2014.11.012
   Rodd JM, 2012, CEREB CORTEX, V22, P1761, DOI 10.1093/cercor/bhr252
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Rogers TT, 2015, NEUROPSYCHOLOGIA, V76, P220, DOI 10.1016/j.neuropsychologia.2015.04.015
   Rorden C, 2012, NEUROIMAGE, V61, P957, DOI 10.1016/j.neuroimage.2012.03.020
   Schwarzbauer C, 2006, NEUROIMAGE, V29, P774, DOI 10.1016/j.neuroimage.2005.08.025
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Smallwood J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152272
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Thompson HE, 2015, BRAIN, V138, P3776, DOI 10.1093/brain/awv281
   Thompson-Schill SL, 1997, P NATL ACAD SCI USA, V94, P14792, DOI 10.1073/pnas.94.26.14792
   Visser M., 2010, J COGNITIVE NEUROSCI
   Vitello S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00530
   Warrington EK, 1996, BRAIN, V119, P611, DOI 10.1093/brain/119.2.611
   Whitney C, 2011, CEREB CORTEX, V21, P1066, DOI 10.1093/cercor/bhq180
   Whitney C, 2011, CEREB CORTEX, V21, P831, DOI 10.1093/cercor/bhq148
   Woolrich MW, 2004, NEUROIMAGE, V21, P1732, DOI 10.1016/j.neuroimage.2003.12.023
   Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]
NR 70
TC 10
Z9 11
U1 0
U2 15
PU ELSEVIER MASSON, CORPORATION OFFICE
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD FEB
PY 2018
VL 99
BP 150
EP 165
DI 10.1016/j.cortex.2017.10.004
PG 16
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FW8FF
UT WOS:000425564100014
PM 29223933
OA Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Tranebjaerg, L
   Strenzke, N
   Lindholm, S
   Rendtorff, ND
   Poulsen, H
   Khandelia, H
   Kopec, W
   Lyngbye, TJB
   Hamel, C
   Delettre, C
   Bocquet, B
   Bille, M
   Owen, HH
   Bek, T
   Jensen, H
   Ostergaard, K
   Moller, C
   Luxon, L
   Carr, L
   Wilson, L
   Rajput, K
   Sirimanna, T
   Harrop-Griffiths, K
   Rahman, S
   Vona, B
   Doll, J
   Haaf, T
   Bartsch, O
   Rosewich, H
   Moser, T
   Bitner-Glindzicz, M
AF Tranebjaerg, Lisbeth
   Strenzke, Nicola
   Lindholm, Sture
   Rendtorff, Nanna D.
   Poulsen, Hanne
   Khandelia, Himanshu
   Kopec, Wojciech
   Lyngbye, Troels J. Brunnich
   Hamel, Christian
   Delettre, Cecile
   Bocquet, Beatrice
   Bille, Michael
   Owen, Hanne H.
   Bek, Toke
   Jensen, Hanne
   Ostergaard, Karen
   Moller, Claes
   Luxon, Linda
   Carr, Lucinda
   Wilson, Louise
   Rajput, Kaukab
   Sirimanna, Tony
   Harrop-Griffiths, Katherine
   Rahman, Shamima
   Vona, Barbara
   Doll, Julia
   Haaf, Thomas
   Bartsch, Oliver
   Rosewich, Hendrik
   Moser, Tobias
   Bitner-Glindzicz, Maria
TI The CAPOS mutation in ATP1A3 alters Na/K-ATPase function and results in
   auditory neuropathy which has implications for management
SO HUMAN GENETICS
LA English
DT Article
ID NA,K-ATPASE ALPHA-SUBUNIT; ALTERNATING HEMIPLEGIA; COCHLEAR
   IMPLANTATION; BETA-SUBUNIT; CEREBELLAR-ATAXIA; ISCEV STANDARD;
   NA+/K+-ATPASE; CHILDHOOD; ISOFORMS; PUMP
AB Cerebellar ataxia, areflexia, pes cavus, optic atrophy and sensorineural hearing impairment (CAPOS) is a rare clinically distinct syndrome caused by a single dominant missense mutation, c.2452G > A, p.Glu818Lys, in ATP1A3, encoding the neuron-specific alpha subunit of the Na+/K+-ATPase alpha 3. Allelic mutations cause the neurological diseases rapid dystonia Parkinsonism and alternating hemiplegia of childhood, disorders which do not encompass hearing or visual impairment. We present detailed clinical phenotypic information in 18 genetically confirmed patients from 11 families (10 previously unreported) from Denmark, Sweden, UK and Germany indicating a specific type of hearing impairment-auditory neuropathy (AN). All patients were clinically suspected of CAPOS and had hearing problems. In this retrospective analysis of audiological data, we show for the first time that cochlear outer hair cell activity was preserved as shown by the presence of otoacoustic emissions and cochlear microphonic potentials, but the auditory brainstem responses were grossly abnormal, likely reflecting neural dyssynchrony. Poor speech perception was observed, especially in noise, which was beyond the hearing level obtained in the pure tone audiograms in several of the patients presented here. Molecular modelling and in vitro electrophysiological studies of the specific CAPOS mutation were performed. Heterologous expression studies of alpha 3 with the p.Glu818Lys mutation affects sodium binding to, and release from, the sodium-specific site in the pump, the third ion-binding site. Molecular dynamics simulations confirm that the structure of the C-terminal region is affected. In conclusion, we demonstrate for the first time evidence for auditory neuropathy in CAPOS syndrome, which may reflect impaired propagation of electrical impulses along the spiral ganglion neurons. This has implications for diagnosis and patient management. Auditory neuropathy is difficult to treat with conventional hearing aids, but preliminary improvement in speech perception in some patients suggests that cochlear implantation may be effective in CAPOS patients.
C1 [Tranebjaerg, Lisbeth] Rigshosp, Bispebjerg, Dept Otorhinolaryngol Head & Neck Surg & Audiol, Copenhagen, Denmark.
   [Tranebjaerg, Lisbeth; Rendtorff, Nanna D.] Copenhagen Univ Hosp, Dept Clin Genet, Kennedy Ctr, Copenhagen, Denmark.
   [Tranebjaerg, Lisbeth; Bitner-Glindzicz, Maria] Univ Copenhagen, Inst Clin Med, Copenhagen, Denmark.
   [Strenzke, Nicola] Univ Med Ctr, Dept Otolaryngol, Auditory Syst Physiol Grp, InnerEarLab, Gottingen, Germany.
   [Lindholm, Sture] Cty Hosp Kalmar, ENT Dept, Kalmar, Sweden.
   [Poulsen, Hanne] Univ Aarhus, Inst Biomed, Aarhus, Denmark.
   [Khandelia, Himanshu; Kopec, Wojciech] Univ So Denmark, MEMPHYS, Ctr Biomembrane Phys, Odense, Denmark.
   [Kopec, Wojciech] Max Planck Inst Biophys Chem, Computat Biomol Dynam Grp, Gottingen, Germany.
   [Lyngbye, Troels J. Brunnich] Aarhus Univ Hosp, Pediat Dept, Aarhus, Denmark.
   [Hamel, Christian; Bocquet, Beatrice] CHRU, Malad Sensorielles Genet, Montpellier, France.
   [Hamel, Christian; Delettre, Cecile; Bocquet, Beatrice] Inst Neurosci Montpellier, INSERM, U1051, Montpellier, France.
   [Hamel, Christian; Bocquet, Beatrice] Univ Montpellier, Montpellier, France.
   [Bille, Michael] Rigshosp, Dept Otorhinolaryngol Head & Neck Surg & Audiol, Gentofte Hosp, Hellerup, Denmark.
   [Owen, Hanne H.] Aarhus Univ Hosp, Dept Audiol, Aarhus, Denmark.
   [Bek, Toke] Aarhus Univ Hosp, Dept Ophthalmol, Aarhus, Denmark.
   [Jensen, Hanne] Rigshosp, Glostrup Hosp, Kennedy Ctr, Eye Dept, Glostrup, Denmark.
   [Ostergaard, Karen] Aarhus Univ Hosp, Dept Neurol, Aarhus, Denmark.
   [Ostergaard, Karen] Univ Aarhus, Aarhus, Denmark.
   [Moller, Claes] Orebro Univ, Fac Med & Hlth, Audiol Res Ctr, Orebro, Sweden.
   [Luxon, Linda] Natl Hosp Neurol, Dept Neurotol, Queen Sq, London WC1N 3BG, England.
   [Carr, Lucinda] Great Ormond St Hosp Sick Children, Dept Neurol, London WC1N 3JH, England.
   [Wilson, Louise; Bitner-Glindzicz, Maria] Great Ormond St Hosp Sick Children, North East Thames Reg Genet Serv, London WC1N 3JH, England.
   [Rajput, Kaukab] Great Ormond St Hosp Sick Children, Cochlear Implant Dept, London WC1N 3JH, England.
   [Sirimanna, Tony] Great Ormond St Hosp Sick Children, Dept Audiovestibular Med, London WC1N 3JH, England.
   [Harrop-Griffiths, Katherine] Royal Natl Throat Nose & Ear Hosp, Nuffield Hearing & Speech Ctr, London WC1X 8DA, England.
   [Rahman, Shamima; Bitner-Glindzicz, Maria] Inst Child Hlth, UCL Great Ormond St, Genet & Genom Med Programme, London WC1N 1EH, England.
   [Vona, Barbara; Doll, Julia; Haaf, Thomas] Julius Maximilians Univ Wurzburg, Inst Human Genet, Wurzburg, Germany.
   [Bartsch, Oliver] Johannes Gutenberg Univ Mainz, Inst Human Genet, Univ Med Ctr, Langenbeckstr 1, Mainz, Germany.
   [Rosewich, Hendrik] Univ Med Ctr, Dept Pediat & Adolescent Med, Div Pediat Neurol, Gottingen, Germany.
   [Moser, Tobias] Univ Med Ctr, Inst Auditory Neurosci, Gottingen, Germany.
   [Moser, Tobias] Univ Med Ctr, InnerEarLab, Gottingen, Germany.
RP Tranebjaerg, L (corresponding author), Rigshosp, Bispebjerg, Dept Otorhinolaryngol Head & Neck Surg & Audiol, Copenhagen, Denmark.; Tranebjaerg, L (corresponding author), Copenhagen Univ Hosp, Dept Clin Genet, Kennedy Ctr, Copenhagen, Denmark.; Tranebjaerg, L (corresponding author), Univ Copenhagen, Inst Clin Med, Copenhagen, Denmark.; Bitner-Glindzicz, M (corresponding author), Great Ormond St Hosp Sick Children, North East Thames Reg Genet Serv, London WC1N 3JH, England.; Bitner-Glindzicz, M (corresponding author), Inst Child Hlth, UCL Great Ormond St, Genet & Genom Med Programme, London WC1N 1EH, England.
EM tranebjaerg@sund.ku.dk; maria.bitner@ucl.ac.uk
RI Rahman, Shamima/M-7904-2019; Moser, Tobias/L-5068-2014; Bocquet,
   Beatrice/AAY-8447-2020; Bartsch, Oliver/ABE-2681-2020; Delettre,
   Cecile/AAC-3096-2020; Rahman, Shamima/C-5232-2008; Vona,
   Barbara/H-7377-2019
OI Moser, Tobias/0000-0001-7145-0533; Bocquet,
   Beatrice/0000-0002-6369-4818; Delettre, Cecile/0000-0003-3269-2155;
   Rahman, Shamima/0000-0003-2088-730X; Vona, Barbara/0000-0002-6719-3447;
   Bek, Toke/0000-0002-0409-2534; Kopec, Wojciech/0000-0001-8801-9563;
   Khandelia, Himanshu/0000-0001-9913-6394
FU German Research Foundation through the Leibniz Program; Lundbeck
   FoundationLundbeckfonden [R248-2016-2518, R271-2017-666,
   R163-2013-16294, R82-2011-7280] Funding Source: researchfish
FX All research at Great Ormond Street Hospital NHS Foundation Trust and
   UCL Great Ormond Street Institute of Child Health is made possible by
   the NIHR Great Ormond Street Hospital Biomedical Research Centre. The
   views expressed are those of the author(s) and not necessarily those of
   the NHS, the NIHR or the Department of Health. TM is supported by the
   German Research Foundation through the Leibniz Program.
CR Attwell D, 2001, J CEREBR BLOOD F MET, V21, P1133, DOI 10.1097/00004647-200110000-00001
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Boothroyd A., 1968, AUDIOL BR J, V2, P3, DOI DOI 10.3109/00381796809075436
   Brand T, 2017, HNO, V65, P182, DOI 10.1007/s00106-016-0224-9
   CHILLA R, 1976, HNO, V24, P342
   Clausen MV, 2017, FRONT PHYSIOL, V8, DOI 10.3389/fphys.2017.00371
   Dard R, 2015, DEV MED CHILD NEUROL, V57, P1183, DOI 10.1111/dmcn.12927
   Demos MK, 2014, ORPHANET J RARE DIS, V9, DOI 10.1186/1750-1172-9-15
   ELBERLING C, 1989, SCAND AUDIOL, V18, P169, DOI 10.3109/01050398909070742
   Erichsen S, 1996, HEARING RES, V100, P143, DOI 10.1016/0378-5955(96)00105-0
   Geering K, 2005, J BIOENERG BIOMEMBR, V37, P387, DOI 10.1007/s10863-005-9476-x
   Giraudet F, 2012, CURR OPIN NEUROL, V25, P50, DOI 10.1097/WCO.0b013e32834f0351
   Han M, 2017, SCI REP-UK, V7, DOI 10.1038/srep39829
   Harrison RV, 2015, INT J PEDIATR OTORHI, V79, P1980, DOI 10.1016/j.ijporl.2015.10.006
   Heimer G, 2015, J CHILD NEUROL, V30, P1749, DOI 10.1177/0883073815579708
   Heinzen EL, 2014, LANCET NEUROL, V13, P503, DOI 10.1016/S1474-4422(14)70011-0
   Hilbers F, 2016, SCI REP-UK, V6, DOI 10.1038/srep20442
   Holmgren M, 2000, NATURE, V403, P898
   Jespersen T, 2002, BIOTECHNIQUES, V32, P536, DOI 10.2144/02323st05
   Kampfhaus RW, 2005, CLIN ASSESSMENT CHIL
   KEMP DT, 1978, J ACOUST SOC AM, V64, P1386, DOI 10.1121/1.382104
   Kopec W, 2014, BIOCHEMISTRY-US, V53, P746, DOI 10.1021/bi401425g
   Li CM, 2006, J MEMBRANE BIOL, V213, P1, DOI 10.1007/s00232-006-0035-0
   Maas RPPWM, 2016, PEDIATR NEUROL, V59, P71, DOI 10.1016/j.pediatrneurol.2016.02.010
   Mazzoli M., 2003, AUDIOL MED, V1, P148, DOI [10.1080/16513860301713, DOI 10.1080/16513860301713]
   MCGUIRT JP, 1994, J HISTOCHEM CYTOCHEM, V42, P843, DOI 10.1177/42.7.8014467
   McLean WJ, 2009, JARO-J ASSOC RES OTO, V10, P37, DOI 10.1007/s10162-008-0152-9
   Morth JP, 2017, NATURE, V450
   Moser T, 2016, NAT REV NEUROL, V12, P135, DOI 10.1038/nrneurol.2016.10
   Odom JV, 2016, DOC OPHTHALMOL, V133, P1, DOI 10.1007/s10633-016-9553-y
   Odom JV, 2010, DOC OPHTHALMOL, V120, P111, DOI 10.1007/s10633-009-9195-4
   Panagiotakaki E, 2015, ORPHANET J RARE DIS, V10, DOI 10.1186/s13023-015-0335-5
   Potic A, 2015, J NEUROL SCI, V358, P453, DOI 10.1016/j.jns.2015.10.002
   Poulsen H, 2010, NATURE, V467, P99, DOI 10.1038/nature09309
   PRICE EM, 1988, BIOCHEMISTRY-US, V27, P8400, DOI 10.1021/bi00422a016
   Rance G, 2015, BRAIN, V138, DOI 10.1093/brain/awv270
   Rodriguez-Ballesteros M, 2003, HUM MUTAT, V22, P451, DOI 10.1002/humu.10274
   Rosewich H, 2014, NEUROLOGY, V83, P861, DOI 10.1212/WNL.0000000000000735
   Rouillon I, 2006, INT J PEDIATR OTORHI, V70, P689, DOI 10.1016/j.ijporl.2005.09.006
   Santarelli R, 2015, BRAIN, V138, P563, DOI 10.1093/brain/awu378
   Schuth O, 2014, JARO-J ASSOC RES OTO, V15, P739, DOI 10.1007/s10162-014-0479-3
   Shinoda T, 2009, NATURE, V459, P446, DOI 10.1038/nature07939
   Starr A, 1998, EAR HEARING, V19, P169, DOI 10.1097/00003446-199806000-00001
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   Sweney MT, 2015, PEDIATR NEUROL, V52, P56, DOI 10.1016/j.pediatrneurol.2014.09.015
   Vedovato N, 2010, J GEN PHYSIOL, V136, P63, DOI 10.1085/jgp.201010407
   Viollet L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137370
   Viollet L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127045
   WATTS AG, 1991, P NATL ACAD SCI USA, V88, P7425, DOI 10.1073/pnas.88.16.7425
   Weigand KM, 2014, BBA-MOL BASIS DIS, V1842, P1010, DOI 10.1016/j.bbadis.2014.03.002
   Yaragatupalli S, 2009, P NATL ACAD SCI USA, V106, P15507, DOI 10.1073/pnas.0903752106
   Yu HB, 2011, NAT STRUCT MOL BIOL, V18, P1159, DOI 10.1038/nsmb.2113
   Zhang QJ, 2016, HEARING RES, V335, P53, DOI 10.1016/j.heares.2016.01.008
NR 53
TC 10
Z9 13
U1 1
U2 21
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0340-6717
EI 1432-1203
J9 HUM GENET
JI Hum. Genet.
PD FEB
PY 2018
VL 137
IS 2
BP 111
EP 127
DI 10.1007/s00439-017-1862-z
PG 17
WC Genetics & Heredity
SC Genetics & Heredity
GA FW2BA
UT WOS:000425104600001
PM 29305691
OA Green Published
DA 2021-02-24
ER

PT J
AU Ruan, YF
   Georgiou, GK
   Song, S
   Li, YX
   Shu, H
AF Ruan, Yufang
   Georgiou, George K.
   Song, Shuang
   Li, Yixun
   Shu, Hua
TI Does Writing System Influence the Associations Between Phonological
   Awareness, Morphological Awareness, and Reading? A Meta-Analysis
SO JOURNAL OF EDUCATIONAL PSYCHOLOGY
LA English
DT Article
DE phonological awareness; morphological awareness; reading; meta-analysis
ID KONG CHINESE CHILDREN; ENGLISH BILITERACY ACQUISITION; WORKING-MEMORY
   ARCHITECTURE; HONG-KONG; DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION; WORD
   RECOGNITION; VOCABULARY KNOWLEDGE; COGNITIVE PROFILES; LANGUAGE-SKILLS
AB Differences in how writing systems represent language raise important questions about the extent to which the role of linguistic skills such as phonological awareness (PA) and morphological awareness (MA) in reading is universal. In this meta-analysis, the authors examined the relationship between PA, MA, and reading (accuracy, fluency, and comprehension) in 2 languages (English and Chinese) representing different writing systems (alphabetic and logographic). A random-effects model analysis of data from 64 studies with native speakers of each language revealed significant correlations between PA, MA, and all reading outcomes in both languages. The correlations remained significant even after controlling for each other's effect on reading. However, PA was a stronger correlate of reading in English than in Chinese. MA was as good a correlate of reading in English as in Chinese (except for comprehension, where it was better). In addition, complex PA tasks in English and production/compounding MA tasks in Chinese produced significantly larger correlations with reading accuracy. Taken together, the findings of this meta-analysis suggest that PA and MA are significant correlates of reading, but their role is influenced by the writing system, the type of reading outcome, and the type of task used to operationalize PA and MA. The implications of these findings are discussed.
C1 [Ruan, Yufang; Song, Shuang; Shu, Hua] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing, Peoples R China.
   [Ruan, Yufang; Song, Shuang; Shu, Hua] Beijing Normal Univ, IDG McGovern Inst Brain Res, Beijing, Peoples R China.
   [Georgiou, George K.] Univ Alberta, Dept Educ Psychol, 6-102 Educ North, Edmonton, AB T6G 2G5, Canada.
   [Li, Yixun] Beijing Normal Univ, Beijing Key Lab Appl Expt Psychol, Sch Psychol, Beijing, Peoples R China.
RP Georgiou, GK (corresponding author), Univ Alberta, Dept Educ Psychol, 6-102 Educ North, Edmonton, AB T6G 2G5, Canada.
EM georgiou@ualberta.ca
RI Ruan, Yufang/AAN-5701-2020
OI Ruan, Yufang/0000-0002-2008-9036
FU National Key Basic Research Program of ChinaNational Basic Research
   Program of China [2014CB846103]; Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [31271082,
   31671126, 31611130107]; Beijing Municipal Science & Technology
   CommissionBeijing Municipal Science & Technology Commission
   [Z151100003915122]
FX This research was supported by the National Key Basic Research Program
   of China (2014CB846103), by the Natural Science Foundation of China
   (31271082, 31671126, 31611130107), and by the Beijing Municipal Science
   & Technology Commission (Z151100003915122). The authors would like to
   thank John Kirby and Peter Bowers for their valuable comments on an
   earlier draft of this manuscript.
CR Apel K, 2012, READ WRIT, V25, P1283, DOI 10.1007/s11145-011-9317-8
   Apel K, 2011, J SPEECH LANG HEAR R, V54, P1312, DOI 10.1044/1092-4388(2011/10-0115)
   Apel K, 2009, LANG SPEECH HEAR SER, V40, P312, DOI 10.1044/0161-1461(2009/08-0015)
   Berninger VW, 2006, SCI STUD READ, V10, P165, DOI 10.1207/s1532799xssr1002_3
   Berninger VW, 2008, DEV NEUROPSYCHOL, V33, P707, DOI 10.1080/87565640802418662
   Borenstein M., 2005, COMPREHENSIVE META A
   Bowers PN, 2010, REV EDUC RES, V80, P144, DOI 10.3102/0034654309359353
   Bowey JA, 2005, BL HBK DEV PSYCHOL, P155, DOI 10.1002/9780470757642.ch9
   Carlisle J. F., 1995, MORPHOLOGICAL ASPECT, P189, DOI DOI 10.4236/PSYCH.2014.58103
   CARLISLE JF, 1993, APPL PSYCHOLINGUIST, V14, P177, DOI 10.1017/S0142716400009541
   Carlisle JF, 2010, READ RES QUART, V45, P464, DOI 10.1598/RRQ.45.4.5
   Chao Y. R., 1976, ASPECTS CHINESE SOCI, V9
   Chen X, 2009, READ WRIT, V22, P615, DOI 10.1007/s11145-008-9127-9
   Cheung H, 2010, J EDUC PSYCHOL, V102, P367, DOI 10.1037/a0017850
   Chik PPM, 2012, READ WRIT, V25, P679, DOI 10.1007/s11145-010-9293-4
   Cho JR, 2011, SCI STUD READ, V15, P383, DOI 10.1080/10888438.2010.487143
   CHOMSKY C, 1970, HARVARD EDUC REV, V40, P287, DOI 10.17763/haer.40.2.y7u0242x76w05624
   Chow BWY, 2008, DEV PSYCHOL, V44, P233, DOI 10.1037/0012-1649.44.1.233
   Chow BWY, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016640
   Chung FHK, 2008, CLIN LINGUIST PHONET, V22, P379, DOI 10.1080/02699200701776757
   Chung KKH, 2008, ANN DYSLEXIA, V58, P15, DOI 10.1007/s11881-008-0015-4
   Chung KKH, 2011, J EDUC PSYCHOL, V103, P909, DOI 10.1037/a0024744
   Chung KKH, 2010, J LEARN DISABIL-US, V43, P195, DOI 10.1177/0022219409345018
   Cunningham AJ, 2015, APPL PSYCHOLINGUIST, V36, P509, DOI 10.1017/S0142716413000295
   Deacon S.H., 2008, SAGE HDB DYSLEXIA, P212, DOI DOI 10.4135/9780857020987.N11
   Deacon SH, 2007, DEV PSYCHOL, V43, P732, DOI 10.1037/0012-1649.43.3.732
   Deacon SH, 2013, DEV PSYCHOL, V49, P1113, DOI 10.1037/a0029474
   Deacon SH, 2012, J RES READ, V35, P456, DOI 10.1111/j.1467-9817.2010.01496.x
   Deacon SH, 2004, APPL PSYCHOLINGUIST, V25, P223, DOI 10.1017/S0142716404001110
   Duval S, 2000, BIOMETRICS, V56, P455, DOI 10.1111/j.0006-341X.2000.00455.x
   Ehri LC, 2005, SCI STUD READ, V9, P167, DOI 10.1207/s1532799xssr0902_4
   Ehri LC, 2001, READ RES QUART, V36, P250, DOI 10.1598/RRQ.36.3.2
   Farran LK, 2012, READ WRIT, V25, P2153, DOI 10.1007/s11145-011-9352-5
   Fraser J, 2008, INT J LANG COMM DIS, V43, P552, DOI 10.1080/13682820701778069
   Goodwin AP, 2010, ANN DYSLEXIA, V60, P183, DOI 10.1007/s11881-010-0041-x
   Grigorakis I., 2014, THESIS
   Newman EH, 2011, J EXP CHILD PSYCHOL, V108, P242, DOI 10.1016/j.jecp.2010.09.001
   Hanley JR, 2005, BL HBK DEV PSYCHOL, P316, DOI 10.1002/9780470757642.ch17
   Hedges L. V., 2014, STAT METHODS METAANA
   Ho CSH, 2014, READ WRIT, V27, P1673, DOI 10.1007/s11145-014-9515-2
   Ho CSH, 2011, DYSLEXIA, V17, P143, DOI 10.1002/dys.429
   Ho CSH, 1997, DEV PSYCHOL, V33, P946, DOI 10.1037/0012-1649.33.6.946
   Hu CF, 2013, READ WRIT, V26, P163, DOI 10.1007/s11145-012-9360-0
   Institute of Language Teaching and Research, 1986, FREQ DICT MOD CHIN
   Jarmulowicz L, 2008, READ WRIT, V21, P275, DOI 10.1007/s11145-007-9073-y
   Jarmulowicz L, 2007, J SPEECH LANG HEAR R, V50, P1593, DOI 10.1044/1092-4388(2007/107)
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Kamhi A., 2012, LANGUAGE READING DIS
   Katzir T, 2006, READ WRIT, V19, P845, DOI 10.1007/s11145-006-9013-2
   Kendeou P, 2009, J EDUC PSYCHOL, V101, P765, DOI 10.1037/a0015956
   Kim YS, 2013, LANG SPEECH HEAR SER, V44, P337, DOI 10.1044/0161-1461(2013/12-0013)
   Kirby JR, 2012, READ WRIT, V25, P389, DOI 10.1007/s11145-010-9276-5
   Kruk RS, 2013, J EXP CHILD PSYCHOL, V114, P10, DOI 10.1016/j.jecp.2012.09.014
   Kulinskaya E., 2008, METAANALYSIS GUIDE C, V756
   Kuo K.-J., 2006, ED PSYCHOL, V41, P161
   Lam FWF, 2008, HONG KONG J PAEDIATR, V13, P90
   Lei L, 2011, J CHILD PSYCHOL PSYC, V52, P212, DOI 10.1111/j.1469-7610.2010.02311.x
   Li H., J CHILD LAN IN PRESS
   Li H, 2012, J RES READ, V35, P287, DOI 10.1111/j.1467-9817.2010.01460.x
   Li LP, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0114417
   Lin D, 2012, J EDUC PSYCHOL, V104, P121, DOI 10.1037/a0025383
   Lin D, 2011, J RES READ, V34, P426, DOI 10.1111/j.1467-9817.2010.01446.x
   Liu D, 2015, SCI STUD READ, V19, P307, DOI 10.1080/10888438.2015.1030749
   Liu D, 2014, J PSYCHOLINGUIST RES, V43, P715, DOI 10.1007/s10936-013-9275-1
   Liu D, 2014, READ WRIT, V27, P431, DOI 10.1007/s11145-013-9451-6
   Liu PD, 2013, APPL PSYCHOLINGUIST, V34, P755, DOI 10.1017/S014271641200001X
   Liu PD, 2010, J EDUC PSYCHOL, V102, P62, DOI 10.1037/a0016933
   Mahony D, 2000, READ WRIT, V12, P191, DOI 10.1023/A:1008136012492
   McBride-Chang C, 2006, READ WRIT, V19, P695, DOI 10.1007/s11145-005-5742-x
   McBride-Chang C, 2005, J EXP CHILD PSYCHOL, V92, P140, DOI 10.1016/j.jecp.2005.03.009
   McBride-Chang C, 2005, APPL PSYCHOLINGUIST, V26, P415, DOI 10.1017/S014271640505023X
   McBride-Chang C, 2004, J EXP CHILD PSYCHOL, V89, P93, DOI 10.1016/j.jecp.2004.05.001
   McBride-Chang C, 2003, J EDUC PSYCHOL, V95, P743, DOI 10.1037/0022-0663.95.4.743
   McBride-Chang C., 2000, J PSYCHOL CHINESE SO, V1, P93
   McBride-Chang C., 2007, VOCABULARY ACQUISITI, P104
   McBride-Chang C, 2008, J CHILD PSYCHOL PSYC, V49, P211, DOI 10.1111/j.1469-7610.2007.01837.x
   McBride-Chang C, 2013, SCI STUD READ, V17, P57, DOI 10.1080/10888438.2012.689787
   McBride-Chang C, 2012, J LEARN DISABIL-US, V45, P503, DOI 10.1177/0022219411400748
   McBride-Chang C, 2012, READ WRIT, V25, P283, DOI 10.1007/s11145-010-9270-y
   McBride-Chang C, 2011, J EXP CHILD PSYCHOL, V110, P422, DOI 10.1016/j.jecp.2011.04.014
   McBride-Chang C, 2011, J CHILD PSYCHOL PSYC, V52, P204, DOI 10.1111/j.1469-7610.2010.02299.x
   McBrideChang C, 1996, READ WRIT, V8, P323, DOI 10.1007/BF00395112
   McCutchen D, 2011, READ RES QUART, V46, P334, DOI 10.1002/RRQ.003
   McCutchen D, 2008, READ PSYCHOL, V29, P289, DOI 10.1080/02702710801982050
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Muter V, 2004, DEV PSYCHOL, V40, P665, DOI 10.1037/0012-1649.40.5.665
   Nagy W, 2006, J EDUC PSYCHOL, V98, P134, DOI 10.1037/0022-0663.98.1.134
   Nagy W, 2003, J EDUC PSYCHOL, V95, P730, DOI 10.1037/0022-0663.95.4.730
   Nunes T., 2004, HDB CHILDRENS LITERA, P651, DOI [10.1007/978-94-017-1731-1_34, DOI 10.1007/978-94-017-1731-1_34]
   Packard J.L., 2000, MORPHOLOGY CHINESE L
   Pan J, 2011, J EDUC PSYCHOL, V103, P897, DOI 10.1037/a0024344
   Perfetti CA, 2005, PSYCHOL REV, V112, P43, DOI 10.1037/0033-295X.112.1.43
   Perfetti CA, 2005, BL HBK DEV PSYCHOL, P227, DOI 10.1002/9780470757642.ch13
   Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56
   Reed D., 2008, LEARNING DISABILITY, V23, P36, DOI DOI 10.1111/J.1540-5826.2007.00261.X
   Roman AA, 2009, J EXP CHILD PSYCHOL, V102, P96, DOI 10.1016/j.jecp.2008.01.004
   Saiegh-Haddad E, 2008, READ WRIT, V21, P481, DOI 10.1007/s11145-007-9074-x
   Savage RS, 2005, J LEARN DISABIL-US, V38, P12, DOI 10.1177/00222194050380010201
   Scarborough HS, 1998, SPECIFIC READING DISABILITY, P75
   Seidenberg M. S., 2011, DYSLEXIA LANGUAGES O, P151
   SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523
   Seymour PHK, 2005, BL HBK DEV PSYCHOL, P296, DOI 10.1002/9780470757642.ch16
   Shankweiler D, 1996, READ WRIT, V8, P267, DOI 10.1007/BF00420279
   SHANWEILER D, 1995, PSYCHOL SCI, V6, P149, DOI 10.1111/j.1467-9280.1995.tb00324.x
   Shu H, 2006, J EDUC PSYCHOL, V98, P122, DOI 10.1037/0022-0663.98.1.122
   Shu H, 2003, INT J PSYCHOL, V38, P274, DOI 10.1080/00207590344000060
   Shu H, 2003, CHILD DEV, V74, P27, DOI 10.1111/1467-8624.00519
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Siegel LS, 2008, TOP LANG DISORD, V28, P15, DOI 10.1097/01.adt.0000311413.75804.60
   Singson M, 2000, READ WRIT, V12, P219, DOI 10.1023/A:1008196330239
   Siok WT, 2001, DEV PSYCHOL, V37, P886, DOI 10.1037//0012-1649.37.6.886
   Song S, 2016, SCI STUD READ, V20, P99, DOI 10.1080/10888438.2015.1088543
   Song S, 2015, DEVELOPMENTAL SCI, V18, P119, DOI 10.1111/desc.12190
   Swank L. K., 1997, AM J SPEECH-LANG PAT, V6, P62
   Swanson HL, 2003, REV EDUC RES, V73, P407, DOI 10.3102/00346543073004407
   Tolchinsky L, 2012, READ WRIT, V25, P1573, DOI 10.1007/s11145-011-9334-7
   Tong XH, 2017, CONTEMP EDUC PSYCHOL, V48, P167, DOI 10.1016/j.cedpsych.2016.07.003
   Tong XH, 2014, J RES READ, V37, pS48, DOI 10.1111/1467-9817.12016
   Tong XL, 2011, J EDUC PSYCHOL, V103, P523, DOI 10.1037/a0023495
   Tong XL, 2011, J RES READ, V34, P315, DOI 10.1111/j.1467-9817.2009.01426.x
   Tong XL, 2010, READ WRIT, V23, P293, DOI 10.1007/s11145-009-9211-9
   Tong XL, 2009, SCI STUD READ, V13, P426, DOI 10.1080/10888430903162910
   Treiman R., 2014, CHILDREN LEARN WRITE
   VENEZKY RL, 1967, READ RES QUART, V2, P75, DOI 10.2307/747031
   Wang M, 2006, J EDUC PSYCHOL, V98, P542, DOI 10.1037/0022-0663.98.3.542
   Wang M, 2009, APPL PSYCHOLINGUIST, V30, P291, DOI 10.1017/S0142716409090122
   Wang Y, 2015, EARLY CHILD RES Q, V32, P51, DOI 10.1016/j.ecresq.2015.02.004
   Wang Y, 2014, READ WRIT, V27, P1281, DOI 10.1007/s11145-013-9486-8
   Wei TQ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096240
   Wenling L., 2002, CHINESE CHILDRENS RE, P87, DOI DOI 10.1007/978-1-4615-0859-5_5
   Wong AMY, 2015, READ WRIT, V28, P699, DOI 10.1007/s11145-015-9546-3
   Wong AMY, 2010, SCI STUD READ, V14, P30, DOI 10.1080/10888430903242043
   Wu NN, 1999, LANG COGNITIVE PROC, V14, P503, DOI 10.1080/016909699386176
   Xue J, 2013, J PSYCHOLINGUIST RES, V42, P433, DOI 10.1007/s10936-012-9228-0
   Yang JF, 2013, BILING-LANG COGN, V16, P354, DOI 10.1017/S1366728912000296
   Yeung PS, 2014, DYSLEXIA, V20, P119, DOI 10.1002/dys.1471
   Yeung PS, 2013, APPL PSYCHOLINGUIST, V34, P1245, DOI 10.1017/S0142716412000239
   Yeung PS, 2011, SCI STUD READ, V15, P285, DOI 10.1080/10888438.2010.482149
   Zhang H., READING WRI IN PRESS
   Zhang J, 2014, DEV PSYCHOL, V50, P1001, DOI 10.1037/a0035086
   Zhang J, 2014, READ WRIT, V27, P481, DOI 10.1007/s11145-013-9453-4
   Zhang J, 2012, READ WRIT, V25, P2183, DOI 10.1007/s11145-011-9353-4
   Zhang YP, 2013, DEV PSYCHOL, V49, P665, DOI 10.1037/a0028612
   Zhou YL, 2012, EARLY EDUC DEV, V23, P475, DOI 10.1080/10409289.2010.530478
   Zhou YL, 2014, J EXP CHILD PSYCHOL, V122, P75, DOI 10.1016/j.jecp.2013.12.003
NR 145
TC 31
Z9 31
U1 3
U2 63
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0022-0663
EI 1939-2176
J9 J EDUC PSYCHOL
JI J. Educ. Psychol.
PD FEB
PY 2018
VL 110
IS 2
BP 180
EP 202
DI 10.1037/edu0000216
PG 23
WC Psychology, Educational
SC Psychology
GA FU7RK
UT WOS:000424050200004
DA 2021-02-24
ER

PT J
AU Di Liberto, GM
   Lalor, EC
   Millman, RE
AF Di Liberto, Giovanni M.
   Lalor, Edmund C.
   Millman, Rebecca E.
TI Causal cortical dynamics of a predictive enhancement of speech
   intelligibility
SO NEUROIMAGE
LA English
DT Article
DE Entrainment; Speech intelligibility; Magnetoencephalography; Beamforming
ID HUMAN AUDITORY-CORTEX; TEMPORAL ENVELOPE; BRAIN; OSCILLATIONS;
   ENTRAINMENT; RESPONSES; PHASE; REPRESENTATIONS; COMPREHENSION;
   ORGANIZATION
AB Speech perception may be underpinned by a hierarchical cortical system, which attempts to match "external" incoming sensory inputs with "internal" top-down predictions. Prior knowledge modulates internal predictions of an upcoming stimulus and exerts its effects in temporal and inferior frontal cortex. Here, we used source-space magnetoencephalography (MEG) to study the spatiotemporal dynamics underpinning the integration of prior knowledge in the speech processing network. Prior knowledge was manipulated to i) increase the perceived intelligibility of speech sentences, and ii) dissociate the perceptual effects of changes in speech intelligibility from acoustical differences in speech stimuli. Cortical entrainment to the speech temporal envelope, which accounts for neural activity specifically related to sensory information, was affected by prior knowledge: This effect emerged early (similar to 50 ms) in left inferior frontal gyrus (IFG) and then (similar to 100 ms) in Heschl's gyrus (HG), and was sustained until latencies of similar to 250 ms. Directed transfer function (DTF) measures were used for estimating direct Granger causal relations between locations of interest. In line with the cortical entrainment result, this analysis indicated that prior knowledge enhanced top-down connections from left IFG to all the left temporal areas of interest namely HG, superior temporal sulcus (STS), and middle temporal gyrus (MTG). In addition, intelligible speech increased top-down information flow between left STS and left HG, and increased bottom-up flow in higher-order temporal cortex, specifically between STS and MTG. These results are compatible with theories that explain this mechanism as a result of both ascending and descending cortical interactions, such as predictive coding. Altogether, this study provides a detailed view of how, where and when prior knowledge influences continuous speech perception.
C1 [Di Liberto, Giovanni M.; Lalor, Edmund C.] Trinity Coll Dublin, Trinity Ctr Bioengn, Sch Engn, Trinity Coll Inst Neurosci, Dublin, Ireland.
   [Lalor, Edmund C.] Univ Rochester, Dept Biomed Engn, Dept Neurosci, De Monte Inst Neurosci, Rochester, NY 14627 USA.
   [Millman, Rebecca E.] Univ Manchester, Manchester Ctr Audiol & Deafness, Div Human Commun Dev & Hearing, Sch Hlth Sci,Fac Biol Med & Hlth, Manchester, Lancs, England.
RP Di Liberto, GM (corresponding author), 152-160 Pearse St, Dublin 2, Ireland.; Millman, RE (corresponding author), B2-8 Ellen Wilkinson Bldg,Oxford Rd, Manchester M13 9PL, Lancs, England.
EM diliberg@tcd.ie; rebecca.millman@manchester.ac.uk
RI Di Liberto, Giovanni/AAT-8865-2020
OI Di Liberto, Giovanni/0000-0002-7361-0980; Lalor,
   Edmund/0000-0002-2498-6631; Millman, Rebecca/0000-0001-8606-0167
FU Irish Research Council Government (GOIPG) of Ireland Postgraduate
   Scholarship [GOIPG/2013/1249]; Guarantors of Brain (UK registered
   charity)
FX This study was supported by an Irish Research Council Government (GOIPG,
   2013-2017) (GOIPG/2013/1249) of Ireland Postgraduate Scholarship and by
   a travel grant from Guarantors of Brain (UK registered charity). The
   authors thank Bahman Nasseroleslami for useful discussions on the
   connectivity analysis approach.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577
   Blinowska KJ, 2011, MED BIOL ENG COMPUT, V49, P521, DOI 10.1007/s11517-011-0739-x
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Crosse MJ, 2016, J NEUROSCI, V36, P9888, DOI 10.1523/JNEUROSCI.1396-16.2016
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Delorme A, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/130714
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Di Liberto G.M., CORTICAL ME IN PRESS
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding M, 2006, HDB TIME SERIES ANAL, P437, DOI DOI 10.1002/9783527609970.CH17
   Ding MZ, 2000, BIOL CYBERN, V83, P35, DOI 10.1007/s004229900137
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Dudley H, 1939, J ACOUST SOC AM, V11, P169, DOI 10.1121/1.1916020
   EVANS AC, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1813, DOI 10.1109/NSSMIC.1993.373602
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   FOSTER JR, 1993, BRIT J AUDIOL, V27, P233, DOI 10.3109/03005369309076700
   Friederici AD, 2010, HUM BRAIN MAPP, V31, P448, DOI 10.1002/hbm.20878
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   George N, 1999, NAT NEUROSCI, V2, P574, DOI 10.1038/9230
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gow DW, 2009, COGNITION, V110, P222, DOI 10.1016/j.cognition.2008.11.011
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Henseler I, 2014, J COGNITIVE NEUROSCI, V26, P1403, DOI 10.1162/jocn_a_00572
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Holdgraf CR, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13654
   Huang MX, 2004, BRAIN TOPOGR, V16, P139
   Huang MX, 1999, PHYS MED BIOL, V44, P423, DOI 10.1088/0031-9155/44/2/010
   Humphries C., 2014, FRONT NEUROSCI, V8
   Ing A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098697
   Johnson S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022251
   Keitel A, 2017, NEUROIMAGE, V147, P32, DOI 10.1016/j.neuroimage.2016.11.062
   Korzeniewska A, 2003, J NEUROSCI METH, V125, P195, DOI 10.1016/S0165-0270(03)00052-9
   Kosem A., 2016, LANG COGN NEUROSCI, P1
   Kozinska D, 2001, CLIN NEUROPHYSIOL, V112, P1553, DOI 10.1016/S1388-2457(01)00556-9
   Kus R, 2004, IEEE T BIO-MED ENG, V51, P1501, DOI 10.1109/TBME.2004.827929
   Lalor EC, 2009, J NEUROPHYSIOL, V102, P349, DOI 10.1152/jn.90896.2008
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014
   Lutkepohl H., 2007, NEW INTRO MULTIPLE T
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Maris E, 2012, PSYCHOPHYSIOLOGY, V49, P549, DOI 10.1111/j.1469-8986.2011.01320.x
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Millman RE, 2015, J COGNITIVE NEUROSCI, V27, P533, DOI 10.1162/jocn_a_00719
   Millman RE, 2013, NEUROIMAGE, V64, P185, DOI 10.1016/j.neuroimage.2012.09.017
   MOORE BCJ, 1983, J ACOUST SOC AM, V74, P750, DOI 10.1121/1.389861
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   Nourski KV, 2009, J NEUROSCI, V29, P15564, DOI 10.1523/JNEUROSCI.3065-09.2009
   O'Sullivan J. A., 2014, CEREB CORTEX
   Obleser J., 2009, CEREB CORTEX
   Obleser J, 2014, LANG LINGUIST COMPAS, V8, P646, DOI 10.1111/lnc3.12098
   Overath T, 2015, NAT NEUROSCI, V18, P903, DOI 10.1038/nn.4021
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Puvvada KC, 2017, J NEUROSCI, V37, P9189, DOI 10.1523/JNEUROSCI.0938-17.2017
   Rademacher J, 2001, NEUROIMAGE, V13, P669, DOI 10.1006/nimg.2000.0714
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Sedley W., 2016, NEURAL SIGNATURES PE, P5
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Stephan KE, 2007, J BIOSCIENCES, V32, P129, DOI 10.1007/s12038-007-0012-5
   Tuennerhoff J, 2016, NEUROIMAGE, V124, P641, DOI 10.1016/j.neuroimage.2015.09.004
   Turken AU, 2011, FRONT SYST NEUROSCI, V5, DOI 10.3389/fnsys.2011.00001
   VanVeen BD, 1997, IEEE T BIO-MED ENG, V44, P867, DOI 10.1109/10.623056
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035
   Zhang LJ, 2015, NEUROSCI LETT, V584, P351, DOI 10.1016/j.neulet.2014.10.054
   Zoefel B, 2016, NEUROIMAGE, V124, P16, DOI 10.1016/j.neuroimage.2015.08.054
NR 83
TC 21
Z9 21
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD FEB 1
PY 2018
VL 166
BP 247
EP 258
DI 10.1016/j.neuroimage.2017.10.066
PG 12
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA FQ9YE
UT WOS:000418716800022
PM 29102808
DA 2021-02-24
ER

PT J
AU Perry, LK
   Mech, EN
   MacDonald, MC
   Seidenberg, MS
AF Perry, Lynn K.
   Mech, Emily N.
   MacDonald, Maryellen C.
   Seidenberg, Mark S.
TI Influences of speech familiarity on immediate perception and final
   comprehension
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Speech perception; Accented speech; Speech shadowing; Listening
   comprehension
ID ADAPTATION; ACCENTS; ENGLISH
AB Unfamiliar speech-spoken in a familiar language but with an accent different from the listener's-is known to increase comprehension difficulty. However, there is evidence of listeners' rapid adaptation to unfamiliar accents (although perhaps not to the level of familiar accents). This paradox might emerge from prior focus on isolated word perception and/or use of single comprehension measures. We investigated processing of fluent connected speech spoken either in a familiar or unfamiliar accent, using participants' ability to "shadow" the speech as an immediate measure as well as a comprehension test at passage end. Shadowing latencies and errors and comprehension errors increased for Unfamiliar relative to Familiar Speech conditions, especially for relatively informal rather than more academic content. Additionally, there was evidence of less adaptation to Unfamiliar than Familiar Speech. These results suggest that unfamiliar speech imposes costs, especially in the immediate timescale of perceiving speech.
C1 [Perry, Lynn K.] Univ Miami, Dept Psychol, 5665 Ponce De Leon Blvd, Coral Gables, FL 33146 USA.
   [Mech, Emily N.] Univ Calif Riverside, Riverside, CA 92521 USA.
   [MacDonald, Maryellen C.; Seidenberg, Mark S.] Univ Wisconsin, Madison, WI USA.
RP Perry, LK (corresponding author), Univ Miami, Dept Psychol, 5665 Ponce De Leon Blvd, Coral Gables, FL 33146 USA.
EM lkperry@miami.edu
OI Perry, Lynn/0000-0001-6976-3741
FU NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R24D075454];
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R24HD075454,
   R24HD075454, R24HD075454, R24HD075454] Funding Source: NIH RePORTER
FX This study was supported by NICHD R24D075454. The authors thank the
   participants and Sarah Isaak and Yannan Gao for help in data collection
   and coding.
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Clarke C. M., 2004, ACOUSTICAL SOC AM, V116
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   GUMPERZ JJ, 1958, AM ANTHROPOL, V60, P668, DOI 10.1525/aa.1958.60.4.02a00050
   Jaeger T.F., 2009, RANDOM EFFECT SHOULD
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Major RC, 2005, LANG LEARN, V55, P37, DOI 10.1111/j.0023-8333.2005.00289.x
   MARSLENWILSON WD, 1975, SCIENCE, V189, P226, DOI 10.1126/science.189.4198.226
   MARSLENWILSON WD, 1985, SPEECH COMMUN, V4, P55, DOI 10.1016/0167-6393(85)90036-6
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   Sabatini E., 2000, INTERPRETING, V5, P25, DOI DOI 10.1075/INTP.5.1.03SAB
   Staum Casasanto L., 2008, P 30 ANN C COGN SCI, V30, P799
   Sumner M, 2011, COGNITION, V119, P131, DOI 10.1016/j.cognition.2010.10.018
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Weatherholtz K, 2014, LANG VAR CHANGE, V26, P387, DOI 10.1017/S0954394514000155
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
   WILSON WM, 1973, NATURE, V244, P522, DOI 10.1038/244522a0
NR 20
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD FEB
PY 2018
VL 25
IS 1
BP 431
EP 439
DI 10.3758/s13423-017-1297-5
PG 9
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA GA1MY
UT WOS:000428081700027
PM 28462503
OA Bronze
DA 2021-02-24
ER

PT J
AU Best, V
   Ahlstrom, JB
   Mason, CR
   Roverud, E
   Perrachione, TK
   Kidd, G
   Dubno, JR
AF Best, Virginia
   Ahlstrom, Jayne B.
   Mason, Christine R.
   Roverud, Elin
   Perrachione, Tyler K.
   Kidd, Gerald, Jr.
   Dubno, Judy R.
TI Talker identification: Effects of masking, hearing loss, and age
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SEQUENTIAL STREAM SEGREGATION; SPEECH-PERCEPTION; COMPETING SPEECH;
   TEMPORAL CUES; HUMAN VOICE; LISTENERS; RECOGNITION; GENDER; FAMILIARITY;
   SEPARATION
AB The ability to identify who is talking is an important aspect of communication in social situations and, while empirical data are limited, it is possible that a disruption to this ability contributes to the difficulties experienced by listeners with hearing loss. In this study, talker identification was examined under both quiet and masked conditions. Subjects were grouped by hearing status (normal hearing/sensorineural hearing loss) and age (younger/older adults). Listeners first learned to identify the voices of four same-sex talkers in quiet, and then talker identification was assessed (1) in quiet, (2) in speech-shaped, steady-state noise, and (3) in the presence of a single, unfamiliar same-sex talker. Both younger and older adults with hearing loss, as well as older adults with normal hearing, generally performed more poorly than younger adults with normal hearing, although large individual differences were observed in all conditions. Regression analyses indicated that both age and hearing loss were predictors of performance in quiet, and there was some evidence for an additional contribution of hearing loss in the presence of masking. These findings suggest that both hearing loss and age may affect the ability to identify talkers in "cocktail party" situations. (C) 2018 Acoustical Society of America.
C1 [Best, Virginia; Mason, Christine R.; Roverud, Elin; Perrachione, Tyler K.; Kidd, Gerald, Jr.] Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
   [Ahlstrom, Jayne B.; Dubno, Judy R.] Med Univ South Carolina, Dept Otolaryngol Head & Neck Surg, Charleston, SC 29425 USA.
RP Best, V (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
EM ginbest@bu.edu
RI Best, Virginia/AAE-4279-2020
FU National Institutes of Health-National Institute on Deafness and Other
   Communication Disorders (NIH-NIDCD)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD) [R01
   DC04545, R01 DC000184]; AFOSRUnited States Department of DefenseAir
   Force Office of Scientific Research (AFOSR) [FA9550-16-1-0372]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC004545, R01DC004545, R01DC004545, R01DC004545,
   R01DC004545, R01DC004545, R01DC004545, R01DC000184, R01DC004545,
   R01DC004545, R01DC004545, R01DC004545, R01DC004545, R01DC004545,
   R01DC004545, R01DC004545, R01DC004545, R01DC004545, R01DC004545,
   R01DC004545] Funding Source: NIH RePORTER
FX This work was supported by National Institutes of Health-National
   Institute on Deafness and Other Communication Disorders (NIH-NIDCD)
   Grant Nos. R01 DC04545 (to G.K.) and R01 DC000184 (to J.R.D.), and AFOSR
   Grant No. FA9550-16-1-0372 (to G.K.). Portions of the work were
   presented at the 5th Joint Meeting of the Acoustical Society of America
   and the Acoustical Society of Japan (Honolulu, November 2016). The
   authors would like to acknowledge Lorraine Delhorne (BU) and Sara Fultz
   (MUSC) for help with subject recruitment.
CR Arehart KH, 2005, J SPEECH LANG HEAR R, V48, P236, DOI 10.1044/1092-4388(2005/017)
   Boersma P., 2009, PRAAT DOING PHONETIC
   BYRNE D, 1991, VANDERBILT HEARING AID REPORT II, P295
   Chandrasekaran B, 2011, J COGNITIVE NEUROSCI, V23, P2690, DOI 10.1162/jocn.2011.21631
   Dillon H., 2012, HEARING AIDS
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Helfer KS, 2009, J ACOUST SOC AM, V125, P447, DOI 10.1121/1.3035837
   Janse E, 2012, AGING NEUROPSYCHOL C, V19, P741, DOI 10.1080/13825585.2011.652590
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   KAUSLER DH, 1981, J GERONTOL, V36, P44, DOI 10.1093/geronj/36.1.44
   Kidd G, 2017, SPRINGER HANDB AUDIT, V60, P75, DOI 10.1007/978-3-319-51662-2_4
   Latinus M, 2013, CURR BIOL, V23, P1075, DOI 10.1016/j.cub.2013.04.055
   Latinus M, 2011, CURR BIOL, V21, pR143, DOI 10.1016/j.cub.2010.12.033
   Mackersie CL, 2003, J SPEECH LANG HEAR R, V46, P912, DOI 10.1044/1092-4388(2003/071)
   Mackersie CL, 2001, J SPEECH LANG HEAR R, V44, P19, DOI 10.1044/1092-4388(2001/002)
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Perrachione TK, 2014, J SPEECH LANG HEAR R, V57, P1651, DOI 10.1044/2014_JSLHR-S-13-0161
   Perrachione TK, 2009, J EXP PSYCHOL HUMAN, V35, P1950, DOI 10.1037/a0015869
   Razak A., 2017, 173 M AC SOC AM
   Remez RE, 2007, J ACOUST SOC AM, V122, P3688, DOI 10.1121/1.2799903
   Rossi-Katz J, 2009, J SPEECH LANG HEAR R, V52, P435, DOI 10.1044/1092-4388(2008/07-0243)
   Roverud E, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516638516
   Schurman J, 2014, J ACOUST SOC AM, V136, P3337, DOI 10.1121/1.4901708
   Schvartz KC, 2012, EAR HEARING, V33, P411, DOI 10.1097/AUD.0b013e31823d78dc
   Schweinberger SR, 2014, WIRES COGN SCI, V5, P15, DOI 10.1002/wcs.1261
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Spencer WD, 1995, PSYCHOL AGING, V10, P527, DOI 10.1037/0882-7974.10.4.527
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Summers V, 1998, J SPEECH LANG HEAR R, V41, P1294, DOI 10.1044/jslhr.4106.1294
   Vongphoe M, 2005, J ACOUST SOC AM, V118, P1055, DOI 10.1121/1.1944507
   Wenndt SJ, 2016, J ACOUST SOC AM, V140, P1172, DOI 10.1121/1.4958682
   Wright BA, 2010, J NEUROSCI, V30, P12868, DOI 10.1523/JNEUROSCI.0487-10.2010
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
NR 35
TC 7
Z9 7
U1 3
U2 5
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2018
VL 143
IS 2
BP 1085
EP 1092
DI 10.1121/1.5024333
PG 8
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA GX3IF
UT WOS:000447615500001
PM 29495693
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Rasanen, O
   Doyle, G
   Frank, MC
AF Rasanen, Okko
   Doyle, Gabriel
   Frank, Michael C.
TI Pre-linguistic segmentation of speech into syllable-like units
SO COGNITION
LA English
DT Article
DE Early language acquisition; Speech perception; Syllables; Speech
   segmentation; Oscillatory entrainment; Sonority
ID WORD SEGMENTATION; AMPLITUDE-MODULATION; INFANTS; MODEL; PERCEPTION;
   INFORMATION; ACQUISITION; FRENCH; RHYTHM; CUES
AB Syllables are often considered to be central to infant and adult speech perception. Many theories and behavioral studies on early language acquisition are also based on syllable-level representations of spoken language. There is little clarity, however, on what sort of pre-linguistic "syllable" would actually be accessible to an infant with no phonological or lexical knowledge. Anchored by the notion that syllables are organized around particularly sonorous (audible) speech sounds, the present study investigates the feasibility of speech segmentation into syllable-like chunks without any a priori linguistic knowledge. We first operationalize sonority as a measurable property of the acoustic input, and then use sonority variation across time, or speech rhythm, as the basis for segmentation. The entire process from acoustic input to chunks of syllable-like acoustic segments is implemented as a computational model inspired by the oscillatory entrainment of the brain to speech rhythm. We analyze the output of the segmentation process in three different languages, showing that the sonority fluctuation in speech is highly informative of syllable and word boundaries in all three cases without any language-specific tuning of the model. These findings support the widely held assumption that syllable-like structure is accessible to infants even when they are only beginning to learn the properties of their native language.
C1 [Rasanen, Okko] Aalto Univ, Dept Signal Proc & Acoust, POB 12000, FI-00076 Aalto, Finland.
   [Doyle, Gabriel; Frank, Michael C.] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA.
RP Rasanen, O (corresponding author), Aalto Univ, Dept Signal Proc & Acoust, POB 12000, FI-00076 Aalto, Finland.
EM okko.rasanen@aalto.fi
RI Rasanen, Okko/P-7904-2016
OI Rasanen, Okko/0000-0002-0537-0946; Frank, Michael/0000-0002-7551-4378
FU Academy of FinlandAcademy of FinlandEuropean Commission [274479];
   NSFNational Science Foundation (NSF) [1456077, 1528526]
FX The authors would like to thank Partel Lippus for providing the Estonian
   Phonetic Corpus of Spontaneous Speech, Mietta Lennes for the FinDialogue
   corpus, and John Pate for providing the forced-aligned phone
   transcriptions for the Brent corpus. In addition, the authors are
   grateful to Martti Vainio, Juraj Simko, Antti Suni, and Unto K. Laine
   for useful discussions and comments related to this work. O. Rasanen was
   funded by the Academy of Finland project "Computational modeling of
   language acquisition" (no. 274479). G. Doyle and M. C. Frank acknowledge
   NSF #1456077 and M. C. Frank acknowledges NSF #1528526 for support. A
   MATLAB implementation of the oscillator based syllabification algorithm
   is available at https://github.com/orasanen/thetaOscillator.
CR Adriaans F, 2010, J MEM LANG, V62, P311, DOI 10.1016/j.jml.2009.11.007
   Ahissar E., 2001, PNAS, V98, P11367
   Almpanidis G, 2008, SPEECH COMMUN, V50, P38, DOI 10.1016/j.specom.2007.06.005
   An GZ, 2013, INTERSPEECH, P178
   BERTONCINI J, 1988, J EXP PSYCHOL GEN, V117, P21, DOI 10.1037/0096-3445.117.1.21
   BERTONCINI J, 1981, INFANT BEHAV DEV, V4, P247, DOI 10.1016/S0163-6383(81)80027-6
   BIJELJACBABIC R, 1993, DEV PSYCHOL, V29, P711, DOI 10.1037/0012-1649.29.4.711
   Bortfeld H., 2013, THEORETICAL COMPUTAT
   Brent MR, 2001, COGNITION, V81, pB33, DOI 10.1016/S0010-0277(01)00122-6
   Christiansen MH, 1998, LANG COGNITIVE PROC, V13, P221, DOI 10.1080/016909698386528
   Clements George N, 1990, PAPERS LAB PHONOLOGY, VI, P283, DOI [DOI 10.1017/CBO9780511627736.017, 10.1017/CBO9780511627736.017, DOI 10.1017/CBO9780511627736]
   Cummins F, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00364
   CUTLER A, 1988, J EXP PSYCHOL HUMAN, V14, P113, DOI 10.1037/0096-1523.14.1.113
   CUTLER A, 1986, J MEM LANG, V25, P385, DOI 10.1016/0749-596X(86)90033-1
   CUTLER A, 1992, COGNITIVE PSYCHOL, V24, P381, DOI 10.1016/0010-0285(92)90012-Q
   Dau T, 1997, J ACOUST SOC AM, V102, P2892, DOI 10.1121/1.420344
   Doyle G., 2013, P 2013 C N AM CHAPT, P117
   DUPOUX E, 1993, COGNITIVE MODELS OF SPEECH PROCESSING: THE SECOND SPERLONGA MEETING, P81
   Dutoit T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1393, DOI 10.1109/ICSLP.1996.607874
   Eimas PD, 1999, J ACOUST SOC AM, V105, P1901, DOI 10.1121/1.426726
   Esposito A, 2005, LECT NOTES ARTIF INT, V3445, P261
   Fenson L., 1993, MACARTHUR COMMUNICAT
   Fisher M.W., 1996, TSYLB2
   Frank MC, 2017, J CHILD LANG, V44, P677, DOI 10.1017/S0305000916000209
   Frank MC, 2010, COGNITION, V117, P107, DOI 10.1016/j.cognition.2010.07.005
   Frank MC, 2009, PSYCHOL SCI, V20, P578, DOI 10.1111/j.1467-9280.2009.02335.x
   Fudge EC, 1969, J LINGUIST, V5, P253, DOI 10.1017/S0022226700002267
   Galves A., 2002, P SPEECH PROS APR 11
   Gambell T., 2006, WORD SEGMENTATION QU
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Godfrey J. J., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P517, DOI 10.1109/ICASSP.1992.225858
   Goldsmith John, 2011, HDB PHONOLOGICAL THE
   Gomez RL, 1999, COGNITION, V70, P109, DOI 10.1016/S0010-0277(99)00003-7
   Grabe E, 2002, PHONOL PHONET, V4-1, P515
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Greenberg S, 1999, SPEECH COMMUN, V29, P159, DOI 10.1016/S0167-6393(99)00050-3
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Guffey K., 2002, SPANISH SYLLABLE STR
   Halle P., 2012, SPEECH PLANNING DYNA
   Harris J, 2006, LINGUA, V116, P1483, DOI 10.1016/j.lingua.2005.07.009
   Hay JF, 2012, INFANCY, V17, P610, DOI 10.1111/j.1532-7078.2011.00110.x
   Hooper Joan B., 1976, INTRO NATURAL GENERA
   Hyafil A, 2015, ELIFE, V4, DOI 10.7554/eLife.06213
   Jany C, 2007, P 16 INT C PHON SCI, P1401
   Jespersen Otto, 1920, LEHRBUCH PHONETIK
   JONES Daniel, 1960, OUTLINE ENGLISH PHON
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   JUSCZYK PW, 1987, DEV PSYCHOL, V23, P648, DOI 10.1037/0012-1649.23.5.648
   JUSCZYK PW, 1978, PERCEPT PSYCHOPHYS, V23, P105, DOI 10.3758/BF03208289
   JUSCZYK PW, 1990, COGNITIVE DEV, V5, P265, DOI 10.1016/0885-2014(90)90018-O
   JUSCZYK PW, 1995, INFANT BEHAV DEV, V18, P27, DOI 10.1016/0163-6383(95)90005-5
   Jusczyk PW, 2002, EAR HEARING, V23, P2, DOI 10.1097/00003446-200202000-00002
   JUSCZYK PW, 1993, J PHONETICS, V21, P3, DOI 10.1016/S0095-4470(19)31319-1
   Kahn D., 1976, THESIS
   Krakow RA, 1999, J PHONETICS, V27, P23, DOI 10.1006/jpho.1999.0089
   Kvale K., 1993, THESIS
   Ladefoged P., 2000, COURSE PHONETICS
   Lee CS, 2004, COGNITION, V93, P225, DOI 10.1016/j.cognition.2003.10.012
   Lennes M., 2009, PHONETICS RUSSIAN FI, P145
   Leong V., 2012, THESIS
   Leong V, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144411
   Leong V, 2014, J ACOUST SOC AM, V136, P366, DOI 10.1121/1.4883366
   Leong V, 2014, HEARING RES, V308, P141, DOI 10.1016/j.heares.2013.07.015
   Leoni F. A, 2015, NOTION SYLLABLE HIST
   LIBERMAN IY, 1974, J EXP CHILD PSYCHOL, V18, P201, DOI 10.1016/0022-0965(74)90101-5
   Lippus P., 2013, PHONETIC CORPUS ESTO
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Malmberg B., 1963, PHONETICS
   Marchand Y., 2007, P 6 INT SPEECH COMM, P316
   Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77
   MEHLER J, 1981, J VERB LEARN VERB BE, V20, P298, DOI 10.1016/S0022-5371(81)90450-3
   MEHLER J, 1990, ACL MIT NAT, P236
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Mehler Jacques, 1995, P943
   MERMELSTEIN P, 1975, J ACOUST SOC AM, V58, P880, DOI 10.1121/1.380738
   Meylan S., 2012, P 34 ANN M COGN SCI, P2002
   MORAIS J, 1986, COGNITION, V24, P45, DOI 10.1016/0010-0277(86)90004-1
   Morals J., 1989, LANG COGNITIVE PROC, V4, P56
   Morgan N, 1998, INT CONF ACOUST SPEE, P729, DOI 10.1109/ICASSP.1998.675368
   Nasukawa K, 2007, CUNY C PREC REL
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2006, J MEM LANG, V54, P283, DOI 10.1016/j.jml.2005.10.004
   Nespor M., 2011, BLACKWELL COMPANION
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2
   Ngon C, 2013, DEVELOPMENTAL SCI, V16, P24, DOI 10.1111/j.1467-7687.2012.01189.x
   Nishibayashi LL, 2015, LANG SPEECH, V58, P334, DOI 10.1177/0023830914551375
   Nusbaum H. C., 1991, PAR SYLL PHON PHON
   Obin N, 2013, INT CONF ACOUST SPEE, P6699, DOI 10.1109/ICASSP.2013.6638958
   Ohala J, 1992, ALTERNATIVES SONORIT, P319
   OHALA JJ, 1990, J PHONETICS, V18, P153, DOI 10.1016/S0095-4470(19)30399-7
   OPPENHEIM A, 1983, SIGNALS SYSTEMS
   Parker Stephen G., 2002, THESIS
   Patterson R. D., 1992, AUDITORY PHYSL PERCE, P123
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Perruchet P, 1998, J MEM LANG, V39, P246, DOI 10.1006/jmla.1998.2576
   Perruchet P, 2010, COGNITIVE SCI, V34, P255, DOI 10.1111/j.1551-6709.2009.01074.x
   Phillips L, 2012, P 34 ANN C COGN SCI, P863
   Port RF, 2005, LANGUAGE, V81, P927, DOI 10.1353/lan.2005.0195
   PRICE PJ, 1980, PHONETICA, V37, P327, DOI 10.1159/000260001
   Prince Alan, 1993, 2 RUTG U CTR COGN SC
   Raimy E, 2009, CURR STUD LINGUIST, P1
   Rasanen O., 2014, P 36 ANN C COGN SCI, P2817
   Rasanen O, 2015, PSYCHOL REV, V122, P792, DOI 10.1037/a0039702
   Rasanen O, 2011, COGNITION, V120, P149, DOI 10.1016/j.cognition.2011.04.001
   Rasanen Okko Johannes, 2009, P INTERSPEECH, P1851
   Rdsanen O., 2013, J ACOUST SOC AM, V134, P407
   Redford MA, 2005, J PHONETICS, V33, P27, DOI 10.1016/j.wocn.2004.05.003
   Rosenberg A, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P146
   Rytting CA, 2010, J CHILD LANG, V37, P513, DOI 10.1017/S0305000910000085
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   Saussure Ferdinand de, 2016, COURS LINGUISTIQUE G
   SCHARENBORG O, 2007, P INT C SPOK LANG PR, P1953
   SEGUI J, 1981, BRIT J PSYCHOL, V72, P471, DOI 10.1111/j.2044-8295.1981.tb01776.x
   Seidl A, 2006, DEVELOPMENTAL SCI, V9, P565, DOI 10.1111/j.1467-7687.2006.00534.x
   Shukla M, 2007, COGNITIVE PSYCHOL, V54, P1, DOI 10.1016/j.cogpsych.2006.04.002
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   STETSON RH, 1951, MOTOR PHONETICS STUD
   Suomi K., 2008, FINNISH SOUND STRUCT
   Swingley D, 2005, COGNITIVE PSYCHOL, V50, P86, DOI 10.1016/j.cogpsych.2004.06.001
   Tesar B, 1998, LINGUIST INQ, V29, P229, DOI 10.1162/002438998553734
   Thiessen ED, 2003, DEV PSYCHOL, V39, P706, DOI 10.1037/0012-1649.39.4.706
   van der Hulst Harry, 2005, HEADHOOD ELEMENTS SP, P193, DOI DOI 10.1075/CILT.259
   VIEMEISTER NF, 1979, J ACOUST SOC AM, V66, P1364, DOI 10.1121/1.383531
   Villing R., 2004, P IR SIGN SYST C ISS
   Vining R., 2006, P ISSC 2006 DUBL IR, P521
   Wagner P., 2008, THESIS
   Wang D, 2007, IEEE T AUDIO SPEECH, V15, P2190, DOI 10.1109/TASL.2007.905178
   Whitney William Dwight, 1874, ORIENTAL LINGUISTIC
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 131
TC 14
Z9 14
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD FEB
PY 2018
VL 171
BP 130
EP 150
DI 10.1016/j.cognition.2017.11.003
PG 21
WC Psychology, Experimental
SC Psychology
GA FY9SX
UT WOS:000427208300013
PM 29156241
DA 2021-02-24
ER

PT J
AU Wagner, L
   Maurits, N
   Maat, B
   Baskent, D
   Wagner, AE
AF Wagner, Luise
   Maurits, Natasha
   Maat, Bert
   Baskent, Deniz
   Wagner, Anita E.
TI The Cochlear Implant EEG Artifact Recorded From an Artificial Brain for
   Complex Acoustic Stimuli
SO IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING
LA English
DT Article
DE Cochlear-implant artifact; EEG; brain substitute
ID AUDITORY-EVOKED POTENTIALS; ITERATED RIPPLED NOISE; GEL MODEL; SPEECH;
   CONDUCTIVITY; RECOGNITION; ATTENUATION; RESPONSES; STRENGTH
AB Electroencephalographic (EEG) recordings provide objective estimates of listeners' cortical processing of sounds and of the status of their speech perception system. For profoundly deaf listeners with cochlear implants (CIs), the applications of EEG are limited because the device adds electric artifacts to the recordings. This restricts the possibilities for the neural-based metrics of speech processing by CI users, for instance to gauge cortical reorganization due to individual's hearing loss history. This paper describes the characteristics of the CI artifact as recorded with an artificial head substitute, and reports how the artifact is affected by the properties of the acoustical input signal versus the settings of the device. Methods: We created a brain substitute using agar that simulates the brain's conductivity, placed it in a human skull, and performed EEG recordings with CIs from three different manufacturers. As stimuli, we used simple and complex non-speech stimuli, as well as naturally produced continuous speech. We examined the effect of manipulating device settings in both controlled experimental CI configurations and real clinical maps. Results: An increase in the magnitude of the stimulation current through the device settings increases also the magnitude of the artifact. The artifact recorded to speech is smaller in magnitude than for nonspeech stimuli due to signal-inherent amplitude modulations. Conclusion: The CI EEG artifact for speech appearsmore difficult to detect than for simple stimuli. Since the artifact differs across CI users, due to their individual clinical maps, the method presented enables insight into the individual manifestations of the artifact.
C1 [Wagner, Luise] Martin Luther Univ Halle Wittenberg, Dept Otorhinolaryngol, D-06120 Halle, Germany.
   [Wagner, Luise] Martin Luther Univ Halle Wittenberg, Halle Hearing & Implant Ctr, D-06120 Halle, Germany.
   [Maurits, Natasha] Univ Groningen, Univ Med Ctr Groningen, Dept Neurol, NL-9712 Groningen, Netherlands.
   [Maurits, Natasha; Maat, Bert; Baskent, Deniz; Wagner, Anita E.] Univ Groningen, Grad Sch Med Sci, Sch Behav & Cognit Neurosci, NL-9712 Groningen, Netherlands.
   [Maat, Bert; Baskent, Deniz; Wagner, Anita E.] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, NL-9712 Groningen, Netherlands.
RP Wagner, L (corresponding author), Martin Luther Univ Halle Wittenberg, Dept Otorhinolaryngol, D-06120 Halle, Germany.; Wagner, L (corresponding author), Martin Luther Univ Halle Wittenberg, Halle Hearing & Implant Ctr, D-06120 Halle, Germany.
EM luise.wagner@uk-halle.de
RI Wagner, Anita/H-9189-2018
OI Wagner, Anita/0000-0003-4724-7927; Baskent, Deniz/0000-0002-6560-1451;
   Maurits, Natasha/0000-0001-6231-7044; Maat, Bert/0000-0001-9856-7010
FU U.S. National Science FoundationNational Science Foundation (NSF)
   [BS123456]; Leonardo Saxony-Anhalt; Rosalind Franklin Fellowship from
   the University of Groningen; Netherlands Organization for Scientific
   Research (NWO, VIDI Grant)Netherlands Organization for Scientific
   Research (NWO) [016.096.397]; Heinsius Houbolt Foundation
FX This work was supported by the U.S. National Science Foundation under
   Grant BS123456. The work of L. Wagner was supported by Leonardo
   Saxony-Anhalt for the Erasmus Grant. The work of D. Baskent was
   supported in part by the Rosalind Franklin Fellowship from the
   University of Groningen, the Netherlands Organization for Scientific
   Research (NWO, VIDI Grant 016.096.397), and the Heinsius Houbolt
   Foundation.
CR Baumann SB, 1997, IEEE T BIO-MED ENG, V44, P220, DOI 10.1109/10.554770
   Bennett D, 2011, MAT SCI ENG C-MATER, V31, P494, DOI 10.1016/j.msec.2010.08.018
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Bonnet RM, 2012, EAR HEARING, V33, P489, DOI 10.1097/AUD.0b013e31824c761a
   BOSTOCK H, 1983, J PHYSIOL-LONDON, V341, P59, DOI 10.1113/jphysiol.1983.sp014792
   Gilley PM, 2006, CLIN NEUROPHYSIOL, V117, P1772, DOI 10.1016/j.clinph.2006.04.018
   Henkin Y., 2012, J HEARING SCI, V2, P49
   Henkin Y, 2015, J AM ACAD AUDIOL, V26, P384, DOI 10.3766/jaaa.26.4.6
   Kandadai MA, 2012, MAT SCI ENG C-MATER, V32, P2664, DOI 10.1016/j.msec.2012.07.024
   Li XX, 2010, INT CONF BIOMED, P799, DOI 10.1109/BMEI.2010.5639942
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Makeig S, 2011, OXFORD HDB EVENT REL
   Martin BA, 2007, J AM ACAD AUDIOL, V18, P126, DOI 10.3766/jaaa.18.2.5
   Mc Laughlin M, 2013, HEARING RES, V302, P84, DOI 10.1016/j.heares.2013.05.006
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Patterson RD, 1996, J ACOUST SOC AM, V100, P3286, DOI 10.1121/1.417212
   PERL ER, 1953, ELECTROEN CLIN NEURO, V5, P501, DOI 10.1016/0013-4694(53)90026-1
   Pomfret R, 2013, ANN NEUROSCI, V20, P118, DOI 10.5214/ans.0972.7531.200309
   R Core Team, R LANG ENV STAT COMP
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872
   Van Dun B, 2014, 8 INT S OBJ MEAS AUD
   Viola FC, 2012, HEARING RES, V284, P6, DOI 10.1016/j.heares.2011.12.010
   Vorwerk J, 2014, NEUROIMAGE, V100, P590, DOI 10.1016/j.neuroimage.2014.06.040
   Wagner A., 2016, 9 INT S OBJ MEAS AUD
   Yost WA, 1996, J ACOUST SOC AM, V100, P511, DOI 10.1121/1.415873
   Yost WA, 1998, J ACOUST SOC AM, V104, P2349, DOI 10.1121/1.423746
NR 27
TC 5
Z9 6
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1534-4320
EI 1558-0210
J9 IEEE T NEUR SYS REH
JI IEEE Trans. Neural Syst. Rehabil. Eng.
PD FEB
PY 2018
VL 26
IS 2
BP 392
EP 399
DI 10.1109/TNSRE.2018.2789780
PG 8
WC Engineering, Biomedical; Rehabilitation
SC Engineering; Rehabilitation
GA FY6YP
UT WOS:000427009100014
PM 29432110
OA Bronze
DA 2021-02-24
ER

PT J
AU Benitez-Barrera, CR
   Angley, GP
   Tharpe, AM
AF Benitez-Barrera, Carlos R.
   Angley, Gina P.
   Tharpe, Anne Marie
TI Remote Microphone System Use at Home: Impact on Caregiver Talk
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID LANGUAGE-DEVELOPMENT; HEARING-LOSS; SPEECH-PERCEPTION; CHILDREN;
   INFANTS; RECOGNITION; OVERHEARING; VOCABULARY; INPUT; WORDS
AB Purpose: The purpose of this study was to investigate the effects of home use of a remote microphone system (RMS) on the spoken language production of caregivers with young children who have hearing loss.
   Method: Language Environment Analysis recorders were used with 10 families during 2 consecutive weekends (RMS weekend and No-RMS weekend). The amount of talk from a single caregiver that could be made accessible to children with hearing loss when using an RMS was estimated using Language Environment Analysis software. The total amount of caregiver talk (close and far talk) was also compared across both weekends. In addition, caregivers' perceptions of RMS use were gathered.
   Results: Children, with the use of RMSs, could potentially have access to approximately 42% more words per day. In addition, although caregivers produced an equivalent number of words on both weekends, they tended to talk more from a distance when using the RMS than when not. Finally, caregivers reported positive perceived communication benefits of RMS use.
   Conclusions: Findings from this investigation suggest that children with hearing loss have increased access to caregiver talk when using an RMS in the home environment. Clinical implications and future directions for research are discussed.
C1 [Benitez-Barrera, Carlos R.; Angley, Gina P.; Tharpe, Anne Marie] Vanderbilt Univ, Sch Med, Dept Hearing & Speech Sci, Nashville, TN 37212 USA.
RP Benitez-Barrera, CR (corresponding author), Vanderbilt Univ, Sch Med, Dept Hearing & Speech Sci, Nashville, TN 37212 USA.
EM carlos.r.benitez@vanderbilt.edu
FU Phonak LLC; Phonak AG
FX We want to thank Drs. Tiffany Woynaroski, Melanie Schuele, and Rene
   Gifford for their collaboration on this project. We also want to thank
   Kim Coulter for her support as a LENA consultant, Phonak LLC, and Phonak
   AG for providing the equipment and funding for this project. Finally, we
   are grateful to all the families who participated in this study and the
   staff at the Mama Lere Hearing School for their assistance in
   recruitment.
CR Akhtar N, 2005, DEVELOPMENTAL SCI, V8, P199, DOI 10.1111/j.1467-7687.2005.00406.x
   Akhtar N, 2001, CHILD DEV, V72, P416, DOI 10.1111/1467-8624.00287
   Ambrose S. E., 2014, EAR HEARING, V36, p48S
   American National Standards Institute/Acoustical Society of America, 2010, S12602010 ANSI AC SO
   Anderson KL, 2004, LANG SPEECH HEAR SER, V35, P169, DOI 10.1044/0161-1461(2004/017)
   Aragon M, 2012, SEMIN SPEECH LANG, V33, P340, DOI 10.1055/s-0032-1326918
   Aslin RN, 1998, PSYCHOL SCI, V9, P321, DOI 10.1111/1467-9280.00063
   Ching TYC, 2013, INT J AUDIOL, V52, pS65, DOI 10.3109/14992027.2013.866339
   CRANDELL CC, 1993, EAR HEARING, V14, P210, DOI 10.1097/00003446-199306000-00008
   Floor P, 2006, INFANCY, V9, P327, DOI 10.1207/s15327078in0903_4
   Flynn T. S., 2005, J ED AUDIOLOGY, V12, P37
   Geers A. E., 2011, EAR HEAR S1, V32, P84
   Hart B., 1995, MEANINGFUL DIFFERENC
   Hoff E, 2002, CHILD DEV, V73, P418, DOI 10.1111/1467-8624.00415
   Hurtado N, 2008, DEVELOPMENTAL SCI, V11, pF31, DOI 10.1111/j.1467-7687.2008.00768.x
   Johnson C. D., 2003, USE FM TECHNOLOGY IN, P98
   Ling D., 1976, SPEECH HEARING IMPAI
   Moeller MP, 1996, EAR HEARING, V17, P28, DOI 10.1097/00003446-199602000-00004
   Mulla I., 2013, USE FM TECHNOLOGY PR
   Mulla Imran, 2014, Seminars in Hearing, V35, P206, DOI 10.1055/s-0034-1383505
   Newman R, 2006, DEV PSYCHOL, V42, P643, DOI 10.1037/0012-1649.42.4.643
   Oller DK, 2010, P NATL ACAD SCI USA, V107, P13354, DOI 10.1073/pnas.1003882107
   Quittner AL, 2013, J PEDIATR-US, V162, P343, DOI 10.1016/j.jpeds.2012.08.003
   Schafer Erin C, 2006, Am J Audiol, V15, P114, DOI 10.1044/1059-0889(2006/015)
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556
   Stickney GS, 2004, J ACOUST SOC AM, V116, P1081, DOI 10.1121/1.1772399
   Szagun G., 2009, REV LOGOPEDIA FONIAT, V29, P165
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Tomblin JB, 2014, JAMA OTOLARYNGOL, V140, P403, DOI 10.1001/jamaoto.2014.267
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Walker EA, 2013, LANG SPEECH HEAR SER, V44, P73, DOI 10.1044/0161-1461(2012/12-0005)
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   Woynaroski T., 2014, THESIS
   Xu D., 2009, RELIABILITY LENA LAN
NR 35
TC 7
Z9 9
U1 0
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2018
VL 61
IS 2
BP 399
EP 409
DI 10.1044/2017_JSLHR-H-17-0168
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FY2GZ
UT WOS:000426634800014
PM 29330553
DA 2021-02-24
ER

PT J
AU Youngdahl, CL
   Healy, EW
   Yoho, SE
   Apoux, F
   Holt, RF
AF Youngdahl, Carla L.
   Healy, Eric W.
   Yoho, Sarah E.
   Apoux, Frederic
   Holt, Rachael Frush
TI The Effect of Remote Masking on the Reception of Speech by Young
   School-Age Children
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID PURE-TONE SIGNAL; AUDITORY FILTER; CRITICAL BAND; NOISE; FREQUENCY;
   PERCEPTION; INFANTS; ADULTS; RECOGNITION; MASKER
AB Purpose: Psychoacoustic data indicate that infants and children are less likely than adults to focus on a spectral region containing an anticipated signal and are more susceptible to remote masking of a signal. These detection tasks suggest that infants and children, unlike adults, do not listen selectively. However, less is known about children's ability to listen selectively during speech recognition. Accordingly, the current study examines remote masking during speech recognition in children and adults.
   Method: Adults and 7- and 5-year-old children performed sentence recognition in the presence of various spectrally remote maskers. Intelligibility was determined for each remote-masker condition, and performance was compared across age groups.
   Results: It was found that speech recognition for 5-year-olds was reduced in the presence of spectrally remote noise, whereas the maskers had no effect on the 7-year-olds or adults. Maskers of different bandwidth and remoteness had similar effects.
   Conclusions: In accord with psychoacoustic data, young children do not appear to focus on a spectral region of interest and ignore other regions during speech recognition. This tendency may help account for their typically poorer speech perception in noise. This study also appears to capture an important developmental stage, during which a substantial refinement in spectral listening occurs.
C1 [Youngdahl, Carla L.; Healy, Eric W.; Yoho, Sarah E.; Apoux, Frederic; Holt, Rachael Frush] Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA.
   [Youngdahl, Carla L.] Univ Notre Dame, St Marys Coll, Dept Communicat Sci & Disorders, Notre Dame, IN 46556 USA.
   [Yoho, Sarah E.] Utah State Univ, Dept Communicat Disorders & Deaf Educ, Logan, UT 84322 USA.
   [Apoux, Frederic] Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
RP Youngdahl, CL; Healy, EW (corresponding author), Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA.; Youngdahl, CL (corresponding author), Univ Notre Dame, St Marys Coll, Dept Communicat Sci & Disorders, Notre Dame, IN 46556 USA.
EM cyoungdahl@saintmarys.edu; healy.66@osu.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIDCD R01DC008594,
   R01 DC015521, R01 DC014956]; Ohio State University Alumni Grants for
   Graduate Research and Scholarship Program; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC008594, R01DC014956, R01DC008594, R01DC008594, R01DC014956,
   R01DC008594, R01DC015521, R01DC015521, R01DC008594, R01DC014956,
   R01DC015521, R01DC014956, R01DC014956, R01DC015521] Funding Source: NIH
   RePORTER
FX This work formed a portion of a dissertation submitted by the first
   author, under the direction of the second author, in partial fulfillment
   of degree requirements for the PhD in Speech and Hearing Science. This
   research was supported in part through grants from the National
   Institutes of Health (NIDCD R01DC008594 and R01 DC015521 to author Eric
   W. Healy and R01 DC014956 to author Rachael Frush Holt). Additional
   funding came from The Ohio State University Alumni Grants for Graduate
   Research and Scholarship Program to author Carla L. Youngdahl. Portions
   were presented at the 2015 Annual American Speech-Language-Hearing
   Association Convention and the 169th Meeting of the Acoustical Society
   of America. The authors thank Brittney Carter for assistance in
   collecting the data and Jordan Vasko for conducting the excitation
   pattern calculations and assisting with manuscript preparation.
CR *AM NAT STAND I, 1969, S351969 ANSI
   American National Standards Institute, 2010, S362010 ANSI
   American National Standards Institute, 2004, S3212004 ANSI
   Apoux F, 2009, HEARING RES, V255, P99, DOI 10.1016/j.heares.2009.06.005
   BARGONES JY, 1994, PSYCHOL SCI, V5, P170, DOI 10.1111/j.1467-9280.1994.tb00655.x
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Buss E, 1999, J SPEECH LANG HEAR R, V42, P844, DOI 10.1044/jslhr.4204.844
   Ciccia AH, 2009, TOP LANG DISORD, V29, P249, DOI 10.1097/TLD.0b013e3181b53211
   Clayton KK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157638
   Cohen L., 1988, STAT POWER ANAL BEHA
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Corbin NE, 2016, EAR HEARING, V37, P55, DOI 10.1097/AUD.0000000000000201
   DAI HP, 1991, J ACOUST SOC AM, V89, P2837, DOI 10.1121/1.400721
   Eisenberg LS, 2000, J ACOUST SOC AM, V107, P2704, DOI 10.1121/1.428656
   ELLIOTT LL, 1980, J ACOUST SOC AM, V67, P343, DOI 10.1121/1.383746
   ELLIOTT LL, 1979, J ACOUST SOC AM, V66, P12, DOI 10.1121/1.383065
   ELLIOTT LL, 1981, PERCEPT PSYCHOPHYS, V30, P411, DOI 10.3758/BF03204836
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   GREENBERG GZ, 1968, J ACOUST SOC AM, V44, P1513, DOI 10.1121/1.1911290
   GREENBERG GZ, 1970, PERCEPT PSYCHOPHYS, V8, P173, DOI 10.3758/BF03210199
   Hall JW, 2002, EAR HEARING, V23, P159, DOI 10.1097/00003446-200204000-00008
   HALL JW, 1991, J SPEECH HEAR RES, V34, P651, DOI 10.1044/jshr.3403.651
   HARTMANN WM, 1988, J ACOUST SOC AM, V83, P2277, DOI 10.1121/1.396358
   Healy EW, 2006, J ACOUST SOC AM, V119, P1083, DOI 10.1121/1.2162176
   IRWIN RJ, 1986, J EXP CHILD PSYCHOL, V41, P429, DOI 10.1016/0022-0965(86)90003-2
   Ison JR, 2002, J ACOUST SOC AM, V112, P238, DOI 10.1121/1.1483321
   Johnson CE, 2000, J SPEECH LANG HEAR R, V43, P144, DOI 10.1044/jslhr.4301.144
   Kohlrausch A, 1997, ACUSTICA, V83, P659
   Leibold LJ, 2007, J ACOUST SOC AM, V121, P3666, DOI 10.1121/1.2723664
   Leibold LJ, 2006, J ACOUST SOC AM, V119, P3960, DOI 10.1121/1.2200150
   Leibold LJ, 2016, J ACOUST SOC AM, V140, P4367, DOI 10.1121/1.4971780
   Leibold LJ, 2016, EAR HEARING, V37, P345, DOI 10.1097/AUD.0000000000000270
   Leibold LJ, 2011, EAR HEARING, V32, P663, DOI 10.1097/AUD.0b013e31820e5074
   Litovsky RY, 2005, J ACOUST SOC AM, V117, P3091, DOI 10.1121/1.1873913
   McGhee RL, 2007, TOKEN TEST CHILDREN
   Moore BCJ, 1997, J AUDIO ENG SOC, V45, P224
   National Center for Education Statistics, 1993, CHAR PUBL SCH KIND S
   Newman RS, 2013, J ACOUST SOC AM, V133, pEL377, DOI 10.1121/1.4798269
   Nittrouer S, 2014, EAR HEARING, V35, P506, DOI 10.1097/AUD.0000000000000051
   Oh EL, 2001, J ACOUST SOC AM, V109, P2888, DOI 10.1121/1.1371764
   OLSHO LW, 1985, INFANT BEHAV DEV, V8, P371, DOI 10.1016/0163-6383(85)90002-5
   PAPSO CF, 1989, EAR HEARING, V10, P235, DOI 10.1097/00003446-198908000-00004
   Plebanek DJ, 2017, PSYCHOL SCI, V28, P723, DOI 10.1177/0956797617693005
   Polka L, 2008, INFANCY, V13, P421, DOI 10.1080/15250000802329297
   PUMPLIN J, 1985, J ACOUST SOC AM, V78, P100, DOI 10.1121/1.392571
   Roman AS, 2017, EAR HEARING, V38, P344, DOI 10.1097/AUD.0000000000000393
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   SCHARF B, 1987, PERCEPT PSYCHOPHYS, V42, P215, DOI 10.3758/BF03203073
   SCHLAUCH RS, 1991, J ACOUST SOC AM, V90, P1332, DOI 10.1121/1.401925
   SCHNEIDER BA, 1990, J EXP PSYCHOL HUMAN, V16, P642
   SODERQUIST DR, 1993, J EXP CHILD PSYCHOL, V56, P371, DOI 10.1006/jecp.1993.1040
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Ubiali T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148360
   van Dinteren R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087347
   WERNER LA, 1991, PERCEPT PSYCHOPHYS, V50, P405, DOI 10.3758/BF03205057
   Wightman FL, 2005, J ACOUST SOC AM, V118, P3164, DOI 10.1121/1.2082567
NR 56
TC 4
Z9 4
U1 1
U2 8
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2018
VL 61
IS 2
BP 420
EP 427
DI 10.1044/2017_JSLHR-H-17-0118
PG 8
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FY2GZ
UT WOS:000426634800016
PM 29396579
OA Green Published
DA 2021-02-24
ER

PT J
AU Scharenborg, O
   Coumans, JMJ
   van Hout, R
AF Scharenborg, Odette
   Coumans, Juul M. J.
   van Hout, Roeland
TI The Effect of Background Noise on the Word Activation Process in
   Nonnative Spoken-Word Recognition
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE nonnative spoken-word recognition; noise; competitor space; proficiency;
   inhibition ability
ID SPEECH-PERCEPTION; NEIGHBORHOOD DENSITY; TIME-COURSE; LISTENERS;
   ENGLISH; IDENTIFICATION; INFORMATION; COMPETITION; CONSONANTS; MODEL
AB This article investigates 2 questions: (1) does the presence of background noise lead to a differential increase in the number of simultaneously activated candidate words in native and nonnative listening? And (2) do individual differences in listeners' cognitive and linguistic abilities explain the differential effect of background noise on (non-) native speech recognition? English and Dutch students participated in an English word recognition experiment, in which either a word's onset or offset was masked by noise. The native listeners outperformed the nonnative listeners in all listening conditions. Importantly, however, the effect of noise on the multiple activation process was found to be remarkably similar in native and nonnative listening. The presence of noise increased the set of candidate words considered for recognition in both native and nonnative listening. The results indicate that the observed performance differences between the English and Dutch listeners should not be primarily attributed to a differential effect of noise, but rather to the difference between native and nonnative listening. Additional analyses showed that word-initial information was found to be more important than word-final information during spoken-word recognition. When word-initial information was no longer reliably available word recognition accuracy dropped and word frequency information could no longer be used suggesting that word frequency information is strongly tied to the onset of words and the earliest moments of lexical access. Proficiency and inhibition ability were found to influence nonnative spoken-word recognition in noise, with a higher proficiency in the nonnative language and worse inhibition ability leading to improved recognition performance.
C1 [Scharenborg, Odette; Coumans, Juul M. J.; van Hout, Roeland] Radboud Univ Nijmegen, Ctr Language Studies, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.
   [Scharenborg, Odette] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Coumans, Juul M. J.] Univ Med Ctr Utrecht, Brain Ctr Rudolf Magnus, Utrecht, Netherlands.
RP Scharenborg, O (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.
EM o.scharenborg@let.ru.nl
RI Coumans, Juul/ABC-3203-2020
OI Coumans, Juul M.J./0000-0001-9945-1263
FU Netherlands Organization for Scientific ResearchNetherlands Organization
   for Scientific Research (NWO) [276-89-003]
FX This research is supported by Vidi Grant 276-89-003 from the Netherlands
   Organization for Scientific Research awarded to Odette Scharenborg.
CR Akaike H., 1973, BREAKTHROUGHS STAT, V1, P610, DOI [10.1007/978-1-4612-0919-5_38, DOI 10.1007/978-1-4612-1694-0_15]
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Aron AR, 2004, TRENDS COGN SCI, V8, P170, DOI 10.1016/j.tics.2004.02.010
   BAAYEN R, 1993, CELEX LEXICAL DATABA
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   Bialystok E, 2004, PSYCHOL AGING, V19, P290, DOI 10.1037/0882-7974.19.2.290
   Bialystok E., 2001, BILINGUALISM DEV LAN
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bohn O.-S., 2007, LANGUAGE EXPERIENCE
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Broersma M, 2012, LANG COGNITIVE PROC, V27, P1205, DOI 10.1080/01690965.2012.660170
   Broersma M, 2010, SPEECH COMMUN, V52, P980, DOI 10.1016/j.specom.2010.08.010
   Brouwer S., 2011, LANGUAGE COGNITIVE P
   Brouwer S, 2016, J PSYCHOLINGUIST RES, V45, P1151, DOI 10.1007/s10936-015-9396-9
   Brouwer S, 2012, J ACOUST SOC AM, V131, P1449, DOI 10.1121/1.3675943
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Chan KY, 2015, J EXP PSYCHOL HUMAN, V41, P69, DOI 10.1037/a0038347
   Clements G. N., 1990, PAPERS LAB PHONOLOGY, P283, DOI DOI 10.1017/CBO9780511627736.017
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Cooke M, 2010, SPEECH COMMUN, V52, P954, DOI 10.1016/j.specom.2010.04.004
   Cooke M, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1847
   Coumans J, 2014, INTERSPEECH, P519
   Cutler A, 2006, J PHONETICS, V34, P269, DOI 10.1016/j.wocn.2005.06.002
   Cutler A, 2008, J ACOUST SOC AM, V124, P1264, DOI 10.1121/1.2946707
   Cutler A, 2012, DUTCH J APPL LINGUIS, V1, P169, DOI 10.1075/dujal.1.2.02cut
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Drozdova P., 2015, P 18 INT C PHON SCI
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Ezzatian P, 2010, SPEECH COMMUN, V52, P919, DOI 10.1016/j.specom.2010.04.001
   Farris-Trimble A, 2014, J EXP PSYCHOL HUMAN, V40, P308, DOI 10.1037/a0034353
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   GOLDINGER SD, 1989, J MEM LANG, V28, P501, DOI 10.1016/0749-596X(89)90009-0
   GOW DW, 1995, J EXP PSYCHOL HUMAN, V21, P344, DOI 10.1037/0096-1523.21.2.344
   Gussenhoven C., 2011, UNDERSTANDING PHONOL
   Hintz F, 2016, INTERSPEECH, P2816, DOI 10.21437/Interspeech.2016-882
   Imai S, 2005, J ACOUST SOC AM, V117, P896, DOI 10.1121/1.1823291
   Kilman L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00651
   Krizman J., 2016, BILINGUALISM LANGUAG
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McQueen J. M, 2005, HDB COGNITION, P255, DOI DOI 10.4135/9781848608177.N11
   McQueen JM, 2012, J ACOUST SOC AM, V131, P509, DOI 10.1121/1.3664087
   Meador D, 2000, BILING-LANG COGN, V3, P55, DOI DOI 10.1017/S1366728900000134
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   R Core Team, 2017, R LANGUAGE ENV STAT
   Ridderinkhof KR, 2002, ATTENTION PERFORM, V19, P494
   Scharenborg O., 2017, INVESTIGATING RELATI
   Scharenborg O, 2016, INTERSPEECH, P863, DOI 10.21437/Interspeech.2016-19
   Scharenborg O, 2016, INTERSPEECH, P858, DOI 10.21437/Interspeech.2016-1095
   Scharenborg O, 2010, J ACOUST SOC AM, V127, P3758, DOI 10.1121/1.3377050
   Schock J, 2012, BEHAV RES METHODS, V44, P374, DOI 10.3758/s13428-011-0162-0
   Shi LF, 2010, J SPEECH LANG HEAR R, V53, P821, DOI 10.1044/1092-4388(2010/09-0081)
   Shimoda D., 2010, SCRABBLEFINDER
   Sikora K, 2016, Q J EXP PSYCHOL, V69, P1719, DOI 10.1080/17470218.2015.1093007
   SLOWIACZEK LM, 1987, J EXP PSYCHOL LEARN, V13, P64, DOI 10.1037/0278-7393.13.1.64
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Spivey MJ, 1999, PSYCHOL SCI, V10, P281, DOI 10.1111/1467-9280.00151
   van den Wildenberg WPM, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00222
   Van Son Rob J. J. H, 2003, P 25 I PHON SCI, V25, P171, DOI DOI 10.1177/1745691612459060
   van Wijngaarden SJ, 2002, J ACOUST SOC AM, V111, P1906, DOI 10.1121/1.1456928
   VANDERVLUGT MJ, 1987, J ACOUST SOC AM, V81, pS2, DOI 10.1121/1.2024178
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   ZWITSERLOOD P, 1989, COGNITION, V32, P25, DOI 10.1016/0010-0277(89)90013-9
NR 74
TC 10
Z9 10
U1 0
U2 2
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD FEB
PY 2018
VL 44
IS 2
BP 233
EP 249
DI 10.1037/xlm0000441
PG 17
WC Psychology; Psychology, Experimental
SC Psychology
GA FX4JQ
UT WOS:000426041200005
PM 28782967
DA 2021-02-24
ER

PT J
AU Specht, K
   Wigglesworth, P
AF Specht, Karsten
   Wigglesworth, Philip
TI The functional and structural asymmetries of the superior temporal
   sulcus
SO SCANDINAVIAN JOURNAL OF PSYCHOLOGY
LA English
DT Article
DE Superior temporal sulcus; asymmetry; speech perception; audiovisual
   integration; theory of mind; fMRI; anatomy
ID CARD SORTING TEST; SPEECH-PERCEPTION; BIOLOGICAL MOTION; INTERINDIVIDUAL
   DIFFERENCES; AUDITORY-PERCEPTION; PREMOTOR CORTEX; NONVERBAL TASK; BRAIN
   ACTIVITY; FMRI; VOICE
AB The superior temporal sulcus (STS) is an anatomical structure that increasingly interests researchers. This structure appears to receive multisensory input and is involved in several perceptual and cognitive core functions, such as speech perception, audiovisual integration, (biological) motion processing and theory of mind capacities. In addition, the superior temporal sulcus is not only one of the longest sulci of the brain, but it also shows marked functional and structural asymmetries, some of which have only been found in humans. To explore the functional-structural relationships of these asymmetries in more detail, this study combines functional and structural magnetic resonance imaging. Using a speech perception task, an audiovisual integration task, and a theory of mind task, this study again demonstrated an involvement of the STS in these processes, with an expected strong leftward asymmetry for the speech perception task. Furthermore, this study confirmed the earlier described, human-specific asymmetries, namely that the left STS is longer than the right STS and that the right STS is deeper than the left STS. However, this study did not find any relationship between these structural asymmetries and the detected brain activations or their functional asymmetries. This can, on the other hand, give further support to the notion that the structural asymmetry of the STS is not directly related to the functional asymmetry of the speech perception and the language system as a whole, but that it may have other causes and functions.
C1 [Specht, Karsten] Univ Bergen, Dept Biol & Med Psychol, Bergen, Norway.
   [Specht, Karsten] UiT, Dept Educ, Tromso, Norway.
   [Wigglesworth, Philip] Dept Behav Sci, Oslo, Norway.
   [Wigglesworth, Philip] Akershus Univ, Coll Appl Sci, Oslo, Norway.
RP Specht, K (corresponding author), Univ Bergen, Bergen fMRI Grp, Bergen Res Grp Auditory Percept, Dept Biol & Med Psychol, Jonas Lies Vei 91, N-5009 Bergen, Norway.
EM karsten.specht@uib.no
RI Specht, Karsten/C-3762-2009
OI Specht, Karsten/0000-0002-9946-3704
FU Bergen Research Foundation; Research Council of NorwayResearch Council
   of Norway [217932]
FX We thank all participants for their participation and the staff of the
   radiological department of the Haukeland University Hospital for their
   help during data acquisition. The study was supported by a grant to KS
   from the Bergen Research Foundation (When a sound becomes speech) and
   the Research Council of Norway (217932: It's time for some music).
CR Alho K, 2006, BRAIN RES, V1075, P142, DOI 10.1016/j.brainres.2005.11.103
   Baron-Cohen S, 1999, EUR J NEUROSCI, V11, P1891, DOI 10.1046/j.1460-9568.1999.00621.x
   Beauchamp MS, 2015, TRENDS COGN SCI, V19, P489, DOI 10.1016/j.tics.2015.07.002
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Binder JR, 2011, NEUROIMAGE, V54, P1465, DOI 10.1016/j.neuroimage.2010.09.048
   Binder JR, 1996, BRAIN, V119, P1239, DOI 10.1093/brain/119.4.1239
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Brunet E, 2000, NEUROIMAGE, V11, P157, DOI 10.1006/nimg.1999.0525
   Brunet E, 2003, NEUROPSYCHOLOGIA, V41, P1574, DOI 10.1016/S0028-3932(03)00119-2
   Calvert GA, 2001, NEUROIMAGE, V14, P427, DOI 10.1006/nimg.2001.0812
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Castelli F, 2002, BRAIN, V125, P1839, DOI 10.1093/brain/awf189
   Deen B, 2015, CEREB CORTEX, V25, P4596, DOI 10.1093/cercor/bhv111
   Dodell-Feder D, 2011, NEUROIMAGE, V55, P705, DOI 10.1016/j.neuroimage.2010.12.040
   Flack TR, 2015, CORTEX, V69, P14, DOI 10.1016/j.cortex.2015.03.002
   FLETCHER PC, 1995, COGNITION, V57, P109, DOI 10.1016/0010-0277(95)00692-R
   Friston KJ, 2005, NEUROIMAGE, V25, P661, DOI 10.1016/j.neuroimage.2005.01.013
   Friston KJ, 1999, NEUROIMAGE, V10, P385, DOI 10.1006/nimg.1999.0484
   Frith U, 2003, PHILOS T R SOC B, V358, P459, DOI 10.1098/rstb.2002.1218
   Gallagher HL, 2003, TRENDS COGN SCI, V7, P77, DOI 10.1016/S1364-6613(02)00025-6
   Glasel H, 2011, NEUROIMAGE, V58, P716, DOI 10.1016/j.neuroimage.2011.06.016
   Goel V, 2007, TRENDS COGN SCI, V11, P435, DOI 10.1016/j.tics.2007.09.003
   Greimel E, 2013, BRAIN STRUCT FUNCT, V218, P929, DOI 10.1007/s00429-012-0439-9
   Han ZZ, 2013, J NEUROSCI, V33, P15442, DOI 10.1523/JNEUROSCI.5868-12.2013
   Hein G, 2008, J COGNITIVE NEUROSCI, V20, P2125, DOI 10.1162/jocn.2008.20148
   Herrington JD, 2011, BRAIN COGNITION, V77, P372, DOI 10.1016/j.bandc.2011.09.001
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hugdahl K., 2015, FRONT HUM NEUROSCI, V9, P1
   Im K, 2010, CEREB CORTEX, V20, P602, DOI 10.1093/cercor/bhp127
   Jancke L, 2002, NEUROIMAGE, V15, P733, DOI 10.1006/nimg.2001.1027
   Kasprian G, 2011, CEREB CORTEX, V21, P1076, DOI 10.1093/cercor/bhq179
   Latinus M, 2011, CURR BIOL, V21, pR143, DOI 10.1016/j.cub.2010.12.033
   Laurita AC, 2017, SOC COGN AFFECT NEUR, V12, P1072, DOI 10.1093/scan/nsx040
   Leroy F, 2015, P NATL ACAD SCI USA, V112, P1208, DOI 10.1073/pnas.1412389112
   Lie CH, 2006, NEUROIMAGE, V30, P1038, DOI 10.1016/j.neuroimage.2005.10.031
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   McGettigan C, 2012, TRENDS COGN SCI, V16, P269, DOI 10.1016/j.tics.2012.04.006
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Noesselt T, 2007, J NEUROSCI, V27, P11431, DOI 10.1523/JNEUROSCI.2252-07.2007
   Noesselt T, 2012, FRONT INTEGR NEUROSC, V6, DOI 10.3389/fnint.2012.00064
   Ochiai T, 2004, NEUROIMAGE, V22, P706, DOI 10.1016/j.neuroimage.2004.01.023
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Osnes B, 2012, BRAIN LANG, V121, P65, DOI 10.1016/j.bandl.2012.02.002
   Osnes B, 2011, BRAIN LANG, V116, P97, DOI 10.1016/j.bandl.2010.10.001
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Price C, 2005, TRENDS COGN SCI, V9, P271, DOI 10.1016/j.tics.2005.03.009
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Puce A, 2003, PHILOS T R SOC B, V358, P435, DOI 10.1098/rstb.2002.1221
   Saito DN, 2005, CEREB CORTEX, V15, P1750, DOI 10.1093/cercor/bhi052
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Scott SK, 2005, CURR OPIN NEUROBIOL, V15, P197, DOI 10.1016/j.conb.2005.03.009
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Segal E, 2012, EUR J NEUROSCI, V36, P2035, DOI 10.1111/j.1460-9568.2012.08109.x
   Sokolov AA, 2012, NEUROIMAGE, V59, P2824, DOI 10.1016/j.neuroimage.2011.08.039
   Specht K, 2005, NEUROSCI LETT, V384, P60, DOI 10.1016/j.neulet.2005.04.057
   Specht K, 2003, NEUROIMAGE, V20, P1944, DOI 10.1016/j.neuroimage.2003.07.034
   Specht K, 2014, HEARING RES, V307, P121, DOI 10.1016/j.heares.2013.09.011
   Specht K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00629
   Specht K, 2009, HUM BRAIN MAPP, V30, P3436, DOI 10.1002/hbm.20768
   Specht K, 2009, HUM BRAIN MAPP, V30, P1734, DOI 10.1002/hbm.20637
   Stevenson RA, 2007, EXP BRAIN RES, V179, P85, DOI 10.1007/s00221-006-0770-6
   Sugranyes G, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025322
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Tettamanti M, 2017, NEUROIMAGE, V155, P169, DOI 10.1016/j.neuroimage.2017.04.050
   Uno T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122580
   Vander Wyk BC, 2012, DEV COGN NEUROS-NETH, V2, P409, DOI 10.1016/j.dcn.2012.04.004
   Vollm BA, 2006, NEUROIMAGE, V29, P90, DOI 10.1016/j.neuroimage.2005.07.022
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
   Westerhausen R, 2011, CEREB CORTEX, V21, P1012, DOI 10.1093/cercor/bhq165
   Westerhausen R, 2009, CEREB CORTEX, V19, P1322, DOI 10.1093/cercor/bhn173
   White SJ, 2014, NEUROPSYCHOLOGIA, V56, P17, DOI 10.1016/j.neuropsychologia.2013.12.013
NR 74
TC 7
Z9 7
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0036-5564
EI 1467-9450
J9 SCAND J PSYCHOL
JI Scand. J. Psychol.
PD FEB
PY 2018
VL 59
IS 1
SI SI
BP 74
EP 82
DI 10.1111/sjop.12410
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA FX4IV
UT WOS:000426038300010
PM 29356006
OA Green Published, Green Accepted, Other Gold
DA 2021-02-24
ER

PT J
AU Fostick, L
   Revah, H
AF Fostick, Leah
   Revah, Hadas
TI Dyslexia as a multi-deficit disorder: Working memory and auditory
   temporal processing
SO ACTA PSYCHOLOGICA
LA English
DT Article
DE Dyslexia; Working memory (WM); Auditory temporal processing (ATP)
ID SHORT-TERM-MEMORY; ATTENTION DEFICIT/HYPERACTIVITY DISORDER;
   PHONOLOGICAL AWARENESS DEFICITS; READING-DISABILITY DYSLEXIA; TO-PHONEME
   CONVERSION; DEVELOPMENTAL DYSLEXIA; LANGUAGE IMPAIRMENT;
   SPEECH-PERCEPTION; FREQUENCY DISCRIMINATION; SPEAKING CHILDREN
AB Dyslexia is difficulty in acquiring reading skills despite adequate intelligence and sufficient reading opportunities. Its origin is still under debate. Studies usually focus on a singular cause for dyslexia; however, some researchers argue that dyslexia reflects multiple deficits. Two of the abilities under investigation in dyslexia are working memory (WM) and auditory temporal processing (ATP). In order to better evaluate the relative roles of WM and ATP in dyslexia, in the present study, we tested the contribution of WM and ATP to different types of reading performance and phonological awareness in dyslexia, using a multidimensional approach. Seventy-eight adults with dyslexia and 23 normal-reading adults performed WM and ATP tasks, as well as reading and phonological awareness tests. Readers with dyslexia showed poorer performance on all tests. Both WM and ATP were significant predictors of reading performance and phonological awareness among participants with dyslexia. Dividing participants with dyslexia according to their performance level on WM and ATP tasks revealed group differences in reading and phonological awareness tests. Both WM and ATP contribute to dyslexia, and varying levels of difficulties in both of these abilities are observed among this population. This is strong evidence in favor of the multi-deficit approach in dyslexia, and suggests that researchers should consider this approach in future studies of dyslexia.
C1 [Fostick, Leah] Ariel Univ, Dept Commun Disorders, IL-40700 Ariel, Israel.
   [Revah, Hadas] Ariel Univ, Dept Psychol, Ariel, Israel.
RP Fostick, L (corresponding author), Ariel Univ, Dept Commun Disorders, IL-40700 Ariel, Israel.
EM leah.fostick@ariel.ac.il
RI Fostick, Leah/E-6115-2017
OI Fostick, Leah/0000-0003-3594-6229
CR Adams M., 1990, BEGINNING READ THINK
   Ahissar M, 2000, P NATL ACAD SCI USA, V97, P6832, DOI 10.1073/pnas.97.12.6832
   Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   American Psychiatric Association, 1994, DIAGN STAT MAN MENT, V4th
   Auclair-Ouellet N, 2013, BEHAV NEUROL, V26, P171, DOI [10.1155/2013/128124, 10.3233/BEN-2012-129003]
   Babkoff H, 2013, ATTEN PERCEPT PSYCHO, V75, P654, DOI 10.3758/s13414-013-0449-6
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Banai K, 2004, AUDIOL NEURO-OTOL, V9, P328, DOI 10.1159/000081282
   Banai K, 2006, CEREB CORTEX, V16, P1718, DOI 10.1093/cercor/bhj107
   Banai K, 2010, DYSLEXIA, V16, P240, DOI 10.1002/dys.407
   Ben-Artzi E, 2005, NEUROPSYCHOLOGIA, V43, P714, DOI 10.1016/j.neuropsychologia.2004.08.004
   Berent I, 2013, COGN NEUROPSYCHOL, V30, P285, DOI 10.1080/02643294.2013.863182
   Berninger VW, 2008, J SCHOOL PSYCHOL, V46, P1, DOI 10.1016/j.jsp.2006.11.008
   Bishop DVM, 2005, CORTEX, V41, P327, DOI 10.1016/S0010-9452(08)70270-3
   Bishop DVM, 2004, DEVELOPMENTAL SCI, V7, pF11, DOI 10.1111/j.1467-7687.2004.00356.x
   Blachman B. A., 2000, HDB READING RES, V3, P483
   Boothroyd A, 1997, SCAND AUDIOL, V26, P9
   Brambati SM, 2006, BRAIN RES, V1113, P174, DOI 10.1016/j.brainres.2006.06.099
   Breier JI, 2001, J EXP CHILD PSYCHOL, V80, P245, DOI 10.1006/jecp.2001.2630
   BRUCK M, 1992, DEV PSYCHOL, V28, P874, DOI 10.1037/0012-1649.28.5.874
   BRUCK M, 1990, DEV PSYCHOL, V26, P439, DOI 10.1037/0012-1649.26.3.439
   Chait M, 2007, BRAIN LANG, V102, P80, DOI 10.1016/j.bandl.2006.07.001
   Coltheart M, 2017, HDB COMMUNI IN PRESS
   Dandache S, 2014, DYSLEXIA, V20, P305, DOI 10.1002/dys.1482
   ELBRO C, 1994, ANN DYSLEXIA, V44, P205, DOI 10.1007/BF02648162
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Fisher C, 2015, DYSLEXIA, V21, P350, DOI 10.1002/dys.1504
   Fostick L, 2012, PSYCHOL RES, V2, P77
   Fostick L., 2012, PSYCHOL RES, V2, P308, DOI DOI 10.17265/2159-5542/2012.05.004
   Fostick L, 2014, J EXP PSYCHOL HUMAN, V40, P1799, DOI 10.1037/a0037527
   Fostick L, 2014, J SPEECH LANG HEAR R, V57, P1078, DOI 10.1044/1092-4388(2013/13-0031)
   Fostick L, 2013, EXP PSYCHOL, V60, P432, DOI 10.1027/1618-3169/a000216
   Francks C, 2002, LANCET NEUROL, V1, P483, DOI 10.1016/S1474-4422(02)00221-1
   FROST R, 1994, J EXP PSYCHOL LEARN, V20, P116, DOI 10.1037/0278-7393.20.1.116
   Garcia RB, 2014, BRIT J DEV PSYCHOL, V32, P17, DOI 10.1111/bjdp.12019
   Gathercole SE, 2005, J CHILD PSYCHOL PSYC, V46, P598, DOI 10.1111/j.1469-7610.2004.00379.x
   Gathercole SE, 2000, BRIT J EDUC PSYCHOL, V70, P177, DOI 10.1348/000709900158047
   Gori S, 2015, CEREB CORTEX, V25, P1685, DOI 10.1093/cercor/bhu234
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Gvion A, 2010, PROCD SOC BEHV, V6, P145, DOI 10.1016/j.sbspro.2010.08.072
   Heath SM, 2004, J SPEECH LANG HEAR R, V47, P751, DOI 10.1044/1092-4388(2004/057)
   Heim S, 2001, NEUROREPORT, V12, P507, DOI 10.1097/00001756-200103050-00016
   Jeffries S, 2004, DYSLEXIA, V10, P196, DOI 10.1002/dys.278
   Keen AG, 2000, VISION RES, V40, P705, DOI 10.1016/S0042-6989(99)00208-4
   Kibby M, 2008, CHILD NEUROPSYCHOL, V14, P525, DOI 10.1080/09297040701821752
   Lallier M, 2013, COGNITION, V126, P121, DOI 10.1016/j.cognition.2012.09.008
   Landerl K, 2000, APPL PSYCHOLINGUIST, V21, P243, DOI 10.1017/S0142716400002058
   Layes S, 2015, DYSLEXIA, V21, P80, DOI 10.1002/dys.1491
   LEVINTHAL CF, 1992, READ WRIT, V4, P231, DOI 10.1007/BF01027149
   LOVEGROVE WJ, 1980, SCIENCE, V210, P439, DOI 10.1126/science.7433985
   Maughan B, 2009, J CHILD PSYCHOL PSYC, V50, P893, DOI 10.1111/j.1469-7610.2009.02079.x
   MAUGHAN B, 1994, READ WRIT, V6, P125, DOI 10.1007/BF01026909
   Mayringer H, 2000, J EXP CHILD PSYCHOL, V75, P116, DOI 10.1006/jecp.1999.2525
   McArthur GM, 2004, COGN NEUROPSYCHOL, V21, P79, DOI 10.1080/02643290342000087
   Menghini D, 2011, DEV NEUROPSYCHOL, V36, P199, DOI 10.1080/87565641.2010.549868
   Meyler A, 2005, DYSLEXIA, V11, P93, DOI 10.1002/dys.294
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Nelson JM, 2015, J LEARN DISABIL-US, V48, P422, DOI 10.1177/0022219413507604
   Nicolson RI, 2001, TRENDS NEUROSCI, V24, P508, DOI 10.1016/S0166-2236(00)01896-8
   NICOLSON RI, 1990, COGNITION, V35, P159, DOI 10.1016/0010-0277(90)90013-A
   Oganian Y, 2012, NEUROPSYCHOLOGIA, V50, P1895, DOI 10.1016/j.neuropsychologia.2012.04.014
   OLOFSSON A, 2002, DYSLEXIA LITERACY, P151
   PENNINGTON BF, 1990, CHILD DEV, V61, P1753, DOI 10.2307/1130836
   Perfetti Charles A., 1992, READING ACQUISITION, P145, DOI DOI 10.4324/9781351236904-6
   Ram-Tsur R, 2006, VISION RES, V46, P3949, DOI 10.1016/j.visres.2006.07.001
   Ram-Tsur R, 2008, J LEARN DISABIL-US, V41, P437, DOI 10.1177/0022219408321141
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Reid AA, 2007, DYSLEXIA, V13, P1, DOI 10.1002/dys.321
   Richardson FM, 2011, J COGNITIVE NEUROSCI, V23, P3746, DOI 10.1162/jocn_a_00060
   RODGERS B, 1986, BRIT J DEV PSYCHOL, V4, P1, DOI 10.1111/j.2044-835X.1986.tb00993.x
   Schaadt G., 2016, DEVELOPMENTAL SCI, V19, P1010
   Schwarb H, 2016, PSYCHOL RES-PSYCH FO, V80, P128, DOI 10.1007/s00426-015-0648-y
   SHALEM Z, 1998, DIAGNOSTIC BATTERY R
   Share DL, 1995, ISSUES ED CONTRIBUTI, V1, P1, DOI DOI 10.1111/J.1467-9817.1995.TB00075.X
   Shatil E., 1995, ONE MINUTE TES UNPUB
   Shatil E., 1995, PIG LATIN UNPUB
   Shatil E., 1995, SPOONERISM UNPUB
   SHAYWITZ SE, 1992, NEW ENGL J MED, V326, P145, DOI 10.1056/NEJM199201163260301
   Shaywitz SE, 1996, SCI AM, V275, P98, DOI 10.1038/scientificamerican1196-98
   Shaywitz SE, 1999, PEDIATRICS, V104, P1351, DOI 10.1542/peds.104.6.1351
   SIEGEL LS, 1995, PSYCHOL SCI, V6, P250, DOI 10.1111/j.1467-9280.1995.tb00601.x
   Snowling M., 2000, DYSLEXIA
   Snowling M.J., 1995, J RES READ, V18, P132, DOI [10.1111/j.1467-9817.1995.tb00079.x, DOI 10.1111/J.1467-9817.1995.TB00079.X]
   Snowling MJ, 2007, J CHILD PSYCHOL PSYC, V48, P609, DOI 10.1111/j.1469-7610.2006.01725.x
   SNOWLING MJ, 1981, PSYCHOL RES-PSYCH FO, V43, P219, DOI 10.1007/BF00309831
   STANOVICH KE, 1991, PSYCHOL SCI, V2, P70, DOI 10.1111/j.1467-9280.1991.tb00103.x
   Stein J, 1997, TRENDS NEUROSCI, V20, P147, DOI 10.1016/S0166-2236(96)01005-3
   Stein J., 2001, DYSLEXIA THEORY GOOD, P65
   Stoodley CJ, 2013, CEREBELLUM, V12, P267, DOI 10.1007/s12311-012-0407-1
   Taitelbaum-Swead R., 2017, CLIN LINGUI IN PRESS
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tanaka H, 2011, PSYCHOL SCI, V22, P1442, DOI 10.1177/0956797611419521
   Tholen N, 2011, DYSLEXIA, V17, P268, DOI 10.1002/dys.434
   Undheim AM, 2009, DYSLEXIA, V15, P291, DOI 10.1002/dys.384
   VALLAR G, 1984, COGNITIVE NEUROPSYCH, V1, P121, DOI 10.1080/02643298408252018
   Varvara P, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00120
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Verhagen J, 2016, J EXP CHILD PSYCHOL, V141, P65, DOI 10.1016/j.jecp.2015.06.015
   Wang ZK, 2014, DYSLEXIA, V20, P280, DOI 10.1002/dys.1475
   Wechsler D., 1997, WESCHSLER ADULT INTE
   Wijnen F, 2012, J SPEECH LANG HEAR R, V55, P1387, DOI 10.1044/1092-4388(2012/10-0302)
   Witton C, 1998, CURR BIOL, V8, P791, DOI 10.1016/S0960-9822(98)70320-3
   Wolf M, 1999, J EDUC PSYCHOL, V91, P415, DOI 10.1037/0022-0663.91.3.415
   Wright BA, 2004, P NATL ACAD SCI USA, V101, P9942, DOI 10.1073/pnas.0401825101
   Wright BA, 2000, CURR OPIN NEUROBIOL, V10, P482, DOI 10.1016/S0959-4388(00)00119-7
   Wybrow DP, 2015, COGN NEUROPSYCHOL, V32, P1, DOI 10.1080/02643294.2014.998185
   YAP R, 1993, READ WRIT, V5, P261, DOI 10.1007/BF01027391
   Zhao J, 2015, DYSLEXIA, V21, P304, DOI 10.1002/dys.1516
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 112
TC 15
Z9 15
U1 2
U2 30
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0001-6918
EI 1873-6297
J9 ACTA PSYCHOL
JI Acta Psychol.
PD FEB
PY 2018
VL 183
BP 19
EP 28
DI 10.1016/j.actpsy.2017.12.010
PG 10
WC Psychology, Experimental
SC Psychology
GA FW8HT
UT WOS:000425573000003
PM 29304447
DA 2021-02-24
ER

PT J
AU Alemi, R
   Batouli, SAH
   Behzad, E
   Ebrahimpoor, M
   Oghabian, MA
AF Alemi, Razieh
   Batouli, Seyed Amir Hossein
   Behzad, Ebrahim
   Ebrahimpoor, Mitra
   Oghabian, Mohammad Ali
TI Not single brain areas but a network is involved in language:
   Applications in presurgical planning
SO CLINICAL NEUROLOGY AND NEUROSURGERY
LA English
DT Article
DE Functional magnetic resonance imaging; Language template; Normal
   population; Presurgical planning
ID INDEPENDENT COMPONENT ANALYSIS; MONKEY RETROSPLENIAL CORTEX;
   FUNCTIONAL-ANATOMY; SPEECH-PERCEPTION; NEURAL BASIS; BROCAS AREA;
   SENSORIMOTOR INTEGRATION; HEMISPHERIC DOMINANCE; POSTERIOR CINGULATE;
   SEMANTIC KNOWLEDGE
AB Objectives: Language is an important human function, and is a determinant of the quality of life. In conditions such as brain lesions, disruption of the language function may occur, and lesion resection is a solution for that. Presurgical planning to determine the language-related brain areas would enhance the chances of language preservation after the operation; however, availability of a normative language template is essential.
   Patients and Methods: In this study, using data from 60 young individuals who were meticulously checked for mental and physical health, and using fMRI and robust imaging and data analysis methods, functional brain maps for the language production, perception and semantic Were produced.
   Results: The obtained templates showed that the language function should be considered as the product of the collaboration of a network of brain regions, instead of considering only few brain areas to be involved in that.
   Conclusion: This study has important clinical applications, and extends our knowledge on the neuroanatomy of the language function.
C1 [Alemi, Razieh; Batouli, Seyed Amir Hossein; Behzad, Ebrahim] Univ Tehran Med Sci, Sch Adv Technol Med, Dept Neurosci & Addict Studies, Tehran, Iran.
   [Alemi, Razieh] McGill Univ, Dept Otorhinolaryngol, Fac Med, Montreal, PQ, Canada.
   [Batouli, Seyed Amir Hossein; Ebrahimpoor, Mitra; Oghabian, Mohammad Ali] Univ Tehran Med Sci, Neuroimaging & Anal Grp, Tehran, Iran.
   [Oghabian, Mohammad Ali] Univ Tehran Med Sci, Med Phys & Biomed Engn Dept, Tehran, Iran.
RP Oghabian, MA (corresponding author), Univ Tehran Med Sci, Res Ctr Cellular & Mol Imaging RCMCI, Neuroimaging & Anal Grp NIAG, Tehran, Iran.
EM oghabian@sina.tums.ac.ir
RI Batouli, Seyed Amir Hossein/AAJ-9845-2020; Ebrahimpoor,
   Mitra/G-7859-2019
OI Batouli, Seyed Amir Hossein/0000-0002-9157-4522; Ebrahimpoor,
   Mitra/0000-0002-2299-876X
FU Iranian Cognitive Sciences and Technologies council [875]
FX This research was performed with the financial support of the Iranian
   Cognitive Sciences and Technologies council (grant number: 875).
CR Amunts K, 2012, TRENDS COGN SCI, V16, P418, DOI 10.1016/j.tics.2012.06.005
   Amunts K, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000489
   Ardila A, 2016, ARCH CLIN NEUROPSYCH, V31, P112, DOI 10.1093/arclin/acv081
   ASFNR Language Functional MRI Paradigms (ASFNR), 2017, AM SOC FUNCT NEUR
   Baciu M, 2005, EUR J RADIOL, V55, P209, DOI 10.1016/j.ejrad.2004.11.004
   Batouli SAH, 2016, PHYS MEDICA, V32, P1201, DOI 10.1016/j.ejmp.2016.06.008
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Bernal B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00687
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Binder JR, 2015, NEUROLOGY, V85, P2170, DOI 10.1212/WNL.0000000000002219
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Bohsali AA, 2015, BRAIN LANG, V141, P80, DOI 10.1016/j.bandl.2014.12.001
   Bookheimer S, 2002, ANNU REV NEUROSCI, V25, P151, DOI 10.1146/annurev.neuro.25.112701.142946
   Booth JR, 2003, J NEUROLINGUIST, V16, P383, DOI 10.1016/S0911-6044(03)00019-8
   Bornkessel I, 2005, NEUROIMAGE, V26, P221, DOI 10.1016/j.neuroimage.2005.01.032
   Brennan Nicole Petrovich, 2016, Top Magn Reson Imaging, V25, P1, DOI 10.1097/RMR.0000000000000074
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Cabeza R, 2000, J COGNITIVE NEUROSCI, V12, P1, DOI 10.1162/08989290051137585
   Calhoun VD, 2001, NEUROIMAGE, V14, P1080, DOI 10.1006/nimg.2001.0921
   Calhoun VD, 2001, HUM BRAIN MAPP, V14, P140, DOI 10.1002/hbm.1048
   Calhoun VD, 2008, HUM BRAIN MAPP, V29, P828, DOI 10.1002/hbm.20581
   Catani M, 2012, CORTEX, V48, P273, DOI 10.1016/j.cortex.2011.12.001
   Chomsky N, 2013, LINGUA, V130, P33, DOI 10.1016/j.lingua.2012.12.003
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   Correa N, 2007, MAGN RESON IMAGING, V25, P684, DOI 10.1016/j.mri.2006.10.017
   Crosson B, 2013, BRAIN LANG, V126, P73, DOI 10.1016/j.bandl.2012.06.011
   Desai RH, 2010, CEREB CORTEX, V20, P468, DOI 10.1093/cercor/bhp115
   Desmond JE, 2002, BRAIN COGNITION, V50, P482, DOI 10.1016/S0278-2626(02)00531-6
   DeWitt I, 2013, BRAIN LANG, V127, P181, DOI 10.1016/j.bandl.2013.09.014
   Dunn M, 2011, NATURE, V473, P79, DOI 10.1038/nature09923
   Epstein RA, 2007, J NEUROSCI, V27, P6141, DOI 10.1523/JNEUROSCI.0799-07.2007
   Erhardt EB, 2011, HUM BRAIN MAPP, V32, P2075, DOI 10.1002/hbm.21170
   Fakhri M, 2013, FUNCT NEUROL, V28, P55, DOI 10.11138/FNeur/2013.10.1.055
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Friederici AD, 2003, CEREB CORTEX, V13, P170, DOI 10.1093/cercor/13.2.170
   Friederici AD, 2015, TRENDS COGN SCI, V19, P329, DOI 10.1016/j.tics.2015.03.012
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Friedman L, 1998, BRAIN LANG, V64, P231, DOI 10.1006/brln.1998.1953
   Gaab N, 2003, NEUROIMAGE, V19, P1417, DOI 10.1016/S1053-8119(03)00224-6
   Gauvin HS, 2016, NEUROIMAGE, V126, P96, DOI 10.1016/j.neuroimage.2015.11.037
   Giraud AL, 2004, CEREB CORTEX, V14, P247, DOI 10.1093/cercor/bhg124
   Gitelman DR, 2005, NEUROIMAGE, V26, P975, DOI 10.1016/j.neuroimage.2005.03.014
   Griffiths J. D., 2012, CEREB CORTEX
   Grodzinsky Y, 2008, TRENDS COGN SCI, V12, P474, DOI 10.1016/j.tics.2008.09.001
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004
   Hagoort P, 2016, NEUROBIOLOGY LANGUAG, P339, DOI DOI 10.1016/B978-0-12-407794-2.00028-6
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416
   Hassabis D, 2007, J NEUROSCI, V27, P14365, DOI 10.1523/JNEUROSCI.4549-07.2007
   Heim S, 2003, COGNITIVE BRAIN RES, V16, P285, DOI 10.1016/S0926-6410(02)00284-7
   Heim S, 2008, NEUROIMAGE, V40, P1362, DOI 10.1016/j.neuroimage.2008.01.009
   Herholz SC, 2012, J COGNITIVE NEUROSCI, V24, P1382, DOI 10.1162/jocn_a_00216
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Himberg J, 2004, NEUROIMAGE, V22, P1214, DOI 10.1016/j.neuroimage.2004.03.027
   Hirnstein M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00997
   Huang CM, 2010, J NEUROSCI METH, V189, P257, DOI 10.1016/j.jneumeth.2010.03.021
   Jackson R. L., 2015, J COGN NEUROSCI
   Jardri R, 2007, NEUROIMAGE, V35, P1645, DOI 10.1016/j.neuroimage.2007.02.002
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   Jenkinson M, 2001, MED IMAGE ANAL, V5, P143, DOI 10.1016/S1361-8415(01)00036-6
   Jenkinson M, 2003, MAGNET RESON MED, V49, P193, DOI 10.1002/mrm.10354
   Jenkinson M., 2005, SKULL SCALP SURFACE
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Josse G, 2006, BRAIN RES, V1068, P184, DOI 10.1016/j.brainres.2005.11.037
   Jung-Beeman M, 2005, TRENDS COGN SCI, V9, P512, DOI 10.1016/j.tics.2005.09.009
   Kaas JH, 1999, NAT NEUROSCI, V2, P1045, DOI 10.1038/15967
   Kansaku K, 2001, NEUROSCI RES, V41, P333, DOI 10.1016/S0168-0102(01)00292-9
   Kim DI, 2009, HUM BRAIN MAPP, V30, P3795, DOI 10.1002/hbm.20807
   Kobayashi Y, 2003, J COMP NEUROL, V466, P48, DOI 10.1002/cne.10883
   Kobayashi Y, 2007, J COMP NEUROL, V502, P810, DOI 10.1002/cne.21346
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leech R, 2014, BRAIN, V137, P12, DOI 10.1093/brain/awt162
   Leech R, 2009, J NEUROSCI, V29, P5234, DOI 10.1523/JNEUROSCI.5758-08.2009
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Levinson SC, 2012, TRENDS COGN SCI, V16, P167, DOI 10.1016/j.tics.2012.01.007
   Li YO, 2007, HUM BRAIN MAPP, V28, P1251, DOI 10.1002/hbm.20359
   Liang PP, 2015, SCI REP-UK, V5, DOI 10.1038/srep18216
   Ma S, 2011, IEEE T BIO-MED ENG, V58, P3406, DOI 10.1109/TBME.2011.2167149
   Mahdavi A, 2008, IRAN J RADIOL, V5, P215
   Mahdavi A, 2011, J MAGN RESON IMAGING, V34, P413, DOI 10.1002/jmri.22604
   Mandavi A., 2008, IRAN J RADIOL, V6
   Mandavi A, 2010, ARCH IRAN MED, V13, P223
   Marien P, 2014, CEREBELLUM, V13, P386, DOI 10.1007/s12311-013-0540-5
   Mazziotta JC, 2009, NEUROIMAGE, V44, P914, DOI 10.1016/j.neuroimage.2008.07.062
   McDermott KB, 2003, NEUROPSYCHOLOGIA, V41, P293, DOI 10.1016/S0028-3932(02)00162-8
   Meda SA, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007911
   Mesulam M.-M., 2000, PRINCIPLES BEHAV COG
   Musz E, 2017, BRAIN LANG, V165, P21, DOI 10.1016/j.bandl.2016.11.002
   Neef NE, 2016, NEUROIMAGE, V142, P628, DOI 10.1016/j.neuroimage.2016.08.030
   Nielsen FA, 2005, NEUROIMAGE, V27, P520, DOI 10.1016/j.neuroimage.2005.04.034
   Niskanen E, 2012, NEURORADIOLOGY, V54, P393, DOI 10.1007/s00234-011-0959-7
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128
   Okada K, 2006, BRAIN LANG, V98, P112, DOI 10.1016/j.bandl.2006.04.006
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Partovi S, 2012, ACAD RADIOL, V19, P518, DOI 10.1016/j.acra.2011.12.017
   Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142
   Peeva MG, 2010, NEUROIMAGE, V50, P626, DOI 10.1016/j.neuroimage.2009.12.065
   Petrella JR, 2006, RADIOLOGY, V240, P793, DOI 10.1148/radiol.2403051153
   PETRIDES M, 1993, P NATL ACAD SCI USA, V90, P878, DOI 10.1073/pnas.90.3.878
   Plakke B, 2016, BRAIN RES, V1640, P278, DOI 10.1016/j.brainres.2015.11.042
   Pobric G, 2010, NEUROPSYCHOLOGIA, V48, P1336, DOI 10.1016/j.neuropsychologia.2009.12.036
   Poeppel D, 2004, COGNITION, V92, P1, DOI 10.1016/j.cognition.2003.11.001
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005
   Poeppel D, 2012, J NEUROSCI, V32, P14125, DOI 10.1523/JNEUROSCI.3244-12.2012
   Poeppel D, 2012, COGN NEUROPSYCHOL, V29, P34, DOI 10.1080/02643294.2012.710600
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Pouratian N, 2002, J NEUROSURG, V97, P21, DOI 10.3171/jns.2002.97.1.0021
   Powell HWR, 2006, NEUROIMAGE, V32, P388, DOI 10.1016/j.neuroimage.2006.03.011
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00237
   Pulvermuller F, 2009, HUM BRAIN MAPP, V30, P3837, DOI 10.1002/hbm.20811
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Ralph MAL, 2008, ANN NY ACAD SCI, V1124, P61, DOI 10.1196/annals.1440.006
   Ramsey NF, 2001, NEUROIMAGE, V13, P719, DOI 10.1006/nimg.2000.0722
   Rauschecker JP, 1998, CURR OPIN NEUROBIOL, V8, P516, DOI 10.1016/S0959-4388(98)80040-8
   Rice G. E., 2015, CEREB CORTEX
   Richardson FM, 2011, J NEUROSCI, V31, P8239, DOI 10.1523/JNEUROSCI.6519-10.2011
   Rogalsky C., 2015, LANG COGN NEUROSCI, P1
   Romanski LM, 1999, NAT NEUROSCI, V2, P1131, DOI 10.1038/16056
   Rossell SL, 2003, NEUROPSYCHOLOGIA, V41, P550, DOI 10.1016/S0028-3932(02)00181-1
   Sachdev PS, 2013, INT REV PSYCHIATR, V25, P738, DOI 10.3109/09540261.2013.870137
   Sahin NT, 2009, SCIENCE, V326, P445, DOI 10.1126/science.1174481
   Schapiro AC, 2013, J COGNITIVE NEUROSCI, V25, P2107, DOI 10.1162/jocn_a_00441
   Schlosser MJ, 1998, HUM BRAIN MAPP, V6, P1, DOI 10.1002/(SICI)1097-0193(1998)6:1<1::AID-HBM1>3.0.CO;2-7
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Seghier ML, 2004, HUM BRAIN MAPP, V23, P140, DOI 10.1002/hbm.20053
   Seydell-Greenwald A, 2014, HUM BRAIN MAPP, V35, P2233, DOI 10.1002/hbm.22323
   Snowden JS, 2012, BEHAV NEUROL, V25, P35, DOI [10.3233/BEN-2012-0347, 10.1155/2012/360965]
   Steven A. J., 2015, NEUROGRAPHICS, V5, P128
   Stevens MC, 2005, NEUROIMAGE, V26, P782, DOI 10.1016/j.neuroimage.2005.02.044
   Sunaert S, 2006, J MAGN RESON IMAGING, V23, P887, DOI 10.1002/jmri.20582
   Tagamets MA, 2000, J COGNITIVE NEUROSCI, V12, P281, DOI 10.1162/089892900562101
   Tehran University of Medical Sciences statement on publication ethics, 2009, ARCH IRAN MED, V12
   Thompson-Schill SL, 1997, P NATL ACAD SCI USA, V94, P14792, DOI 10.1073/pnas.94.26.14792
   Tie YM, 2008, NEUROIMAGE, V42, P1214, DOI 10.1016/j.neuroimage.2008.05.028
   Tie YM, 2014, HUM BRAIN MAPP, V35, P1018, DOI 10.1002/hbm.22231
   Tomasello R., 2016, NEUROPSYCHOLOGIA
   Tremblay P, 2016, BRAIN LANG, V162, P60, DOI 10.1016/j.bandl.2016.08.004
   Tremblay P, 2011, CEREB CORTEX, V21, P1166, DOI 10.1093/cercor/bhq189
   Tune S., 2016, NEUROIMAGE
   Venezia JH, 2016, NEUROIMAGE, V126, P196, DOI 10.1016/j.neuroimage.2015.11.038
   Vergani F., 2014, J NEUROL NEUROSURG P
   Vigneau M, 2011, NEUROIMAGE, V54, P577, DOI 10.1016/j.neuroimage.2010.07.036
   Vincent JL, 2006, J NEUROPHYSIOL, V96, P3517, DOI 10.1152/jn.00048.2006
   Weiss EM, 2006, J INT NEUROPSYCH SOC, V12, P502, DOI 10.1017/S1355617706060656
   Welker KM, 2012, RADIOLOGY, V265, P222, DOI 10.1148/radiol.12112052
   Wilke M, 2010, EUR J PAEDIATR NEURO, V14, P474, DOI 10.1016/j.ejpn.2010.05.002
   Xu JS, 2013, NEUROIMAGE, V79, P62, DOI 10.1016/j.neuroimage.2013.04.038
   Yao Zhijun, 2015, Brain Inform, V2, P45
   Zaccarella E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01818
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
   Zatorre RJ, 2002, NAT NEUROSCI, V5, P905, DOI 10.1038/nn904
   Zhang S, 2012, HUM BRAIN MAPP, V33, P89, DOI 10.1002/hbm.21197
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 163
TC 3
Z9 3
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0303-8467
EI 1872-6968
J9 CLIN NEUROL NEUROSUR
JI Clin. Neurol. Neurosurg.
PD FEB
PY 2018
VL 165
BP 116
EP 128
DI 10.1016/j.clineuro.2018.01.009
PG 13
WC Clinical Neurology; Surgery
SC Neurosciences & Neurology; Surgery
GA FW7DC
UT WOS:000425478400023
PM 29334640
DA 2021-02-24
ER

PT J
AU Ghaleh, M
   Skipper-Kallal, LM
   Xing, SH
   Lacey, E
   DeWitt, L
   DeMarco, A
   Turkeltaub, P
AF Ghaleh, Maryam
   Skipper-Kallal, Laura M.
   Xing, Shihui
   Lacey, Elizabeth
   DeWitt, Lain
   DeMarco, Andrew
   Turkeltaub, Peter
TI Phonotactic processing deficit following left-hemisphere stroke
SO CORTEX
LA English
DT Article
DE Phonotactics; Sublexical processing; Left-hemisphere stroke;
   Lesion-symptom mapping; Voxel-based morphometry
ID SPOKEN-WORD-RECOGNITION; PHONOLOGICAL WORKING-MEMORY; SENSORY-MOTOR
   INTEGRATION; SUPERIOR TEMPORAL GYRUS; EVENT-RELATED FMRI;
   SPEECH-PERCEPTION; ANGULAR GYRUS; NEIGHBORHOOD ACTIVATION; CORTICAL
   ORGANIZATION; FUNCTIONAL NEUROANATOMY
AB The neural basis of speech processing is still a matter of great debate. Phonotactic knowledge knowledge of the allowable sound combinations in a language remains particularly understudied. The purpose of this study was to investigate the brain regions crucial to phonotactic knowledge in left-hemisphere stroke survivors. Results were compared to areas in which gray matter anatomy related to phonotactic knowledge in healthy controls. 44 patients with chronic left-hemisphere stroke, and 32 controls performed an English-likeness rating task on 60 auditory non-words of varying phonotactic regularities. They were asked to rate on a 1-5 scale, how close each non-word sounded to English. Patients' performance was compared to that of healthy controls, using mixed effects modeling. Multivariate lesion-symptom mapping and voxel-based morphometry were used to find the brain regions important for phonotactic processing in patients and controls respectively. The results showed that compared to controls, stroke survivors were less sensitive to phonotactic regularity differences. Lesion-symptom mapping demonstrated that a loss of sensitivity to phonotactic regularities was associated with lesions in left angular gyms and posterior middle temporal gyrus. Voxel-based morphometry also revealed a positive correlation between gray matter density in left angular gyms and sensitivity to phonotactic regularities in controls. We suggest that the angular gyrus is used to compare the incoming speech stream to internal predictions based on the frequency of sound sequences in the language derived from stored lexical representations in the posterior middle temporal gyrus. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Ghaleh, Maryam; Skipper-Kallal, Laura M.; Xing, Shihui; Lacey, Elizabeth; DeMarco, Andrew; Turkeltaub, Peter] Georgetown Univ, Med Ctr, Dept Neurol, 4000 Reservoir Rd,NW,Bldg D,Suite 165, Washington, DC 20057 USA.
   [Lacey, Elizabeth; Turkeltaub, Peter] MedStar Natl Rehabil Hosp, Washington, DC USA.
   [Xing, Shihui] Sun Yat Sen Univ, Dept Neurol, Affiliated Hosp 1, Guangzhou, Guangdong, Peoples R China.
   [DeWitt, Lain] NIDCD, Brain Imaging & Modeling Sect, NIH, Bethesda, MD USA.
RP Skipper-Kallal, LM (corresponding author), Georgetown Univ, Med Ctr, Dept Neurol, 4000 Reservoir Rd,NW,Bldg D,Suite 165, Washington, DC 20057 USA.; Turkeltaub, P (corresponding author), Georgetown Univ, Div Res, Dept Neurol, Med Ctr, 4000 Reservoir Rd,NW,Bldg D,Suite 165, Washington, DC 20057 USA.
EM mg1477@georgetown.edu; turkeltp@georgetown.edu
OI Turkeltaub, Peter/0000-0003-2080-6055
FU NIH/NCATS via the Georgetown-Howard Universities Center for Clinical and
   Translational Science [KL2TR000102]; Doris Duke Charitable
   FoundationDoris Duke Charitable Foundation (DDCF) [2012062]; Vernon
   Family Trust; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [81000500]; Natural Science
   Foundation of Guangdong ProvinceNational Natural Science Foundation of
   Guangdong Province [2015A030313049]; NATIONAL CENTER FOR ADVANCING
   TRANSLATIONAL SCIENCESUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Center for
   Advancing Translational Sciences (NCATS) [KL2TR000102, KL2TR000102,
   KL2TR000102] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC014960, R01DC014960, R01DC014960] Funding Source: NIH RePORTER
FX This study was supported by the NIH/NCATS via the Georgetown-Howard
   Universities Center for Clinical and Translational Science
   (KL2TR000102), Doris Duke Charitable Foundation (2012062), Vernon Family
   Trust, National Natural Science Foundation of China (81000500) and
   Natural Science Foundation of Guangdong Province (2015A030313049).
CR Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Breese EL, 2004, BRAIN LANG, V89, P3, DOI 10.1016/S0093-934X(03)00412-7
   Buchsbaum BR, 2005, NEUROIMAGE, V24, P444, DOI 10.1016/j.neuroimage.2004.08.025
   Buchsbaum BR, 2008, J COGNITIVE NEUROSCI, V20, P762, DOI 10.1162/jocn.2008.20501
   Cibelli ES, 2015, BRAIN LANG, V147, P66, DOI 10.1016/j.bandl.2015.05.005
   Cornelissen K, 2004, BRAIN LANG, V89, P617, DOI 10.1016/j.bandl.2003.12.007
   Crystal D., 2008, DICT LINGUISTICS PHO
   DeWitt I., 2012, THESIS
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Dronkers NF, 2004, COGNITION, V92, P145, DOI 10.1016/j.cognition.2003.11.002
   Freeman MR, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00702
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015
   Garavan H, 1999, P NATL ACAD SCI USA, V96, P8301, DOI 10.1073/pnas.96.14.8301
   Gow DW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086212
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   Graves WW, 2008, J COGNITIVE NEUROSCI, V20, P1698, DOI 10.1162/jocn.2008.20113
   Haggard P, 2012, CURR BIOL, V22, pR390, DOI 10.1016/j.cub.2012.02.040
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2008, BRAIN LANG, V107, P179, DOI 10.1016/j.bandl.2008.09.006
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, SPRINGER HANDB AUDIT, V43, P333, DOI 10.1007/978-1-4614-2314-0_12
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   Hickok G, 2009, J NEUROPHYSIOL, V101, P2725, DOI 10.1152/jn.91099.2008
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Kimberg DY, 2007, J COGNITIVE NEUROSCI, V19, P1067, DOI 10.1162/jocn.2007.19.7.1067
   Leff AP, 2009, BRAIN, V132, P3401, DOI 10.1093/brain/awp273
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Martin RC, 2003, ANNU REV PSYCHOL, V54, P55, DOI 10.1146/annurev.psych.54.101601.145201
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McGettigan C, 2011, J COGNITIVE NEUROSCI, V23, P961, DOI 10.1162/jocn.2010.21491
   Mirman D, 2016, ARXIV160600475QBIOST
   MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366
   Newhart M, 2012, CORTEX, V48, P1288, DOI 10.1016/j.cortex.2011.09.009
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   Obrig H, 2016, BRAIN, V139, P1800, DOI 10.1093/brain/aww077
   Pa J, 2008, NEUROPSYCHOLOGIA, V46, P362, DOI 10.1016/j.neuropsychologia.2007.06.024
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Price AR, 2016, J NEUROSCI, V36, P3829, DOI 10.1523/JNEUROSCI.3120-15.2016
   Raettig T, 2008, NEUROIMAGE, V39, P1420, DOI 10.1016/j.neuroimage.2007.09.030
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rogalsky C, 2015, NEUROPSYCHOLOGIA, V71, P18, DOI 10.1016/j.neuropsychologia.2015.03.012
   Scott SK, 2004, COGNITION, V92, P13, DOI 10.1016/j.cognition.2002.12.002
   Seghier ML, 2013, NEUROSCIENTIST, V19, P43, DOI 10.1177/1073858412440596
   Seghier ML, 2010, J NEUROSCI, V30, P16809, DOI 10.1523/JNEUROSCI.3377-10.2010
   Specht K, 2014, HEARING RES, V307, P121, DOI 10.1016/j.heares.2013.09.011
   Strand F, 2008, BRAIN RES, V1212, P48, DOI 10.1016/j.brainres.2008.02.097
   Treiman R, 2000, PAPERS LAB PHONOLOGY, P269
   Tremblay P, 2011, NEUROIMAGE, V57, P1561, DOI 10.1016/j.neuroimage.2011.05.067
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   Vaden KI, 2011, NEUROPSYCHOLOGIA, V49, P3563, DOI 10.1016/j.neuropsychologia.2011.09.008
   Vaden KI, 2011, J COGNITIVE NEUROSCI, V23, P2665, DOI 10.1162/jocn.2011.21620
   Vara AS, 2014, DEV COGN NEUROS-NETH, V10, P129, DOI 10.1016/j.dcn.2014.08.009
   Vitevitch MS, 1997, LANG SPEECH, V40, P47, DOI 10.1177/002383099704000103
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Vitevitch MS, 1999, BRAIN LANG, V68, P306, DOI 10.1006/brln.1999.2116
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
   Wilson SM, 2017, LANG COGN NEUROSCI, V32, P891, DOI 10.1080/23273798.2016.1248984
   Zhang YS, 2014, HUM BRAIN MAPP, V35, P5861, DOI 10.1002/hbm.22590
NR 66
TC 6
Z9 6
U1 1
U2 5
PU ELSEVIER MASSON, CORPORATION OFFICE
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD FEB
PY 2018
VL 99
BP 346
EP 357
DI 10.1016/j.cortex.2017.12.010
PG 12
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FW8FF
UT WOS:000425564100030
PM 29351881
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Johns, AR
   Myers, EB
   Skoe, E
AF Johns, Alexis R.
   Myers, Emily B.
   Skoe, Erika
TI Sensory and cognitive contributions to age-related changes in spoken
   word recognition
SO LANGUAGE AND LINGUISTICS COMPASS
LA English
DT Article
ID BRAIN-STEM RESPONSE; GAP-DETECTION THRESHOLDS; OLDER-ADULTS;
   HEARING-LOSS; SPEECH-PERCEPTION; WORKING-MEMORY; LANGUAGE COMPREHENSION;
   INDIVIDUAL-DIFFERENCES; EYE-MOVEMENTS; TIME-COURSE
AB Many older adults experience declines in auditory and cognitive abilities that negatively affect language comprehension, including spoken word recognition. In the case of auditory function, poor neural responses to sound at the earliest stages of auditory processing may adversely affect phoneme identification, and ultimately, lexical access. Declines in cognitive functions, such as inhibitory control or working memory, may also impede word recognition. Furthermore, complex interactions between auditory and cognitive declines make it difficult to distinguish these possible causes of age differences in speech perception. We review age-related changes in spoken word recognition, with respect to current models of this process. Then, we invoke frameworks of sensory-cognitive compensation and argue that online, sensitive measures of sensory processing and of comprehension are important in distinguishing between effects of sensory and cognitive decline. We conclude that investigations of spoken word recognition in older listeners must carefully assess listener differences at early levels of auditory processing, in conjunction with cognitive abilities.
C1 [Johns, Alexis R.; Myers, Emily B.] Univ Connecticut, Psychol Sci, Storrs, CT USA.
   [Johns, Alexis R.] Brandeis Univ, Dept Psychol, Volen Natl Ctr Complex Syst, Waltham, MA 02254 USA.
   [Johns, Alexis R.] Brandeis Univ, Volen Natl Ctr Complex Syst, Dept Neurosci, Waltham, MA 02254 USA.
   [Myers, Emily B.; Skoe, Erika] Univ Connecticut, Speech Language & Hearing Sci, Storrs, CT USA.
RP Johns, AR (corresponding author), Brandeis Ctr Complex Syst, Volen Ctr 206 MS013, 415 South St, Waltham, MA 02454 USA.
EM ajohns@brandeis.edu
OI /0000-0002-9475-764X
FU National Institute of Neurological Disorders and StrokeUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Neurological Disorders & Stroke (NINDS)
   [T32 NS 007292-30]; National Institute on Deafness and Other
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01 DC 013064];
   National Institute of AgingUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Aging (NIA) [R01 AG 019714]
FX National Institute of Neurological Disorders and Stroke, Grant/Award
   Number: T32 NS 007292-30; National Institute on Deafness and Other
   Communication Disorders, Grant/Award Number: R01 DC 013064; National
   Institute of Aging, Grant/Award Number: R01 AG 019714.
CR Abada SH, 2008, EXP AGING RES, V34, P232, DOI 10.1080/03610730802070183
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Alain C, 2004, PSYCHOL AGING, V19, P125, DOI 10.1037/0882-7974.19.1.125
   Alain C, 2007, J AM ACAD AUDIOL, V18, P573, DOI 10.3766/jaaa.18.7.5
   Albers MW, 2015, ALZHEIMERS DEMENT, V11, P70, DOI 10.1016/j.jalz.2014.04.514
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Anderson S, 2013, P NATL ACAD SCI USA, V110, P4357, DOI 10.1073/pnas.1213555110
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   Ayasse ND, 2017, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00329
   Baldwin CL, 2011, PSYCHOL AGING, V26, P85, DOI 10.1037/a0020360
   Baltes PB, 1997, PSYCHOL AGING, V12, P12, DOI 10.1037/0882-7974.12.1.12
   Baum SR, 2003, SPEECH COMMUN, V39, P231, DOI 10.1016/S0167-6393(02)00028-6
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   Benichov J, 2012, EAR HEARING, V33, P262, DOI 10.1097/AUD.0b013e31822f680f
   Bergman M, 1980, AGING PERCEPTION SPE
   Bialystok E, 2008, J EXP PSYCHOL LEARN, V34, P859, DOI 10.1037/0278-7393.34.4.859
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Bramhall NF, 2017, EAR HEARING, V38, pE1, DOI 10.1097/AUD.0000000000000370
   Cabeza R, 2002, NEUROIMAGE, V17, P1394, DOI 10.1006/nimg.2002.1280
   Campbell KL, 2012, NEUROPSYCHOLOGIA, V50, P2212, DOI 10.1016/j.neuropsychologia.2012.05.025
   CAMPBELL KB, 1986, ELECTROEN CLIN NEURO, V65, P142, DOI 10.1016/0168-5597(86)90047-X
   Chen Q, 2015, COGNITIVE SCI, V39, P538, DOI 10.1111/cogs.12156
   Classon E., 2013, FRONT PSYCHOL, V4, P1
   Clinard CG, 2013, J AM ACAD AUDIOL, V24, P590, DOI 10.3766/jaaa.24.7.7
   Craik F. I. M, 1992, HDB AGING COGNITION
   Cruickshanks KJ, 2010, SPRINGER HANDB AUDIT, V34, P259, DOI 10.1007/978-1-4419-0993-0_9
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Dubno JR, 2000, J ACOUST SOC AM, V107, P538, DOI 10.1121/1.428322
   Eckert MA, 2012, JARO-J ASSOC RES OTO, V13, P703, DOI 10.1007/s10162-012-0332-5
   Federmeier KD, 2003, PSYCHOL AGING, V18, P858, DOI 10.1037/0882-7974.18.4.858
   Fitzgibbons P J, 1996, J Am Acad Audiol, V7, P183
   Fitzgibbons PJ, 2010, SPRINGER HANDB AUDIT, V34, P111, DOI 10.1007/978-1-4419-0993-0_5
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gernsbacher M. A., 1991, ADV PSYCHOL, P97, DOI DOI 10.1016/S0166-4115
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Gordon-Salant S, 1999, J SPEECH LANG HEAR R, V42, P300, DOI 10.1044/jslhr.4202.300
   Goy H, 2013, J SPEECH LANG HEAR R, V56, P1715, DOI 10.1044/1092-4388(2013/12-0053)
   HELLSTROM LI, 1990, HEARING RES, V50, P163, DOI 10.1016/0378-5955(90)90042-N
   Hornickel J, 2013, J NEUROSCI, V33, P3500, DOI 10.1523/JNEUROSCI.4205-12.2013
   HOWES DH, 1951, J EXP PSYCHOL, V41, P401, DOI 10.1037/h0056020
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Humes L E, 1996, J Am Acad Audiol, V7, P161
   Humes LE, 2007, J AM ACAD AUDIOL, V18, P590, DOI 10.3766/jaaa.18.7.6
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   Hunter CR, 2016, NEUROPSYCHOLOGIA, V91, P451, DOI 10.1016/j.neuropsychologia.2016.09.007
   Ison JR, 2010, SPRINGER HANDB AUDIT, V34, P75, DOI 10.1007/978-1-4419-0993-0_4
   Janse E, 2013, LANG SPEECH, V56, P421, DOI 10.1177/0023830912447914
   January D, 2009, J COGNITIVE NEUROSCI, V21, P2434, DOI 10.1162/jocn.2008.21179
   JERGER J, 1988, EAR HEARING, V9, P4, DOI 10.1097/00003446-198802000-00010
   JERGER J, 1980, ARCH OTOLARYNGOL, V106, P387
   JEWETT DL, 1971, BRAIN, V94, P681, DOI 10.1093/brain/94.4.681
   Johns A. R., 2017, 173 M AC SOC AM BOST, V141, P3747
   KAHNEMAN D, 1966, SCIENCE, V154, P1583, DOI 10.1126/science.154.3756.1583
   Kamal B., 2013, FRONTIERS SYSTEMS NE, V7, P1
   Krizman J, 2015, CLIN NEUROPHYSIOL, V126, P2348, DOI 10.1016/j.clinph.2015.01.026
   Kuchinsky SE, 2016, EXP AGING RES, V42, P64, DOI 10.1080/0361073X.2016.1108712
   Kuchinsky SE, 2013, PSYCHOPHYSIOLOGY, V50, P23, DOI 10.1111/j.1469-8986.2012.01477.x
   Kujawa SG, 2015, HEARING RES, V330, P191, DOI 10.1016/j.heares.2015.02.009
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   Kutas M, 1998, EVOKED POTENTIAL, V108, P456, DOI 10.1016/S0168-5597(98)00023-9
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lash A, 2013, EXP AGING RES, V39, P235, DOI 10.1080/0361073X.2013.779175
   LAUTER JL, 1986, SCAND AUDIOL, V15, P167, DOI 10.3109/01050398609070693
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   LINDENBERGER U, 1994, PSYCHOL AGING, V9, P339, DOI 10.1037/0882-7974.9.3.339
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lister J, 2002, J ACOUST SOC AM, V111, P2793, DOI 10.1121/1.1476685
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Magnuson J. S., 2013, OXFORD HDB COGNITIVE, P412, DOI DOI 10.1093/OXFORDHB/9780195376746.013.0027
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Martin BA, 1997, J ACOUST SOC AM, V101, P1585, DOI 10.1121/1.418146
   Mattys SL, 2014, PSYCHOL AGING, V29, P150, DOI 10.1037/a0035387
   McCabe DP, 2010, NEUROPSYCHOLOGY, V24, P222, DOI 10.1037/a0017619
   MCCANDLESS GA, 1966, J SPEECH HEAR RES, V9, P266, DOI 10.1044/jshr.0902.266
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McCloy DR, 2016, J ACOUST SOC AM, V139, pEL57, DOI 10.1121/1.4943787
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   McGinley MJ, 2015, NEURON, V87, P179, DOI 10.1016/j.neuron.2015.05.038
   Mehraei G, 2016, J NEUROSCI, V36, P3755, DOI 10.1523/JNEUROSCI.4460-15.2016
   Mohrle D, 2016, NEUROBIOL AGING, V44, P173, DOI 10.1016/j.neurobiolaging.2016.05.001
   Morrell CH, 1996, J ACOUST SOC AM, V100, P1949, DOI 10.1121/1.417906
   Musiek FE, 2005, EAR HEARING, V26, P608, DOI 10.1097/01.aud.0000188069.80699.41
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Neef NE, 2017, CLIN NEUROPHYSIOL, V128, P484, DOI 10.1016/j.clinph.2016.12.007
   Novick JM, 2005, COGN AFFECT BEHAV NE, V5, P263, DOI 10.3758/CABN.5.3.263
   Ouda L, 2015, CELL TISSUE RES, V361, P337, DOI 10.1007/s00441-014-2107-2
   Palmer SB, 2014, J AM ACAD AUDIOL, V25, P999, DOI 10.3766/jaaa.25.10.8
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Phillips DP, 1997, J ACOUST SOC AM, V101, P3694, DOI 10.1121/1.419376
   Phillips DP, 2004, PERCEPTION, V33, P371, DOI 10.1068/p5116
   Pichora-Fuller M. K, 2009, HEARING CARE ADULTS, P53
   Pichora-Fuller M. K., 2008, AUDITORY SIGNAL PROC, P291
   Pichora-Fuller MK, 2007, HEARING RES, V223, P114, DOI 10.1016/j.heares.2006.10.009
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Pichora-Fuller MK, 2006, J ACOUST SOC AM, V119, P1143, DOI 10.1121/1.2149837
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS59
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Piquado T, 2010, PSYCHOPHYSIOLOGY, V47, P560, DOI 10.1111/j.1469-8986.2009.00947.x
   PLOMP R, 1986, J SPEECH HEAR RES, V29, P146, DOI 10.1044/jshr.2902.146
   Postle BR, 2006, NEUROSCIENCE, V139, P23, DOI 10.1016/j.neuroscience.2005.06.005
   Pratt J, 2006, J MOTOR BEHAV, V38, P373, DOI 10.3200/JMBR.38.5.373-382
   RABBITT P, 1991, ACTA OTO-LARYNGOL, P167
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Reitan R.M., 1992, TRAIL MAKING TEST MA
   Revill KP, 2012, PSYCHOL AGING, V27, P80, DOI 10.1037/a0024113
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Rogers CS, 2012, PSYCHOL AGING, V27, P33, DOI 10.1037/a0026231
   Rogersa CS, 2015, J ACOUST SOC AM, V138, pEL26, DOI 10.1121/1.4922363
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, TRENDS AMPLIF, V15, P140, DOI 10.1177/1084713811409762
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Roth T. N., 2014, HDB CLIN NEUROLOGY, V129, P357
   Salthouse T.A., 1991, THEORETICAL PERSPECT
   Schneider B. A., 2009, ENCY NEUROSCIENCE, P19
   Schneider BA, 2000, PSYCHOL AGING, V15, P110, DOI 10.1037/0882-7974.15.1.110
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schneider BA, 1999, J ACOUST SOC AM, V106, P371, DOI 10.1121/1.427062
   Schneider BA, 2000, HDB AGING COGNITION, V2, P155
   Schneider BA, 2010, SPRINGER HANDB AUDIT, V34, P167, DOI 10.1007/978-1-4419-0993-0_7
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   Singh G, 2008, J ACOUST SOC AM, V124, P1294, DOI 10.1121/1.2949399
   Skoe E, 2015, CEREB CORTEX, V25, P1415, DOI 10.1093/cercor/bht311
   Snell KB, 2000, J ACOUST SOC AM, V107, P1615, DOI 10.1121/1.428446
   Sommers MS, 2005, BLACKW HBK LINGUIST, P469, DOI 10.1002/9780470757024.ch19
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   Sommers MS, 1996, PSYCHOL AGING, V11, P333, DOI 10.1037/0882-7974.11.2.333
   Song JH, 2011, CLIN NEUROPHYSIOL, V122, P346, DOI 10.1016/j.clinph.2010.07.009
   Stanley R., 2012, J COMMUN RES, V4, P157
   Starns JJ, 2010, PSYCHOL AGING, V25, P377, DOI 10.1037/a0018022
   Strauss A, 2013, J COGNITIVE NEUROSCI, V25, P1383, DOI 10.1162/jocn_a_00389
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Taler V, 2010, J GERONTOL B-PSYCHOL, V65, P551, DOI 10.1093/geronb/gbq039
   Tanenhaus MK, 2000, J PSYCHOLINGUIST RES, V29, P557, DOI 10.1023/A:1026464108329
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   Valentijn SAM, 2005, J AM GERIATR SOC, V53, P374, DOI 10.1111/j.1532-5415.2005.53152.x
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   VANROOIJ JCGM, 1990, J ACOUST SOC AM, V88, P2611, DOI 10.1121/1.399981
   Werff KRV, 2011, EAR HEARING, V32, P168, DOI 10.1097/AUD.0b013e3181f534b5
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   WINGFIELD A, 1994, LANG SPEECH, V37, P221, DOI 10.1177/002383099403700301
   WINGFIELD A, 1991, J GERONTOL, V46, pP127, DOI 10.1093/geronj/46.3.P127
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006
   Wingfield A, 2006, J AM ACAD AUDIOL, V17, P487, DOI 10.3766/jaaa.17.7.4
   Wingfield A, 2016, EAR HEARING, V37, p35S, DOI 10.1097/AUD.0000000000000310
   Wingfield A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00684
   Wingfield Arthur, 2001, Seminars in Hearing, V22, P287, DOI 10.1055/s-2001-15632
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   Wlotko EW, 2010, LANG LINGUIST COMPAS, V4, P623, DOI 10.1111/j.1749-818x.2010.00224.x
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
   Wynne DP, 2013, BRAIN, V136, P1626, DOI 10.1093/brain/awt056
   Zacks R, 1997, J GERONTOL B-PSYCHOL, V52, pP274, DOI 10.1093/geronb/52B.6.P274
   Zekveld AA, 2014, NEUROIMAGE, V101, P76, DOI 10.1016/j.neuroimage.2014.06.069
   Zekveld AA, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00088
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
NR 172
TC 2
Z9 2
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1749-818X
J9 LANG LINGUIST COMPAS
JI Lang. Linguist. Compass
PD FEB
PY 2018
VL 12
IS 2
AR e12272
DI 10.1111/lnc3.12272
PG 25
WC Language & Linguistics
SC Linguistics
GA FW6ZR
UT WOS:000425469500002
DA 2021-02-24
ER

PT J
AU Zhao, X
   Berent, I
AF Zhao, Xu
   Berent, Iris
TI The Basis of the Syllable Hierarchy: Articulatory Pressures or Universal
   Phonological Constraints?
SO JOURNAL OF PSYCHOLINGUISTIC RESEARCH
LA English
DT Article
DE Phonology; Universal grammar; Embodiment; Articulation
ID TRANSCRANIAL MAGNETIC STIMULATION; SHORT-TERM-MEMORY; SPEECH-PERCEPTION;
   LANGUAGE UNIVERSALS; MOTOR CORTEX; WORD IDENTIFICATION; SONORITY;
   SOUNDS; REPRESENTATIONS; CONSEQUENCES
AB Across languages, certain syllable types are systematically preferred to others (e.g., lbif, where indicates a preference). Previous research has shown that these preferences are active in the brains of individual speakers, they are evident even when none of these syllable types exists in participants' language, and even when the stimuli are presented in print. These results suggest that the syllable hierarchy cannot be reduced to either lexical or auditory/phonetic pressures. Here, we examine whether the syllable hierarchy is due to articulatory pressures. According to the motor embodiment view, the perception of a linguistic stimulus requires simulating its production; dispreferred syllables (e.g., lbif) are universally disliked because their production is harder to simulate. To address this possibility, we assessed syllable preferences while articulation was mechanically suppressed. Our four experiments each found significant effects of suppression. Remarkably, people remained sensitive to the syllable hierarchy regardless of suppression. Specifically, results with auditory materials (Experiments 1-2) showed strong effects of syllable structure irrespective of suppression. Moreover, syllable structure uniquely accounted for listeners' behavior even when controlling for several phonetic characteristics of our auditory materials. Results with printed stimuli (Experiments 3-4) were more complex, as participants in these experiments relied on both phonological and graphemic information. Nonetheless, readers were sensitive to most of the syllable hierarchy (e.g., ), and these preferences emerged when articulation was suppressed, and even when the statistical properties of our materials were controlled via a regression analysis. Together, these findings indicate that speakers possess broad grammatical preferences that are irreducible to either sensory or motor factors.
C1 [Zhao, Xu; Berent, Iris] Northeastern Univ, Dept Psychol, 125 Nightingale,360 Huntington Ave, Boston, MA 02115 USA.
RP Berent, I (corresponding author), Northeastern Univ, Dept Psychol, 125 Nightingale,360 Huntington Ave, Boston, MA 02115 USA.
EM i.berent@neu.edu
CR ABLER WL, 1989, J SOC BIOL STRUCT, V12, P1, DOI 10.1016/0140-1750(89)90015-8
   Acuna BD, 2002, CEREB CORTEX, V12, P1312, DOI 10.1093/cercor/12.12.1312
   BADDELEY AD, 1975, J VERB LEARN VERB BE, V14, P575, DOI 10.1016/S0022-5371(75)80045-4
   BERENT I, 1995, PSYCHOL REV, V102, P146, DOI 10.1037/0033-295X.102.1.146
   Berent I, 2008, J EXP PSYCHOL HUMAN, V34, P1288, DOI 10.1037/0096-1523.34.5.1288
   Berent I, 2008, P NATL ACAD SCI USA, V105, P5321, DOI 10.1073/pnas.0801469105
   Berent I, 2007, COGNITION, V104, P591, DOI 10.1016/j.cognition.2006.05.015
   Berent I, 2016, LANG COGN NEUROSCI, V31, P1178, DOI 10.1080/23273798.2016.1211301
   Berent I, 2015, P NATL ACAD SCI USA, V112, P1983, DOI 10.1073/pnas.1416851112
   Berent I, 2012, MENT LEX, V7, P275, DOI 10.1075/ml.7.3.02ber
   Berent I, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095155
   Berent I, 2013, COGN NEUROPSYCHOL, V30, P285, DOI 10.1080/02643294.2013.863182
   Berent I, 2013, TRENDS COGN SCI, V17, P319, DOI 10.1016/j.tics.2013.05.004
   Berent I, 2012, LANG SPEECH, V55, P311, DOI 10.1177/0023830911417804
   Berent I, 2010, J EXP PSYCHOL HUMAN, V36, P212, DOI 10.1037/a0017638
   Berent I, 2009, PHONOLOGY, V26, P75, DOI 10.1017/S0952675709001729
   BESNER D, 1987, Q J EXP PSYCHOL-A, V39, P467, DOI 10.1080/14640748708401799
   Besner D., 1982, CAN J PSYCHOL, V36, P701, DOI [10.1037/h0080665, DOI 10.1037/H0080665]
   Blevins Juliette, 2004, EVOLUTIONARY PHONOLO
   Bolognini N, 2010, J NEUROSCI, V30, P9647, DOI 10.1523/JNEUROSCI.1990-10.2010
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Bybee Joan, 2008, LINGUISTIC UNIVERSAL, P108, DOI [10.1093/ acprof: oso/ 9780199298495.003.0005, DOI 10.1093/ACPROF:OSO/9780199298495.003.0005]
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clements Nick, 2005, CONT VIEWS ARCHITECT, P19
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Eiter BM, 2008, PSYCHOL RES-PSYCH FO, V72, P666, DOI 10.1007/s00426-008-0166-2
   Evans N, 2009, BEHAV BRAIN SCI, V32, P429, DOI 10.1017/S0140525X0999094X
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   GLASS GV, 1972, REV EDUC RES, V42, P237, DOI 10.2307/1169991
   Glenberg A. M., 2005, GROUNDING COGNITION, P1, DOI [10.1017/CBO9780511499968.006, DOI 10.1017/CBO9780511499968.006]
   Greenberg Joseph, 1978, UNIVERSALS HUMAN LAN, P243
   HARWELL MR, 1992, J EDUC STAT, V17, P315, DOI 10.3102/10769986017004315
   Hatsopoulos NG, 2011, NEURON, V72, P477, DOI 10.1016/j.neuron.2011.10.020
   HITCH GJ, 1976, Q J EXP PSYCHOL, V28, P603, DOI 10.1080/14640747608400587
   Kang Yoonjung, 2003, PHONOLOGY, V20, P219, DOI DOI 10.1017/S0952675703004524
   KLEIMAN GM, 1975, J VERB LEARN VERB BE, V14, P323, DOI 10.1016/S0022-5371(75)80013-2
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Lakoff G., 1999, PHILOS FLESH EMBODIE
   Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675
   Lennertz T. J., 2010, THESIS
   Lennertz T, 2015, MENT LEX, V10, P88, DOI 10.1075/ml.10.1.04len
   LEVY B, 1978, COGNITIVE PSYCHOL IN
   LEVY BA, 1975, J VERB LEARN VERB BE, V14, P304, DOI 10.1016/S0022-5371(75)80074-0
   LEVY BA, 1971, J VERB LEARN VERB BE, V10, P123, DOI 10.1016/S0022-5371(71)80003-8
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lix LM, 1996, REV EDUC RES, V66, P579, DOI 10.2307/1170654
   Lukatela G, 2004, J EXP PSYCHOL HUMAN, V30, P151, DOI 10.1037/0096-1523.30.1.151
   MacNeilage P.F., 2008, ORIGIN SPEECH
   Maionchi-Pino N, 2012, RES DEV DISABIL, V33, P12, DOI 10.1016/j.ridd.2011.07.045
   Martin C.G., 1977, J ED STAT, V2, P187, DOI DOI 10.2307/1164993
   MARTIN M, 1978, MEM COGNITION, V6, P108, DOI 10.3758/BF03197435
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Nespor M, 2014, P NATL ACAD SCI USA, V111, P5387
   Nusbaum H. C., 1984, RES SPEECH PERCEPTIO, V10, P357
   O'Shea J, 2007, CURR BIOL, V17, pR196, DOI 10.1016/j.cub.2007.01.030
   Parker S, 2008, J PHONETICS, V36, P55, DOI 10.1016/j.wocn.2007.09.003
   Prince Alan, 1993, OPTIMALITY THEORY CO
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Samuel AG, 2011, ANNU REV PSYCHOL, V62, P49, DOI 10.1146/annurev.psych.121208.131643
   Sanes JN, 2000, ANNU REV NEUROSCI, V23, P393, DOI 10.1146/annurev.neuro.23.1.393
   Schwartz J. L., 2002, PHONETICS PHONOLOGY, P254
   Tamasi K, 2015, J PSYCHOLINGUIST RES, V44, P359, DOI 10.1007/s10936-014-9289-3
   VANORDEN GC, 1990, PSYCHOL REV, V97, P488, DOI 10.1037/0033-295X.97.4.488
   Wilson C., 2013, P NELS
   Wilson C, 2014, J MEM LANG, V77, P1, DOI 10.1016/j.jml.2014.08.001
   Zhao X, 2016, J PSYCHOLINGUIST RES, V45, P795, DOI 10.1007/s10936-015-9375-1
NR 70
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0090-6905
EI 1573-6555
J9 J PSYCHOLINGUIST RES
JI J. Psycholinguist. Res.
PD FEB
PY 2018
VL 47
IS 1
BP 29
EP 64
DI 10.1007/s10936-017-9510-2
PG 36
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA FV0BI
UT WOS:000424220500002
PM 28710697
DA 2021-02-24
ER

PT J
AU Mokari, PG
   Werner, S
AF Mokari, Payam Ghaffarvand
   Werner, Stefan
TI Perceptual Training of Second-Language Vowels: Does Musical Ability Play
   a Role?
SO JOURNAL OF PSYCHOLINGUISTIC RESEARCH
LA English
DT Article
DE Phonetic training; L2 vowels; Musical ability; Perception; Tonal memory
ID AMERICAN ENGLISH VOWELS; SHORT-TERM-MEMORY; R-VERTICAL-BAR; JAPANESE
   LISTENERS; FOREIGN-LANGUAGE; INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION;
   WORKING-MEMORY; AUDITORY-PERCEPTION; LENGTH CONTRASTS
AB The present study attempts to extend the research on the effects of phonetic training on the production and perception of second-language (L2) vowels. We also examined whether success in learning L2 vowels through high-variability intensive phonetic training is related to the learners' general musical abilities. Forty Azerbaijani learners of Standard Southern British English participated in a pre-test/training/post-test setting. Discrimination and production tests were used in pre- and post-tests. The participants' musical ability was evaluated through three musical aptitude tests. Results revealed a significant improvement in the discrimination and production of L2 vowels after training. However, the lack of a one-to-one relationship between production and perception gains suggests distinct representations underlying L2 speech perception and production. There was no significant correlation between overall musical ability scores and L2 vowel learning, however, results revealed a correlation between discrimination improvements and tonal memory. This suggests tonal memory facilitates the perceptual learning of the novel phonological structure of L2.
C1 [Mokari, Payam Ghaffarvand] Univ Eastern Finland, Dept Gen Linguist & Language Technol, Room 101,Agora Bldg,Yliopistokatu 4, Joensuu 80100, Finland.
   [Werner, Stefan] Univ Eastern Finland, Dept Gen Linguist & Language Technol, Room 258,Agora Bldg,Yliopistokatu 4, Joensuu 80100, Finland.
RP Mokari, PG (corresponding author), Univ Eastern Finland, Dept Gen Linguist & Language Technol, Room 101,Agora Bldg,Yliopistokatu 4, Joensuu 80100, Finland.
EM payam.ghaffarvand@uef.fi; stefan.werner@uef.fi
OI Ghaffarvand Mokari, Payam/0000-0002-1816-2783
CR Alexander J. A., 2005, INTERSPEECH, P397
   Aliaga-Garcia C, 2011, POZ STUD CONTEMP LIN, V47, P1, DOI 10.2478/psicl-2011-0002
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2015, PRAAT DOING PHONETIC
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bowles AR, 2016, LANG LEARN, V66, P774, DOI 10.1111/lang.12159
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Broselow Ellen, 2009, PHONOLOGY PERCEPTION, P191
   Brown S, 2004, NEUROREPORT, V15, P2033, DOI 10.1097/00001756-200409150-00008
   Brown S, 2007, BRAIN COGNITION, V63, P59, DOI 10.1016/j.bandc.2006.08.006
   Cervino-Povedano E., 2010, ACHIEVEMENTS PERSPEC, P53
   Chobert J, 2013, BRAIN SCI, V3, P923, DOI 10.3390/brainsci3020923
   Colantoni L, 2008, APPL PSYCHOLINGUIST, V29, P489, DOI 10.1017/S0142716408080223
   Darcy I., 2014, CONCORDIA WORKING PA, V5, P115
   Darcy I, 2016, LANG LEARN, V66, P1
   Darcy I, 2015, LEARN INDIVID DIFFER, V40, P63, DOI 10.1016/j.lindif.2015.04.005
   Davidson L, 2003, WCCFL 22 P, V22, P165
   Davidson L, 2010, J PHONETICS, V38, P272, DOI 10.1016/j.wocn.2010.01.001
   de Jong K, 2009, J PHONETICS, V37, P357, DOI 10.1016/j.wocn.2009.06.001
   Delogu F, 2010, EUR J COGN PSYCHOL, V22, P46, DOI 10.1080/09541440802708136
   Delogu Franco, 2006, Cogn Process, V7, P203, DOI 10.1007/s10339-006-0146-7
   DIEHL RL, 1987, J PHONETICS, V15, P289, DOI 10.1016/S0095-4470(19)30573-X
   Flege J, 1995, SPEECH PERCEPTION LI, P233
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1989, J ACOUST SOC AM, V86, P1684, DOI 10.1121/1.398599
   FLEGE JE, 1987, SPEECH COMMUN, V6, P185, DOI 10.1016/0167-6393(87)90025-2
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585
   Gordon RL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009889
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   gunleece L. F., 2006, THESIS
   Hazan V, 2005, SPEECH COMMUN, V47, P360, DOI 10.1016/j.specom.2005.04.007
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hirata Y, 2004, J ACOUST SOC AM, V116, P2384, DOI 10.1121/1.1783351
   Hirata Y, 2007, J ACOUST SOC AM, V121, P3837, DOI 10.1121/1.2734401
   Holt L. L., 1998, CHICAGO LINGUISTIC S, P253
   Huensch A, 2015, J PHONETICS, V52, P105, DOI 10.1016/j.wocn.2015.06.007
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Isaacs T, 2011, APPL PSYCHOLINGUIST, V32, P113, DOI 10.1017/S0142716410000317
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Iverson P., 2007, P 16 INT C PHON SCI, P1625
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Jakobson LS, 2003, MUSIC PERCEPT, V20, P307, DOI 10.1525/mp.2003.20.3.307
   Kempe V, 2015, BRIT J PSYCHOL, V106, P349, DOI 10.1111/bjop.12092
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Lambacher SG, 2005, APPL PSYCHOLINGUIST, V26, P227, DOI 10.1017/S0142716405050150
   Lee CY, 2008, J ACOUST SOC AM, V124, P3235, DOI 10.1121/1.2990713
   Lengeris A., 2009, THESIS
   Lengeris A, 2010, J ACOUST SOC AM, V128, P3757, DOI 10.1121/1.3506351
   Levitin DJ, 2003, NEUROIMAGE, V18, P74, DOI 10.1006/nimg.2002.1297
   Li M, 2017, STUD SECOND LANG ACQ, V39, P593, DOI 10.1017/S0272263116000358
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Lotto A. J, 2004, FROM SOUND TO SENSE, V50, pC381
   Maess B, 2001, NAT NEUROSCI, V4, P540
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Mirman D, 2004, J ACOUST SOC AM, V116, P1198, DOI 10.1121/1.1766020
   Munro M. J., 2004, SYSTEM, V32, P539, DOI DOI 10.1016/J.SYSTEM.2004.09.011
   Nakata Hitomi, 2002, READING WORKING PAPE, V6, P1
   NEAREY TM, 1990, J PHONETICS, V18, P347, DOI 10.1016/S0095-4470(19)30379-1
   Nishi K, 2007, J SPEECH LANG HEAR R, V50, P1496, DOI 10.1044/1092-4388(2007/103)
   Nishi K, 2008, J SPEECH LANG HEAR R, V51, P1480, DOI 10.1044/1092-4388(2008/07-0109)
   O'Brien I, 2007, STUD SECOND LANG ACQ, V29, P557, DOI 10.1017/S027226310707043X
   Ohala JJ, 1996, J ACOUST SOC AM, V99, P1718, DOI 10.1121/1.414696
   Ohnishi T, 2001, CEREB CORTEX, V11, P754, DOI 10.1093/cercor/11.8.754
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   Pei Z, 2016, ENGLISH LANGUAGE TEA, V9, P19
   Pereira Reyes Y. I, 2014, THESIS
   Piske T, 2002, PHONETICA, V59, P49, DOI 10.1159/000056205
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   Fabra LR, 2012, J PHONETICS, V40, P491, DOI 10.1016/j.wocn.2012.01.001
   Rammsayer T. H., 2003, PSYCHOL MUSIC, V31, P123, DOI [10.1177/0305735603031002290, DOI 10.1177/0305735603031002290]
   Rato A., 2014, CONCORDIA WORKING PA, V5, P529
   Rochet B. L., 1995, SPEECH PERCEPTION LI, P379
   Safronova E., 2016, THESIS
   Schon D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schon D, 2010, NEUROIMAGE, V51, P450, DOI 10.1016/j.neuroimage.2010.02.023
   Semal C, 1996, J ACOUST SOC AM, V100, P1132, DOI 10.1121/1.416298
   SERVICE E, 1992, Q J EXP PSYCHOL-A, V45, P21, DOI 10.1080/14640749208401314
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   SLOBODA J. A., 1985, MUSICAL MIND COGNITI
   Snodgrass J. G., 1985, HUMAN EXPT PSYCHOL
   Sperbeck M, 2005, J ACOUST SOC AM, V117, P2400
   TAHTA S, 1981, LANG SPEECH, V24, P265, DOI 10.1177/002383098102400306
   Tajima K, 2008, J ACOUST SOC AM, V123, P397, DOI 10.1121/1.2804942
   Tanaka A, 2004, PSYCHOL REP, V95, P723, DOI 10.2466/pr0.95.3.723-734
   THOMPSON I, 1991, LANG LEARN, V41, P177, DOI 10.1111/j.1467-1770.1991.tb00683.x
   Tillmann B, 2003, COGNITIVE BRAIN RES, V16, P145, DOI 10.1016/S0926-6410(02)00245-8
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Williamson VJ, 2010, MEM COGNITION, V38, P163, DOI 10.3758/MC.38.2.163
   Wing H, 1968, TESTS MUSICAL ABILIT
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Zeromskaite I, 2014, J EUROPEAN PSYCHOL S, V5, P77
NR 104
TC 0
Z9 0
U1 2
U2 17
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0090-6905
EI 1573-6555
J9 J PSYCHOLINGUIST RES
JI J. Psycholinguist. Res.
PD FEB
PY 2018
VL 47
IS 1
BP 95
EP 112
DI 10.1007/s10936-017-9517-8
PG 18
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA FV0BI
UT WOS:000424220500005
PM 28852917
DA 2021-02-24
ER

PT J
AU Tseng, WH
   Hsieh, DL
   Shih, WT
   Liu, TC
AF Tseng, Wen-Hsuan
   Hsieh, Dun-Lieh
   Shih, Wan-Ting
   Liu, Tien-Chen
TI Extended bandwidth nonlinear frequency compression in Mandarin-speaking
   hearing-aid users
SO JOURNAL OF THE FORMOSAN MEDICAL ASSOCIATION
LA English
DT Article
DE hearing aid; Mandarin Hearing in Noise Test; Mandarin Monosyllable
   Recognition Test; nonlinear frequency compression
ID SPEECH-PERCEPTION; AMPLIFICATION; RECOGNITION; AUDIBILITY; BENEFITS;
   CHILDREN; NOISE
AB Background/purpose: The high frequency information of consonant messages is important for recognition of speech. Recently, the nonlinear frequency compression (NLFC) technique has been shown to improve the speech perception in patients with high frequency hearing loss. In Mandarin, seven consonants are located over 10-16 kHz. Extended-bandwidth (EB) NLFC may provide an additional benefit for recognition of Mandarin words. The purpose of this study was to explore the effects of NLFC and EB-NLFC on Mandarin word recognition in patients with high frequency hearing loss.
   Methods: Fourteen native Mandarin-speaking adult patients, aged 20-65 years with bilateral, moderate to severe, sensorineural hearing loss, specifically high frequency hearing loss were included in single-blind randomized study. The assessment tools included the Mandarin Monosyllable Recognition Test (MMRT), Mandarin Hearing in Noise Test (MHINT), and International Outcome Inventory for Hearing Aids (IOI-HA) and sound quality scale of the hearing aids. The patients were tested under unaided condition, after which they were randomly assigned to wear NLFC and EB-NLFC hearing aids, alternatively, in a crossover fashion. After each 4-week block, the patients were tested again to obtain the test outcomes.
   Results: Patients with hearing aids with EB-NLFC had a significantly better word and consonant recognition using the MMRT (p < 0.05). The MHINT was better for the EB-NLFC group without significant differences. The EB-NLFC group had better scores in both the IOI-HA and sound quality scale but not statistically significant.
   Conclusion: Patients with high-frequency hearing loss may benefit more from using EB-NLFC for word and consonant recognition; however, the improvement was small under a noisy listening environment. The subjective questionnaires did not show significant benefit of EB-NLFC either. Copyright (C) 2017, Formosan Medical Association. Published by Elsevier Taiwan LLC.
C1 [Tseng, Wen-Hsuan; Hsieh, Dun-Lieh; Shih, Wan-Ting; Liu, Tien-Chen] Natl Taiwan Univ Hosp, Dept Otolaryngol, 7 Chung Shan South Rd, Taipei 100, Taiwan.
RP Liu, TC (corresponding author), Natl Taiwan Univ Hosp, Dept Otolaryngol, 7 Chung Shan South Rd, Taipei 100, Taiwan.
EM liuent@ntu.edu.tw
FU National Science CouncilMinistry of Science and Technology, Taiwan [NSC
   100-2314-B-002-045]
FX This study was support by a grant from National Science Council (NSC
   100-2314-B-002-045) to T.C.L.
CR Alexander Joshua M., 2013, Seminars in Hearing, V34, P86, DOI 10.1055/s-0033-1341346
   BOOTHROYD A, 1992, EAR HEARING, V13, P150, DOI 10.1097/00003446-199206000-00003
   Chou YS, 2014, THESIS
   Feng YM, 2010, EAR HEARING, V31, P115, DOI 10.1097/AUD.0b013e3181bb69be
   Glista D, 2009, INT J AUDIOL, V48, P632, DOI 10.1080/14992020902971349
   Hogan CA, 1998, J ACOUST SOC AM, V104, P432, DOI 10.1121/1.423247
   Huang M.-W., 2005, THESIS
   Jenstad LM, 2005, J SPEECH LANG HEAR R, V48, P651, DOI 10.1044/1092-4388(2005/045)
   Lai YH, 2013, PLOS ONE, V8
   Liu TC, 2000, AUDIOLOGY, V39, P106
   Liu Y., 2016, THESIS
   Moeller MP, 2007, EAR HEARING, V28, P605, DOI 10.1097/AUD.0b013e31812564ab
   Moore B C, 2001, Trends Amplif, V5, P1, DOI 10.1177/108471380100500102
   Moore BCJ, 1997, AUDIT NEUROSCI, V3, P289
   Moore BCJ, 1996, EAR HEARING, V17, P133, DOI 10.1097/00003446-199604000-00007
   Ong S, 2006, J NAT KAOHSIUNG U AP, V35, P325
   Plyler PN, 2006, J SPEECH LANG HEAR R, V49, P616, DOI 10.1044/1092-4388(2006/044)
   Simpson A, 2005, INT J AUDIOL, V44, P281, DOI 10.1080/14992020500060636
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556
   Teder H, 1993, Am J Audiol, V2, P41, DOI 10.1044/1059-0889.0202.41
   Tsai KS, 2009, EAR HEARING, V30, P90, DOI 10.1097/AUD.0b013e31818f28a6
   Turner CW, 2002, J ACOUST SOC AM, V112, P1675, DOI 10.1121/1.1506158
   Wolfe J, 2010, J AM ACAD AUDIOL, V21, P618, DOI 10.3766/jaaa.21.10.2
   Wolfe J, 2011, INT J AUDIOL, V50, P396, DOI 10.3109/14992027.2010.551788
NR 24
TC 4
Z9 4
U1 0
U2 1
PU ELSEVIER TAIWAN
PI TAIPEI
PA RM N-412, 4F, CHIA HSIN BUILDING 11, NO 96, ZHONG SHAN N ROAD SEC 2,
   TAIPEI, 10449, TAIWAN
SN 0929-6646
EI 1876-0821
J9 J FORMOS MED ASSOC
JI J. Formos. Med. Assoc.
PD FEB
PY 2018
VL 117
IS 2
BP 109
EP 116
DI 10.1016/j.jfma.2017.01.013
PG 8
WC Medicine, General & Internal
SC General & Internal Medicine
GA FV1KW
UT WOS:000424321100005
PM 28392194
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Viswanathan, N
   Kelty-Stephen, DG
AF Viswanathan, Navin
   Kelty-Stephen, Damian G.
TI Comparing speech and nonspeech context effects across timescales in
   coarticulatory contexts
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Similarity; Temporal processing
ID PRECEDING LIQUID; COMPENSATION; INFORMATION; PERCEPTION; ACCOUNT
AB Context effects are ubiquitous in speech perception and reflect the ability of human listeners to successfully perceive highly variable speech signals. In the study of how listeners compensate for coarticulatory variability, past studies have used similar effects speech and tone analogues of speech as strong support for speech-neutral, general auditory mechanisms for compensation for coarticulation. In this manuscript, we revisit compensation for coarticulation by replacing standard button-press responses with mouse-tracking responses and examining both standard geometric measures of uncertainty as well as newer information-theoretic measures that separate fast from slow mouse movements. We found that when our analyses were restricted to end-state responses, tones and speech contexts appeared to produce similar effects. However, a more detailed time-course analysis revealed systematic differences between speech and tone contexts such that listeners' responses to speech contexts, but not to tone contexts, changed across the experimental session. Analyses of the time course of effects within trials using mouse tracking indicated that speech contexts elicited fewer x-position flips but more area under the curve (AUC) and maximum deviation (MD), and they did so in the slower portions of mouse-tracking movements. Our results indicate critical differences between the time course of speech and nonspeech context effects and that general auditory explanations, motivated by their apparent similarity, be reexamined.
C1 [Viswanathan, Navin] Univ Kansas, Lawrence, KS 66045 USA.
   [Kelty-Stephen, Damian G.] Grinnell Coll, Grinnell, IA 50112 USA.
RP Viswanathan, N (corresponding author), Univ Kansas, Lawrence, KS 66045 USA.
EM navin@ku.edu
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R15 DC011875-01, BCS-1431105];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R15DC011875] Funding Source: NIH
   RePORTER
FX This research was supported by NIDCD Grant R15 DC011875-01 to N.V. and
   N.S.F., Grant BCS-1431105 to N.V. Both authors contributed equally to
   all aspects of the reported research.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Calcagni A, 2017, BEHAV RES METHODS, V49, P2012, DOI 10.3758/s13428-016-0839-5
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Fan J, 2014, J COGNITIVE NEUROSCI, V26, P1490, DOI 10.1162/jocn_a_00554
   Fowler C. A., 1986, INVARIANCE VARIABILI, P123
   Fowler CA, 2000, J EXP PSYCHOL HUMAN, V26, P877, DOI 10.1037/0096-1523.26.3.877
   Freeman JB, 2013, BEHAV RES METHODS, V45, P83, DOI 10.3758/s13428-012-0225-x
   Holt L. L., 1999, THESIS
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Kieslich P. J., 2017, MOUSETRAP R PACKAGE
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   MANN VA, 1981, J ACOUST SOC AM, V69, P548, DOI 10.1121/1.385483
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SILVERMAN K, 1986, PHONETICA, V43, P76, DOI 10.1159/000261762
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Viswanathan N, 2016, ATTEN PERCEPT PSYCHO, V78, P2341, DOI 10.3758/s13414-016-1187-3
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   Viswanathan N, 2013, J EXP PSYCHOL HUMAN, V39, P1181, DOI 10.1037/a0030735
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   Viswanathan N, 2009, PSYCHON B REV, V16, P74, DOI 10.3758/PBR.16.1.74
   Withagen R, 2005, J EXP PSYCHOL HUMAN, V31, P1379, DOI 10.1037/0096-1523.31.6.1379
NR 25
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD FEB
PY 2018
VL 80
IS 2
BP 316
EP 324
DI 10.3758/s13414-017-1449-8
PG 9
WC Psychology; Psychology, Experimental
SC Psychology
GA FV0ZY
UT WOS:000424292000002
PM 29134576
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU Wang, JJ
   Wydell, TN
   Zhang, LJ
   Quan, WX
   Tian, J
   Liu, J
   Dong, WT
AF Wang, Jiuju
   Wydell, Taeko N.
   Zhang, Linjun
   Quan, Wenxiang
   Tian, Ju
   Liu, Jin
   Dong, Wentian
TI The underlying mechanism of deficits of speech comprehension and
   hallucinations in Chinese patients with schizophrenia
SO JOURNAL OF PSYCHIATRIC RESEARCH
LA English
DT Article
DE Schizophrenia; Perception; Comprehension; Lexical tone; Context
ID FUNDAMENTAL-FREQUENCY CONTOURS; TONAL INFORMATION; PLANUM TEMPORALE;
   PERCEPTION; ROLES; INTELLIGIBILITY; RECOGNITION; IMPAIRMENTS; DISORDER;
   CONTEXT
AB Sentence context and fundamental frequency (F0) contours are important factors to speech perception and comprehension. In Chinese-Mandarin, lexical tones can be distinguished by the F0 contours. Previous studies found healthy people could use the cue of context to recover the phonological representations of lexical tones from the altered tonal patterns to comprehend the sentences in quiet condition, but can not in noise environment. Lots of research showed that patients with schizophrenia have deficits of speech perception and comprehension. However, it is unclear how context and F0 contours influence speech perception and comprehension in patients with schizophrenia. This study detected the contribution of context and lexical tone to sentence comprehension in four types of sentences by manipulating the context and F0 contours in 32 patients with schizophrenia and 33 healthy controls. The results showed that (1) in patients with schizophrenia, the interaction between context and F0 contour was not significant, which was significant in healthy controls; (2) the scores of sentences with two types of sentences with flattened F0 contours were negatively correlated with hallucination trait scores; (3) the patients with schizophrenia showed significantly lower scores on the intelligibility of sentences in all conditions, which were negatively correlated with PANSS-P. The patients with schizophrenia couldn't use the cue of context to recover the phonological representations of lexical tones from the altered tonal patterns when they comprehend the sentences, inner noise may be the underlying mechanism for the deficits of speech perception and comprehension.
C1 [Wang, Jiuju; Quan, Wenxiang; Tian, Ju; Liu, Jin; Dong, Wentian] Peking Univ, Hosp 6, Inst Mental Hlth, Beijing 100191, Peoples R China.
   [Wang, Jiuju; Quan, Wenxiang; Tian, Ju; Liu, Jin; Dong, Wentian] Peking Univ, Minist Hlth, Natl Clin Res Ctr Mental Disorders, Beijing 100191, Peoples R China.
   [Wang, Jiuju; Quan, Wenxiang; Tian, Ju; Liu, Jin; Dong, Wentian] Peking Univ, Minist Hlth, Key Lab Mental Hlth, Beijing 100191, Peoples R China.
   [Wydell, Taeko N.] Brunel Univ London, Ctr Cognit & Neuroimaging, Uxbridge, Middx, England.
   [Zhang, Linjun] Beijing Language & Culture Univ, Coll Chinese Studies, Beijing 100083, Peoples R China.
RP Dong, WT (corresponding author), Peking Univ, Hosp 6, Inst Mental Hlth, Beijing 100191, Peoples R China.
EM dongwentian@bjmu.edu.cn
OI Wydell, Taeko/0000-0001-9675-164X; Zhang, Linjun/0000-0002-9436-0773
FU Humanities and Social Science Research Projects, Ministry of Education
   of China [15YJC880142]
FX This work was supported by Humanities and Social Science Research
   Projects, Ministry of Education of China (15YJC880142).
CR American P.A., 2000, DIAGN STAT MAN MENT
   Boudewyn MA, 2012, SCHIZOPHR RES TREAT, V2012, DOI 10.1155/2012/484502
   Brown M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00643
   CHAPMAN L J, 1964, Prog Exp Pers Res, V72, P49
   Ditman T, 2005, HARVARD REV PSYCHIAT, V13, P280, DOI 10.1080/10673220500326391
   Erritty P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052913
   Feng-Ming Tsao, 2013, Journal of the Acoustical Society of America, V134, DOI 10.1121/1.4831564
   GANDOUR J, 1988, BRAIN LANG, V35, P201, DOI 10.1016/0093-934X(88)90109-5
   Gavarro A, 2013, CLIN LINGUIST PHONET, V27, P632, DOI 10.3109/02699206.2013.800908
   Hazlett EA, 2012, SCHIZOPHR RES, V141, P119, DOI 10.1016/j.schres.2012.08.022
   Jiang W, 2017, J ACOUST SOC AM, V141, pEL338, DOI 10.1121/1.4979565
   Jones SR, 2007, CONSCIOUS COGN, V16, P391, DOI 10.1016/j.concog.2005.12.003
   Katz J, 2016, ACTA PSYCHIAT SCAND, V134, P31, DOI 10.1111/acps.12579
   KAY SR, 1989, BRITISH JOURNAL OF PSYCHIATRY, VOL 155, SUPP NO. 7, P59
   Kyong JS, 2014, J COGNITIVE NEUROSCI, V26, P1748, DOI 10.1162/jocn_a_00583
   Laures JS, 1999, J SPEECH LANG HEAR R, V42, P1148, DOI 10.1044/jslhr.4205.1148
   Lee SH, 2004, ACTA NEUROPSYCHIATR, V16, P154, DOI 10.1111/j.0924-2708.2004.00071.x
   Li C., 1989, MANDARIN CHINESE FUN
   Li CC, 2013, PSYCHON B REV, V20, P773, DOI 10.3758/s13423-013-0395-2
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   McBride-Chang C, 2008, SCI STUD READ, V12, P171, DOI 10.1080/10888430801917290
   Morch-Johnsen L, 2017, SCHIZOPHRENIA BULL, V43, P75, DOI 10.1093/schbul/sbw130
   Moseley P, 2016, COGNITION, V146, P206, DOI 10.1016/j.cognition.2015.09.015
   Oertel-Knochel V, 2013, SCHIZOPHR RES, V147, P331, DOI 10.1016/j.schres.2013.04.024
   REPP BH, 1990, J PHONETICS, V18, P481, DOI 10.1016/S0095-4470(19)30410-3
   Ross LA, 2007, SCHIZOPHR RES, V97, P173, DOI 10.1016/j.schres.2007.08.008
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Shapleske J, 2001, BIOL PSYCHIAT, V49, P685, DOI 10.1016/S0006-3223(00)01006-4
   SHENTON ME, 1992, NEW ENGL J MED, V327, P604, DOI 10.1056/NEJM199208273270905
   Shenton ME, 2001, SCHIZOPHR RES, V49, P1, DOI 10.1016/S0920-9964(01)00163-3
   Simper R, 2011, NEUROSCI RES, V71, P405, DOI 10.1016/j.neures.2011.08.007
   Sitnikova T, 2002, PSYCHOPHYSIOLOGY, V39, P851, DOI 10.1111/1469-8986.3960851
   Sumich A, 2005, BIOL PSYCHIAT, V57, P947, DOI 10.1016/j.biopsych.2004.12.041
   Taft M., 1992, LANGUAGE PROCESSING, V90, P151, DOI DOI 10.1016/S0166-4115(08)61891-9
   Titze I, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004907
   Wang JJ, 2013, J ACOUST SOC AM, V134, pEL91, DOI 10.1121/1.4811159
   Whitford V, 2013, J EXP PSYCHOL GEN, V142, P57, DOI 10.1037/a0028062
   Xu GQ, 2013, NEUROPSYCHOLOGIA, V51, P550, DOI 10.1016/j.neuropsychologia.2012.12.006
   Yang L, 2012, PSYCHOL MED, V42, P1485, DOI 10.1017/S0033291711002224
   Yip M. Tone, 2002, CAMBRIGE TEXTBOOKS L, P178
   Zhang LJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00908
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
NR 42
TC 0
Z9 1
U1 0
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0022-3956
EI 1879-1379
J9 J PSYCHIATR RES
JI J. Psychiatr. Res.
PD FEB
PY 2018
VL 97
BP 16
EP 21
DI 10.1016/j.jpsychires.2017.10.020
PG 6
WC Psychiatry
SC Psychiatry
GA FU1YY
UT WOS:000423646600003
PM 29161608
DA 2021-02-24
ER

PT J
AU Bosker, HR
   Cooke, M
AF Bosker, Hans Rutger
   Cooke, Martin
TI Talkers produce more pronounced amplitude modulations when speaking in
   noise
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
AB Speakers adjust their voice when talking in noise (known as Lombard speech), facilitating speech comprehension. Recent neurobiological models of speech perception emphasize the role of amplitude modulations in speech-in-noise comprehension, helping neural oscillators to "track" the attended speech. This study tested whether talkers produce more pronounced amplitude modulations in noise. Across four different corpora, modulation spectra showed greater power in amplitude modulations below 4Hz in Lombard speech compared to matching plain speech. This suggests that noise-induced speech contains more pronounced amplitude modulations, potentially helping the listening brain to entrain to the attended talker, aiding comprehension. (C) 2018 Acoustical Society of America
C1 [Bosker, Hans Rutger] Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   [Cooke, Martin] Univ Basque Country, Language & Speech Lab, Vitoria 01006, Spain.
   [Bosker, Hans Rutger] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Cooke, Martin] Ikerbasque, Basque Sci Fdn, Bilbao, Spain.
RP Bosker, HR (corresponding author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.; Bosker, HR (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM HansRutger.Bosker@mpi.nl; m.cooke@ikerbasque.org
OI Bosker, Hans Rutger/0000-0002-2628-7738
FU Dutch Government
FX The first author was supported by a Gravitation grant from the Dutch
   Government to the Language in Interaction Consortium.
CR Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bosker H. R, 2017, P INT 2017 STOCKH
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Cooke M, 2014, J ACOUST SOC AM, V135, P874, DOI 10.1121/1.4861342
   Cooke M, 2014, COMPUT SPEECH LANG, V28, P543, DOI 10.1016/j.csl.2013.08.003
   Cooke M, 2013, SPEECH COMMUN, V55, P572, DOI 10.1016/j.specom.2013.01.001
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   DREHER JJ, 1957, J ACOUST SOC AM, V29, P1320, DOI 10.1121/1.1908780
   Dreschler WA, 2001, AUDIOLOGY, V40, P148
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   Folk L, 2011, P INT 2011, P2701
   Garnier M, 2014, COMPUT SPEECH LANG, V28, P580, DOI 10.1016/j.csl.2013.07.005
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2012, BRAIN LANG, V122, P151, DOI 10.1016/j.bandl.2011.12.010
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Kosem A, 2017, NEURAL ENTRAINMENT D
   Koutsogiannaki M, 2016, INTERSPEECH, P2508, DOI 10.21437/Interspeech.2016-500
   Krause JC, 2004, J ACOUST SOC AM, V115, P362, DOI 10.1121/1.1635842
   Krause JC, 2002, J ACOUST SOC AM, V112, P2165, DOI 10.1121/1.1509432
   Lombard E., 1911, ANN MALADIES OREILLE, V37, P101
   Lu YY, 2008, J ACOUST SOC AM, V124, P3261, DOI 10.1121/1.2990705
   Mayo C, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1706
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pittman AL, 2001, J SPEECH LANG HEAR R, V44, P487, DOI 10.1044/1092-4388(2001/038)
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464
   Uchanski R. M, 2008, HDB SPEECH PERCEPTIO, p[Hoboken, 207]
   VANSUMMERS W, 1988, J ACOUST SOC AM, V84, P917, DOI 10.1121/1.396660
   Varnet L, 2017, J ACOUST SOC AM, V142, P1976, DOI 10.1121/1.5006179
   Zhu W, 2006, MECH SYST SIGNAL PR, V8, P261
NR 41
TC 7
Z9 7
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2018
VL 143
IS 2
AR EL121
DI 10.1121/1.5024404
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA VJ4XK
UT WOS:000598750800002
PM 29495684
OA Bronze
DA 2021-02-24
ER

PT J
AU Hou, LM
   Xu, L
AF Hou, Limin
   Xu, Li
TI Role of short-time acoustic temporal fine structure cues in sentence
   recognition for normal-hearing listeners
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
AB Short-time processing was employed to manipulate the amplitude, bandwidth, and temporal fine structure (TFS) in sentences. Fifty-two native-English-speaking, normal-hearing listeners participated in four sentence-recognition experiments. Results showed that recovered envelope (E) played an important role in speech recognition when the bandwidth was> 1 equivalent rectangular bandwidth. Removing TFS drastically reduced sentence recognition. Preserving TFS greatly improved sentence recognition when amplitude information was available at a rate >= 10 Hz (i.e., time segment <= 100 ms). Therefore, the short-time TFS facilitates speech perception together with the recovered E and works with the coarse amplitude cues to provide useful information for speech recognition. (C) 2018 Acoustical Society of America
C1 [Hou, Limin] Shanghai Univ, Commun & Informat Engn, Shanghai, Peoples R China.
   [Xu, Li] Ohio Univ, Commun Sci & Disorders, Athens, OH 45701 USA.
RP Xu, L (corresponding author), Ohio Univ, Commun Sci & Disorders, Athens, OH 45701 USA.
EM lmhou@staff.shu.edu.cn; xul@ohio.edu
RI Xu, Li/C-5908-2008
OI Xu, Li/0000-0002-0988-7934
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81300820/61071187]; Special Research Fund
   for the Public Welfare Industry of Health [201202001]; NIH/NIDCDUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R15-DC014587]
FX The authors are grateful to Kyle Brown, Ali Colopy, Samantha Cross,
   Yitao Mao, Lauren Muscari, and Jing Yang for their technical and
   editorial assistance. The study was supported in part by the National
   Natural Science Foundation of China (Grant No. 81300820/61071187)
   (L.H.), the Special Research Fund for the Public Welfare Industry of
   Health (Grant No. 201202001) (L.H.), and the NIH/NIDCD Grant No.
   R15-DC014587 (L.X.).
CR Apoux F, 2013, J ACOUST SOC AM, V134, P2205, DOI 10.1121/1.4816413
   Chen F, 2013, J ACOUST SOC AM, V134, pEL520, DOI 10.1121/1.4828978
   Fogerty D, 2011, J ACOUST SOC AM, V129, P977, DOI 10.1121/1.3531954
   Ghitza O, 2001, J ACOUST SOC AM, V110, P1628, DOI 10.1121/1.1396325
   Gilbert G, 2006, J ACOUST SOC AM, V119, P2438, DOI 10.1121/1.2173522
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Hopkins K, 2010, J ACOUST SOC AM, V127, P1595, DOI 10.1121/1.3293003
   Hopkins K, 2009, J ACOUST SOC AM, V125, P442, DOI 10.1121/1.3037233
   Leger AC, 2015, J ACOUST SOC AM, V137, P505, DOI 10.1121/1.4904540
   Li B, 2015, HEARING RES, V326, P66, DOI 10.1016/j.heares.2015.04.004
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lorenzi C, 2012, JARO-J ASSOC RES OTO, V13, P853, DOI 10.1007/s10162-012-0350-3
   Lorenzi C, 2009, J ACOUST SOC AM, V125, P27, DOI 10.1121/1.2939125
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Qi B, 2017, J ACOUST SOC AM, V141, P3022, DOI 10.1121/1.4982247
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Seldran F, 2011, HEARING RES, V282, P252, DOI 10.1016/j.heares.2011.06.004
   Shamma S, 2013, J ACOUST SOC AM, V133, P2818, DOI 10.1121/1.4795783
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Swaminathan J, 2014, J ACOUST SOC AM, V135, P2078, DOI 10.1121/1.4865920
   Wang S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129710
   Wang S, 2011, JARO-J ASSOC RES OTO, V12, P783, DOI 10.1007/s10162-011-0285-0
   Warton DI, 2011, ECOLOGY, V92, P3, DOI 10.1890/10-0340.1
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
   Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786
   Xu L, 2002, J ACOUST SOC AM, V112, P247, DOI 10.1121/1.1487843
   Xu L, 2008, HEARING RES, V242, P132, DOI 10.1016/j.heares.2007.12.010
   Yang J, 2017, INTERSPEECH, P1407, DOI 10.21437/Interepeech.2017-29
   Zeng FG, 2004, J ACOUST SOC AM, V116, P1351, DOI 10.1121/1.1777938
NR 30
TC 2
Z9 2
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2018
VL 143
IS 2
AR EL127
DI 10.1121/1.5024817
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA VJ4XK
UT WOS:000598750800003
PM 29495716
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Giardina, CK
   Krause, ES
   Koka, K
   Fitzpatrick, DC
AF Giardina, Christopher Kenneth
   Krause, Elliot Samuel
   Koka, Kanthaiah
   Fitzpatrick, Douglas Carl
TI Impedance Measures During in vitro Cochlear Implantation Predict Array
   Positioning
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE cochlear implants; Impedance measurement; implantable biomedical devices
ID ROUND WINDOW ELECTROCOCHLEOGRAPHY; ELECTRODE POSITION; OUTCOMES;
   PLACEMENT; INSERTION; LOCATION; HEARING; NERVE
AB Objective: Improper electrode placement during cochlear implant (CI) insertion can adversely affect speech perception outcomes. However, the intraoperative methods to determine positioning are limited. Because measures of electrode impedance can be made quickly, the goal of this study was to assess the relationship between CI impedance and proximity to adjacent structures. Methods: An Advanced Bionics CI array was inserted into a clear, plastic cochlea one electrode contact at a time in a saline bath (nine trials). At each insertion depth, response to biphasic current pulses was used to calculate access resistance (Ra), polarization resistance (Rp), and polarization capacitance (Cp). These measures were correlated to actual proximity as assessed by microscopy using linear regression models. Results: Impedance increased with insertion depth and proximity to the inner wall. Specifically, Ra increased, Cp decreased, and Rp slightly increased. Incorporating all impedance measures afforded a prediction model (r = 0.88) while optimizing for sub-mm positioning afforded a model with 78.3% specificity. Conclusion: Impedance in vitro greatly changes with electrode insertion depth and proximity to adjacent structures in a predicable manner. Significance: Assessing proximity of the CI to adjacent structures is a significant first step in qualifying the electrode-neural interface. This information should aid in CI fitting, which should help maximize hearing and speech outcomes with a CI. Additionally, knowledge of the relationship between impedance and positioning could have utility in other tissue implants in the brain, retina, or spinal cord.
C1 [Giardina, Christopher Kenneth] UNC, NCSU, Dept Biomed Engn, Chapel Hill, NC 27514 USA.
   [Krause, Elliot Samuel; Fitzpatrick, Douglas Carl] Univ N Carolina, Dept Biomed Engn, Chapel Hill, NC USA.
   [Koka, Kanthaiah] Adv Bion Corp, Sylmar, CA USA.
   [Fitzpatrick, Douglas Carl] Univ N Carolina, Dept Otolaryngol Head & Neck Surg, Chapel Hill, NC USA.
   [Fitzpatrick, Douglas Carl] North Carolina State Univ, Raleigh, NC 27695 USA.
RP Giardina, CK (corresponding author), UNC, NCSU, Dept Biomed Engn, Chapel Hill, NC 27514 USA.
EM christopher_giardina@med.unc.edu; sekrause@live.unc.edu;
   Kanthaiah.Koka@advancedbionics.com; douglas_fitzpatrick@med.unc.edu
RI Koka, Kanthaiah/AAJ-1965-2020
OI Krause, Samuel/0000-0002-7679-3989
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [F30 DC015168]; NATIONAL INSTITUTE OF
   GENERAL MEDICAL SCIENCESUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of General Medical Sciences (NIGMS) [T32GM008719, T32GM008719,
   T32GM008719, T32GM008719, T32GM008719, T32GM008719, T32GM008719,
   T32GM008719, T32GM008719, T32GM008719, T32GM008719, T32GM008719,
   T32GM008719, T32GM008719, T32GM008719, T32GM008719, T32GM008719,
   T32GM008719, T32GM008719, T32GM008719, T32GM008719, T32GM008719,
   T32GM008719, T32GM008719, T32GM008719, T32GM008719, T32GM008719,
   T32GM008719, T32GM008719, T32GM008719, T32GM008719] Funding Source: NIH
   RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F30DC015168, F30DC015168,
   F30DC015168, F30DC015168] Funding Source: NIH RePORTER
FX This work was supported by NIH F30 DC015168 and equipment donated from
   Advanced Bionics Corporation. (Corresponding Author: Christopher Kenneth
   Giardina.)
CR Adunka OF, 2016, LARYNGOSCOPE, V126, P1193, DOI 10.1002/lary.25602
   Busby P., 2013, COCHLEAR IMPLANTS IN, V3, P87
   Clark JR, 2011, J MED DEVICES, V5, DOI 10.1115/1.4002932
   Cohen LT, 1996, AM J OTOL, V17, P859
   Davis TJ, 2016, OTOL NEUROTOL, V37, P31, DOI 10.1097/MAO.0000000000000896
   Devries L, 2016, JARO-J ASSOC RES OTO, V17, P237, DOI 10.1007/s10162-016-0557-9
   Finley CC, 2008, OTOL NEUROTOL, V29, P920, DOI 10.1097/MAO.0b013e318184f492
   Fitzpatrick DC, 2014, OTOL NEUROTOL, V35, P64, DOI 10.1097/MAO.0000000000000219
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Hughes M. L., 2012, OBJECTIVE MEASURES C
   Jones GL, 2013, J ACOUST SOC AM, V133, P425, DOI 10.1121/1.4768881
   Kratchman LB, 2016, AUDIOL NEURO-OTOL, V21, P244, DOI 10.1159/000445736
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   LEHNHARDT E, 1993, HNO, V41, P356
   Limnuson K, 2014, IEEE T BIOMED CIRC S, V8, P391, DOI 10.1109/TBCAS.2013.2274574
   Mandala M, 2012, OTOLARYNG HEAD NECK, V146, P774, DOI 10.1177/0194599811435895
   McClellan JH, 2014, OTOL NEUROTOL, V35, pE245, DOI 10.1097/MAO.0000000000000557
   Mens Lucas H M, 2007, Trends Amplif, V11, P143, DOI 10.1177/1084713807304362
   Miller CA, 2008, HEARING RES, V242, P184, DOI 10.1016/j.heares.2008.04.005
   Mittmann P, 2015, OTOL NEUROTOL, V36, P1010, DOI 10.1097/MAO.0000000000000736
   Nag S, 2015, IEEE SENS J, V15, P3734, DOI 10.1109/JSEN.2015.2399248
   Noble JH, 2014, AUDIOL NEURO-OTOL, V19, P400, DOI 10.1159/000365273
   O'Connell BP, 2016, LARYNSCOPE INVESTIG, V1, P169, DOI 10.1002/lio2.42
   O'Connell BP, 2016, OTOL NEUROTOL, V37, P1016, DOI 10.1097/MAO.0000000000001125
   Pile J, 2017, LARYNGOSCOPE, V127, P1413, DOI 10.1002/lary.26183
   Radeloff A, 2012, OTOL NEUROTOL, V33, P348, DOI 10.1097/MAO.0b013e318248ea86
   Saunders E, 2002, EAR HEARING, V23, p28S, DOI 10.1097/00003446-200202001-00004
   SHEPHERD RK, 1993, HEARING RES, V66, P108, DOI 10.1016/0378-5955(93)90265-3
   Tan CT, 2013, LARYNGOSCOPE, V123, P1028, DOI 10.1002/lary.23714
   Tan LR, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.391
   Tang C, 2008, IEEE T BIO-MED ENG, V55, P2286, DOI 10.1109/TBME.2008.923919
   Tykocinski M, 2005, OTOL NEUROTOL, V26, P948, DOI 10.1097/01.mao.0000185056.99888.f3
   Vanpoucke F, 2004, OTOL NEUROTOL, V25, P282, DOI 10.1097/00129492-200405000-00014
   Vanpoucke FJ, 2012, IEEE T BIO-MED ENG, V59, P307, DOI 10.1109/TBME.2011.2173198
   Vanpoucke FJ, 2004, IEEE T BIO-MED ENG, V51, P2174, DOI 10.1109/TBME.2004.836518
   Wysocki J, 1999, HEARING RES, V135, P39, DOI 10.1016/S0378-5955(99)00088-X
NR 36
TC 7
Z9 7
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD FEB
PY 2018
VL 65
IS 2
BP 327
EP 335
DI 10.1109/TBME.2017.2764881
PG 9
WC Engineering, Biomedical
SC Engineering
GA FT1RU
UT WOS:000422914700009
PM 29346102
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Incera, S
   McLennan, CT
AF Incera, Sara
   McLennan, Conor T.
TI The time course of within and between-language interference in
   bilinguals
SO INTERNATIONAL JOURNAL OF BILINGUALISM
LA English
DT Article
DE Bilingualism; time course; activation; mouse tracking; interference
ID INTERLINGUAL INTERFERENCE; SPEECH-PERCEPTION; STROOP TASK; MONOLINGUALS;
   ACTIVATION; TRACKING; MODEL; FACILITATION; INFORMATION; MOVEMENTS
AB Purpose: Recent research has provided support for linguistic coactivation, the view that the two languages of a bilingual are simultaneously active. Importantly, even if the system is fundamentally nonselective, the two languages of a bilingual can be activated to different degrees. The main contribution of the present paper is to empirically test what different degrees of activation really means. Differences could emerge in the timing or the magnitude of language activation.
   Methodology: Most of the research to date has been based on experiments using reaction times. In the present experiment participants responded to a bilingual Stroop task using a computer mouse. We argue that mouse tracking can provide new insights into the temporal dynamics of cognitive processes.
   Data and analysis: We used a series of t-tests to analyze participants' mouse trajectories (n = 20). We compared the x-coordinates over time for each of the four experimental conditions (Congruent-Within, Congruent-Between, Incongruent-Within, Incongruent-Between) with the x-coordinates over time for the control trajectory.
   Findings: Differences in the timing, but not the magnitude, of interference are at the root of the differential effects within and between languages. Within-language interference emerged 80 ms earlier than between-language interference.
   Originality: To our knowledge, the current experiment is the first to use the dynamic mouse-tracking paradigm to compare the time course of the two languages of a bilingual participant.
   Implications: The mouse-tracking paradigm can help to distinguish between the timing and the magnitude of interference, informing current theories of the bilingual mind.
C1 [Incera, Sara; McLennan, Conor T.] Cleveland State Univ, Dept Psychol, Language Res Lab, 2121 Euclid Ave, Cleveland, OH 44115 USA.
RP Incera, S (corresponding author), Cleveland State Univ, Dept Psychol, Language Res Lab, 2121 Euclid Ave, Cleveland, OH 44115 USA.
EM saraincera@gmail.com
RI McLennan, Conor T/G-5061-2017
OI McLennan, Conor T/0000-0002-4770-262X; Incera, Sara/0000-0001-9124-9204
CR Bartolotti J, 2012, COGNITIVE SCI, V36, P1129, DOI 10.1111/j.1551-6709.2012.01243.x
   Coderre EL, 2013, BILING-LANG COGN, V16, P420, DOI 10.1017/S1366728912000405
   Dale R, 2007, MEM COGNITION, V35, P15, DOI 10.3758/BF03195938
   Dijkstra Ton, 2005, HDB BILINGUALISM PSY, P179
   DYER FN, 1971, J VERB LEARN VERB BE, V10, P297, DOI 10.1016/S0022-5371(71)80057-9
   Farmer TA, 2007, COGNITIVE SCI, V31, P889, DOI 10.1080/03640210701530797
   Freeman JB, 2011, PSYCHON B REV, V18, P705, DOI 10.3758/s13423-011-0097-6
   Freeman JB, 2010, BEHAV RES METHODS, V42, P226, DOI 10.3758/BRM.42.1.226
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   GRAINGER J, 1987, Q J EXP PSYCHOL-A, V39, P295, DOI 10.1080/14640748708401788
   GRAINGER J, 1993, BILINGUAL LEXICON, P11, DOI DOI 10.1075/SIBIL.6
   GRATTON G, 1992, J EXP PSYCHOL GEN, V121, P480, DOI 10.1037/0096-3445.121.4.480
   Grosjean F., 1998, BILING-LANG COGN, V1, P131, DOI DOI 10.1017/S136672899800025X
   Incera S., 2013, OHIO PSYCHOL, V60, P33
   Incera S, 2016, BILING-LANG COGN, V19, P610, DOI 10.1017/S1366728915000218
   KLEIN GS, 1964, AM J PSYCHOL, V77, P576, DOI 10.2307/1420768
   Krestar M., 2013, OHIO PSYCHOL, V60, P29
   Libben MR, 2009, J EXP PSYCHOL LEARN, V35, P381, DOI 10.1037/a0014875
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   MACLEOD CM, 1991, PSYCHOL BULL, V109, P163, DOI 10.1037/0033-2909.109.2.163
   MAGISTE E, 1985, J PSYCHOLINGUIST RES, V14, P137, DOI 10.1007/BF01067626
   Marian V, 2003, BRAIN LANG, V86, P70, DOI 10.1016/S0093-934X(02)00535-7
   Marian V, 2003, APPL PSYCHOLINGUIST, V24, P173, DOI 10.1017/S0142716403000092
   Marian V., 2003, BILING-LANG COGN, V6, P97, DOI DOI 10.1017/S1366728903001068
   Mayr U, 2003, NAT NEUROSCI, V6, P450, DOI 10.1038/nn1051
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   PRESTON MS, 1969, J VERB LEARN VERB BE, V8, P295, DOI 10.1016/S0022-5371(69)80079-4
   Roelofs A, 2010, J EXP PSYCHOL LEARN, V36, P411, DOI 10.1037/a0018523
   Scherbaum S, 2010, COGNITION, V115, P407, DOI 10.1016/j.cognition.2010.02.004
   Schmidt JR, 2011, ACTA PSYCHOL, V138, P176, DOI 10.1016/j.actpsy.2011.06.002
   Schwartz AI, 2006, J MEM LANG, V55, P197, DOI 10.1016/j.jml.2006.03.004
   Spivey MJ, 2005, P NATL ACAD SCI USA, V102, P10393, DOI 10.1073/pnas.0503903102
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Tse CS, 2012, BILING-LANG COGN, V15, P663, DOI 10.1017/S1366728912000077
NR 35
TC 3
Z9 3
U1 0
U2 12
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1367-0069
EI 1756-6878
J9 INT J BILINGUAL
JI Int. J. Biling.
PD FEB
PY 2018
VL 22
IS 1
BP 88
EP 99
DI 10.1177/1367006916644688
PG 12
WC Linguistics; Language & Linguistics
SC Linguistics
GA FR8CJ
UT WOS:000419301300006
DA 2021-02-24
ER

PT J
AU Nakashima, A
   Abel, SM
   Smith, I
AF Nakashima, Ann
   Abel, Sharon M.
   Smith, Ingrid
TI Communication in military environments: Influence of noise, hearing
   protection and language proficiency
SO APPLIED ACOUSTICS
LA English
DT Article
DE Hearing protection; Military noise; Speech understanding; Non-native
   speech
ID NONNATIVE SPEECH-PERCEPTION; INTELLIGIBILITY; 2ND-LANGUAGE; HEADSETS;
   COMMAND
AB Military training and international operations require different nationalities to communicate in a common language, where there are potential challenges with non-native (L2) speech communication. An experiment of speech communication in military noise was conducted for co-located (face-to-face [F2F]) and distributed (using communication headsets) talker-listener pairs. Half of the twenty-four participants were monolingual English speakers (native group, NA) and the remaining half had obtained English fluency after the age of eight years (non-native group, NN). Two tests of speech understanding were used: the Modified Rhyme Test (MRT) and the Speech Perception in Noise test (SPIN). In the F2F condition, the participants wore a communication headset (earmuff) with the power off for occluded listening. Three levels of armoured vehicle noise were used, 55, 60 and 65 dBA, for speech-to-noise ratios ranging from -10 to +5 dB. In the radio condition, the pairs Were separated by a visual barrier and used the communication headset for the tests in 80 dBA armoured vehicle noise. The results showed that the NN group had difficulty with the SPIN test in the radio and F2F conditions. This result was attributed to the open-response set of the SPIN. Headset occlusion likely contributed to the lower scores for the NN listeners in the F2F condition. There was a main effect of talker for the MRT in the F2F and radio conditions, and for the SPIN in the radio condition, suggesting that foreign accent reduced the intelligibility for both the NA and NN groups. The results were surprising considering the high L2 proficiency of the NN group. Training methods for improving L2 communication in operational settings should be further investigated.
C1 [Nakashima, Ann; Abel, Sharon M.; Smith, Ingrid] Def Res & Dev Canada, Toronto Res Ctr, 1133 Sheppard Ave West, Toronto, ON M3K 2C9, Canada.
RP Nakashima, A (corresponding author), Def Res & Dev Canada, Toronto Res Ctr, 1133 Sheppard Ave West, Toronto, ON M3K 2C9, Canada.
EM arm.nalcashima@drdc-rddc.gc.ca
FU Personnel Portfolio, Diagnostics and Health Protection Project (04k),
   Defence Research and Development Canada
FX The work was supported by the Personnel Portfolio, Diagnostics and
   Health Protection Project (04k), Defence Research and Development
   Canada. The project sponsors and clients did not participate in the
   design of this work or the decision to submit for publication. A portion
   of this work was published as a conference proceedings paper and
   presented at Acoustics Week in Canada, Halifax, NS, Canada [31].
CR Abel SM, 2014, MIL MED, V179, P1036, DOI 10.7205/MILMED-D-13-00556
   Abel SM, 2012, MIL MED, V177, P436, DOI 10.7205/MILMED-D-11-00283
   Abel SM, 2011, NOISE HEALTH, V13, P378, DOI 10.4103/1463-1741.90289
   Abel SM, 1999, APPL ACOUST, V57, P61, DOI 10.1016/S0003-682X(98)00024-3
   ABEL SM, 1982, J ACOUST SOC AM, V71, P708, DOI 10.1121/1.387547
   Abel SM, 2015, DRDCRDDC2015R066
   [Anonymous], S12422010 ANSIASA
   [Anonymous], S321999 ANSIASA
   BELL DW, 1972, J SPEECH HEAR RES, V15, P287, DOI 10.1044/jshr.1502.287
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Brammer AJ, 2014, J ACOUST SOC AM, V136, P671, DOI 10.1121/1.4883385
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Casali JG, 2010, INT J ACOUST VIB, V15, P168
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Farris C, 2008, TESOL QUART, V42, P397, DOI 10.2307/40264475
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Giguere C, 2015, DRDCRDDC2015C239, P62
   Giguere C, 2015, INT J AUDIOL, V54, pS9, DOI 10.3109/14992027.2014.973540
   Giguere C, 2012, NOISE CONTROL ENG J, V60, P630, DOI 10.3397/1.3701037
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Markham D, 2004, J SPEECH LANG HEAR R, V47, P725, DOI 10.1044/1092-4388(2004/055)
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   Nakashima A, 2015, CAN ACOUST, V43, P113
   Nakashima A, 2009, TR2009074 DRDC
   Nakashima AM, 2007, IND HEALTH, V45, P318, DOI 10.2486/indhealth.45.318
   Nixon CW, 1998, AVIAT SPACE ENVIR MD, V69, P675
   Park J., PROFILE CANADIAN FOR, P17
   Rajguru R, 2013, AVIAT SPACE ENVIR MD, V84, P1268, DOI 10.3357/ASEM.3503.2013
   Song JH, 2012, CEREB CORTEX, V22, P1180, DOI 10.1093/cercor/bhr196
   Tufts JB, 2003, J ACOUST SOC AM, V114, P1069, DOI 10.1121/1.1592165
NR 31
TC 1
Z9 1
U1 1
U2 12
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0003-682X
EI 1872-910X
J9 APPL ACOUST
JI Appl. Acoust.
PD FEB
PY 2018
VL 131
BP 38
EP 44
DI 10.1016/j.apacoust.2017.10.010
PG 7
WC Acoustics
SC Acoustics
GA FQ2YK
UT WOS:000418223700005
DA 2021-02-24
ER

PT J
AU Mitterer, H
   Reinisch, E
   McQueen, JM
AF Mitterer, Holger
   Reinisch, Eva
   McQueen, James M.
TI Allophones, not phonemes in spoken-word recognition
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Spoken-word recognition; Phonemes; Allophones; Pre-lexical
   representations; Selective adaptation
ID PHONOLOGICAL ABSTRACTION; SPEECH-PERCEPTION; ADAPTATION;
   REPRESENTATIONS; RECALIBRATION; CATEGORIES; NONSPEECH; LANGUAGE;
   ENGLISH; ORDER
AB What are the phonological representations that listeners use to map information about the segmental content of speech onto the mental lexicon during spoken-word recognition? Recent evidence from perceptual-learning paradigms seems to support (context-dependent) allophones as the basic representational units in spoken-word recognition. But recent evidence from a selective-adaptation paradigm seems to suggest that context-independent phonemes also play a role. We present three experiments using selective adaptation that constitute strong tests of these representational hypotheses. In Experiment 1, we tested generalization of selective adaptation using different allophones of Dutch /r/ and /l/-a case where generalization has not been found with perceptual learning. In Experiments 2 and 3, we tested generalization of selective adaptation using German back fricatives in which allophonic and phonemic identity were varied orthogonally. In all three experiments, selective adaptation was observed only if adaptors and test stimuli shared allophones. Phonemic identity, in contrast, was neither necessary nor sufficient for generalization of selective adaptation to occur. These findings and other recent data using the perceptual-learning paradigm suggest that pre-lexical processing during spoken-word recognition is based on allophones, and not on context-independent phonemes. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Mitterer, Holger] Univ Malta, Fac Media & Knowledge Sci, Dept Cognit Sci, MSD-2080 Msida, Malta.
   [Reinisch, Eva] Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Munich, Germany.
   [McQueen, James M.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [McQueen, James M.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
RP Mitterer, H (corresponding author), Univ Malta, Fac Media & Knowledge Sci, Dept Cognit Sci, MSD-2080 Msida, Malta.
EM holger.mitterer@um.edu.mt
RI Mitterer, Holger/D-1908-2010; McQueen, James M./B-2212-2010; Reinisch,
   Eva/R-1646-2016
OI Mitterer, Holger/0000-0003-4318-0032; McQueen, James
   M./0000-0003-3734-6286; Reinisch, Eva/0000-0002-1400-5473
FU University of Malta Research Grant; Emmy-Noether Fellowship by German
   Research Council (DFG) [RE 3047/1-1]
FX This work was supported by a University of Malta Research Grant to the
   first author. The second author was supported by an Emmy-Noether
   Fellowship by the German Research Council (DFG, grant nr. RE 3047/1-1).
CR Baguley T, 2010, BRIT J MATH STAT PSY, V63, P695, DOI 10.1348/000711009X481027
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Boersma P., 1998, FUNCTIONAL PHONOLOGY
   Bowers JS, 2016, J MEM LANG, V87, P71, DOI 10.1016/j.jml.2015.11.002
   Burki A, 2012, J EXP PSYCHOL LEARN, V38, P617, DOI 10.1037/a0026167
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403
   Dienes Z, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00781
   Dixon P, 2008, J MEM LANG, V59, P447, DOI 10.1016/j.jml.2007.11.004
   Draxler Christoph, 2004, P 4 INT C LANG RES E, P559
   Dumay N, 2012, J MEM LANG, V66, P680, DOI 10.1016/j.jml.2012.03.001
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Ettlinger M, 2009, PHONETICA, V66, P222, DOI 10.1159/000298584
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   GOLDINGER SD, 1989, J MEM LANG, V28, P501, DOI 10.1016/0749-596X(89)90009-0
   Harnad S., 1987, CATEGORICAL PERCEPTI, P199
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Jesse A, 2011, PSYCHON B REV, V18, P943, DOI 10.3758/s13423-011-0129-2
   Kang S, 2016, SPEECH COMMUN, V77, P84, DOI 10.1016/j.specom.2015.12.005
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Keetels M, 2016, J PHONETICS, V56, P124, DOI 10.1016/j.wocn.2016.02.005
   Keetels M, 2015, COGNITION, V141, P121, DOI 10.1016/j.cognition.2015.04.019
   Kleinschmidt DF, 2016, PSYCHON B REV, V23, P678, DOI 10.3758/s13423-015-0943-z
   KOLINSKY R, 1995, J MEM LANG, V34, P19, DOI 10.1006/jmla.1995.1002
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Krieger-Redwood K, 2013, J COGNITIVE NEUROSCI, V25, P2179, DOI 10.1162/jocn_a_00463
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Liberman AM, 1996, SPEECH SPECIAL CODE
   Lotto AJ, 2009, TRENDS COGN SCI, V13, P110, DOI 10.1016/j.tics.2008.11.008
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   MacMillan NA, 1991, DETECTION THEORY USE
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McQueen J. M, 2005, HDB COGNITION, P255, DOI DOI 10.4135/9781848608177.N11
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   McQueen JM, 1999, J EXP PSYCHOL HUMAN, V25, P1363, DOI 10.1037/0096-1523.25.5.1363
   MEHLER J, 1981, J VERB LEARN VERB BE, V20, P298, DOI 10.1016/S0022-5371(81)90450-3
   Mitterer H, 2017, LANG COGN NEUROSCI, V32, P1133, DOI 10.1080/23273798.2017.1286361
   Mitterer H, 2016, J PHONETICS, V56, P110, DOI 10.1016/j.wocn.2016.03.001
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Mitterer H, 2013, COGNITION, V129, P356, DOI 10.1016/j.cognition.2013.07.011
   Mitterer H, 2013, ATTEN PERCEPT PSYCHO, V75, P557, DOI 10.3758/s13414-012-0407-8
   Mitterer H, 2011, COGNITIVE SCI, V35, P184, DOI 10.1111/j.1551-6709.2010.01140.x
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Morey R. D., 2015, BAYESFACTOR COMPUTAT
   Morey RD, 2008, TUTOR QUANT METHODS, V4, P61, DOI 10.20982/tqmp.04.2.p061
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Ohala JJ, 1996, J ACOUST SOC AM, V99, P1718, DOI 10.1121/1.414696
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Poellmann K, 2014, J PHONETICS, V46, P101, DOI 10.1016/j.wocn.2014.06.004
   Poeppel D., 2014, LANG COGN NEUROSCI, P1
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   REMEZ RE, 1979, COGNITIVE PSYCHOL, V11, P38, DOI 10.1016/0010-0285(79)90003-3
   Repp B. H., 1987, CATEGORICAL PERCEPTI, P89
   Rouder JN, 2017, PSYCHOL METHODS, V22, P304, DOI 10.1037/met0000057
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Salverda AP, 2014, J MEM LANG, V71, P145, DOI 10.1016/j.jml.2013.11.002
   Samuel AG, 1996, J EXP PSYCHOL HUMAN, V22, P676
   SAWUSCH JR, 1981, J EXP PSYCHOL HUMAN, V7, P408, DOI 10.1037/0096-1523.7.2.408
   Schuppler B, 2014, INTERSPEECH, P1453
   Sjerps MJ, 2010, J EXP PSYCHOL HUMAN, V36, P195, DOI 10.1037/a0016803
   Smits R, 2001, J EXP PSYCHOL HUMAN, V27, P1145, DOI 10.1037/0096-1523.27.5.1145
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   Sussman HM, 1998, BEHAV BRAIN SCI, V21, P241, DOI 10.1017/S0140525X98001174
   Toscano JC, 2013, PSYCHON B REV, V20, P981, DOI 10.3758/s13423-013-0417-0
   van Bezooijen R, 2005, SPEECH COMMUN, V47, P15, DOI 10.1016/j.specom.2005.04.010
   Weber A, 2001, LANG SPEECH, V44, P95, DOI 10.1177/00238309010440010401
   WICKELGR.WA, 1969, PSYCHOL REV, V76, P1, DOI 10.1037/h0026823
   Wurm LH, 1997, J MEM LANG, V37, P438, DOI 10.1006/jmla.1997.2524
NR 79
TC 13
Z9 13
U1 2
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD FEB
PY 2018
VL 98
BP 77
EP 92
DI 10.1016/j.jml.2017.09.005
PG 16
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA FL3HR
UT WOS:000414114000006
OA Green Published
DA 2021-02-24
ER

PT J
AU Yu, LD
   Zhang, Y
AF Yu, Luodi
   Zhang, Yang
TI Testing native language neural commitment at the brainstem level: A
   cross-linguistic investigation of the association between
   frequency-following response and speech perception
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Native language neural commitment Theory; Frequency following response;
   Speech perception; Lexical tones; Garner paradigm
ID FUNDAMENTAL-FREQUENCY; PITCH CONTOURS; MISMATCH NEGATIVITY; LEXICAL
   TONES; INFANT BRAIN; EXPERIENCE; CHINESE; REPRESENTATION; INFORMATION;
   PLASTICITY
AB A current topic in auditory neurophysiology is how brainstem sensory coding contributes to higher-level perceptual, linguistic and cognitive skills. This cross-language study was designed to compare frequency following responses (FFRs) for lexical tones in tonal (Mandarin Chinese) and non-tonal (English) language users and test the correlational strength between FFRs and behavior as a function of language experience. The behavioral measures were obtained in the Garner paradigm to assess how lexical tones might interfere with vowel category and duration judgement. The FFR results replicated previous findings about between-group differences, showing enhanced pitch tracking responses in the Chinese subjects. The behavioral data from the two subject groups showed that lexical tone variation in the vowel stimuli significantly interfered with vowel identification with a greater effect in the Chinese group. Moreover, the FFRs for lexical tone contours were significantly correlated with the behavioral interference only in the Chinese group. This pattern of language-specific association between speech perception and brainstem-level neural phase-locking of linguistic pitch information provides evidence for a possible native language neural commitment at the subcortical level, highlighting the role of experience dependent brainstem tuning in influencing subsequent linguistic processing in the adult brain.
C1 [Yu, Luodi; Zhang, Yang] Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
   [Yu, Luodi; Zhang, Yang] South China Normal Univ, Sch Psychol, Guangzhou 510631, Guangdong, Peoples R China.
   [Zhang, Yang] Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN 55455 USA.
RP Zhang, Y (corresponding author), Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
EM zhanglab@umn.edu
RI Zhang, Yang/Q-1780-2015
OI Zhang, Yang/0000-0001-6777-3487
FU Graduate Research Partnership Program Fellowship at the University of
   Minnesota; Grand Challenges Exploratory Research Grant at the University
   of MinnesotaUniversity of Minnesota System; Brain Imaging Research
   Project Award at the University of MinnesotaUniversity of Minnesota
   System; Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [NSFC 31728009]
FX This work was funded in part by the Graduate Research Partnership
   Program Fellowship (LY), the Grand Challenges Exploratory Research Grant
   (YZ) and Brain Imaging Research Project Award (YZ) at the University of
   Minnesota, and a grant from the Natural Science Foundation of China (YZ,
   NSFC 31728009). We thank Drs. Dorea Ruggles and Andrew Byrne at the
   Multisensory Perception Laboratory for their assistance in EEG data
   collection.
CR Baumann S, 2008, J COGNITIVE NEUROSCI, V20, P2238, DOI 10.1162/jocn.2008.20157
   Bidelman GM, 2017, SPRINGER HANDB AUDIT, V61, P193, DOI 10.1007/978-3-319-47944-6_8
   Bidelman GM, 2015, BRAIN LANG, V143, P32, DOI 10.1016/j.bandl.2015.02.002
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Boersma P., 2014, PRAAT DOING PHONETIC
   BRIGNER WL, 1988, PERCEPT MOTOR SKILL, V67, P301, DOI 10.2466/pms.1988.67.1.301
   Carcagno S, 2011, JARO-J ASSOC RES OTO, V12, P89, DOI 10.1007/s10162-010-0236-1
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chandrasekaran B, 2012, J NEUROPHYSIOL, V107, P1325, DOI 10.1152/jn.00923.2011
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Cumming R, 2011, J PHONETICS, V39, P375, DOI 10.1016/j.wocn.2011.01.004
   Dahmen JC, 2007, CURR OPIN NEUROBIOL, V17, P456, DOI 10.1016/j.conb.2007.07.004
   GARNER WR, 1970, COGNITIVE PSYCHOL, V1, P225, DOI 10.1016/0010-0285(70)90016-2
   Ghazanfar AA, 2009, BEHAV NEUROSCI, V123, P822, DOI 10.1037/a0016391
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Intartaglia B, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12575-1
   Intartaglia B, 2016, NEUROPSYCHOLOGIA, V89, P57, DOI 10.1016/j.neuropsychologia.2016.05.033
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Jamieson Donald G, 2004, J Am Acad Audiol, V15, P508, DOI 10.3766/jaaa.15.7.5
   Jeng FC, 2016, J ACOUST SOC AM, V139, pEL190, DOI 10.1121/1.4953998
   Jeng FC, 2016, PERCEPT MOTOR SKILL, V122, P123, DOI 10.1177/0031512516631054
   Jeng FC, 2011, EAR HEARING, V32, P699, DOI 10.1097/AUD.0b013e31821cc0df
   Johnson MH, 2001, NAT REV NEUROSCI, V2, P475, DOI 10.1038/35081509
   Jongman A., 2006, PERCEPTION PRODUCTIO
   Keating P, 2012, J ACOUST SOC AM, V132, P1050, DOI 10.1121/1.4730893
   Kleiner M, 2007, PERCEPTION, V36, P14
   Koerner TK, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7030026
   Kraus N, 2017, SPRINGER HANDB AUDIT, V61, P1, DOI 10.1007/978-3-319-47944-6_1
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Krishnan A, 2004, HEARING RES, V189, P1, DOI 10.1016/S0378-5955(03)00402-7
   Krishnan A, 2017, SPRINGER HANDB AUDIT, V61, P45, DOI 10.1007/978-3-319-47944-6_3
   Krishnan A, 2015, J NEUROLINGUIST, V33, P128, DOI 10.1016/j.jneuroling.2014.08.002
   Krishnan A, 2014, BRAIN LANG, V138, P51, DOI 10.1016/j.bandl.2014.09.005
   Krishnan A, 2010, BRAIN LANG, V114, P193, DOI 10.1016/j.bandl.2010.05.004
   Krishnan A, 2010, BRAIN RES, V1313, P124, DOI 10.1016/j.brainres.2009.11.061
   Krishnan A, 2010, J NEUROLINGUIST, V23, P81, DOI 10.1016/j.jneuroling.2009.09.001
   Krishnan A, 2009, J COGNITIVE NEUROSCI, V21, P1092, DOI 10.1162/jocn.2009.21077
   Krishnan A, 2009, NEUROREPORT, V20, P408, DOI 10.1097/WNR.0b013e3283263000
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   Lake JI, 2014, ACTA PSYCHOL, V149, P169, DOI 10.1016/j.actpsy.2014.03.010
   LEE L, 1993, PERCEPT PSYCHOPHYS, V53, P157, DOI 10.3758/BF03211726
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   Lehiste I., 1976, J PHONETICS, V4, P113
   Luo H, 2006, P NATL ACAD SCI USA, V103, P19558, DOI 10.1073/pnas.0607065104
   Mamiya PC, 2016, P NATL ACAD SCI USA, V113, P7249, DOI 10.1073/pnas.1606602113
   Musacchia G, 2008, HEARING RES, V241, P34, DOI 10.1016/j.heares.2008.04.013
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Nelken I, 2004, CURR OPIN NEUROBIOL, V14, P474, DOI 10.1016/j.conb.2004.06.005
   PISONI DB, 1976, J ACOUST SOC AM, V59, pS39, DOI 10.1121/1.2002669
   Ramirez NF, 2017, MIND BRAIN EDUC, V11, P133, DOI 10.1111/mbe.12144
   Rao A, 2010, HEARING RES, V268, P123, DOI 10.1016/j.heares.2010.05.013
   Reetz H., 2011, PHONETICS TRANSCRIPT, V34
   REPP BH, 1990, J PHONETICS, V18, P481, DOI 10.1016/S0095-4470(19)30410-3
   Russo NM, 2005, BEHAV BRAIN RES, V156, P95, DOI 10.1016/j.bbr.2004.05.012
   Schlauch RS, 2001, J ACOUST SOC AM, V109, P2880, DOI 10.1121/1.1372913
   SHEN XNS, 1993, J ACOUST SOC AM, V93, P2241, DOI 10.1121/1.406688
   Skoe E, 2015, J COGNITIVE NEUROSCI, V27, P124, DOI 10.1162/jocn_a_00691
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Song JH, 2008, J COGNITIVE NEUROSCI, V20, P1892, DOI 10.1162/jocn.2008.20131
   Stevens J, 2014, J NEUROLINGUIST, V30, P27, DOI 10.1016/j.jneuroling.2014.03.003
   Swaminathan J, 2008, NEUROREPORT, V19, P1163, DOI 10.1097/WNR.0b013e3283088d31
   Swaminathan J, 2008, IEEE T BIO-MED ENG, V55, P281, DOI 10.1109/TBME.2007.896592
   Tong YX, 2008, LANG COGNITIVE PROC, V23, P689, DOI 10.1080/01690960701728261
   Wang W. S. Y., 1976, J ACOUST SOC AM, V60
   Weiss MW, 2015, J NEUROSCI, V35, P1687, DOI 10.1523/JNEUROSCI.3680-14.2015
   White-Schwoch T, 2017, SPRINGER HANDB AUDIT, V61, P121, DOI 10.1007/978-3-319-47944-6_6
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Xu Y, 1997, J PHONETICS, V25, P61, DOI 10.1006/jpho.1996.0034
   Xu YS, 2006, NEUROREPORT, V17, P1601, DOI 10.1097/01.wnr.0000236865.31705.3a
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Yu Alan C. L., 2010, LAB PHONOLOGY, V10, P151, DOI DOI 10.1515/9783110224917.2.151
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
   Zhang LJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00908
   Zhang Y, 2005, NEUROIMAGE, V26, P703, DOI 10.1016/j.neuroimage.2005.02.040
   Zhang Y, 2007, BILING-LANG COGN, V10, P147, DOI 10.1017/S1366728907002908
   Zhang Y, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6030027
   Zhang Y, 2011, DEVELOPMENTAL SCI, V14, P566, DOI 10.1111/j.1467-7687.2010.01004.x
   Zhang Y, 2009, NEUROIMAGE, V46, P226, DOI 10.1016/j.neuroimage.2009.01.028
NR 85
TC 3
Z9 3
U1 0
U2 3
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD JAN 31
PY 2018
VL 109
BP 140
EP 148
DI 10.1016/j.neuropsychologia.2017.12.022
PG 9
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FW3JJ
UT WOS:000425202400015
PM 29246484
DA 2021-02-24
ER

PT J
AU Treille, A
   Vilain, C
   Schwartz, JL
   Hueber, T
   Sato, M
AF Treille, Avril
   Vilain, Coriandre
   Schwartz, Jean-Luc
   Hueber, Thomas
   Sato, Marc
TI Electrophysiological evidence for Audio-visuo-lingual speech integration
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Speech perception; Audio-visual integration; Visual tongue feedback;
   Action perception; EEG
ID HUMAN AUDITORY-CORTEX; AUDIOVISUAL SPEECH; MULTISENSORY INTEGRATION;
   VISIBLE SPEECH; SEEING VOICES; MOTOR SYSTEM; HEARING LIPS; BROCAS AREA;
   PERCEPTION; CONTEXT
AB Recent neurophysiological studies demonstrate that audio-visual speech integration partly operates through temporal expectations and speech-specific predictions. From these results, one common view is that the binding of auditory and visual, lipread, speech cues relies on their joint probability and prior associative audio-visual experience. The present EEG study examined whether visual tongue movements integrate with relevant speech sounds, despite little associative audio-visual experience between the two modalities. A second objective was to determine possible similarities and differences of audio-visual speech integration between unusual audio-visuo-lingual and classical audio-visuo-labial modalities. To this aim, participants were presented with auditory, visual, and audio-visual isolated syllables, with the visual presentation related to either a sagittal view of the tongue movements or a facial view of the lip movements of a speaker, with lingual and facial movements previously recorded by an ultrasound imaging system and a video camera. In line with previous EEG studies, our results revealed an amplitude decrease and a latency facilitation of P2 auditory evoked potentials in both audiovisual-lingual and audio-visuo-labial conditions compared to the sum of unimodal conditions. These results argue against the view that auditory and visual speech cues solely integrate based on prior associative audiovisual perceptual experience. Rather, they suggest that dynamic and phonetic informational cues are sharable across sensory modalities, possibly through a cross-modal transfer of implicit articulatory motor knowledge.
C1 [Treille, Avril; Vilain, Coriandre; Schwartz, Jean-Luc; Hueber, Thomas] Univ Grenoble Alpes, GIPSA Lab, Dept Parole & Cognit, Grenoble, France.
   [Treille, Avril; Vilain, Coriandre; Schwartz, Jean-Luc; Hueber, Thomas] CNRS, Grenoble, France.
   [Sato, Marc] Aix Marseille Univ, Lab Parole & Langage, Aix En Provence, France.
   [Sato, Marc] CNRS, Aix En Provence, France.
RP Sato, M (corresponding author), CNRS, UMR 7309, Lab Parole & Langage, 5 Ave Pasteur, F-13100 Aix En Provence, France.; Sato, M (corresponding author), Aix Marseille Univ, 5 Ave Pasteur, F-13100 Aix En Provence, France.
EM marc.sato@lpl-aix.fr
FU European Research Council (FP7) [339152]
FX This study was supported by research funds from the European Research
   Council (FP7/2007-2013 Grant Agreement No. 339152). Any opinions,
   findings, and conclusions or recommendations expressed in this material
   are those of the authors and do not necessarily reflect the views of the
   funding agency.
CR Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Baart M, 2015, J MEM LANG, V85, P42, DOI 10.1016/j.jml.2015.06.008
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Badin P, 2010, SPEECH COMMUN, V52, P493, DOI 10.1016/j.specom.2010.03.002
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   BENOI C, 1994, J SPEECH HEAR RES, V37, P1195, DOI 10.1044/jshr.3705.1195
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Callan DE, 2004, J COGNITIVE NEUROSCI, V16, P805, DOI 10.1162/089892904970771
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Campbell CS, 1997, PERCEPTION, V26, P627, DOI 10.1068/p260627
   Campbell R, 2001, COGNITIVE BRAIN RES, V12, P233, DOI 10.1016/S0926-6410(01)00054-4
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   D'Ausilio A, 2014, NEUROPSYCHOLOGIA, V63, P85, DOI 10.1016/j.neuropsychologia.2014.08.018
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Derrick D, 2013, MULTISENS RES, V26, P405, DOI 10.1163/22134808-00002427
   Fowler C. A., 2004, HDB MULTISENSORY PRO, P189
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Frtusova JB, 2013, PSYCHOL AGING, V28, P481, DOI 10.1037/a0031243
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Ganesh AC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01340
   Gick B, 2008, J ACOUST SOC AM, V123, pEL72, DOI 10.1121/1.2884349
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   GREEN KP, 1998, HEARING EYE, V2, P3
   Hertrich I, 2007, NEUROPSYCHOLOGIA, V45, P1342, DOI 10.1016/j.neuropsychologia.2006.09.019
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hisanaga S, 2016, SCI REP-UK, V6, DOI 10.1038/srep35265
   Hueber T., 2008, P INT SEM SPEECH PRO, P365
   Huhn Z, 2009, NEUROSCI LETT, V465, P204, DOI 10.1016/j.neulet.2009.08.077
   Ito T, 2012, J NEUROPHYSIOL, V107, P442, DOI 10.1152/jn.00029.2011
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Jones J. A., 1997, Canadian Acoustics, V25, P13
   Kaganovich N, 2014, BRAIN LANG, V139, P36, DOI 10.1016/j.bandl.2014.09.011
   Katz WE, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00612
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Liberman A. M., 2000, TRENDS COGN SCI, V3, P254
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Navarra J., 2005, PSYCHOL RES, V71, P4, DOI DOI 10.1007/S00426-005-0031-5
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Paris T, 2016, CORTEX, V75, P220, DOI 10.1016/j.cortex.2015.03.010
   Pekkola J, 2006, NEUROIMAGE, V29, P797, DOI 10.1016/j.neuroimage.2005.09.069
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Rosenblum LD, 2016, ECOL PSYCHOL, V28, P262, DOI 10.1080/10407413.2016.1230373
   Sato M, 2010, NEUROPSYCHOLOGIA, V48, P3683, DOI 10.1016/j.neuropsychologia.2010.08.017
   Sato M, 2010, SPEECH COMMUN, V52, P533, DOI 10.1016/j.specom.2009.12.004
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Schepers IM, 2013, NEUROIMAGE, V70, P101, DOI 10.1016/j.neuroimage.2012.11.066
   SCHERG M, 1986, ELECTROEN CLIN NEURO, V65, P344, DOI 10.1016/0168-5597(86)90014-6
   Schwartz J.-L., 2004, ERIC J REP RES COGN, V93, P69
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Stekelenburg JJ, 2013, SCHIZOPHR RES, V147, P253, DOI 10.1016/j.schres.2013.04.038
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Sundara M, 2001, NEUROREPORT, V12, P1341, DOI 10.1097/00001756-200105250-00010
   Treille A., 2017, EXP BRAIN RES
   Treille A, 2017, J COGNITIVE NEUROSCI, V29, P448, DOI 10.1162/jocn_a_01057
   Treille A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00420
   Treille A, 2014, NEUROPSYCHOLOGIA, V57, P71, DOI 10.1016/j.neuropsychologia.2014.02.004
   Tremblay P, 2011, NEUROIMAGE, V57, P1561, DOI 10.1016/j.neuroimage.2011.05.067
   Tremblay P, 2011, CEREB CORTEX, V21, P1166, DOI 10.1093/cercor/bhq189
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   Venezia JH, 2016, ATTEN PERCEPT PSYCHO, V78, P583, DOI 10.3758/s13414-015-1026-y
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Winneke AH, 2011, PSYCHOL AGING, V26, P427, DOI 10.1037/a0021683
NR 83
TC 1
Z9 1
U1 1
U2 16
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD JAN 31
PY 2018
VL 109
BP 126
EP 133
DI 10.1016/j.neuropsychologia.2017.12.024
PG 8
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FW3JJ
UT WOS:000425202400013
PM 29248497
DA 2021-02-24
ER

PT J
AU Kakouros, S
   Salminen, N
   Rasanen, O
AF Kakouros, Sofoklis
   Salminen, Nelli
   Rasanen, Okko
TI Making predictable unpredictable with style - Behavioral and
   electrophysiological evidence for the critical role of prosodic
   expectations in the perception of prominence in speech
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Statistical learning; Prosody; Attention; Prominence; Event-related
   potentials; Speech perception
ID FUNDAMENTAL-FREQUENCY; NEURAL MECHANISMS; SPOKEN LANGUAGE; ACOUSTIC
   CUES; BRAIN; WORD; POTENTIALS; ATTENTION; N400; COMPREHENSION
AB Perceptual prominence of linguistic units such as words has been earlier connected to the concepts of predictability and attentional orientation. One hypothesis is that low-probability prosodic or lexical content is perceived as prominent due to the surprisal and high information value associated with the stimulus. However, the existing behavioral studies have used stimulus manipulations that follow or violate typical linguistic patterns present in the listeners' native language, i.e., assuming that the listeners have already established a model for acceptable prosodic patterns in the language. In the present study, we investigated whether prosodic expectations and the resulting subjective impression of prominence is affected by brief statistical adaptation to suprasegmental acoustic features in speech, also in the case where the prosodic patterns do not necessarily follow language-typical marking for prominence. We first exposed listeners to five minutes of speech with uneven distributions of falling and rising fundamental frequency (F0) trajectories on sentence-final words, and then tested their judgments of prominence on a set of new utterances. The results show that the probability of the F0 trajectory affects the perception of prominence, a less frequent F0 trajectory making a word more prominent independently of the absolute direction of F0 change. In the second part of the study, we conducted EEG-measurements on a set of new subjects listening to similar utterances with predominantly rising or falling F0 on sentence-final words. Analysis of the resulting event-related potentials (ERP) reveals a significant difference in N200 and N400 ERP-component amplitudes between standard and deviant prosody, again independently of the F0 direction and the underlying lexical content. Since N400 has earlier been associated with semantic processing of stimuli, this suggests that listeners implicitly track probabilities at the suprasegmental level and that predictability of a prosodic pattern during a word has an impact to the semantic processing of the word. Overall, the study suggests that prosodic markers for prominence are at least partially driven by the statistical structure of recently perceived speech, and therefore prominence perception could be based on statistical learning mechanisms similar to those observed in early word learning, but in this case operating at the level of suprasegmental acoustic features.
C1 [Kakouros, Sofoklis; Salminen, Nelli; Rasanen, Okko] Aalto Univ, Dept Signal Proc & Acoust, POB 12200, FI-00076 Espoo, Finland.
   [Salminen, Nelli] Aalto Univ, Aalto Neuroimaging, Aalto Behav Lab, FI-00076 Espoo, Finland.
RP Rasanen, O (corresponding author), Aalto Univ, Dept Signal Proc & Acoust, POB 12200, FI-00076 Espoo, Finland.
EM sofoklis.kakouros@aalto.fi; nelli.salminen@aalto.fi;
   oldco.rasanen@aalto.fi
RI Rasanen, Okko/P-7904-2016; Kakouros, Sofoklis/E-2404-2012
OI Rasanen, Okko/0000-0002-0537-0946; Kakouros,
   Sofoklis/0000-0001-8996-0793
FU Academy of FinlandAcademy of FinlandEuropean Commission [312490, 269279,
   274479, 312105, 296751]
FX An initial report on the behavioral results of the first experiment was
   presented in the Annual Conference of the Cognitive Science Society held
   at Philadelphia, PA, in August 2016. Author S.K. was funded by Academy
   of Finland projects 312490 and 269279, O.R. by Academy of Finland
   projects 274479 and 312105, and N.S. was funded by Academy of Finland
   project 296751. The authors would like to thank Veli-Matti Saarinen for
   his assistance in conducting the EEG measurements.
CR Altosaar T., 2010, P INT C LANG RES EV, P1062
   Aslin RN, 2012, CURR DIR PSYCHOL SCI, V21, P170, DOI 10.1177/0963721412436806
   Aylett M, 2004, LANG SPEECH, V47, P31, DOI 10.1177/00238309040470010201
   Aylett M, 2006, J ACOUST SOC AM, V119, P3048, DOI 10.1121/1.2188331
   BARRETT SE, 1990, BRAIN COGNITION, V14, P201, DOI 10.1016/0278-2626(90)90029-N
   Bendixen A, 2012, INT J PSYCHOPHYSIOL, V83, P120, DOI 10.1016/j.ijpsycho.2011.08.003
   Bishop J., 2012, PROSODY AND MEANING, V25, P239, DOI [DOI 10.1515/9783110261790.239, 10.1515/9783110261790.239]
   BOCK JK, 1983, MEM COGNITION, V11, P64, DOI 10.3758/BF03197663
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bogels S, 2011, NEUROPSYCHOLOGIA, V49, P2022, DOI 10.1016/j.neuropsychologia.2011.03.032
   BOLINGER D, 1972, LANGUAGE, V48, P633, DOI 10.2307/412039
   BOLINGER D, 1983, AM SPEECH, V58, P156, DOI 10.2307/455326
   Bosseler AN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162177
   Broadbent D., 1958, LANGUAGE, V86, P1
   Buxo-Lugo A, 2016, J MEM LANG, V90, P1, DOI 10.1016/j.jml.2016.03.001
   Campbell N., 1995, P 13 INT C PHON SCI, P676
   Campbell N., 1997, INTONATION THEORY MO, P67
   Cohen J, 1997, INT J PSYCHOPHYSIOL, V25, P249, DOI 10.1016/S0167-8760(96)00743-X
   Cole J., 2010, LAB PHONOL, V1, DOI [https://doi.org/10.1515/labphon.2010.022, DOI 10.1515/LABPHON.2010.022, DOI 10.1515/LABPH0N.2010.022]
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   COOPER RP, 1994, CHILD DEV, V65, P1663, DOI 10.1111/j.1467-8624.1994.tb00841.x
   CUTLER A, 1977, LANG SPEECH, V20, P1
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   CUTLER A, 1987, J CHILD LANG, V14, P145, DOI 10.1017/S0305000900012782
   Dien J, 2017, INT J PSYCHOPHYSIOL, V111, P42, DOI 10.1016/j.ijpsycho.2016.09.006
   Dimitrova DV, 2012, J COGNITIVE NEUROSCI, V24, P2400, DOI 10.1162/jocn_a_00302
   Eckstein K, 2005, COGNITIVE BRAIN RES, V25, P130, DOI 10.1016/j.cogbrainres.2005.05.003
   Erickson LC, 2015, DEV REV, V37, P66, DOI 10.1016/j.dr.2015.05.002
   Escera C, 1998, J COGNITIVE NEUROSCI, V10, P590, DOI 10.1162/089892998562997
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Francois C, 2017, NEUROPSYCHOLOGIA, V98, P56, DOI 10.1016/j.neuropsychologia.2016.10.006
   Friston KJ, 2009, NEURAL NETWORKS, V22, P1093, DOI 10.1016/j.neunet.2009.07.023
   FRY DB, 1955, J ACOUST SOC AM, V27, P765, DOI 10.1121/1.1908022
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029
   Gonsalvez CJ, 2002, PSYCHOPHYSIOLOGY, V39, P388, DOI 10.1017/S0048577201393137
   Gouvea AC, 2010, LANG COGNITIVE PROC, V25, P149, DOI 10.1080/01690960902965951
   GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1016/S0364-0213(87)80025-3
   Hagoort P, 2003, NEUROIMAGE, V20, pS18, DOI 10.1016/j.neuroimage.2003.09.013
   HERMES DJ, 1994, J ACOUST SOC AM, V96, P83, DOI 10.1121/1.410377
   HOLCOMB PJ, 1990, LANG COGNITIVE PROC, V5, P281, DOI 10.1080/01690969008407065
   Honbolygo F, 2016, J NEUROLINGUIST, V37, P22, DOI 10.1016/j.jneuroling.2015.08.001
   Hruska C., 2001, ORALITY GESTURES INT
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kaan E, 2003, J COGNITIVE NEUROSCI, V15, P98, DOI 10.1162/089892903321107855
   Kakouros S., 2014, P 36 ANN C COGN SCI, P1246
   Kakouros S, 2016, INTERSPEECH, P1074, DOI 10.21437/Interspeech.2016-926
   Kakouros S, 2016, COGNITIVE SCI, V40, P1739, DOI 10.1111/cogs.12306
   Kakouros S, 2016, SPEECH COMMUN, V82, P67, DOI 10.1016/j.specom.2016.06.004
   Kidd C, 2014, CHILD DEV, V85, P1795, DOI 10.1111/cdev.12263
   Kidd C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036399
   Kiefer M, 2002, COGNITIVE BRAIN RES, V13, P27, DOI 10.1016/S0926-6410(01)00085-4
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   Koelsch S, 2016, SCI REP-UK, V6, DOI 10.1038/srep19741
   Krishnan A, 2015, J NEUROLINGUIST, V33, P128, DOI 10.1016/j.jneuroling.2014.08.002
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Kutas M., 1994, HDB PSYCHOLINGUISTIC, P83, DOI DOI 10.1016/8978-012369374-7/50018-3
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Laszlo S, 2011, PSYCHOPHYSIOLOGY, V48, P176, DOI 10.1111/j.1469-8986.2010.01058.x
   Li XQ, 2012, NEUROPSYCHOLOGIA, V50, P1882, DOI 10.1016/j.neuropsychologia.2012.04.013
   LIEBERMAN P, 1960, J ACOUST SOC AM, V32, P451, DOI 10.1121/1.1908095
   Magne C, 2005, J COGNITIVE NEUROSCI, V17, P740, DOI 10.1162/0898929053747667
   Maier A, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P616
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Mietz A, 2008, BRAIN LANG, V104, P159, DOI 10.1016/j.bandl.2007.03.005
   Moore C.B., 1993, WORK PAP CORNELL PHO, V8, P89
   Murray MM, 2008, BRAIN TOPOGR, V20, P249, DOI 10.1007/s10548-008-0054-5
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Ortega-Llebaria M., 2010, LANG SPEECH, V54, P1
   OSTERHOUT L, 1992, J MEM LANG, V31, P785, DOI 10.1016/0749-596X(92)90039-Z
   Pan S., 1999, P EMNLP VLC 99, P148
   Pan SM, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P233
   Pannekamp A, 2011, BRAIN TOPOGR, V24, P229, DOI 10.1007/s10548-011-0194-x
   PICTON TW, 1992, J CLIN NEUROPHYSIOL, V9, P456, DOI 10.1097/00004691-199210000-00002
   Polich J., 2007, UPDATING P300 INTEGR
   Ranganath C, 2003, NAT REV NEUROSCI, V4, P193, DOI 10.1038/nrn1052
   Rasanen O., 2017, P 39 ANN C COGN SCI, P998
   Rasanen O., IS INFANT DIRE UNPUB
   RIETVELD ACM, 1985, J PHONETICS, V13, P299, DOI 10.1016/S0095-4470(19)30761-2
   Rosenberg A, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SPEECH PROSODY, VOLS I AND II, P278
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   SAMUEL AG, 1987, J MEM LANG, V26, P36, DOI 10.1016/0749-596X(87)90061-1
   Sanford AJ, 2006, DISCOURSE PROCESS, V42, P99, DOI 10.1207/s15326950dp4202_1
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572
   Sluijter AMC, 1996, J ACOUST SOC AM, V100, P2471, DOI 10.1121/1.417955
   Soderstrom M, 2007, DEV REV, V27, P501, DOI 10.1016/j.dr.2007.06.002
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   Suomi K., 2008, FINNISH SOUND STRUCT
   Suomi K., 2002, P SWED PHON C FON 20, P73
   TERKEN J, 1991, J ACOUST SOC AM, V89, P1768, DOI 10.1121/1.401019
   Terken J, 1987, LANG COGNITIVE PROC, V2, P145, DOI DOI 10.1080/01690968708406928
   TERVANIEMI M, 1994, NEUROREPORT, V5, P844, DOI 10.1097/00001756-199403000-00027
   THART J, 1981, J ACOUST SOC AM, V69, P811, DOI 10.1121/1.385592
   Toepel U., 2004, INFORM STRUCTURE THE, P227
   Toepel U, 2007, BEHAV BRAIN FUNCT, V3, DOI 10.1186/1744-9081-3-53
   Tong XH, 2014, BRAIN LANG, V138, P61, DOI 10.1016/j.bandl.2014.09.004
   TREISMAN A, 1964, J VERB LEARN VERB BE, V3, P449, DOI 10.1016/S0022-5371(64)80015-3
   Tsuchida T., 2012, P 34 ANN C COGN SCI, P1048
   Vaissiere J., 1983, PROSODY MODELS MEASU, P53, DOI [10.1007/978-3-642-69103-45, DOI 10.1007/978-3-642-69103-4_5]
   Van Berkum J. J. A., 2009, SEMANTICS PRAGMATICS, P276
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394
   Wagner P., 2015, P 18 INT C PHON SCI
   Wang L, 2011, NEUROPSYCHOLOGIA, V49, P813, DOI 10.1016/j.neuropsychologia.2010.12.035
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Watson DG, 2008, COGNITION, V106, P1548, DOI 10.1016/j.cognition.2007.06.009
   Winkler I, 1996, J COGNITIVE NEUROSCI, V8, P403, DOI 10.1162/jocn.1996.8.5.403
   Ylitalo R., 2009, THESIS
   Zarcone A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 117
TC 5
Z9 5
U1 6
U2 16
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD JAN 31
PY 2018
VL 109
BP 181
EP 199
DI 10.1016/j.neuropsychologia.2017.12.011
PG 19
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FW3JJ
UT WOS:000425202400020
PM 29247667
DA 2021-02-24
ER

PT J
AU Feng, GY
   Ingvalson, EM
   Grieco-Calub, TM
   Roberts, MY
   Ryan, ME
   Birmingham, P
   Burrowes, D
   Young, NM
   Wong, PCM
AF Feng, Gangyi
   Ingvalson, Erin M.
   Grieco-Calub, Tina M.
   Roberts, Megan Y.
   Ryan, Maura E.
   Birmingham, Patrick
   Burrowes, Delilah
   Young, Nancy M.
   Wong, Patrick C. M.
TI Neural preservation underlies speech improvement from auditory
   deprivation in young cochlear implant recipients
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE neural preservation; cochlear implant; prediction; auditory deprivation;
   machine learning
ID SPOKEN LANGUAGE-DEVELOPMENT; CROSS-MODAL PLASTICITY; FUNCTIONAL
   CONNECTIVITY; HESCHLS GYRUS; BRAIN; CHILDREN; DEAF; HEARING; CORTEX; MRI
AB Although cochlear implantation enables some children to attain age-appropriate speech and language development, communicative delays persist in others, and outcomes are quite variable and difficult to predict, even for children implanted early in life. To understand the neurobiological basis of this variability, we used presurgical neural morphological data obtained from MRI of individual pediatric cochlear implant (CI) candidates implanted younger than 3.5 years to predict variability of their speech-perception improvement after surgery. We first compared neuroanatomical density and spatial pattern similarity of CI candidates to that of age-matched children with normal hearing, which allowed us to detail neuroanatomical networks that were either affected or unaffected by auditory deprivation. This information enables us to build machine-learning models to predict the individual children's speech development following CI. We found that regions of the brain that were unaffected by auditory deprivation, in particular the auditory association and cognitive brain regions, produced the highest accuracy, specificity, and sensitivity in patient classification and the most precise prediction results. These findings suggest that brain areas unaffected by auditory deprivation are critical to developing closer to typical speech outcomes. Moreover, the findings suggest that determination of the type of neural reorganization caused by auditory deprivation before implantation is valuable for predicting post-CI language outcomes for young children.
C1 [Feng, Gangyi; Wong, Patrick C. M.] Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Hong Kong, Hong Kong, Peoples R China.
   [Feng, Gangyi; Wong, Patrick C. M.] Chinese Univ Hong Kong, Brain & Mind Inst, Hong Kong, Hong Kong, Peoples R China.
   [Ingvalson, Erin M.] Florida State Univ, Sch Commun Sci & Disorders, Tallahassee, FL 32301 USA.
   [Ingvalson, Erin M.; Young, Nancy M.] Northwestern Univ, Feinberg Sch Med, Dept Otolaryngol Head & Neck Surg, Chicago, IL 60611 USA.
   [Grieco-Calub, Tina M.; Roberts, Megan Y.] Northwestern Univ, Roxelyn & Richard Pepper Dept Commun Sci & Disord, Evanston, IL 60208 USA.
   [Grieco-Calub, Tina M.; Young, Nancy M.] Northwestern Univ, Sch Commun, Knowles Hearing Ctr, Evanston, IL 60208 USA.
   [Ryan, Maura E.; Burrowes, Delilah] Northwestern Univ, Feinberg Sch Med, Dept Radiol, Chicago, IL 60611 USA.
   [Ryan, Maura E.; Burrowes, Delilah] Ann & Robert H Lurie Childrens Hosp Chicago, Dept Med Imaging, Chicago, IL 60611 USA.
   [Birmingham, Patrick] Ann & Robert H Lurie Childrens Hosp Chicago, Dept Anesthesiol, Chicago, IL 60611 USA.
   [Birmingham, Patrick] Northwestern Univ, Feinberg Sch Med, Dept Anesthesiol, Chicago, IL 60611 USA.
   [Young, Nancy M.] Ann & Robert H Lurie Childrens Hosp Chicago, Div Otolaryngol Head & Neck Surg, Chicago, IL 60611 USA.
   [Wong, Patrick C. M.] Chinese Univ Hong Kong, Dept Otorhinolaryngol Head & Neck Surg, Hong Kong, Hong Kong, Peoples R China.
RP Wong, PCM (corresponding author), Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Hong Kong, Hong Kong, Peoples R China.; Wong, PCM (corresponding author), Chinese Univ Hong Kong, Brain & Mind Inst, Hong Kong, Hong Kong, Peoples R China.; Wong, PCM (corresponding author), Chinese Univ Hong Kong, Dept Otorhinolaryngol Head & Neck Surg, Hong Kong, Hong Kong, Peoples R China.
EM p.wong@cuhk.edu.hk
OI Feng, Gangyi/0000-0003-2239-5296; Ingvalson, Erin/0000-0002-5498-2543;
   Young, Nancy/0000-0003-1498-2984; Wong, Patrick/0000-0002-6105-5027;
   Roberts, Megan/0000-0002-4699-0236
FU Knowles Hearing Center at Northwestern University; Ann & Robert H. Lurie
   Children's Hospital of Chicago
FX We thank Haejung Shin, Beth Tournis, and members of the cochlear implant
   team at the Ann & Robert H. Lurie Children's Hospital of Chicago for
   their support of this research. This research is supported by grants
   from Knowles Hearing Center at Northwestern University and Ann & Robert
   H. Lurie Children's Hospital of Chicago, and donations from the Global
   Parent Child Resource Centre Limited and the Dr. Stanley Ho Medical
   Development Foundation awarded to The Chinese University of Hong Kong.
CR Almli CR, 2007, NEUROIMAGE, V35, P308, DOI 10.1016/j.neuroimage.2006.08.058
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Barnard JM, 2015, OTOL NEUROTOL, V36, P985, DOI 10.1097/MAO.0000000000000723
   Burges C. J., 2010, MSRTR201082
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chapelle O, 2010, INFORM RETRIEVAL, V13, P201, DOI 10.1007/s10791-009-9109-9
   Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155
   De Martino F, 2008, NEUROIMAGE, V43, P44, DOI 10.1016/j.neuroimage.2008.06.037
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Emmorey K, 2003, P NATL ACAD SCI USA, V100, P10049, DOI 10.1073/pnas.1730169100
   Fink Nancy E, 2007, Cochlear Implants Int, V8, P92, DOI 10.1002/cii.333
   Gabrieli JDE, 2015, NEURON, V85, P11, DOI 10.1016/j.neuron.2014.10.047
   Gilmore JH, 2012, CEREB CORTEX, V22, P2478, DOI 10.1093/cercor/bhr327
   Giraud AL, 2007, RESTOR NEUROL NEUROS, V25, P381
   Hackett TA, 2011, HEARING RES, V271, P133, DOI 10.1016/j.heares.2010.01.011
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hill J, 2010, P NATL ACAD SCI USA, V107, P13135, DOI 10.1073/pnas.1001229107
   Joachims T., 2002, P133, DOI DOI 10.1145/775047.775067
   Kiviniemi VJ, 2005, MAGN RESON IMAGING, V23, P531, DOI 10.1016/j.mri.2005.02.009
   Klinke R, 1999, SCIENCE, V285, P1729, DOI 10.1126/science.285.5434.1729
   Kral A, 2013, NEUROSCIENCE, V247, P117, DOI 10.1016/j.neuroscience.2013.05.021
   Kral A, 2002, CEREB CORTEX, V12, P797, DOI 10.1093/cercor/12.8.797
   Kral A, 2006, PROG BRAIN RES, V157, P283, DOI 10.1016/S0079-6123(06)57018-9
   Kral A, 2007, INT J AUDIOL, V46, P479, DOI 10.1080/14992020701383027
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lopez-Barroso D, 2013, P NATL ACAD SCI USA, V110, P13168, DOI 10.1073/pnas.1301696110
   Manjon JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Marschark M, 2007, J DEAF STUD DEAF EDU, V12, P269, DOI 10.1093/deafed/enm013
   Mhuircheartaigh RN, 2010, J NEUROSCI, V30, P9095, DOI 10.1523/JNEUROSCI.5516-09.2010
   Mueller S, 2013, NEURON, V77, P586, DOI 10.1016/j.neuron.2012.12.028
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Oosterhof NN, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00027
   Peltier SJ, 2005, NEUROREPORT, V16, P285, DOI 10.1097/00001756-200502280-00017
   Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007
   Richards JE, 2016, NEUROIMAGE, V124, P1254, DOI 10.1016/j.neuroimage.2015.04.055
   Richardson M., 2006, P 15 INT C WORLD WID, P707, DOI DOI 10.1145/1135777.1135881
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Sharma A, 2009, J COMMUN DISORD, V42, P272, DOI 10.1016/j.jcomdis.2009.03.003
   Shi F, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018746
   Shibata DK, 2007, AM J NEURORADIOL, V28, P243
   Shiell MM, 2015, J COGNITIVE NEUROSCI, V27, P150, DOI 10.1162/jocn_a_00683
   Smith KM, 2011, CEREB CORTEX, V21, P991, DOI 10.1093/cercor/bhq164
   Sowell ER, 2004, J NEUROSCI, V24, P8223, DOI 10.1523/JNEUROSCI.1798-04.2004
   Supekar K, 2013, P NATL ACAD SCI USA, V110, P8230, DOI 10.1073/pnas.1222154110
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Tan LR, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.391
   Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016
   Wang NY, 2008, OTOL NEUROTOL, V29, P240, DOI 10.1097/MAO.0b013e3181627a37
   Whelan R, 2014, BIOL PSYCHIAT, V75, P746, DOI 10.1016/j.biopsych.2013.05.014
   Wong PCM, 2008, CEREB CORTEX, V18, P828, DOI 10.1093/cercor/bhm115
   Wong PCM, 2007, HUM BRAIN MAPP, V28, P995, DOI 10.1002/hbm.20330
   Wong PCM, 2017, NEUROPSYCHOLOGIA, V98, P192, DOI 10.1016/j.neuropsychologia.2016.10.002
NR 57
TC 15
Z9 17
U1 1
U2 14
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD JAN 30
PY 2018
VL 115
IS 5
BP E1022
EP E1031
DI 10.1073/pnas.1717603115
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FU3CZ
UT WOS:000423728800019
PM 29339512
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Stavrinos, G
   Iliadou, VM
   Edwards, L
   Sirimanna, T
   Bamiou, DE
AF Stavrinos, Georgios
   Iliadou, Vassiliki-Maria
   Edwards, Lindsey
   Sirimanna, Tony
   Bamiou, Doris-Eva
TI The Relationship between Types of Attention and Auditory Processing
   Skills: Reconsidering Auditory Processing Disorder Diagnosis
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE auditory processing disorder; attention deficits; diagnostic criteria;
   attention; audiology; paediatrics
ID TEST LISN-S; CORPUS-CALLOSUM; LANGUAGE IMPAIRMENT; SPEECH-PERCEPTION;
   COGNITIVE-ABILITIES; SELECTIVE ATTENTION; DIVIDED-ATTENTION; DICHOTIC
   DEFICITS; COCKTAIL PARTY; BRAIN-STEM
AB Measures of attention have been found to correlate with specific auditory processing tests in samples of children suspected of Auditory Processing Disorder (APD), but these relationships have not been adequately investigated. Despite evidence linking auditory attention and deficits/symptoms of APD, measures of attention are not routinely used in APD diagnostic protocols. The aim of the study was to examine the relationship between auditory and visual attention tests and auditory processing tests in children with APD and to assess whether a proposed diagnostic protocol for APD, including measures of attention, could provide useful information for APD management. A pilot study including 27 children, aged 7-11 years, referred for APD assessment was conducted. The validated test of everyday attention for children, with visual and auditory attention tasks, the listening in spatialized noise sentences test, the children's communication checklist questionnaire and tests from a standard APD diagnostic test battery were administered. Pearson's partial correlation analysis examining the relationship between these tests and Cochrane's Q test analysis comparing proportions of diagnosis under each proposed battery were conducted. Divided auditory and divided auditory-visual attention strongly correlated with the dichotic digits test, r = 0.68, p < 0.05, and r = 0.76, p = 0.01, respectively, in a sample of 20 children with APD diagnosis. The standard APD battery identified a larger proportion of participants as having APD, than an attention battery identified as having Attention Deficits (ADs). The proposed APD battery excluding AD cases did not have a significantly different diagnosis proportion than the standard APD battery. Finally, the newly proposed diagnostic battery, identifying an inattentive subtype of APD, identified five children who would have otherwise been considered not having ADs. The findings show that a subgroup of children with APD demonstrates underlying sustained and divided attention deficits. Attention deficits in children with APD appear to be centred around the auditory modality but further examination of types of attention in both modalities is required. Revising diagnostic criteria to incorporate attention tests and the inattentive type of APD in the test battery, provides additional useful data to clinicians to ensure careful interpretation of APD assessments.
C1 [Stavrinos, Georgios; Bamiou, Doris-Eva] UCL, Fac Brain Sci, Ear Inst, London, England.
   [Iliadou, Vassiliki-Maria] Aristotle Univ Thessaloniki, Neurosci Div, Thessaloniki, Greece.
   [Edwards, Lindsey] Great Ormond St Hosp Sick Children, Psychol Serv, London, England.
   [Sirimanna, Tony] Great Ormond St Hosp Sick Children, Dept Paediat Audiol, London, England.
   [Bamiou, Doris-Eva] Natl Hosp Neurol & Neurosurg, Dept Neurootol, London, England.
   [Bamiou, Doris-Eva] Natl Inst Hlth Res, Biomed Res Ctr, London, England.
RP Stavrinos, G (corresponding author), UCL, Fac Brain Sci, Ear Inst, London, England.
EM georgios.stavrinos.13@ucl.ac.uk
RI Bamiou, Doris-Eva/M-4082-2017; Iliadou, Vasiliki/AAG-3750-2021
OI Bamiou, Doris-Eva/0000-0001-7486-4264; Iliadou,
   Vasiliki/0000-0002-1122-5104
FU GN ReSound; Action Medical Research; National Institute of Health
   Research, Biomedical Research CentreNational Institute for Health
   Research (NIHR)
FX This study was funded by GN ReSound and Action Medical Research and for
   D-EB the study was supported by the National Institute of Health
   Research, Biomedical Research Centre.
CR American Academy of Audiology, 2010, AM AC AUD CLIN PRACT
   American Speech-Language-Hearing Association, 2005, TECHNICAL REPORT
   BAMIOU DE, 2006, AUDIOLOGICAL MED, V4, P46, DOI DOI 10.1080/16513860600630498
   Bishop D., 2003, CHILDRENS COMMUNICAT
   British Society of Audiology, 2013, REC PROC TYMP, P1
   British Society of Audiology, 2012, REC PROC PUR TON AIR, P1
   Broadbent D. E., 1958, PERECEPTION COMMUNIC
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   Cameron S, 2016, J AM ACAD AUDIOL, V27, P470, DOI 10.3766/jaaa.15085
   Cameron S, 2011, J AM ACAD AUDIOL, V22, P678, DOI 10.3766/jaaa.22.10.6
   Cameron S, 2008, J AM ACAD AUDIOL, V19, P377, DOI 10.3766/jaaa.19.5.2
   Chermak Gail D, 2002, J Am Acad Audiol, V13, P332
   Cowan J., 2009, CONTROVERSIES CENTRA, P187
   Dawes P, 2009, INT J LANG COMM DIS, V44, P440, DOI 10.1080/13682820902929073
   Dillon H, 2012, J AM ACAD AUDIOL, V23, P97, DOI 10.3766/jaaa.23.2.4
   Ferguson MA, 2011, J SPEECH LANG HEAR R, V54, P211, DOI 10.1044/1092-4388(2010/09-0167)
   Filippini R, 2012, FOLIA PHONIATR LOGO, V64, P217, DOI 10.1159/000342139
   Forster S, 2014, NEUROPSYCHOLOGY, V28, P91, DOI 10.1037/neu0000020
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grube M, 2014, HEARING RES, V308, P129, DOI 10.1016/j.heares.2013.09.015
   Guenette L. A., 2006, HEARING J, V59, P50, DOI DOI 10.1097/01.HJ.0000286532.22073.ED
   Gyldenkaerne P, 2014, J AM ACAD AUDIOL, V25, P676, DOI 10.3766/jaaa.25.7.6
   Hahn B, 2008, BRAIN RES, V1215, P137, DOI 10.1016/j.brainres.2008.03.058
   Hutchinson AD, 2008, NEUROPSYCHOLOGY, V22, P341, DOI 10.1037/0894-4105.22.3.341
   Iliadou V, 2016, AM J AUDIOL, V25, P368, DOI 10.1044/2016_AJA-16-0055
   Johnston KN, 2009, INT J AUDIOL, V48, P371, DOI 10.1080/14992020802687516
   Keith R. W., 2009, SCAN 3 CHILDREN TEST
   Keith William J., 2014, Seminars in Hearing, V35, P27, DOI 10.1055/s-0033-1363522
   Kerns KA, 1999, DEV NEUROPSYCHOL, V16, P273, DOI 10.1207/S15326942DN1602_9
   Kuppen SEA, 2016, DEV PSYCHOL, V52, P717, DOI 10.1037/a0040207
   Lagace J, 2011, INT J AUDIOL, V50, P385, DOI 10.3109/14992027.2011.553204
   Lam Emilie, 2007, Australian and New Zealand Journal of Audiology, V29, P26, DOI 10.1375/audi.29.1.26
   Lavie N, 2005, TRENDS COGN SCI, V9, P75, DOI 10.1016/j.tics.2004.12.004
   Loo JHY, 2016, EAR HEARING, V37, P38, DOI 10.1097/AUD.0000000000000225
   Manly T., 1999, TEA CH TEST EVERYDAY
   Martin J. S., 2009, PAEDIAT AUDIOLOGICAL, P227
   Martin J, 2007, J AM ACAD AUDIOL, V18, P34, DOI 10.3766/jaaa.18.1.4
   Mattys SL, 2015, J ACOUST SOC AM, V137, P1464, DOI 10.1121/1.4913507
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Miller CA, 2011, J COMMUN DISORD, V44, P745, DOI 10.1016/j.jcomdis.2011.04.001
   Musiek F. E., 2002, HEARING J, V55, P58, DOI DOI 10.1097/01.HJ.0000293280.99394.DD
   MUSIEK FE, 1987, AUDIOLOGY, V26, P79
   Musiek FE, 2011, BRAIN COGNITION, V76, P225, DOI 10.1016/j.bandc.2011.03.011
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Parasuraman R, 1998, ATTENTIVE BRAIN, P3
   Paulovicks J., 2008, HEAR J, V61, P67, DOI DOI 10.1097/01.HJ.0000314723.80439.72
   Rosen S, 2010, INT J PEDIATR OTORHI, V74, P594, DOI 10.1016/j.ijporl.2010.02.021
   Sarter M, 2001, BRAIN RES REV, V35, P146, DOI 10.1016/S0165-0173(01)00044-3
   Sharma M, 2012, INT J AUDIOL, V51, P506, DOI 10.3109/14992027.2012.670272
   Sharma M, 2009, J SPEECH LANG HEAR R, V52, P706, DOI 10.1044/1092-4388(2008/07-0226)
   Tawfik S, 2015, INT J PEDIATR OTORHI, V79, P2404, DOI 10.1016/j.ijporl.2015.11.001
   the American Society for Testing and Materials, 2005, AUD PROC DIS ROL AUD, p1e23, DOI 10.1520/D6648-08R16.2.
   The British Standards Institution, 2011, PRACT GUID OV CURR M, P1
   Tomlin D, 2015, EAR HEARING, V36, P527, DOI 10.1097/AUD.0000000000000172
   van der Knaap LJ, 2011, BEHAV BRAIN RES, V223, P211, DOI 10.1016/j.bbr.2011.04.018
   Wahn B, 2017, ADV COGN PSYCHOL, V13, P83, DOI 10.5709/acp-0209-2
   Wechsler D., 2006, WECHLER NONVERBAL SC
   Westerhausen R, 2008, NEUROSCI BIOBEHAV R, V32, P1044, DOI 10.1016/j.neubiorev.2008.04.005
   Wilson WJ, 2013, J SPEECH LANG HEAR R, V56, P63, DOI 10.1044/1092-4388(2012/11-0352)
   Wolraich M, 2011, PEDIATRICS, V128, P1007, DOI 10.1542/peds.2011-2654
NR 60
TC 11
Z9 11
U1 0
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JAN 30
PY 2018
VL 9
AR 34
DI 10.3389/fpsyg.2018.00034
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA FU0YP
UT WOS:000423576600001
PM 29441033
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Guiraud, H
   Bedoin, N
   Krifi-Papoz, S
   Herbillon, V
   Caillot-Bascoul, A
   Gonzalez-Monge, S
   Boulenger, V
AF Guiraud, Helene
   Bedoin, Nathalie
   Krifi-Papoz, Sonia
   Herbillon, Vania
   Caillot-Bascoul, Aurelia
   Gonzalez-Monge, Sibylle
   Boulenger, Veronique
TI Don't speak too fast! Processing of fast rate speech in children with
   specific language impairment
SO PLOS ONE
LA English
DT Article
ID AUDITORY-CORTEX; INHERITED SPEECH; DEVELOPMENTAL APHASIA; PERCEPTION
   DEFICITS; COMPRESSED SPEECH; BEAT PERCEPTION; TIME; DYSLEXIA; RHYTHM;
   PATTERNS
AB Background
   Perception of speech rhythm requires the auditory system to track temporal envelope fluctuations, which carry syllabic and stress information. Reduced sensitivity to rhythmic acoustic cues has been evidenced in children with Specific Language Impairment (SLI), impeding syllabic parsing and speech decoding. Our study investigated whether these children experience specific difficulties processing fast rate speech as compared with typically developing (TD) children.
   Method
   Sixteen French children with SLI (8-13 years old) with mainly expressive phonological disorders and with preserved comprehension and 16 age-matched TD children performed a judgment task on sentences produced 1) at normal rate, 2) at fast rate or 3) time-compressed. Sensitivity index (d) to semantically incongruent sentence-final words was measured.
   Results
   Overall children with SLI perform significantly worse than TD children. Importantly, as revealed by the significant Group x Speech Rate interaction, children with SLI find it more challenging than TD children to process both naturally or artificially accelerated speech. The two groups do not significantly differ in normal rate speech processing.
   Conclusion
   In agreement with rhythm-processing deficits in atypical language development, our results suggest that children with SLI face difficulties adjusting to rapid speech rate. These findings are interpreted in light of temporal sampling and prosodic phrasing frameworks and of oscillatory mechanisms underlying speech perception.
C1 [Guiraud, Helene; Bedoin, Nathalie; Boulenger, Veronique] Univ Lyon, CNRS, UMR5596, Lab Dynam Langage, Lyon, France.
   [Krifi-Papoz, Sonia] Hop Femme Mere Enfant, Serv Neurol Pediat, Bron, France.
   [Herbillon, Vania] Hop Femme Mere Enfant, Serv Epilepsie Sommeil & Explorat Fonct Neuropedi, Bron, France.
   [Herbillon, Vania] CNRS, INSERM, Ctr Rech Neurosci Lyon, DYCOG,U1028,UMR5292, Bron, France.
   [Caillot-Bascoul, Aurelia] CHU Gabriel Montpied, Serv ORL Chirurg Cerv Faciale, Clermont Ferrand, France.
   [Gonzalez-Monge, Sibylle] Hop Femme Mere Enfant, Serv Reeduc Pediat, Ctr Reference Troubles Apprentissages, Bron, France.
RP Guiraud, H; Boulenger, V (corresponding author), Univ Lyon, CNRS, UMR5596, Lab Dynam Langage, Lyon, France.
EM helene.guiraud@univ-lyon2.fr; veronique.boulenger@cnrs.fr
RI Boulenger, Veronique/P-6339-2015; Boulenger, Veronique/AAQ-2881-2020
OI Boulenger, Veronique/0000-0001-8701-8278; Guiraud,
   Helene/0000-0003-0937-5872
FU ODYSSEE project [11 JSH2 005 1]; French National Research Agency
   (ANR)French National Research Agency (ANR) [11 JSH2 0051]; LabExASLAN of
   Universite de Lyon within the program "Investissements d'Avenir" of the
   French governmentFrench National Research Agency (ANR)
   [ANR-10-LABX-0081, ANR-11-IDEX-0007]
FX This study was conducted as part of the ODYSSEE project (PI: V.B; no 11
   JSH2 005 1) funded by the French National Research Agency (ANR; grant
   number 11 JSH2 0051, http://www.agence-nationale-recherche.fr/). HG is
   funded by a doctoral fellowship from the LabExASLAN (ANR-10-LABX-0081)
   of Universite de Lyon within the program "Investissements d'Avenir"
   (ANR-11-IDEX-0007) of the French government operated by the ANR
   (http://aslan.universite-lyon.fr/). The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.; We would like to thank parents and their
   children for participating in this study. We also thank Lydie Merle for
   helping to recruit children with SLI, Emmanuel Ferragne for his help in
   the construction of the stimuli and Damien Gouy for recording the
   sentences. This study was conducted as part of the ODYSSEE project (PI:
   V.B; no 11 JSH2 005 1) funded by the French National Research Agency
   (ANR). H.G is funded by a doctoral fellowship from the LabEx ASLAN
   (ANR-10-LABX-0081) of Universite de Lyon within the program
   "Investissements d'Avenir" (ANR-11-IDEX-0007) of the French government
   operated by the ANR.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Abrams DA, 2009, J NEUROSCI, V29, P7686, DOI 10.1523/JNEUROSCI.5242-08.2009
   Adank P, 2010, NEUROIMAGE, V49, P1124, DOI 10.1016/j.neuroimage.2009.07.032
   Adank P, 2009, J ACOUST SOC AM, V126, P2649, DOI 10.1121/1.3216914
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Ahissar M, 2004, TRENDS COGN SCI, V8, P457, DOI 10.1016/j.tics.2004.08.011
   Alcock KJ, 2000, BRAIN LANG, V75, P34, DOI 10.1006/brln.2000.2323
   Alho J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00394
   American Psychiatric Association, 2013, DIAGNOSTIC AND STATI
   Beattie RL, 2013, J LEARN DISABIL-US, V46, P200, DOI 10.1177/0022219412449421
   Bedoin N, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00245
   Belton E, 2003, HUM BRAIN MAPP, V18, P194, DOI 10.1002/hbm.10093
   Bishop DVM, 2014, INT J LANG COMM DIS, V49, P381, DOI 10.1111/1460-6984.12101
   Bishop DVM, 2002, AM J MED GENET, V114, P56, DOI 10.1002/ajmg.1630
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Botting N, 2005, J CHILD PSYCHOL PSYC, V46, P317, DOI 10.1111/j.1469-7610.2004.00355.x
   Bowyer-Crane C, 2011, LEARN DISAB, V9, P107
   Carr KW, 2014, P NATL ACAD SCI USA, V111, P14559, DOI 10.1073/pnas.1406219111
   Chen JL, 2008, J COGNITIVE NEUROSCI, V20, P226, DOI 10.1162/jocn.2008.20018
   Chevrie-Muller C., 2001, NOUVELLES EPREUVES E
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Corriveau KH, 2009, CORTEX, V45, P119, DOI 10.1016/j.cortex.2007.09.008
   Cumming R, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3339/fnhum.2015.00672, 10.3389/fnhum.2015.00672]
   Cumming R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00972
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   de Weck G, 2003, TROUBLES DYSPHASIQUE
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Duez D., 1998, P ESCA SOUND PATT SP, P63
   Duez D, 1987, TRAVAUX I PHONETIQUE, V11, P157
   Dupoux E, 1997, J EXP PSYCHOL HUMAN, V23, P914, DOI 10.1037/0096-1523.23.3.914
   Ferragne E, 2012, ROCME RECORDING ORAL
   Fey M. E., 1994, SPECIFIC LANGUAGE IM, P161
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   Fraser J, 2010, SCI STUD READ, V14, P8, DOI 10.1080/10888430903242068
   Geiser E, 2008, J COGNITIVE NEUROSCI, V20, P541, DOI 10.1162/jocn.2008.20029
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gordon-Salant S, 2014, J ACOUST SOC AM, V136, pEL268, DOI 10.1121/1.4895014
   Goswami U, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00791
   Goswami U, 2012, EMPIR MUSICOL REV, V7, P57, DOI 10.18061/1811/52980
   Goswami U, 2013, LAB PHONOL, V4, P67, DOI 10.1515/lp-2013-0004
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893
   Greenberg S, 2003, DYNAMICS SPEECH PROD
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Guiraud H, 2013, P INT, P2
   Hamalainen JA, 2012, NEUROIMAGE, V59, P2952, DOI 10.1016/j.neuroimage.2011.09.075
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hill EL, 2001, INT J LANG COMM DIS, V36, P149, DOI 10.1080/13682820010019874
   Iversen JR, 2009, ANN NY ACAD SCI, V1169, P58, DOI 10.1111/j.1749-6632.2009.04579.x
   Jacquier-Roux M., 2010, BALE BATTERIE ANAL L
   Janse E, 2004, SPEECH COMMUN, V42, P155, DOI 10.1016/j.specom.2003.07.001
   Khomsi A., 2007, BILAN INFORM LANGAGE
   Khomsi A., 2001, ELO EVALUATION LANGA
   Koreman J, 2006, J ACOUST SOC AM, V119, P582, DOI 10.1121/1.2133436
   Korkman M, 1998, NEPSY BILAN NEUROPSY
   Kotz SA, 2015, CORTEX, V68, P48, DOI 10.1016/j.cortex.2015.02.021
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   Law J, 1998, Int J Lang Commun Disord, V33 Suppl, P21
   Lefavrais P., 1967, TEST DE LALOUETTE
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Leonard L.B., 2014, INT J LANG COMM DIS, V49, P436
   Leonard LB, 2014, CHILDREN WITH SPECIFIC LANGUAGE IMPAIRMENT, 2ND EDITION, P1
   Leonard LB, 1998, CHILDREN SPECIFIC LA
   Leong V, 2014, HEARING RES, V308, P141, DOI 10.1016/j.heares.2013.07.015
   Lete B, 2004, BEHAV RES METH INS C, V36, P156, DOI 10.3758/BF03195560
   Leybaert J, 2014, FRONTIERS PSYCHOL, V5
   MacMillan NA, 1991, DETECTION THEORY USE
   MacNeilage PF, 1998, BEHAV BRAIN SCI, V21, P499, DOI 10.1017/S0140525X98001265
   Maillart C., 2012, ORTHOPHONIE ENTRETIE, P22
   Marquardt T. P., 2001, TREATING DISORDERED, P413
   Marquardt TP, 2002, J COMMUN DISORD, V35, P31, DOI 10.1016/S0021-9924(01)00068-5
   Max L, 1997, J SPEECH LANG HEAR R, V40, P1097, DOI 10.1044/jslhr.4005.1097
   Mazeau M., 2005, READAPTATION, V522, P8
   Mehler J., 2004, CARTOGRAPHY SYNTACTI, V3, P213
   Montgomery JW, 2005, INT J LANG COMM DIS, V40, P171, DOI 10.1080/13682820400011069
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Muneaux M, 2004, NEUROREPORT, V15, P1255, DOI 10.1097/01.wnr.0000127459.31232.c4
   New B, 2007, APPL PSYCHOLINGUIST, V28, P661, DOI 10.1017/S014271640707035X
   Parisse C, 2010, AUTOUR MOT PRATIQUES
   Pastor MA, 2004, J NEUROSCI, V24, P2585, DOI 10.1523/JNEUROSCI.4210-03.2004
   Peelle JE, 2004, BRAIN LANG, V91, P315, DOI 10.1016/j.bandl.2004.05.007
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Peter B, 2008, CLIN LINGUIST PHONET, V22, P171, DOI 10.1080/02699200701799825
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Port RF, 2003, J PHONETICS, V31, P599, DOI 10.1016/j.wocn.2003.08.001
   Rapin I, 1996, J CHILD PSYCHOL PSYC, V37, P643, DOI 10.1111/j.1469-7610.1996.tb01456.x
   Rapin I., 1983, NEUROPSYCHOLOGY LANG
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Raven J. C., 1998, COLOURED PROGR MATRI
   Reilly S, 2014, INT J LANG COMM DIS, V49, P452, DOI 10.1111/1460-6984.12111
   Richards S, 2015, J SPEECH LANG HEAR R, V58, P1292, DOI 10.1044/2015_JSLHR-L-13-0306
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   SANDGREN O., 2014, INT J LANG COMM DIS, V49, P381, DOI [10.1111/1460-6984.12101, DOI 10.1111/1460-6984.12101]
   Schon D, 2015, ANN NY ACAD SCI, V1337, P32, DOI 10.1111/nyas.12635
   Scott SK, 1998, PSYCHOL RES-PSYCH FO, V61, P4, DOI 10.1007/PL00008162
   Soltesz F., 2013, PLOS ONE, V8
   STARK RE, 1995, APPL PSYCHOLINGUIST, V16, P137, DOI 10.1017/S0142716400007050
   TALLAL P, 1973, NEUROPSYCHOLOGIA, V11, P389, DOI 10.1016/0028-3932(73)90025-0
   TALLAL P, 1975, NEUROPSYCHOLOGIA, V13, P69, DOI 10.1016/0028-3932(75)90049-4
   Telkemeyer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00062
   Telkemeyer S, 2009, J NEUROSCI, V29, P14726, DOI 10.1523/JNEUROSCI.1246-09.2009
   Thomson JM, 2008, J PHYSIOL-PARIS, V102, P120, DOI 10.1016/j.jphysparis.2008.03.007
   Tierney A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00949
   Tierney AT, 2013, BRAIN LANG, V124, P225, DOI 10.1016/j.bandl.2012.12.014
   Tomblin J. B., 2014, UNDERSTANDING INDIVI
   Tomblin JB, 1999, NEURODEVOPMENTAL DIS
   Vargha-Khadem F, 1998, P NATL ACAD SCI USA, V95, P12695, DOI 10.1073/pnas.95.21.12695
   Wake M, 2013, PEDIATRICS, V132, pE895, DOI 10.1542/peds.2012-3878
   Watkins KE, 2002, BRAIN, V125, P452, DOI 10.1093/brain/awf058
   Wechsler D., 2005, ECHELLE INTELLIGENCE
   Wechsler D, 2014, WPPSI 4 ECHELLE INTE
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
   Ziegler JC, 2011, J EXP CHILD PSYCHOL, V110, P362, DOI 10.1016/j.jecp.2011.05.001
NR 118
TC 3
Z9 3
U1 1
U2 14
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 26
PY 2018
VL 13
IS 1
AR e0191808
DI 10.1371/journal.pone.0191808
PG 23
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FT8TF
UT WOS:000423425400025
PM 29373610
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Farris-Trimble, A
   McMurray, B
AF Farris-Trimble, Ashley
   McMurray, Bob
TI Morpho-phonological regularities influence the dynamics of real-time
   word recognition: Evidence from artificial language learning
SO LABORATORY PHONOLOGY
LA English
DT Article
DE phonological processing; lexical access; phonological alternations; word
   recognition; eye-tracking
ID SPEECH-PERCEPTION; LEXICAL ACCESS; SPOKEN WORDS; AMBIGUITY RESOLUTION;
   PLACE ASSIMILATION; TALKER VARIABILITY; PHONETIC FEATURES;
   EYE-MOVEMENTS; MODEL; ENGLISH
AB Phonological alternations are attested in many of the world's languages. In production, these robustly generalize to new words and contexts, suggesting that talkers and listeners of a language have internalized them in some form. However, it is unclear whether listeners' knowledge of phonological alternations is used during real-time spoken word recognition. The present study asks whether listeners use knowledge of phonological alternations to modulate activation of competitor forms during real-time word recognition. In two experiments, listeners learned an artificial language with phonological alternations. We then used eye-tracking in the visual world paradigm to assess real-time spoken word recognition. We examined fixations to competitors that would be a match to the input because of the learned phonological alternation. Results showed that listeners do use phonological alternations in real time. Given a [t] similar to [d] alternation and an auditory stimulus with a surface [d], listeners fixated the [t]-competitor more than one that could not alternate with [d]. They were even able to generalize this to words that had not been learned in their alternated form. However, not all alternations showed the same pattern; listeners did not use a [d] similar to [z] alternation in the same way. Implications for various models of word recognition are discussed.
C1 [Farris-Trimble, Ashley] Simon Fraser Univ, Dept Linguist, Burnaby, BC, Canada.
   [McMurray, Bob] Univ Iowa, Dept Psychol & Brain Sci, Iowa City, IA USA.
   [McMurray, Bob] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA USA.
   [McMurray, Bob] Univ Iowa, Dept Linguist, Iowa City, IA USA.
   [McMurray, Bob] Univ Iowa, DeLTA Ctr, Iowa City, IA USA.
RP Farris-Trimble, A (corresponding author), Simon Fraser Univ, Dept Linguist, Burnaby, BC, Canada.
EM afarrist@sfu.ca
OI Farris-Trimble, Ashley/0000-0001-6627-4301
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [DC011669, DC0008089]; Social Sciences
   and Humanities Research Council of Canada (SSHRC)Social Sciences and
   Humanities Research Council of Canada (SSHRC)
FX Thanks to Hannah Rigler and the members of the MACLab at the University
   of Iowa for help with data collection. Thanks also to John Alderete,
   Paul Tupper, the members of the Vancouver Phonology Group, and attendees
   at LSA 85 and Mid-Phon 17 for helpful discussion. This work was
   supported by NIH grants DC011669 to AFT and DC0008089 to BM, and by a
   research grant from the Social Sciences and Humanities Research Council
   of Canada (SSHRC).
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Apfelbaum KS, 2013, DEV PSYCHOL, V49, P1348, DOI 10.1037/a0029839
   ARCHANGELI D, 1989, LINGUIST INQ, V20, P173
   Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   Armstrong BC, 2017, J EXP PSYCHOL GEN, V146, P227, DOI 10.1037/xge0000257
   Brouwer S, 2012, LANG COGNITIVE PROC, V27, P539, DOI 10.1080/01690965.2011.555268
   Clayards M, 2015, ATTEN PERCEPT PSYCHO, V77, P311, DOI 10.3758/s13414-014-0750-z
   Coenen E, 2001, LANG COGNITIVE PROC, V16, P535, DOI 10.1080/01690960143000155
   COLE RA, 1978, J ACOUST SOC AM, V64, P44, DOI 10.1121/1.381955
   Dahan D, 2007, J MEM LANG, V57, P483, DOI 10.1016/j.jml.2007.01.001
   Darcy I., 2007, LAB PHONOLOGY, VIX, P411
   Darcy I, 2009, PHONOL PHONET, V14, P265
   de Jong K, 1998, J PHONETICS, V26, P283, DOI 10.1006/jpho.1998.0077
   Dinnsen DA, 1996, J CHILD LANG, V23, P57, DOI 10.1017/S0305000900010096
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E
   ELMAN JL, 1988, J ACOUST SOC AM, V83, P1615, DOI 10.1121/1.395916
   Ernestus M, 2004, BRAIN LANG, V90, P378, DOI 10.1016/S0093-934X(03)00449-8
   Ernestus M., 2011, BLACKWELL COMPANION, P2115, DOI [10.1002/9781444335262.wbctp0089, DOI 10.1002/9781444335262.WBCTP0089]
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Finley S, 2009, J MEM LANG, V61, P423, DOI 10.1016/j.jml.2009.05.002
   FRISCH SA, 2001, FREQUENCY EMERGENCE, P159, DOI DOI 10.1075/TSL
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gaskell MG, 2003, J PHONETICS, V31, P447, DOI 10.1016/S0095-4470(03)00012-3
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gaskell MG, 1998, J EXP PSYCHOL HUMAN, V24, P380, DOI 10.1037/0096-1523.24.2.380
   Gaskell MG, 2001, J MEM LANG, V44, P325, DOI 10.1006/jmla.2000.2741
   GOLDINGER SD, 1991, J EXP PSYCHOL LEARN, V17, P152, DOI 10.1037/0278-7393.17.1.152
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476
   Gow DW, 2004, J MEM LANG, V51, P279, DOI 10.1016/j.jml.2004.05.004
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Gow DW, 2002, J EXP PSYCHOL HUMAN, V28, P163, DOI 10.1037//0096-1523.28.1.163
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   Gupta P, 2009, J MEM LANG, V61, P481, DOI 10.1016/j.jml.2009.08.001
   Hercus Luise, 1986, VICTORIAN LANGUAGES
   HUME E, 2001, ROLE SPEECH PERCEPTI, P3
   ITO J, 1986, LINGUIST INQ, V17, P49
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Kim W, 2013, PSYCHOL REV, V120, P903, DOI 10.1037/a0034195
   KLATT DH, 1979, J PHONETICS, V7, P279, DOI 10.1016/S0095-4470(19)31059-9
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lee Shinsook, 2008, PHONOLOGICAL INFEREN
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Magnuson JS, 2003, J EXP PSYCHOL GEN, V132, P202, DOI 10.1037/0096-3445.132.2.202
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Martin A, 2015, J ACOUST SOC AM, V137, pEL307, DOI 10.1121/1.4916792
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   McClelland JL, 2013, J EXP PSYCHOL GEN, V142, P1190, DOI 10.1037/a0033812
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCCLELLAND JL, 1991, COGNITIVE PSYCHOL, V23, P1, DOI 10.1016/0010-0285(91)90002-6
   McClelland JL, 2002, TRENDS COGN SCI, V6, P465, DOI 10.1016/S1364-6613(02)01993-9
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Mitterer H, 2006, COGNITIVE SCI, V30, P451, DOI 10.1207/s15516709cog0000_57
   Mitterer H, 2013, J MEM LANG, V69, P59, DOI 10.1016/j.jml.2013.02.001
   Newton BE, 1972, GENERATIVE INTERPRET
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   PADGETT J, 1994, NAT LANG LINGUIST TH, V12, P465
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Pater Joe., 2004, OPTIMALITY THEORY PH, P271
   Peng L., 2003, U PENNSYLVANIA WORKI, V9, P199
   Peng L., 2008, REALITY EXPLORATION
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pitt MA, 2009, J MEM LANG, V61, P19, DOI 10.1016/j.jml.2009.02.005
   Pontillo D., 2015, PROCEEDINGS OF THE 3, P1895
   PULLEYBLANK D, 1988, LINGUIST INQ, V19, P233
   Pulleyblank D., 1988, PHONOLOGY, V5, P299, DOI DOI 10.1017/S0952675700002323
   PULLEYBLANK DOUGLAS, 1986, STUDIES AFRICAN LING, V17, P119
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   REYNOLDS B, 1994, AM SPEECH, V69, P361, DOI 10.2307/455855
   Ringen C.O., 1988, PHONOLOGY, V5, P327, DOI [10.1017/S0952675700002335, DOI 10.1017/S0952675700002335]
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Salverda AP, 2014, J MEM LANG, V71, P145, DOI 10.1016/j.jml.2013.11.002
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   SCHILLINGESTES N, 1995, AM SPEECH, V70, P291, DOI 10.2307/455901
   Snoeren ND, 2009, J EXP PSYCHOL LEARN, V35, P542, DOI 10.1037/a0014509
   Spivey MJ, 2005, P NATL ACAD SCI USA, V102, P10393, DOI 10.1073/pnas.0503903102
   Stemberger J.P., 1991, SPECIAL STATUS CORON, P181, DOI [10.1016/B978-0-12-544966-3.50015-4, DOI 10.1016/B978-0-12-544966-3.50015-4]
   Stemberger J. P., 1991, PHONOLOGY, V8, P73, DOI DOI 10.1017/S0952675700001287
   Viviani P, 1990, Rev Oculomot Res, V4, P353
   WANG MD, 1973, J ACOUST SOC AM, V54, P1248, DOI 10.1121/1.1914417
   Wheeldon L, 2004, BRAIN LANG, V90, P401, DOI 10.1016/S0093-934X(03)00451-6
NR 90
TC 1
Z9 1
U1 0
U2 2
PU UBIQUITY PRESS LTD
PI LONDON
PA 6 WINDMILL ST, LONDON, W1T 2JB, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD JAN 23
PY 2018
VL 9
IS 1
AR 2
DI 10.5334/labphon.41
PG 34
WC Linguistics; Language & Linguistics
SC Linguistics
GA GB0MN
UT WOS:000428740600001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Van Ackeren, MJ
   Barbero, FM
   Mattioni, S
   Bottini, R
   Collignon, O
AF Van Ackeren, Markus Johannes
   Barbero, Francesca M.
   Mattioni, Stefania
   Bottini, Roberto
   Collignon, Olivier
TI Neuronal populations in the occipital cortex of the blind synchronize to
   the temporal dynamics of speech
SO ELIFE
LA English
DT Article
ID PRIMARY VISUAL-CORTEX; HUMAN AUDITORY-CORTEX; INTERSENSORY PERCEPTION;
   CORTICAL ORGANIZATION; INTELLIGIBLE SPEECH; RIGHT-HEMISPHERE; SPOKEN
   LANGUAGE; BRAIN; PHASE; OSCILLATIONS
AB The occipital cortex of early blind individuals (EB) activates during speech processing, challenging the notion of a hard-wired neurobiology of language. But, at what stage of speech processing do occipital regions participate in EB? Here we demonstrate that parieto-occipital regions in EB enhance their synchronization to acoustic fluctuations in human speech in the theta-range (corresponding to syllabic rate), irrespective of speech intelligibility. Crucially, enhanced synchronization to the intelligibility of speech was selectively observed in primary visual cortex in EB, suggesting that this region is at the interface between speech perception and comprehension. Moreover, EB showed overall enhanced functional connectivity between temporal and occipital cortices that are sensitive to speech intelligibility and altered directionality when compared to the sighted group. These findings suggest that the occipital cortex of the blind adopts an architecture that allows the tracking of speech material, and therefore does not fully abstract from the reorganized sensory inputs it receives.
C1 [Van Ackeren, Markus Johannes; Mattioni, Stefania; Bottini, Roberto; Collignon, Olivier] Univ Trento, Ctr Mind Brain Studies, Trento, Italy.
   [Barbero, Francesca M.; Collignon, Olivier] Univ Louvain, Inst Res Psychol, Louvain, Belgium.
   [Barbero, Francesca M.; Collignon, Olivier] Univ Louvain, Inst Neurosci, Louvain, Belgium.
RP Collignon, O (corresponding author), Univ Trento, Ctr Mind Brain Studies, Trento, Italy.; Collignon, O (corresponding author), Univ Louvain, Inst Res Psychol, Louvain, Belgium.; Collignon, O (corresponding author), Univ Louvain, Inst Neurosci, Louvain, Belgium.
EM olivier.collignon@uclouvain.be
OI collignon, olivier/0000-0003-1882-3550; BOTTINI,
   Roberto/0000-0001-7941-7762
FU H European Research Council [337573]
FX H2020 European Research Council 337573 Markus Johannes Van Ackeren
   Stefania Mattioni Roberto Bottini Olivier Collignon; The funders had no
   role in study design, data collection and interpretation, or the
   decision to submit the work for publication.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Alexandrou AM, 2017, NEUROIMAGE, V152, P628, DOI 10.1016/j.neuroimage.2017.03.006
   Amedi A, 2003, NAT NEUROSCI, V6, P758, DOI 10.1038/nn1072
   Amedi A, 2004, NAT NEUROSCI, V7, P1266, DOI 10.1038/nn1328
   Amedi A, 2010, RESTOR NEUROL NEUROS, V28, P143, DOI [10.3233/RNN-2010-0497, 10.3233/RNN-2010-0503]
   Arnaud L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064553
   Atilgan H, 2017, BRAIN LANG, V170, P71, DOI 10.1016/j.bandl.2017.03.008
   Bates E, 2005, J PIAGET SY, P205
   Bates E, 1999, J COMMUN DISORD, V32, P195, DOI 10.1016/S0021-9924(99)00015-5
   Bedny M, 2017, TRENDS COGN SCI, V21, P637, DOI 10.1016/j.tics.2017.06.003
   Bedny M, 2015, J NEUROSCI, V35, P11674, DOI 10.1523/JNEUROSCI.0634-15.2015
   Bedny M, 2011, P NATL ACAD SCI USA, V108, P4429, DOI 10.1073/pnas.1014818108
   Belin P, 1998, J COGNITIVE NEUROSCI, V10, P536, DOI 10.1162/089892998562834
   Benetti S, 2017, P NATL ACAD SCI USA, V114, pE6437, DOI 10.1073/pnas.1618287114
   Berwick RC, 2013, TRENDS COGN SCI, V17, P89, DOI 10.1016/j.tics.2012.12.002
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Brookes H, 2001, INFANT CHILD DEV, V10, P75, DOI 10.1002/icd.249
   Buchel C, 2003, NAT NEUROSCI, V6, P657, DOI 10.1038/nn0703-657
   Burton H, 2003, J NEUROSCI, V23, P4005
   Burton H, 2003, J NEUROPHYSIOL, V90, P1965, DOI 10.1152/jn.00279.2003
   Burton H, 2002, J NEUROPHYSIOL, V88, P3359, DOI 10.1152/jn.00129.2002
   Burton H, 2012, BRAIN RES, V1438, P22, DOI 10.1016/j.brainres.2011.12.032
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chomsky Noam A, 1976, REFLECTIONS LANGUAGE
   Collignon O, 2015, CURR BIOL, V25, P2379, DOI 10.1016/j.cub.2015.07.036
   Collignon O, 2013, BRAIN, V136, P2769, DOI 10.1093/brain/awt176
   Collignon O, 2011, P NATL ACAD SCI USA, V108, P4435, DOI 10.1073/pnas.1013928108
   Collignon O, 2009, EXP BRAIN RES, V192, P343, DOI 10.1007/s00221-008-1553-z
   Davis MH, 2003, J NEUROSCI, V23, P3423
   de Heer WA, 2017, J NEUROSCI, V37, P6539, DOI 10.1523/JNEUROSCI.3267-16.2017
   Deen B, 2015, J COGNITIVE NEUROSCI, V27, P1633, DOI 10.1162/jocn_a_00807
   Dehaene-Lambertz G, 2006, TRENDS NEUROSCI, V29, P367, DOI 10.1016/j.tins.2006.05.011
   Dietrich S, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-74
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Dormal G, 2016, NEUROIMAGE, V134, P630, DOI 10.1016/j.neuroimage.2016.04.027
   Elman JL., 1996, RETHINKING INNATENES
   Falchier A, 2002, J NEUROSCI, V22, P5749
   Fonteneau E, 2015, CEREB CORTEX, V25, P3962, DOI 10.1093/cercor/bhu283
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Giordano BL, 2017, ELIFE, V6, DOI 10.7554/eLife.24763
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hannagan T, 2015, TRENDS COGN SCI, V19, P374, DOI 10.1016/j.tics.2015.05.006
   Hasson U, 2016, NEUROIMAGE, V128, P362, DOI 10.1016/j.neuroimage.2015.12.048
   He CX, 2013, NEUROIMAGE, V79, P1, DOI 10.1016/j.neuroimage.2013.04.051
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Horowitz-Kraus T, 2015, BRAIN IMAGING BEHAV, V9, P19, DOI 10.1007/s11682-014-9341-9
   Jiang F, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00324
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   Kayser C, 2009, NEURON, V61, P597, DOI 10.1016/j.neuron.2009.01.008
   Kayser SJ, 2015, J NEUROSCI, V35, P14691, DOI 10.1523/JNEUROSCI.2243-15.2015
   Klinge C, 2010, J NEUROSCI, V30, P12798, DOI 10.1523/JNEUROSCI.2384-10.2010
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kushnerenko E, 2008, P NATL ACAD SCI USA, V105, P11442, DOI 10.1073/pnas.0804275105
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011
   Lamme VAF, 1998, CURR OPIN NEUROBIOL, V8, P529, DOI 10.1016/S0959-4388(98)80042-1
   Lane C, 2015, J NEUROSCI, V35, P12859, DOI 10.1523/JNEUROSCI.1256-15.2015
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lewkowicz DJ, 2010, INFANCY, V15, P46, DOI 10.1111/j.1532-7078.2009.00005.x
   Lewkowicz DJ, 2010, DEV PSYCHOL, V46, P66, DOI 10.1037/a0015579
   Lewkowicz DJ, 2000, CHILD DEV, V71, P1241, DOI 10.1111/1467-8624.00226
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   Liljestrom M, 2005, NEUROIMAGE, V25, P734, DOI 10.1016/j.neuroimage.2004.11.034
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000445
   MacSweeney M, 2001, P ROY SOC B-BIOL SCI, V268, P451, DOI 10.1098/rspb.2000.0393
   MacSweeney M, 2000, NEUROREPORT, V11, P1729, DOI 10.1097/00001756-200006050-00026
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Moos Anja, 2007, P 16 INT C PHON SCI, P677
   Murray MM, 2016, TRENDS NEUROSCI, V39, P567, DOI 10.1016/j.tins.2016.05.003
   Narain C, 2003, CEREB CORTEX, V13, P1362, DOI 10.1093/cercor/bhg083
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   NIEMEYER W, 1981, AUDIOLOGY, V20, P510
   Nolte G, 2003, PHYS MED BIOL, V48, P3637, DOI 10.1088/0031-9155/48/22/002
   Nolte G, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.234101
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Peelen MV, 2013, J COGNITIVE NEUROSCI, V25, P1225, DOI 10.1162/jocn_a_00411
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, P2486
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pellegrino F, 2011, LANGUAGE, V87, P539
   Pietrini P, 2004, P NATL ACAD SCI USA, V101, P5658, DOI 10.1073/pnas.0400707101
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Poirier C, 2006, NEUROIMAGE, V31, P279, DOI 10.1016/j.neuroimage.2005.11.036
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Reich L, 2011, CURR BIOL, V21, P363, DOI 10.1016/j.cub.2011.01.040
   Ricciardi E, 2007, CEREB CORTEX, V17, P2933, DOI 10.1093/cercor/bhm018
   Rodd JM, 2010, BRAIN LANG, V115, P182, DOI 10.1016/j.bandl.2010.07.005
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Roder B, 2002, EUR J NEUROSCI, V16, P930, DOI 10.1046/j.1460-9568.2002.02147.x
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Sadato N, 1996, NATURE, V380, P526, DOI 10.1038/380526a0
   Schepers IM, 2012, BRAIN, V135, P922, DOI 10.1093/brain/aws014
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Smith SM, 2009, NEUROIMAGE, V44, P83, DOI 10.1016/j.neuroimage.2008.03.061
   Stephan KE, 2010, NEUROIMAGE, V49, P3099, DOI 10.1016/j.neuroimage.2009.11.015
   Striem-Amit E, 2015, BRAIN, V138, P1679, DOI 10.1093/brain/awv083
   Szymanski FD, 2011, J NEUROSCI, V31, P15787, DOI 10.1523/JNEUROSCI.1416-11.2011
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   VanVeen BD, 1997, IEEE T BIO-MED ENG, V44, P867, DOI 10.1109/10.623056
   Vouloumanos A, 2009, P NATL ACAD SCI USA, V106, P18867, DOI 10.1073/pnas.0906049106
   Weeks R, 2000, J NEUROSCI, V20, P2664
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Zoefel B, 2015, J NEUROSCI, V35, P1954, DOI 10.1523/JNEUROSCI.3484-14.2015
NR 121
TC 7
Z9 8
U1 0
U2 2
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD JAN 17
PY 2018
VL 7
AR e31640
DI 10.7554/eLife.31640
PG 20
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA FU0AA
UT WOS:000423512600001
PM 29338838
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Choi, JE
   Won, JH
   Kim, CH
   Cho, YS
   Hong, SH
   Moon, IJ
AF Choi, Ji Eun
   Won, Jong Ho
   Kim, Cheol Hee
   Cho, Yang-Sun
   Hong, Sung Hwa
   Moon, Il Joon
TI Relationship between spectrotemporal modulation detection and music
   perception in normal-hearing, hearing-impaired, and cochlear implant
   listeners
SO SCIENTIFIC REPORTS
LA English
DT Article
ID CLINICAL-ASSESSMENT; SPEECH-PERCEPTION; USERS; CUES; INTELLIGIBILITY;
   DISCRIMINATION; SENSITIVITY; FREQUENCY; NOISE
AB The objective of this study was to examine the relationship between spectrotemporal modulation (STM) sensitivity and the ability to perceive music. Ten normal-nearing (NH) listeners, ten hearing aid (HA) users with moderate hearing loss, and ten cochlear Implant (CI) users participated in this study. Three different types of psychoacoustic tests including spectral modulation detection (SMD), temporal modulation detection (TMD), and STM were administered. Performances on these psychoacoustic tests were compared to music perception abilities. In addition, psychoacoustic mechanisms involved in the improvement of music perception through HA were evaluated. Music perception abilities in unaided and aided conditions were measured for HA users. After that, HA benefit for music perception was correlated with aided psychoacoustic performance. STM detection study showed that a combination of spectral and temporal modulation cues were more strongly correlated with music perception abilities than spectral or temporal modulation cues measured separately. No correlation was found between music perception performance and SMD threshold or TMD threshold in each group. Also, HA benefits for melody and timbre identification were significantly correlated with a combination of spectral and temporal envelope cues though HA.
C1 [Choi, Ji Eun; Kim, Cheol Hee; Cho, Yang-Sun; Moon, Il Joon] Sungkyunkwan Univ, Samsung Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Sch Med, Seoul, South Korea.
   [Won, Jong Ho] US FDA, Div Ophthalm & Ear Nose & Throat Devices, Off Device Evaluat, Ctr Devices & Radiol Hlth, Silver Spring, MD 20993 USA.
   [Hong, Sung Hwa] Sungkyunkwan Univ, Sch Med, Samsung Changwon Hosp, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
RP Moon, IJ (corresponding author), Sungkyunkwan Univ, Samsung Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Sch Med, Seoul, South Korea.
EM moonij@skku.edu
RI Cho, Yang Sun/F-4611-2014; Choi, Ji Eun/I-5707-2015
OI Choi, Ji Eun/0000-0001-8105-813X
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP; Ministry of Science, ICT & Future Planning)
   [NRF-2017R1C1B5016610]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP; Ministry of Science,
   ICT & Future Planning) (NRF-2017R1C1B5016610). The views expressed in
   this paper are those of the authors. They do not necessarily reflect the
   official policy or position of the US Department of Health and Human
   Services and the US Food and Drug Administration.
CR Anderson ES, 2012, J ACOUST SOC AM, V132, P3925, DOI 10.1121/1.4763999
   Bernstein JGW, 2013, J AM ACAD AUDIOL, V24, P293, DOI 10.3766/jaaa.24.4.5
   Chi TS, 1999, J ACOUST SOC AM, V106, P2719, DOI 10.1121/1.428100
   Choi JE, 2016, SCI REP-UK, V6, DOI 10.1038/srep35235
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Drennan WR, 2008, JARO-J ASSOC RES OTO, V9, P138, DOI 10.1007/s10162-007-0107-6
   Eddins DA, 2007, J ACOUST SOC AM, V121, P363, DOI 10.1121/1.2382347
   George ELJ, 2010, J SPEECH LANG HEAR R, V53, P1429, DOI 10.1044/1092-4388(2010/09-0197)
   Hallgren M, 2005, INT J AUDIOL, V44, P574, DOI 10.1080/14992020500190011
   Jung KH, 2012, AUDIOL NEURO-OTOL, V17, P189, DOI 10.1159/000336407
   Jung KH, 2010, ACTA OTO-LARYNGOL, V130, P716, DOI 10.3109/00016480903380521
   Kang R, 2009, EAR HEARING, V30, P411, DOI 10.1097/AUD.0b013e3181a61bc0
   Kiefer J, 2001, AUDIOLOGY, V40, P32
   Kirchberger M., 2016, TRENDS HEAR, V20
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Landsberger D. M., 2017, EAR HEAR
   Looi V, 2008, EAR HEARING, V29, P421, DOI 10.1097/AUD.0b013e31816a0d0b
   Looi V, 2010, INT J AUDIOL, V49, P116, DOI 10.3109/14992020903405987
   Madsen SMK, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514558271
   Marshall C., 2004, HEARING J, V57
   Patil K, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002759
   Plack C. J., 2016, THE SENSE OF HEARING, P213
   Saoji AA, 2009, J ACOUST SOC AM, V126, P955, DOI 10.1121/1.3179670
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Supin AY, 1997, HEARING RES, V108, P17, DOI 10.1016/S0378-5955(97)00035-X
   UYSMARINDA, 2011, S AFR J COMMUN DISOR, V58, P19, DOI DOI 10.4102/sajcd.v58i1.38
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Won JH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140920
   Won JH, 2011, J ACOUST SOC AM, V130, P376, DOI 10.1121/1.3592521
   Won JH, 2010, EAR HEARING, V31, P796, DOI 10.1097/AUD.0b013e3181e8b7bd
   Zahorik Pavel, 2011, Proc Meet Acoust, V12, P50005
   Zhang T, 2013, EAR HEARING, V34, P133, DOI 10.1097/AUD.0b013e31826709af
   Zheng Y, 2017, HEARING RES, V351, P45, DOI 10.1016/j.heares.2017.05.009
NR 33
TC 6
Z9 6
U1 0
U2 11
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JAN 15
PY 2018
VL 8
AR 800
DI 10.1038/s41598-017-17350-w
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FS8CE
UT WOS:000422637200059
PM 29335454
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rodriguez, SM
   Archila-Suerte, P
   Vaughn, KA
   Chiarello, C
   Hernandez, AE
AF Rodriguez, Stephen Matthew
   Archila-Suerte, Pilar
   Vaughn, Kelly A.
   Chiarello, Christine
   Hernandez, Arturo E.
TI Anterior insular thickness predicts speech sound learning ability in
   bilinguals
SO NEUROIMAGE
LA English
DT Article
DE Neuroanatomy; Speech learning; Bilingualism; Insula
ID HUMAN CEREBRAL-CORTEX; CORTICAL THICKNESS; BRAIN STRUCTURE; HESCHLS
   GYRUS; JAPANESE ADULTS; AUDITORY-CORTEX; LANGUAGE; MRI; ACTIVATION;
   PLASTICITY
AB A previous fMRI study of novel speech sound learning, tied to the methods and results presented here, identified groups of advanced and novice learners and related their classification to neural activity. To complement those results and better elucidate the role of the entire neural system in speech learning, the current study analyzed the neuroanatomical data with the goals of 1) uncovering the regions of interest (ROIs) that predicted speech learning performance in a sample of monolingual and bilingual adults, and 2) examining if the relationship between cortical thickness from selected ROIs and individual learning ability depends on language group. The ROIs selected were brain regions well-established in the literature as areas associated with language and speech processing (i.e., Transverse Superior Temporal Gyrus, anterior insula and posterior insula, all bilaterally). High-resolution brain scans (T1-weighted) were acquired from 23 Spanish-English bilinguals and 20 English monolingual adults. The thickness of the left anterior insula significantly predicted speech sound learning ability in bilinguals but not monolinguals. These results suggest that aptitude for learning a new language is associated with variations in the cortical thickness of the left anterior insula in bilinguals. These findings may provide insight into the higher order mechanisms involved in speech perception and advance our understanding of the unique strategies employed by the bilingual brain during language learning.
C1 [Rodriguez, Stephen Matthew; Archila-Suerte, Pilar; Vaughn, Kelly A.; Hernandez, Arturo E.] Univ Houston, 4800 Calhoun Rd, Houston, TX 77004 USA.
   [Chiarello, Christine] Univ Calif Riverside, 900 Univ Ave, Riverside, CA 92521 USA.
RP Rodriguez, SM (corresponding author), Univ Houston, Dept Psychol, Houston, TX 77004 USA.
EM matt23411@gmail.com
FU EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH &HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R03HD050313,
   R03HD050313] Funding Source: NIH RePORTER; NICHD NIH HHSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [R03 HD050313] Funding Source: Medline
CR Abutalebi J, 2008, ACTA PSYCHOL, V128, P466, DOI 10.1016/j.actpsy.2008.03.014
   Abutalebi J, 2007, J NEUROLINGUIST, V20, P242, DOI 10.1016/j.jneuroling.2006.10.003
   Archila-Suerte P., 2011, BILING-LANG COGN, V15, P190
   Archila-Suerte P, 2016, INT J BILINGUAL, V20, P231, DOI 10.1177/1367006914552206
   Ardila A, 1999, APHASIOLOGY, V13, P79, DOI 10.1080/026870399402334
   Ardila A, 2014, J NEUROLINGUIST, V29, P31, DOI 10.1016/j.jneuroling.2014.02.001
   Bamiou DE, 2003, BRAIN RES REV, V42, P143, DOI 10.1016/S0165-0173(03)00172-3
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Bernheim F., 1900, APHASIE MOTRICE
   Blackmon K, 2010, NEUROIMAGE, V51, P1453, DOI 10.1016/j.neuroimage.2010.03.028
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Booth JR, 2007, BRAIN RES, V1133, P136, DOI 10.1016/j.brainres.2006.11.074
   Chee MWL, 2004, P NATL ACAD SCI USA, V101, P15265, DOI 10.1073/pnas.0403703101
   Chee MWL, 2001, NEUROIMAGE, V13, P1155, DOI 10.1006/nimg.2001.0781
   Cohen J., 2010, PSYSCOPE X BUILD, V57
   Dejerine J., 1914, SEMIOLOGIE AFFECTION
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Dickerson BC, 2008, NEUROIMAGE, V39, P10, DOI 10.1016/j.neuroimage.2007.08.042
   Dierks T, 1999, NEURON, V22, P615, DOI 10.1016/S0896-6273(00)80715-1
   Draganski B, 2004, NATURE, V427, P311, DOI 10.1038/427311a
   Dronkers NF, 1996, NATURE, V384, P159, DOI 10.1038/384159a0
   Eickhoff SB, 2009, PHILOS T R SOC A, V367, P2399, DOI 10.1098/rsta.2008.0287
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087
   Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Gaab N, 2006, NEUROIMAGE, V31, P255, DOI 10.1016/j.neuroimage.2005.11.046
   Garbin G, 2011, BRAIN LANG, V119, P129, DOI 10.1016/j.bandl.2011.03.011
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Glasser MF, 2011, J NEUROSCI, V31, P11597, DOI 10.1523/JNEUROSCI.2180-11.2011
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Golestani N, 2007, CEREB CORTEX, V17, P575, DOI 10.1093/cercor/bhk001
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Kolb B, 2008, NEUROBIOL LEARN MEM, V90, P295, DOI 10.1016/j.nlm.2008.04.012
   Lu LH, 2007, CEREB CORTEX, V17, P1092, DOI 10.1093/cercor/bhl019
   Maguire EA, 2000, P NATL ACAD SCI USA, V97, P4398, DOI 10.1073/pnas.070039597
   Marshall RS, 1996, J NEUROIMAGING, V6, P189, DOI 10.1111/jon199663189
   McCandliss BD, 2002, COGN AFFECT BEHAV NE, V2, P89, DOI 10.3758/CABN.2.2.89
   Menon V, 2010, BRAIN STRUCT FUNCT, V214, P655, DOI 10.1007/s00429-010-0262-0
   Mimura K, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.031910
   Oh A, 2014, BRAIN LANG, V135, P96, DOI 10.1016/j.bandl.2014.06.003
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Patterson RD, 2002, NEURON, V36, P767, DOI 10.1016/S0896-6273(02)01060-7
   Porter JN, 2011, NEUROIMAGE, V55, P1865, DOI 10.1016/j.neuroimage.2011.01.018
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Segonne F, 2004, NEUROIMAGE, V22, P1060, DOI 10.1016/j.neuroimage.2004.03.032
   Shaw P, 2006, NATURE, V440, P676, DOI 10.1038/nature04513
   SHUREN J, 1993, J NEUROL, V240, P216, DOI 10.1007/BF00818707
   Simos PG, 2002, CEREB CORTEX, V12, P297, DOI 10.1093/cercor/12.3.297
   Sowell ER, 2007, CEREB CORTEX, V17, P1550, DOI 10.1093/cercor/bhl066
   Tatsuno Y, 2005, J NEUROSCI, V25, P1637, DOI 10.1523/JNEUROSCI.3978-04.2005
   Taubert M, 2010, J NEUROSCI, V30, P11670, DOI 10.1523/JNEUROSCI.2567-10.2010
   Wang Y, 2003, J COGNITIVE NEUROSCI, V15, P1019, DOI 10.1162/089892903770007407
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Warrier C, 2009, J NEUROSCI, V29, P61, DOI 10.1523/JNEUROSCI.3489-08.2009
   Wong PCM, 2008, CEREB CORTEX, V18, P828, DOI 10.1093/cercor/bhm115
   Woodcock R.W., 1995, WOODCOCK JOHNSON LAN
   Woodcock R. W., 1995, WOODCOCK LANGUAGE PR
   Zatorre RJ, 2012, NAT NEUROSCI, V15, P528, DOI 10.1038/nn.3045
NR 64
TC 6
Z9 6
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD JAN 15
PY 2018
VL 165
BP 278
EP 284
DI 10.1016/j.neuroimage.2017.10.038
PG 7
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA FP5CJ
UT WOS:000417635900025
PM 29061528
OA Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Lohvansuu, K
   Hamalainen, JA
   Ervast, L
   Lyytinen, H
   Leppanen, PHT
AF Lohvansuu, Kaisa
   Hamalainen, Jarmo A.
   Ervast, Leena
   Lyytinen, Heikki
   Leppanen, Paavo H. T.
TI Longitudinal interactions between brain and cognitive measures on
   reading development from 6 months to 14 years
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Children; Dyslexia; Event-related potentials; Infants; Reading; Speech
   perception
ID AUTOMATIZED NAMING RAN; FAMILIAL RISK; SPEECH-PERCEPTION; SCHOOL-AGE;
   DYSLEXIA; CHILDREN; SKILLS; INFANTS; RESPONSES; FLUENCY
AB Dyslexia is a neurobiological disorder impairing learning to read. Brain responses of infants at genetic risk for dyslexia are abnormal already at birth, and associations from infant speech perception to preschool cognitive skills and reading in early school years have been documented, but there are no studies showing predicting power until adolescence. Here we show that in at-risk infants, brain activation to pseudowords at left hemisphere predicts 44% of reading speed at 14 years, and even improves the prediction after taking into account neurocognitive preschool measures of letter naming, phonology, and verbal short-term memory. The association between infant brain responses and reading speed is mediated by preschool rapid automatized naming ability. Therefore, we suggest that rapid naming and reading speed could share a similar cognitive process of automatized access to lexicon via phonological representations, and brain activation to speech sounds in infancy probably acts as an index of deficient development of the same process.
C1 [Lohvansuu, Kaisa; Hamalainen, Jarmo A.; Lyytinen, Heikki; Leppanen, Paavo H. T.] Univ Jyvaskyla, Dept Psychol, POB 35, FI-40014 Jyvaskyla, Finland.
   [Lohvansuu, Kaisa; Hamalainen, Jarmo A.; Lyytinen, Heikki; Leppanen, Paavo H. T.] Univ Jyvaskyla, Jyvaskyla Ctr Interdisciplinary Brain Res, POB 35, FI-40014 Jyvaskyla, Finland.
   [Ervast, Leena] Univ Oulu, Fac Humanities, Logoped & Child Language Res Ctr, POB 1000, FI-90014 Oulu, Finland.
   [Ervast, Leena] Oulu Univ Hosp, Dept Clin Neurophysiol, Neurocognit Unit, POB 50, FI-90029 Oulu, Finland.
RP Lohvansuu, K (corresponding author), Univ Jyvaskyla, Dept Psychol, POB 35, FI-40014 Jyvaskyla, Finland.
EM kaisa.lohvansuu@jyu.fi
RI Lyytinen, Heikki/AAS-3200-2020
OI Lohvansuu, Kaisa/0000-0002-1641-844X; Hamalainen,
   Jarmo/0000-0001-7188-8148
FU Centre of Excellence Program of the Academy of FinlandAcademy of Finland
   [44858, 213486]
FX This work was supported by the Centre of Excellence Program of the
   Academy of Finland (grant numbers 44858, 213486). We thank the
   participants and their families and students who took part in data
   collection.
CR BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Blomert L, 2011, NEUROIMAGE, V57, P695, DOI 10.1016/j.neuroimage.2010.11.003
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Cantiani C, 2016, DEV COGN NEUROS-NETH, V20, P23, DOI 10.1016/j.dcn.2016.03.002
   Clark KA, 2014, BRAIN, V137, P3136, DOI 10.1093/brain/awu229
   DENCKLA MB, 1976, NEUROPSYCHOLOGIA, V14, P471, DOI 10.1016/0028-3932(76)90075-0
   Eklund K, 2015, J EDUC PSYCHOL, V107, P126, DOI 10.1037/a0037121
   GALABURDA AM, 1985, ANN NEUROL, V18, P222, DOI 10.1002/ana.410180210
   Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3
   Guttorm TK, 2010, J LEARN DISABIL-US, V43, P391, DOI 10.1177/0022219409345005
   Hamalainen JA, 2013, DEV NEUROPSYCHOL, V38, P550, DOI 10.1080/87565641.2012.718817
   Hayrinen T., 1999, LUKILASSE LUKEMISEN
   Karhu J, 1997, NEUROREPORT, V8, P1327, DOI 10.1097/00001756-199704140-00002
   Korkman M., 1998, NEPSY DEV NEUROPSYCH
   Leinonen S, 2001, READ WRIT, V14, P265, DOI 10.1023/A:1011117620895
   Leppanen PHT, 2012, NEUROPHYSIOL CLIN, V42, P35, DOI 10.1016/j.neucli.2011.08.005
   Leppanen PHT, 2010, CORTEX, V46, P1362, DOI 10.1016/j.cortex.2010.06.003
   Leppanen PHT, 2002, DEV NEUROPSYCHOL, V22, P407, DOI 10.1207/S15326942dn2201_4
   Lyytinen H., 2008, SAGE HDB DYSLEXIA, P121, DOI DOI 10.4135/9780857020987
   MCBRIDECHANG C, 1995, EDUC PSYCHOL, V30, P109, DOI 10.1207/s15326985ep3003_2
   McNemar Q., 1969, PSYCHOL STAT
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   Norton ES, 2012, ANNU REV PSYCHOL, V63, P427, DOI 10.1146/annurev-psych-120710-100431
   Preacher KJ, 2004, BEHAV RES METH INS C, V36, P717, DOI 10.3758/BF03206553
   Preacher KJ, 2008, BEHAV RES METHODS, V40, P879, DOI 10.3758/BRM.40.3.879
   Puolakanaho A, 2008, J LEARN DISABIL-US, V41, P353, DOI 10.1177/0022219407311747
   Raschle NM, 2012, P NATL ACAD SCI USA, V109, P2156, DOI 10.1073/pnas.1107721109
   Raschle NM, 2011, NEUROIMAGE, V57, P742, DOI 10.1016/j.neuroimage.2010.09.055
   Richardson U, 2003, DEV NEUROPSYCHOL, V23, P385, DOI 10.1207/S15326942DN2303_5
   Richlan F, 2013, HUM BRAIN MAPP, V34, P3055, DOI 10.1002/hbm.22127
   Richlan F, 2011, NEUROIMAGE, V56, P1735, DOI 10.1016/j.neuroimage.2011.02.040
   Suomi K, 2008, STUDIA HUMANIARIA OU, V9, P39
   van der Leij A, 2013, DYSLEXIA, V19, P191, DOI 10.1002/dys.1463
   van Leeuwen T, 2006, NEUROREPORT, V17, P351, DOI 10.1097/01.wnr.0000203624.02082.2d
   van Zuijen TL, 2013, DEVELOPMENTAL SCI, V16, P554, DOI 10.1111/desc.12049
   van Zuijen TL, 2012, NEUROSCI LETT, V528, P31, DOI 10.1016/j.neulet.2012.08.058
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Wechsler D, 1991, WISC 3 WECHSLER INTE
NR 38
TC 17
Z9 17
U1 1
U2 21
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD JAN 8
PY 2018
VL 108
BP 6
EP 12
DI 10.1016/j.neuropsychologia.2017.11.018
PG 7
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FU1YD
UT WOS:000423644500002
PM 29157996
DA 2021-02-24
ER

PT J
AU Hladek, L
   Porr, B
   Brimijoin, WO
AF Hladek, L'ubos
   Porr, Bernd
   Brimijoin, W. Owen
TI Real-time estimation of horizontal gaze angle by saccade integration
   using in-ear electrooculography
SO PLOS ONE
LA English
DT Article
ID EYE-MOVEMENTS; SPEECH-PERCEPTION; EOG ARTIFACTS; HEARING; ALGORITHM;
   BIASES
AB The manuscript proposes and evaluates a real-time algorithm for estimating eye gaze angle based solely on single-channel electrooculography (EOG), which can be obtained directly from the ear canal using conductive ear moulds. In contrast to conventional high-pass filtering, we used an algorithm that calculates absolute eye gaze angle via statistical analysis of detected saccades. The estimated eye positions of the new algorithm were still noisy. However, the performance in terms of Pearson product-moment correlation coefficients was significantly better than the conventional approach in some instances. The results suggest that in-ear EOG signals captured with conductive ear moulds could serve as a basis for lightweight and portable horizontal eye gaze angle estimation suitable for a broad range of applications. For instance, for hearing aids to steer the directivity of microphones in the direction of the user's eye gaze.
C1 [Hladek, L'ubos; Brimijoin, W. Owen] MRC, Chief Scientist Off, Inst Hearing Res, Scottish Sect, Glasgow, Lanark, Scotland.
   [Porr, Bernd] Univ Glasgow, Sch Engn, Glasgow, Lanark, Scotland.
RP Hladek, L (corresponding author), MRC, Chief Scientist Off, Inst Hearing Res, Scottish Sect, Glasgow, Lanark, Scotland.
EM lubos.hladek@nottingham.ac.uk
OI Hladek, Lubos/0000-0002-0870-7612; Porr, Bernd/0000-0001-8157-998X;
   Brimijoin, W. Owen/0000-0001-6124-3987
FU Oticon Foundation; UK Medical Research CouncilUK Research & Innovation
   (UKRI)Medical Research Council UK (MRC) [U135097131, MC_UU_00010/4];
   Chief Scientist Office (Government of Scotland)
FX This work was supported by grants from the Oticon Foundation, the UK
   Medical Research Council [grant nos. U135097131 and MC_UU_00010/4], and
   the Chief Scientist Office (Government of Scotland). The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Anderson TJ, 2013, NAT REV NEUROL, V9, P74, DOI 10.1038/nrneurol.2012.273
   [Anonymous], 2015, BIOIMPEDANCE BIOELEC
   Barea R, 2012, EXPERT SYST APPL, V39, P2677, DOI 10.1016/j.eswa.2011.08.123
   Barea R, 2002, J INTELL ROBOT SYST, V34, P279, DOI 10.1023/A:1016359503796
   Behrens F, 2010, BEHAV RES METHODS, V42, P701, DOI 10.3758/BRM.42.3.701
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Boccignone G, 2015, ADV STAT METHODS EYE
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brown M, 2006, DOC OPHTHALMOL, V113, P205, DOI 10.1007/s10633-006-9030-0
   Bulling A, 2016, INTERACTIONS, V23, p70 , DOI [DOI 10.1145/2930854, DOI 10.1145/2912886]
   Bulling A, 2011, IEEE T PATTERN ANAL, V33, P741, DOI 10.1109/TPAMI.2010.86
   Bulling A, 2009, J AMB INTEL SMART EN, V1, P157, DOI 10.3233/AIS-2009-0020
   de Bruijn N.G, 1946, P K NED AKAD WETENSC, V49, P758
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Fang Y, 2015, PLOS ONE, V10, P1
   Glickman ME, 2014, J CLIN EPIDEMIOL, V67, P850, DOI 10.1016/j.jclinepi.2014.03.012
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Hart J, 2009, LECT NOTES COMPUT SC, V5726, P19, DOI 10.1007/978-3-642-03655-2_4
   Haslwanter T, 2010, HDB CLIN NEUROPHYSIO
   Higgins E, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00210
   Hladek Porr B, 2017, EFFECT WIDTH ACOUSTI
   Ianez E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067099
   Kassner M, 2014, PUPIL OPEN SOURCE PL
   Kidd G, 2013, J ACOUST SOC AM, V133, pEL202, DOI 10.1121/1.4791710
   Kleiner M, 2007, PERCEPTION, V36, P14
   Komogortsev OV, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P229, DOI 10.1145/1344471.1344525
   Krassanakis V, 2014, J EYE MOVEMENT RES, V7
   Le Meur O, 2016, VISION RES, V121, P72, DOI 10.1016/j.visres.2016.01.005
   Manabe H., 2006, FULL TIME WEARABLE H, P1073
   Manabe H, 2006, NTT DOCOMO TECH J, V12, P12
   Manabe H, 2015, IEEE T BIO-MED ENG, V62, P1553, DOI 10.1109/TBME.2015.2394409
   Manabe H, 2013, IEEE ENG MED BIO, P53, DOI 10.1109/EMBC.2013.6609435
   MCPARTLAND RJ, 1978, INT J BIOMED COMPUT, V9, P409, DOI 10.1016/0020-7101(78)90048-X
   Nakashima R, 2015, VISION RES, V117, P59, DOI 10.1016/j.visres.2015.10.001
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pettersson K, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-110
   Puthusserypady S, 2006, SIGNAL PROCESS, V86, P2351, DOI 10.1016/j.sigpro.2005.10.018
   Ramli R, 2015, EXPERT SYST APPL, V42, P2451, DOI 10.1016/j.eswa.2014.10.052
   Schleicher R, 2008, ERGONOMICS, V51, P982, DOI 10.1080/00140130701817062
   SHANK MD, 1987, PERCEPT MOTOR SKILL, V64, P1191, DOI 10.2466/pms.1987.64.3c.1191
   Sugano Y, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P363, DOI 10.1145/2807442.2807445
   Tatler BW, 2009, VIS COGN, V17, P1029, DOI 10.1080/13506280902764539
   Toivanen M., 2015, J EYE MOVEMENT RES, V8, P1, DOI DOI 10.16910/JEMR.8.2.1
   Vidal M., 2011, P 1 INT WORKSH PERV, P15, DOI DOI 10.1145/2029956.2029962
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 46
TC 5
Z9 5
U1 0
U2 2
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 5
PY 2018
VL 13
IS 1
AR e0190420
DI 10.1371/journal.pone.0190420
PG 24
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FR9OU
UT WOS:000419403800047
PM 29304120
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Honeder, C
   Liepins, R
   Arnoldner, C
   Sinkovec, H
   Kaider, A
   Vyskocil, E
   Riss, D
AF Honeder, Clemens
   Liepins, Rudolfs
   Arnoldner, Christoph
   Sinkovec, Hana
   Kaider, Alexandra
   Vyskocil, Erich
   Riss, Dominik
TI Fixed and adaptive beamforming improves speech perception in noise in
   cochlear implant recipients equipped with the MED-EL SONNET audio
   processor
SO PLOS ONE
LA English
DT Article
ID DIRECTIONAL MICROPHONES; SOUND PROCESSOR; HEARING; PERFORMANCE;
   INTELLIGIBILITY; MULTICENTER; STRATEGIES; BENEFIT
AB Objective
   To determine the impact of the fixed and adaptive beamforming technology of the new MED-EL SONNET cochlear implant audio processor on speech perception in noise.
   Methods
   The study cohort comprises 18 postlingually deafened adult cochlear implant recipients with at least six months of experience. Speech reception thresholds were measured with the Oldenburg Sentence Test in continuous, speech-shaped noise. Target sentences were presented in front of the listener, with noise sources placed at -135 degrees and 135 degrees, respectively. Outcome measures were the differences in speech reception threshold using omnidirectional, fixed and adaptive beamformer microphone settings.
   Results
   The use of directional microphones significantly improved speech reception thresholds: fixed beamformer vs. omnidirectional: 4.3 dB (95%-CI [3.1; 5.5]), p<0.0001; adaptive beamformer vs. omnidirectional: 6.1 dB (95%-CI [4.9; 7.3]), p<0.0001; and adaptive beamformer vs. fixed beamformer: 1.8 dB (95%-CI [0.7; 3.0]), p = 0.001.
   Conclusion
   This study confirms the previously reported improvements in speech perception in noise of the fixed beamformer microphone setting and is the first to report significant improvements in speech perception in noise when applying the adaptive beamformer microphone settings of the SONNET audio processor. Cochlear implant users may be able to benefit from improved hearing performance especially in difficult listening situations.
C1 [Honeder, Clemens; Liepins, Rudolfs; Arnoldner, Christoph; Vyskocil, Erich; Riss, Dominik] Med Univ Vienna, Dept Otorhinolaryngol Head & Neck Surg, Vienna, Austria.
   [Sinkovec, Hana; Kaider, Alexandra] Med Univ Vienna, Ctr Med Stat Informat & Intelligent Syst, Sect Clin Biometr, Vienna, Austria.
RP Riss, D (corresponding author), Med Univ Vienna, Dept Otorhinolaryngol Head & Neck Surg, Vienna, Austria.
EM dominik.riss@meduniwien.ac.at
OI Arnoldner, Christoph/0000-0003-0066-810X
FU MED-EL Corporation, Innsbruck, Austria
FX DR and CA currently receive funding from MED-EL Corporation, Innsbruck,
   Austria. The funder had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Bentler Ruth A, 2005, J Am Acad Audiol, V16, P473, DOI 10.3766/jaaa.16.7.7
   Buechner A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095542
   Chung K, 2009, HEARING RES, V250, P27, DOI 10.1016/j.heares.2009.01.005
   Dillier N, 2015, AUDIOL RES, V5, DOI 10.4081/audiores.2015.132
   Gifford RH, 2015, OTOL NEUROTOL, V36, P1331, DOI 10.1097/MAO.0000000000000804
   Gifford RH, 2010, EAR HEARING, V31, P186, DOI 10.1097/AUD.0b013e3181c6b831
   Hey M, 2014, INT J AUDIOL, V53, P895, DOI 10.3109/14992027.2014.938368
   Kokkinakis K, 2012, TRENDS AMPLIF, V16, P102, DOI 10.1177/1084713812456906
   Litovsky R, 2006, EAR HEARING, V27, P714, DOI 10.1097/01.aud.0000246816.50820.42
   McCreery RW, 2012, AM J AUDIOL, V21, P295, DOI 10.1044/1059-0889(2012/12-0014)
   Mosnier I, 2014, EUR ARCH OTO-RHINO-L, V271, P49, DOI 10.1007/s00405-013-2381-8
   Rader T, 2008, DEUTSCHE JAHRESTAGUN
   Razza S, 2013, OTOLARYNG HEAD NECK, V149, P608, DOI 10.1177/0194599813496382
   Ricketts T, 2000, EAR HEARING, V21, P194, DOI 10.1097/00003446-200006000-00002
   Riss D, 2014, EAR HEARING, V35, pE272, DOI 10.1097/AUD.0000000000000063
   Smulders YE, 2016, JAMA OTOLARYNGOL, V142, P249, DOI 10.1001/jamaoto.2015.3305
   Spahr AJ, 2007, EAR HEARING, V28, P260, DOI 10.1097/AUD.0b013e3180312607
   Spriet A, 2007, EAR HEARING, V28, P62, DOI 10.1097/01.aud.0000252470.54246.54
   Vermeire K, 2010, ORL-J OTO-RHIN-LARYN, V72, P305, DOI 10.1159/000319748
   Wagener K., 2004, FACTORS INFLUENCING
   Wagener K, 1999, Z AUDIOL, V38, P86
   Wagener K, 1999, Z AUDIOL, V38, P44
   Wagener K., 1999, Z AUDIOL, V38, P4
   Wimmer W, 2016, OTOL NEUROTOL, V37, P19, DOI 10.1097/MAO.0000000000000866
   Wolfe J, 2012, OTOL NEUROTOL, V33, P553, DOI 10.1097/MAO.0b013e31825367a5
NR 25
TC 6
Z9 6
U1 0
U2 1
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 5
PY 2018
VL 13
IS 1
AR e0190718
DI 10.1371/journal.pone.0190718
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FR9OU
UT WOS:000419403800106
PM 29304186
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Burnham, D
   Singh, L
   Mattock, K
   Woo, PJ
   Kalashnikova, M
AF Burnham, Denis
   Singh, Leher
   Mattock, Karen
   Woo, Pei J.
   Kalashnikova, Marina
TI Constraints on Tone Sensitivity in Novel Word Learning by Monolingual
   and Bilingual Infants: Tone Properties Are More Influential than Tone
   Familiarity
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE word learning; lexical tone; monolingual/bilingual; infant;
   nativenan-native
ID LEXICAL TONE; SPEECH-PERCEPTION; 1ST YEAR; LANGUAGE INPUT; INTONATION;
   RECOGNITION; FLEXIBILITY; PROSODY; VOWEL
AB This study compared tone sensitivity in monolingual and bilingual infants in a novel word learning task. Tone language learning infants (Experiment 1, Mandarin monolingual; Experiment 2, Mandarin-English bilingual) were tested with Mandarin (native) or Thai (non-native) lexical tone pairs which contrasted static vs. dynamic (high vs. rising) tones or dynamic vs. dynamic (rising vs. falling) tones. Non-tone language, English-learning infants (Experiment 3) were tested on English intonational contrasts or the Mandarin or Thai tone contrasts. Monolingual Mandarin language infants were able to bind tones to novel words for the Mandarin High-Rising contrast, but not for the Mandarin Rising-Falling contrast; and they were insensitive to both the High-Rising and the Rising-Falling tone contrasts in Thai. Bilingual English-Mandarin infants were similar to the Mandarin monolinguals in that they were sensitive to the Mandarin High-Rising contrast and not to the Mandarin Rising-Falling contrast. However, unlike the Mandarin monolinguals, they were also sensitive to the High Rising contrast in Thai. Monolingual English learning infants were insensitive to all three types of contrasts (Mandarin, Thai, English), although they did respond differentially to tone-bearing vs. intonation-marked words. Findings suggest that infants' sensitivity to tones in word learning contexts depends heavily on tone properties, and that this influence is, in some cases, stronger than effects of language familiarity. Moreover, bilingual infants demonstrated greater phonological flexibility in tone interpretation.
C1 [Burnham, Denis; Mattock, Karen; Kalashnikova, Marina] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
   [Singh, Leher] Natl Univ Singapore, Dept Psychol, Singapore, Singapore.
   [Mattock, Karen] Western Sydney Univ, Sch Social Sci & Psychol, Sydney, NSW, Australia.
   [Woo, Pei J.] Sunway Univ, Dept Psychol, Kuala Lumpur, Malaysia.
RP Burnham, D (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
EM denis.burnham@westernsydney.edu.au
RI Kalashnikova, Marina/B-6590-2019; Burnham, Denis/L-3742-2019
OI Kalashnikova, Marina/0000-0002-7924-8687; Burnham,
   Denis/0000-0002-1980-3458; Woo, Pei Jun/0000-0002-8999-2979
FU Australian Research CouncilAustralian Research Council [DP0988201];
   Ministry of Education, Singapore (MOE)Ministry of Education, Singapore
   [FY2013-FRC2-009]
FX This project was primarily supported by the Australian Research Council
   (DP0988201) to DB (lead investigator) and KM; and was also supported by
   a grant from the Ministry of Education, Singapore to LS (MOE Tier 1
   Grant FY2013-FRC2-009). The authors wish to thank Dr. Benjawan Kasisopa
   for assistance with the design of the stimuli and for collecting the
   Thai, Mandarin, and English speech samples and then selecting and
   editing the speech stimuli. We thank the following people for
   recruitment and testing of participants: Ms. Jhia Mae Woo and Ms. Ai Jia
   Tan in Malaysia, Ms. Felicia Poh in Singapore, and Ms. Candice Michael
   in Sydney. We are very grateful for the time and commitment of all the
   caregivers and infants who participated in the study in Lancaster, Kuala
   Lumpur, Singapore, and Sydney.
CR Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bolinger D., 1958, AM SPEECH, V33, P5, DOI DOI 10.2307/453459
   Burnham D., 1997, SE ASIAN LINGUISTIC, P29
   Burnham D, 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI 10.1017/S0142716414000496
   Chen A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00297
   Chen A, 2016, INFANT CHILD DEV, V25, P426, DOI 10.1002/icd.1944
   Cohen L.B, 2004, HABIT X NEW PROGRAM
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   Da J., 2015, MODERN CHINESE CHARA
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Fromkin V.A., 1978, TONE LINGUISTIC SURV
   Frota S, 2014, INFANCY, V19, P194, DOI 10.1111/infa.12037
   Garcia-Sierra A, 2011, J PHONETICS, V39, P546, DOI 10.1016/j.wocn.2011.07.002
   Gussenhoven Carlos, 2004, PHONOLOGY TONE INTON
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Ma WY, 2017, COGNITION, V159, P139, DOI 10.1016/j.cognition.2016.11.011
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Ramachers S, 2018, J CHILD LANG, V45, P290, DOI 10.1017/S0305000917000228
   Ramirez NF, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12427
   Shi RS, 2017, INFANCY, V22, P790, DOI 10.1111/infa.12191
   Singh L, 2018, CHILD DEV, V89, pe397, DOI 10.1111/cdev.12852
   Singh L, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00667
   Singh L, 2016, J PHONETICS, V55, P109, DOI 10.1016/j.wocn.2015.12.005
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   van Heuven VJ, 2002, PHONOL PHONET, V4-1, P61
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wong P, 2013, J ACOUST SOC AM, V133, P434, DOI 10.1121/1.4768883
   Wong P, 2012, J SPEECH LANG HEAR R, V55, P1423, DOI 10.1044/1092-4388(2012/11-0273)
   Wong PS, 2012, J PHONETICS, V40, P141, DOI 10.1016/j.wocn.2011.10.005
   Yeung HH, 2014, CHILD DEV, V85, P1036, DOI 10.1111/cdev.12185
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE, P1
   Yuan JH, 2004, 2004 International Symposium on Chinese Spoken Language Processing, Proceedings, P45
   Yuan JH, 2006, LECT NOTES COMPUT SC, V4274, P19
   Zeng Xiao-Li, 2004, INT S TON ASP LANG E
NR 48
TC 9
Z9 9
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JAN 4
PY 2018
VL 8
AR 2190
DI 10.3389/fpsyg.2017.02190
PG 14
WC Psychology, Multidisciplinary
SC Psychology
GA FR9MY
UT WOS:000419399000002
PM 29354077
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Nayana, M
   Parmeshwara, KS
   Geetha, C
AF Nayana, M.
   Parmeshwara, Keerthi Sringari
   Geetha, Chinnaraj
TI Effect of number of talkers and language of babble on acceptable noise
   level in Kannada listeners
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Acceptable noise level; Kannada speech babble; English speech babble;
   normal hearing individuals
ID INFORMATIONAL MASKING; SENTENCE RECOGNITION; SPEECH-PERCEPTION;
   BACKGROUND-NOISE; HEARING; ENGLISH; SIGNAL
AB Objective: The objectives of the study were to evaluate the effect of number of talkers (2-talker, 4-talker, 8-talker, 10-talker and 12-talker) in native (Kannada) and non-native (English) speech babble on acceptable noise level (ANL) in individuals with normal hearing; and to compare ANL obtained in the presence of Kannada speech babble with that of English speech babble across different number of talker babbles.
   Study sample: Thirty participants between in the age range of 18-24 years with normal hearing sensitivity participated in the study. ANL was obtained in the presence of different number of talkers in English and Kannada languages.
   Results: The results revealed that Kannada talker babble had lower ANL for 8-talker babble whereas in English, 2-talker babble had the lowest ANL. The results also showed that ANL was lower when Kannada babble was used when compared to English babble. The reason for this result could be due to familiarity with the languages and the similarity between the two languages of interest.
C1 [Nayana, M.; Parmeshwara, Keerthi Sringari] All India Inst Speech & Hearing, Dept Audiol, Mysuru, India.
   [Geetha, Chinnaraj] All India Inst Speech & Hearing, Dept Audiol, Audiol, Mysuru, India.
RP Geetha, C (corresponding author), All India Inst Speech & Hearing, Dept Audiol, Audiol, Mysore 570006, Karnataka, India.
EM geethamysore.cs@gmail.com
CR American National Standards Institute, S311991 ANSI
   Brungart DS, 2009, J ACOUST SOC AM, V125, P4006, DOI 10.1121/1.3117686
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   CARHART R, 1975, J ACOUST SOC AM, V58, pS35, DOI 10.1121/1.2002082
   Cord Mary T, 2004, J Am Acad Audiol, V15, P353, DOI 10.3766/jaaa.15.5.3
   Crowley HJ, 1996, J SPEECH HEAR RES, V39, P19, DOI 10.1044/jshr.3901.19
   Durlach NI, 2003, J ACOUST SOC AM, V113, P2984, DOI 10.1121/1.1570435
   Fairbanks G., 1960, VOICE ARTICULATION D
   Freyaldenhoven M. C., 2006, J ED AUDIOLOGY, V13, P27
   Freyaldenhoven MC, 2006, J AM ACAD AUDIOL, V17, P640, DOI 10.3766/jaaa.17.9.3
   Freyman RL, 2004, J ACOUST SOC AM, V115, P2246, DOI 10.1121/1.1689343
   Geetha C, 2014, J HEAR SCI, V4, P18
   Ho HC, 2013, INT J AUDIOL, V52, P83, DOI 10.3109/14992027.2012.733422
   Hoen M, 2007, SPEECH COMMUN, V49, P905, DOI 10.1016/j.specom.2007.05.008
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   NABELEK AK, 1991, J SPEECH HEAR RES, V34, P679, DOI 10.1044/jshr.3403.679
   Nabelek AK, 2004, J SPEECH LANG HEAR R, V47, P1001, DOI 10.1044/1092-4388(2004/074)
   Nabelek AK, 2006, J AM ACAD AUDIOL, V17, P626, DOI 10.3766/jaaa.17.9.2
   Recker KL, 2014, J AM ACAD AUDIOL, V25, P605, DOI 10.3766/jaaa.25.6.10
   Savithri SR, 2005, 300 WORDS READING PA
   Shi LF, 2015, J SPEECH LANG HEAR R, V58, P497, DOI 10.1044/2015_JSLHR-H-14-0244
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   SURR RK, 1978, ARCH OTOLARYNGOL, V104, P732
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   Van Engen KJ, 2010, SPEECH COMMUN, V52, P943, DOI 10.1016/j.specom.2010.05.002
   von Hapsburg Deborah, 2004, J Am Acad Audiol, V15, P88, DOI 10.3766/jaaa.15.1.9
   von Hapsburg D, 2006, J AM ACAD AUDIOL, V17, P649, DOI 10.3766/jaaa.17.9.4
   Wylie E, 2006, INT 2 LANGUAGE PROFI
NR 28
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2018
VL 16
IS 4
BP 241
EP 247
DI 10.1080/21695717.2018.1542858
PG 7
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA IB1ZI
UT WOS:000470066400008
DA 2021-02-24
ER

PT J
AU Gabr, TA
   Serag, SA
AF Gabr, Takwa A.
   Serag, Shaymaa A.
TI Speech auditory evoked potentials in cochlear implant recipients in
   relation to rehabilitation outcomes
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Cochlear implants (CIs); cortical auditory evoked potentials (CAEPs);
   mismatch negativity (MMN); auditory brainstem response to complex Sound
   (cABR); language improvement quotient (LIQ)
ID LANGUAGE; CHILDREN; AGE; DISCRIMINATION; REPRESENTATION; STIMULATION;
   PLASTICITY
AB Background: Speech perception abilities showed great variability among different cochlear implants (CIs) recipients. Assessment of such perceptual abilities through behavioural speech perception tests is very limited, especially in young recipients. Hence, objective auditory evoked potentials (AEPs) can be very important in the assessment of such a young age group.
   Objectives: To study the ability to use different types of speech evoked AEPs clinically for the assessment of auditory pathway at different levels in children fitted with CIs.
   Methods: Two groups of children fitted with CIs participated in this study. They were divided into two groups according to their language improvement quotient (LIQ): Group I: included 20 children with LIQ >0.7 and Group II: included 20 children with LIQ <0.7. Children were evaluated through an auditory skills assessment, aided sound field, aided speech evoked AEPs.
   Results: Children of group I showed better aided-AEPs results in response to speech stimuli compared with group II with the significant positive effect of early age of implantation on the results.
   Conclusions: Objective aided-AEPs recording in response to complex sounds (such as speech) can be used efficiently for evaluation of speech perception at different levels along the auditory pathway in children fitted with CIs. In addition, they constitute a promising tool for following up and designing the appropriate rehabilitation programs.
C1 [Gabr, Takwa A.] Kafrelsheikh Univ, Fac Med, Kafrelsheikh, Egypt.
   [Serag, Shaymaa A.] Tanta Univ, Fac Med, Tanta, Egypt.
RP Gabr, TA (corresponding author), Kafrelsheikh Univ Hosp, Otolaryngol Head & Neck Surg Dept, Audiovestibular Med Unit, Elgeesh St, Kafrelsheikh 33516, Egypt.
EM takwagabr@gmail.com
RI Gabr, Takwa/C-6632-2016
OI Gabr, Takwa/0000-0003-2222-4147
CR Baltaxe C, 2001, HDB EARLY LANGUAGE I, P63
   CAZALS Y, 1990, ACTA OTO-LARYNGOL, P150, DOI 10.1080/00016489.1990.12088422
   Clark JH, 2012, J AM GERIATR SOC, V60, P1936, DOI 10.1111/j.1532-5415.2012.04150.x
   Eggermont JJ, 1997, ACTA OTO-LARYNGOL, V117, P161, DOI 10.3109/00016489709117760
   Gabr TA, 2015, INT J PEDIATR OTORHI, V79, P2028, DOI 10.1016/j.ijporl.2015.09.002
   GALEY FR, 1984, ACTA OTO-LARYNGOL, P38
   GANTZ BJ, 1988, LARYNGOSCOPE, V98, P1100
   Greenberg M., 1993, PROMOTING SOCIAL EMO
   Hart B., 1995, MEANINGFUL DIFFERENC
   Kotby MN, 1995, P 18 WORLD C INT ASS, P263
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   KRAUS N, 1993, HEARING RES, V65, P118, DOI 10.1016/0378-5955(93)90206-G
   Loizou PC, 2000, J ACOUST SOC AM, V108, P790, DOI 10.1121/1.429612
   Manrique M, 1999, INT J PEDIATR OTORHI, V49, pS193
   Melika L, 1998, STANFORD BINET INTEL
   Naatanen R, 2017, HEARING RES, V353, P57, DOI 10.1016/j.heares.2017.07.007
   Nathan L, 2004, J SPEECH LANG HEAR R, V47, P377, DOI 10.1044/1092-4388(2004/031)
   NEVILLE HJ, 1983, BRAIN RES, V266, P127, DOI 10.1016/0006-8993(83)91314-8
   Rahne T, 2010, THESCIENTIFICWORLDJO, V10, P329, DOI 10.1100/tsw.2010.28
   Rescorla L, 2002, J SPEECH LANG HEAR R, V45, P360, DOI 10.1044/1092-4388(2002/028)
   Rocha-Muniz CN, 2012, HEARING RES, V294, P143, DOI 10.1016/j.heares.2012.08.008
   Russo N, 2004, CLIN NEUROPHYSIOL, V115, P2021, DOI 10.1016/j.clinph.2004.04.003
   Shannon RV, SPRINGER HDB AUDITOR, V20
   Sharma Anu, 2015, Otorinolaringologia, V65, P103
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   TALLAL P, 1981, J ACOUST SOC AM, V69, P568, DOI 10.1121/1.385431
   Tomblin JB, 2005, J SPEECH LANG HEAR R, V48, P853, DOI 10.1044/1092-4388(2005/059)
   Toppelberg CO, 2000, J AM ACAD CHILD PSY, V39, P143, DOI 10.1097/00004583-200002000-00011
   Tremblay KL, 2002, NEUROREPORT, V13, P1865, DOI 10.1097/00001756-200210280-00007
   Walton JP, 2008, JARO-J ASSOC RES OTO, V9, P90, DOI 10.1007/s10162-007-0101-z
   Waltzman SB, 2005, PEDIATRICS, V116, pE487, DOI 10.1542/peds.2005-0282
   Wible B, 2004, BIOL PSYCHOL, V67, P299, DOI 10.1016/j.biopsycho.2004.02.002
   Zeng FG, 2002, J ACOUST SOC AM, V111, P377, DOI 10.1121/1.1423926
   Zeng FG, 1998, NEUROREPORT, V9, P1845, DOI 10.1097/00001756-199806010-00033
NR 35
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2018
VL 16
IS 4
BP 255
EP 262
DI 10.1080/21695717.2018.1507577
PG 8
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA IB1ZI
UT WOS:000470066400010
DA 2021-02-24
ER

PT J
AU Osawa, E
   Arai, T
   Hodoshima, N
AF Osawa, Eri
   Arai, Takayuki
   Hodoshima, Nao
TI Perception of Japanese consonant-vowel syllables in reverberation:
   Comparing non-native listeners with native listeners
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Speech perception; Reverberation; CV syllable; Japanese
ID OVERLAP-MASKING
AB Long reverberation degrades the intelligibility of speech sounds. Previous studies have reported that non-native listeners have difficulty in understanding speech in reverberation more than native listeners. In the results of the previous studies, there was the possibility that lower identification scores for non-native listeners were attributed to non-native phonemes which did not exist in their native languages. The current study investigated the identification of Japanese consonant-vowel ( CV) syllables in reverberation for native English listeners whose native language has counterparts to most or all Japanese consonants. The current study used 62 CV syllables as stimuli. The reverberation time of the reverberant condition was 2.7 s. The results showed that the correct answer rate for non-native listeners declined in the reverberant condition more than that for native listeners. There was significant difference between native and non-native listeners in the correct answer rate of /m, r, k, d, s/ in reverberation. The results suggested that non-native listeners had disadvantage in listening to non-native consonants even if their native languages had counterparts to the consonants. In addition, the results suggested that native English listeners might had advantage in finding acoustic cues of place of articulation in adverse environments because of the inventory of English.
C1 [Osawa, Eri; Arai, Takayuki] Sophia Univ, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
   [Hodoshima, Nao] Tokai Univ, Minato Ku, 2-3-23 Takanawa, Tokyo 1088619, Japan.
RP Osawa, E (corresponding author), Sophia Univ, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
EM eri1989.16.11@gmail.com; arai@sophia.ac.jp
OI Hodoshima, Nao/0000-0002-2147-9378
CR Arai T., 2016, P AUTUMN MEET ACOUST, P293
   Arai T, 2018, ACOUST SCI TECHNOL, V39, P252, DOI 10.1250/ast.39.252
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   BOLT RH, 1949, J ACOUST SOC AM, V21, P577, DOI 10.1121/1.1906551
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Hodoshima N, 2006, J ACOUST SOC AM, V119, P4055, DOI 10.1121/1.2198191
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   Ladefoged Peter, 1975, COURSE PHONETICS
   Masuda H, 2016, SPEECH COMMUN, V79, P74, DOI 10.1016/j.specom.2016.02.007
   NABELEK AK, 1989, J ACOUST SOC AM, V86, P1259
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   Osawa E., 2016, J ACOUST SOC AM, V140, P3333
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   Tsujimura Natsuko, 2014, INTRO JAPANESE LINGU
   Vance T. J., 2008, SOUND JAPANESE
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
   Yokoyama S., 1999, J I NOISE CONTROL EN, V23, P228
NR 19
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2018
VL 39
IS 6
BP 369
EP 378
DI 10.1250/ast.39.369
PG 10
WC Acoustics
SC Acoustics
GA HK2RD
UT WOS:000457759500001
OA Bronze
DA 2021-02-24
ER

PT J
AU Zhu, Z
   Miyauchih, R
   Araki, Y
   Unoki, M
AF Zhu, Zhi
   Miyauchih, Ryota
   Araki, Yukiko
   Unoki, Masashi
TI Contribution of modulation spectral features on the perception of
   vocal-emotion using noise-vocoded speech
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Temporal modulation cue; Modulation spectral feature; Vocal emotion;
   Noise-vocoded speech; Speech perception
ID AMPLITUDE-MODULATION; RECOGNITION; MODEL
AB Previous studies on noise-vocoded speech showed that the temporal modulation cues provided by the temporal envelope play an important role in the perception of vocal emotion. However, the exact role that the temporal envelope and its modulation components play in the perceptual processing of vocal emotion is still unknown. To clarify the exact features that the temporal envelope contributes to the perception of vocal emotion, a method based on the mechanism of modulation frequency analysis in the auditory system is necessary. In this study, auditory-based modulation spectral features were used to account for the perceptual data collected from vocal-emotion recognition experiments using noise-vocoded speech. An auditory-based modulation filterbank was used to calculate the modulation spectrogram of noise-vocoded speech stimuli, and ten types of modulation spectral features were then extracted from the modulation spectrograms. The results showed that there were high similarities between modulation spectral features and the perceptual data of vocal-emotion recognition experiments. It was shown that the modulation spectral features are useful for accounting for the perceptual processing of vocal emotion with noise-vocoded speech.
C1 [Zhu, Zhi; Miyauchih, Ryota; Unoki, Masashi] Japan Adv Inst Sci & Technol, 1-1 Asahidai, Nomi 9231292, Japan.
   [Araki, Yukiko] Kanazawa Univ, Kanazawa, Ishikawa 9201192, Japan.
RP Zhu, Z (corresponding author), Japan Adv Inst Sci & Technol, 1-1 Asahidai, Nomi 9231292, Japan.
EM zhuzhi@jaist.ac.jp; ryota@jaist.ac.jp; yukikoa@staff.kanazawa-u.ac.jp;
   unoki@jaist.ac.jp
FU MEXT, JapanMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT) [25240026, 16H01669, 18H05004]; Mitsubishi
   Research Foundation; JSPS KAKENHIMinistry of Education, Culture, Sports,
   Science and Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP. 17J08312]
FX This work was supported by a Grant in Aid for Scientific Research (A)
   (No. 25240026), Innovative Areas (No. 16H01669) and (No. 18H05004) from
   MEXT, Japan, and the Mitsubishi Research Foundation. This work was also
   supported by JSPS KAKENHI Grant Number JP. 17J08312.
CR Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Dau T, 1996, J ACOUST SOC AM, V99, P3623, DOI 10.1121/1.414960
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959
   Dau T, 1997, J ACOUST SOC AM, V102, P2892, DOI 10.1121/1.420344
   Ewert SD, 2000, J ACOUST SOC AM, V108, P1181, DOI 10.1121/1.1288665
   Huang CF, 2008, SPEECH COMMUN, V50, P810, DOI 10.1016/j.specom.2008.05.017
   Johnstone T., 2000, HDB EMOTION, P220, DOI DOI 10.1016/J.JML.2007.11.007
   Moore B. C. J., 2013, INTRO PSYCHOL HEARIN, P74
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Xiang J., 2013, J ACOUST SOC AM, V133, P7
   Zhu Z, 2018, ACOUST SCI TECHNOL, V39, P234, DOI 10.1250/ast.39.234
   Zhu Z, 2016, INTERSPEECH, P262, DOI 10.21437/Interspeech.2016-737
NR 14
TC 2
Z9 2
U1 1
U2 2
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2018
VL 39
IS 6
BP 379
EP 386
DI 10.1250/ast.39.379
PG 8
WC Acoustics
SC Acoustics
GA HK2RD
UT WOS:000457759500002
OA Bronze
DA 2021-02-24
ER

PT J
AU Martu, C
   Butnaru, C
   Anghelina, F
   Meriacre, T
   Cobzeanu, BM
   Martu, D
AF Martu, C.
   Butnaru, Corina
   Anghelina, F.
   Meriacre, Tatiana
   Cobzeanu, B. M.
   Martu, D.
TI EXPECTATION FROM COCHLEAR IMPLANTATION IN PATIENTS WITH LONG-TERM
   PRELINGUAL DEAFNESS
SO MEDICAL-SURGICAL JOURNAL-REVISTA MEDICO-CHIRURGICALA
LA English
DT Article
DE LATE COCHLEAR IMPLANTATION; PRELINGUAL DEAFNESS
ID SPEECH-PERCEPTION; RESIDUAL HEARING; CHILDREN; AGE; CLARION; NUCLEUS
AB Cochlear implantation is a well-established method of treating bilateral profound cochlear deafness. One should be aware that the medical literature is quite poor, in regard to the outcomes of the implantation of adolescents or adults with prelingual deafness. The aim of this study is to evaluate the audio-verbal outcome in late implanted adolescents and adults with congenital deafness. Material and methods: the study included 8 late implanted patients with bilateral profound deafness 4 of them were implanted as adolescents and the other 4 as adults; all of them were implanted at the Clinical Rehabilitation Hospital from Iasi. The patients' hearing abilities were tested using 2 scales: Speech Perception Rating Scale and Speech Intelligibility Rating Scale. Results: all of the patients have benefited from the implant when their hearing performances were compared to those before implantation. Conclusions: the topic remains open as long as the studies had only a limited number of subjects, but even so it can be affirmed that, with no doubt, all the subjects have had significant improvements after implantation.
C1 [Martu, C.; Butnaru, Corina; Martu, D.] Grigore T Popa Univ Med & Pharm Iasi, Fac Med, Dept Surg 2, Iasi, Romania.
   [Martu, C.; Butnaru, Corina; Meriacre, Tatiana; Cobzeanu, B. M.] Clin Rehabil Hosp, ENT Dept, Iasi, Romania.
   [Anghelina, F.] Univ Med & Pharm Craiova, ENT Dept, Craiova, Romania.
RP Butnaru, C (corresponding author), Grigore T Popa Univ Med & Pharm Iasi, Fac Med, Dept Surg 2, Iasi, Romania.; Butnaru, C (corresponding author), Clin Rehabil Hosp, ENT Dept, Iasi, Romania.
EM cmbutnaru@yahoo.com
RI Cobzeanu, Bogdan Mihail/AAX-2773-2020
CR Aschendorff A, 2009, HNO, V57, P533, DOI 10.1007/s00106-009-1936-x
   Bayazit YA, 2015, INT J PEDIATR OTORHI, V79, P146, DOI 10.1016/j.ijporl.2014.11.026
   Cavaleriu BD, 2015, ARCH BIOL SCI, V67, P1297, DOI 10.2298/ABS150909106C
   CLARK GM, 1987, AM J OTOL, V8, P234
   Eisenberg LS, 2004, ARCH OTOLARYNGOL, V130, P563, DOI 10.1001/archotol.130.5.563
   El-Hakim H, 2002, ANN OTO RHINOL LARYN, V111, P102, DOI 10.1177/00034894021110S521
   Geier L, 2000, COCHLEAR IMPLANTS, P336
   Georgescu MG, 2014, ROM J LEG MED, V22, P35, DOI 10.4323/rjlm.2014.35
   Harrison RV, 2005, DEV PSYCHOBIOL, V46, P252, DOI 10.1002/dev.20052
   Kang DH, 2016, CLIN EXP OTORHINOLAR, V9, P220, DOI 10.21053/ceo.2015.01487
   Kirk KI, 2002, ANN OTO RHINOL LARYN, V111, P69
   Knight K, 2016, S AFR J COMMUN DISOR, V63, DOI 10.4102/sajcd.v63i1.142
   Kos MI, 2009, INT J PEDIATR OTORHI, V73, P189, DOI 10.1016/j.ijporl.2008.10.009
   Krahulcova B, 2005, STUDY GUIDE ED STAFF, P475
   Markey Anne L, 2015, Cochlear Implants Int, V16, P186, DOI 10.1179/1754762813Y.0000000033
   Oh SH, 2003, ACTA OTO-LARYNGOL, V123, P148, DOI 10.1080/0036554021000028111
   Radulescu L, 2007, REV ROM BIOET, V5, P27
   Radulescu L, 2018, REV CHIM-BUCHAREST, V69, P2273
   Taitelbaum-Swead R, 2005, INT J PEDIATR OTORHI, V69, P1675, DOI 10.1016/j.ijporl.2005.05.002
   Teoh SW, 2004, LARYNGOSCOPE, V114, P1536
   Tyler RS, 2000, ADV OTO-RHINO-LARYNG, V57, P305
NR 21
TC 0
Z9 0
U1 0
U2 1
PU SOC MEDICI NATURALISTI IASI- SOC PHYSICIAN NATURALISTS
PI IASI
PA BD INDEPENDENTEI 16, PO BOX 25, IASI 6600, ROMANIA
SN 0048-7848
EI 2286-2560
J9 MED-SURG J
JI Med.-Surg. J.
PY 2018
VL 122
IS 4
BP 753
EP 758
PG 6
WC Medicine, General & Internal
SC General & Internal Medicine
GA HJ7XF
UT WOS:000457410000016
DA 2021-02-24
ER

PT J
AU Bhaduri, S
   Ghosh, D
AF Bhaduri, Susmita
   Ghosh, Dipak
TI Speech and Music - Nonlinear Acoustical Decoding in Neurocognitive
   Scenario
SO ARCHIVES OF ACOUSTICS
LA English
DT Article
DE speech signal; multifractality; Visibility Graph; Fractal Darwinism;
   neurocognitive disorders
ID TIME-SERIES; DISCRIMINATION; COMPLEXITY; SPECTRUM; MODELS; LONG
AB Speech and music signals are multifractal phenomena. The time displacement profile of speech and music signal show strikingly different scaling behaviour. However, a full complexity analysis of their frequency and amplitude has not been made so far. We propose a novel complex network based approach (Visibility Graph) to study the scaling behaviour of frequency wise amplitude variation of speech and music signals over time and then extract their PSVG (Power of Scale freeness of Visibility Graph). From this analysis it emerges that the scaling behaviour of amplitude-profile of music varies a lot from frequency to frequency whereas it's almost consistent for the speech signal. Our left auditory cortical areas are proposed to be neurocognitively specialised in speech perception and right ones in music. Hence we can conclude that human brain might have adapted to the distinctly different scaling behaviour of speech and music signals and developed different decoding mechanisms, as if following the so called Fractal Darwinism. Using this method, we can capture all non-stationary aspects of the acoustic properties of the source signal to the deepest level, which has huge neurocognitive significance. Further, we propose a novel non-invasive application to detect neurological illness (here autism spectrum disorder, ASD), using the quantitative parameters deduced from the variation of scaling behaviour for speech and music.
C1 [Bhaduri, Susmita; Ghosh, Dipak] Deepa Ghosh Res Fdn, Kolkata 700031, W Bengal, India.
RP Bhaduri, S (corresponding author), Deepa Ghosh Res Fdn, Kolkata 700031, W Bengal, India.
EM susmita.sbhaduri@dgfoundation.in; deegee111@gmail.com
OI Bhaduri, Susmita/0000-0003-1246-9124
CR Ahmadlou M, 2012, PHYSICA A, V391, P4720, DOI 10.1016/j.physa.2012.04.025
   Babloyantz A., 1985, PHYS LETT A, V111, P3, DOI DOI 10.1016/0375-9601(85)90444-X
   Bhaduri A, 2017, PHYSICA A, V482, P786, DOI 10.1016/j.physa.2017.04.091
   Bhaduri A, 2016, FRONT PHYSIOL, V7, DOI 10.3389/fphys.2016.00044
   BHADURI S, 2016, J NEUROLOGY NEUROSCI, V7, P100, DOI [10.21767/2171-6625.1000100, DOI 10.21767/2171-6625.1000100]
   Bhaduri S., 2016, J NEUROLOGY NEUROSCI, V7, P1, DOI DOI 10.21767/2171-6625.100084
   Bhaduri S, 2016, CURR SCI INDIA, V110, P1817, DOI 10.18520/cs/v110/i9/1817-1822
   Bhaduri S, 2015, CLIN EEG NEUROSCI, V46, P218, DOI 10.1177/1550059414526186
   BINNIG G, 2002, EUROPHYS NEWS, V33, P44, DOI DOI 10.1051/EPN:2002202
   Bullmore ET, 2011, ANNU REV CLIN PSYCHO, V7, P113, DOI 10.1146/annurev-clinpsy-040510-143934
   Chen Z, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.041107
   COHEN MA, 1995, J ACOUST SOC AM, V98, P862, DOI 10.1121/1.413512
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   Fulop SA, 2006, J ACOUST SOC AM, V119, P360, DOI 10.1121/1.2133000
   Gallagher R, 1999, SCIENCE, V284, P79, DOI 10.1126/science.284.5411.79
   Ganguli M, 2011, AM J GERIAT PSYCHIAT, V19, P205, DOI 10.1097/JGP.0b013e3182051ab4
   Gonzalez Diana Cristina, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P740, DOI 10.1007/978-3-642-33275-3_91
   Harb H, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P125, DOI 10.1109/ISSPA.2003.1224831
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Higgins JP, 2002, YALE J BIOL MED, V75, P247
   HORGAN J, 1995, SCI AM, V272, P104, DOI 10.1038/scientificamerican0695-104
   HSU KJ, 1990, P NATL ACAD SCI USA, V87, P938, DOI 10.1073/pnas.87.3.938
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huang YX, 2011, PHYS REV E, V84, DOI 10.1103/PhysRevE.84.016208
   Jafari GR, 2007, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2007/04/P04012
   Jiang S, 2013, APPL PHYS LETT, V102, DOI 10.1063/1.4812645
   Joos Martin, 1948, LANGUAGE, V24, P5, DOI DOI 10.2307/522229
   Kantelhardt JW, 2001, PHYSICA A, V295, P441, DOI 10.1016/S0378-4371(01)00144-3
   Kantelhardt JW, 2002, PHYSICA A, V316, P87, DOI 10.1016/S0378-4371(02)01383-3
   Kinsner W, 2008, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P351, DOI 10.1109/COGINF.2008.4639188
   Lacasa L, 2009, EPL-EUROPHYS LETT, V86, DOI 10.1209/0295-5075/86/30001
   Lacasa L, 2008, P NATL ACAD SCI USA, V105, P4972, DOI 10.1073/pnas.0709247105
   Langi AZR, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P527, DOI 10.1109/ICICS.1997.647154
   Levelt WJM, 1999, TRENDS COGN SCI, V3, P223, DOI 10.1016/S1364-6613(99)01319-4
   MANDELBROT B, 1967, SCIENCE, V156, P636, DOI 10.1126/science.156.3775.636
   Mandelbrot B. B., 1983, AM J PHYS, V51, P286, DOI [10.1119/1.13295, DOI 10.1119/1.13295]
   MARAGOS P, 1999, J ACOUST SOC AM, V105, P223
   MCKAY C., 2004, P INT C MUS INF RETR, P525
   Mikulecky DC, 2001, COMPUT CHEM, V25, P341, DOI 10.1016/S0097-8485(01)00070-5
   Nilanjana P, 2016, TRANSLATIONAL BIOMED, V7, P1, DOI [10.21767/2172-0479.100079, DOI 10.21767/2172-0479.100079]
   OSWIECIMKA P, 2011, ARXIV11062902
   Oswiecimka P, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016103
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Poincare H., 1890, ACTA MATH, V13, pA3, DOI DOI 10.1007/BF02392506
   Proctor RW, 2008, HUMAN FACTORS SIMPLE
   Rosen S., 2010, SIGNALS SYSTEMS SPEE
   SAMSON S, 1994, NEUROPSYCHOLOGIA, V32, P231, DOI 10.1016/0028-3932(94)90008-6
   Serrano E, 2009, PHYSICA A, V388, P2793, DOI 10.1016/j.physa.2009.03.043
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sporns O, 2005, PLOS COMPUT BIOL, V1, P245, DOI 10.1371/journal.pcbi.0010042
   Su ZY, 2006, PHYSICA D, V221, P188, DOI 10.1016/j.physd.2006.08.001
   TRICOT C, 1988, J CHIM PHYS PCB, V85, P379, DOI 10.1051/jcp/1988850379
   Trost W, 2012, CEREB CORTEX, V22, P2769, DOI 10.1093/cercor/bhr353
   Vaggione H, 2001, COMPUT MUSIC J, V25, P54, DOI 10.1162/014892601300126115
   Van der Merwe P., 1989, ORIGINS POPULAR STYL
   Varnet L, 2015, SCI REP-UK, V5, DOI 10.1038/srep14489
   VOSS RF, 1975, NATURE, V258, P317, DOI 10.1038/258317a0
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Wolfe J., 2002, P 7 INT C MUS PERC C, P10
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 63
TC 1
Z9 1
U1 0
U2 0
PU POLSKA AKAD NAUK, POLISH ACAD SCIENCES, INST FUNDAMENTAL TECH RES PAS
PI WARSZAWA
PA PL DEFILAD 1, WARSZAWA, 00-901, POLAND
SN 0137-5075
EI 2300-262X
J9 ARCH ACOUST
JI Arch. Acoust.
PY 2018
VL 43
IS 4
BP 593
EP 602
DI 10.24425/aoa.2018.125153
PG 10
WC Acoustics
SC Acoustics
GA HD9MK
UT WOS:000452886600002
DA 2021-02-24
ER

PT J
AU Kim, BJ
   Han, JJ
   Shin, SH
   Kim, HS
   Yang, HR
   Choi, EH
   Chang, MY
   Lee, SY
   Suh, MW
   Koo, JW
   Lee, JH
   Choi, BY
   Oh, SH
AF Kim, Bong Jik
   Han, Jae Joon
   Shin, Seung Han
   Kim, Han-Suk
   Yang, Hye Ran
   Choi, Eun Hwa
   Chang, Mun Young
   Lee, Sang-Yeon
   Suh, Myung-Whan
   Koo, Ja-Won
   Lee, Jun Ho
   Choi, Byung Yoon
   Oh, Seung-Ha
TI Characterization of Detailed Audiological Features of Cytomegalovirus
   Infection: A Composite Cohort Study from Groups with Distinct
   Demographics
SO BIOMED RESEARCH INTERNATIONAL
LA English
DT Article
ID BRAIN-STEM RESPONSES; LONG-TERM OUTCOMES; CONGENITAL CYTOMEGALOVIRUS;
   CMV INFECTION; COCHLEAR IMPLANTATION; AUDITORY NEUROPATHY; HEARING-LOSS;
   CHILDREN; HYPERBILIRUBINEMIA; PREGNANCY
AB Congenital cytomegalovirus (cCMV) infection is a common congenital infection that causes sensorineural hearing loss (SNHL). Despite its substantial impact on public health and cost burden, epidemiology and clinical features of CMV-related SNHL have never been reported in the Korean populations. This study investigated the detailed audiologic phenotypes of cCMV infection to see if a specific SNHL pattern is associated with a particular clinical setting. A total of 38 patients with cCMV infection were studied retrospectively. Patients were classified into three groups with distinct demographics: clinically driven diagnosis (n=17), routine newborn CMV screening according to the NICU protocols (n=10), or referral to ENT for cochlear implant (CI) (n=11). The incidence of cCMV infection was 3.6%, showing 33.3% of SNHL among cCMV patients, 38% of asymmetric hearing loss, 29% of late-onset hearing loss, and diverse severity spectrum in patients with CMV-related SNHL. CI recipients with CMV-related SNHL showed a significantly improved speech perception. Surprisingly, in 36.4 % of CI implantees, initial audiological manifestation was significant asymmetry of hearing thresholds between both ears, with better ear retaining significant residual hearing up to 50dB. CMV turns out to be a significant etiology of SNHL, first to date reported in the Korean pediatric population. Analysis of audiologic phenotypes showed a very wide spectrum of SNHL and favorable CI outcomes in case of profound deafness. Especially for the patients with asymmetric hearing loss, close surveillance of hearing should be warranted and CI could be considered on the worse side first, based on the observation of rapid progression to profound deafness of better side.
C1 [Kim, Bong Jik] Chungnam Natl Univ, Coll Med, Dept Otolaryngol Head & Neck Surg, Daejeon 35015, South Korea.
   [Han, Jae Joon; Koo, Ja-Won; Choi, Byung Yoon] Seoul Natl Univ, Bundang Hosp, Coll Med, Dept Otolaryngol, Seongnam 13620, South Korea.
   [Shin, Seung Han; Kim, Han-Suk; Choi, Eun Hwa] Seoul Natl Univ, Seoul Natl Univ Hosp, Coll Med, Dept Pediat, Seoul 03080, South Korea.
   [Yang, Hye Ran] Seoul Natl Univ, Bundang Hosp, Coll Med, Dept Pediat, Seongnam 13620, South Korea.
   [Chang, Mun Young] Chung Ang Univ, Coll Med, Dept Otolaryngol, Seoul 06973, South Korea.
   [Lee, Sang-Yeon; Suh, Myung-Whan; Lee, Jun Ho; Oh, Seung-Ha] Seoul Natl Univ, Seoul Natl Univ Hosp, Coll Med, Dept Otolaryngol, Seoul 03080, South Korea.
RP Choi, BY (corresponding author), Seoul Natl Univ, Bundang Hosp, Coll Med, Dept Otolaryngol, Seongnam 13620, South Korea.; Oh, SH (corresponding author), Seoul Natl Univ, Seoul Natl Univ Hosp, Coll Med, Dept Otolaryngol, Seoul 03080, South Korea.
EM choiby2010@gmail.com; shaoh@snu.ac.kr
RI Suh, Myung-Whan/AAZ-9615-2020
OI Kim, Bong Jik/0000-0002-6384-2171; Suh, Myung-Whan/0000-0003-1301-2249
FU Korean Health Technology R&D project, Ministry for Health, Welfare,
   Republic of Korea [HI12C0014]; Seoul National University Bundang
   Hospital (SNUBH) [13-2017-013]; Basic Science Research Program through
   the National Research Foundation of Korea (NRF) - Ministry of Education
   [2018R1D1A1B07046159]; Brain Research Program through the National
   Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future
   Planning [2015M3C7A1028376]
FX This work was supported by the Korean Health Technology R&D project,
   Ministry for Health, Welfare, Republic of Korea (no. HI12C0014) to B. Y.
   Choi, Seoul National University Bundang Hospital (SNUBH) (Grant
   13-2017-013 to Byung Yoon Choi), Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2018R1D1A1B07046159), and the Brain Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Science, ICT & Future Planning (2015M3C7A1028376).
CR Akman I, 2004, INT J AUDIOL, V43, P516, DOI 10.1080/14992020400050066
   Barkai G, 2014, J CLIN VIROL, V60, P361, DOI 10.1016/j.jcv.2014.04.024
   Dahle A J, 2000, J Am Acad Audiol, V11, P283
   Fowler KB, 2006, J CLIN VIROL, V35, P226, DOI 10.1016/j.jcv.2005.09.016
   Fowler KB, 1999, J PEDIATR-US, V135, P60, DOI 10.1016/S0022-3476(99)70328-8
   FUNATO M, 1994, PEDIATRICS, V93, P50
   Goderis J, 2016, J PEDIATR-US, V172, P110, DOI 10.1016/j.jpeds.2016.01.024
   Goderis J, 2014, PEDIATRICS, V134, P972, DOI 10.1542/peds.2014-1173
   Hoey Andrew Wesley, 2017, Cochlear Implants Int, V18, P216, DOI 10.1080/14670100.2017.1315510
   Kenneson A, 2007, REV MED VIROL, V17, P253, DOI 10.1002/rmv.535
   Kimberlin DW, 2015, NEW ENGL J MED, V372, P933, DOI 10.1056/NEJMoa1404599
   Lanzieri TM, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-2610
   Manicklal S, 2013, CLIN MICROBIOL REV, V26, P86, DOI 10.1128/CMR.00062-12
   MEDEARIS DN, 1964, AM J OBSTET GYNECOL, V90, P1140, DOI 10.1016/0002-9378(64)90837-3
   NAKAMURA H, 1985, PEDIATRICS, V75, P703
   Saluja S, 2010, INT J PEDIATR OTORHI, V74, P1292, DOI 10.1016/j.ijporl.2010.08.007
   Seo S, 2009, KOREAN J LAB MED, V29, P557, DOI 10.3343/kjlm.2009.29.6.557
   SOHN Y M, 1992, Journal of Korean Medical Science, V7, P47
   STAGNO S, 1986, JAMA-J AM MED ASSOC, V256, P1904, DOI 10.1001/jama.256.14.1904
   Suh MW, 2009, CLIN EXP OTORHINOLAR, V2, P120, DOI 10.3342/ceo.2009.2.3.120
   Yoshida H, 2017, OTOL NEUROTOL, V38, pE190, DOI 10.1097/MAO.0000000000001483
NR 21
TC 4
Z9 4
U1 0
U2 1
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2314-6133
EI 2314-6141
J9 BIOMED RES INT
JI Biomed Res. Int.
PY 2018
VL 2018
AR 7087586
DI 10.1155/2018/7087586
PG 8
WC Biotechnology & Applied Microbiology; Medicine, Research & Experimental
SC Biotechnology & Applied Microbiology; Research & Experimental Medicine
GA GT0MI
UT WOS:000444135700001
PM 30228987
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cristia, A
AF Cristia, Alejandrina
TI Can infants learn phonology in the lab? A meta-analytic answer
SO COGNITION
LA English
DT Article
DE Infant language learning; Artificial grammars; Experimental psychology;
   Replication
ID SPEECH-PERCEPTION; PHONOTACTIC PATTERNS; SOUND PATTERNS; INFORMATION;
   SENSITIVITY; ACQUISITION; ISSUES
AB Two of the key tasks facing the language-learning infant lie at the level of phonology: establishing which sounds are contrastive in the native inventory, and determining what their possible syllabic positions and permissible combinations (phonotactics) are. In 2002-2003, two theoretical proposals, one bearing on how infants can learn sounds (Maye, Werker, & Gerken, 2002) and the other on phonotactics (Chambers, Onishi, & Fisher, 2003), were put forward on the pages of Cognition, each supported by two laboratory experiments, wherein a group of infants was briefly exposed to a set of pseudo-words, and plausible phonological generalizations were tested subsequently. These two papers have received considerable attention from the general scientific community, and inspired a flurry of follow-up work. In the context of questions regarding the replicability of psychological science, the present work uses a meta-analytic approach to appraise extant empirical evidence for infant phonological learning in the laboratory. It is found that neither seminal finding (on learning sounds and learning phonotactics) holds up when close methodological replications are integrated, although less close methodological replications do provide some evidence in favor of the sound learning strand of work. Implications for authors and readers of this literature are drawn out. It would be desirable that additional mechanisms for phonological learning be explored, and that future infant laboratory work employ paradigms that rely on constrained and unambiguous links between experimental exposure and measured infant behavior.
C1 [Cristia, Alejandrina] PSL Res Univ, CNRS, EHESS, Dept Etud Cognit,LSCP,ENS, Paris, France.
RP Cristia, A (corresponding author), PSL Res Univ, CNRS, EHESS, Dept Etud Cognit,LSCP,ENS, Paris, France.
RI Cristia, Alejandrina/H-2768-2019
OI Cristia, Alejandrina/0000-0003-2979-4556
FU [ANR-14-CE30-0003 MechELex];  [ANR-10-IDEX-0001-02 PSL*]; 
   [ANR-10-LABX-0087 IEC]
FX This work was made possible by the support of ANR-14-CE30-0003 MechELex,
   ANR-10-IDEX-0001-02 PSL*, and ANR-10-LABX-0087 IEC, which had no role in
   the intellectual work involved. I am indebted to Sophie ter Schure for
   doing the systematic searches in conference programs for the
   distributional learning literature, as well as to Sharon Peperkamp,
   Elliott Moreton, and three anonymous reviewers for detailed feedback on
   a previous version of this manuscript. This work has benefited greatly
   from discussions with my colleagues at the LSCP (particularly Christina
   Bergmann, Sho Tsuji, and Emmanuel Dupoux) and beyond (Janet Werker,
   members of the Dutch Baby Circle, the French GDR ADYLOC, and
   particularly the other members of the MetaLab project). Finally, I am
   extremely grateful to the authors of the body of literature on which the
   present work builds, and particularly to Kyle Chambers, Robert Daland,
   Naomi Feldman, LouAnn Gerken, Rend Kager, Liquan Liu, Fernan Pons,
   Amanda Seidl, Karin Waanrooij, Yuanyuan Wang, and Kathleen Yoshida, for
   sharing information and/or raw data with me. All errors, claims, and
   opinions remain my own responsibility.
CR Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716
   Aslin RN, 2007, DEVELOPMENTAL SCI, V10, P48, DOI 10.1111/j.1467-7687.2007.00563.x
   Bergmann C, 2016, DEVELOPMENTAL SCI, V19, P901, DOI 10.1111/desc.12341
   Bion RAH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0051594
   Capel D. J. H., 2011, SOUND SOUNDS STUDIES, P33
   Chambers CD, 2015, ADDICTION, V110, P10, DOI 10.1111/add.12728
   Chambers K. E., 2004, THESIS
   Chambers KE, 2003, COGNITION, V87, pB69, DOI 10.1016/S0010-0277(02)00233-0
   Chambers KE, 2011, LANG LEARN DEV, V7, P287, DOI 10.1080/15475441.2011.580447
   Champely S., 2009, PWR BASIC FUNCTIONS
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cristia A., 2011, INFANTS LEARNI UNPUB
   Cristia A., 2015, INFANTS ABILIT UNPUB
   Cristia A., 2011, PHONOLOGICAL CONTRAS, P303
   Cristia A., 2006, THESIS
   Cristia A., 2011, U PENNSYLVANIA WORKI, V17
   Cristia A, 2016, INFANCY, V21, P648, DOI 10.1111/infa.12127
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Cristia A, 2012, PROC ANN BUCLD, P126
   Cristia A, 2011, J PHONETICS, V39, P388, DOI 10.1016/j.wocn.2011.02.004
   Cristia A, 2008, LANG LEARN DEV, V4, P203, DOI 10.1080/15475440802143109
   Daland R, 2009, THESIS
   Feldman NH, 2013, COGNITION, V127, P427, DOI 10.1016/j.cognition.2013.02.007
   Fennell C. T., 2012, 18 BIENN INT C INF S
   Frank M. C., 2017, INFANCY
   Gerken L, 2015, COGNITION, V143, P187, DOI 10.1016/j.cognition.2015.04.018
   Gerken L, 2015, DEVELOPMENTAL SCI, V18, P80, DOI 10.1111/desc.12183
   Gonzalez-Gomez N, 2012, DEVELOPMENTAL SCI, V15, P885, DOI 10.1111/j.1467-7687.2012.01186.x
   Head ML, 2015, PLOS BIOL, V13, DOI DOI 10.1371/JOURNAL.PBIO.1002106
   Hedges L, 1981, J EDUC STAT, V6, P107, DOI [10.3102/10769986006002107, DOI 10.3102/10769986006002107]
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Kraft P, 2009, STAT SCI, V24, P561, DOI 10.1214/09-STS290
   Lewis M., 2015, BOST C LANG DEV BOST
   Liu L., 2011, ICPHS, V17, P1270
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   MANDEL DR, 1995, PSYCHOL SCI, V6, P314, DOI 10.1111/j.1467-9280.1995.tb00517.x
   Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1371/journal.pmed.1000097, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535]
   Moreton E, 2012, LANG LINGUIST COMPAS, V6, P686, DOI 10.1002/lnc3.363
   Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374
   Nosek BA, 2012, PERSPECT PSYCHOL SCI, V7, P615, DOI 10.1177/1745691612459058
   Nosek BA, 2012, PSYCHOL INQ, V23, P217, DOI 10.1080/1047840X.2012.692215
   Obrig H, 2017, DEV COGN NEUROS-NETH, V25, P185, DOI 10.1016/j.dcn.2016.09.001
   Onishi KH, 2002, COGNITION, V83, pB13, DOI 10.1016/S0010-0277(01)00165-2
   Peterson D., 2016, SOCIUS, V2, DOI [DOI 10.1177/2378023115625071, 10.1177/2378023115625071]
   Pons F., 2006, INT C INF STUD KYOT
   Pons F., 2008, 28 ANN C COGN SCI SO
   Quam C., 2016, DEVELOPMENTAL SCI, V20
   R Core Team, 2015, R LANG ENV STAT COMP
   Seidl A, 2009, LANG LEARN DEV, V5, P191, DOI 10.1080/15475440902754326
   Seidl A, 2005, LANG LEARN DEV, V1, P289, DOI 10.1207/s15473341lld0103&4_4
   Seidl A, 2014, LANG LEARN DEV, V10, P297, DOI 10.1080/15475441.2013.858575
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Simonsohn U, 2014, J EXP PSYCHOL GEN, V143, P534, DOI 10.1037/a0033242
   Smith GD, 1998, BMJ-BRIT MED J, V316, P221
   STERLING TD, 1995, AM STAT, V49, P108, DOI 10.2307/2684823
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   ter Schure SMM, 2016, INFANT BEHAV DEV, V43, P44, DOI 10.1016/j.infbeh.2016.01.002
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Versteegh M., 2015, P INT
   Viechtbauer W, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i03
   Wagenmakers EJ, 2012, PERSPECT PSYCHOL SCI, V7, P632, DOI 10.1177/1745691612463078
   Wanrooij K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00077
   Weitzman RS, 2007, ANAL VERBAL BEHAV, V23, P17, DOI 10.1007/BF03393043
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   White J, 2014, COGNITION, V130, P96, DOI 10.1016/j.cognition.2013.09.008
   White KS, 2008, COGNITION, V107, P238, DOI 10.1016/j.cognition.2007.11.012
   Wilson D.B., 2001, PRACTICAL METAANALYS
   Xie Y, 2014, IMPLEMENT REPROD, V1, P20
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
   YOUNGER BA, 1983, CHILD DEV, V54, P858, DOI 10.1111/j.1467-8624.1983.tb00507.x
   Zhao XY, 2015, J NANOMATER, V2015, DOI 10.1155/2015/104193
NR 80
TC 5
Z9 5
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD JAN
PY 2018
VL 170
BP 312
EP 327
DI 10.1016/j.cognition.2017.09.016
PG 16
WC Psychology, Experimental
SC Psychology
GA FR3PW
UT WOS:000418979600027
PM 29102857
DA 2021-02-24
ER

PT S
AU Rohde, H
   Kurumada, C
AF Rohde, Hannah
   Kurumada, Chigusa
BE Federmeier, KD
   Watson, DG
TI Alternatives and Inferences in the Communication of Meaning
SO CURRENT TOPICS IN LANGUAGE
SE Psychology of Learning and Motivation
LA English
DT Article; Book Chapter
ID TURN-TAKING; PITCH ACCENTS; CHILDRENS INTERPRETATION; AMBIGUITY
   RESOLUTION; PRAGMATIC DIRECTIONS; REFERENTIAL CONTEXT; SCALAR
   IMPLICATURES; PRONOUN RESOLUTION; SPEECH-PERCEPTION; SPOKEN LANGUAGE
AB Communicating meaning is a primary goal of everyday language use. One significant puzzle in the study of linguistic comprehension is that the meaning communicated via language often goes beyond an aggregate of word meaning; comprehenders systematically derive pragmaticdas opposed to lexical or semanticdinterpretations by leveraging their extralinguistic contextual knowledge. Key to this process is the insight that comprehenders compare what was said against what could have been saiddthe range of alternative messages and alternative utterancesdto enrich their inferences about the speaker's intention behind a given choice of the linguistic signal. In this article, we offer a conceptual framework for investigating the roles of alternatives and how they are used in comprehension. The case studies we present span multiple levels, with the common thread that their surface forms fail to uniquely disambiguate the underlying meaning: turn-taking, disfluencies, intonational phonology, and pronoun resolution. We discuss Bayesian statistical inference as a possible computational- level approach to rationally combining assumptions about alternative forms and alternative meanings for pragmatic comprehension.
C1 [Rohde, Hannah] Univ Edinburgh, Linguist & English Language, Edinburgh, Midlothian, Scotland.
   [Kurumada, Chigusa] Univ Rochester, Dept Brain & Cognit Sci, Rochester, NY USA.
RP Rohde, H (corresponding author), Univ Edinburgh, Linguist & English Language, Edinburgh, Midlothian, Scotland.
EM hannah.rohde@ed.ac.uk
OI Kurumada, Chigusa/0000-0001-8624-4214
CR ACKERMAN BP, 1981, J EXP CHILD PSYCHOL, V31, P487, DOI 10.1016/0022-0965(81)90032-1
   ACKERMAN BP, 1990, DEV PSYCHOL, V26, P234, DOI 10.1037/0012-1649.26.2.234
   Akhtar N, 1996, BRIT J DEV PSYCHOL, V14, P79, DOI 10.1111/j.2044-835X.1996.tb00695.x
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Anderson J., 1990, ADAPTIVE CHARACTER T
   Ariel M., 1990, ACCESSING NOUN PHRAS
   Arnold JE, 2004, PSYCHOL SCI, V15, P578, DOI 10.1111/j.0956-7976.2004.00723.x
   Arnold JE, 2001, DISCOURSE PROCESS, V31, P137, DOI 10.1207/S15326950DP3102_02
   Arnold JE, 2008, COGNITION, V108, P69, DOI 10.1016/j.cognition.2008.01.001
   Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914
   Arvaniti A, 2007, PAPERS LAB PHONOLOGY, V9, P547
   AU TKF, 1986, J MEM LANG, V25, P104, DOI 10.1016/0749-596X(86)90024-0
   Barner D, 2011, COGNITION, V118, P84, DOI 10.1016/j.cognition.2010.10.010
   Barr D. J., 2001, ORALITE GESTUALITE I, P597
   Barr DJ, 2010, LANG COGNITIVE PROC, V25, P441, DOI 10.1080/01690960903047122
   Beckman M. E., 1986, INTONATION STRUCTURE
   Bergen L, 2012, J EXP PSYCHOL LEARN, V38, P1450, DOI 10.1037/a0027850
   Blunsom P., 2009, P JOINT C 47 ANN M A, V2, P782
   Bock J. K., 1994, HDB PSYCHOLINGUISTIC, P945
   BOCK K, 1987, J MEM LANG, V26, P119, DOI 10.1016/0749-596X(87)90120-3
   Bogels S., 2015, PLOS ONE, P1
   Bortfeld H., 2001, LANG SPEECH, V32, P229
   Bosker HR, 2014, J MEM LANG, V75, P104, DOI 10.1016/j.jml.2014.05.004
   BRAINE MDS, 1981, J EXP CHILD PSYCHOL, V31, P46, DOI 10.1016/0022-0965(81)90003-5
   Breen M, 2012, CORPUS LINGUIST LING, V8, P277, DOI 10.1515/cllt-2012-0011
   Breheny R, 2013, LANG COGNITIVE PROC, V28, P443, DOI 10.1080/01690965.2011.649040
   BRENNAN SE, 1995, J MEM LANG, V34, P383, DOI 10.1006/jmla.1995.1017
   Brennan SE, 2001, J MEM LANG, V44, P274, DOI 10.1006/jmla.2000.2753
   BROWN R, 1983, COGNITION, V14, P237, DOI 10.1016/0010-0277(83)90006-9
   Brown-Schmidt S, 2008, COGNITIVE SCI, V32, P643, DOI 10.1080/03640210802066816
   Buxo-Lugo A, 2018, DISCOURSE PROCESS, V55, P305, DOI 10.1080/0163853X.2016.1240742
   Calhoun S., 2004, P SPEECH PROSODY, V2004, P103
   Calhoun S., 2006, THESIS U EDINBURGH
   CARAMAZZA A, 1977, J VERB LEARN VERB BE, V16, P601, DOI 10.1016/S0022-5371(77)80022-4
   Casillas M., 2013, THESIS STANFORD U
   Casillas M, 2016, J CHILD LANG, V43, P1310, DOI 10.1017/S0305000915000689
   CHAFE WL, 1974, LANGUAGE, V50, P111, DOI 10.2307/412014
   Chambers CG, 2004, J EXP PSYCHOL LEARN, V30, P687, DOI 10.1037/0278-7393.30.3.687
   Chambers CG, 2002, J MEM LANG, V47, P30, DOI 10.1006/jmla.2001.2832
   Chierchia G., 2006, P 25 ANN BOST U C LA, P157
   CLARK E, 1999, STUDIES LINGUISTIC S, V0029
   CLARK E. V., 2009, 1 LANGUAGE ACQUISITI
   Clark EV, 1998, J CHILD LANG, V25, P1, DOI 10.1017/S0305000997003309
   Clark EV, 2002, LANG SOC, V31, P181, DOI 10.1017/S0047404501020152
   CLARK EV, 1990, J CHILD LANG, V17, P417, DOI 10.1017/S0305000900013842
   Clark EV, 2015, HDB LANGUAGE EMERGEN, P328, DOI DOI 10.1002/9781118346136.CH15
   Clark Eve V., 1987, MECH LANGUAGE ACQUIS, V1, P33
   Clark H.H., 1996, USING LANGUAGE
   CLARK HH, 1994, SPEECH COMMUN, V15, P243, DOI 10.1016/0167-6393(94)90075-2
   Clark HH, 2002, COGNITION, V84, P73, DOI 10.1016/S0010-0277(02)00017-3
   Clark HH, 1998, COGNITIVE PSYCHOL, V37, P201, DOI 10.1006/cogp.1998.0693
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cohen Shay B., 2016, BAYESIAN ANAL NATURA
   Cole J., 2010, LAB PHONOLOGY, V1
   Cole J, 2015, LANG COGN NEUROSCI, V30, P1, DOI 10.1080/23273798.2014.963130
   Corley M, 2007, COGNITION, V105, P658, DOI 10.1016/j.cognition.2006.10.010
   CRAWLEY RA, 1990, J PSYCHOLINGUIST RES, V19, P245, DOI 10.1007/BF01077259
   CRUTTENDEN A, 1985, J CHILD LANG, V12, P643, DOI 10.1017/S030500090000670X
   Cruttenden A., 1997, INTONATION
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   CUTLER A, 1987, J CHILD LANG, V14, P145, DOI 10.1017/S0305000900012782
   Cutler A., 2015, NATIVE LISTENING LAN
   Dahan D, 2015, WIRES COGN SCI, V6, P441, DOI 10.1002/wcs.1355
   De Ruiter JP, 2006, LANGUAGE, V82, P515, DOI 10.1353/lan.2006.0130
   DE RUITER J. P., 2012, P 16 WORKSH SEM PRAG, P149
   Degen J., 2013, THESIS U ROCHESTER
   Degen J, 2016, COGNITIVE SCI, V40, P172, DOI 10.1111/cogs.12227
   Dilley L., 2006, P INT C SPOK LANG PR
   Dilley LC, 2005, J PHONETICS, V33, P115, DOI 10.1016/j.wocn.2004.02.003
   Drager K., 2010, LAB PHONOLOGY, V1, P473
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Endress AD, 2013, COGNITION, V127, P159, DOI 10.1016/j.cognition.2012.11.014
   Eskritt M, 2008, BRIT J DEV PSYCHOL, V26, P435, DOI 10.1348/026151007X253260
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Feldman N. H., 2009, P 29 ANN C COGN SCI, V1, P6
   Fox Tree JE, 1997, COGNITION, V62, P151, DOI 10.1016/S0010-0277(96)00781-0
   Frank MC, 2014, COGNITIVE PSYCHOL, V75, P80, DOI 10.1016/j.cogpsych.2014.08.002
   Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633
   Frank MC, 2009, PSYCHOL SCI, V20, P578, DOI 10.1111/j.1467-9280.2009.02335.x
   Franke M, 2014, PALG STUD PRAGM LANG, P170
   Frederiksen J., 1981, DISCOURSE PROCESS, V4, P323, DOI DOI 10.1080/01638538109544525
   Fukumura K, 2010, J MEM LANG, V62, P52, DOI 10.1016/j.jml.2009.09.001
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garvey C., 1974, LINGUIST INQ, V5, P459
   GERNSBACHER MA, 1988, J MEM LANG, V27, P699, DOI 10.1016/0749-596X(88)90016-2
   GERNSBACHER MA, 1989, J MEM LANG, V28, P735, DOI 10.1016/0749-596X(89)90006-5
   Givon T., 1983, TOPIC CONTINUITY DIS, P5, DOI [10.1075/tsl.3, DOI 10.1075/TSL.3.01GIV, 10.1075/tsl.3.01giv]
   Goldwater S, 2009, COGNITION, V112, P21, DOI 10.1016/j.cognition.2009.03.008
   GOLINKOFF RM, 1992, DEV PSYCHOL, V28, P99, DOI 10.1037/0012-1649.28.1.99
   Goodman Noah D, 2013, TOPICS COGNITIVE SCI
   GORDON PC, 1993, COGNITIVE SCI, V17, P311, DOI 10.1207/s15516709cog1703_1
   Grice H. P., 1989, STUDIES WAY WORDS, V65
   Grice H. Paul, 1975, SYNTAX SEMANTICS, V3, P41, DOI [10.1057/9780230005853_5., DOI 10.1111/J.1365-2664.2006.01229.X]
   Grodner D., 2011, PROCESSING ACQUISITI, P239
   Grodner DJ, 2010, COGNITION, V116, P42, DOI 10.1016/j.cognition.2010.03.014
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   Gualmini A., 2003, P 25 PENN LING C U P, V9, P87
   Gualmini A., 2001, SEMANTICS LINGUISTIC, V11, P231, DOI [10.3765/salt.v11i0.2840, DOI 10.3765/SALT.V11I0.2840]
   GUNDEL JK, 1993, LANGUAGE, V69, P274, DOI 10.2307/416535
   Hagoort P, 2007, PHILOS T R SOC B, V362, P801, DOI 10.1098/rstb.2007.2089
   Hale J, 2006, COGNITIVE SCI, V30, P643, DOI 10.1207/s15516709cog0000_64
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Hay J, 2007, ANNU REV ANTHROPOL, V36, P89, DOI 10.1146/annurev.anthro.34.081804.120633
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Heller D, 2015, LANG SPEECH, V58, P190, DOI 10.1177/0023830914528107
   Hemforth B, 2010, COGNITION IN FLUX, P2218
   Hirschberg J., 1985, THESIS U PENNSYLVANI
   Horn Laurence, 1972, THESIS UCLA
   Huang YT, 2018, COGNITIVE PSYCHOL, V102, P105, DOI 10.1016/j.cogpsych.2018.01.004
   Huang YT, 2011, LANG COGNITIVE PROC, V26, P1161, DOI 10.1080/01690965.2010.508641
   Huang YT, 2009, COGNITIVE PSYCHOL, V58, P376, DOI 10.1016/j.cogpsych.2008.09.001
   Ito K., 2013, J CHILD LANG, V1, P27
   Ito K, 2008, J MEM LANG, V58, P541, DOI 10.1016/j.jml.2007.06.013
   Jarvikivi J, 2005, PSYCHOL SCI, V16, P260, DOI 10.1111/j.0956-7976.2005.01525.x
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Jurafsky D., 2008, PRAGMATICS COMPUTATI
   Jurafsky Daniel, 2009, SPEECH LANGUAGE PROC
   Katsos N, 2011, COGNITION, V120, P67, DOI 10.1016/j.cognition.2011.02.015
   Kehler A, 2013, THEOR LINGUIST, V39, P1, DOI 10.1515/tl-2013-0001
   Kehler A, 2008, J SEMANT, V25, P1, DOI 10.1093/jos/ffm018
   Kehler Andrew, 2018, J PRAGMATICS
   Kendrick KH, 2015, DISCOURSE PROCESS, V52, P255, DOI 10.1080/0163853X.2014.955997
   King JPJ, 2018, DISCOURSE PROCESS, V55, P123, DOI 10.1080/0163853X.2017.1330041
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kohne J., 2013, P 35 ANN M COGN SCI, V35, P2760
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Kurumada C., 2018, PROBABILISTIC INFERE
   Kurumada C., 2016, J CHILD LANGUAGE
   Kurumada C., 2017, PSYCHOL B REV
   Kurumada C., 2012, P ANN C COGN SCI SOC, V34, P647
   Kurumada C, 2014, COGNITION, V133, P335, DOI 10.1016/j.cognition.2014.05.017
   Labov W, 2006, J PHONETICS, V34, P500, DOI 10.1016/j.wocn.2006.05.002
   Ladd DR, 2003, J PHONETICS, V31, P81, DOI 10.1016/S0095-4470(02)00073-6
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   Ladd DR, 1997, J PHONETICS, V25, P313, DOI 10.1006/jpho.1997.0046
   Lake JK, 2011, PSYCHON B REV, V18, P135, DOI 10.3758/s13423-010-0037-x
   Lambrecht Knud, 1994, INFORM STRUCTURE SEN
   Levelt WJ, 1989, SPEAKING INTENTION A
   Levinson S. C., 1983, PRAGNTATICS CAMBRIDG
   Levinson S.C., 2000, PRESUMPTIVE MEANINGS
   Levinson SC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00731
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Lidz J, 2002, COGNITION, V84, P113, DOI 10.1016/S0010-0277(02)00013-6
   LIEBERMAN P, 1960, J ACOUST SOC AM, V32, P451, DOI 10.1121/1.1908095
   Loy JE, 2017, COGNITIVE SCI, V41, P1434, DOI 10.1111/cogs.12378
   MACDONALD MC, 1994, LANG COGNITIVE PROC, V9, P157, DOI 10.1080/01690969408402115
   Markman EM, 2003, COGNITIVE PSYCHOL, V47, P241, DOI 10.1016/S0010-0285(03)00034-3
   MCKOON G, 1993, J EXP PSYCHOL LEARN, V19, P1040, DOI 10.1037/0278-7393.19.5.1040
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McRae K, 1998, J MEM LANG, V38, P283, DOI 10.1006/jmla.1997.2543
   MELTZOFF AN, 1995, DEV PSYCHOL, V31, P838, DOI 10.1037/0012-1649.31.5.838
   NEELY JH, 1977, J EXP PSYCHOL GEN, V106, P226, DOI 10.1037/0096-3445.106.3.226
   Ni WJ, 1996, LANG COGNITIVE PROC, V11, P283, DOI 10.1080/016909696387196
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D., 2000, COGNITIVE SCI AUSTR
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Noveck IA, 2001, COGNITION, V78, P165, DOI 10.1016/S0010-0277(00)00114-1
   Ochs E., 1979, DEV PRAGMATICS
   Orena AJ, 2015, CHILD DEV, V86, P1701, DOI 10.1111/cdev.12421
   OVIATT S, 1995, COMPUT SPEECH LANG, V9, P19, DOI 10.1006/csla.1995.0002
   Papadopoulou D, 2006, J LINGUIST, V42, P109, DOI 10.1017/S0022226705003701
   Papafragou A., 2004, CHILDRENS COMPUTATIO
   Papafragou A, 2006, J CHILD LANG, V33, P721, DOI 10.1017/S0305000906007550
   Perfors A, 2011, COGNITION, V120, P302, DOI 10.1016/j.cognition.2010.11.015
   Perfors A, 2010, J CHILD LANG, V37, P607, DOI 10.1017/S0305000910000012
   Pierrehumbert J. B., 1990, INTENTIONS COMMUNICA, V271, P311
   Pierrehumbert J.B., 1980, PHONOLOGY PHONETICS
   Pisoni DB, 2007, OXFORD HDB PSYCHOLIN, P3
   Potts Christopher, 2005, LOGIC CONVENTIONAL I
   Rabagliati H, 2017, J MEM LANG, V94, P15, DOI 10.1016/j.jml.2016.09.007
   Recanati Francois, 1989, MIND LANG, V4, P295, DOI DOI 10.1111/J.1468-0017.1989.TB00258.X
   Rohde H, 2014, LANG COGN NEUROSCI, V29, P912, DOI 10.1080/01690965.2013.854918
   Rosa EC, 2017, J MEM LANG, V94, P43, DOI 10.1016/j.jml.2016.07.007
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   Sauerland U, 2012, LANG LINGUIST COMPAS, V6, P36, DOI 10.1002/lnc3.321
   Sedivy JC, 2002, J MEM LANG, V46, P341, DOI 10.1006/jmla.2001.2812
   SELKIRK ELISABETH, 1996, HDB PHONOLOGICAL THE, P550
   Shriberg E. E., 1996, P INT C SPOK LANG PR, P11
   Silverman K., 1990, PAPERS LAB PHONOLOGY, P72, DOI [10.1017/cbo9780511627736.005, DOI 10.1017/CBO9780511627736.005, DOI 10.1017/CBO9780511627736]
   Silverman Kim, 1992, P 1992 INT C SPOK LA, P867
   SMITH CL, 1980, J EXP CHILD PSYCHOL, V30, P191, DOI 10.1016/0022-0965(80)90057-0
   SMITH VL, 1993, J MEM LANG, V32, P25, DOI 10.1006/jmla.1993.1002
   Sobel D., 2010, COGNITIVE SCI, V28, P303
   SOLAN L, 1980, J SPEECH HEAR RES, V23, P688, DOI 10.1044/jshr.2303.688
   Sonderegger M, 2010, COGNITION IN FLUX, P375
   Speer SR, 2009, LANG LINGUIST COMPAS, V3, P90, DOI 10.1111/j.1749-818x.2008.00103.x
   Spivey MJ, 2005, P NATL ACAD SCI USA, V102, P10393, DOI 10.1073/pnas.0503903102
   Spivey MJ, 1998, J EXP PSYCHOL LEARN, V24, P1521, DOI 10.1037/0278-7393.24.6.1521
   Staum Casasanto L., 2008, P 30 ANN C COGN SCI, V30, P799
   Stephens N., 2010, THESIS STANFORD U
   Stiller AJ, 2015, LANG LEARN DEV, V11, P176, DOI 10.1080/15475441.2014.927328
   Stivers T, 2018, J PRAGMATICS, V124, P14, DOI 10.1016/j.pragma.2017.11.013
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106
   SURIAN L, 1991, J CHILD LANG, V18, P451, DOI 10.1017/S0305000900011156
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tenebaum JB, 2001, BEHAV BRAIN SCI, V24, P629, DOI 10.1017/S0140525X01000061
   Tree JEF, 1995, J MEM LANG, V34, P709, DOI 10.1006/jmla.1995.1032
   Turnbull R., 2017, LANG COGN NEUROSCI, P1
   van Berkum JJA, 1999, J MEM LANG, V41, P147, DOI 10.1006/jmla.1999.2641
   Vieira T., 2017, T ASS COMPUTATIONAL, V5, P263
   Vouloumanos A, 2012, P NATL ACAD SCI USA, V109, P12933, DOI 10.1073/pnas.1121057109
   Warren P, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.92
   Watson DG, 2008, COGNITIVE SCI, V32, P1232, DOI 10.1080/03640210802138755
   Wells B, 2004, J CHILD LANG, V31, P749, DOI 10.1017/S030500090400652X
   WIGHTMAN C, 2002, P SPEECH PROS 2002 A, P25
   Xiang M, 2015, LANG COGN NEUROSCI, V30, P648, DOI 10.1080/23273798.2014.995679
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245
   Xu Y, 2005, SPEECH COMMUN, V46, P220, DOI 10.1016/j.specom.2005.02.014
   Yoon S. O., 2016, INFLUENCE HIST DISCO
NR 215
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER ACADEMIC PRESS INC
PI SAN DIEGO
PA 525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0079-7421
BN 978-0-12-815086-3
J9 PSYCHOL LEARN MOTIV
JI Psychol. Learn. Motiv.
PY 2018
VL 68
BP 215
EP 261
DI 10.1016/bs.plm.2018.08.012
PG 47
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA BL5NQ
UT WOS:000452378800008
DA 2021-02-24
ER

PT J
AU Canete, OM
   Purdy, SC
   Neeff, M
   Brown, CRS
   Thorne, PR
AF Canete, Oscar M.
   Purdy, Suzanne C.
   Neeff, Michel
   Brown, Colin R. S.
   Thorne, Peter R.
TI Cortical auditory evoked potential (CAEP) and behavioural measures of
   auditory function in an adult with a single sided deafness: case study
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Unilateral hearing loss; single sided deafness; speech in noise
   recognition; sound localization; cortical auditory evoked potential;
   auditory plasticity
ID UNILATERAL HEARING-LOSS; NATURALLY PRODUCED SPEECH; SOUND LOCALIZATION;
   ACOUSTIC NEUROMA; CHILDREN; HUMANS; NOISE; EAR; REORGANIZATION;
   RECOGNITION
AB Objective: To examine cortical auditory evoked potentials (CAEPs) and behavioural measures of spatial speech in noise recognition, sound localization and self-reported perception of hearing performance before and after surgical removal of an acoustic neuroma, and to monitor changes over time after surgery.
   Methods: CAEPs in noise were recorded and auditory skills were assessed using tests of sound localization, spatial speech perception in noise and self-ratings of auditory abilities (Speech, Spatial and Qualities of Hearing questionnaire, SSQ) in a male adult with single-sided deafness due to acoustic neuroma removal. Measurements took place at 2, 6 and 12 months after surgery.
   Results: The pattern of CAEP responses, behavioural measurements and self-reported perception after surgery differed from the pre-surgery baseline and changed over time after surgery.
   Conclusions: The participant experienced considerable listening fatigue and deficits in auditory skills after losing hearing in one ear. Different patterns of change in CAEPs and other measures over time suggest multiple physiological mechanisms for auditory plasticity after acute onset of single sided deafness.
C1 [Canete, Oscar M.; Purdy, Suzanne C.] Univ Auckland, Sch Psychol, Speech Sci, Bldg 721,Tamaki Campus,261 Morrin Rd, Auckland, New Zealand.
   [Canete, Oscar M.; Purdy, Suzanne C.; Thorne, Peter R.] Eisdell Moore Ctr Res Hearing & Balance, Auckland, New Zealand.
   [Neeff, Michel; Brown, Colin R. S.] Starship Childrens Hosp, Auckland, New Zealand.
   [Thorne, Peter R.] Univ Auckland, Sect Audiol, Auckland, New Zealand.
RP Canete, OM (corresponding author), Univ Auckland, Sch Psychol, Speech Sci, Bldg 721,Tamaki Campus,261 Morrin Rd, Auckland, New Zealand.
EM ocan093@aucklanduni.ac.nz
RI Purdy, Suzanne C/F-2050-2010; Canete, Oscar M/P-7553-2017
OI Purdy, Suzanne C/0000-0001-9978-8173; Neeff, Michel/0000-0003-0040-0437;
   Brown, Colin/0000-0001-9768-2826; Canete, Oscar M/0000-0002-2622-5086;
   Thorne, Peter/0000-0003-0214-0210
CR Augustine AM, 2013, INDIAN J OTOLARYNGOL, V65, P120, DOI 10.1007/s12070-012-0586-6
   Bellis TJ, 2000, J NEUROSCI, V20, P791, DOI 10.1523/JNEUROSCI.20-02-00791.2000
   BESS FH, 1984, PEDIATRICS, V74, P206
   BESS FH, 1986, EAR HEARING, V7, P20, DOI 10.1097/00003446-198602000-00005
   Bilecen D, 2000, NEUROLOGY, V54, P765, DOI 10.1212/WNL.54.3.765
   Canete OM, 2016, NZ AUDIOLOGIC SOC B, V26, P13
   Cullington HE, 2011, COCHLEAR IMPLANTS IN, V12, pS18
   Douglas SA, 2007, LARYNGOSCOPE, V117, P1648, DOI 10.1097/MLG.0b013e3180caa162
   Easwar V, 2012, INT J AUDIOL, V51, P926, DOI 10.3109/14992027.2012.711913
   Green JD, 1999, LARYNGOSCOPE, V109, P1626, DOI 10.1097/00005537-199910000-00015
   Harner SG, 2000, AM J OTOL, V21, P405, DOI 10.1016/S0196-0709(00)80052-6
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Hornsby BWY, 2014, AM J AUDIOL, V23, P129, DOI 10.1044/1059-0889(2013/13-0017)
   HUMES LE, 1980, AUDIOLOGY, V19, P508
   Hutson KA, 2008, HEARING RES, V237, P19, DOI 10.1016/j.heares.2007.12.007
   Johnstone PM, 2010, J AM ACAD AUDIOL, V21, P522, DOI 10.3766/jaaa.21.8.4
   Khosla D, 2003, JARO-J ASSOC RES OTO, V4, P235, DOI 10.1007/s10162-002-3014-x
   Lee MY, 2017, NEUROSCI LETT, V657, P171, DOI 10.1016/j.neulet.2017.08.001
   Li LPH, 2006, EUR J NEUROSCI, V24, P937, DOI 10.1111/j.1460-9568.2006.04961.x
   Lunner T, 2009, SCAND J PSYCHOL, V50, P395, DOI 10.1111/j.1467-9450.2009.00742.x
   Maslin MRD, 2015, J ACOUST SOC AM, V137, pEL408, DOI 10.1121/1.4914945
   Maslin MRD, 2013, CLIN NEUROPHYSIOL, V124, P1414, DOI 10.1016/j.clinph.2012.12.052
   McAlpine D, 1997, J NEUROPHYSIOL, V78, P767
   Morita T, 2007, NEUROSCI RES, V58, P6, DOI 10.1016/j.neures.2007.01.010
   NEWTON VE, 1983, AUDIOLOGY, V22, P189
   Noble W, 2004, INT J AUDIOL, V43, P100, DOI 10.1080/14992020400050015
   NOBLE W, 1994, INT J AUDIOL, V33, P117
   Noble W, 2013, INT J AUDIOL, V52, P409, DOI 10.3109/14992027.2013.781278
   Olsen S.O., 2012, AUDIOL MED, V10, P83
   Plack C. J., 2010, OXFORD HDB AUDITORY, V3
   Ponton CW, 2001, HEARING RES, V154, P32, DOI 10.1016/S0378-5955(01)00214-3
   Purdy Suzanne C., 2016, Seminars in Hearing, V37, P62, DOI 10.1055/s-0035-1570329
   Reeder RM, 2015, AUDIOL NEURO-OTOL, V20, P31, DOI 10.1159/000380745
   Ruscetta MN, 2005, INT J PEDIATR OTORHI, V69, P771, DOI 10.1016/j.ijporl.2005.01.010
   Schmithorst VJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00164
   Schmithorst VJ, 2005, NEUROREPORT, V16, P463, DOI 10.1097/00001756-200504040-00009
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Vannson N, 2015, AUDIOL NEURO-OTOL, V20, P38, DOI 10.1159/000380746
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vasama JP, 1997, HEARING RES, V104, P183, DOI 10.1016/S0378-5955(96)00200-6
   VASAMA JP, 1994, HEARING RES, V78, P91, DOI 10.1016/0378-5955(94)90047-7
   VASAMA JP, 1995, NEUROREPORT, V6, P961, DOI 10.1097/00001756-199505090-00003
   Vincent C, 2015, AUDIOL NEURO-OTOL, V20, P87, DOI 10.1159/000380754
NR 43
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2018
VL 16
IS 1
BP 64
EP 72
DI 10.1080/21695717.2018.1426297
PG 9
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA GL6KJ
UT WOS:000437294400009
DA 2021-02-24
ER

PT J
AU de Schonen, S
   Bertoncini, J
   Petroff, N
   Couloigner, V
   Van Den Abbeele, T
AF de Schonen, Scania
   Bertoncini, Josiane
   Petroff, Nathalie
   Couloigner, Vincent
   Van Den Abbeele, Thierry
TI Visual cortical activity before and after cochlear implantation: A
   follow up ERP prospective study in deaf children
SO INTERNATIONAL JOURNAL OF PSYCHOPHYSIOLOGY
LA English
DT Article
DE Prelingual and postlingual deafness; Visual event related potentials in
   deaf children; Pre-post CI follow up; Cochlear implantation outcome
ID CROSS-MODAL PLASTICITY; MOVEMENT DETECTION TASK; ACTIVATE
   AUDITORY-CORTEX; EVENT-RELATED POTENTIALS; SPEECH-PERCEPTION;
   SIGN-LANGUAGE; CEREBRAL ORGANIZATION; SELECTIVE ATTENTION;
   RIGHT-HEMISPHERE; HUMAN INFANTS
AB ERPs were recorded in response to presentation of static colored patterned stimuli in 25 children (19 to 80 months of age at cochlear implantation, CI) with very early prelingual profound deafness (PreLD), 21 post lingual profoundly deaf children (PostLD) (34 to 180 months of age at CI) and gender- and age-matched control hearing children. Recording sessions were performed before CI, then 6 and 24 months after CI.
   Results showed that prelingual and, at a lesser degree, postlingual auditory deprivation altered cortical visual neural activity associated to colored shapes from both P1 and N1 cortical processing stages. The P1 and N1 amplitude modifications vanished about 24 months after CI in both PreLD and PostLD deaf children. In PreLD the visual processing pattern becomes similar to the typical one essentially by an amplitude decrease of P1 on the left hemisphere together with an amplitude increase of the N1 on the right hemisphere. Finally, in PreLD, increased LH advantage over the RH in N1 amplitude on the cerebellar-occipito-parietal region before CI showed a significant inverse relationship with speech perception outcomes 3 years after CI.
   Investigating early visual processing development and its neural substrates in deaf children would help to understand the variability of CI outcome, because their cortical visual organization diverged from the one of typically developing hearing children, and cannot be predicted from what is observed in deaf adults.
C1 [de Schonen, Scania; Bertoncini, Josiane] Univ Paris 05, CNRS, Neurosci & Cognit Inst, Lab Psychol Percept,UMR8242, Paris, France.
   [Petroff, Nathalie; Couloigner, Vincent; Van Den Abbeele, Thierry] Univ Hosp CHU, Hop Robert Debre, Dept Otorhinolaryngol & ENT Surg, Paris, France.
RP de Schonen, S (corresponding author), Univ Paris 05, CNRS, Neurosci & Cognit Inst, Lab Psychol Percept,UMR8242, Paris, France.
EM scania.de-schonen@parisdescartes.fr;
   josiane.bertoncini@parisdescartes.fr; nathalie.petroff@rdb.aphp.fr;
   vincent.couloigner@nck.aphp.fr; thierry.van-den-abbeele@rdb.aphp.fr
OI Van Den abbeele, Thierry/0000-0003-2572-1544
CR Arcizet F, 2011, CEREB CORTEX, V21, P2498, DOI 10.1093/cercor/bhr035
   Armstrong BA, 2002, COGNITIVE BRAIN RES, V14, P422, DOI 10.1016/S0926-6410(02)00211-2
   Balan PF, 2006, J NEUROSCI, V26, P9239, DOI 10.1523/JNEUROSCI.1898-06.2006
   Bartels A, 2000, EUR J NEUROSCI, V12, P172, DOI 10.1046/j.1460-9568.2000.00905.x
   Bavelier D, 2001, J NEUROSCI, V21, P8931, DOI 10.1523/JNEUROSCI.21-22-08931.2001
   Bavelier D, 2000, J NEUROSCI, V20, DOI 10.1523/JNEUROSCI.20-17-j0001.2000
   Bavelier D, 1998, NEUROREPORT, V9, P1537, DOI 10.1097/00001756-199805110-00054
   Bavelier D, 2006, TRENDS COGN SCI, V10, P512, DOI 10.1016/j.tics.2006.09.006
   BERTONCINI J, 1989, BRAIN LANG, V37, P591, DOI 10.1016/0093-934X(89)90113-2
   Bottari D, 2014, NEUROIMAGE, V94, P172, DOI 10.1016/j.neuroimage.2014.02.031
   Bottari D, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025607
   BROWN AM, 1990, VISION RES, V30, P1159, DOI 10.1016/0042-6989(90)90173-I
   BROWN AM, 1995, VISION RES, V35, P3145, DOI 10.1016/0042-6989(95)00017-T
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   CATALANAHUMADA M, 1993, BRAIN RES, V623, P287, DOI 10.1016/0006-8993(93)91439-Y
   Clark V. P., 1994, HUMAN BRAIN MAPPING, V2, P170, DOI [10.1002/hbm.460020306, DOI 10.1002/HBM.460020306]
   Clark VP, 1997, HUM BRAIN MAPP, V5, P293, DOI 10.1002/(SICI)1097-0193(1997)5:4<293::AID-HBM15>3.0.CO;2-F
   Cleary KM, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00922
   Coch D, 2005, DEVELOPMENTAL SCI, V8, P372, DOI 10.1111/j.1467-7687.2005.00425.x
   Codina C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020417
   Codina C, 2011, DEVELOPMENTAL SCI, V14, P725, DOI 10.1111/j.1467-7687.2010.01017.x
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Corbetta M, 2008, NEURON, V58, P306, DOI 10.1016/j.neuron.2008.04.017
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Deruelle C, 1998, DEV NEUROPSYCHOL, V14, P535, DOI 10.1080/87565649809540727
   DERUELLE C, 1995, INFANT BEHAV DEV, V18, P123, DOI 10.1016/0163-6383(95)90042-X
   DESCHONEN S, 1990, CHILD DEV, V61, P1192, DOI 10.2307/1130887
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Fecteau JH, 2006, TRENDS COGN SCI, V10, P382, DOI 10.1016/j.tics.2006.06.011
   Fine I, 2005, J COGNITIVE NEUROSCI, V17, P1621, DOI 10.1162/089892905774597173
   Finney EM, 2003, NEUROREPORT, V14, P1425, DOI 10.1097/00001756-200308060-00004
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   FOLK CL, 1994, J EXP PSYCHOL HUMAN, V20, P317, DOI 10.1037/0096-1523.20.2.317
   Franklin A, 2008, P NATL ACAD SCI USA, V105, P3221, DOI 10.1073/pnas.0712286105
   Franklin A, 2004, BRIT J DEV PSYCHOL, V22, P349, DOI 10.1348/0261510041552738
   Giraud AL, 2007, RESTOR NEUROL NEUROS, V25, P381
   Hellige JB, 2010, 2 HALVES BRAIN INFOR, P379, DOI [DOI 10.7551/MITPRESS/9780262014137.003.0279, 10.7551/mitpress/9780262014137.003.0279]
   Hillyard SA, 1998, P NATL ACAD SCI USA, V95, P781, DOI 10.1073/pnas.95.3.781
   Hixson SM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152264
   Itier RJ, 2004, NEUROIMAGE, V21, P1518, DOI 10.1016/j.neuroimage.2003.12.016
   Lange JJ, 1998, BIOL PSYCHOL, V48, P153, DOI 10.1016/S0301-0511(98)00011-8
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee HJ, 2005, HEARING RES, V203, P2, DOI 10.1016/j.heares.2004.11.005
   Lee HJ, 2007, CEREB CORTEX, V17, P909, DOI 10.1093/cercor/bhl001
   Lomber SG, 2017, COGNITIVE DEV, V42, P49, DOI 10.1016/j.cogdev.2017.02.007
   Lomber SG, 2010, NAT NEUROSCI, V13, P1421, DOI 10.1038/nn.2653
   Luu P., 2000, TECHNICAL NOTE, P6
   Macaluso E, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00685
   Mahmoudzadeh M, 2013, P NATL ACAD SCI USA, V110, P4846, DOI 10.1073/pnas.1212220110
   Mesulam MM, 1999, PHILOS T R SOC B, V354, P1325, DOI 10.1098/rstb.1999.0482
   Mitchell TV, 2004, J COGNITIVE NEUROSCI, V16, P1363, DOI 10.1162/0898929042304750
   Mullen KT, 2015, EUR J NEUROSCI, V42, P2923, DOI 10.1111/ejn.13090
   NEVILLE HJ, 1987, BRAIN RES, V405, P253, DOI 10.1016/0006-8993(87)90295-2
   NEVILLE HJ, 1987, BRAIN RES, V405, P284, DOI 10.1016/0006-8993(87)90297-6
   NEVILLE HJ, 1987, BRAIN RES, V405, P268, DOI 10.1016/0006-8993(87)90296-4
   NEVILLE HJ, 1983, BRAIN RES, V266, P127, DOI 10.1016/0006-8993(83)91314-8
   Neville HJ, 1998, P NATL ACAD SCI USA, V95, P922, DOI 10.1073/pnas.95.3.922
   Newman AJ, 2002, NAT NEUROSCI, V5, P76, DOI 10.1038/nn775
   Pavani F., 2012, NEURAL BASEMULTISE
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   Petroff N., 2006, CONNAISSANCES SURDIT, V17, P19
   Rugg MD, 2007, TRENDS COGN SCI, V11, P251, DOI 10.1016/j.tics.2007.04.004
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Sharma A, 2009, J COMMUN DISORD, V42, P272, DOI 10.1016/j.jcomdis.2009.03.003
   Taylor MJ, 2003, INT J PSYCHOPHYSIOL, V51, P85, DOI 10.1016/S0167-8760(03)00155-7
   Taylor MJ, 2002, CLIN NEUROPHYSIOL, V113, P1903, DOI 10.1016/S1388-2457(02)00309-7
   Taylor MJ, 2000, INT J PSYCHOPHYSIOL, V37, P135, DOI 10.1016/S0167-8760(00)00084-2
   Ungerleider Leslie G., 1994, Current Opinion in Neurobiology, V4, P157, DOI 10.1016/0959-4388(94)90066-3
   Vachon P, 2013, NEUROSCIENCE, V245, P50, DOI 10.1016/j.neuroscience.2013.04.004
   Williams RJ, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.408
NR 73
TC 0
Z9 0
U1 1
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-8760
EI 1872-7697
J9 INT J PSYCHOPHYSIOL
JI Int. J. Psychophysiol.
PD JAN
PY 2018
VL 123
BP 88
EP 102
DI 10.1016/j.ijpsycho.2017.10.009
PG 15
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
SC Psychology; Neurosciences & Neurology; Physiology
GA FU9KR
UT WOS:000424175300012
PM 29108924
DA 2021-02-24
ER

PT J
AU Noor, H
   Arif, MH
AF Noor, Hina
   Arif, Manzoor Hussain
TI Development and Validation of Phonetically Balanced Speech Perception
   Test in Urdu Language
SO INTERNET JOURNAL OF ALLIED HEALTH SCIENCES AND PRACTICE
LA English
DT Article
DE hearing impairment; phonetic balance speech perception test; Urdu
   language
AB Purpose: The tool of speech or language assessment is required to be linguistically and culturally appropriate for the individual being tested. Testing in native language is essential if an audiologist or speech and language therapist wants to test the speech perception capacities of an individual and to use the data for further planning and monitoring of the therapeutic efforts. Numerous speech perception tests are available in different international and regional languages. But in Urdu language, no such tool is available to the clinicians to check the speech perception abilities of hearing impaired individuals. Therefore, this study was designed to: (1) estimate the frequency of occurrence of Urdu consonants; (2) develop a speech perception test in Urdu language for children with hearing impairments; and 3) establish the reliability and validity of the test. Methods: This study was carried out in three stages. In stage I, structural attributes of the test were planned. During stage II, mean phonetic occurrence of each consonant in Urdu language was calculated. Then a pool of the most common image-able Urdu words was generated from which a 25 word-list for identification task was created. Finally, the speech perception test was finalized after establishing its content validity. In stage III, reliability and validity of the test was established through a pilot study conducted via randomly selected 100 normally hearing and 30 hearing impaired subjects. Results: The Urdu speech perception test is a non-verbal, norm referenced test. Content, predictive and construct validity was established. Split half reliability of the test was 0.798 and test-retest reliability was 0.881 which was found to be significant at alpha = 0.05 and 0.01 level of significance. Inter-scorer reliability was 0.598 which was significant at alpha = 0.10 level. Conclusions: The Urdu speech perception test is a reliable, validated and linguistically appropriate non verbal tool to check the speech perception abilities of children with hearing impairment.
C1 [Noor, Hina] Allama Iqbal Open Univ, Fac Educ, Dept Special Educ, Room 116,H-8, Islamabad, Pakistan.
   [Arif, Manzoor Hussain] Bilqees Coll Educ, Teacher Training Inst, Rawalpindi, Pakistan.
RP Noor, H (corresponding author), Allama Iqbal Open Univ, Fac Educ, Dept Special Educ, Room 116,H-8, Islamabad, Pakistan.
RI Noor, Hina/P-7470-2019
CR Ali H., 2012, P 4 INT C EL COMP TE, P473
   Boothroyd A, 2005, SOUND FDN EARLY AMPL, P129
   CARHART R, 1951, ACTA OTO-LARYNGOL, V40, P62, DOI 10.3109/00016485109138908
   Dias MA, 2015, LANG INDIA, V15, P268
   Eisenberg LS, 2007, INT J PEDIATR OTORHI, V71, P1339, DOI 10.1016/j.ijporl.2007.05.017
   Erber N. P., 1982, AUDITORY TRAINING
   Harris RW, 2007, INT J AUDIOL, V46, P47, DOI 10.1080/14992020601058117
   Hussain S, 2003, 10 C EUR CHAPT, P31
   Khan I, 2015, SINDH U RES J SURJ S, V47
   Kinsey A., 2010, THESIS
   Kirk KI, 1995, 20 IND U
   Kishon-Rabin L, 2000, INT J AUDIOL, V39, P269, DOI DOI 10.3109/00206090009073091
   Kumar S. B. R., 2012, THEORY PRACT LANG ST, V2, P193, DOI DOI 10.4304/tpls.2.2.193-204
   Kumar SR, 2016, INT J OTORHINOLARYNG, V2, P205, DOI [10.18203/issn.2454-5929.ijohns20163467, DOI 10.18203/ISSN.2454-5929.IJOHNS20163467]
   Madell J, 2011, AUDIOLOGYONLINE
   Mahwish F, 2016, P 6 C LANG TECHN CLT, P15
   Martin F N, 2000, J Am Acad Audiol, V11, P489
   Martin FN, 2000, J AM ACAD AUDIOL, V11, P522
   Mukati AS, 2013, IDENTIFYING CORE VOC
   Munthuli A., 2015, 29 PAC AS C LANG INF
   Nawaz S, 2002, DELETION RULES URDU
   Raza AA, 2009, THESIS
   Sagon R, 2006, 382 WASH U SCH MED P
   Saleem AM, 2002, URDU CONSONANTAL VOC
   Silverman SB, 1996, 469 WASH U SCH MED P
   Wyne N., LANGUAGES THEIR FAMI
   Zheng Y, 2009, EAR HEARING, V30, P600, DOI 10.1097/AUD.0b013e3181b4aba8
NR 27
TC 0
Z9 0
U1 0
U2 0
PU NOVA SOUTHEASTERN UNIV
PI FORT LAUDERDALE
PA 3200 S UNIVERSITY DR, FORT LAUDERDALE, FL 33328 USA
SN 1540-580X
J9 INTERNET J ALLIED HE
JI Internet J. Allied Health Sci. Pract.
PY 2018
VL 16
IS 4
AR 12
PG 15
WC Health Care Sciences & Services
SC Health Care Sciences & Services
GA HD9XZ
UT WOS:000452920200012
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Richards, MD
   Goltz, HC
   Wong, AME
AF Richards, Michael D.
   Goltz, Herbert C.
   Wong, Agnes M. E.
TI Optimal Audiovisual Integration in the Ventriloquism Effect But
   Pervasive Deficits in Unisensory Spatial Localization in Amblyopia
SO INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE
LA English
DT Article
DE amblyopia; multisensory integration; audiovisual integration;
   ventriloquism effect; spatial localization
ID SPEECH-PERCEPTION; VISUAL-ATTENTION; BINOCULAR VISION; CHILDREN; ACUITY;
   EYES; SUSCEPTIBILITY; ENHANCEMENT; INFORMATION; STABILITY
AB PURPOSE. Classically understood as a deficit in spatial vision, amblyopia is increasingly recognized to also impair audiovisual multisensory processing. Studies to date, however, have not determined whether the audiovisual abnormalities reflect a failure of multisensory integration, or an optimal strategy in the face of unisensory impairment. We use the ventriloquism effect and the maximum-likelihood estimation (MLE) model of optimal integration to investigate integration of audiovisual spatial information in amblyopia.
   METHODS. Participants with unilateral amblyopia (n = 14; mean age 28.8 years; 7 anisometropic, 3 strabismic, 4 mixed mechanism) and visually normal controls (n = 16, mean age 29.2 years) localized brief unimodal auditory, unimodal visual, and bimodal (audiovisual) stimuli during binocular viewing using a location discrimination task. A subset of bimodal trials involved the ventriloquism effect, an illusion in which auditory and visual stimuli originating from different locations are perceived as originating from a single location. Localization precision and bias were determined by psychometric curve fitting, and the observed parameters were compared with predictions from the MLE model.
   RESULTS. Spatial localization precision was significantly reduced in the amblyopia group compared with the control group for unimodal visual, unimodal auditory, and bimodal stimuli. Analyses of localization precision and bias for bimodal stimuli showed no significant deviations from the MLE model in either the amblyopia group or the control group.
   CONCLUSIONS. Despite pervasive deficits in localization precision for visual, auditory, and audiovisual stimuli, audiovisual integration remains intact and optimal in unilateral amblyopia.
C1 [Richards, Michael D.] Univ Toronto, Inst Med Sci, Fac Med, Toronto, ON, Canada.
   [Richards, Michael D.; Wong, Agnes M. E.] Hosp Sick Children, Dept Ophthalmol & Vis Sci, 555 Univ Ave, Toronto, ON M5G 1X8, Canada.
   [Richards, Michael D.; Goltz, Herbert C.; Wong, Agnes M. E.] Univ Toronto, Dept Ophthalmol & Vis Sci, Toronto, ON, Canada.
   [Goltz, Herbert C.; Wong, Agnes M. E.] Hosp Sick Children, Program Neurosci & Mental Hlth, Toronto, ON, Canada.
RP Goltz, HC; Wong, AME (corresponding author), Hosp Sick Children, Dept Ophthalmol & Vis Sci, 555 Univ Ave, Toronto, ON M5G 1X8, Canada.
EM herb.goltz@sickkids.ca; agnes.wong@sickkids.ca
FU Canadian Institutes of Health Research (CIHR; Ottawa, Ontario,
   Canada)Canadian Institutes of Health Research (CIHR) [MOP 106663];
   Leaders Opportunity Fund from the Canada Foundation for Innovation (CFI;
   Ottawa, Ontario, Canada); John and Melinda Thompson Endowment Fund in
   Vision Neurosciences at The Hospital for Sick Children (Toronto,
   Ontario, Canada); Department of Ophthalmology and Vision Sciences at The
   Hospital for Sick Children (Toronto, Ontario, Canada); Vision Science
   Research Program at the University of Toronto (Toronto, Ontario, Canada)
FX Supported by Grant MOP 106663 from the Canadian Institutes of Health
   Research (CIHR; Ottawa, Ontario, Canada), Leaders Opportunity Fund from
   the Canada Foundation for Innovation (CFI; Ottawa, Ontario, Canada), the
   John and Melinda Thompson Endowment Fund in Vision Neurosciences at The
   Hospital for Sick Children (Toronto, Ontario, Canada), the Department of
   Ophthalmology and Vision Sciences at The Hospital for Sick Children
   (Toronto, Ontario, Canada), and the Vision Science Research Program at
   the University of Toronto (Toronto, Ontario, Canada).
CR Aaen-Stockdale C, 2008, VISION RES, V48, P1965, DOI 10.1016/j.visres.2008.06.012
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   ALTMANN L, 1986, VISION RES, V26, P1959, DOI 10.1016/0042-6989(86)90121-5
   [Anonymous], 2012, PREF PRACT PATT GUID
   Barrett BT, 2003, INVEST OPHTH VIS SCI, V44, P1555, DOI 10.1167/iovs.02-0515
   BEDELL HE, 1985, INVEST OPHTH VIS SCI, V26, P909
   Bertelson P, 2000, PERCEPT PSYCHOPHYS, V62, P321, DOI 10.3758/BF03205552
   Birch EE, 2013, PROG RETIN EYE RES, V33, P67, DOI 10.1016/j.preteyeres.2012.11.001
   Burgmeier R, 2015, JAMA OPHTHALMOL, V133, P11, DOI 10.1001/jamaophthalmol.2014.3307
   Burnham D., 1996, SPEECHREADING HUMANS, P103
   Burr D., 2012, NEURAL BASEMULTISE, P345
   Chen YC, 2017, CURR BIOL, V27, P583, DOI 10.1016/j.cub.2017.01.009
   Daw N. W., 2006, VISUAL DEV
   Driver J, 1996, NATURE, V381, P66, DOI 10.1038/381066a0
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Frassinetti F, 2002, EXP BRAIN RES, V147, P332, DOI 10.1007/s00221-002-1262-y
   Fronius M, 2004, GRAEF ARCH CLIN EXP, V242, P827, DOI 10.1007/s00417-004-0936-5
   Fujisaki W, 2005, EXP BRAIN RES, V166, P455, DOI 10.1007/s00221-005-2385-8
   Gonzalez EG, 2012, INVEST OPHTH VIS SCI, V53, P5386, DOI 10.1167/iovs.12-9941
   Gori M, 2008, CURR BIOL, V18, P694, DOI 10.1016/j.cub.2008.04.036
   Gori M, 2010, CURR BIOL, V20, P223, DOI 10.1016/j.cub.2009.11.069
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   HESS RF, 1992, VISION RES, V32, P1319, DOI 10.1016/0042-6989(92)90225-8
   Ho CS, 2006, VISION RES, V46, P3274, DOI 10.1016/j.visres.2006.03.029
   Howard IP, 1966, YALE J BIOL MED, V39, P332
   KANDEL GL, 1980, AM J OPTOM PHYS OPT, V57, P1
   LEVI DM, 1985, VISION RES, V25, P979, DOI 10.1016/0042-6989(85)90208-1
   LITOVSKY RY, 1997, BINAURAL SPATIAL HEA, P571
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McKee SP, 2003, J VISION, V3, P380, DOI 10.1167/3.5.5
   Meier K, 2017, INVEST OPHTH VIS SCI, V58, P1779, DOI 10.1167/iovs.16-20964
   Mirabella G, 2011, ARCH OPHTHALMOL-CHIC, V129, P176, DOI 10.1001/archophthalmol.2010.354
   Moro SS, 2014, MULTISENS RES, V27, P173, DOI 10.1163/22134808-00002453
   MORRELL LK, 1968, J EXP PSYCHOL, V77, P14, DOI 10.1037/h0021289
   Nardini M, 2008, CURR BIOL, V18, P689, DOI 10.1016/j.cub.2008.04.021
   Narinesingh C, 2015, INVEST OPHTH VIS SCI, V56, P2107, DOI 10.1167/iovs.14-15898
   Narinesingh C, 2014, INVEST OPHTH VIS SCI, V55, P3158, DOI 10.1167/iovs.14-14140
   Niechwiej-Szwedo E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031075
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   Preslan MW, 1996, OPHTHALMOLOGY, V103, P105, DOI 10.1016/S0161-6420(96)30753-7
   Pulkki V., 2001, SPATIAL SOUND GENERA
   Richards MD, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179516
   Rubin GS, 2000, INVEST OPHTH VIS SCI, V41, P3327
   SCHOR CM, 1984, INVEST OPHTH VIS SCI, V25, P729
   Sireteanu R, 2008, VISION RES, V48, P1150, DOI 10.1016/j.visres.2008.01.028
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Strasburger H, 2001, PERCEPT PSYCHOPHYS, V63, P1348, DOI 10.3758/BF03194547
   STUART JA, 1962, AM J OPHTHALMOL, V53, P471, DOI 10.1016/0002-9394(62)94878-X
   Student Support Services Team, SCH HEAR SCREEN GUID
   Subramanian V, 2013, INVEST OPHTH VIS SCI, V54, P1998, DOI 10.1167/iovs.12-11054
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Vroomen J, 2001, PERCEPT PSYCHOPHYS, V63, P651, DOI 10.3758/BF03194427
   Warncke H, 1941, AKUST Z, V6, P174
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
NR 60
TC 3
Z9 3
U1 0
U2 4
PU ASSOC RESEARCH VISION OPHTHALMOLOGY INC
PI ROCKVILLE
PA 12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA
SN 0146-0404
EI 1552-5783
J9 INVEST OPHTH VIS SCI
JI Invest. Ophthalmol. Vis. Sci.
PD JAN
PY 2018
VL 59
IS 1
BP 122
EP 131
DI 10.1167/iovs.17-22504
PG 10
WC Ophthalmology
SC Ophthalmology
GA FX1ZL
UT WOS:000425855900015
PM 29332124
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Fuse, A
   Navichkova, Y
   Alloggio, K
AF Fuse, Akiko
   Navichkova, Yuliya
   Alloggio, Krysteena
TI Perception of intelligibility and qualities of non-native accented
   speakers
SO JOURNAL OF COMMUNICATION DISORDERS
LA English
DT Article
DE Non-native accent; Perception of intelligibility; Perceived personal
   qualities; Speech perception; Familiarity; Monolingual; Bilingual;
   Russian accent; Spanish accent; Chinese accent; Indian accent; Native
   English speakers; Speech-language pathology
ID FOREIGN ACCENT; SPEECH-INTELLIGIBILITY; LISTENING COMPREHENSION;
   ENGLISH; LANGUAGE; 2ND-LANGUAGE; FAMILIARITY; ATTITUDES; CHILDREN; NOISE
AB Purpose: To provide effective treatment to clients, speech-language pathologists must be understood, and be perceived to demonstrate the personal qualities necessary for therapeutic practice (e.g., resourcefulness and empathy). One factor that could interfere with the listener's perception of non-native speech is the speaker's accent. The current study explored the relationship between how accurately listeners could understand non-native speech and their perceptions of personal attributes of the speaker. Additionally, this study investigated how listeners' familiarity and experience with other languages may influence their perceptions of non-native accented speech.
   Methods: Through an online survey, native monolingual and bilingual English listeners rated four non-native accents (i.e., Spanish, Chinese, Russian, and Indian) on perceived intelligibility and perceived personal qualities (i.e., professionalism, intelligence, resourcefulness, empathy, and patience) necessary for speech-language pathologists.
   Results: The results indicated significant relationships between the perception of intelligibility and the perception of personal qualities (i.e., professionalism, intelligence, and resourcefulness) attributed to non-native speakers. However, these findings were not supported for the Chinese accent. Bilingual listeners judged the non-native speech as more intelligible in comparison to monolingual listeners. No significant differences were found in the ratings between bilingual listeners who share the same language background as the speaker and other bilingual listeners.
   Conclusions: Based on the current findings, greater perception of intelligibility was the key to promoting a positive perception of personal qualities such as professionalism, intelligence, and resourcefulness, important for speech-language pathologists. The current study found evidence to support the claim that bilinguals have a greater ability in understanding non-native accented speech compared to monolingual listeners. The results, however, did not confirm an advantage for bilingual listeners sharing the same language backgrounds with the non-native speaker over other bilingual listeners.
C1 [Fuse, Akiko; Navichkova, Yuliya; Alloggio, Krysteena] CUNY Brooklyn Coll, Dept Speech Commun Arts & Sci, 4400 Boylan Hall,2900 Bedford Ave, Brooklyn, NY 11210 USA.
RP Fuse, A (corresponding author), CUNY Brooklyn Coll, Dept Speech Commun Arts & Sci, 4400 Boylan Hall,2900 Bedford Ave, Brooklyn, NY 11210 USA.
EM afuse@brooklyn.cuny.edu
CR Amaro J. C., 2012, 3 LANGUAGE ACQUISITI, V46
   American Speech -Language -Hearing Association, 2016, CULTURAL COMPETENCE
   American Speech -Language -Hearing Association, 2016, CHAR ID SLP
   American Speech-Language-Hearing Association, 1998, STUD PROF WHO SPEAK
   American Speech -Language -Hearing Association, 2017, ACC MOD
   Anand S, 2015, J SPEECH LANG HEAR R, V58, P1134, DOI 10.1044/2015_JSLHR-S-14-0243
   Archibald J, 1997, LINGUISTICS, V35, P167, DOI 10.1515/ling.1997.35.1.167
   Batalova J., 2016, MIGRATION INFORM SOU
   Behrman A, 2013, J SPEECH LANG HEAR R, V56, P1567, DOI 10.1044/1092-4388(2013/12-0192)
   Beinhoff B., 2014, CONCORDIA WORKING PA, V5, P58
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Bernthal J., 2017, ARTICULATION PHONOLO
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Cargile AC, 1997, J LANG SOC PSYCHOL, V16, P434, DOI 10.1177/0261927X970164004
   Carlson HK, 2006, J EMPLOYMENT COUNS, V43, P70, DOI 10.1002/j.2161-1920.2006.tb00008.x
   Chen HC, 2010, CONCENTRIC-STUD LING, V36, P183
   Chin SB, 2012, J COMMUN DISORD, V45, P355, DOI 10.1016/j.jcomdis.2012.05.003
   Christiansen T., 2014, TEXTUS, V27, P35
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   COPLAN J, 1988, PEDIATRICS, V82, P447
   DeLacy P, 2007, CAMBRIDGE HANDBOOK OF PHONOLOGY, P1
   Derwing T.M., 1997, STUDIES 2 LANGUAGE A, V19, P1, DOI [10.1017/s0272263197001010, DOI 10.1017/S0272263197001010]
   Drazinski L., 2009, CONTINUUM PROFESSION
   Duff K, 2007, ARCH CLIN NEUROPSYCH, V22, P15, DOI 10.1016/j.acn.2006.08.013
   Eisenchlas SA, 2011, AUST REV APPL LINGUI, V34, P216, DOI 10.1075/aral.34.2.05eis
   Fairbanks G., 1960, VOICE ARTICULATION D
   Fay MP, 2010, STAT SURV, V4, P1, DOI 10.1214/09-SS051
   FLEGE JE, 1984, J ACOUST SOC AM, V76, P692, DOI 10.1121/1.391256
   Flipsen P, 2006, CLIN LINGUIST PHONET, V20, P303, DOI 10.1080/02699200400024863
   Fuertes J N, 2000, Cultur Divers Ethnic Minor Psychol, V6, P211, DOI 10.1037/1099-9809.6.2.211
   Galesic M, 2009, PUBLIC OPIN QUART, V73, P349, DOI 10.1093/poq/nfp031
   GASS S, 1984, LANG LEARN, V34, P65, DOI 10.1111/j.1467-1770.1984.tb00996.x
   George ELJ, 2010, J SPEECH LANG HEAR R, V53, P1429, DOI 10.1044/1092-4388(2010/09-0197)
   Gilakjani A., 2011, ENGLISH LANGUAGE TEA, V4, P74, DOI DOI 10.5539/ELT.V4N3P74
   GILES H, 1971, EDUC REV, V24, P11, DOI 10.1080/0013191710240102
   Giles H., 1983, LANG COMMUN, V3, P302
   Golper L. C., 2007, VISION IDEAL SLP FUT
   Guitart J., 1996, SPANISH CONTACT ISSU, P151
   GUITART JM, 1978, BILINGUAL REV, V5, P57
   Hayes-Harb R, 2008, J PHONETICS, V36, P664, DOI 10.1016/j.wocn.2008.04.002
   Hickey R., 1997, LANGUAGE HIST LINGUI, V1
   Holland A., 2013, COUNSELING COMMUNICA
   Huang BH, 2013, SYSTEM, V41, P770, DOI 10.1016/j.system.2013.07.009
   Jaber M., 2011, ENGLISH LANGUAGE TEA, V4, P77, DOI DOI 10.5539/ELT.V4N4P77
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   Kent R. D., 1994, AM J SPEECH LANG PAT, V3, P81, DOI DOI 10.1044/1058-0360.0302.81
   Kraut R, 2013, J MULTILING MULTICUL, V34, P249, DOI 10.1080/01434632.2013.767340
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Kummer A. W., 2003, ASHA LEADER, V8, P2
   Labov W., 2005, ATLAS N AM ENGLISH P
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   Lev-Ari S, 2010, J EXP SOC PSYCHOL, V46, P1093, DOI 10.1016/j.jesp.2010.05.025
   Levi SV, 2007, J ACOUST SOC AM, V121, P2327, DOI 10.1121/1.2537345
   Levy ES, 2012, COMMUN DISORD Q, V34, P59, DOI 10.1177/1525740111409567
   Levy ES, 2012, COMM DISORD Q, V34, P47, DOI 10.1177/1525740112446851
   Mackay IRA, 2006, APPL PSYCHOLINGUIST, V27, P157, DOI 10.1017/S0142716406060231
   Major RC, 2005, LANG LEARN, V55, P37, DOI 10.1111/j.0023-8333.2005.00289.x
   Major RC, 2002, TESOL QUART, V36, P173, DOI 10.2307/3588329
   MARTIN DC, 1986, PUBLIC PERS MANAGE, V15, P101, DOI 10.1177/009102608601500201
   Moyer A., 2007, J MULTILING MULTICUL, V28, P502, DOI DOI 10.2167/JMMD514.0
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   Munro MJ, 2006, STUD SECOND LANG ACQ, V28, P111, DOI 10.1017/S0272263106060049
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Munro MJ, 2010, SPEECH COMMUN, V52, P626, DOI 10.1016/j.specom.2010.02.013
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nordis M. J., 1983, SPSS 10 STAT ALGORIT
   Pantos AJ, 2013, J LANG SOC PSYCHOL, V32, P3, DOI 10.1177/0261927X12463005
   Patil G. S., 2011, J ALL INDIA I SPEECH, P3067
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   Rennies J, 2014, J ACOUST SOC AM, V136, P2642, DOI 10.1121/1.4897398
   RUBIN DL, 1990, INT J INTERCULT REL, V14, P337, DOI 10.1016/0147-1767(90)90019-S
   Schober-Peterson D., 2011, PERSPECTIVES ADM SUP, V21, P43
   Schwartz I., 2007, P ANN C COUNC AC PRO
   Sikorski Lorna D., 2005, Seminars in Speech and Language, V26, P118, DOI 10.1055/s-2005-871207
   Smith PB, 2004, J CROSS CULT PSYCHOL, V35, P50, DOI 10.1177/0022022103260380
   STEWART MA, 1985, PERS SOC PSYCHOL B, V11, P98, DOI 10.1177/0146167285111009
   Strach P, 2015, POLIT COMMUN, V32, P183, DOI 10.1080/10584609.2014.914614
   Strack F., 1992, CONTEXT EFFECTS SOCI
   Tsurutani C, 2012, J MULTILING MULTICUL, V33, P587, DOI 10.1080/01434632.2012.697465
   Venugopal A., 2012, WNYC NEWS
   Witteman MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P537, DOI 10.3758/s13414-012-0404-y
   Wolfram W., 2006, AM ENGLISH
NR 82
TC 1
Z9 1
U1 0
U2 11
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0021-9924
EI 1873-7994
J9 J COMMUN DISORD
JI J. Commun. Disord.
PD JAN-FEB
PY 2018
VL 71
BP 37
EP 51
DI 10.1016/j.jcomdis.2017.12.006
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FW3GT
UT WOS:000425195500004
PM 29268109
DA 2021-02-24
ER

PT J
AU Bang, HY
   Sonderegger, M
   Kang, Y
   Clayards, M
   Yoon, TJ
AF Bang, Hye-Young
   Sonderegger, Morgan
   Kang, Yoonjung
   Clayards, Meghan
   Yoon, Tae-Jin
TI The emergence, progress, and impact of sound change in progress in Seoul
   Korean: Implications for mechanisms of tonogenesis
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Tonogenesis; Transphonologization; Vowel intrinsic f0; Word frequency;
   Cue tradeoff; Sound change; Korean
ID VOICE-ONSET TIME; SPEAKING RATE; SPEECH-PERCEPTION; VOWEL HEIGHT;
   INTRINSIC F0; FREQUENCY; STOPS; TONE; PHONOLOGY; DURATION
AB This study examines the origin, progression, and impact of a sound change in Seoul Korean where the primary cue to a stop contrast in phrase-initial position is shifting from VOT to f0. Because it shares similarities with the initial phase of tonogenesis, investigating this "quasi-tonogenetic" sound change provides insight into the nature of the emergence of contrastive f0 in "tonogenetic" sound changes more generally. Using a dataset from a large apparent-time corpus of Seoul Korean, we built mixed-effects regression models of VOT and f0 to examine the time-course of change, focusing on word frequency and vowel height effects. We found that both VOT contrast reduction and f0 contrast enhancement are more advanced in high-frequency words and in stops before non high vowels, indicating that the change is spreading across words and phonetic contexts in parallel. Furthermore, speakers suppress non-contrastive variation in f0 as f0 emerges as a primary cue. Our findings suggest that one impetus for tonogenetic change is production bias coupled with an adaptive link between the cues. We further discuss the role of Korean intonational phonology on f0 which may help explain why the phonetic precondition leads to change in Seoul Korean but not in other languages. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Bang, Hye-Young; Sonderegger, Morgan; Clayards, Meghan] McGill Univ, Dept Linguist, Montreal, PQ, Canada.
   [Sonderegger, Morgan; Clayards, Meghan] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Kang, Yoonjung] Univ Toronto, Ctr French & Linguist, Scarborough, ON, Canada.
   [Kang, Yoonjung] Univ Toronto, Dept Linguist, Toronto, ON, Canada.
   [Yoon, Tae-Jin] Sungshin Womens Univ, Dept English Language & Literature, Seoul, South Korea.
RP Bang, HY (corresponding author), 1085 Dr Penfield,Room 111, Montreal, PQ H3A 1A7, Canada.
EM hye-young.bang@mail.mcgill.ca
OI Sonderegger, Morgan/0000-0001-7675-2370
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [430-2014-00018, 435-2014-1504, 890-2012-25]; FRQSC grant [183356]
FX A preliminary version of this paper was published as Bang, Sonderegger,
   Kang, Clayards, and Yoon (2015). We thank audiences at the 2014
   Montreal-Ottawa-Toronto Phonology workshop, ICPhS 2015, and ICKL &
   Harvard-ISOKL 2015, as well as James Kirby for useful feedback. We
   especially thank three anonymous reviewers and the editor (Taehong Cho)
   for their helpful comments. This work was supported by SSHRC grant
   430-2014-00018 and FRQSC grant 183356 to MS, SSHRC grant 435-2014-1504
   to MC, and SSHRC Partnership Development Grant 890-2012-25 to YK.
CR Abramson AS, 2004, PHONETICA, V61, P147, DOI 10.1159/000082561
   Atkinson J. E., 1972, J ACOUST SOC AM, V63, P211
   Aylett M, 2004, LANG SPEECH, V47, P31, DOI 10.1177/00238309040470010201
   Aylett M, 2006, J ACOUST SOC AM, V119, P3048, DOI 10.1121/1.2188331
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Bailey G., 1993, LANG VAR CHANGE, V5, P359
   Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   Baker RE, 2009, LANG SPEECH, V52, P391, DOI 10.1177/0023830909336575
   Bang H.-Y., 2017, 4 WORKSH SOUND CHANG
   Bang H. Y., 2015, P 18 INT C PHON SCI
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, 150604967 ARXIV
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Beckman ME, 2014, LAB PHONOL, V5, P151, DOI 10.1515/lp-2014-0007
   Beddor P.S., 2015, P 18 INT C PHON SCI
   Beddor PS, 2013, J ACOUST SOC AM, V133, P2350, DOI 10.1121/1.4794366
   Beddor PS, 2009, LANGUAGE, V85, P785
   Bell A, 2003, J ACOUST SOC AM, V113, P1001, DOI 10.1121/1.1534836
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   BELLBERTI F, 1975, J ACOUST SOC AM, V57, P456, DOI 10.1121/1.380468
   Bermudez-Otero R., 2015, OXFORD HDB HIST PHON, P374, DOI DOI 10.1093/OXFORDHB/9780199232819.001.0001
   Berry J, 2011, J ACOUST SOC AM, V130, pEL365, DOI 10.1121/1.3651095
   Bush N., 1999, THESIS
   Bybee J.L., 2001, FREQUENCY EMERGENCE
   Bybee J. L, 2012, INITIATION SOUND CHA, P210
   Bybee Joan, 2002, LANG VAR CHANGE, V14, P261, DOI DOI 10.1017/S0954394502143018
   Bybee Joan, 2000, USAGE BASED MODELS L, P65, DOI DOI 10.1093/ACPROF:OSO/9780195301571.003.0009
   Bybee Joan L., 1985, MORPHOLOGY STUDY REL
   CHEN M, 1972, FOUND LANG, V8, P457
   Chen YY, 2011, J PHONETICS, V39, P612, DOI 10.1016/j.wocn.2011.04.001
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Cho TH, 2001, J PHONETICS, V29, P155, DOI 10.1006/jpho.2001.0131
   Clayards M, 2008, THESIS
   Clayards M, 2018, PHONETICA, V75, P1, DOI 10.1159/000448809
   Coetzee A. W., 2014, J ACOUST SOC AM, V135, P2421
   Connell B, 2002, J PHONETICS, V30, P101, DOI 10.1006/jpho.2001.0156
   DiCanio CT, 2012, J PHONETICS, V40, P162, DOI 10.1016/j.wocn.2011.10.006
   Eckert Penelope, 1989, LANG VAR CHANGE, V1, P245, DOI [DOI 10.1017/S095439450000017X, 10.1017/S095439450000017X]
   Esposito A, 2002, PHONETICA, V59, P197, DOI 10.1159/000068347
   Fant G., 2002, P FON TMH QPSR AIX P, P161
   FISCHERJORGENSEN E, 1990, PHONETICA, V47, P99, DOI 10.1159/000261858
   Fruehwald J., 2013, P 40 ANN M N E LING
   Fruehwald J, 2016, LANGUAGE, V92, P376, DOI 10.1353/lan.2016.0041
   Gahl S, 2008, LANGUAGE, V84, P474
   Gelman A., 2007, DATA ANAL USING REGR
   Gelman A, 2015, ARM DATA ANAL USING
   Hagege C., 1978, PHONOLOGIE PANCHRONI
   Han M. S., 1967, STUDIES PHONOLOGY AS, VV
   HAN MS, 1965, STUDIES PHONOLOGY AS, V3
   Hardcastle W. J., 1973, J PHONETICS, V1, P263
   Harrell F, 2001, REGRESSION MODELING, DOI DOI 10.1007/978-3-319-19425-7
   Harrell FE, 2015, SPRINGER SER STAT, DOI 10.1007/978-3-319-19425-7
   Harrell J., 2015, HMISC HARRELL MISCEL
   Harrington J., 2012, HDB LAB PHONOLOGY, P321
   Harrington J, 2016, SMART INNOV SYST TEC, V48, P15, DOI 10.1007/978-3-319-28109-4_3
   Harrington J, 2015, LAB PHONOL, V6, P87, DOI 10.1515/lp-2015-0002
   Hay J, 2016, LANGUAGE, V92, P298, DOI 10.1353/lan.2016.0036
   Hay JB, 2015, COGNITION, V139, P83, DOI 10.1016/j.cognition.2015.02.012
   Higgins MB, 1998, J SPEECH LANG HEAR R, V41, P712, DOI 10.1044/jslhr.4104.712
   HIROSE H, 1972, PHONETICA, V25, P140, DOI 10.1159/000259378
   Hockett Charles F., 1958, COURSE MODERN LINGUI
   Hombert J.-M., 1977, STUDIES AFRICAN LING, V8, P1
   Hombert J.-M., 1974, STUDIES AFRICAN LI S, V5, P169
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   Honda K., 1983, RELATIONSHIP PITCH C, P269
   Honda K., 1994, P 1994 INT C SPOK LA, P157
   Hoole P., 2011, DO PHONOLOGICAL FEAT, P131
   Hoole P., 2006, P 7 INT SEM SPEECH P
   Hooper Joan Bybee, 1976, CURRENT PROGR HIST L, P96
   Hyman L. M, 1976, LINGUISTIC STUDIES O, V2
   Hyman LM, 2008, LINGUIST REV, V25, P83, DOI 10.1515/TLIR.2008.003
   Hyslop G, 2009, LINGUA, V119, P827, DOI 10.1016/j.lingua.2007.11.012
   Jacewicz E, 2009, LANG VAR CHANGE, V21, P233, DOI 10.1017/S0954394509990093
   Jun S. A, 2005, UCLA WORKING PAPERS, V104, P14
   Jun S. A, 1996, UCLA WORKING PAPERS, P14
   Jun S.-A., 1998, PHONOLOGY, V15, P189, DOI DOI 10.1017/S0952675798003571
   Jun SA, 1993, THESIS
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kang KH, 2008, J ACOUST SOC AM, V124, P3909, DOI 10.1121/1.2988292
   Kang Y, 2016, LANG VAR CHANGE, V28, P249, DOI 10.1017/S095439451600003X
   Kang YJ, 2015, LAB PHONOL, V6, P469, DOI 10.1515/lp-2015-0014
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   Kang Y, 2013, LINGUA, V134, P62, DOI 10.1016/j.lingua.2013.06.002
   Keating P., 2003, PAPERS LAB PHONOLOGY, P143, DOI DOI 10.1121/1.380986
   Keshet J., 2014, AUTOVOT TOOL AUTOMAT
   Kessinger RH, 1997, J PHONETICS, V25, P143, DOI 10.1006/jpho.1996.0039
   KIM CW, 1965, WORD, V21, P339, DOI 10.1080/00437956.1965.11435434
   Kim J, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.33
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   KINGSTON J, 1992, LANG SPEECH, V35, P99, DOI 10.1177/002383099203500209
   Kingston J, 2011, BLACKWELL COMPANION, P2304, DOI DOI 10.1017/S0952675713000079
   Kingston J., 2005, ATHABASKAN PROSODY, P137, DOI [DOI 10.1075/CILT.269.09KIN, 10.1075/cilt.269.09kin]
   Kirby J., 2015, P 18 INT C PHON SCI
   Kirby J. P, 2013, ORIGIN SOUND CHANGE
   Kirby JP, 2014, J PHONETICS, V43, P69, DOI 10.1016/j.wocn.2014.02.001
   KLATT DH, 1975, J SPEECH HEAR RES, V18, P686, DOI 10.1044/jshr.1804.686
   Kong EJ, 2011, J PHONETICS, V39, P196, DOI 10.1016/j.wocn.2011.02.002
   Kuznetsova A, 2015, IMERTEST TESTS LINEA
   Labov W., 2010, PRINCIPLES LINGUISTI, V3
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Labov W, 2007, LANGUAGE, V83, P344, DOI 10.1353/lan.2007.0082
   Labov William, 1966, SOCIAL STRATIFICATIO
   Labov William, 1990, LANG VAR CHANGE, V2, P205, DOI [10. 1017/S09543945 00000338, DOI 10.1017/S0954394500000338]
   LADA DR, 1984, PHONETICA, V41, P31
   Lee H, 2013, J PHONETICS, V41, P117, DOI 10.1016/j.wocn.2012.12.002
   Lee H, 2012, J INT PHON ASSOC, V42, P145, DOI 10.1017/S0025100312000035
   Lehiste Isle, 1976, CONT ISSUES EXPT PHO, P225
   Lieberman E, 2007, NATURE, V449, P713, DOI 10.1038/nature06137
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LOFQVIST A, 1989, J ACOUST SOC AM, V85, P1314
   Maran L. R., 1973, CONSONANT TYPES TONE, V1, P97
   Matisoff J. A., 1973, SO CALIFORNIA OCCASI, P72
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   Mazaudon M, 2008, PHONETICA, V65, P231, DOI 10.1159/000192794
   McCrea CR, 2005, J SPEECH LANG HEAR R, V48, P1013, DOI 10.1044/1092-4388(2005/069)
   MILLER JL, 1986, PHONETICA, V43, P106, DOI 10.1159/000261764
   Misnadin M., 2015, P 18 INT C PHON SCI, P1
   Morris RJ, 2008, J PHONETICS, V36, P308, DOI 10.1016/j.wocn.2007.06.003
   Nolan F., 2003, P 15 INT C PHON SCI
   Ogura M., 2012, HDB HIST SOCIOLINGUI, P427
   Oh E, 2011, J PHONETICS, V39, P59, DOI 10.1016/j.wocn.2010.11.002
   Ohala J. J., 2000, CONSONANT TYPES TONE, P3
   Ohala J. J., 2003, P 15 INT C PHON SCI
   Ohala J. J., 1978, TONE LINGUISTIC SURV, P1
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   OHALA JJ, 1993, SPEECH COMMUN, V13, P155, DOI 10.1016/0167-6393(93)90067-U
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Pan SM, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P233
   Phillips BS, 2006, PALGR STUD LANG HIST, P1, DOI 10.1057/9780230286610
   PHILLIPS BS, 1984, LANGUAGE, V60, P320, DOI 10.2307/413643
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   PIND J, 1995, PERCEPT PSYCHOPHYS, V57, P291, DOI 10.3758/BF03213055
   PURCELL ET, 1978, PHONETICA, V35, P284, DOI 10.1159/000259934
   Reubold U., 2015, LANGUAGE DEV LIFESPA, P9
   Roubeau B., 1972, ACTA OTOLARYNGOLICAL, V117, P459
   Sankoff G., 2004, SOCIOLINGUISTIC VARI, P121
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Siddins J., 2015, P 18 INT C PHON SCI, P27
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Silva D. J., 2002, PATHWAYS KOREAN LANG, P447
   Sole M.J., 2007, EXPT APPROACHES PHON, P302
   Soltani M, 2014, J VOICE, V28, DOI 10.1016/j.jvoice.2013.10.012
   Soskuthy M, 2015, LINGUA, V163, P40, DOI 10.1016/j.lingua.2015.05.010
   Stebbins J., 2010, THESIS
   Stevens KN, 1998, ACOUSTIC PHONETICS
   Stevens M, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.003
   Stuart-Smith J, 2015, LAB PHONOL, V6, P505, DOI 10.1515/lp-2015-0015
   SVANTESSON JO, 2006, PHONOLOGY, V23, P309, DOI DOI 10.1017/S0952675706000923
   The National Institute of the Korean Language, 2005, SPEECH CORP READ ST
   TITZE IR, 1989, J ACOUST SOC AM, V85, P1699, DOI 10.1121/1.397959
   Torre P, 2009, J COMMUN DISORD, V42, P324, DOI 10.1016/j.jcomdis.2009.03.001
   Torreira F., 2015, J PHONETICS, V52, P46
   Van Hoof S, 2011, J PHONETICS, V39, P168, DOI 10.1016/j.wocn.2011.02.007
   Wagner SE, 2012, LANG LINGUIST COMPAS, V6, P371, DOI 10.1002/lnc3.343
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   WANG WSY, 1969, LANGUAGE, V45, P9, DOI 10.2307/411748
   Weinreich U., 1968, DIRECTIONS HIST LING, P95
   WHALEN DH, 1995, J ACOUST SOC AM, V97, P2533, DOI 10.1121/1.411973
   WHALEN DH, 1995, J PHONETICS, V23, P349, DOI 10.1016/S0095-4470(95)80165-0
   Wright J., 2007, THESIS
   Yip M., 2002, TONE
   Yoon J., 1999, CSTR99139 KAIST
   Yoon T.-J, 2014, JAPANESE KOREAN LING, V23
   Yoon Tae-Jin, 2014, MALSORIWA UMSENGKWAH, V6, P139
   Zellou G, 2014, J PHONETICS, V47, P18, DOI 10.1016/j.wocn.2014.09.002
   Zhao Y, 2007, P ICPHS 16 SAARBR GE, VXVI, P477
   Zhao Y, 2009, J PHONETICS, V37, P231, DOI 10.1016/j.wocn.2009.03.002
   박한상, 2002, [EONEOHAG, 언어학], V33, P87
NR 173
TC 17
Z9 17
U1 2
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JAN
PY 2018
VL 66
BP 120
EP 144
DI 10.1016/j.wocn.2017.09.005
PG 25
WC Linguistics; Language & Linguistics
SC Linguistics
GA FS8ZP
UT WOS:000422703600008
DA 2021-02-24
ER

PT J
AU Coetzee, AW
   Beddor, PS
   Shedden, K
   Styler, W
   Wissing, D
AF Coetzee, Andries W.
   Beddor, Patrice Speeter
   Shedden, Kerby
   Styler, Will
   Wissing, Daan
TI Plosive voicing in Afrikaans: Differential cue weighting and tonogenesis
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Voicing; Fundamental frequency; Afrikaans; Speech perception;
   Production-perception relation; Cue weighting
ID ONSET TIME; FUNDAMENTAL-FREQUENCY; INDIVIDUAL-DIFFERENCES; PERCEPTION;
   F0; LANGUAGE; CONTRAST; SPANISH; STOPS; FO
AB This study documents the relation between f0 and prevoicing in the production and perception of plosive voicing in Afrikaans. Acoustic data show that Afrikaans speakers differed in how likely they were to produce prevoicing to mark phonologically voiced plosives, but that all speakers produced large and systematic f0 differences after phonologically voiced and voiceless plosives to convey the contrast between the voicing categories. This pattern is mirrored in these same participants' perception: although some listeners relied more than others on prevoicing as a perceptual cue, all listeners used f0 (especially in the absence of prevoicing) to perceptually differentiate historically voiced and voiceless plosives. This variation in the speech community is shown to be generationally structured such that older speakers were more likely than younger speakers to produce prevoicing, and to rely on prevoicing perceptually. These patterns are consistent with generationally determined differential cue weighting in the speech community and with an ongoing sound change in which the original consonantal voicing contrast is being replaced by a tonal contrast on the following vowel. (C) 2017 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Coetzee, Andries W.; Beddor, Patrice Speeter; Shedden, Kerby; Styler, Will] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Coetzee, Andries W.; Wissing, Daan] North West Univ, ZA-2531 Potchefstroom, South Africa.
RP Coetzee, AW (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.; Coetzee, AW (corresponding author), North West Univ, ZA-2531 Potchefstroom, South Africa.
EM coetzee@umich.edu
FU NSFNational Science Foundation (NSF) [BCS-1348150]; Direct For Social,
   Behav & Economic ScieNational Science Foundation (NSF)NSF - Directorate
   for Social, Behavioral & Economic Sciences (SBE) [1348150] Funding
   Source: National Science Foundation; Division Of Behavioral and
   Cognitive SciNational Science Foundation (NSF)NSF - Directorate for
   Social, Behavioral & Economic Sciences (SBE) [1348150] Funding Source:
   National Science Foundation
FX This work is supported by NSF Grant BCS-1348150 to Patrice Speeter
   Beddor and Andries W. Coetzee. Earlier versions of this work were
   presented at the 3rd Biennial Workshop on Sound Change (2014, Berkeley,
   CA), the 167th Meeting of the Acoustical Society of America (2014,
   Providence, RI) and the Annual Meeting of the Linguistic Society of
   Southern Africa (2015, Potchefstroom, South Africa). We also thank the
   audiences at several universities where we have discussed this research,
   and in particular James Kirby, Bob Ladd and Phil Hoole for valuable
   feedback on this project.<SUP>10</SUP>
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Abramson A. S., 1975, STAT REP HASKINS LAB, V41, P165
   Abramson AS, 2017, J PHONETICS, V63, P75, DOI 10.1016/j.wocn.2017.05.002
   Amemiya T., 1985, ADV ECONOMETRICS
   Bailey Guy, 2002, HDB LANGUAGE VARIATI, P312
   Bang H.-Y., 2015, ICPHS
   Bates D., 2013, IME4 LINEAR MIXED EF
   Beddor PS, 2009, LANGUAGE, V85, P785
   Boersma P., 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Boersma P., 2013, PRAAT DOING PHONETIC
   Brunelle M., 2009, J SE ASIAN LINGUISTI, V2, P1
   Collins B., 2003, PHONETICS ENGLISH DU
   Davidson L, 2016, J PHONETICS, V54, P35, DOI 10.1016/j.wocn.2015.09.003
   DEBOOR C, 1978, APPL MATH SCI SERIES, V27
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   Ewan W., 1974, J PHONETICS, V2, P327, DOI 10.1016/S0095-4470(19)31302-6
   Green P.J., 1994, NONPARAMETRIC REGRES
   Gussenhoven C., 1999, HDB INT PHONETIC ASS, P74
   HAGGARD M, 1970, J ACOUST SOC AM, V47, P613, DOI 10.1121/1.1911936
   Halle Morris, 1971, MIT Q PROGR REPORT, V101, P198
   Hanson HM, 2009, J ACOUST SOC AM, V125, P425, DOI 10.1121/1.3021306
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Hombert J., 1978, TONE LINGUISTIC SURV, P77
   Hombert Jean-Marie, 1977, STUDIES AFRICAN LING, V8, P173
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   Honda K, 1999, LANG SPEECH, V42, P401, DOI 10.1177/00238309990420040301
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   Jessen M, 1999, PHONETICS PHONOLOGY
   Jun Sun-Ah, 1996, UCLA WORKING PAPERS, V92, P97
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   Kang Y, 2013, LINGUA, V134, P62, DOI 10.1016/j.lingua.2013.06.002
   Kim M.-R., 2000, THESIS
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kingston J, 2011, BLACKWELL COMPANION, P2304, DOI DOI 10.1017/S0952675713000079
   Kingston J., 2005, ATHABASKAN PROSODY, P137, DOI [DOI 10.1075/CILT.269.09KIN, 10.1075/cilt.269.09kin]
   Kirby J., 2013, ORIGINS SOUND CHANGE, P228, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0011
   Kirby J., 2015, P 18 INT C PHON SCI
   Kirby JP, 2016, J ACOUST SOC AM, V140, P2400, DOI 10.1121/1.4962445
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kuznetsova A., 2016, IMERTEST TESTS LINEA
   LABOV W, 1963, WORD, V19, P273, DOI 10.1080/00437956.1963.11659799
   Labov William, 1965, GEORGETOWN MONOGRAPH, V18, P91
   Labov William, 1966, SOCIAL STRATIFICATIO
   Labov William, 1972, SOCIOLINGUISTIC PATT
   Le Roux T.H., 1927, AFRIKAANSE FONETIEK
   LEHISTE I, 1961, J ACOUST SOC AM, V33, P419, DOI 10.1121/1.1908681
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Liu M., 2015, PRODUCTION IDENTIFIC
   Llanos F, 2013, J ACOUST SOC AM, V134, P2213, DOI 10.1121/1.4817845
   LOFQVIST A, 1975, PHONETICA, V31, P228
   LOFQVIST A, 1989, J ACOUST SOC AM, V85, P1314
   Maddieson Ian, 1993, OCEAN LINGUIST, V24, P75
   Maran L. R., 1973, CONSONANT TYPES TONE, P98
   MASSARO DW, 1976, J ACOUST SOC AM, V60, P704, DOI 10.1121/1.381143
   MASSARO DW, 1977, PERCEPT PSYCHOPHYS, V22, P373, DOI 10.3758/BF03199703
   Matisoff J. A., 1973, SO CALIFORNIA OCCASI, P72
   Mees I., 1982, J INT PHON ASSOC, V12, P2
   Myers S, 2003, PHONETICA, V60, P71, DOI 10.1159/000071448
   Myers S, 1999, STUDIES AFRICAN LING, V28, P215
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P235
   Ohala J. J, 1973, SO CALIFORNIA OCCASI, P1
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Pearce M, 2009, LINGUA, V119, P846, DOI 10.1016/j.lingua.2007.10.023
   PEARCE MARY, 2005, U COLL LONDON WORKIN, V17, P61
   Pinget A., 2015, THESIS
   R Core Team, 2013, R LANG ENV STAT COMP
   Sankoff G., 2006, ENCY LANGUAGE LINGUI, P110, DOI DOI 10.1016/B0-08-044854-2/01479-6
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Simon E, 2009, SECOND LANG RES, V25, P377, DOI 10.1177/0267658309104580
   SLIS IH, 1969, LANG SPEECH, V12, P80, DOI 10.1177/002383096901200202
   Sun JY, 2000, ANN STAT, V28, P429, DOI 10.1214/aos/1016218225
   SVANTESSON JO, 2006, PHONOLOGY, V23, P309, DOI DOI 10.1017/S0952675706000923
   Tagliamonte Sali A., 2012, VARIATIONIST SOCIOLI
   Thurgood G, 1996, LANGUAGE, V72, P1, DOI 10.2307/416792
   Thurgood G., 2002, DIACHRONICA, V19, P333, DOI DOI 10.1075/DIA.19.2.04THU
   van Alphen P. M., 2004, PERCEPTUAL RELEVANCE
   van Alphen PM, 2004, J PHONETICS, V32, P455, DOI 10.1016/j.wocn.2004.05.001
   Van Wyk E.B., 1977, PRAKTIESE FONETIEK V
   Verhoeven J., 2005, J INT PHONETIC ASS, V35, P243, DOI [10.1017/S0025100305002173, DOI 10.1017/S0025100305002173]
   Vietti A., PHONOLOGY IN PRESS
   Wagner SE, 2012, LANG LINGUIST COMPAS, V6, P371, DOI 10.1002/lnc3.343
   WESTBURY JR, 1983, J ACOUST SOC AM, V73, P1322, DOI 10.1121/1.389236
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Wissing Daan, 1982, ALGEMENE AFRIKAANSE
   Xu Y, 2001, PHONETICA, V58, P26, DOI 10.1159/000028487
   Xu Y, 1999, P 14 INT C PHON SCI, P1881
   Yu A. C. L., 2013, ORIGINS SOUND CHANGE, P201, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0010
NR 90
TC 24
Z9 25
U1 3
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JAN
PY 2018
VL 66
BP 185
EP 216
DI 10.1016/j.wocn.2017.09.009
PG 32
WC Linguistics; Language & Linguistics
SC Linguistics
GA FS8ZP
UT WOS:000422703600011
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Walker, A
   Hay, J
   Drager, K
   Sanchez, K
AF Walker, Abby
   Hay, Jennifer
   Drager, Katie
   Sanchez, Kauyumari
TI Divergence in speech perception
SO LINGUISTICS
LA English
DT Article
DE perception; adaptation; attitudes; divergence
ID NEW-ZEALAND ENGLISH; CONVERGENCE; EXPECTATIONS; IMITATION; GENDER
AB This paper presents results from an experiment designed to test whether New Zealand listeners' perceptual adaptation towards Australian English is mediated by their attitudes toward Australia, which we attempted to manipulate experimentally. Participants were put into one of three conditions, where they either read good facts about Australia, bad facts about Australia, or no facts about Australia (the control). Participants performed the same listening task - matching the vowel in a sentence to a vowel in a synthesized continuum - before and after reading the facts. The results indicate that participants who read the bad facts shifted their perception of KIT to more Australian-like tokens relative to the control group, while the participants who read good facts shifted their perception of KIT to more NZ-like tokens relative to the control group. This result shows that perceptual adaptation towards a dialect can occur in the absence of a speaker of that dialect and that these adaptations are subject to a listener's (manipulated) affect towards the primed dialect region.
C1 [Walker, Abby] Virginia Polytech Inst & State Univ, Dept English, 409 Shanks Hall,181 Turner St NW, Blacksburg, VA 24061 USA.
   [Hay, Jennifer] Univ Canterbury, Dept Linguist, Private Bag 4800, Christchurch, New Zealand.
   [Drager, Katie] Univ Hawaii Manoa, Dept Linguist, 1890 East West Rd,Moore Hall 569, Honolulu, HI 96822 USA.
   [Sanchez, Kauyumari] Humboldt State Univ, Dept Psychol, Behav & Social Sci Bldg 410,1 Harpst St, Arcata, CA 95519 USA.
RP Walker, A (corresponding author), Virginia Polytech Inst & State Univ, Dept English, 409 Shanks Hall,181 Turner St NW, Blacksburg, VA 24061 USA.
EM ajwalker@vt.edU; jen.hay@canterbury.ac.nz; kdrager@hawaii.edu;
   kauyumari.sanchez@humboldt.edu
FU Rutherford Discovery Fellowship
FX The authors would like to acknowledge the valuable feedback from the
   reviewers and the time of our participants. This project was funded in
   part by a Rutherford Discovery Fellowship awarded to the second author.
CR Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Baumeister R. F., 2001, REV GEN PSYCHOL, V5, P323, DOI [10.1037//1089-2680.5.4.323., DOI 10.1037/1089-2680.5.4.323]
   Bayard D, 2000, MOD SPRAK, V94, P8
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Bourhis R. Y., 1977, LANGUAGE ETHNICITY I, V13, P119
   Bourhis R. Y., 1979, LANGUAGE SOCIAL PSYC, P158
   Cox F, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P342
   Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914
   Dijksterhuis A, 2003, PSYCHOL SCI, V14, P14, DOI 10.1111/1467-9280.t01-1-01412
   Drager K., 2010, TE REO, V53, P27
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   GILES H, 1973, ANTHROPOL LINGUIST, V15, P87
   Giles H., 1972, LANG SOC, V2, DOI [https://doi.org/10.1017/S0047404500000701, DOI 10.1017/S0047404500000701]
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Hay J, 2010, LANG SPEECH, V53, P447, DOI 10.1177/0023830910372489
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Hay Jennifer, 2008, NZ ENGLISH
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   Koops Christian, 2008, U PENNSYLVANIA WORKI, V14, P93
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   McMurray B, KLATTWORKS SOM UNPUB
   NATALE M, 1975, J PERS SOC PSYCHOL, V32, P790, DOI 10.1037/0022-3514.32.5.790
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Palma de Figueiredo Roja, 2015, J EUROPEAN PSYCHOL S, V6, P53
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Peeters G., 1990, EUROPEAN REV SOCIAL, V1, P33, DOI [DOI 10.1080/14792779108401856, 10.1080/14792779108401856.]
   Powesland P. F., 1975, SPEECH STYLE SOCIAL
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Smith A, 2004, SPORT NATL IDENTITY, P168
   Staum-Casasanto L., 2010, PENN WORKING PAPERS, V15, P40
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Sumner M, 2013, J ACOUST SOC AM, V134, pEL485, DOI 10.1121/1.4826151
   Walker Abby, 2014, THESIS
   Weatherholtz K, 2014, LANG VAR CHANGE, V26, P387, DOI 10.1017/S0954394514000155
   Wells John C., 1982, ACCENTS OF ENGLISH, V1
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
NR 43
TC 3
Z9 3
U1 1
U2 6
PU DE GRUYTER MOUTON
PI BERLIN
PA GENTHINER STRASSE 13, 10785 BERLIN, GERMANY
SN 0024-3949
EI 1613-396X
J9 LINGUISTICS
JI Linguistics
PD JAN
PY 2018
VL 56
IS 1
BP 257
EP 278
DI 10.1515/ling-2017-0036
PG 22
WC Linguistics; Language & Linguistics
SC Linguistics
GA FS6WK
UT WOS:000419938900007
DA 2021-02-24
ER

PT J
AU Yaguchi, A
   Hidaka, S
AF Yaguchi, Ayako
   Hidaka, Souta
TI Distinct Autistic Traits Are Differentially Associated With the Width of
   the Multisensory Temporal Binding Window
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Autism spectrum disorder; audiovisual interaction; temporal-binding
   window; flash-beep illusion
ID SPECTRUM QUOTIENT AQ; FUNCTIONING AUTISM; SPEECH-PERCEPTION;
   INTEGRATION; SYNCHRONY; ILLUSIONS; VALIDITY; ADULTS
AB Autism spectrum disorder (ASD) is a neurodevelopmental disorder characterized by deficits in social communication and interaction, and restricted interests and behavior patterns. These characteristics are considered as a continuous distribution in the general population. People with ASD show atypical temporal processing in multisensory integration. Regarding the flash-beep illusion, which refers to how a single flash can be illusorily perceived as multiple flashes when multiple auditory beeps are concurrently presented, some studies reported that people with ASD have a wider temporal binding window and greater integration than typically developed people; others found the opposite or inconsistent tendencies. Here, we investigated the relationships between the manner of the flash-beep illusion and the various dimensions of ASD traits by estimating the degree of typically developed participants' ASD traits including five subscales using the Autism-Spectrum Quotient. We found that stronger ASD traits of communication and social skill were associated with a wider and narrower temporal binding window respectively. These results suggest that specific ASD traits are differently involved in the particular temporal binding processes of audiovisual integration.
C1 [Yaguchi, Ayako; Hidaka, Souta] Rikkyo Univ, Dept Psychol, 1-2-26 Kitano, Niiza, Saitama 3528558, Japan.
RP Yaguchi, A (corresponding author), Rikkyo Univ, Dept Psychol, 1-2-26 Kitano, Niiza, Saitama 3528558, Japan.
EM yaguchi@rikkyo.ac.jp
RI Hidaka, Souta/L-6393-2019
OI Hidaka, Souta/0000-0001-6727-5322
FU JSPSMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of Science [15K12615]
FX We thank Junichi Takahashi for his comments on early versions of the
   manuscript. This research was supported by a Grant-in-Aid for
   Challenging Exploratory Research from JSPS (No. 15K12615).
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Andersen TS, 2004, COGNITIVE BRAIN RES, V21, P301, DOI 10.1016/j.cogbrainres.2004.06.004
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S., 1995, MINDBLINDNESS ESSAY
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Calvert GA, 2004, J PHYSIOL-PARIS, V98, P191, DOI 10.1016/j.jphysparis.2004.03.018
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   Davis J, 2017, BRIT J PSYCHOL, V108, P191, DOI 10.1111/bjop.12188
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Donohue SE, 2012, EXP BRAIN RES, V222, P377, DOI 10.1007/s00221-012-3223-4
   Donohue SE, 2010, ATTEN PERCEPT PSYCHO, V72, P1120, DOI 10.3758/APP.72.4.1120
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   FRITH U, 1991, AUTISM ASPERGERS SYN
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Hoekstra RA, 2008, J AUTISM DEV DISORD, V38, P1555, DOI 10.1007/s10803-008-0538-x
   Horder J, 2014, J AUTISM DEV DISORD, V44, P1461, DOI 10.1007/s10803-013-2012-7
   Jung M, 2014, MOL AUTISM, V5, DOI 10.1186/2040-2392-5-35
   Keane BP, 2010, RES AUTISM SPECT DIS, V4, P276, DOI 10.1016/j.rasd.2009.09.015
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Palmer CJ, 2015, J AUTISM DEV DISORD, V45, P1291, DOI 10.1007/s10803-014-2289-1
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Shams L, 2002, COGNITIVE BRAIN RES, V14, P147, DOI 10.1016/S0926-6410(02)00069-1
   Spence C, 2003, CURR BIOL, V13, pR519, DOI 10.1016/S0960-9822(03)00445-7
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   van der Smagt MJ, 2007, J AUTISM DEV DISORD, V37, P2014, DOI 10.1007/s10803-006-0346-0
   Wakabayashi Akio, 2004, Shinrigaku Kenkyu, V75, P78
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Wheelwright S, 2010, MOL AUTISM, V1, DOI 10.1186/2040-2392-1-10
   Woodbury-Smith MR, 2005, J AUTISM DEV DISORD, V35, P331, DOI 10.1007/s10803-005-3300-7
NR 36
TC 9
Z9 9
U1 0
U2 1
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 6
BP 523
EP 536
DI 10.1163/22134808-00002612
PG 14
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FX4BB
UT WOS:000426015700002
PM 31264616
DA 2021-02-24
ER

PT J
AU Clayards, M
AF Clayards, Meghan
TI Individual Talker and Token Covariation in the Production of Multiple
   Cues to Stop Voicing
SO PHONETICA
LA English
DT Article
ID ONSET-TIME; SPEAKING-RATE; FUNDAMENTAL-FREQUENCY; SPEECH-PERCEPTION;
   ACOUSTIC CUES; ENGLISH; CONTEXT; INTELLIGIBILITY; VARIABILITY;
   INTEGRATION
AB Background/Aims: Previous research found that individual talkers have consistent differences in the production of segments impacting the perception of their speech by others. Speakers also produce multiple acoustic-phonetic cues to phonological contrasts. Less is known about how multiple cues covary within a phonetic category and across talkers. We examined differences in individual talkers across cues and whether token-by-token variability is a result of intrinsic factors or speaking style by examining within-category correlations. Methods: We examined correlations for 3 cues (voice onset time, VOT, talker-relative onset fundamental frequency, f0, and talker-relative following vowel duration) to word-initial labial stop voicing in English. Results: VOT for /b/ and /p/ productions and onset f0 for /b/ productions varied significantly by talker. Token-by-token within-category variation was largely limited to speaking rate effects. VOT and f0 were negatively correlated within category for /b/ productions after controlling for speaking rate and talker mean f0, but in the opposite direction expected for an intrinsic effect. Within-category talker means were correlated across VOT and vowel duration for /p/ productions. Some talkers produced more prototypical values than others, indicating systematic talker differences. Conclusion: Relationships between cues are mediated more by categories and talkers than by intrinsic physiological relationships. Talker differences reflect systematic speaking style differences. (c) 2017 S. Karger AG, Basel
C1 [Clayards, Meghan] McGill Univ, Sch Commun Sci & Disorders, Dept Linguist, 2001 McGill Coll,8th Floor, Montreal, PQ H3A 1G1, Canada.
RP Clayards, M (corresponding author), McGill Univ, Sch Commun Sci & Disorders, Dept Linguist, 2001 McGill Coll,8th Floor, Montreal, PQ H3A 1G1, Canada.
EM meghan.clayards@mcgill.ca
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [DC-005071]; FQRSC [145433]
FX Data collection was supported by NIH research grant DC-005071 to Michael
   K. Tanenhaus and Richard N. Aslin and by FQRSC grant 145433 to the
   author.
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Baese-Berk M, 2009, LANG COGNITIVE PROC, V24, P527, DOI 10.1080/01690960802299378
   BAILEY PJ, 1980, J EXP PSYCHOL HUMAN, V6, P536
   Bang H. Y., 2015, P 18 INT C PHON SCI
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma P., 2011, PRAAT DOING PHONETIC
   Boucher VJ, 2002, PERCEPT PSYCHOPHYS, V64, P121, DOI 10.3758/BF03194561
   Buzz E, 2014, P 36 ANN C COGN SCI
   Chodroff E., 2015, P 18 INT C PHON SCI
   Clayards M, 2008, THESIS
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cole J, 2007, J PHONETICS, V35, P180, DOI 10.1016/j.wocn.2006.03.004
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Ferguson SH, 2004, J ACOUST SOC AM, V116, P2365, DOI 10.1121/1.1788730
   Fox NP, 2015, J MEM LANG, V83, P97, DOI 10.1016/j.jml.2015.04.002
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   GOLDINGER S, 1989, RES SPEECH PERCEPTIO, V15, P331
   Goldstein L., 2006, LAB PHONOLOGY, V1-8, P367
   Green D. M., 1966, SIGNAL DETECTION THE
   Hazan V, 2004, J ACOUST SOC AM, V116, P3108, DOI 10.1121/1.1806826
   Hazan V., 2011, P 17 INT C PHON SCI, P839
   Holt LL, 2001, J ACOUST SOC AM, V109, P764, DOI 10.1121/1.1339825
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   Hoole P., 2011, DO PHONOLOGICAL FEAT, P131, DOI 10.1075/lfab.6.06hoo
   Hoole P, 2004, P C VOIC PHYS BIOM M
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   JOHNSON K, 1993, J ACOUST SOC AM, V94, P701, DOI 10.1121/1.406887
   Kessinger RH, 1997, J PHONETICS, V25, P143, DOI 10.1006/jpho.1996.0039
   Kessinger RH, 1998, J PHONETICS, V26, P117, DOI 10.1006/jpho.1997.0069
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kingston J, 2008, J PHONETICS, V36, P28, DOI 10.1016/j.wocn.2007.02.001
   Kirby J., 2013, ORIGINS SOUND CHANGE, P228, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0011
   Kirby J., 2015, P 18 INT C PHON SCI
   Kirby JP, 2016, J ACOUST SOC AM, V140, P2400, DOI 10.1121/1.4962445
   Kirby James P., 2010, THESIS
   Kliegl R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2010.00238
   KOHLER KJ, 1979, PHONETICA, V36, P332, DOI 10.1159/000259970
   Krause JC, 2009, J ACOUST SOC AM, V125, P3346, DOI 10.1121/1.3097491
   LEHISTE I, 1961, J ACOUST SOC AM, V33, P419, DOI 10.1121/1.1908681
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   MACK M, 1982, J ACOUST SOC AM, V71, P173, DOI 10.1121/1.387344
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   Matuschek H, 2015, BALANCING TYPE I ERR
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2008, PSYCHON B REV, V15, P1064, DOI 10.3758/PBR.15.6.1064
   MILLER JL, 1986, PHONETICA, V43, P106, DOI 10.1159/000261764
   Nearey T, 1986, EXPT PHONOLOGY, P121
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Noiray A, 2014, LAB PHONOL, V5, P271, DOI 10.1515/lp-2014-0010
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   OHDE RN, 1984, J ACOUST SOC AM, V75, P224, DOI 10.1121/1.390399
   PORT RF, 1981, J ACOUST SOC AM, V69, P262, DOI 10.1121/1.385347
   PORT RF, 1982, PERCEPT PSYCHOPHYS, V32, P141, DOI 10.3758/BF03204273
   R Core Team, 2016, R LANG ENV STAT COMP
   Raphael LJ, 2005, BLACKW HBK LINGUIST, P182, DOI 10.1002/9780470757024.ch8
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   SLIS IH, 1969, LANG SPEECH, V12, P80, DOI 10.1177/002383096901200202
   Smiljanic R, 2009, LANG LINGUIST COMPAS, V3, P236, DOI 10.1111/j.1749-818x.2008.00112.x
   Sonderegger M, 2015, P 18 INT C PHON SCI
   Sussman HM, 1998, BEHAV BRAIN SCI, V21, P241, DOI 10.1017/S0140525X98001174
   Theodore RM, 2015, J ACOUST SOC AM, V138, P1068, DOI 10.1121/1.4927489
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   UMEDA N, 1981, J ACOUST SOC AM, V70, P350, DOI 10.1121/1.386783
   WANG WSY, 1961, J SPEECH HEAR RES, V4, P130, DOI 10.1044/jshr.0402.130
NR 75
TC 11
Z9 11
U1 0
U2 6
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0031-8388
EI 1423-0321
J9 PHONETICA
JI Phonetica
PY 2018
VL 75
IS 1
BP 1
EP 23
DI 10.1159/000448809
PG 23
WC Acoustics; Audiology & Speech-Language Pathology; Linguistics; Language
   & Linguistics
SC Acoustics; Audiology & Speech-Language Pathology; Linguistics
GA FQ8WJ
UT WOS:000418643600001
PM 28595176
OA Bronze
DA 2021-02-24
ER

PT J
AU Lin, CY
   Cheng, CX
   Wang, M
AF Lin, Candise Y.
   Cheng, Chenxi
   Wang, Min
TI The contribution of phonological and morphological awareness in
   Chinese-English bilingual reading acquisition
SO READING AND WRITING
LA English
DT Article
DE Phonological awareness; Morphological awareness; Cross-language
   transfer; English reading; Chinese reading
ID CROSS-LANGUAGE TRANSFER; WORD RECOGNITION; BILITERACY ACQUISITION;
   HONG-KONG; LINGUISTIC INTERDEPENDENCE; DEVELOPMENTAL DYSLEXIA;
   VOCABULARY KNOWLEDGE; SPEAKING CHILDREN; SPEECH-PERCEPTION; CONTENT
   VALIDITY
AB The current study examined the contribution of cross-language phonological and morphological awareness to reading acquisition in bilingual children. Participants were 140 children (M (age) = 8.26 years) between Grades 1-4 who learned Chinese as their first language and English as their second language. Awareness of phoneme, onset-rime, compound structures and polysemy (i.e. words with multiple meanings) were measured using conceptually comparable tasks in both languages. Oral vocabulary, single word reading, and reading comprehension were also assessed. Path analysis revealed significant direct effects from Chinese rime awareness to both English word reading and reading comprehension. English phoneme awareness also had a significant direct effect on Chinese word reading. There was a significant direct effect from Chinese polyseme identification to English reading comprehension. Awareness of compound structure in one language also had indirect effects on reading outcomes in the other language via within-language compound structure awareness. These finding provided evidence for bi-directional cross-language phonological and morphological transfer in Chinese-English bilingual reading acquisition.
C1 [Lin, Candise Y.] Univ Southern Calif, Dept Psychol, Los Angeles, CA USA.
   [Cheng, Chenxi; Wang, Min] Univ Maryland, Dept Human Dev & Quantitat Methodol, 3304C Benjamin Bldg, College Pk, MD 20742 USA.
RP Wang, M (corresponding author), Univ Maryland, Dept Human Dev & Quantitat Methodol, 3304C Benjamin Bldg, College Pk, MD 20742 USA.
EM candisel@usc.edu; cxc815@gmail.com; minwang@umd.edu
FU NIH/NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD048438]
FX The current study was based on part of the second author's dissertation
   project under the third author's supervision. The current study was
   supported by the NIH/NICHD R01 grant (R01HD048438) awarded to the third
   author. The first author took the leadership in re-analyzing the data
   and writing up the manuscript. We would like to thank Dr. Ji Seung Yang
   for her valuable advice and assistance in running the path analysis.
CR American Speech-Language-Hearing Association [ASHA], 2004, KNOWL SKILLS NEED SP
   Berninger V., 1999, MORPHOLOGICAL UNPUB
   Bialystok E, 2005, SCI STUD READ, V9, P43, DOI 10.1207/s1532799xssr0901_4
   BYRNE B, 1995, J EDUC PSYCHOL, V87, P488, DOI 10.1037/0022-0663.87.3.488
   Carlisle J. F., 1995, MORPHOLOGICAL ASPECT, P189, DOI DOI 10.4236/PSYCH.2014.58103
   Ceccagno A, 2006, LINGUE LINGUAGGIO, V5, P233, DOI 10.1418/23145
   Ceccagno A, 2007, MORPHOLOGY, V17, P207, DOI 10.1007/s11525-008-9119-0
   Chen X, 2009, READ WRIT, V22, P615, DOI 10.1007/s11145-008-9127-9
   Cheung H, 2010, J EDUC PSYCHOL, V102, P367, DOI 10.1037/a0017850
   Cho JR, 2008, READ WRIT, V21, P255, DOI 10.1007/s11145-007-9072-z
   Chow BWY, 2008, DEV PSYCHOL, V44, P233, DOI 10.1037/0012-1649.44.1.233
   Chow BWY, 2005, J EDUC PSYCHOL, V97, P81, DOI 10.1037/0022-0663.97.1.81
   Chung KKH, 2013, J RES READ, V36, P202, DOI 10.1111/j.1467-9817.2011.01500.x
   Chung KKH, 2010, J LEARN DISABIL-US, V43, P195, DOI 10.1177/0022219409345018
   CISERO CA, 1995, CONTEMP EDUC PSYCHOL, V20, P275, DOI 10.1006/ceps.1995.1018
   CUMMINS J, 1979, REV EDUC RES, V49, P222, DOI 10.3102/00346543049002222
   de Jong PF, 1999, J EDUC PSYCHOL, V91, P450, DOI 10.1037/0022-0663.91.3.450
   Dressler Wolfgang U., 2006, REPRESENTATION PROCE, P23
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Epskamp S, 2014, SEMPLOT PATH DIAGRAM
   Genesee F., 2006, DEV LITERACY 2 LANGU, P153
   Gertken LM, 2014, SECOND LANG ACQUIS, V78, P208
   Goswami U., 1990, PHONOLOGICAL SKILLS
   Gottardo A, 2001, J EDUC PSYCHOL, V93, P530, DOI 10.1037/0022-0663.93.3.530
   Hatcher PJ, 2004, J CHILD PSYCHOL PSYC, V45, P338, DOI 10.1111/j.1469-7610.2004.00225.x
   Haynes SN, 1995, PSYCHOL ASSESSMENT, V7, P238, DOI 10.1037/1040-3590.7.3.238
   Ho CSH, 1997, J PSYCHOLINGUIST RES, V26, P109, DOI 10.1023/A:1025016322316
   Hu CF, 1998, SCI STUD READ, V2, P55, DOI DOI 10.1207/S1532799XSSR0201_3
   Hulme C, 2002, J EXP CHILD PSYCHOL, V82, P2, DOI 10.1006/jecp.2002.2670
   Jastak J., 1984, WIDE RANGE ACHIEVEME
   Jiang X., 2011, READING MATRIX, V11, P177
   Kang S., 2005, J CHINESE LANGUAGE C, V15, P103
   Kim YS, 2009, READ WRIT, V22, P843, DOI 10.1007/s11145-008-9132-z
   Koda K., 2008, LEARNING READ LANGUA, P68
   Koda K., 2007, LANG LEARN, V57, P1, DOI DOI 10.1111/0023-8333.101997010-I1
   Krashen S., 1983, LANGUAGE TRANSFER LA, P135
   Kuo L. J., 2007, LEARNING READ LANGUA, P39
   LEGARRETA D, 1979, TESOL QUART, V13, P521, DOI 10.2307/3586447
   Liu PD, 2013, APPL PSYCHOLINGUIST, V34, P755, DOI 10.1017/S014271641200001X
   Liu PD, 2010, J EDUC PSYCHOL, V102, P62, DOI 10.1037/a0016933
   Luo YC, 2014, WRIT LANG LIT, V17, P89, DOI 10.1075/wll.17.1.05luo
   McBride-Chang C, 2006, READ WRIT, V19, P695, DOI 10.1007/s11145-005-5742-x
   McBride-Chang C, 2005, J EXP CHILD PSYCHOL, V92, P140, DOI 10.1016/j.jecp.2005.03.009
   McBride-Chang C, 2003, J EDUC PSYCHOL, V95, P743, DOI 10.1037/0022-0663.95.4.743
   McBride-Chang C, 2008, SCI STUD READ, V12, P171, DOI 10.1080/10888430801917290
   McBride-Chang C, 2008, J CHILD PSYCHOL PSYC, V49, P211, DOI 10.1111/j.1469-7610.2007.01837.x
   [孟红霞 Meng Hongxia], 2014, [心理学报, Acta Psychologica Sinica], V46, P36
   Nagy W, 2006, J EDUC PSYCHOL, V98, P134, DOI 10.1037/0022-0663.98.1.134
   Nagy W, 2003, J EDUC PSYCHOL, V95, P730, DOI 10.1037/0022-0663.95.4.730
   Nagy W., 2002, CHINESE CHILDRENS RE, P58, DOI 10.1007/978-1-4615-0859-5_4
   Nicoladis E, 2002, J CHILD LANG, V29, P843, DOI 10.1017/S0305000902005366
   Nicoladis E., 2003, BILING-LANG COGN, V6, P17, DOI [10.1017/S1366728903001019S1366728903001019, DOI 10.1017/S1366728903001019]
   Odlin T., 1989, LANGUAGE TRANSFER
   Packard J.L., 2000, MORPHOLOGY CHINESE L
   Pasquarella A, 2011, J RES READ, V34, P23, DOI 10.1111/j.1467-9817.2010.01484.x
   Polit DF, 2006, RES NURS HEALTH, V29, P489, DOI 10.1002/nur.20147
   R Core Team, 2017, R LANGUAGE ENV STAT
   Rispens JE, 2008, READ WRIT, V21, P587, DOI 10.1007/s11145-007-9077-7
   Robertson G. J., 2001, WIDE RANGE ACHIEVEME, V133, DOI [10.1037/0022-0663.98.1.122, DOI 10.1037/0022-0663.98.1.122]
   Rosseel Y, 2012, J STAT SOFTW, V48, P1, DOI 10.18637/jss.v048.i02
   Saiegh-Haddad E, 2008, READ WRIT, V21, P481, DOI 10.1007/s11145-007-9074-x
   Shu H, 2006, J EDUC PSYCHOL, V98, P122, DOI 10.1037/0022-0663.98.1.122
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Shuanfan H., 1998, NEW APPROACHES CHINE, P261, DOI DOI 10.1515/9783110809084.261
   Siok WT, 2001, DEV PSYCHOL, V37, P886, DOI 10.1037//0012-1649.37.6.886
   Sproat R., 1999, YB MORPHOLOGY, V1998, P289
   Tong XH, 2017, CONTEMP EDUC PSYCHOL, V48, P167, DOI 10.1016/j.cedpsych.2016.07.003
   Tong XH, 2014, BRAIN LANG, V138, P61, DOI 10.1016/j.bandl.2014.09.004
   TREIMAN R, 1995, J MEM LANG, V34, P132, DOI 10.1006/jmla.1995.1007
   TROIKE R, 1978, NABE J, V3, P13
   VERHOEVEN LT, 1994, LANG LEARN, V44, P381, DOI 10.1111/j.1467-1770.1994.tb01112.x
   Wang M, 2006, J EDUC PSYCHOL, V98, P148, DOI 10.1037/0022-0663.98.1.148
   Wang M, 2005, COGNITION, V97, P67, DOI 10.1016/j.cognition.2004.10.001
   Wang M., 2014, READING DEV DIFFICUL, P191
   Wang M, 2008, READ WRIT, V21, P627, DOI 10.1007/s11145-007-9081-y
   Wang M, 2006, J EDUC PSYCHOL, V98, P542, DOI 10.1037/0022-0663.98.3.542
   Wang M, 2009, CONTEMP EDUC PSYCHOL, V34, P132, DOI 10.1016/j.cedpsych.2008.12.002
   Wang M, 2009, APPL PSYCHOLINGUIST, V30, P291, DOI 10.1017/S0142716409090122
   Wang Y, 2016, APPL PSYCHOLINGUIST, V37, P371, DOI 10.1017/S014271641500003X
   Wu XY, 2009, SCI STUD READ, V13, P26, DOI 10.1080/10888430802631734
   Yeung SS, 2013, BRIT J EDUC PSYCHOL, V83, P550, DOI 10.1111/j.2044-8279.2012.02082.x
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 82
TC 6
Z9 6
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0922-4777
EI 1573-0905
J9 READ WRIT
JI Read. Writ.
PD JAN
PY 2018
VL 31
IS 1
BP 99
EP 132
DI 10.1007/s11145-017-9775-8
PG 34
WC Education & Educational Research; Psychology, Educational
SC Education & Educational Research; Psychology
GA FR9JP
UT WOS:000419390200005
DA 2021-02-24
ER

PT J
AU Galic, J
   Popovic, B
   Pavlovic, DS
AF Galic, Jovan
   Popovic, Branislav
   Pavlovic, Dragana Sumarac
TI Whispered Speech Recognition using Hidden Markov Models and Support
   Vector Machines
SO ACTA POLYTECHNICA HUNGARICA
LA English
DT Article
DE Automatic Speech Recognition; Hidden Markov Models; Support Vector
   Machines; Whispered speech; Whi-Spe speech database
AB Whisper is a specific mode of speech characterized by turbulent airflow at the glottis level. Despite an increased effort in speech perception, the intelligibility of whisper in human communication is very high. An enormous acoustic mismatch between normally phonated (neutral) and whispered speech is the main reason why modern Automatic Speech Recognition (ASR) systems have significant drop of performances when applied to whisper. In this paper, we present an analysis in recognition of whisper using 2 machine-learning techniques: Hidden Markov Models (HMM) and Support Vector Machines (SVM). The experiments are conducted in both Speaker Dependent (SD) and Speaker Independent (SI) fashion for Whi-Spe speech database. The best neutral-trained whisper recognition accuracy in SD fashion (83.36%) is obtained in SVM framework. At the same time, HMM-based recognition gave the highest recognition accuracy in SI fashion (87.42%). The results in recognition of neutral speech are given as well.
C1 [Galic, Jovan; Pavlovic, Dragana Sumarac] Univ Belgrade, Sch Elect Engn, Bulevar Kralj Aleksandra 73, Belgrade 11120, Serbia.
   [Galic, Jovan] Univ Banja Luka, Fac Elect Engn, Patre 5, Banja Luka 78000, Bosnia & Herceg.
   [Popovic, Branislav] Univ Novi Sad, Fac Tech Sci, Dept Power Elect & Telecommun Engn, Chair Telecommun & Signal Proc, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
RP Galic, J (corresponding author), Univ Belgrade, Sch Elect Engn, Bulevar Kralj Aleksandra 73, Belgrade 11120, Serbia.; Galic, J (corresponding author), Univ Banja Luka, Fac Elect Engn, Patre 5, Banja Luka 78000, Bosnia & Herceg.
EM jovan.galic@etf.unibl.org; bpopovic@uns.ac.rs; dsumarac@etf.rs
OI Popovic, Branislav/0000-0002-5413-1028
FU Ministry of Education, Science and Technological Development of the
   Republic of Serbia [OI178027, TR32032, TR32035]; EUREKA project DANSPLAT
   "A Platform for the Applications of Speech Technologies on Smartphones
   for the Languages of the Danube Region" [9944]; Provincial Secretariat
   for Higher Education and Scientific Research within project "Central
   Audio-Library of the University of Novi Sad" [114-451-2570/2016-02]
FX This work is partially supported by the Ministry of Education, Science
   and Technological Development of the Republic of Serbia under grants
   OI178027, TR32032, and TR32035, EUREKA project DANSPLAT, "A Platform for
   the Applications of Speech Technologies on Smartphones for the Languages
   of the Danube Region", id.! 9944, and the Provincial Secretariat for
   Higher Education and Scientific Research, within the project "Central
   Audio-Library of the University of Novi Sad", No. 114-451-2570/2016-02.
CR Babani D, 2011, INT CONF ACOUST SPEE, P5224
   Baranyi P., 2015, COGNITIVE INFOCOMMUN
   Baranyi P, 2012, ACTA POLYTECH HUNG, V9, P67
   Chaves JB, 2005, P ISCA TUT RES WORKS, P137
   Croft William, 2004, COGNITIVE LINGUISTIC
   Fan X, 2011, EUR SIGNAL PR CONF, P1500
   Fan X, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1313
   Galic J., 2018, SPIIRAS P J
   Galic J, 2014, LECT NOTES ARTIF INT, V8773, P251, DOI 10.1007/978-3-319-11581-8_31
   GARCIACABELLOS JM, 2004, P EUSIPCO 2004, P2067
   Ghaffarzadegan Shabnam, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2544, DOI 10.1109/ICASSP.2014.6854059
   Ghaffarzadegan S., 2014, INTERSPEECH 2014, P2420
   Ghaffarzadegan S, 2016, IEEE-ACM T AUDIO SPE, V24, P1705, DOI 10.1109/TASLP.2016.2580944
   Gong CH, 2009, 2009 INTERNATIONAL FORUM ON COMPUTER SCIENCE-TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P429, DOI 10.1109/IFCSTA.2009.227
   Grozdic D, 2017, ADV ELECTR COMPUT EN, V17, P21, DOI 10.4316/AECE.2017.01004
   Grozdic DT, 2017, ENG APPL ARTIF INTEL, V59, P15, DOI 10.1016/j.engappai.2016.12.012
   Grozdic DT, 2014, 2014 12TH SYMPOSIUM ON NEURAL NETWORK APPLICATIONS IN ELECTRICAL ENGINEERING (NEUREL), P157, DOI 10.1109/NEUREL.2014.7011492
   Ito T., 2005, SPEECH COMMUN, P129, DOI DOI 10.1016/J.SPEC0M.2003.10.005
   Jakovljevic N., 2013, THESIS
   Jou S.-C., 2004, P INTERSPEECH JEJ IS, P1493
   Jovicic ST, 2008, J VOICE, V22, P263, DOI 10.1016/j.jvoice.2006.08.012
   Jovicic ST, 1998, ACUSTICA, V84, P739
   Kiss G, 2017, INT CONF COGN INFO, P213, DOI 10.1109/CogInfoCom.2017.8268245
   Kozierski Piotr, 2016, Przeglad Elektrotechniczny, V92, P301, DOI 10.15199/48.2016.11.70
   Markovic B, 2013, LECT NOTES COMPUT SC, V8082, P591, DOI 10.1007/978-3-642-40585-3_74
   Markovic BR, 2018, ARCH ACOUST, V43, P3, DOI 10.24425/118075
   Popovic B., 2014, 10 DIG SPEECH IM PRO, P31
   Qu ZY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 2, PROCEEDINGS, P100
   Riviello MT, 2012, ACTA POLYTECH HUNG, V9, P157
   Rusko M, 2016, INT CONF COGN INFO, P181, DOI 10.1109/CogInfoCom.2016.7804546
   Stas J, 2016, INT CONF COGN INFO, P133, DOI 10.1109/CogInfoCom.2016.7804538
   TARTTER VC, 1991, PERCEPT PSYCHOPHYS, V49, P365, DOI 10.3758/BF03205994
   Tesic L, 2017, ACTA POLYTECH HUNG, V14, P197
   THOMAS IB, 1969, J ACOUST SOC AM, V46, P468, DOI 10.1121/1.1911712
   Toda T, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P636
   Tundik MA, 2017, INT CONF COGN INFO, P67, DOI 10.1109/CogInfoCom.2017.8268218
   Vaughan B, 2012, ACTA POLYTECH HUNG, V9, P7
   Zhang C., 2007, INTERSPEECH, P2289
   Zhang C, 2010, CONF REC ASILOMAR C, P1707, DOI 10.1109/ACSSC.2010.5757831
   Zhang C, 2011, IEEE T AUDIO SPEECH, V19, P883, DOI 10.1109/TASL.2010.2066967
   Zhang C, 2010, INT CONF ACOUST SPEE, P5170, DOI 10.1109/ICASSP.2010.5495022
NR 41
TC 0
Z9 0
U1 0
U2 1
PU BUDAPEST TECH
PI BUDAPEST
PA BECSI UT 96-B, BUDAPEST, H-1034, HUNGARY
SN 1785-8860
J9 ACTA POLYTECH HUNG
JI Acta Polytech. Hung.
PY 2018
VL 15
IS 5
SI SI
BP 11
EP 29
PG 19
WC Engineering, Multidisciplinary
SC Engineering
GA GZ0LW
UT WOS:000449055300002
DA 2021-02-24
ER

PT J
AU Gosy, M
   Krepsz, V
AF Gosy, Maria
   Krepsz, Valeria
TI Evaluation of Cognitive Processes using Synthesized Words: Screening of
   Hearing and Global Speech Perception
SO ACTA POLYTECHNICA HUNGARICA
LA English
DT Article
DE synthesized speech; frequency cues; cognitive processes; evaluation of
   speech processing
ID CHILDREN; LANGUAGE; CUES
AB This study focuses on children's cognitive capability within the framework of cognitive infocommunication. Speech processing works in quasi-parallel in time between hearing and speech comprehension. Hierarchical operations are decisive for elaboration of the speech signal. To test children's speech processing quickly and reliably is of great importance both for language acquisition and for learning to read and write. Specific speech synthesis using sufficient, but not redundant spectral cues highlight hearing and global speech perception processes. 644 monolingual Hungarian children aged between 4 and 8 years participated in the study. 20 monosyllables were specially synthesized based on a set of pre-determined spectral values. Children were asked to repeat what they heard. The combination of speech synthesis as information and communication technology with the study of cognitive capabilities is a new direction in research and practice. Our results show that the great majority of children were confirmed to have good hearing (about 95%), while some children had a previously unknown hearing impairment. More than 30% of all children encountered speech perception deficit, despite good hearing. Digital technology including speech synthesis has reshaped both speech science and its cognitive connections to get closer to a proper interpretation of the mechanisms analyzed.
C1 [Gosy, Maria; Krepsz, Valeria] Hungarian Acad Sci, Res Inst Linguist, Benczur U 33, H-1068 Budapest, Hungary.
RP Gosy, M (corresponding author), Hungarian Acad Sci, Res Inst Linguist, Benczur U 33, H-1068 Budapest, Hungary.
EM gosy.maria@nytud.mta.hu; krepsz.valeria@nytud.mta.hu
CR Aitchison J., 2012, WORDS MIND INTRO MEN
   Baranyi P., 2010, 11 IEEE INT S COMP I
   Baranyi P., 2015, COGNITIVE INFOCOMMUN
   Baranyi P, 2012, ACTA POLYTECH HUNG, V9, P67
   Bishara L, 1999, Int Tinnitus J, V5, P107
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   Briscoe J, 2001, J CHILD PSYCHOL PSYC, V42, P329, DOI 10.1017/S0021963001007041
   DesJardin JL, 2009, INT J AUDIOL, V48, P248, DOI 10.1080/14992020802607423
   Eisenberg LS, 2000, J ACOUST SOC AM, V107, P2704, DOI 10.1121/1.428656
   Fuess R. V. L, 2002, ENT-EAR NOSE THROAT, V4, P123
   Gosy M, 2008, HUMAN FACTORS VOICE, P127
   Gosy M, 1992, SPEECH PERCEPTION
   Gosy M., 1987, P 11 ICPHS, V4, P185
   Guberina P., 1972, CASE STUDIES USE RES
   Hazan V, 1983, SPEECH HEARING LANGU, V3, P41
   Heald S. L., 2014, FRONTIERS SYSTEMS NE, V8, P1, DOI DOI 10.3389/FNINS.2014
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Hugdahl K, 2003, ASYMMETRICAL BRAIN, P441
   JOHNSON CD, 1997, ED AUDIOLOGY HDB
   Kemaloglu YK, 2005, INT J PEDIATR OTORHI, V69, P209, DOI 10.1016/j.ijporl.2004.08.018
   Krepsz V, 2018, BESZEDKUTATAS, V26, P156
   Mohammad F. T., 2007, J MED SCI, V7, P1362
   Moleti A, 2003, J ACOUST SOC AM, V113, P423, DOI 10.1121/1.1523389
   Olaszy G, 1985, MAGYAR BESZED LEGGYA
   Phillips DP, 2010, J AM ACAD AUDIOL, V21, P404, DOI 10.3766/jaaa.21.6.5
   Stover L, 1996, J ACOUST SOC AM, V100, P956, DOI 10.1121/1.416207
   Winn MB, 2012, J ACOUST SOC AM, V131, P1465, DOI 10.1121/1.3672705
NR 27
TC 14
Z9 14
U1 0
U2 0
PU BUDAPEST TECH
PI BUDAPEST
PA BECSI UT 96-B, BUDAPEST, H-1034, HUNGARY
SN 1785-8860
J9 ACTA POLYTECH HUNG
JI Acta Polytech. Hung.
PY 2018
VL 15
IS 5
SI SI
BP 31
EP 45
PG 15
WC Engineering, Multidisciplinary
SC Engineering
GA GZ0LW
UT WOS:000449055300003
DA 2021-02-24
ER

PT J
AU Mestnikova, AZ
   Gogolev, II
   Diab, KM
   Machalov, AS
   Fedotova, EE
   Vasilieva, EM
AF Mestnikova, A. Z.
   Gogolev, I. I.
   Diab, Kh. M.
   Machalov, A. S.
   Fedotova, E. E.
   Vasilieva, E. M.
TI RESULTS OF COCHLEAR IMPLANTATION IN THE REPUBLIC OF SAKHA (YAKUTIA)
SO YAKUT MEDICAL JOURNAL
LA English
DT Article
DE cochlear implantation; sensorineural hearing loss; inner ear
AB The article discusses the priorities of cochlear implantation (CI) in the RS (Ya). The results of the CI in Yakutsk to 11 children are presented. All patients in the preoperative period underwent general clinical examination, examination of ENT organs, earmicroscopy, acoustic impedance measurement, a study of otoacoustic emission and short-latency auditory evoked potentials research. A computed tomography of temporal bones with a 2 mm cut thickness was also performed. All patients were examined by a speech therapist and the faculty for the purpose of determining the level of general development, auditory and speech perception and development of speech.
   All patients were operated using Neurelec implants (France).
   The need for further introduction of high-tech care for children to improve the quality of life was noted.
C1 [Mestnikova, A. Z.; Gogolev, I. I.] Pediat Ctr State Autonomous Inst Republ Hosp 1 NC, Dept Otorhinolaryngol, Yakutsk, Russia.
   [Diab, Kh. M.] Federal Med Biol Agcy Russian Federat, Dept Ear Dis, Fed State Budgetary Inst, Clin Res Ctr Otorhinolaryngol, Moscow, Russia.
   [Machalov, A. S.] FGBU NKTsO FMBA RF, Sci & Clin Dept Audiol Hearing & Hearing Rehabil, Moscow, Russia.
   [Machalov, A. S.] Russian Natl Res Med Univ, Otorhinolaryngol Fac, Addit Vocat Educ, Moscow, Russia.
   [Fedotova, E. E.; Vasilieva, E. M.] Republican Audiol Ctr, Yakutsk, Russia.
RP Mestnikova, AZ (corresponding author), Pediat Ctr State Autonomous Inst Republ Hosp 1 NC, Dept Otorhinolaryngol, Yakutsk, Russia.
EM Ain-o4ka_13@mail.ru; innokentiy.gogolev@mail.ru; Hasandiab@mail.ru;
   sakhasurdo@mail.ru; vasilevalena70@mail.ru
CR Cejas I, 2015, PEDIATR HEALTH MED T, V6, P45, DOI 10.2147/PHMT.S65797
   Fedoseev V. I., 2014, Vestnik Otorinolaringologii, P17
   Tavartkiladze G. A., 2016, Vestnik Otorinolaringologii, P4, DOI 10.17116/otorino20168164-8
   Tavartkiladze G. A., 2016, Vestnik Otorinolaringologii, P7, DOI 10.17116/otorino20168127-12
   Tokat T, 2018, J CRANIOFAC SURG, V10, P1097
NR 5
TC 0
Z9 0
U1 0
U2 0
PU RUSSIAN ACAD SCIENCES SIBERIAN BRANCH
PI NOVOSIBIRSK
PA S P C  U I G G M  S B  R A S, 3 AKADEMIKA KOPTYGA PROSPEKT, 630090
   NOVOSIBIRSK, RUSSIA
SN 1813-1905
EI 2312-1017
J9 YAKUT MED J
JI Yakut Med. J.
PY 2018
IS 3
BP 69
EP 71
PG 3
WC Medicine, Research & Experimental
SC Research & Experimental Medicine
GA GY8IY
UT WOS:000448869500023
DA 2021-02-24
ER

PT J
AU van den Bunt, MR
   Groen, MA
   van der Kleij, SW
   Noordenbos, MW
   Segers, E
   Pugh, KR
   Verhoeven, L
AF van den Bunt, M. R.
   Groen, M. A.
   van der Kleij, S. W.
   Noordenbos, M. W.
   Segers, E.
   Pugh, K. R.
   Verhoeven, L.
TI Deficient Response to Altered Auditory Feedback in Dyslexia
SO DEVELOPMENTAL NEUROPSYCHOLOGY
LA English
DT Article
ID ARCUATE FASCICULUS; SPEECH PRODUCTION; DEVELOPMENTAL DYSLEXIA;
   PHONOLOGICAL REPRESENTATIONS; ALLOPHONIC MODE; READING FLUENCY; FAMILIAL
   RISK; CHILDREN; PERCEPTION; ADULTS
AB Although dyslexia is characterized by a deficit in phonological representations, the nature of this deficit is debated. Previously, it was shown that adults with dyslexia respond differently to online manipulations of auditory feedback. In the present study, we found that individual differences in reading and reading-related skills within a group of 30 children (10-13 years old) with dyslexia were associated with the response to altered feedback. The fractional anisotropy of the arcuate fasciculus/superior longitudinal fasciculus was not directly related to the response to altered feedback. This study corroborates that speech perception-production communication is important for phonological representations and reading.
C1 [van den Bunt, M. R.; Groen, M. A.; van der Kleij, S. W.; Segers, E.; Verhoeven, L.] Radboud Univ Nijmegen, Behav Sci Inst, Nijmegen, Netherlands.
   [Noordenbos, M. W.] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.
   [Pugh, K. R.] Yale Univ, Haskins Labs, New Haven, CT USA.
RP van den Bunt, MR (corresponding author), Montessorilaan 3, NL-6525 HR Nijmegen, Netherlands.
EM m.vandenbunt@pwo.ru.nl
RI Noordenbos, Mark W/E-7886-2012; Groen, Margriet/A-5087-2012
OI Groen, Margriet/0000-0002-6178-2937
FU Nederlandse Organisatie voor Wetenschappelijk OnderzoekNetherlands
   Organization for Scientific Research (NWO)European Commission
   [275-89-017]
FX This work was supported by the Nederlandse Organisatie voor
   Wetenschappelijk Onderzoek [#275-89-017];
CR Andrews JS, 2010, DEV MED CHILD NEUROL, V52, pE94, DOI 10.1111/j.1469-8749.2009.03456.x
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernal B, 2009, BRAIN, V132, P2309, DOI 10.1093/brain/awp206
   Blomert L., 2006, PROTOCOL DIAGNOSTIEK
   Boada R, 2006, J EXP CHILD PSYCHOL, V95, P153, DOI 10.1016/j.jecp.2006.04.003
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Borgwaldt S. R., 2005, READ WRIT, V18, P211, DOI [10.1007/s11145-005-3001-9, DOI 10.1007/S11145-005-3001-9]
   Brus B.T., 1973, EEN MINUUT TEST
   Cai S., 2008, PROCEEDINGS OF THE 8, P65
   Catani M, 2008, CORTEX, V44, P1105, DOI 10.1016/j.cortex.2008.05.004
   Catani M, 2008, CORTEX, V44, P953, DOI 10.1016/j.cortex.2008.04.002
   CATTS HW, 1989, J SPEECH HEAR DISORD, V54, P422, DOI 10.1044/jshd.5403.422
   CATTS HW, 1986, J LEARN DISABIL, V19, P504, DOI 10.1177/002221948601900813
   de Jong PF, 2003, J EDUC PSYCHOL, V95, P22, DOI 10.1037/0022-0663.95.1.22
   Dougherty RF, 2007, P NATL ACAD SCI USA, V104, P8556, DOI 10.1073/pnas.0608961104
   Elbro C, 1998, READ RES QUART, V33, P36, DOI 10.1598/RRQ.33.1.3
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Foy JG, 2012, READ WRIT, V25, P799, DOI 10.1007/s11145-011-9300-4
   Furnes B, 2011, LEARN INDIVID DIFFER, V21, P85, DOI 10.1016/j.lindif.2010.10.005
   Georgiou GK, 2008, J EDUC PSYCHOL, V100, P566, DOI 10.1037/0022-0663.100.3.566
   GESCHWIND N, 1972, SCI AM, V226, P76, DOI 10.1038/scientificamerican0472-76
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Gullick MM, 2015, DEV COGN NEUROS-NETH, V13, P68, DOI 10.1016/j.dcn.2015.05.002
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Hakvoort B, 2015, CORTEX, V63, P90, DOI 10.1016/j.cortex.2014.08.013
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Kamali A, 2014, BRAIN STRUCT FUNCT, V219, P269, DOI 10.1007/s00429-012-0498-y
   Kort NS, 2014, NEUROIMAGE, V86, P525, DOI 10.1016/j.neuroimage.2013.09.042
   Kort W., 2005, DST NL DYSLEXIE SCRE
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Lane H, 1997, J ACOUST SOC AM, V101, P2244, DOI 10.1121/1.418245
   Langer N, 2017, CEREB CORTEX, V27, P1027, DOI 10.1093/cercor/bhv281
   Law JM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00482
   Lebel C, 2013, BRAIN LANG, V125, P215, DOI 10.1016/j.bandl.2012.10.009
   Lebel C, 2009, HUM BRAIN MAPP, V30, P3563, DOI 10.1002/hbm.20779
   Long MA, 2016, NEURON, V89, P1187, DOI 10.1016/j.neuron.2016.01.032
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   MacDonald EN, 2012, CURR BIOL, V22, P113, DOI 10.1016/j.cub.2011.11.052
   Malek Ayyoub, 2013, ISRN Pediatr, V2013, P165193, DOI 10.1155/2013/165193
   Matsumoto R, 2004, BRAIN, V127, P2316, DOI 10.1093/brain/awh246
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Nelson JM, 2015, ANN DYSLEXIA, V65, P159, DOI 10.1007/s11881-015-0105-z
   Niziolek CA, 2013, J NEUROSCI, V33, P12090, DOI 10.1523/JNEUROSCI.1008-13.2013
   Noordenbos MW, 2012, RES DEV DISABIL, V33, P1469, DOI 10.1016/j.ridd.2012.03.021
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Pugh KR, 2000, MENT RETARD DEV D R, V6, P207, DOI 10.1002/1098-2779(2000)6:3<207::AID-MRDD8>3.3.CO;2-G
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   R Core Team, 2015, R LANG ENV STAT COMP
   Rabiner L., 1978, DIGITAL PROCESSING S
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Rollins NK, 2009, RADIOLOGY, V251, P882, DOI 10.1148/radiol.2513080884
   Scheerer NE, 2016, NEUROSCIENCE, V314, P106, DOI 10.1016/j.neuroscience.2015.11.037
   Schmahmann JD, 2006, FIBER PATHWAYS BRAIN
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Share DL, 2008, PSYCHOL BULL, V134, P584, DOI 10.1037/0033-2909.134.4.584
   Shaywitz BA, 2002, BIOL PSYCHIAT, V52, P101, DOI 10.1016/S0006-3223(02)01365-3
   SMITH CR, 1975, J SPEECH HEAR RES, V18, P795, DOI 10.1044/jshr.1804.795
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Smith SM, 2006, NEUROIMAGE, V31, P1487, DOI 10.1016/j.neuroimage.2006.02.024
   SNOWLING MJ, 1981, PSYCHOL RES-PSYCH FO, V43, P219, DOI 10.1007/BF00309831
   Sprugevica I, 2003, SCAND J PSYCHOL, V44, P119, DOI 10.1111/1467-9450.00329
   Steinbrink C, 2008, NEUROPSYCHOLOGIA, V46, P3170, DOI 10.1016/j.neuropsychologia.2008.07.015
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x
   Tilanus EAT, 2016, DYSLEXIA, V22, P214, DOI 10.1002/dys.1533
   Tourville J. A., 2013, P 165 M AC SOC AM MO
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Van Den Bos K. P., 2014, CB WL CONTINU BENOEM
   van den Bunt MR, 2017, J SPEECH LANG HEAR R, V60, P654, DOI 10.1044/2016_JSLHR-L-16-0201
   Vandermosten M, 2015, DEV COGN NEUROS-NETH, V14, P8, DOI 10.1016/j.dcn.2015.05.006
   Vandermosten M, 2012, BRAIN, V135, P935, DOI 10.1093/brain/awr363
   Woolrich MW, 2009, NEUROIMAGE, V45, pS173, DOI 10.1016/j.neuroimage.2008.10.055
   Yeatman JD, 2013, BRAIN LANG, V125, P146, DOI 10.1016/j.bandl.2012.04.010
NR 77
TC 1
Z9 1
U1 0
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 8756-5641
EI 1532-6942
J9 DEV NEUROPSYCHOL
JI Dev. Neuropsychol.
PY 2018
VL 43
IS 7
BP 622
EP 641
DI 10.1080/87565641.2018.1495723
PG 20
WC Psychology, Developmental; Psychology; Psychology, Experimental
SC Psychology
GA GV9RU
UT WOS:000446498600006
PM 30001162
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Abdrabbou, MF
   Tucker, DA
   Compton, MV
   Mankoff, L
AF Abdrabbou, Marwa F.
   Tucker, Denise A.
   Compton, Mary, V
   Mankoff, Lyn
TI Quality of life and speech perception in two late deafened adults with
   cochlear implants
SO AUDIOLOGY RESEARCH
LA English
DT Article
DE Cochlear implants; biopsychosocial; late-deafened adults; quality of
   life
ID HEARING-LOSS; PERFORMANCE
AB The aim was to demonstrate the need for a quality of life assessment in biopsychosocial aural rehabilitation (AR) practices with late deafened adults (LDAs) with cochlear implants (CIs).
   We present a case report of a medical records review of two LDAs enrolled in a biopsychosocial group AR program. A speech perception test Contrasts for Auditory and Speech Training (CAST) and a quality of life (QoL) assessment the Nijmegen Cochlear Implant Questionnaire (NCIQ) were given prior to AR therapy. CAST scores indicated both patients had excellent basic speech perception. However, NCIQ results revealed patients' difficulties in basic and advanced listening settings. NCIQ highlighted patients' self-perceived poor self-esteem and ongoing challenges to their QoL. Speech perception testing results alone are not enough to document the daily challenges of QoL needs of LDAs with CIs. The inclusion of a QoL measure such as the NCIQ is vital in evaluating outcomes of cochlear implantation in LDAs.
C1 [Abdrabbou, Marwa F.; Tucker, Denise A.; Compton, Mary, V; Mankoff, Lyn] Univ North Carolina Greensboro, Dept Commun Sci & Disorders, 524 Highland Ave, Greensboro, NC 27402 USA.
RP Tucker, DA (corresponding author), Univ North Carolina Greensboro, Dept Commun Sci & Disorders, 524 Highland Ave, Greensboro, NC 27402 USA.
EM datucker@uncg.edu
CR Bodmer D, 2007, LARYNGOSCOPE, V117, P1408, DOI 10.1097/MLG.0b013e318068b57e
   Boothroyd Arthur, 2007, Trends Amplif, V11, P63, DOI 10.1177/1084713807301073
   Buhagiar R, 2011, Cochlear Implants Int, V12 Suppl 2, pS44, DOI 10.1179/146701011X13074645127559
   Capretta NR, 2016, LARYNGOSCOPE, V126, P699, DOI 10.1002/lary.25525
   Erdman S., 2014, ADULT AUDIOLOGIC REH
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Linguisystem, 2003, CONTR AUD SPEECH PER
   Martin W, 2008, OTOL NEUROTOL, V29, P615, DOI 10.1097/MAO.0b013e318172cfac
   Mo B, 2005, EAR HEARING, V26, P186, DOI 10.1097/00003446-200504000-00006
   Montano J. J., 2014, ADULT AUDIOLOGIC REH
   Phan NT, 2016, AUST FAM PHYSICIAN, V45, P366
   Preminger JE, 2010, J AM ACAD AUDIOL, V21, P315, DOI 10.3766/jaaa.21.5.4
   Tucker D, 2011, ASHA LEAD, V16, P24
   van Dijk JE, 1999, AUDIOLOGY, V38, P109
NR 14
TC 0
Z9 0
U1 0
U2 0
PU PAGEPRESS PUBL
PI PAVIA
PA MEDITGROUP, VIA G BELLI, 4, PAVIA, 27100, ITALY
SN 2039-4330
EI 2039-4349
J9 AUDIOL RES
JI Audiol. Res.
PY 2018
VL 8
IS 1
BP 1
EP 4
AR 194
DI 10.4081/audiores.2018.194
PG 4
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA GV6TX
UT WOS:000446250200001
PM 29725521
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Brown, T
   Murray, E
   McCabe, P
AF Brown, Tayla
   Murray, Elizabeth
   McCabe, Patricia
TI The boundaries of auditory perception for within-word syllable
   segregation in untrained and trained adult listeners
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE Auditory perception; apraxia of speech; speech perception; syllable
   segregation
ID GAP DETECTION; CHILDHOOD APRAXIA; DIAGNOSTIC MARKER; SPEECH; CHILDREN;
   INTELLIGIBILITY; RELIABILITY; EXPERIENCE
AB Syllable segregation is among the core diagnostic features of both childhood apraxia of speech and acquired apraxia of speech; however, little is known about the limen of perception of syllable segregation. The purpose of this research was therefore to explore adult listeners' auditory perception of within-word syllable segregation in trained and untrained adult listeners.Two experimental design studies, each with two phases, were conducted. Study one included 40 untrained listeners (aged 18-28years), and study two included 5 trained listeners (10-25years of experience). Recorded audio samples of multisyllabic non-words were manipulated to insert gaps of increasing length to simulate syllable segregation. All stimuli were anchored against an unaltered control sample. In each phase, 32 stimuli were randomly presented twice in a free-field listening task with listeners making Yes/No decisions to record their perception of segregation.At a 90% accuracy threshold, the untrained listeners' limen was 90ms, while the trained listeners' was 85ms. At an 80% accuracy threshold, both sets of listeners had a limen of 80ms. Overall, there were no significant differences in accuracy between the two listening groups. Gap duration was positively correlated with accurate perception across both studies. Both groups demonstrated good intra-rater reliability and excellent inter-rater reliability, with no significant differences between the untrained and trained listeners.These findings have implications for developing a standardised criteria for rating syllable segregation in clinical contexts. No evidence was found for the hypothesis that training makes a difference in listeners' accuracy or reliability when rating syllable segregation.
C1 [Brown, Tayla; Murray, Elizabeth; McCabe, Patricia] Univ Sydney, Speech Pathol, Sydney, NSW, Australia.
RP McCabe, P (corresponding author), Univ Sydney, Dept Speech Pathol, 75 East St, Lidcombe, NSW 2141, Australia.
EM tricia.mccabe@sydney.edu.au
OI McCabe, Patricia/0000-0002-5182-1007; Murray,
   Elizabeth/0000-0002-0883-155X
CR ABRAMSON JH, 2010, PROGRAMS EPIDEMIOLOG
   Altman DG, 1991, PRACTICAL STAT MED R, V1, P396
   American Speech-Language-Hearing Association, 2007, TECHNICAL REPORT
   American Speech-Language-Hearing Association Audiologic Assessment Panel, 1996, GUID AUD SCREEN
   Awan SN, 2009, J VOICE, V23, P341, DOI 10.1016/j.jvoice.2007.10.006
   Boersma P. P. G, 2001, PRAAT SYSTEM DOING P
   BOOTHROYD A, 1985, J SPEECH HEAR RES, V28, P185, DOI 10.1044/jshr.2802.185
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Brinca L, 2015, J VOICE, V29, DOI 10.1016/j.jvoice.2015.01.007
   Cohen J, 1992, CURRENT DIRECTIONS P, V1, P98, DOI [10.1111/1467-8721.ep10768783, DOI 10.1111/1467-8721.EP10768783]
   Donai JJ, 2016, J ACOUST SOC AM, V139, pEL128, DOI 10.1121/1.4947070
   Eadie TL, 2011, J SPEECH LANG HEAR R, V54, P430, DOI 10.1044/1092-4388(2010/09-0205)
   Eadie TL, 2010, J VOICE, V24, P564, DOI 10.1016/j.jvoice.2008.12.005
   Gierut JA, 2010, AM J SPEECH-LANG PAT, V19, P167, DOI 10.1044/1058-0360(2009/09-0020)
   Goy H, 2013, J VOICE, V27, P545, DOI 10.1016/j.jvoice.2013.03.002
   Heldner M, 2011, J ACOUST SOC AM, V130, P508, DOI 10.1121/1.3598457
   IBM Corp, 2014, IBM SPSS STAT WIND V
   KENT RD, 1983, J SPEECH HEAR RES, V26, P231, DOI 10.1044/jshr.2602.231
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Madill C, 2013, COMMUN D ACROSS LANG, P182
   Markham D, 2004, J SPEECH LANG HEAR R, V47, P725, DOI 10.1044/1092-4388(2004/055)
   MASSARO DW, 1972, PSYCHOL REV, V79, P124, DOI 10.1037/h0032264
   MasteryConnect, 2016, MASTERYCONNECT
   McCabe P., 2017, RAPID SYLLABLE TRANS
   Mishra SK, 2014, J ACOUST SOC AM, V136, pEL173, DOI 10.1121/1.4890207
   Munson B, 2012, AM J SPEECH-LANG PAT, V21, P124, DOI 10.1044/1058-0360(2011/11-0009)
   Murray E, 2015, J SPEECH LANG HEAR R, V58, P43, DOI 10.1044/2014_JSLHR-S-12-0358
   Phillips DP, 1997, J ACOUST SOC AM, V101, P3694, DOI 10.1121/1.419376
   Pichora-Fuller MK, 2006, J ACOUST SOC AM, V119, P1143, DOI 10.1121/1.2149837
   Quene H, 2007, J PHONETICS, V35, P353, DOI 10.1016/j.wocn.2006.09.001
   Sayyahi F, 2017, RES DEV DISABIL, V61, P151, DOI 10.1016/j.ridd.2016.12.004
   Shriberg LD, 2017, J SPEECH LANG HEAR R, V60, P1096, DOI 10.1044/2016_JSLHR-S-15-0296
   Shriberg LD, 2017, J SPEECH LANG HEAR R, V60, P1118, DOI 10.1044/2016_JSLHR-S-15-0297
   Shriberg LD, 2009, J SPEECH LANG HEAR R, V52, P1189, DOI 10.1044/1092-4388(2009/08-0047)
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P286, DOI 10.1044/jslhr.4002.286
   Shriberg LD, 2003, CLIN LINGUIST PHONET, V17, P575, DOI 10.1080/0269920031000138141
   University of South Dakota, WEB LAW JUST NOT DIF
NR 38
TC 0
Z9 0
U1 1
U2 2
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PY 2018
VL 32
IS 11
BP 979
EP 996
DI 10.1080/02699206.2018.1463395
PG 18
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GV4YD
UT WOS:000446106800001
PM 29672170
DA 2021-02-24
ER

PT J
AU Arimitsu, T
   Minagawa, Y
   Yagihashi, T
   Uchida, MO
   Matsuzaki, A
   Ikeda, K
   Takahashi, T
AF Arimitsu, Takeshi
   Minagawa, Yasuyo
   Yagihashi, Tatsuhiko
   Uchida, Mariko O.
   Matsuzaki, Atsuko
   Ikeda, Kazushige
   Takahashi, Takao
TI The cerebral hemodynamic response to phonetic changes of speech in
   preterm and term infants: The impact of postmenstrual age
SO NEUROIMAGE-CLINICAL
LA English
DT Article
DE Near-infrared spectroscopy; Preterm infants; Laterality; Speech
   perception
ID NEAR-INFRARED SPECTROSCOPY; NEUROCOGNITIVE DEVELOPMENT;
   VISUAL-STIMULATION; LANGUAGE; CORTEX; ACQUISITION; LATERALIZATION;
   CHILDREN; OUTCOMES
AB Higher brain dysfunction, such as language delay, is a major concern among preterm infants. Cerebral substrates of cognitive development in preterm infants remain elusive, partly because of limited methods. The present study focuses on hemodynamic response patterns for brain function by using near-infrared spectroscopy. Specifically, the study investigates gestational differences in the hemodynamic response pattern evoked in response to phonetic changes of speech and cerebral hemispheric specialization of the auditory area in preterm infants (n=60) and term infants (n=20). Eighty neonates born between 26 and 41 weeks of gestational age (GA) were tested from 33 to 41 weeks of postmenstrual age (PMA). We analyzed the hemodynamic response pattern to phonemic and prosodic contrasts for multiple channels on temporal regions and the laterality index of the auditory area. Preterm infants younger than 39 weeks of PMA showed significantly atypical hemodynamic patterns, with an inverted response shape. Partial correlation analysis of the typicality score of hemodynamic response revealed a significant positive correlation with PMA. The laterality index of preterm infants from 39 weeks of PMA demonstrated a tendency rightward dominance for prosodic changes similar to term infants. We provide new evidence that alterations in hemodynamic regulation and the functional system for phonemic and prosodic processing in preterm infants catch up by their projected due dates.
C1 [Arimitsu, Takeshi; Yagihashi, Tatsuhiko; Ikeda, Kazushige; Takahashi, Takao] Keio Univ, Dept Pediat, Sch Med, Shinjuku Ku, Tokyo 1608582, Japan.
   [Minagawa, Yasuyo] Keio Univ, Fac Letters, Dept Psychol, Kohoku Ku, 4-1-1 Hiyoshi, Yokohama, Kanagawa 2238521, Japan.
   [Uchida, Mariko O.; Matsuzaki, Atsuko] Keio Univ, Grad Sch Human Relat, Minato Ku, Tokyo 1088345, Japan.
RP Minagawa, Y (corresponding author), Keio Univ, Fac Letters, Dept Psychol, Kohoku Ku, 4-1-1 Hiyoshi, Yokohama, Kanagawa 2238521, Japan.
EM myasuyo@bea.hi-ho.ne.jp
FU MEXTMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT); MEXT KAKENHIMinistry of Education, Culture, Sports,
   Science and Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP15H01691,
   JP24300105, JP24591609, JP15K09725]
FX This work was supported in part by the MEXT-supported program for
   strategic research foundations at private universities and MEXT KAKENHI;
   Grant numbers JP15H01691, JP24300105 (YM) and JP24591609, JP15K09725
   (TA).
CR Aarnoudse-Moens CSH, 2009, PEDIATRICS, V124, P717, DOI 10.1542/peds.2008-2816
   Alho K., 1990, ERPS AUDITORY STIMUL, P139
   Arimitsu T, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00202
   Bisiacchi PS, 2009, BIOL PSYCHOL, V82, P176, DOI 10.1016/j.biopsycho.2009.07.005
   Born P, 1996, LANCET, V347, P543, DOI 10.1016/S0140-6736(96)91175-7
   Boynton GM, 1996, J NEUROSCI, V16, P4207, DOI 10.1523/jneurosci.16-13-04207.1996
   Caskey M, 2011, PEDIATRICS, V128, P910, DOI 10.1542/peds.2011-0609
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   CheourLuhtanen M, 1996, PSYCHOPHYSIOLOGY, V33, P478, DOI 10.1111/j.1469-8986.1996.tb01074.x
   CSIBRA G, 2004, J PEDIAT NEUROL, V2, P85, DOI DOI 10.1055/S-0035-15
   Dehaene-Lambertz G, 2004, J COGNITIVE NEUROSCI, V16, P1375, DOI 10.1162/0898929042304714
   Friston KJ, 2000, NEUROIMAGE, V12, P196, DOI 10.1006/nimg.2000.0609
   Funane T, 2014, NEUROPHOTONICS, V1, DOI 10.1117/1.NPh.1.2.025003
   Gervain J, 2011, DEV COGN NEUROS-NETH, V1, P22, DOI 10.1016/j.dcn.2010.07.004
   Gervain Judit, 2008, Proc Natl Acad Sci U S A, V105, P14222, DOI 10.1073/pnas.0806530105
   HUTTENLOCHER PR, 1990, NEUROPSYCHOLOGIA, V28, P517, DOI 10.1016/0028-3932(90)90031-I
   Imaizumi S, 1998, NEUROREPORT, V9, P899, DOI 10.1097/00001756-199803300-00025
   Jobe Alan H., 2001, American Journal of Respiratory and Critical Care Medicine, V163, P1723
   Kohno S, 2007, J BIOMED OPT, V12, DOI 10.1117/1.2814249
   Kozberg MG, 2013, P NATL ACAD SCI USA, V110, P4380, DOI 10.1073/pnas.1212785110
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kusaka T, 2004, HUM BRAIN MAPP, V22, P122, DOI 10.1002/hbm.20020
   Lin PY, 2013, CEREB CORTEX, V23, P339, DOI 10.1093/cercor/bhs023
   Lloyd-Fox S, 2010, NEUROSCI BIOBEHAV R, V34, P269, DOI 10.1016/j.neubiorev.2009.07.008
   Luu TM, 2009, PEDIATRICS, V124, P333, DOI 10.1542/peds.2008-2587
   Mahmoudzadeh M, 2013, P NATL ACAD SCI USA, V110, P4846, DOI 10.1073/pnas.1212220110
   Meek JH, 1998, PEDIATR RES, V43, P840, DOI 10.1203/00006450-199806000-00019
   Mento G, 2012, NEUROSCI BIOBEHAV R, V36, P536, DOI 10.1016/j.neubiorev.2011.08.008
   Minagawa-Kawai Y, 2008, DEV NEUROBIOL, V68, P712, DOI 10.1002/dneu.20618
   Minagawa-Kawai Y, 2007, J NEUROSCI, V27, P315, DOI 10.1523/JNEUROSCI.1984-06.2007
   Minagawa-Kawai Y, 2011, DEV COGN NEUROS-NETH, V1, P217, DOI 10.1016/j.dcn.2011.03.005
   Minagawa-Kawai Y, 2009, NEUROREPORT, V20, P1219, DOI 10.1097/WNR.0b013e32832fa65f
   Mwaniki MK, 2012, LANCET, V379, P445, DOI 10.1016/S0140-6736(11)61577-8
   NORMAN MG, 1986, J NEUROPATH EXP NEUR, V45, P222
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Sato H, 2013, NEUROIMAGE, V83, P158, DOI 10.1016/j.neuroimage.2013.06.043
   Sato Y., 2003, JPN J LOGOPED PHONIA, V44, P165, DOI DOI 10.5112/JJLP.44.165
   Sato Y, 2007, NEUROREPORT, V18, P2001, DOI 10.1097/WNR.0b013e3282f262de
   Sato Y, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00070
   Spittle A, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005495.pub3
   Streimish IG, 2012, EARLY HUM DEV, V88, P765, DOI 10.1016/j.earlhumdev.2012.04.004
   Taga G, 2003, EARLY HUM DEV, V75, pS203, DOI 10.1016/j.earlhumdev.2003.08.023
   Takahashi T, 2011, NEUROIMAGE, V57, P991, DOI 10.1016/j.neuroimage.2011.05.012
   Tsuzuki D, 2007, NEUROIMAGE, V34, P1506, DOI 10.1016/j.neuroimage.2006.10.043
   Tusor N, 2014, CLIN PERINATOL, V41, P25, DOI 10.1016/j.clp.2013.10.001
   Watanabe H., 2017, P NATL ACAD SCI US, V114
   Zimmerman FJ, 2009, PEDIATRICS, V124, P342, DOI 10.1542/peds.2008-2267
NR 48
TC 7
Z9 8
U1 0
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 2213-1582
J9 NEUROIMAGE-CLIN
JI NeuroImage-Clin.
PY 2018
VL 19
BP 599
EP 606
DI 10.1016/j.nicl.2018.05.005
PG 8
WC Neuroimaging
SC Neurosciences & Neurology
GA GQ7PL
UT WOS:000441936300061
PM 29984167
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Remez, RE
   Thomas, EF
   Crank, AT
   Kostro, KB
   Cheimets, CB
   Pardo, JS
AF Remez, Robert E.
   Thomas, Emily F.
   Crank, Aislinn T.
   Kostro, Katrina B.
   Cheimets, Chloe B.
   Pardo, Jennifer S.
TI Short-term perceptual tuning to talker characteristics
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Speech perception; talker familiarity; perceptual tuning
ID SPEECH-PERCEPTION; SINUSOIDAL SENTENCES; SPOKEN WORDS; RECOGNITION;
   VARIABILITY; INTONATION; LISTENERS; TIME
AB When a listener encounters an unfamiliar talker, the ensuing perceptual accommodation to the unique characteristics of the talker has two aspects: (1) the listener assesses acoustic characteristics of speech to resolve the properties of the talker's sound production; and, (2) the listener appraises the talker's idiolect, subphonemic phonetic properties that compose the finest grain of linguistic production. A new study controlled a listener's exposure to determine whether the perceptual benefit rests on specific segmental experience. Effects of sentence exposure were measured using a spoken word identification task of Easy words (likely words drawn from sparse neighbourhoods of less likely words) and Hard words (less likely words drawn from dense neighbourhoods of more likely words). Recognition of words was facilitated by exposure to voiced obstruent consonants. Overall, these findings indicate that talker-specific perceptual tuning might depend more on exposure to phonemically marked consonants than to exposure distributed across the phoneme inventory.
C1 [Remez, Robert E.; Thomas, Emily F.; Crank, Aislinn T.; Kostro, Katrina B.; Cheimets, Chloe B.] Columbia Univ, Barnard Coll, Dept Psychol, Program Neurosci & Behav, New York, NY 10027 USA.
   [Pardo, Jennifer S.] Montclair State Univ, Dept Psychol, Montclair, NJ USA.
RP Remez, RE (corresponding author), Columbia Univ, Barnard Coll, Dept Psychol, Program Neurosci & Behav, New York, NY 10027 USA.
EM remez@columbia.edu
OI Remez, Robert/0000-0001-6023-2178
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [DC000308]
FX This research was supported by a grant from the National Institute on
   Deafness and Other Communication Disorders to author R. E. R. [grant
   number DC000308].
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   BRICKER PD, 1976, CONT ISSUES EXPT PHO, P295
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Feng YM, 2012, J ACOUST SOC AM, V131, pEL133, DOI 10.1121/1.3670594
   GOLDINGER SD, 1991, J EXP PSYCHOL LEARN, V17, P152, DOI 10.1037/0278-7393.17.1.152
   HUGGINS AWF, 1985, J ACOUST SOC AM, V77, P1896, DOI 10.1121/1.391941
   Hume E., 2011, COMPANION PHONOLOGY, V1, P79
   JAKOBSON R, 1972, SCI AM, V227, P72, DOI 10.1038/scientificamerican0972-72
   Johnson K. A., 1997, TALKER VARIABILITY S
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Khalighinejad B, 2017, J NEUROSCI, V37, P2176, DOI 10.1523/JNEUROSCI.2383-16.2017
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kreiman J., 2011, FDN VOICE STUDIES
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Ladefoged P., 1967, 3 AREAS EXPT PHONETI
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1952, AM J PSYCHOL, V65, P497, DOI 10.2307/1418032
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Nolan F., 1983, PHONETIC BASIS SPEAK
   Nusbaum H. C., 1984, RES SPEECH PERCEPTIO, V10, P357
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Remez R. E., 2010, EXPRESSING ONE SELF, P167
   Remez R. E., 2008, SCHOLARPEDIA, V3, P2394, DOI [DOI 10.4249/SCHOLARPEDIA.2394, 10.4249/scholarpedia.2394]
   REMEZ RE, 1993, J ACOUST SOC AM, V94, P1983, DOI 10.1121/1.407501
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   REMEZ RE, 1984, PERCEPT PSYCHOPHYS, V35, P429, DOI 10.3758/BF03203919
   Remez RE, 2013, WIRES COGN SCI, V4, P213, DOI 10.1002/wcs.1213
   Remez RE, 2011, J ACOUST SOC AM, V130, P2173, DOI 10.1121/1.3631667
   Remez RE, 2011, J EXP PSYCHOL HUMAN, V37, P968, DOI 10.1037/a0020734
   Sheffert SM, 2002, J EXP PSYCHOL HUMAN, V28, P1447, DOI 10.1037//0096-1523.28.6.1447
   STUBBS RJ, 1990, J ACOUST SOC AM, V87, P359, DOI 10.1121/1.399257
NR 38
TC 0
Z9 0
U1 0
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 9
BP 1083
EP 1091
DI 10.1080/23273798.2018.1442580
PG 9
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA GS7SI
UT WOS:000443903200001
PM 31008139
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Cohen, C
   Kang, S
AF Cohen, Clara
   Kang, Shinae
TI Flexible perceptual sensitivity to acoustic and distributional cues
SO MENTAL LEXICON
LA English
DT Article
DE probability; perception; pronunciation variation; cognitive resources;
   phonetics; morphology
ID SPOKEN-WORD RECOGNITION; MORPHOLOGICAL COMPLEXITY; TIME-COURSE;
   PRONUNCIATION VARIATION; COGNITIVE LOAD; PROSODIC CUES; SPEECH;
   DURATION; VERBS; DUTCH
AB Pronunciation variation in many ways is systematic, yielding patterns that a canny listener can exploit in order to aid perception. This work asks whether listeners actually do draw upon these patterns during speech perception. We focus in particular on a phenomenon known as paradigmatic enhancement, in which suffixes are phonetically enhanced in verbs which are frequent in their inflectional paradigms. In a set of four experiments, we found that listeners do not seem to attend to paradigmatic enhancement patterns. They do, however, attend to the distributional properties of a verb's inflectional paradigm when the experimental task encourages attention to sublexical detail, as is the case with phoneme monitoring (Experiment 1a-b). When tasks require more holistic lexical processing, as with lexical decision (Experiment 2), the effect of paradigmatic probability disappears. If stimuli are presented in full sentences, such that the surrounding context provides richer contextual and semantic information (Experiment 3), even otherwise robust influences like lexical frequency disappear. We propose that these findings are consistent with a perceptual system that is flexible, and devotes processing resources to exploiting only those patterns that provide a sufficient cognitive return on investment.
C1 [Cohen, Clara] Univ Glasgow, Glasgow, Lanark, Scotland.
   [Cohen, Clara; Kang, Shinae] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Kang, Shinae] George Washington Univ, Dept Speech Language & Hearing Sci, Washington, DC 20052 USA.
RP Cohen, C (corresponding author), 12 Univ Gardens, Glasgow G12 8QQ, Lanark, Scotland.
EM clara.cohen@glasgow.ac.uk; skang@email.gwu.edu
FU University of California, Berkeley's Linguistics Research Apprenticeship
   ProgramUniversity of California System; University of Glasgow College of
   Arts Strategic Research Allocation Fund
FX This work was completed with funding by the University of California,
   Berkeley's Linguistics Research Apprenticeship Program and the
   University of Glasgow College of Arts Strategic Research Allocation
   Fund. We are grateful to Rozina Fonyo for her vital assistance in
   preparing and running experiments, and to Keith Johnson for helpful
   discussion and suggestions. We are also grateful to Professor James
   Mahshie for supporting data collection with Experiment 1b. Portions of
   this work have been presented at the 2015 CUNY Conference on Sentence
   Processing, the Fall 2015 Acoustical Society of America Meeting, and the
   2016 Annual Meeting of the Berkeley Linguistics Society.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Aylett M, 2004, LANG SPEECH, V47, P31, DOI 10.1177/00238309040470010201
   Aylett M, 2006, J ACOUST SOC AM, V119, P3048, DOI 10.1121/1.2188331
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen R. H., 2008, CHICAGO LINGUISTICS, V43, P1
   Baayen RH, 2007, MENT LEX, V2, P419, DOI 10.1075/ml.2.3.06baa
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beddor PS, 2013, J ACOUST SOC AM, V133, P2350, DOI 10.1121/1.4794366
   Bell A, 2003, J ACOUST SOC AM, V113, P1001, DOI 10.1121/1.1534836
   Blazej LJ, 2015, J EXP PSYCHOL HUMAN, V41, P50, DOI 10.1037/a0038509
   Boersma P, 2015, PRAAT DOING PHONETIC
   Brysbaert M, 2012, BEHAV RES METHODS, V44, P991, DOI 10.3758/s13428-012-0190-4
   Cohen C, 2014, MORPHOLOGY, V24, P291, DOI 10.1007/s11525-014-9243-y
   Cohen C, 2015, MENT LEX, V10, P313, DOI 10.1075/ml.10.3.01coh
   CONNINE CM, 1993, J EXP PSYCHOL LEARN, V19, P81, DOI 10.1037/0278-7393.19.1.81
   Dahan D, 2000, J MEM LANG, V42, P465, DOI 10.1006/jmla.1999.2688
   Davis MH, 2002, J EXP PSYCHOL HUMAN, V28, P218, DOI 10.1037//0096-1523.28.1.218
   Ferreira F, 1996, J EXP PSYCHOL LEARN, V22, P324, DOI 10.1037/0278-7393.22.2.324
   Gahl S, 2004, LANGUAGE, V80, P748, DOI 10.1353/lan.2004.0185
   Gregory M. L., 1999, CHICAGO LINGUISTICS, V35, P151
   Heinrich A, 2010, SPEECH COMMUN, V52, P1038, DOI 10.1016/j.specom.2010.09.009
   Hyona J, 2002, EUR J COGN PSYCHOL, V14, P417, DOI 10.1080/09541440143000131
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kemps RJJK, 2005, MEM COGNITION, V33, P430, DOI 10.3758/BF03193061
   Kemps RJJK, 2005, LANG COGNITIVE PROC, V20, P43, DOI 10.1080/01690960444000223
   Kuperman V, 2007, J ACOUST SOC AM, V121, P2261, DOI 10.1121/1.2537393
   Kuperman V, 2012, J MEM LANG, V66, P588, DOI 10.1016/j.jml.2012.04.003
   LEHISTE I, 1972, J ACOUST SOC AM, V51, P2018, DOI 10.1121/1.1913062
   Lukyanenko C, 2016, COGNITION, V146, P349, DOI 10.1016/j.cognition.2015.10.012
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   Martin FMD, 2004, COGNITION, V94, P1, DOI 10.1016/j.cognition.2003.10.015
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   Mattys SL, 2014, PSYCHON B REV, V21, P748, DOI 10.3758/s13423-013-0544-7
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   Molinaro N, 2011, CORTEX, V47, P908, DOI 10.1016/j.cortex.2011.02.019
   Osterhout L, 1995, J MEM LANG, V34, P739, DOI 10.1006/jmla.1995.1033
   R Core Team, 2015, R LANG ENV STAT COMP
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Schuppler B, 2012, J PHONETICS, V40, P595, DOI 10.1016/j.wocn.2012.05.004
   Tabak W., 2005, LINGUISTIC EVIDENCE, P529, DOI [10.1515/9783110197549.529, DOI 10.1515/9783110197549.529, DOI 10.1515/9783110197549]
   Tabak W, 2010, MENT LEX, V5, P22, DOI 10.1075/ml.5.1.02tab
   Tily H, 2012, J ACOUST SOC AM, V132, P3935, DOI 10.1121/1.4765071
   Tily H, 2009, LANG COGN, V1, P147, DOI 10.1515/LANGCOG.2009.008
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394
   White L, 2010, J PHONETICS, V38, P459, DOI 10.1016/j.wocn.2010.05.002
NR 49
TC 0
Z9 0
U1 0
U2 1
PU JOHN BENJAMINS PUBLISHING CO
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 1871-1340
EI 1871-1375
J9 MENT LEX
JI Ment. Lex.
PY 2018
VL 13
IS 1
BP 38
EP 73
DI 10.1075/ml.16029.coh
PG 36
WC Linguistics
SC Linguistics
GA GQ6BD
UT WOS:000441783000003
OA Green Accepted
DA 2021-02-24
ER

PT J
AU van den Bunt, MR
   Groen, MA
   Frost, S
   Lau, A
   Preston, JL
   Gracco, VL
   Pugh, KR
   Verhoeven, LTW
AF van den Bunt, Mark R.
   Groen, Margriet A.
   Frost, Steve
   Lau, Airey
   Preston, Jonathan L.
   Gracco, Vincent L.
   Pugh, Kenneth R.
   Verhoeven, Ludo T. W.
TI Sensorimotor Control of Speech and Children's Reading Ability
SO SCIENTIFIC STUDIES OF READING
LA English
DT Article
ID PHONOLOGICAL REPRESENTATIONS; DEFICITS; PERCEPTION; ORGANIZATION;
   AWARENESS; FEEDBACK; SOUNDS; NOISE
AB Studies of the role of phonological representations in learning to read have almost exclusively focused on speech perception. In the current study, we examined links between sensorimotor control of speech, reading, and reading-related abilities. We studied two languages, English and Dutch, which vary in the regularity of their spelling-to-sound mappings. There were 236 American and Dutch children, 4 to 8years old, who performed an altered auditory feedback task in which the first formant of the // vowel was altered. A stronger response to altered feedback for literate relative to preliterate children was observed, and this was particularly the case for the Dutch children. Moreover, the magnitude of the responses was related to precursors of reading in preliterate children and to reading skill in literate children. We propose that these findings could be related to changes in children's speech production skills that facilitate the integration of orthographic and phonemic information.
C1 [van den Bunt, Mark R.; Groen, Margriet A.; Verhoeven, Ludo T. W.] Radboud Univ Nijmegen, Nijmegen, Netherlands.
   [Frost, Steve; Lau, Airey; Preston, Jonathan L.; Gracco, Vincent L.; Pugh, Kenneth R.] Yale Univ, New Haven, CT 06520 USA.
   [Preston, Jonathan L.] Syracuse Univ, Syracuse, NY 13244 USA.
RP van den Bunt, MR (corresponding author), Radboud Univ Nijmegen, Behav Sci Inst, Montessorilaan 3, NL-6525 HP Nijmegen, Netherlands.
EM m.vandenbunt@pwo.ru.nl
RI Groen, Margriet/A-5087-2012; Preston, Jonathan/E-9310-2010
OI Groen, Margriet/0000-0002-6178-2937; Preston,
   Jonathan/0000-0001-9971-6321
FU Foundation for the National Institutes of HealthUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USA
   [P01HD001994]; Nederlandse Organisatie voor Wetenschappelijk
   OnderzoekNetherlands Organization for Scientific Research (NWO)European
   Commission [275-89-017]
FX This work was supported by the Foundation for the National Institutes of
   Health (P01HD001994), Nederlandse Organisatie voor Wetenschappelijk
   Onderzoek (275-89-017).
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boada R, 2006, J EXP CHILD PSYCHOL, V95, P153, DOI 10.1016/j.jecp.2006.04.003
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Borgwaldt S. R., 2005, READ WRIT, V18, P211, DOI [10.1007/s11145-005-3001-9, DOI 10.1007/S11145-005-3001-9]
   Cai S., 2008, PROCEEDINGS OF THE 8, P65
   Caravolas M, 2005, J EXP CHILD PSYCHOL, V92, P107, DOI 10.1016/j.jecp.2005.04.003
   CATTS HW, 1989, J SPEECH HEAR DISORD, V54, P422, DOI 10.1044/jshd.5403.422
   Catts HW, 1997, LANG SPEECH HEAR SER, V28, P86, DOI 10.1044/0161-1461.2801.86
   CATTS HW, 1986, J LEARN DISABIL, V19, P504, DOI 10.1177/002221948601900813
   Cornelissen PL, 1996, COGNITION, V59, P275, DOI 10.1016/0010-0277(95)00697-4
   Ellis NC, 2004, READ RES QUART, V39, P438, DOI 10.1598/RRQ.39.4.5
   Farouk, 2014, SPRINGER BRIEFS SPEE, DOI [10.1007/978-3-319-02732-6_2, DOI 10.1007/978-3-319-02732-6_2]
   Foy JG, 2001, APPL PSYCHOLINGUIST, V22, P301, DOI 10.1017/S0142716401003022
   Foy JG, 2012, READ WRIT, V25, P799, DOI 10.1007/s11145-011-9300-4
   Georgiou GK, 2008, J EDUC PSYCHOL, V100, P566, DOI 10.1037/0022-0663.100.3.566
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Hazan V, 2013, J SPEECH LANG HEAR R, V56, P44, DOI 10.1044/1092-4388(2012/10-0107)
   HESTER E., 2004, CHILD LANG TEACH THE, V20, P115, DOI DOI 10.1191/0265659004CT266OA
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Leinenger M, 2014, PSYCHOL BULL, V140, P1534, DOI 10.1037/a0037830
   Liberman A. M., 1989, READING IS HARD JUST
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   Mattingly I. G., 1972, LANGUAGE EAR EYE
   Melby-Lervag M, 2012, SCI STUD READ, V16, P1, DOI 10.1080/10888438.2010.537715
   Mustafa K, 2006, IEEE T AUDIO SPEECH, V14, P435, DOI 10.1109/TSA.2005.855840
   Nittrouer S, 2013, RES DEV DISABIL, V34, P2304, DOI 10.1016/j.ridd.2013.04.018
   Niziolek CA, 2013, J NEUROSCI, V33, P12090, DOI 10.1523/JNEUROSCI.1008-13.2013
   Pugh KR, 2013, BRAIN LANG, V125, P173, DOI 10.1016/j.bandl.2012.04.004
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   R Core Team, 2014, R LANG ENV STAT COMP
   Ramachandra V, 2011, J PSYCHOLINGUIST RES, V40, P93, DOI 10.1007/s10936-010-9157-8
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Rueckl JG, 2015, P NATL ACAD SCI USA, V112, P15510, DOI 10.1073/pnas.1509321112
   Share DL, 2008, PSYCHOL BULL, V134, P584, DOI 10.1037/0033-2909.134.4.584
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Smith AB, 2006, AM J SPEECH-LANG PAT, V15, P289, DOI 10.1044/1058-0360(2006/027)
   SNOWLING MJ, 1981, PSYCHOL RES-PSYCH FO, V43, P219, DOI 10.1007/BF00309831
   Tourville J. A., 2013, P 165 M AC SOC AM MO
   Van den Bos K.P., 1994, KLEPEL TEST LEESVAAR
   van den Bunt MR, 2017, J SPEECH LANG HEAR R, V60, P654, DOI 10.1044/2016_JSLHR-L-16-0201
   Wagner R, 1999, COMPREHENSIVE TEST P
   Wagner R. K., 2013, COMPREHENSIVE TEST P
   Woodcock R. W., 2001, WOODCOCKJOHNSON 3 TE
   Yang J, 2013, INTERSPEECH, P1262
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 47
TC 1
Z9 1
U1 0
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1088-8438
EI 1532-799X
J9 SCI STUD READ
JI Sci. Stud. Read.
PY 2018
VL 22
IS 6
BP 503
EP 516
DI 10.1080/10888438.2018.1491583
PG 14
WC Education & Educational Research; Psychology, Educational
SC Education & Educational Research; Psychology
GA GQ8PK
UT WOS:000442018500004
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bosker, HR
   Ghitza, O
AF Bosker, Hans Rutger
   Ghitza, Oded
TI Entrained theta oscillations guide perception of subsequent speech:
   behavioural evidence from rate normalisation
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Neural entrainment; theta oscillations; speech rate; rate normalisation
ID COMPRESSED SPEECH; COMPREHENSION; RESPONSES; RHYTHMS; INTELLIGIBILITY;
   RESTORATION; MODULATION; PATTERNS; WORDS; LOAD
AB This psychoacoustic study provides behavioural evidence that neural entrainment in the theta range (3-9 Hz) causally shapes speech perception. Adopting the "rate normalization" paradigm (presenting compressed carrier sentences followed by uncompressed target words), we show that uniform compression of a speech carrier to syllable rates inside the theta range influences perception of subsequent uncompressed targets, but compression outside theta range does not. However, the influence of carriers - compressed outside theta range - on target perception is salvaged when carriers are "repackaged" to have a packet rate inside theta. This suggests that the brain can only successfully entrain to syllable/packet rates within theta range, with a causal influence on the perception of subsequent speech, in line with recent neuroimaging data. Thus, this study points to a central role for sustained theta entrainment in rate normalisation and contributes to our understanding of the functional role of brain oscillations in speech perception.
C1 [Bosker, Hans Rutger] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Bosker, Hans Rutger] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Ghitza, Oded] Boston Univ, Dept Biomed Engn, Hearing Res Ctr, Boston, MA 02215 USA.
   [Ghitza, Oded] Max Planck Inst Empir Aesthet, Neurosci Dept, Frankfurt, Germany.
RP Bosker, HR (corresponding author), Max Planck Inst Psycholinguist, Nijmegen, Netherlands.; Bosker, HR (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM HansRutger.Bosker@mpi.nl
OI Bosker, Hans Rutger/0000-0002-2628-7738
FU Gravitation grant from the Dutch Government; Air Force Office of
   Scientific ResearchUnited States Department of DefenseAir Force Office
   of Scientific Research (AFOSR)
FX The first author was supported by a Gravitation grant from the Dutch
   Government to the Language in Interaction Consortium. The second author
   was supported by a research grant from the Air Force Office of
   Scientific Research.
CR Adank P, 2009, J ACOUST SOC AM, V126, P2649, DOI 10.1121/1.3216914
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bosker HR, 2017, INTERSPEECH, P2416, DOI 10.21437/Interspeech.2017-73
   Bosker HR, 2018, J ACOUST SOC AM, V143, DOI 10.1121/1.5024404
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Dent ML, 1997, J ACOUST SOC AM, V102, P1891, DOI 10.1121/1.420111
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   Dupoux E, 1997, J EXP PSYCHOL HUMAN, V23, P914, DOI 10.1037/0096-1523.23.3.914
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Ghitza O., 2014, FRONT PSYCHOL, V5, P1
   Ghitza O, 2017, LANG COGN NEUROSCI, V32, P545, DOI 10.1080/23273798.2016.1232419
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   GORDON PC, 1988, PERCEPT PSYCHOPHYS, V43, P137, DOI 10.3758/BF03214191
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   KIDD GR, 1989, J EXP PSYCHOL HUMAN, V15, P736, DOI 10.1037/0096-1523.15.4.736
   Kosem A., 2017, BIORXIV, DOI [10.1101/175000, DOI 10.1101/175000]
   Krause JC, 2004, J ACOUST SOC AM, V115, P362, DOI 10.1121/1.1635842
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P540, DOI 10.3758/BF03213089
   Obleser J, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00250
   OLLER DK, 1991, PHONETICA, V48, P32
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pefkou M, 2017, J NEUROSCI, V37, P7930, DOI 10.1523/JNEUROSCI.2882-16.2017
   PICKETT JM, 1960, LANG SPEECH, V3, P11, DOI 10.1177/002383096000300103
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   R Development Core Team, 2012, R LANG ENV STAT COMP
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2016, ATTEN PERCEPT PSYCHO, V78, P1203, DOI 10.3758/s13414-016-1067-x
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Sawusch JR, 2000, PERCEPT PSYCHOPHYS, V62, P285, DOI 10.3758/BF03205549
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Spaak E, 2014, J NEUROSCI, V34, P3536, DOI 10.1523/JNEUROSCI.4385-13.2014
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Ueda K., 2017, SCI REP, V7, P1, DOI [10.1038/s41598-016-0028-x, DOI 10.1038/S41598-016-0028-X]
   Varnet L, 2017, J ACOUST SOC AM, V142, P1976, DOI 10.1121/1.5006179
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
NR 65
TC 16
Z9 15
U1 1
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 8
BP 955
EP 967
DI 10.1080/23273798.2018.1439179
PG 13
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA GP7EN
UT WOS:000441056100003
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Gosy, M
   Bahr, RH
   Gyarmathy, D
   Beke, A
AF Gosy, Maria
   Bahr, Ruth Huntley
   Gyarmathy, Dorottya
   Beke, Andras
TI Dichotic listening and sentence repetition performance in children with
   reading difficulties
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE School children; reading difficulty; dichotic listening test; sentence
   identification test
ID SPEECH-PERCEPTION DEFICITS; PHONOLOGICAL AWARENESS; LANGUAGE IMPAIRMENT;
   CONSONANT-VOWEL; DEVELOPMENTAL DYSLEXIA; LEARNING-DISABILITIES; PLANUM
   TEMPORALE; WORKING-MEMORY; EAR ADVANTAGE; POOR READERS
AB Numerous investigations have identified weaknesses in speech processing and language skills in children with dyslexia; however, little is known about these abilities in children with reading difficulties (RD). The primary objective of this investigation was to determine the utility of auditory speech processing tasks in differentiating children with RD from those with typical reading skills. It was hypothesized that children, who perform below grade level in reading, would also show poorer performance on both dichotic listening and sentence repetition tasks because of the reciprocal influences of deficient auditory speech processing and language abilities. A total of 180 Hungarian-speaking, monolingual 8-, 9- and 10-year-old children, with and without RD, participated in dichotic listening and sentence repetition (modified by noise and morphosyntactic complexity) tasks. Performances were compared across ability groups, age and gender. Children with RD evidenced significantly poorer performance than controls on both tasks. Effects for age and gender were more noticeable in students with RD. Our findings support the notion that reading deficiencies are also associated with poor auditory speech processing and language abilities in cases where dyslexia is not diagnosed. We suggest that these tasks may be used as easy and fast screening tests in the identification of RD.
C1 [Gosy, Maria; Gyarmathy, Dorottya; Beke, Andras] Hungarian Acad Sci, Res Inst Linguist, Phonet Dept, Budapest, Hungary.
   [Bahr, Ruth Huntley] Univ S Florida, Dept Commun Sci & Disorders, Tampa, FL USA.
RP Gosy, M (corresponding author), Hungarian Acad Sci, Res Inst Linguist, Benczur U 33, H-1068 Budapest, Hungary.
EM gosy.maria@nytud.mta.hu
RI Gosy, Maria/I-4620-2017
OI Gosy, Maria/0000-0003-4336-3007
CR Alloway TP, 2005, LEARN INDIVID DIFFER, V15, P271, DOI 10.1016/j.lindif.2005.05.001
   Asbjornsen AE, 1998, NEUROPSYCHOLOGIA, V36, P143, DOI 10.1016/S0028-3932(97)00090-0
   Asbjornsen AE, 2006, LATERALITY, V11, P251, DOI 10.1080/13576500500489360
   ASBJORNSEN AE, 1995, BRAIN LANG, V49, P189, DOI 10.1006/brln.1995.1029
   Asbjornsen AE, 2003, CHILD NEUROPSYCHOL, V9, P277, DOI 10.1076/chin.9.4.277.23521
   Bishop DVM, 2013, SCIENCE, V340, DOI 10.1126/science.1230531
   Boada R, 2006, J EXP CHILD PSYCHOL, V95, P153, DOI 10.1016/j.jecp.2006.04.003
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Bradlow AR, 2003, J SPEECH LANG HEAR R, V46, P80, DOI 10.1044/1092-4388(2003/007)
   Briscoe J, 2001, J CHILD PSYCHOL PSYC, V42, P329, DOI 10.1017/S0021963001007041
   Castles A, 2004, COGNITION, V91, P77, DOI 10.1016/S0010-0277(03)00164-1
   Catts HW, 2002, J LEARN DISABIL-US, V35, P509
   Conti-Ramsden G, 2001, J CHILD PSYCHOL PSYC, V42, P741, DOI 10.1111/1469-7610.00770
   Dawes P, 2010, ARCH DIS CHILD, V95, P432, DOI 10.1136/adc.2009.170118
   De Martino S, 2001, BRAIN COGNITION, V46, P104
   Dole M, 2014, NEUROPSYCHOLOGIA, V60, P103, DOI 10.1016/j.neuropsychologia.2014.05.016
   Fowler AE, 2004, ANN DYSLEXIA, V54, P247, DOI 10.1007/s11881-004-0013-0
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Goldwave Inc, 2012, GOLDW V 5 7
   Gosy M., 2011, MAGYAR NYELVR, V135/2, P161
   Gosy M., 1999, PATHOLOGIES SPEECH L, P50
   Gosy M, 2007, CLIN LINGUIST PHONET, V21, P909, DOI 10.1080/02699200701580084
   Habib M, 2000, BRAIN, V123, P2373, DOI 10.1093/brain/123.12.2373
   Heiervang E, 2000, NEUROPSYCHOLOGIA, V38, P1704, DOI 10.1016/S0028-3932(00)00085-3
   Helland T, 2008, DYSLEXIA, V14, P42, DOI 10.1002/dys.343
   Hirnstein M, 2013, CORTEX, V49, P1910, DOI 10.1016/j.cortex.2012.08.002
   Hosmer D.W., 1989, APPL LOGISTIC REGRES
   Hugdahl K, 1999, NEUROPSYCHOLOGIA, V37, P431, DOI 10.1016/S0028-3932(98)00101-8
   Hugdahl K, 1995, J CLIN EXP NEUROPSYC, V17, P833, DOI 10.1080/01688639508402432
   Hugdahl K, 2003, ASYMMETRICAL BRAIN, P441
   Hugdahl K, 2003, NEUROPSYCHOLOGIA, V41, P666, DOI 10.1016/S0028-3932(02)00224-5
   Juhasz a., 1999, LOGOPEDIAI VIZSGALAT
   Kenesei I., 2011, HUNGARIAN
   KERSHNER JR, 1990, NEUROPSYCHOLOGIA, V28, P181, DOI 10.1016/0028-3932(90)90100-3
   Klem M, 2015, DEVELOPMENTAL SCI, V18, P146, DOI 10.1111/desc.12202
   Leonard CM, 2008, DEV NEUROPSYCHOL, V33, P663, DOI 10.1080/87565640802418597
   Lyytinen H, 2004, ANN DYSLEXIA, V54, P184, DOI 10.1007/s11881-004-0010-3
   MANN VA, 1984, ANN DYSLEXIA, V34, P117, DOI 10.1007/BF02663616
   McBride-Chang C, 1997, J EDUC PSYCHOL, V89, P621, DOI 10.1037/0022-0663.89.4.621
   Meyers JE, 2002, ARCH CLIN NEUROPSYCH, V17, P79, DOI 10.1016/S0887-6177(00)00105-0
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Moll K, 2014, LEARN INSTR, V29, P65, DOI 10.1016/j.learninstruc.2013.09.003
   Moncrieff D., 2010, 2 HALVES BRAIN, P561
   Moncrieff DW, 2008, INT J AUDIOL, V47, P84, DOI 10.1080/14992020701770835
   Moncrieff DW, 2008, DYSLEXIA, V14, P54, DOI 10.1002/dys.344
   Moncrieff Deborah W, 2002, J Am Acad Audiol, V13, P428
   Moncrieff DW, 2011, BRAIN COGNITION, V76, P316, DOI 10.1016/j.bandc.2011.03.013
   Nagyne Rez I., 2008, WISC 4 GYERMEK INTEL
   Nittrouer S, 1999, J SPEECH LANG HEAR R, V42, P925, DOI 10.1044/jslhr.4204.925
   Nittrouer S, 2013, RES DEV DISABIL, V34, P2304, DOI 10.1016/j.ridd.2013.04.018
   OBRZUT J, 1988, BRAIN LATERALIZATION, P567
   Obrzut JE, 2011, BRAIN COGNITION, V76, P323, DOI 10.1016/j.bandc.2011.02.012
   Pennington BF, 2009, ANNU REV PSYCHOL, V60, P283, DOI 10.1146/annurev.psych.60.110707.163548
   Piazza M., 1985, LANG SCI, V7, P73, DOI [10.1016/S0388-0001(85)80013-9, DOI 10.1016/S0388-0001(85)80013-9]
   Plaza M, 2002, BRAIN COGNITION, V48, P505, DOI 10.1006/brcg.2001.1407
   Samuelsson S, 2003, ANN DYSLEXIA, V53, P201, DOI 10.1007/s11881-003-0010-8
   Seeff-Gabriel B, 2010, INT J LANG COMM DIS, V45, P691, DOI 10.3109/13682820903509432
   SHAYWITZ SE, 1992, NEW ENGL J MED, V326, P145, DOI 10.1056/NEJM199201163260301
   Snow C., 1998, PREVENTING READING D
   Steinberg Media Technologies, 2012, WAV 7
   Stokes SF, 2006, J SPEECH LANG HEAR R, V49, P219, DOI 10.1044/1092-4388(2006/019)
   StuddertKennedy M, 1995, PSYCHON B REV, V2, P508, DOI 10.3758/BF03210986
   van den Noort M, 2008, NEUROIMAGE, V40, P902, DOI 10.1016/j.neuroimage.2007.11.051
   van Ettinger-Veenstra HM, 2010, NEUROIMAGE, V49, P3481, DOI 10.1016/j.neuroimage.2009.10.041
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   WATSON ES, 1982, J EXP CHILD PSYCHOL, V34, P1, DOI 10.1016/0022-0965(82)90027-3
   Willis CS, 2001, MEMORY, V9, P349, DOI 10.1080/09658210143000155
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 69
TC 0
Z9 0
U1 1
U2 3
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PY 2018
VL 32
IS 9
BP 787
EP 803
DI 10.1080/02699206.2018.1431807
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GP2WB
UT WOS:000440696300001
PM 29393703
DA 2021-02-24
ER

PT J
AU McKnight, RJ
   Glick, H
   Cardon, G
   Sharma, A
AF McKnight, Rosemary J.
   Glick, Hannah
   Cardon, Garrett
   Sharma, Anu
TI The effects of stimulus rate on ABR morphology and its relationship to
   P1 CAEP responses and auditory speech perception outcomes in children
   with auditory neuropathy spectrum disorder: evidence from case reports
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Auditory neuropathy spectrum disorder (ANSD); auditory brainstem
   response (ABR); stimulus rate; P1 cortical auditory evoked potential (P1
   CAEP)
ID BRAIN-STEM RESPONSE; EVOKED POTENTIALS; COCHLEAR IMPLANTS; HEARING-LOSS;
   REPETITION RATE; YOUNG-CHILDREN; SYNCHRONY; MATURATION; DIAGNOSIS;
   MANAGEMENT
AB Objective: Auditory neuropathy spectrum disorder (ANSD) affects approximately 5-15% of children with sensorineural hearing loss (SNHL). ANSD is characterized by the presence of otoacoustic emissions (OAE) and an absent or abnormal auditory brainstem response (ABR). The purpose of this study was to investigate the prognostic value of slow-rate ABR in predicting the auditory cortical development and auditory speech perception outcomes in case studies of children with ANSD.
   Design: ABR waveform characteristics were collected at slow stimulation rates (5.1 clicks/second) and a fast stimulation rates (>11-31.1 clicks/second, rates typically used in a clinical setting) in three case reports of children with ANSD. P1 CAEP responses and measures of auditory speech perception using the Infant Toddler Meaningful Auditory Integration Scale (IT-MAIS) were also collected in these children. Retrospective analysis was performed to evaluate the prognostic value of slow-versus fast-rate ABR in predicting P1 CAEP responses and auditory speech perception outcomes in these children.
   Study sample: Participants included case reports of three paediatric participants with a clinical diagnosis of ANSD.
   Results: Slow-rate ABR did not elicit significant improvements in waveform morphology compared to fast-rate ABR. P1 CAEP results were present in 2 out of 3 cases and were consistent with auditory speech perception outcomes.
   Conclusions: Even when ABR stimulation rates were slowed, ABR responses in these children with ANSD did not display any characteristic or replicable pattern, and ABR responses were not predictive of cortical auditory maturation or behavioural performance. In contrast, P1 CAEP responses provided valuable information regarding the maturational status of the auditory cortex and P1 CAEP responses were consistent with behavioural measures of auditory speech perception. Overall, results highlight the high prognostic value of P1 CAEP testing when used in conjunction with behavioural measures of auditory speech perception in children with ANSD.
C1 [McKnight, Rosemary J.] Univ Colorado, Speech Language & Hearing Sci Dept, Boulder, CO 80309 USA.
   [Glick, Hannah; Cardon, Garrett; Sharma, Anu] Univ Colorado, Ctr Neurosci, Inst Cognit Sci, Speech Language & Hearing Sci Dept, Boulder, CO USA.
RP Sharma, A (corresponding author), Univ Colorado, Speech Language & Hearing Sci Dept, Boulder, CO 80309 USA.
EM anu.sharma@colorado.edu
OI Cardon, Garrett/0000-0003-4294-0204; McKnight,
   Rosemary/0000-0002-7064-6734
FU Foundation for the National Institutes of Health [R01DC006257]
FX This work was supported by the Foundation for the National Institutes of
   Health under Grant number R01DC006257.
CR Alvarenga KF, 2012, INT J PEDIATR OTORHI, V76, P1332, DOI 10.1016/j.ijporl.2012.06.001
   BERLIN C, 2001, AUDIOL TODAY, V13, P15
   Berlin CI, 2010, INT J AUDIOL, V49, P30, DOI 10.3109/14992020903160892
   Berlin CI, 2003, MENT RETARD DEV D R, V9, P225, DOI 10.1002/mrdd.10084
   BERLIN CI, 2001, ABSTR ASS RES OTOLAR, V24, P137
   Burkard R F, 2001, Am J Audiol, V10, P53, DOI 10.1044/1059-0889(2001/008)
   Cardon G, 2013, INT J AUDIOL, V52, P577, DOI 10.3109/14992027.2013.799786
   DEBRUYNE F, 1986, AUDIOLOGY, V25, P101
   GORGA MP, 1989, J SPEECH HEAR RES, V32, P281, DOI 10.1044/jshr.3202.281
   Hall J., 2015, EHANDBOOK AUDITORY E
   JEWETT DL, 1970, SCIENCE, V167, P1517, DOI 10.1126/science.167.3924.1517
   JEWETT DL, 1971, BRAIN, V94, P681, DOI 10.1093/brain/94.4.681
   Kirkim G, 2008, INT J PEDIATR OTORHI, V72, P1461, DOI 10.1016/j.ijporl.2008.06.010
   Kraus N, 2000, JARO-J ASSOC RES OTO, V1, P33, DOI 10.1007/s101620010004
   Liang SY, 2016, INT J AUDIOL, V55, P224, DOI 10.3109/14992027.2015.1120891
   Nash-Kille A, 2014, CLIN NEUROPHYSIOL, V125, P1459, DOI 10.1016/j.clinph.2013.11.017
   PALUDETTI G, 1983, AM J OTOL, V4, P226
   Parthasarathy T K, 1998, J Am Acad Audiol, V9, P134
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7
   Rance G, 1999, EAR HEARING, V20, P238, DOI 10.1097/00003446-199906000-00006
   Rance G, 2007, EAR HEARING, V28, P351, DOI 10.1097/AUD.0b013e3180479404
   Rance Gary, 2005, Trends Amplif, V9, P1, DOI 10.1177/108471380500900102
   Rance G, 2009, INT J AUDIOL, V48, P313, DOI 10.1080/14992020802665959
   ROBBINS AM, 1991, AM J OTOL, V12, P144
   Sharma A, 1997, EVOKED POTENTIAL, V104, P540, DOI 10.1016/S0168-5597(97)00050-6
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Sharma A, 2002, ANN OTO RHINOL LARYN, V111, P38
   Sharma A, 2002, NEUROREPORT, V13, P1365, DOI 10.1097/00001756-200207190-00030
   Sharma Anu, 2006, Adv Otorhinolaryngol, V64, P66, DOI 10.1159/000094646
   Sharma Anu, 2005, J Am Acad Audiol, V16, P564, DOI 10.3766/jaaa.16.8.5
   Sharma A, 2015, HEARING RES, V330, P221, DOI 10.1016/j.heares.2015.06.001
   Sharma A, 2013, HEARING BALANC COMMU, V11, P110, DOI 10.3109/21695717.2013.812378
   Sharma A, 2011, INT J AUDIOL, V50, P98, DOI 10.3109/14992027.2010.542492
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Sininger Y, 2008, GUID DEV C NHS 2008
   SININGER YS, 1989, J SPEECH HEAR RES, V32, P880, DOI 10.1044/jshr.3204.880
   Sininger Yvonne S., 2002, Seminars in Hearing, V23, P193, DOI 10.1055/s-2002-34456
   Spitzer E, 2015, J AM ACAD AUDIOL, V26, P30, DOI 10.3766/jaaa.26.1.4
   Starr A, 2001, EAR HEARING, V22, P91, DOI 10.1097/00003446-200104000-00002
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   STOCKARD JE, 1979, ARCH NEUROL-CHICAGO, V36, P823, DOI 10.1001/archneur.1979.00500490037006
   Talaat HS, 2009, INT J PEDIATR OTORHI, V73, P937, DOI 10.1016/j.ijporl.2009.03.009
   Vignesh SS, 2016, INDIAN J OTOLARYNGOL, V68, P196, DOI 10.1007/s12070-014-0759-6
   YAGI T, 1979, ARCH OHREN NASEN KEH, V222, P91, DOI 10.1007/BF00469746
   Zeng FG, 2006, J SPEECH LANG HEAR R, V49, P367, DOI 10.1044/1092-4388(2006/029)
   Zheng Y, 2009, AUDIOL NEURO-OTOL, V14, P214, DOI 10.1159/000189264
   Zimmerman-Phillips S, 2000, ANN OTO RHINOL LARYN, V109, P42
NR 47
TC 0
Z9 0
U1 0
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2018
VL 16
IS 1
BP 1
EP 12
DI 10.1080/21695717.2017.1418803
PG 12
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA GL6KJ
UT WOS:000437294400001
PM 32953369
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Gabr, TA
   Kotait, MA
AF Gabr, Takwa A.
   Kotait, Mona A.
TI Cochlear implant versus hearing aids: cortical auditory-evoked
   potentials study
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Cochlear implants (CIs); hearing aids; cortical auditory-evoked
   potentials; speech processing
ID IMPAIRED PATIENTS; DEPRIVATION; PLASTICITY; CHILDREN; PERFORMANCE; USERS
AB Patients with severe and profound hearing loss (HL) represent a unique challenge in hearing aids (HAs) fitting for whom cochlear implants (CIs) are better choice.
   Objectives: To assess speech perception in children with severe-to-profound HL who are fitted with power HAs or CIs and compare their results with children with better hearing thresholds who are fitted with HAs.
   Methods: Seventy children were participated in this work divided into four groups according to their hearing thresholds: GI: 18 children with moderate HL fitted with HAs, GII: 16 children with severe HL fitted with HAs, GIII: 16 children with profound HL fitted with HAs and GIV: 20 children with profound HL and fitted with CIs.
   Results: Aided speech audiometry showed better results in GI and GIV while GIII showed the worst results among the four groups. P1-N1 of aided speech-evoked cortical auditory-evoked potentials (S-CAEPs) was recorded in all cases in GI and GIV and their latencies showed no significant difference, while GIII showed significantly delayed latencies. There was a significant negative correlation between P1 and N1 latencies and duration of HAs and CIs use in GII and GIV, respectively. Amplitudes of P1 and N2 showed a significant positive correlation with duration of HAs use in GII and GIII, respectively. GI showed a significant positive correlation between SRTs and P1 latency. GII showed significant negative correlations between SD% and N2 latency, while GIV showed a significant positive correlation between SRTs and P2 latency.
   Conclusion: CIs represent a good choice for children with severe-to-profound and profound HL than power HAs. Children with more severe degrees of HL who do well on speech perception measures tend to have better S-CAEPs results with good correspondence between both measures. S-CAEPs and speech perception tests can be used regularly to assess the efficiency of auditory rehabilitation.
C1 [Gabr, Takwa A.] Kafrelsheikh Univ, Fac Med, Audiol Unit, Ear Nose & Throat, Kafrelsheikh, Egypt.
   [Kotait, Mona A.] Tanta Univ, Tanta Univ Hosp, Fac Med, Tanta, Egypt.
RP Gabr, TA (corresponding author), Kafrelsheikh Univ, Fac Med, Audiol Unit, Ear Nose & Throat, Kafrelsheikh, Egypt.
EM takwagabr@gmail.com
RI Gabr, Takwa/C-6632-2016; kotait, Mona Ahmed/I-8248-2017
OI Gabr, Takwa/0000-0003-2222-4147; kotait, Mona Ahmed/0000-0002-8179-832X
CR BYRNE D, 1990, EAR HEARING, V11, P40, DOI 10.1097/00003446-199002000-00009
   Ching TYC, 2004, EAR HEARING, V25, P9, DOI 10.1097/01.AUD.0000111261.84611.C8
   Ching TYC, 1998, J ACOUST SOC AM, V103, P1128, DOI 10.1121/1.421224
   Dorman MF, 2007, J COMMUN DISORD, V40, P284, DOI 10.1016/j.jcomdis.2007.03.007
   Eggermont JJ, 1997, ACTA OTO-LARYNGOL, V117, P161, DOI 10.3109/00016489709117760
   Flynn M, 2002, HEAR REV, V9, P28
   Geers Ann E, 2006, Adv Otorhinolaryngol, V64, P50, DOI 10.1159/000094644
   Gulick L, 1989, HEARING PHYSIL ACOUS, P161
   Hamzavi J, 2001, AUDIOLOGY, V40, P26
   Humes L, 1982, MONOGRAPHS CONT AUDI, P16
   KEWLEYPORT D, 1983, J ACOUST SOC AM, V73, P322, DOI 10.1121/1.388813
   Kirk KI, 2002, ANN OTO RHINOL LARYN, V111, P69
   Kral A, 2007, BRAIN RES REV, V56, P259, DOI 10.1016/j.brainresrev.2007.07.021
   Kral A, 2006, PROG BRAIN RES, V157, P283, DOI 10.1016/S0079-6123(06)57018-9
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Mo B, 2004, INT J AUDIOL, V43, P572, DOI 10.1080/14992020400050073
   Mo B, 2004, ANN OTO RHINOL LARYN, V113, P914, DOI 10.1177/000348940411301111
   Moore B., 2001, SOUND FDN EARLY AMPL, P153
   Moore B C, 2001, Trends Amplif, V5, P1, DOI 10.1177/108471380100500102
   Moore JK, 2007, INT J AUDIOL, V46, P460, DOI 10.1080/14992020701383019
   Novak MA, 2000, ANN OTO RHINOL LARYN, V109, P46
   Sharma A, 1997, EVOKED POTENTIAL, V104, P540, DOI 10.1016/S0168-5597(97)00050-6
   Sharma A, 2002, NEUROREPORT, V13, P1365, DOI 10.1097/00001756-200207190-00030
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma Anu, 2005, J Am Acad Audiol, V16, P564, DOI 10.3766/jaaa.16.8.5
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Weir C, 2009, IELTS RES REPORTS, V9, P157
NR 27
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2018
VL 16
IS 1
BP 56
EP 63
DI 10.1080/21695717.2018.1426307
PG 8
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA GL6KJ
UT WOS:000437294400008
DA 2021-02-24
ER

PT J
AU Carmichael, K
AF Carmichael, Katie
TI "Since when does the Midwest have an accent?" The role of regional US
   accents and reported speaker origin in speaker evaluations
SO ENGLISH WORLD-WIDE
LA English
DT Article
DE language attitudes; language ideologies; speech perception; speaker
   evaluation; regional dialects; sense of place; American English
ID LANGUAGE ATTITUDES; SPEECH-PERCEPTION; ENGLISH; STEREOTYPES; AMERICAN;
   INFORMATION
AB Folk ideologies about regional variation often depend on the consideration of certain varieties in contrast with the idea of a linguistically unmarked, standard way of speaking (Preston 1996; Lippi-Green 2012). This study analyzes the relationship between those abstract ideologies and in-the-moment reactions to linguistic input. Examining this question with respect to American English, a listening task manipulated where speakers were said to be from and whether the speakers used regional speech varieties linked to those places. Listeners were asked to make social judgments about speakers with varying degrees of local accentedness said to be from Southern, Northeastern, and Midwestern locales in the U.S.; these locations were selected to target highly enregistered nonstandard dialect areas versus more linguistically "unmarked" regions. Results indicate that while pre-existing sociolinguistic stereotypes about these three locations in some cases trumped the actual linguistic input that listeners encountered, effects of accentedness also varied in place-specific ways related to expectations for each locale.
C1 [Carmichael, Katie] Virginia Tech, Dept English, MC 0112,407 Shanks Hall,181 Turner St NW, Blacksburg, VA 24061 USA.
RP Carmichael, K (corresponding author), Virginia Tech, Dept English, MC 0112,407 Shanks Hall,181 Turner St NW, Blacksburg, VA 24061 USA.
EM katcarm@vt.edu
CR Agha A, 2003, LANG COMMUN, V23, P231, DOI 10.1016/S0271-5309(03)00012-0
   ANISFELD M, 1962, J ABNORM PSYCHOL, V65, P223, DOI 10.1037/h0045060
   Barbara Johnstone, 2006, J ENGL LINGUIST, V34, P77, DOI DOI 10.1177/0075424206290692
   Becker K, 2014, LANG SOC, V43, P395, DOI 10.1017/S0047404514000372
   Bonfiglio Thomas P., 2002, RACE RISE STANDARD A, DOI [10.1515/9783110851991, DOI 10.1515/9783110851991]
   CALLAN VJ, 1983, J CROSS CULT PSYCHOL, V14, P407, DOI 10.1177/0022002183014004002
   Campbell-Kibler K, 2015, J ENGL LINGUIST, V43, P95, DOI 10.1177/0075424215577834
   Campbell-Kibler K, 2009, LANG VAR CHANGE, V21, P135, DOI 10.1017/S0954394509000052
   Campbell-Kibler Kathryn, 2006, THESIS
   Clopper C., 2004, THESIS
   Clopper CG, 2007, J PHONETICS, V35, P421, DOI 10.1016/j.wocn.2006.06.001
   Clopper Cynthia G, 2006, Lang Var Change, V18, P193
   Clopper CG, 2006, SPEECH COMMUN, V48, P633, DOI 10.1016/j.specom.2005.09.010
   D'Onofrio A, 2015, J SOCIOLING, V19, P241, DOI 10.1111/josl.12115
   DiStefano C., 2009, PRACT ASSESSMENT RES, V14, P1, DOI DOI 10.10/1531-7714
   Eckert P., 2004, SOCIOLINGUISTIC VARI, P107
   Edwards J, 1999, J LANG SOC PSYCHOL, V18, P101, DOI 10.1177/0261927X99018001007
   GILES H, 1971, BRIT J SOC CLIN PSYC, V10, P280, DOI 10.1111/j.2044-8260.1971.tb00748.x
   Hartley Laura, 1999, STANDARD ENGLISH WID, P207
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   IANNACCARO G, 2001, SOC CULT GEOGR, V2, P265, DOI DOI 10.1080/14649360120073851
   Jeon L, 2015, DIALECTOLOGIA, P17
   Johnstone B., 2010, HDB LANGUAGE GLOBALI, P386, DOI [10.1002/9781444324068.ch17, DOI 10.1002/9781444324068.CH17]
   Johnstone B., 2004, SOCIOLINGUISTIC VARI
   Johnstone B, 2009, HANDB SPRACH KOMMUN, V1, P1
   Labov W., 2006, ATLAS N AM ENGLISH P
   Labov William, 2006, SOCIAL STRATIFICATIO, DOI [10.1017/CBO9780511618208, DOI 10.1017/CBO9780511618208]
   Labov William, 1991, NEW WAYS ANAL VARIAT, P1
   Ladegaard HJ, 1998, LANG COMMUN, V18, P251, DOI 10.1016/S0271-5309(98)00008-1
   LAMBERT WE, 1960, J ABNORM SOC PSYCH, V60, P44, DOI 10.1037/h0044430
   LEE RR, 1971, Q J SPEECH, V57, P410, DOI 10.1080/00335637109383086
   Lippi-Green R., 2012, ENGLISH ACCENT LANGU
   LUHMAN R, 1990, LANG SOC, V19, P331, DOI 10.1017/S0047404500014548
   Milroy L, 1999, J LANG SOC PSYCHOL, V18, P4, DOI 10.1177/0261927X99018001001
   Milroy L., 1977, BELFAST WORKING PAPE, V2, P1
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Powesland P. F., 1975, SPEECH STYLE SOCIAL
   Preston D., 1996, FOCUS US, P297, DOI DOI 10.1075/VEAW.G16.16PRE
   Preston Dennis, 1989, PERCEPTUAL DIALECTOL, DOI [10.1515/9783110871913, DOI 10.1515/9783110871913]
   Preston Dennis, 1999, LANGUAGE VARIETY S R, P311
   Purnell T, 1999, J LANG SOC PSYCHOL, V18, P10, DOI 10.1177/0261927X99018001002
   Staum Casasanto Laura, 2009, U PENNSYLVANIA WORKI, V15, P39
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Williams R. T., 1989, ENGLISH CULTURES CUL, P55, DOI [10.1515/9783110848328.55, DOI 10.1515/9783110848328.55]
   Zahn C. J., 1985, J LANG SOC PSYCHOL, V4, P113, DOI DOI 10.1177/0261927X8500400203
NR 45
TC 1
Z9 1
U1 1
U2 5
PU JOHN BENJAMINS PUBLISHING CO
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 0172-8865
EI 1569-9730
J9 ENGL WORLD-WIDE
JI Engl. World-Wide
PY 2018
VL 39
IS 2
BP 127
EP 156
DI 10.1075/eww.00008.car
PG 30
WC Linguistics; Language & Linguistics
SC Linguistics
GA GJ7QZ
UT WOS:000435585100001
DA 2021-02-24
ER

PT J
AU Zhu, Z
   Miyauchi, R
   Araki, Y
   Unoki, M
AF Zhu, Zhi
   Miyauchi, Ryota
   Araki, Yukiko
   Unoki, Masashi
TI Contributions of temporal cue on the perception of speaker individuality
   and vocal emotion for noise-vocoded speech
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Temporal cue; Speaker individuality; Vocal emotion; Noise-vocoded
   speech; Speech perception
ID MODULATION SPECTRAL FEATURES; COCHLEAR IMPLANTS; RECOGNITION;
   IDENTIFICATION; INFORMATION; HEARING; SIMULATIONS; CHANNELS; ENVELOPE;
   CHILDREN
AB This paper investigates the importance of temporal cues in the perception of speaker individuality and vocal emotion. Experiments of speaker and vocal-emotion recognition were carried out using an analysis/synthesis method of noise-vocoded speech (NVS). The temporal resolution of NVS was controlled by varying the upper limit of modulation frequency (0, 0.5, 1, 2, 4, 8, 16, 32, and 64 Hz). In addition, the role of temporal cue in the different spectral resolution condition was also investigated by varying the number of channels (4, 8, and 16). The results demonstrated that temporal resolution contributes to the recognition of both speaker and vocal emotion. Therefore, temporal cues are found to be important for the perception of not only linguistic information but also speaker individuality and vocal emotion. On the other hand, the performance of speaker recognition was less sensitive to the spectral resolution, at least in the limited set of stimuli in the present study. For vocal-emotion recognition, the spectral resolution was shown to be important for recognizing only neutral, joy, and cold anger, but not sadness or hot anger. The important modulation frequency band for the perception of nonlinguistic information was suggested to be higher than that of linguistic information.
C1 [Zhu, Zhi; Miyauchi, Ryota; Unoki, Masashi] Japan Adv Inst Sci & Technol, 1-1 Asahidai, Nomi 9231292, Japan.
   [Araki, Yukiko] Kanazawa Univ, Kakuma Machi, Kanazawa, Ishikawa 9201192, Japan.
RP Zhu, Z (corresponding author), Japan Adv Inst Sci & Technol, 1-1 Asahidai, Nomi 9231292, Japan.
EM zhuzhi@jaist.ac.jp; ryota@jaist.ac.jp; yukikoa@staff.kanazawa-u.ac.jp;
   unoki@jaist.ac.jp
FU MEXT, JapanMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT) [25240026, 16H01669]; Mitsubishi Research
   Foundation; JSPS KAKENHI GrantMinistry of Education, Culture, Sports,
   Science and Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP. 17J08312]
FX This work was supported by a Grant in Aid for Scientific Research (A)
   (No. 25240026), Innovative Areas (No. 16H01669) from MEXT, Japan, and
   the Mitsubishi Research Foundation. This work was also supported by JSPS
   KAKENHI Grant Number JP. 17J08312.
CR Arai T., 1997, P EUR RHOD GREEC, P1011
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Dau T, 1996, J ACOUST SOC AM, V99, P3623, DOI 10.1121/1.414960
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   Gonzalez J, 2005, J ACOUST SOC AM, V118, P461, DOI 10.1121/1.1928892
   Huang CF, 2008, SPEECH COMMUN, V50, P810, DOI 10.1016/j.specom.2008.05.017
   Intl. Telecom. Union, 1993, P56 ITUT
   Kitamura T., 1995, Journal of the Acoustical Society of Japan (E), V16, P283
   Kitamura T., 2015, J ACOUST SOC JPN J, V71, P516
   Kitamura T, 2005, ACOUST SCI TECHNOL, V26, P16, DOI 10.1250/ast.26.16
   Krull V, 2012, J ACOUST SOC AM, V131, P3069, DOI 10.1121/1.3688533
   Loizou PC, 1998, IEEE SIGNAL PROC MAG, V15, P101, DOI 10.1109/79.708543
   Loizou PC, 1999, J ACOUST SOC AM, V106, P2097, DOI 10.1121/1.427954
   Moore B. C. J., 2013, INTRO PSYCHOL HEARIN, P74
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Tachibana RO, 2013, ACOUST SCI TECHNOL, V34, P263, DOI 10.1250/ast.34.263
   Vongpaisal T, 2010, EAR HEARING, V31, P555, DOI 10.1097/AUD.0b013e3181daae5a
   Vongphoe M, 2005, J ACOUST SOC AM, V118, P1055, DOI 10.1121/1.1944507
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Xin Luo, 2007, Trends Amplif, V11, P301
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
   Xu L, 2008, HEARING RES, V242, P132, DOI 10.1016/j.heares.2007.12.010
   Zhu Z, 2016, ACOUST SCI TECHNOL, V37, P258, DOI 10.1250/ast.37.258
   Zhu Z, 2016, INTERSPEECH, P262, DOI 10.21437/Interspeech.2016-737
NR 30
TC 4
Z9 4
U1 0
U2 1
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2018
VL 39
IS 3
BP 234
EP 242
DI 10.1250/ast.39.234
PG 9
WC Acoustics
SC Acoustics
GA GI4FQ
UT WOS:000434326800008
OA Bronze
DA 2021-02-24
ER

PT J
AU Arai, T
   Osawa, E
   Igeta, T
   Hodoshima, N
AF Arai, Takayuki
   Osawa, Eri
   Igeta, Takako
   Hodoshima, Nao
TI Reverberation degrades native listener's perception of Japanese
   monosyllables and special morae
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Speech perception; Reverberation; Japanese; Monosyllable; Special mora
ID SPEECH
C1 [Arai, Takayuki] Sophia Univ, Dept Informat & Commun Sci, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
   [Osawa, Eri] Sophia Univ, Grad Sch Sci & Technol, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
   [Igeta, Takako] JF Oberlin Univ, Inst Japanese Language & Culture, Chuo Ku, 4-16-1 Fuchinobe, Sagamihara, Kanagawa 2520206, Japan.
   [Hodoshima, Nao] Tokai Univ, Dept Informat Media Technol, Minato Ku, 2-3-23 Takanawa, Tokyo 1088619, Japan.
RP Arai, T (corresponding author), Sophia Univ, Dept Informat & Commun Sci, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
EM arai@sophia.ac.jp
OI Hodoshima, Nao/0000-0002-2147-9378
CR Arai T, 2007, ACOUST SCI TECHNOL, V28, P438, DOI 10.1250/ast.28.438
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Fujisaki H., 1977, IWANAMI COURSE JAPAN, P63
   Fujisaki H., 1975, AUDITORY ANAL PERCEP, P197, DOI DOI 10.1016/B978-0-12-248550-3.50017-9
   Hodoshima N., 2007, THESIS
   Kingston J, 2009, J PHONETICS, V37, P297, DOI 10.1016/j.wocn.2009.03.007
   LIBERMAN AM, 1961, J EXP PSYCHOL, V61, P379, DOI 10.1037/h0049038
   NABELEK AK, 1989, J ACOUST SOC AM, V86, P1259
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
NR 10
TC 2
Z9 2
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2018
VL 39
IS 3
BP 252
EP 255
DI 10.1250/ast.39.252
PG 4
WC Acoustics
SC Acoustics
GA GI4FQ
UT WOS:000434326800010
OA Bronze
DA 2021-02-24
ER

PT J
AU Slater, J
   Kraus, N
   Carr, KW
   Tierney, A
   Azem, A
   Ashley, R
AF Slater, Jessica
   Kraus, Nina
   Carr, Kali Woodruff
   Tierney, Adam
   Azem, Andrea
   Ashley, Richard
TI Speech-in-noise perception is linked to rhythm production skills in
   adult percussionists and non-musicians
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Speech perception; music; rhythm; temporal processing
ID SCHUMANN TRAUMEREI; NORMAL-HEARING; BASAL GANGLIA; MASKED SPEECH;
   RESPONSES; DURATION; ENGLISH; DISCRIMINATION; DISTINCTION; PERFORMANCE
AB Speech rhythms guide perception, especially in noise. We recently revealed that percussionists outperform non-musicians in speech-in-noise perception, with better speech-in-noise perception associated with better rhythm discrimination across a range of rhythmic expertise. Here, we consider rhythm production skills, specifically drumming to a beat (metronome or music) and to sequences (metrical or jittered patterns), as well as speech-in-noise perception in adult percussionists and non-musicians. Given the absence of a regular beat in speech, we hypothesise that processing of sequences is more important for speech-in-noise perception than the ability to entrain to a regular beat. Consistent with our hypothesis, we find that the sequence-based drumming measures predict speech-in-noise perception, above and beyond hearing thresholds and IQ, whereas the beat-based measures do not. Outcomes suggest temporal patterns may help disambiguate speech under degraded listening conditions, extending theoretical considerations about speech rhythm to the everyday challenge of listening in noise.
C1 [Slater, Jessica; Kraus, Nina; Carr, Kali Woodruff; Tierney, Adam; Azem, Andrea] Northwestern Univ, Auditory Neurosci Lab, Evanston, IL 60208 USA.
   [Slater, Jessica; Kraus, Nina; Carr, Kali Woodruff; Tierney, Adam; Azem, Andrea] Northwestern Univ, Dept Commun Sci, Evanston, IL 60208 USA.
   [Kraus, Nina] Northwestern Univ, Inst Neurosci, Evanston, IL 60208 USA.
   [Kraus, Nina] Northwestern Univ, Dept Neurobiol, Evanston, IL 60208 USA.
   [Kraus, Nina] Northwestern Univ, Dept Otolaryngol, Evanston, IL 60208 USA.
   [Ashley, Richard] Northwestern Univ, Sch Mus, Evanston, IL USA.
   [Ashley, Richard] Northwestern Univ, Program Cognit Sci, Evanston, IL USA.
   [Tierney, Adam] Univ London Birkbeck, Dept Psychol Sci, London, England.
RP Kraus, N (corresponding author), Northwestern Univ, Auditory Neurosci Lab, Evanston, IL 60208 USA.; Kraus, N (corresponding author), Northwestern Univ, Dept Commun Sci, Evanston, IL 60208 USA.; Kraus, N (corresponding author), Northwestern Univ, Inst Neurosci, Evanston, IL 60208 USA.; Kraus, N (corresponding author), Northwestern Univ, Dept Neurobiol, Evanston, IL 60208 USA.; Kraus, N (corresponding author), Northwestern Univ, Dept Otolaryngol, Evanston, IL 60208 USA.
EM nkraus@northwestern.edu
RI Slater, Jessica/AAS-4515-2020
OI Slater, Jessica/0000-0001-7281-5231; Tierney, Adam/0000-0002-7624-6918
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [F31DC014891-01];
   National Association of Music Merchants (NAMM); Knowles Hearing Center
FX This work was supported by the National Institutes of Health [grant
   number F31DC014891-01] to J.S., the National Association of Music
   Merchants (NAMM) and the Knowles Hearing Center. The authors declare no
   competing financial interests.
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Alain Claude, 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920049
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Andreou LV, 2011, HEARING RES, V280, P228, DOI 10.1016/j.heares.2011.06.001
   Ashley R, 2002, MUSIC PERCEPT, V19, P311, DOI 10.1525/mp.2002.19.3.311
   Bella SD, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071945
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Brown L, 1997, TEST NONVERBAL INTEL
   Cameron DJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.01003
   Choi JY, 2005, J ACOUST SOC AM, V118, P2579, DOI 10.1121/1.2010288
   Cross I., 1999, MUSIC MIND SCI, P10
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ehrle N, 2005, BRAIN COGNITION, V58, P133, DOI 10.1016/j.bandc.2004.09.014
   FEAR BD, 1995, J ACOUST SOC AM, V97, P1893, DOI 10.1121/1.412063
   FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247
   Gordon RL, 2015, DEVELOPMENTAL SCI, V18, P635, DOI 10.1111/desc.12230
   Graybiel AM, 1997, SCHIZOPHRENIA BULL, V23, P459, DOI 10.1093/schbul/23.3.459
   Herdener M, 2014, CEREB CORTEX, V24, P836, DOI 10.1093/cercor/bhs367
   Iversen J.R., 2008, P 10 INT C MUS PERC, V10, P465, DOI DOI 10.1016/J.HEARES.2007.10.007
   Ivry R B, 1989, J Cogn Neurosci, V1, P136, DOI 10.1162/jocn.1989.1.2.136
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010
   Krause V, 2010, NEUROIMAGE, V52, P245, DOI 10.1016/j.neuroimage.2010.03.081
   Lehiste Ilse, 1977, J PHONETICS, V5, P253, DOI 10.1016/S0095-4470(19)31139-8
   LIBERMAN M, 1977, LINGUIST INQ, V8, P249
   Manning FC, 2016, PSYCHOL RES-PSYCH FO, V80, P532, DOI 10.1007/s00426-015-0678-5
   Matthews TE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00069
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Palmer C, 1997, ANNU REV PSYCHOL, V48, P115, DOI 10.1146/annurev.psych.48.1.115
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel A. D., 2008, MUSIC LANGUAGE BRAIN
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   POVEL DJ, 1985, MUSIC PERCEPT, V2, P411
   Rammsayer T, 2006, MUSIC PERCEPT, V24, P37, DOI 10.1525/mp.2006.24.1.37
   REPP BH, 1995, J ACOUST SOC AM, V98, P2413, DOI 10.1121/1.413276
   REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Salvi RJ, 2002, HEARING RES, V170, P96, DOI 10.1016/S0378-5955(02)00386-6
   Schmidt-Kassow M, 2008, BRAIN RES, V1226, P144, DOI 10.1016/j.brainres.2008.06.017
   SCOTT DR, 1982, J ACOUST SOC AM, V71, P996, DOI 10.1121/1.387581
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Slater J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077250
   SMITH MR, 1989, J SPEECH HEAR RES, V32, P912, DOI 10.1044/jshr.3204.912
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Swaminathan J, 2014, J ACOUST SOC AM, V135, P2078, DOI 10.1121/1.4865920
   Teki S, 2011, J NEUROSCI, V31, P3805, DOI 10.1523/JNEUROSCI.5561-10.2011
   Thompson EC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128839
   Tierney A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136645
   Turk AE, 1997, J PHONETICS, V25, P25, DOI 10.1006/jpho.1996.0032
   Vuust P, 2006, NEUROIMAGE, V31, P832, DOI 10.1016/j.neuroimage.2005.12.037
   Vuust P, 2005, NEUROIMAGE, V24, P560, DOI 10.1016/j.neuroimage.2004.08.039
NR 56
TC 1
Z9 1
U1 0
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 6
BP 710
EP 717
DI 10.1080/23273798.2017.1411960
PG 8
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA GE9YL
UT WOS:000431587000004
PM 31475217
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Tuninetti, A
   Tokowicz, N
AF Tuninetti, Alba
   Tokowicz, Natasha
TI The influence of a first language: training nonnative listeners on
   voicing contrasts
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Speech perception; second language; EEG; MMN; training
ID MISMATCH NEGATIVITY MMN; R-VERTICAL-BAR; NATIVE PHONOLOGICAL SYSTEM;
   SPEECH-PERCEPTION; CROSS-LANGUAGE; JAPANESE LISTENERS; PHONETIC
   CATEGORIES; AUDITORY STIMULUS; BRAIN RESPONSES; ONSET TIME
AB Learning how to perceive speech contrasts in a second language (L2) is influenced by many factors, including similarity to the first language (L1). Over five days, we trained native English and native Spanish speakers to perceive differences in the voiced Hindi contrast /p/-/p(h)/ while recording their mismatch negativity (MMN) response before, during, and after training. Our results show that only native Spanish speakers showed a decrease in MMN amplitude following training, suggesting that the nonnative contrast was learned successfully, but this was not the case for native English speakers. This suggests that the acoustic and phonetic organisation of L1 differentially affects how we perceive and learn L2 sounds. We examine our results in the context of L2 learning and speech models, suggesting that further development on the difficulty of learning to perceive L2 speech should include more details on similarity to L1.
C1 [Tuninetti, Alba; Tokowicz, Natasha] Univ Pittsburgh, Dept Psychol, Learning Res & Dev Ctr, Pittsburgh, PA 15260 USA.
RP Tuninetti, A (corresponding author), Univ Pittsburgh, Dept Psychol, Learning Res & Dev Ctr, Pittsburgh, PA 15260 USA.
EM alt63@pitt.edu
OI Tuninetti, Alba/0000-0002-0087-7756
FU Language Learning Journal Dissertation Grant; NSF DDIGNational Science
   Foundation (NSF) [1451424]; Australian Research Council (ARC) Centre of
   Excellence for the Dynamics of LanguageAustralian Research Council
   [CE140100041]; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 HD075800];
   Division of Behavioral and Cognitive SciencesNational Science Foundation
   (NSF)NSF - Directorate for Social, Behavioral & Economic Sciences (SBE);
   Eunice Kennedy Shriver National Institute of Child Health and Human
   DevelopmentUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD); Direct For
   Social, Behav & Economic ScieNational Science Foundation (NSF)NSF -
   Directorate for Social, Behavioral & Economic Sciences (SBE) [1451424]
   Funding Source: National Science Foundation; Division Of Behavioral and
   Cognitive SciNational Science Foundation (NSF)NSF - Directorate for
   Social, Behavioral & Economic Sciences (SBE) [1451424] Funding Source:
   National Science Foundation
FX This research was supported by a Language Learning Journal Dissertation
   Grant (2014) and by NSF DDIG Award 1451424 to NT and AT. During the
   writing of this manuscript, AT was supported by the Australian Research
   Council (ARC) Centre of Excellence for the Dynamics of Language
   [CE140100041] and NT was supported by NIH R01 HD075800; Division of
   Behavioral and Cognitive Sciences; Eunice Kennedy Shriver National
   Institute of Child Health and Human Development.
CR Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Best C. T., 1992, HASKINS LABORATORIES, V109/110, P89
   Best C. T., 2003, P 15 INT C PHON SCI
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Brandmeyer A, 2012, NEUROREPORT, V23, P653, DOI 10.1097/WNR.0b013e32835542cd
   Bundgaard-Nielsen RL, 2011, APPL PSYCHOLINGUIST, V32, P51, DOI 10.1017/S0142716410000287
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   Elvin J, 2016, J ACOUST SOC AM, V140, P576, DOI 10.1121/1.4952387
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Flanagan J L, 1972, SPEECH ANAL SYNTHESI
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   FLEGE JE, 1989, J ACOUST SOC AM, V86, P1684, DOI 10.1121/1.398599
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Keil A, 2014, PSYCHOPHYSIOLOGY, V51, P1, DOI 10.1111/psyp.12147
   KRAUS N, 1995, J COGNITIVE NEUROSCI, V7, P25, DOI 10.1162/jocn.1995.7.1.25
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1993, NATO ADV SCI INST SE, V69, P259
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Liu R, 2011, J COGNITIVE NEUROSCI, V23, P683, DOI 10.1162/jocn.2009.21392
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Llanos F, 2013, J ACOUST SOC AM, V134, P2213, DOI 10.1121/1.4817845
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   MacWhinney B, 2005, HDB BILINGUALISM PSY, P49
   MacWhinney B., 2012, ROUTLEDGE HDB 2 LANG, P221, DOI [10.4324/9780203808184.ch13., DOI 10.4324/9780203808184.CH13, 10.4324/9780203808184.ch13]
   McCandliss BD, 2002, COGN AFFECT BEHAV NE, V2, P89, DOI 10.3758/CABN.2.2.89
   McClelland JL, 2002, PHYSIOL BEHAV, V77, P657, DOI 10.1016/S0031-9384(02)00916-2
   Mueller JL, 2005, SECOND LANG RES, V21, P152, DOI 10.1191/0267658305sr256oa
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Naatanen R, 2004, CLIN NEUROPHYSIOL, V115, P140, DOI 10.1016/j.clinph.2003.04.001
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Nenonen S, 2005, BRAIN LANG, V92, P26, DOI 10.1016/j.bandl.2004.05.005
   Nenonen S, 2003, COGNITIVE BRAIN RES, V16, P492, DOI 10.1016/S0926-6410(03)00055-7
   OYAMA S, 1976, J PSYCHOLINGUIST RES, V5, P261, DOI 10.1007/BF01067377
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Peltola MS, 2003, NEUROSCI LETT, V352, P25, DOI 10.1016/j.neulet.2003.08.013
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   Pruitt JS, 2006, J ACOUST SOC AM, V119, P1684, DOI 10.1121/1.2161427
   R Core Team, 2013, R LANG ENV STAT COMP
   Raven J., 1981, MANUAL RAVENS PRO S1
   Rivera-Gaxiola M, 2000, BEHAV BRAIN RES, V111, P13, DOI 10.1016/S0166-4328(00)00139-X
   SAMS M, 1984, PSYCHOPHYSIOLOGY, V21, P434, DOI 10.1111/j.1469-8986.1984.tb00223.x
   Schmidt R, 1993, ANNU REV APPL LINGUI, V13, P206, DOI [10.1017/S0267190500002476, DOI 10.1017/S0267190500002476]
   SCHMIDT RW, 1990, APPL LINGUIST, V11, P129, DOI 10.1093/applin/11.2.129
   SELIGER H, 1975, LANG SCI, V36, P20
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   SUMMERFIELD Q, 1977, J ACOUST SOC AM, V62, P435, DOI 10.1121/1.381544
   TAHTA S, 1981, LANG SPEECH, V24, P363, DOI 10.1177/002383098102400405
   Tamminen H, 2015, INT J PSYCHOPHYSIOL, V97, P23, DOI 10.1016/j.ijpsycho.2015.04.020
   Tokowicz N., 2004, BILING-LANG COGN, V7, P255, DOI DOI 10.1017/S1366728904001634
   Tolentino LC, 2011, STUD SECOND LANG ACQ, V33, P91, DOI 10.1017/S0272263110000549
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Tremblay K, 1997, J ACOUST SOC AM, V102, P3762, DOI 10.1121/1.420139
   Tricomi E, 2006, J COGNITIVE NEUROSCI, V18, P1029, DOI 10.1162/jocn.2006.18.6.1029
   TURNER ML, 1989, J MEM LANG, V28, P127, DOI 10.1016/0749-596X(89)90040-5
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   WINKLER I, 1990, PSYCHOPHYSIOLOGY, V27, P228, DOI 10.1111/j.1469-8986.1990.tb00374.x
   Ylinen S, 2010, J COGNITIVE NEUROSCI, V22, P1319, DOI 10.1162/jocn.2009.21272
NR 70
TC 0
Z9 0
U1 0
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 6
BP 750
EP 768
DI 10.1080/23273798.2017.1421318
PG 19
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA GE9YL
UT WOS:000431587000007
DA 2021-02-24
ER

PT J
AU Volter, C
   Gotze, L
   Dazert, T
   Falkenstein, M
   Thomas, JP
AF Voelter, Christiane
   Goetze, Lisa
   Dazert, Tefan
   Falkenstein, Michael
   Thomas, Jan Peter
TI Can cochlear implantation improve neurocognition in the aging
   population?
SO CLINICAL INTERVENTIONS IN AGING
LA English
DT Article
DE neurocognition; cochlear implantation; hearing rehabilitation; aging
ID QUALITY-OF-LIFE; MILD COGNITIVE IMPAIRMENT; HEARING-AID USE;
   WORKING-MEMORY; OLDER-ADULTS; AGE-DIFFERENCES; SPEECH RECOGNITION;
   DEMENTIA FINDINGS; PERFORMANCE; IMPACT
AB Introduction: The relationship between cognition and the ability to hear is well known. Due to changes in demographics, the number of people with sensorineural hearing loss and cognitive impairment is increasing. The aim of this study was to identify the impact of hearing rehabilitation via cochlear implantation on cognitive decline among the aging population.
   Patients and methods: This prospective study included 60 subjects aged between 50 and 84 years (mean 65.8 years, SD=8.9) with a severe to profound bilateral hearing impairment. A computer-based evaluation of short-and long-term memory, processing speed, attention, working memory and inhibition was performed prior to surgery as well as 6 and 12 months after cochlear implantation. Additionally, speech perception at 65 and 80 dB (Freiburger monosyllabic speech test) as well as disease-related (Nijmegen Cochlear Implant Questionnaire) and general (WHOQOL-OLD) quality of life were assessed.
   Results: Six months postimplantation, speech perception, quality of life and also neurocognitive abilities significantly increased. The most remarkable improvement after 6 months was detected in executive functions such as attention (p<0.001), inhibition (p=0.025) and working memory (n-back: p=0.002; operation span task: p=0.008), followed by delayed recall (p=0.03). In contrast, long-term memory showed a significant change of performance only after 12 months (p=0.021). After 6 months, most cognitive domains remained stable, except working memory assessed by the operation span task, which significantly improved between 6 and 12 months (p<0.001). No correlation was found between cognitive results and duration of deafness, speech perception or quality of life.
   Conclusion: Cochlear implantation does not only lead to better speech perception and quality of life, but has also been shown to improve cognitive skills in hearing impaired adults aged 50 years or more. These effects seem to be independent of each other.
C1 [Voelter, Christiane; Goetze, Lisa; Dazert, Tefan; Thomas, Jan Peter] Ruhr Univ Bochum, St Elisabeth Hosp, Dept Otorhinolaryngol Head & Neck Surg, Bleichstr 15, D-44787 Bochum, Germany.
   [Falkenstein, Michael] Inst Work Learning & Ageing ALA, Bochum, Germany.
   [Falkenstein, Michael] Leibniz Res Ctr Working Environm & Human Factors, Dortmund, Germany.
RP Volter, C (corresponding author), Ruhr Univ Bochum, St Elisabeth Hosp, Dept Otorhinolaryngol Head & Neck Surg, Bleichstr 15, D-44787 Bochum, Germany.
EM christiane.voelter@ruhr-uni-bochum.de
RI Falkenstein, Michael/ABA-7497-2020
FU MedEL
FX CV has received travel expense support from MedEL, SD has received third
   party funds, payment for lectures and travel expense support from MedEL,
   and JPT has received travel expense support and payment for lectures
   from MedEL. The authors report no conflicts of interest in this work.
CR Ambert-Dahan E, 2017, OTOL NEUROTOL, V38, pE282, DOI 10.1097/MAO.0000000000001464
   Amieva H, 2015, J AM GERIATR SOC, V63, P2099, DOI 10.1111/jgs.13649
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Bell-McGinty S, 2002, INT J GERIATR PSYCH, V17, P828, DOI 10.1002/gps.646
   Braver TS, 2001, J EXP PSYCHOL GEN, V130, P746, DOI 10.1037//0096-3445.130.4.746
   Brickenkamp R, 1962, TEST D2 AUFMERKSAMKE
   Brookmeyer R, 2007, ALZHEIMERS DEMENT, V3, P186, DOI 10.1016/j.jalz.2007.04.381
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Capretta NR, 2016, LARYNGOSCOPE, V126, P699, DOI 10.1002/lary.25525
   Castiglione A, 2016, AUDIOL NEURO-OTOL, V21, P21, DOI 10.1159/000448350
   Chan RCK, 2008, ARCH CLIN NEUROPSYCH, V23, P201, DOI 10.1016/j.acn.2007.08.010
   Claes AJ, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00512
   Conrad I, 2015, PSYCHIAT PRAX, V42, P152, DOI 10.1055/s-0034-1369831
   Cosetti MK, 2016, CLIN INTERV AGING, V11, P603, DOI 10.2147/CIA.S100255
   Davies HR, 2017, J AM GERIATR SOC, V65, P2074, DOI 10.1111/jgs.14986
   Dawes P, 2015, INT J AUDIOL, V54, P838, DOI 10.3109/14992027.2015.1059503
   de Oliveira RS, 2014, EINSTEIN-SAO PAULO, V12, P149, DOI 10.1590/S1679-45082014AO2954
   Desjardins JL, 2016, AM J AUDIOL, V25, P127, DOI 10.1044/2016_AJA-15-0067
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   DOBBS AR, 1989, PSYCHOL AGING, V4, P500, DOI 10.1037/0882-7974.4.4.500
   Doherty KA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00721
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Ferri CP, 2005, LANCET, V366, P2112, DOI 10.1016/S0140-6736(05)67889-0
   Fortunato S, 2016, ACTA OTORHINOLARYNGO, V36, P155, DOI 10.14639/0392-100X-993
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Fullgrabe C, 2016, ADV EXP MED BIOL, V894, P29, DOI 10.1007/978-3-319-25474-6_4
   Fulton Susan E., 2015, Seminars in Hearing, V36, P140, DOI 10.1055/s-0035-1555117
   Gablenz P, 2015, HNO, V63, P195, DOI DOI 10.1007/S00106-014-2949-7
   Gaylor JM, 2013, JAMA OTOLARYNGOL, V139, P265, DOI 10.1001/jamaoto.2013.1744
   Harper A, 1998, PSYCHOL MED, V28, P551, DOI 10.1017/S0033291798006667
   Helmstaedter C., 2001, VERBALER LERN MERKFA
   Heydebrand G, 2007, AUDIOL NEURO-OTOL, V12, P254, DOI 10.1159/000101473
   Heywood R, 2017, DEMENT GERIATR COGN, V43, P259, DOI 10.1159/000464281
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Hirschfelder A, 2008, OTOLARYNG HEAD NECK, V138, P357, DOI 10.1016/j.otohns.2007.10.019
   Jayakody DMP, 2018, CLIN OTOLARYNGOL, V43, P182, DOI 10.1111/coa.12937
   Jayakody DMP, 2017, OTOL NEUROTOL, V38, pE289, DOI 10.1097/MAO.0000000000001502
   Kalbe E, 2004, INT J GERIATR PSYCH, V19, P136, DOI 10.1002/gps.1042
   Kalluri S, 2012, AM J AUDIOL, V21, P338, DOI 10.1044/1059-0889(2012/12-0026)
   KIRCHNER WK, 1958, J EXP PSYCHOL, V55, P352, DOI 10.1037/h0043688
   Knight S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00230
   Lehrl S, 2005, MWT B MEHRFACH WORTS
   Lenarz T, 2017, AUDIOL NEURO-OTOL, V22, P61, DOI 10.1159/000477533
   Lin FR, 2014, AGING MENT HEALTH, V18, P671, DOI 10.1080/13607863.2014.915924
   Lin FR, 2012, MEDICINE, V91, P229, DOI 10.1097/MD.0b013e31826b145a
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lodeiro-Fernandez L, 2015, CLIN INTERV AGING, V10, P695, DOI 10.2147/CIA.S81260
   McRackan TR, 2018, LARYNGOSCOPE, V128, P982, DOI 10.1002/lary.26738
   Meister H, 2013, NEUROSCIENCE, V232, P74, DOI 10.1016/j.neuroscience.2012.12.006
   Miller G, 2015, BMC GERIATR, V15, DOI 10.1186/s12877-015-0014-3
   Moberly AC, 2017, LARYNGOSCOPE INVEST, V2, P254, DOI 10.1002/lio2.90
   Moberly AC, 2016, OTOL NEUROTOL, V37, P1522, DOI 10.1097/MAO.0000000000001211
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   Mukari SZMS, 2017, ANN OTO RHINOL LARYN, V126, P697, DOI 10.1177/0003489417727547
   Oberauer K, 2003, INTELLIGENCE, V31, P167, DOI 10.1016/S0160-2896(02)00115-0
   Power M, 2005, QUAL LIFE RES, V14, P2197, DOI 10.1007/s11136-005-7380-9
   Qiu Chengxuan, 2009, Dialogues Clin Neurosci, V11, P111
   Redick TS, 2013, PSYCHON B REV, V20, P1102, DOI 10.3758/s13423-013-0453-9
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Reuter-Lorenz PA, 2000, J COGNITIVE NEUROSCI, V12, P174, DOI 10.1162/089892900561814
   Rey-Mermet A, PSYCHON B REV
   Ronnberg J, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00326
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Roth TN, 2011, EUR ARCH OTO-RHINO-L, V268, P1101, DOI 10.1007/s00405-011-1597-8
   Rudner M, 2011, J AM ACAD AUDIOL, V22, P156, DOI 10.3766/jaaa.22.3.4
   Salthouse TA, 2000, BIOL PSYCHOL, V54, P35, DOI 10.1016/S0301-0511(00)00052-1
   Salthouse TA, 2011, INTELLIGENCE, V39, P222, DOI 10.1016/j.intell.2011.03.001
   Sonnet MH, 2017, OTOL NEUROTOL, V38, pE296, DOI 10.1097/MAO.0000000000001503
   Stenfelt S, 2009, SCAND J PSYCHOL, V50, P385, DOI 10.1111/j.1467-9450.2009.00748.x
   Su PJ, 2017, EUR ARCH OTO-RHINO-L, V274, P2327, DOI 10.1007/s00405-017-4471-5
   Thomson RS, 2017, LARYNGOSCOPE INVEST, V2, P69, DOI 10.1002/lio2.65
   THURSTONE LL, 1948, SCIENCE, V108, P585
   TURNER ML, 1989, J MEM LANG, V28, P127, DOI 10.1016/0749-596X(89)90040-5
   Uchida Y, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00201
   United Nations, WORLD POP AG 1950 20
   van Hooren SAH, 2005, INT J AUDIOL, V44, P265, DOI 10.1080/14992020500060370
   Verhaeghen P, 2011, CURR DIR PSYCHOL SCI, V20, P174, DOI 10.1177/0963721411408772
   Volter C, 2017, CLIN INTERV AGING, V12, P1681, DOI 10.2147/CIA.S142541
   Wild-Wall N, 2008, BRAIN RES, V1211, P72, DOI 10.1016/j.brainres.2008.03.025
   Wild-Wall N, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00186
   World Health Organization, 2001, DEAFN HEAR IMP SURV
   Yesavage JA, 2002, J PSYCHIAT RES, V36, P281, DOI 10.1016/S0022-3956(02)00020-1
NR 82
TC 30
Z9 30
U1 0
U2 8
PU DOVE MEDICAL PRESS LTD
PI ALBANY
PA PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND
EI 1178-1998
J9 CLIN INTERV AGING
JI Clin. Interv. Aging
PY 2018
VL 13
BP 701
EP 712
DI 10.2147/CIA.S160517
PG 12
WC Geriatrics & Gerontology
SC Geriatrics & Gerontology
GA GE6RB
UT WOS:000431355600002
PM 29719382
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cheng, XT
   Liu, YWY
   Wang, B
   Yuan, YS
   Galvin, JJ
   Fu, QJ
   Shu, YL
   Chen, B
AF Cheng, Xiaoting
   Liu, Yangwenyi
   Wang, Bing
   Yuan, Yasheng
   Galvin, John J., III
   Fu, Qian-Jie
   Shu, Yilai
   Chen, Bing
TI The Benefits of Residual Hair Cell Function for Speech and Music
   Perception in Pediatric Bimodal Cochlear Implant Listeners
SO NEURAL PLASTICITY
LA English
DT Article
ID MELODIC CONTOUR IDENTIFICATION; ELECTRIC-STIMULATION; ACOUSTIC
   STIMULATION; PITCH PERCEPTION; NONIMPLANTED EAR; TONE PERCEPTION;
   YOUNG-CHILDREN; HEARING-AID; RECOGNITION; VALIDATION
AB Objective. The aim of this study was to investigate the benefits of residual hair cell function for speech and music perception in bimodal pediatric Mandarin-speaking cochlear implant (CI) listeners. Design. Speech and music performance was measured in 35 Mandarin-speaking pediatric CI users for unilateral (CI-only) and bimodal listening. Mandarin speech perception was measured for vowels, consonants, lexical tones, and sentences in quiet. Music perception was measured for melodic contour identification (MCI). Results. Combined electric and acoustic hearing significantly improved MCI and Mandarin tone recognition performance, relative to CI-only performance. For MCI, performance was significantly better with bimodal listening for all semitone spacing conditions (p < 0 05 in all cases). For tone recognition, bimodal performance was significantly better only for tone 2 (rising; p < 0 05). There were no significant differences between CI-only and CI + HA for vowel, consonant, or sentence recognition. Conclusions. The results suggest that combined electric and acoustic hearing can significantly improve perception of music and Mandarin tones in pediatric Mandarin-speaking CI patients. Music and lexical tone perception depends strongly on pitch perception, and the contralateral acoustic hearing coming from residual hair cell function provided pitch cues that are generally not well preserved in electric hearing.
C1 [Cheng, Xiaoting; Liu, Yangwenyi; Wang, Bing; Yuan, Yasheng; Shu, Yilai; Chen, Bing] Fudan Univ, Throat Hosp, Dept Otol & Skull Base Surg, Eye & Ear,Nose, Shanghai, Peoples R China.
   [Cheng, Xiaoting; Liu, Yangwenyi; Wang, Bing; Yuan, Yasheng; Shu, Yilai; Chen, Bing] Natl Hlth & Family Planning Commiss, Key Lab Hearing Med, Shanghai, Peoples R China.
   [Galvin, John J., III] House Ear Res Inst, Los Angeles, CA USA.
   [Fu, Qian-Jie] Univ Calif Los Angeles, David Geffen Sch Med, Dept Head & Neck Surg, Los Angeles, CA 90095 USA.
RP Shu, YL; Chen, B (corresponding author), Fudan Univ, Throat Hosp, Dept Otol & Skull Base Surg, Eye & Ear,Nose, Shanghai, Peoples R China.; Shu, YL; Chen, B (corresponding author), Natl Hlth & Family Planning Commiss, Key Lab Hearing Med, Shanghai, Peoples R China.
EM yilai_shu@fudan.edu.cn; bingchen@fudan.edu.cn
OI Fu, Qian-Jie/0000-0003-3494-7633
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01-DC 004792]; Joint
   project of key disease of health system in shanghai [2014ZYJB0005];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81570914]; NATIONAL INSTITUTE ON DEAFNESS
   AND OTHER COMMUNICATION DISORDERSUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC004792, R01DC004792, R01DC004792, R01DC004792, R01DC004792,
   R01DC004792, R01DC004792, R01DC004792, R01DC004792, R01DC004792,
   R01DC004792, R01DC004792, R01DC004792, R01DC004792, R01DC004792,
   R01DC004792, R01DC004792, R01DC004792] Funding Source: NIH RePORTER
FX The authors thank the subjects for their participation in this study.
   This work was partly supported by the National Institutes of Health
   (Grant no. R01-DC 004792), Joint project of key disease of health system
   in shanghai (2014ZYJB0005), and the National Natural Science Foundation
   of China (Grant nos. 81570914).
CR Armstrong M, 1997, AM J OTOL, V18, pS140
   Bartov T, 2014, J SPEECH LANG HEAR R, V57, P1929, DOI 10.1044/2014_JSLHR-H-13-0190
   Berrettini S, 2010, AM J OTOLARYNG, V31, P332, DOI 10.1016/j.amjoto.2009.04.002
   Brown CA, 2009, EAR HEARING, V30, P489, DOI 10.1097/AUD.0b013e3181ab2b87
   Chang YP, 2016, EAR HEARING, V37, P271, DOI 10.1097/AUD.0000000000000265
   Chen JKC, 2014, OTOL NEUROTOL, V35, P1409, DOI 10.1097/MAO.0000000000000407
   Ching TYC, 2004, EAR HEARING, V25, P9, DOI 10.1097/01.AUD.0000111261.84611.C8
   Crew JD, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669329
   Crew JD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120279
   Cullington HE, 2011, EAR HEARING, V32, P16, DOI 10.1097/AUD.0b013e3181edfbd2
   Dorman MF, 2008, AUDIOL NEURO-OTOL, V13, P105, DOI 10.1159/000111782
   Dorman MF, 2010, INT J AUDIOL, V49, P912, DOI 10.3109/14992027.2010.509113
   Driscoll VD, 2016, OTOL NEUROTOL, V37, pE141, DOI 10.1097/MAO.0000000000000945
   El Fata F, 2009, AUDIOL NEURO-OTOL, V14, P14, DOI 10.1159/000206491
   Fu QJ, 2015, J SPEECH LANG HEAR R, V58, P163, DOI 10.1044/2014_JSLHR-H-14-0127
   Fu QJ, 2011, J ACOUST SOC AM, V129, pEL267, DOI 10.1121/1.3590739
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   Fu QJ, 2004, EAR HEARING, V25, P501, DOI 10.1097/01.aud.0000145125.50433.19
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Galvin JJ, 2009, ANN NY ACAD SCI, V1169, P518, DOI 10.1111/j.1749-6632.2009.04551.x
   Gfeller Kate E, 2006, Audiol Neurootol, V11 Suppl 1, P12, DOI 10.1159/000095608
   Heo Ji-Hye, 2013, Korean J Audiol, V17, P65, DOI 10.7874/kja.2013.17.2.65
   Huang T S, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P294
   Kong YY, 2005, J ACOUST SOC AM, V117, P1351, DOI 10.1121/1.1857526
   Kumar SBR, 2010, INDIAN J OTOLARYNGOL, V62, P342, DOI 10.1007/s12070-010-0050-4
   Li YG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111707
   Li YX, 2017, INT J AUDIOL, V56, pS31, DOI 10.1080/14992027.2016.1204564
   Lin MC, 1988, CHINESE YUWEN, V204, P182
   Looi V, 2008, INT J AUDIOL, V47, P257, DOI 10.1080/14992020801955237
   Luo X, 2008, EAR HEARING, V29, P957, DOI 10.1097/AUD.0b013e3181888f61
   Luo X, 2014, HEARING RES, V312, P1, DOI 10.1016/j.heares.2014.02.005
   Peterson N., 2011, COCHLEAR IMPLANTS S3, V16, pS71
   Polonenko MJ, 2017, J ACOUST SOC AM, V141, P4494, DOI 10.1121/1.4985123
   Potts LG, 2009, J AM ACAD AUDIOL, V20, P353, DOI 10.3766/jaaa.20.6.4
   Prentiss SM, 2015, J AM ACAD AUDIOL, V26, P494, DOI 10.3766/jaaa.14098
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Shirvani S, 2016, ANN OTO RHINOL LARYN, V125, P470, DOI 10.1177/0003489415619943
   Su Q., 2016, TRENDS HEARING
   Sucher Catherine M, 2009, Cochlear Implants Int, V10 Suppl 1, P96, DOI 10.1179/cim.2009.10.Supplement-1.96
   Tao DD, 2015, EAR HEARING, V36, P102, DOI 10.1097/AUD.0000000000000086
   Tyler RS, 2002, EAR HEARING, V23, P98, DOI 10.1097/00003446-200204000-00003
   Wang R. H., 1993, STANDARD CHINESE DAT
   Wei WI, 2000, ACTA OTO-LARYNGOL, V120, P218
   Wu JL, 2003, INT J PEDIATR OTORHI, V67, P247, DOI 10.1016/S0165-5876(02)00378-6
   Yang HI, 2017, INT J AUDIOL, V56, pS17, DOI 10.1080/14992027.2017.1321789
   Yoon Yang-Soo, 2015, Cochlear Implants Int, V16, P159, DOI 10.1179/1754762814Y.0000000101
   Yoon YS, 2012, J SPEECH LANG HEAR R, V55, P105, DOI 10.1044/1092-4388(2011/10-0325)
   Yuen Kevin C P, 2009, Cochlear Implants Int, V10 Suppl 1, P120, DOI 10.1179/cim.2009.10.Supplement-1.120
   Zhang T, 2010, EAR HEARING, V31, P195, DOI 10.1097/AUD.0b013e3181c4758d
   Zhang T, 2010, EAR HEARING, V31, P63, DOI 10.1097/AUD.0b013e3181b7190c
   Zhou N, 2013, OTOL NEUROTOL, V34, P499, DOI 10.1097/MAO.0b013e318287ca86
   Zhu MM, 2012, ACTA OTO-LARYNGOL, V132, P855, DOI 10.3109/00016489.2011.653668
NR 52
TC 8
Z9 8
U1 0
U2 4
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2090-5904
EI 1687-5443
J9 NEURAL PLAST
JI Neural. Plast.
PY 2018
VL 2018
AR 4610592
DI 10.1155/2018/4610592
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA GE4ZS
UT WOS:000431227600001
PM 29849556
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Katz, WF
   Mehta, S
   Wood, M
AF Katz, William F.
   Mehta, Sonya
   Wood, Matthew
TI Effects of syllable position and vowel context on Japanese /r/:
   Kinematic and perceptual data
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Speech production; Articulatory movement; Electromagnetic
   articulography; Speech perception
AB In order to investigate the articulatory processes involved in producing Japanese /r/, we obtained speech recordings for native talkers of standard Japanese using an electromagnetic articulography (EMA) system. Each talker produced repetitions of /r/in a carrier phrase designed to contrast syllable (CV and VCV VCV) and vowel (/a/, /i/, /u/, /e/, and /o/) contexts. Kinematic recordings were made using tongue (tip, TT; dorsum, TD; body, TB; left lateral, TLL; and right lateral, TRL) and lower lip/jaw (LL) sensors. We measured TT vertical displacement, TT duration at maximum position, and tongue blade width for the consonant gestures. In a perceptual experiment, American English listeners decided whether these consonants consisted of 'l,' 'r,' or 'd.' The kinematic results indicate Japanese talkers produced CV consonants with greater stricture and longer closures than consonants in intervocalic positions. CV productions also had narrower tongue blade widths than VCV VCV productions, especially in /i/and /u/contexts. The data were modeled with Dirichlet regression in order to determine how strongly tongue width and context (syllable and vowel) factors predict listeners' judgments. The results showed a significant fit for 'r' judgments, with the tongue width fit successively increased by the addition of syllable and vowel context information.
C1 [Katz, William F.; Mehta, Sonya] Univ Texas Dallas, 800 W Campbell Rd, Richardson, TX 75080 USA.
   [Wood, Matthew] Univ Texas San Antonio, One UTSA Circle San Antonio, San Antonio, TX 78249 USA.
RP Katz, WF (corresponding author), Univ Texas Dallas, 800 W Campbell Rd, Richardson, TX 75080 USA.
EM wkatz@utdallas.edu
OI Katz, William/0000-0002-5627-6458
CR Akamatsu T., 1997, JAPANESE PHONETICS T, P106
   Amanuma Y., 2004, NIHONGO ONSEIGAKU  C
   Green JR, 2013, INTERSPEECH, P1330
   Hirahara T., 2004, P 18 INT C AC KYOT, P3387
   Joo H., 2005, NIHON ONSEIGAKU KENK
   Katz WF, 2017, J ACOUST SOC AM, V141, pEL57, DOI 10.1121/1.4973907
   KAWAKAMI S, 1977, NIHONGO ONSEI GAISET
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   Kokken [ National Language Research Institute], 1990, 100 KOKK
   Ladefoged P., 2016, COURSE PHONETICS
   Magnuson T., 2010, CAN ACOUST, V38, P130
   Magnuson T., 2009, THESIS, P2
   Magnuson Thomas, 2011, P ICPHS HONG KONG, P1306
   Maier M. J., 2014, I STAT MATH RES REPO
   Narayanan SS, 1997, J ACOUST SOC AM, V101, P1064, DOI 10.1121/1.418030
   Okada H., 1999, HDB INT PHONETIC ASS, P117
   Ong D., 1998, PHONOSCOPE, V1, P1
   Otsuka N., 1991, CHOKAKU GENGO SHOUGA, V20, P69
   RCore T. E. A. M, 2001, R LANG ENV STAT COMP
   Sudo M., 1983, ANN B RILP, V17, P55
   Sudo M., 1982, ANN B RIPLP, V16, P21
   Ueno M., 1998, P 16 INT C AC 135 M, V4, P3001
   Vance Timothy J., 1987, INTRO JAPANESE PHONO
   Wang J, 2013, J SPEECH LANG HEAR R, V56, P1539, DOI 10.1044/1092-4388(2013/12-0030)
   Yamada N., 2015, PROTOPLASMA, P1
NR 25
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2018
VL 39
IS 2
SI SI
BP 130
EP 137
DI 10.1250/ast.39.130
PG 8
WC Acoustics
SC Acoustics
GA GD8WD
UT WOS:000430793800010
OA Bronze
DA 2021-02-24
ER

PT J
AU Blankenship, KG
   Ohde, RN
   Won, JH
   Hedrick, M
AF Blankenship, Kathryn Guillot
   Ohde, Ralph N.
   Won, Jong Ho
   Hedrick, Mark
TI Speech perception in children with cochlear implants for continua
   varying in formant transition duration
SO INTERNATIONAL JOURNAL OF SPEECH-LANGUAGE PATHOLOGY
LA English
DT Article
DE Cochlear implants; children; speech perception
ID VOWEL PERCEPTION; LANGUAGE IMPAIRMENT; CUES; HEARING; ARTICULATION;
   SYLLABLES; LITERACY; ADULTS; AGE
AB Purpose: To examine the developmental course of labial and alveolar manner of articulation contrasts, and to determine how that course may be different for typically developing (TD) children with cochlear implants (CI).
   Method: Eight young adults, eight TD 5-8 year-old children, and seven 5-8 year-old children with CIs participated. Labial /ba/-/wa/ and alveolar /da/-/ja/ continua stimuli were presented, with each continuum consisting of nine synthetic stimuli varying in F2 and F3 transition duration. Participants were asked to label the stimuli as either a stop or glide, and responses were analysed for phonetic boundaries and slopes.
   Result: For the /ba/-/wa/ contrast, children with CIs required longer transition durations compared to TD children or adults to cross from one phoneme category to another. The children with CIs demonstrated less confidence in labelling the stimuli (i.e. less steep slopes) than the TD children or the adults. For the /da/-/ja/ contrast, the children with CIs showed less steep slope values than adults.
   Conclusion: These results suggest that there are differences in the way TD children and children with CIs develop and maintain phonetic categories, perhaps differences in phonetic representation or in linking acoustic and phonetic representations.
C1 [Blankenship, Kathryn Guillot] Middle TN State Univ, Dept Speech Language Pathol & Audiol, Nashville, TN USA.
   [Ohde, Ralph N.] Vanderbilt Univ, Dept Hearing & Speech Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Won, Jong Ho; Hedrick, Mark] Univ Tennessee, Hlth Sci Ctr, Dept Audiol & Speech Pathol, Knoxville, TN USA.
RP Blankenship, KG (corresponding author), Middle TN State Univ, Dept Speech Language Pathol & Audiol, Nashville, TN USA.
EM kathryn.blankenship@mtsu.edu
CR Ashmead D., 2010, REGRESSION CAL UNPUB
   BECK IL, 1995, AM EDUC, V19, P8
   Burlingame E, 2005, J SPEECH LANG HEAR R, V48, P805, DOI 10.1044/1092-4388(2005/056)
   Bus AG, 1999, J EDUC PSYCHOL, V91, P403, DOI 10.1037/0022-0663.91.3.403
   Carrow-Woolfolk Elizabeth, 1995, OWLS ORAL WRITTEN LA
   DUNN L, 1996, PEABODY PICTURE VOCA
   Eisenberg LS, 2000, J ACOUST SOC AM, V107, P2704, DOI 10.1121/1.428656
   Fudala J. B., 2000, ARIZONA ARTICULATION
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   Geers AE, 2002, LANG SPEECH HEAR SER, V33, DOI 10.1044/0161-1461(2002/015)
   Guillot KM, 2013, J SPEECH LANG HEAR R, V56, P1133, DOI 10.1044/1092-4388(2012/12-0082)
   Hicks CB, 2005, J SPEECH LANG HEAR R, V48, P960, DOI 10.1044/1092-4388(2005/066)
   Jerger S, 2007, EAR HEARING, V28, P754, DOI 10.1097/AUD.0b013e318157f049
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Mayo C, 2005, J ACOUST SOC AM, V118, P1730, DOI 10.1121/1.1979451
   Mayo C, 2004, J ACOUST SOC AM, V115, P3184, DOI 10.1121/1.1738838
   Nittrouer S, 2005, J ACOUST SOC AM, V118, P1072, DOI 10.1121/1.1940508
   Nittrouer S, 1996, J SPEECH HEAR RES, V39, P278, DOI 10.1044/jshr.3902.278
   Nittrouer S, 2001, VOLTA REV, V103, P5
   Ohde RN, 2011, J ACOUST SOC AM, V130, P1628, DOI 10.1121/1.3596461
   OHDE RN, 1994, J ACOUST SOC AM, V96, P675, DOI 10.1121/1.411326
   Ohde RN, 1996, J ACOUST SOC AM, V100, P3813, DOI 10.1121/1.417338
   Ohde RN, 1997, J ACOUST SOC AM, V102, P3711, DOI 10.1121/1.420135
   Roid G. H., 1997, LEITER INT PERFORMAN
   SANDER EK, 1972, J SPEECH HEAR DISORD, V37, P55, DOI 10.1044/jshd.3701.55
   Shannon R.V., 2004, SPRINGER HDB AUDITOR, V20
   SMIT AB, 1990, J SPEECH HEAR DISORD, V55, P779, DOI 10.1044/jshd.5504.779
   Spencer LJ, 2003, EAR HEARING, V24, P236, DOI 10.1097/01.AUD.0000069231.72244.94
   STEVENS KN, 1991, J PHONETICS, V19, P161, DOI 10.1016/S0095-4470(19)30310-9
   SUSSMAN JE, 1993, J SPEECH HEAR RES, V36, P1286, DOI 10.1044/jshr.3606.1286
   Sussman JE, 2001, J ACOUST SOC AM, V109, P1173, DOI 10.1121/1.1349428
   Vandali AE, 2000, EAR HEARING, V21, P608, DOI 10.1097/00003446-200012000-00008
   Williams K., 1997, EXPRESSIVE VOCABULAR
NR 33
TC 0
Z9 0
U1 0
U2 2
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1754-9507
EI 1754-9515
J9 INT J SPEECH-LANG PA
JI Int. J. Speech-Lang. Pathol.
PY 2018
VL 20
IS 2
BP 238
EP 246
DI 10.1080/17549507.2016.1265589
PG 9
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GB7BU
UT WOS:000429230700005
PM 28000516
DA 2021-02-24
ER

PT J
AU Chang, J
   Zhang, XY
   Zhang, QP
   Sun, Y
AF Chang, Jiang
   Zhang, Xueying
   Zhang, Qiping
   Sun, Ying
TI Investigating Duration Effects of Emotional Speech Stimuli in a Tonal
   Language by Using Event-Related Potentials
SO IEEE ACCESS
LA English
DT Article
DE Emotional speech; event-related potentials (ERPs); speech duration;
   speech perception; auditory emotion
ID AFFECTIVE PROSODY; PERCEPTION; RESPONSES; IDENTIFICATION; SCHIZOPHRENIA;
   RECOGNITION; SEMANTICS; COMPONENT; CHINESE; WORDS
AB Studying event-related potentials (ERPs) is considered as an effective method for investigating cerebral mechanisms of processing emotional speech. It has been shown that the amplitudes of ERP components in the cognitive processing of emotional speech are modulated by acoustic characteristics, such as valence and arousal. However, whether the duration of emotional speech stimuli impacts emotion-related cognitive processing remains unclear. To better understand the effect of emotional speech stimulus duration on emotion-related cognitive processing, we explored whether emotional speech ERPs were influenced by the duration of stimuli presented. Specifically, this paper focused on the ERP investigation of different durations (short: 0.50-1.00 s; medium: 1.50-2.00 s; and long: 2.50-3.00 s) of Chinese emotional speech stimuli. Chinese is a typical tonal language, and the stimuli were excerpted from radio plays in order to make emotions more obvious and easier to distinguish. We investigated the three different stages of the emotional speech processing: sensory processing, salience detection, and cognition. During the experiment, participants passively listened to emotional utterances matched for semantics and prosody with four emotions (sadness, anger, happiness, and surprise). Our results showed significant differences in the amplitudes of ERP components for different emotions during short-duration emotional speech stimuli. These findings suggest that shorter duration emotional speech stimuli may be more effective for separating the ERP components representing different emotions (N100, P200, and N300).
C1 [Chang, Jiang; Zhang, Xueying; Zhang, Qiping; Sun, Ying] Taiyuan Univ Technol, Coll Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
RP Zhang, XY; Zhang, QP (corresponding author), Taiyuan Univ Technol, Coll Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
EM tyzhangxy@163.com; qiping.zhang@gmail.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61371193]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61371193.
CR Agrawal D, 2013, NEUROIMAGE-CLIN, V2, P229, DOI 10.1016/j.nicl.2013.01.001
   Bostanov V, 2004, PSYCHOPHYSIOLOGY, V41, P259, DOI 10.1111/j.1469-8986.2003.00142.x
   Burkhardt F., 2005, INTERSPEECH 2005 EUR, P1517
   [畅江 Chang Jiang], 2016, [清华大学学报. 自然科学版, Journal of Tsinghua University. Science and Technology], V56, P1131
   Crook Tim., 1999, RADIO DRAMA THEORY P
   Das D. M. P., 2013, GLOBAL MEDIA J INDIA, V4, P1
   Dmitrieva E. S., 2005, FIZIOL CHELOVEKA, V32, P36
   Grasu D, 2015, TONAL VS NONTONAL LA
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Iredale JM, 2013, INT J PSYCHOPHYSIOL, V89, P483, DOI 10.1016/j.ijpsycho.2013.06.025
   Jimenez-Ortega L, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00192
   Keshtiari N, 2015, BEHAV RES METHODS, V47, P295, DOI 10.3758/s13428-014-0504-9
   Klein D, 2001, NEUROIMAGE, V13, P646, DOI 10.1006/nimg.2000.0738
   Kotz SA, 2007, BRAIN RES, V1151, P107, DOI 10.1016/j.brainres.2007.03.015
   Kotz SA, 2011, LANG LINGUIST COMPAS, V5, P108, DOI 10.1111/j.1749-818x.2010.00267.x
   Lakshminarayanan K, 2003, BRAIN LANG, V84, P250, DOI 10.1016/S0093-934X(02)00516-3
   Li A, 2011, P ICPHS, P17
   Luo H, 2007, HEARING RES, V224, P75, DOI 10.1016/j.heares.2006.11.007
   Pakarinen S, 2014, NEUROSCI LETT, V577, P28, DOI 10.1016/j.neulet.2014.06.004
   Pantev C, 1996, HEARING RES, V101, P62, DOI 10.1016/S0378-5955(96)00133-5
   Paulmann S, 2008, BRAIN LANG, V105, P59, DOI 10.1016/j.bandl.2007.11.005
   Paulmann S, 2008, BRAIN LANG, V104, P262, DOI 10.1016/j.bandl.2007.03.002
   Paulmann S, 2008, NEUROREPORT, V19, P209, DOI 10.1097/WNR.0b013e3282f454db
   Paulmann S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00345
   Paulmann S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017694
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Pinheiro AP, 2013, PSYCHOL MED, V43, P603, DOI 10.1017/S003329171200133X
   Pinheiro A. P., 2010, RES DEVICE DISABIL, V32, P47
   Pinheiro AP, 2014, J VOICE, V28, P106, DOI 10.1016/j.jvoice.2013.07.014
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Pourtois G, 2000, NEUROREPORT, V11, P1329, DOI 10.1097/00001756-200004270-00036
   Rohr L, 2015, NEUROIMAGE, V109, P273, DOI 10.1016/j.neuroimage.2015.01.031
   Rosburg T, 2008, PSYCHIAT RES, V161, P259, DOI 10.1016/j.psychres.2008.03.017
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2004, COGNITIVE BRAIN RES, V21, P269, DOI 10.1016/j.cogbrainres.2004.04.003
   Schirmer A, 2003, J COGNITIVE NEUROSCI, V15, P1135, DOI 10.1162/089892903322598102
   Schirmer A, 2013, COGN AFFECT BEHAV NE, V13, P80, DOI 10.3758/s13415-012-0132-8
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Seither-Preisler A, 2006, HEARING RES, V213, P88, DOI 10.1016/j.heares.2006.01.003
   Sokka L, 2014, INT J PSYCHOPHYSIOL, V94, P427, DOI 10.1016/j.ijpsycho.2014.11.001
   Song J., 2016, MODERN ELECT TECHNIQ, V39, P51, DOI DOI 10.16652/J.ISSN.1004-373X.2016.13.013
   Stekelenburg JJ, 2012, FRONT INTEGR NEUROSC, V6, DOI 10.3389/fnint.2012.00026
   Thonnessen H, 2010, NEUROIMAGE, V50, P250, DOI 10.1016/j.neuroimage.2009.11.082
   Wambacq IJA, 2004, COGNITIVE BRAIN RES, V20, P427, DOI 10.1016/j.cogbrainres.2004.03.015
   Wambacq IJA, 2004, NEUROREPORT, V15, P555, DOI 10.1097/00001756-200403010-00034
   Zhang X. Y., 2015, TAIYUAN LI GONG DA X, V46, P629
NR 46
TC 2
Z9 2
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2018
VL 6
BP 13541
EP 13554
DI 10.1109/ACCESS.2018.2813358
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA GB5XD
UT WOS:000429140500001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Hong, T
   Shuai, L
   Frost, SJ
   Landi, N
   Pugh, KR
   Shu, H
AF Hong, Tian
   Shuai, Lan
   Frost, Stephen J.
   Landi, Nicole
   Pugh, Kenneth R.
   Shu, Hua
TI Cortical Responses to Chinese Phonemes in Preschoolers Predict Their
   Literacy Skills at School Age
SO DEVELOPMENTAL NEUROPSYCHOLOGY
LA English
DT Article
ID EVENT-RELATED POTENTIALS; MISMATCH NEGATIVITY MMN; SPEECH-PERCEPTION
   DEFICITS; DEVELOPMENTAL DYSLEXIA; PHONOLOGICAL AWARENESS; FAMILIAL RISK;
   COGNITIVE NEUROSCIENCE; NEUROBIOLOGICAL BASIS; LANGUAGE-DEVELOPMENT;
   ACTIVATION PATTERNS
AB We investigated whether preschoolers with poor phonological awareness (PA) skills had impaired cortical basis for detecting speech feature, and whether speech perception influences future literacy outcomes in preschoolers. We recorded ERP responses to speech in 52 Chinese preschoolers. The results showed that the poor PA group processed speech changes differentially compared to control group in mismatch negativity (MMN) and late discriminative negativity (LDN). Furthermore, speech perception in kindergarten could predict literacy outcomes after literacy acquisition. These suggest that impairment in detecting speech features occurs before formal reading instruction, and that speech perception plays an important role in reading development.
C1 [Hong, Tian; Shu, Hua] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
   [Hong, Tian; Shu, Hua] Beijing Normal Univ, IDG McGovern Inst Brain Res, Beijing, Peoples R China.
   [Shuai, Lan; Frost, Stephen J.; Landi, Nicole; Pugh, Kenneth R.] Yale Univ, Haskins Labs, New Haven, CT USA.
   [Landi, Nicole; Pugh, Kenneth R.] Univ Connecticut, Dept Psychol Sci, Storrs, CT USA.
RP Shu, H (corresponding author), Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
EM shuh@bnu.edu.cn
RI landi, nicole/ABG-5374-2020
FU National Key Basic Research Program of ChinaNational Basic Research
   Program of China [2014CB846103]; Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [31671126,
   31611130107]; Beijing Municipal Science & Technology CommissionBeijing
   Municipal Science & Technology Commission [Z151100003915122];
   Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [2017XTCX04];
   Interdiscipline Research Funds of Beijing Normal University; National
   Institute of Child Health and Human DevelopmentUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [P01 HD001994]; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994] Funding Source: NIH RePORTER; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH &HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994, P01HD001994, P01HD001994,
   P01HD001994, P01HD001994, P01HD001994] Funding Source: NIH RePORTER
FX This research was supported by National Key Basic Research Program of
   China (2014CB846103), by Natural Science Foundation of China (31671126,
   31611130107), by Beijing Municipal Science & Technology Commission
   (Z151100003915122), by the Fundamental Research Funds for the Central
   Universities (2017XTCX04), by the Interdiscipline Research Funds of
   Beijing Normal University, and by the National Institute of Child Health
   and Human Development (grant number P01 HD001994) to Haskins
   Laboratories.
CR Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Blomert L, 2004, J SPEECH LANG HEAR R, V47, P1030, DOI 10.1044/1092-4388(2004/077)
   Boets B, 2007, BRAIN LANG, V101, P19, DOI 10.1016/j.bandl.2006.06.009
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Boets B, 2010, BRIT J DEV PSYCHOL, V28, P5, DOI 10.1348/026151010X485223
   BRYANT PE, 1990, DEV PSYCHOL, V26, P429, DOI 10.1037/0012-1649.26.3.429
   Cao F, 2006, J CHILD PSYCHOL PSYC, V47, P1041, DOI 10.1111/j.1469-7610.2006.01684.x
   Castles A, 2014, MIND LANG, V29, P270, DOI 10.1111/mila.12050
   Ceponiene R, 2004, PSYCHOPHYSIOLOGY, V41, P130, DOI 10.1111/j.1469-8986.2003.00138.x
   Chan CKK, 2001, J EXP CHILD PSYCHOL, V80, P23, DOI 10.1006/jecp.2000.2622
   Cheour M, 2000, CLIN NEUROPHYSIOL, V111, P4, DOI 10.1016/S1388-2457(99)00191-1
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Cheung H, 2009, J CHILD PSYCHOL PSYC, V50, P726, DOI 10.1111/j.1469-7610.2008.02001.x
   Corbera S, 2006, NEUROREPORT, V17, P1051, DOI 10.1097/01.wnr.0000221846.43126.a6
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Demonet JF, 2004, LANCET, V363, P1451, DOI 10.1016/S0140-6736(04)16106-0
   Elbro C, 1996, READ WRIT, V8, P453, DOI 10.1007/BF00577023
   Espy KA, 2004, ANN DYSLEXIA, V54, P9, DOI 10.1007/s11881-004-0002-3
   FOWLER AE, 1991, PHONOLOGICAL PROCESSES IN LITERACY, P97
   Frost SJ, 2009, ANN DYSLEXIA, V59, P78, DOI 10.1007/s11881-009-0024-y
   Gerrits E, 2009, J COMMUN DISORD, V42, P180, DOI 10.1016/j.jcomdis.2008.10.004
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2015, NAT REV NEUROSCI, V16, DOI 10.1038/nrn3836-c2
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3
   Guttorm TK, 2010, J LEARN DISABIL-US, V43, P391, DOI 10.1177/0022219409345005
   Hamalainen JA, 2008, CLIN NEUROPHYSIOL, V119, P100, DOI 10.1016/j.clinph.2007.09.064
   Hamalainen J, 2018, INT J BEHAV DEV, V42, P357, DOI 10.1177/0165025417728582
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hulme C, 2012, PSYCHOL SCI, V23, P572, DOI 10.1177/0956797611435921
   Huttunen T, 2007, DEV NEUROPSYCHOL, V31, P453, DOI 10.1080/87565640701229656
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426
   Kraus N, 1996, SCIENCE, V273, P971, DOI 10.1126/science.273.5277.971
   Kushnerenko E, 2001, DEV NEUROPSYCHOL, V19, P83, DOI 10.1207/S15326942DN1901_6
   Lachmann T, 2005, INT J PSYCHOPHYSIOL, V56, P105, DOI 10.1016/j.ijpsycho.2004.11.005
   Law JM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00124
   Lei L, 2011, J CHILD PSYCHOL PSYC, V52, P212, DOI 10.1111/j.1469-7610.2010.02311.x
   Leppanen PHT, 1999, NEUROREPORT, V10, P969, DOI 10.1097/00001756-199904060-00014
   Li H, 2012, J RES READ, V35, P287, DOI 10.1111/j.1467-9817.2010.01460.x
   Li WS, 2011, J CHILD LANG, V38, P793, DOI 10.1017/S0305000910000346
   Lovio R, 2010, BRAIN RES, V1335, P53, DOI 10.1016/j.brainres.2010.03.097
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Makeig S., 1995, INT C SIGNAL PROCESS, V2, P1548
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   Maurer U, 2009, BIOL PSYCHIAT, V66, P341, DOI 10.1016/j.biopsych.2009.02.031
   MCBRIDECHANG C, 1995, EDUC PSYCHOL, V30, P109, DOI 10.1207/s15326985ep3003_2
   McCandliss BD, 2003, MENT RETARD DEV D R, V9, P196, DOI 10.1002/mrdd.10080
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   Muter V, 1998, J EXP CHILD PSYCHOL, V71, P1
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1995, EAR HEARING, V16, P6
   Neuhoff N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034909
   Pan JE, 2016, DEVELOPMENTAL SCI, V19, P982, DOI 10.1111/desc.12356
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Pennington KA, 2012, DIS MODEL MECH, V5, P9, DOI 10.1242/dmm.008516
   Pihko E, 1999, NEUROREPORT, V10, P901, DOI 10.1097/00001756-199904060-00002
   Plakas A, 2013, CORTEX, V49, P1034, DOI 10.1016/j.cortex.2012.02.013
   Preston JL, 2016, PSYCHOL SCI, V27, P75, DOI 10.1177/0956797615611921
   Pugh KR, 2013, BRAIN LANG, V125, P173, DOI 10.1016/j.bandl.2012.04.004
   Pugh KR, 2001, J COMMUN DISORD, V34, P479, DOI 10.1016/S0021-9924(01)00060-0
   Pulvermuller F, 2003, NEUROIMAGE, V20, P159, DOI 10.1016/S1053-8119(03)00261-1
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Raschle NM, 2012, P NATL ACAD SCI USA, V109, P2156, DOI 10.1073/pnas.1107721109
   Raven JC., 1996, STANDARD PROGR MATRI
   Richardson U, 2003, DEV NEUROPSYCHOL, V23, P385, DOI 10.1207/S15326942DN2303_5
   Sandak R, 2004, SCI STUD READ, V8, P273, DOI 10.1207/s1532799xssr0803_6
   Schirmer A, 2005, J COGNITIVE NEUROSCI, V17, P1, DOI 10.1162/0898929052880057
   Schlaggar BL, 2007, ANNU REV NEUROSCI, V30, P475, DOI 10.1146/annurev.neuro.28.061604.135645
   Schulte-Korne G, 2010, CLIN NEUROPHYSIOL, V121, P1794, DOI 10.1016/j.clinph.2010.04.028
   Schulte-Korne G, 2001, INT J PSYCHOPHYSIOL, V40, P77, DOI 10.1016/S0167-8760(00)00152-5
   Serniclaes W, 2001, J SPEECH LANG HEAR R, V44, P384, DOI 10.1044/1092-4388(2001/032)
   Shankweiler D., 1992, ORTHOGRAPHY PHONOLOG, P179
   Sharma M, 2006, CLIN NEUROPHYSIOL, V117, P1130, DOI 10.1016/j.clinph.2006.02.001
   Shu H, 2003, CHILD DEV, V74, P27, DOI 10.1111/1467-8624.00519
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Siok WT, 2001, DEV PSYCHOL, V37, P886, DOI 10.1037//0012-1649.37.6.886
   SNOWLING M, 1994, PHILOS T ROY SOC B, V346, P21, DOI 10.1098/rstb.1994.0124
   Snowling M J, 2001, Dyslexia, V7, P37
   Sperling AJ, 2003, NEUROPSYCHOLOGIA, V41, P1422, DOI 10.1016/S0028-3932(03)00044-7
   Steinbrink C, 2014, CHILD DEV, V85, P1711, DOI 10.1111/cdev.12208
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x
   Tallal P, 2006, TRENDS NEUROSCI, V29, P382, DOI 10.1016/j.tins.2006.06.003
   Thomson JM, 2006, J RES READ, V29, P334, DOI 10.1111/j.1467-9817.2006.00312.x
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 92
TC 6
Z9 6
U1 3
U2 11
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 8756-5641
EI 1532-6942
J9 DEV NEUROPSYCHOL
JI Dev. Neuropsychol.
PY 2018
VL 43
IS 4
BP 356
EP 369
DI 10.1080/87565641.2018.1439946
PG 14
WC Psychology, Developmental; Psychology; Psychology, Experimental
SC Psychology
GA GA8FU
UT WOS:000428574800005
PM 29521532
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Schmitz, J
   Diaz, B
   Rubio, KF
   Sebastian-Galles, N
AF Schmitz, Judith
   Diaz, Begona
   Fernandez Rubio, Karla
   Sebastian-Galles, Nuria
TI Exploring the relationship between speech perception and production
   across phonological processes, language familiarity, and sensory
   modalities
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Speech perception; speech production; phonological processes; language
   familiarity; audio-visual integration
ID DEVELOPMENTAL DYSLEXIA; LEXICAL ACCESS; LINGUISTIC EXPERIENCE; MISMATCH
   NEGATIVITY; EARLY BILINGUALS; MOTOR CORTEX; HEARING LIPS; MODEL;
   ENGLISH; SOUNDS
AB Current speech perception models disagree over the role of speech production in speech perception. In the current study we aimed to characterise the relationship between speech perception and production by testing a large sample of early and highly proficient Spanish-Catalan bilinguals in a variety of speech perception and production tasks. Speech perception was measured for different phonological processes (sub-lexical and phono-lexical), different language familiarities (native, second, and unknown language), and different sensory modalities (auditory and audio-visual). Speech production ability was assessed in the second language. Non-linguistic auditory and sensory motor abilities were also measured. We used factor analysis to look at the relations between the variables. Results showed a tight relationship between speech perception and production measurements, which was present across phonological processes and language familiarities but was independent of audio-visual and non-linguistic (auditory and sensory-motor) skills.
C1 [Schmitz, Judith; Diaz, Begona; Fernandez Rubio, Karla; Sebastian-Galles, Nuria] Pompeu Fabra Univ, Ctr Brain & Cognit, Barcelona, Spain.
RP Schmitz, J; Diaz, B (corresponding author), Pompeu Fabra Univ, Ctr Brain & Cognit, Barcelona, Spain.
EM judith-schmitz@gmx.net; begona.diaz@upf.edu
RI Sebastian-Galles, Nuria/A-4215-2008; Rubio, Karla
   Fernandez/AAC-3340-2020; Diaz, Begona/H-5854-2012
OI Sebastian-Galles, Nuria/0000-0001-6938-2498; Rubio, Karla
   Fernandez/0000-0003-2104-2392; Diaz, Begona/0000-0003-1628-4901
FU European CommissionEuropean CommissionEuropean Commission Joint Research
   Centre [FP7/2007-2013]; ERCEuropean Research Council (ERC)European
   Commission [323961]; Spanish Ministerio de Economia y Competitividad
   [PSI201566918-P]; Catalan Government [SGR 2014-1210]; Generalitat de
   CatalunyaGeneralitat de Catalunya; European Union under REA grant
   [FP7/2007-2013, 32867]; Spanish Government [Juan de la Cierva
   fellowship] [JCI-2012-12678]
FX This research was funded by grants from the European Commission Seventh
   Framework Programme [grant number FP7/2007-2013]: ERC grant [agreement
   number 323961 (UNDER CONTROL)]; the Spanish Ministerio de Economia y
   Competitividad [grant number PSI201566918-P] and the Catalan Government
   [grant number SGR 2014-1210] awarded to NSG. NSG also received the
   "ICREA Academia" prize for excellence in research, funded by the
   Generalitat de Catalunya. BD received funding from the People Programme
   (Marie Curie Actions) of the European Union's Seventh Framework
   Programme [grant number FP7/2007-2013] under REA grant agreement n 32867
   and a postdoctoral fellowship from the Spanish Government [Juan de la
   Cierva fellowship JCI-2012-12678].
CR Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Besle J, 2009, HEARING RES, V258, P143, DOI 10.1016/j.heares.2009.06.016
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bosch L, 2000, EUR J COGN PSYCHOL, V12, P189, DOI 10.1080/09541446.2000.10590222
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   CARAMAZZA A, 1987, COGNITION, V26, P59, DOI 10.1016/0010-0277(87)90014-X
   Courtney M. G., 2013, PRACTICAL ASSESSMENT, V18, P1, DOI DOI 10.3758/S13428-014-0511-X
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Diaz B, 2016, BILING-LANG COGN, V19, P955, DOI 10.1017/S1366728915000450
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   Dupoux E, 2010, COGNITION, V114, P266, DOI 10.1016/j.cognition.2009.10.001
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   FROMKIN VA, 1971, LANGUAGE, V47, P27, DOI 10.2307/412187
   Gabay Y, 2012, NEUROPSYCHOLOGIA, V50, P2435, DOI 10.1016/j.neuropsychologia.2012.06.014
   Gazzaniga M., 2002, COGNITIVE NEUROSCIEN
   Hedenius M, 2013, RES DEV DISABIL, V34, P3924, DOI 10.1016/j.ridd.2013.08.014
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hillis AE, 1999, CORTEX, V35, P337, DOI 10.1016/S0010-9452(08)70804-9
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Kartushina N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01246
   Kelly Steve W, 2002, Dyslexia, V8, P43, DOI 10.1002/dys.208
   Kittredge AK, 2016, J MEM LANG, V89, P8, DOI 10.1016/j.jml.2015.08.001
   KLATT DH, 1979, J PHONETICS, V7, P279, DOI 10.1016/S0095-4470(19)31059-9
   Levelt WJ, 1989, SPEAKING INTENTION A
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Levy ES, 2010, J ACOUST SOC AM, V128, P1290, DOI 10.1121/1.3466879
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lotto AJ, 2009, TRENDS COGN SCI, V13, P110, DOI 10.1016/j.tics.2008.11.008
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Peperkamp S., 2011, P INTERSPEECH, V12, P161
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Fabra LR, 2012, J PHONETICS, V40, P491, DOI 10.1016/j.wocn.2012.01.001
   Ramus F, 2003, J CHILD PSYCHOL PSYC, V44, P712, DOI 10.1111/1469-7610.00157
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Sanchez-Garcia C, 2013, EXP BRAIN RES, V225, P499, DOI 10.1007/s00221-012-3390-3
   Sanchez-Garcia C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025198
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Sebastian-Galles N, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P279
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vicari S, 2005, J NEUROL NEUROSUR PS, V76, P1392, DOI 10.1136/jnnp.2004.061093
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Winkler I, 2012, INT J PSYCHOPHYSIOL, V83, P132, DOI 10.1016/j.ijpsycho.2011.10.001
NR 81
TC 3
Z9 3
U1 0
U2 16
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 5
BP 527
EP 546
DI 10.1080/23273798.2017.1390142
PG 20
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA GA4DH
UT WOS:000428279300001
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Michelas, A
   Esteve-Gibert, N
   Dufour, S
AF Michelas, Amandine
   Esteve-Gibert, Nuria
   Dufour, Sophie
TI On French listeners' ability to use stress during spoken word processing
SO JOURNAL OF COGNITIVE PSYCHOLOGY
LA English
DT Article
DE Speech perception; word discrimination; French prosody; primary stress
ID LEXICAL ACCESS; BOUNDARIES; DEAFNESS; PROSODY
AB Previous studies have suggested that French listeners experience difficulties when they have to discriminate between words that differ in stress. A limitation is that these studies used stress patterns that do not respect the rules of stress placement in French. In this study, three stress patterns were tested on bisyllabic words (1) the legal stress pattern in French, namely words that were unstressed compared to words that bore primary stress on their last syllable (/u?i/-/u'?i/), (2) an illegal stress location pattern, namely words that bore primary stress on their first syllable compared to words that bore primary stress on their last syllable (/'u?i/-/u'?i/) and (3) an illegal pattern that involves an unstressed word, namely words that were unstressed compared to words that bore primary stress on their first syllable (/u?i/-/'u?i/). In an ABX task, participants heard three items produced by three different speakers and had to indicate whether X was identical to A or B.The stimuli A and B varied in stress (/u'?i/-/u?i/-/u'?i/), in one phoneme (/u'?i/-/u'??/-/u'?i/) or in both stress and one phoneme (/u'?i/-/u??/-/u'?i/). The results showed that French listeners are fully able to discriminate between two words differing in stress provided that the stress pattern included an unstressed word. More importantly, they suggest that the French listeners' difficulties mainly reside in locating stress within words.
C1 [Michelas, Amandine; Esteve-Gibert, Nuria; Dufour, Sophie] Aix Marseille Univ, CNRS, LPL, UMR 7309, F-13100 Aix En Provence, France.
RP Dufour, S (corresponding author), Aix Marseille Univ, CNRS, LPL, UMR 7309, F-13100 Aix En Provence, France.
EM sophie.dufour@lpl-aix.fr
OI Michelas, Amandine/0000-0003-0213-6131
FU Labex Brain and Language Research Institute [ANR-11-LABX-0036]; French
   National Agency of Research (ANR), under the project title "Investments
   of the Future" A*MIDEXFrench National Research Agency (ANR)
   [ANR-11-IDEX-0001-02]
FX This work was supported by the Labex Brain and Language Research
   Institute [grant number ANR-11-LABX-0036] and has benefited from support
   from the French National Agency of Research (ANR), under the project
   title "Investments of the Future" A*MIDEX [grant number
   ANR-11-IDEX-0001-02].
CR BANEL MH, 1994, SPEECH COMMUN, V15, P115, DOI 10.1016/0167-6393(94)90046-9
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bretz F., 2011, MULTIPLE COMP USING
   Christophe A, 2004, J MEM LANG, V51, P523, DOI 10.1016/j.jml.2004.07.001
   Cutler A, 1999, J ACOUST SOC AM, V105, P1877, DOI 10.1121/1.426724
   Cutler A, 2001, LANG SPEECH, V44, P171, DOI 10.1177/00238309010440020301
   Dupoux E, 1997, J MEM LANG, V36, P406, DOI 10.1006/jmla.1996.2500
   Dupoux E, 2001, J ACOUST SOC AM, V110, P1606, DOI 10.1121/1.1380437
   Dupoux E, 2008, COGNITION, V106, P682, DOI 10.1016/j.cognition.2007.04.001
   Dupoux E, 2010, COGNITION, V114, P266, DOI 10.1016/j.cognition.2009.10.001
   Jun SA, 2000, TEXT SPEECH LANG TEC, V15, P209
   Lee C., 2000, THESIS
   MCQUEEN JM, 1994, J EXP PSYCHOL LEARN, V20, P621, DOI 10.1037/0278-7393.20.3.621
   Michelas A, 2012, J PHONETICS, V40, P816, DOI 10.1016/j.wocn.2012.08.004
   Peperkamp S, 2010, J PHONETICS, V38, P422, DOI 10.1016/j.wocn.2010.04.001
   RIETVELD ACM, 1980, LANG SPEECH, V23, P289, DOI 10.1177/002383098002300306
   Soto-Faraco S, 2001, J MEM LANG, V45, P412, DOI 10.1006/jmla.2000.2783
   Spinelli E, 2007, LANG COGNITIVE PROC, V22, P828, DOI 10.1080/01690960601076472
   Spinelli E, 2010, ATTEN PERCEPT PSYCHO, V72, P775, DOI 10.3758/APP.72.3.775
   Sulpizio S, 2012, J MEM LANG, V66, P177, DOI 10.1016/j.jml.2011.08.001
   Welby P, 2006, J PHONETICS, V34, P343, DOI 10.1016/j.wocn.2005.09.001
NR 21
TC 2
Z9 2
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2044-5911
EI 2044-592X
J9 J COGN PSYCHOL
JI J. Cogn. Psychol.
PY 2018
VL 30
IS 2
BP 198
EP 206
DI 10.1080/20445911.2017.1394862
PG 9
WC Psychology, Experimental
SC Psychology
GA FZ6OE
UT WOS:000427718100005
DA 2021-02-24
ER

PT J
AU Moore-Cantwell, C
   Sanders, L
AF Moore-Cantwell, Claire
   Sanders, Lisa
TI Effects of probabilistic phonology on the perception of words and
   nonwords
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Speech perception; stress; phonology; ERP; phonotactics
ID EVENT-RELATED POTENTIALS; EYE-MOVEMENTS; ENGLISH; CONSTRAINTS;
   FREQUENCY; STRESS; PHONOTACTICS; CLUSTERS; GRAMMAR; MODEL
AB Although listeners have knowledge about both categorical and probabilistic phonological patterns, it is not clear if knowledge of probabilistic patterns affects speech processing. One such pattern in English is that words ending in /i/ (e.g. remedy) are more likely to have antepenultimate stress than penultimate stress (e.g. spaghetti). In the current study, participants extended this trend to ratings of novel words (e.g. bakati). Further, ERPs revealed that real words that violate this trend elicit an early negativity 280-380 ms after onset compared to words that observe this trend. These results indicate that probabilistic phonology interacts with lexical access. More specifically, they suggest that extra processing power is needed to recognise the stress pattern of trend-violating words because of competition between the expectations of the phonological grammar and lexical encoding of trend-violating patterns.
C1 [Moore-Cantwell, Claire] Univ Massachusetts, Dept Linguist, Amherst, MA 01003 USA.
   [Sanders, Lisa] Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA 01003 USA.
RP Moore-Cantwell, C (corresponding author), Simon Fraser Univ, Dept Linguist, Burnaby, BC V5A 1S6, Canada.
EM clairemoorecantwell@gmail.com
FU UMass Graduate School Dissertation Research Grant; UMass ICESL seed
   grant; National Science Foundation Graduate Research FellowshipNational
   Science Foundation (NSF) [NSF DGE-0907995]
FX This research was supported in part by a UMass Graduate School
   Dissertation Research Grant, in part by a UMass ICESL seed grant, and in
   part by a National Science Foundation Graduate Research Fellowship to
   the first author (grant number NSF DGE-0907995).
CR Bailey TM, 2001, J MEM LANG, V44, P568, DOI 10.1006/jmla.2000.2756
   Becker Michael, 2009, THESIS
   BECKMAN ME, 1986, STRESS NONSTRESS ACC, V7
   Berent I, 2009, PHONOLOGY, V26, P75, DOI 10.1017/S0952675709001729
   Bocker KBE, 1999, PSYCHOPHYSIOLOGY, V36, P706, DOI 10.1111/1469-8986.3660706
   Breen M, 2013, ATTEN PERCEPT PSYCHO, V75, P101, DOI 10.3758/s13414-012-0376-y
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Burzio Luigi, 1994, PRINCIPLES ENGLISH S, V72
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Coetzee A. W., 2009, HDB PHONOLOGICAL THE, P401
   Cutler A., 1987, Computer Speech and Language, V2, P133, DOI 10.1016/0885-2308(87)90004-0
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P635, DOI 10.1162/089892900562390
   Domahs U, 2014, J COMP GER LINGUIST, V17, P59, DOI 10.1007/s10828-014-9063-9
   Domahs U, 2009, LANG SPEECH, V52, P415, DOI 10.1177/0023830909336581
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Ernestus M, 2003, LANGUAGE, V79, P5, DOI 10.1353/lan.2003.0076
   Gouvea AC, 2010, LANG COGNITIVE PROC, V25, P149, DOI 10.1080/01690960902965951
   Hayes B, 1980, THESIS
   Hayes B, 2008, LINGUIST INQ, V39, P379, DOI 10.1162/ling.2008.39.3.379
   Hayes B, 2009, LANGUAGE, V85, P822
   Jarmulowicz LD, 2002, BRAIN LANG, V81, P192, DOI 10.1006/brln.2001.2517
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   Kretzschtnar F, 2015, J EXP PSYCHOL LEARN, V41, P1648, DOI 10.1037/xlm0000128
   MASSARO DW, 1983, PERCEPT PSYCHOPHYS, V34, P338, DOI 10.3758/BF03203046
   Moore-Cantwell C, 2016, THESIS
   Moore-Cantwell C, 2016, CATALAN J LINGUIST, V15, P53
   Moreton E, 2002, COGNITION, V84, P55, DOI 10.1016/S0010-0277(02)00014-8
   OSTERHOUT L, 1992, J MEM LANG, V31, P785, DOI 10.1016/0749-596X(92)90039-Z
   Patel AD, 1998, J COGNITIVE NEUROSCI, V10, P717, DOI 10.1162/089892998563121
   Pater J, 2005, PROC ANN BUCLD, P482
   Pater Joe, 2000, PHONOLOGY, V17, P237, DOI DOI 10.1017/S0952675700003900
   Pitkanen I., 2010, THESIS
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Reichle ED, 1998, PSYCHOL REV, V105, P125, DOI 10.1037/0033-295X.105.1.125
   Rossi S, 2013, BRAIN LANG, V127, P404, DOI 10.1016/j.bandl.2013.02.009
   Rossi S, 2011, J COGNITIVE NEUROSCI, V23, P1752, DOI 10.1162/jocn.2010.21547
   RUGG MD, 1987, MEM COGNITION, V15, P473, DOI 10.3758/BF03198381
   RUGG MD, 1984, NEUROPSYCHOLOGIA, V22, P435, DOI 10.1016/0028-3932(84)90038-1
   Selkirk E., 1984, SYNTAX PHONOLOGY REL
   TYLER A, 1989, J MEM LANG, V28, P649, DOI 10.1016/0749-596X(89)90002-8
   Vaden K., IRVINE PHONOTACTIC O
   Weide R. L., 1994, CMU PRONOUNCING DICT
   Zuraw Kie, 2000, THESIS
NR 43
TC 0
Z9 0
U1 0
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 2
BP 148
EP 164
DI 10.1080/23273798.2017.1376101
PG 17
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA FZ6UW
UT WOS:000427736300002
DA 2021-02-24
ER

PT J
AU Zhang, CC
AF Zhang, Caicai
TI Online adjustment of phonetic expectation of lexical tones to
   accommodate speaker variation: a combined behavioural and ERP study
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Speaker variation; signal-to-representation mapping; Cantonese; lexical
   tones; phonological mapping negativity
ID SPOKEN WORD IDENTIFICATION; CANTONESE LEVEL TONES; TOP-DOWN INFLUENCES;
   VOICE-ONSET TIME; SPEECH-PERCEPTION; FUNDAMENTAL-FREQUENCY; PHONOLOGICAL
   SIMILARITY; TALKER NORMALIZATION; RECOGNITION MEMORY; MANDARIN CHINESE
AB An unresolved question in speech perception is how speech signals with speaker variation are mapped onto their perceptual representations. In this study, this issue was examined using a written-word/spoken-word matching paradigm, where listeners could adjust phonetic expectations of spoken words carrying lexical tones according to speaker-specific F0 cues contained in a preceding speech context, to analyse the tone of the incoming spoken word. Behavioural results showed that Cantonese listeners perceived spoken words differently, in a way compatible with the adjustment of F0 expectations of lexical tones to accommodate between- and within-speaker variation in F0. Electrophysiologically, effects of F0 expectation adjustment were found in the phonological mapping negativity (PMN) time-window (250-310 ms after spoken word onset). These results suggest that phonetic representations of lexical tones are adjustable in a speaker- and context-specific manner, with the adjustment occurring no later than pre-lexical phonemic processing. These findings are consistent with exemplar theory.
C1 [Zhang, Caicai] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Hong Kong, Peoples R China.
   [Zhang, Caicai] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
RP Zhang, CC (corresponding author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Hong Kong, Peoples R China.; Zhang, CC (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM caicai.zhang@polyu.edu.hk
RI Zhang, Caicai/Q-6914-2018
OI Zhang, Caicai/0000-0002-7687-0518
FU Research Grants Council, University Grants Committee [GRF: 14408914,
   ECS: 25603916]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [NSFC: 11504400]
FX This work was partly supported by grants from the Research Grants
   Council, University Grants Committee (GRF: 14408914; ECS: 25603916), and
   National Natural Science Foundation of China (NSFC: 11504400).
CR Bauer R., 1997, MODERN CANTONESE PHO
   Bishop J, 2012, J ACOUST SOC AM, V132, P1100, DOI 10.1121/1.4714351
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chao Y. R., 1947, CANTONESE PRIMER
   Chen F, 2016, J SIGNAL PROCESS SYS, V82, P253, DOI 10.1007/s11265-015-1008-2
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   CRAIK FIM, 1974, Q J EXP PSYCHOL, V26, P274, DOI 10.1080/14640747408400413
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Desroches AS, 2009, J COGNITIVE NEUROSCI, V21, P1893, DOI 10.1162/jocn.2008.21142
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Francis AL, 2006, J ACOUST SOC AM, V119, P1712, DOI 10.1121/1.2149768
   GARRETT KL, 1987, J ACOUST SOC AM, V82, P58, DOI 10.1121/1.395437
   GAY T, 1978, J ACOUST SOC AM, V63, P223, DOI 10.1121/1.381717
   GERSTMAN LJ, 1968, IEEE T ACOUST SPEECH, VAU16, P78, DOI 10.1109/TAU.1968.1161953
   GOLDINGER SD, 1991, J EXP PSYCHOL LEARN, V17, P152, DOI 10.1037/0278-7393.17.1.152
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Goldinger SD, 1999, MEM COGNITION, V27, P328, DOI 10.3758/BF03211416
   Hannemann R, 2007, BRAIN RES, V1153, P134, DOI 10.1016/j.brainres.2007.03.069
   HINTZMAN DL, 1972, J VERB LEARN VERB BE, V11, P741, DOI 10.1016/S0022-5371(72)80008-2
   Honorof DN, 2005, J ACOUST SOC AM, V117, P2193, DOI 10.1121/1.1841751
   Huang JY, 2009, J ACOUST SOC AM, V125, P3983, DOI 10.1121/1.3125342
   JOHNSON K, 1993, LANGUAGE, V69, P505, DOI 10.2307/416697
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Johnson K., 2007, EXPT APPROACHES PHON, P25
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Joos M, 1948, ACOUSTIC PHONETICS
   Kessinger RH, 1998, J PHONETICS, V26, P117, DOI 10.1006/jpho.1997.0069
   Koenig LL, 2000, J SPEECH LANG HEAR R, V43, P1211, DOI 10.1044/jslhr.4305.1211
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kraljic T, 2011, COGNITION, V121, P459, DOI 10.1016/j.cognition.2011.08.015
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   LEATHER J, 1983, J PHONETICS, V11, P373, DOI 10.1016/S0095-4470(19)30836-8
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Luo X, 2014, J ACOUST SOC AM, V136, pEL109, DOI 10.1121/1.4885483
   MacMillan N. A., 2005, DETECTION THEORY USE
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Malins JG, 2012, NEUROPSYCHOLOGIA, V50, P2032, DOI 10.1016/j.neuropsychologia.2012.05.002
   Maniwa K, 2009, J ACOUST SOC AM, V125, P3962, DOI 10.1121/1.2990715
   Mok PPK, 2013, LANG VAR CHANGE, V25, P341, DOI 10.1017/S0954394513000161
   Moore CB, 1997, J ACOUST SOC AM, V102, P1864, DOI 10.1121/1.420092
   Morris RJ, 2008, J PHONETICS, V36, P308, DOI 10.1016/j.wocn.2007.06.003
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Newman RL, 2009, BIOL PSYCHOL, V80, P114, DOI 10.1016/j.biopsycho.2008.04.008
   Newman RL, 2003, PSYCHOPHYSIOLOGY, V40, P640, DOI 10.1111/1469-8986.00065
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Obleser J, 2011, NEUROIMAGE, V55, P713, DOI 10.1016/j.neuroimage.2010.12.020
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Peng G, 2006, J CHINESE LINGUIST, V34, P134
   Peng G, 2012, J SPEECH LANG HEAR R, V55, P579, DOI 10.1044/1092-4388(2011/11-0025)
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Protopapas A, 1997, J ACOUST SOC AM, V101, P2267, DOI 10.1121/1.418247
   Rose P, 1996, VOCAL FOLD, P307
   Smith DRR, 2005, J ACOUST SOC AM, V118, P3177, DOI 10.1121/1.2047107
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Wang W. S. Y, 1972, LINGUISTICS PHONETIC, P487
   WOLDORFF MG, 1993, PSYCHOPHYSIOLOGY, V30, P98, DOI 10.1111/j.1469-8986.1993.tb03209.x
   Wong PCM, 2003, J SPEECH LANG HEAR R, V46, P413, DOI 10.1044/1092-4388(2003/034)
   Yip M., 2002, TONE
   Zekveld AA, 2006, NEUROIMAGE, V32, P1826, DOI 10.1016/j.neuroimage.2006.04.199
   Zhang CC, 2016, J EXP PSYCHOL HUMAN, V42, P1252, DOI 10.1037/xhp0000216
   Zhang CC, 2013, BRAIN LANG, V126, P193, DOI 10.1016/j.bandl.2013.05.010
   Zhang CC, 2012, J ACOUST SOC AM, V132, P1088, DOI 10.1121/1.4731470
   Zhao JJ, 2011, NEUROPSYCHOLOGIA, V49, P1761, DOI 10.1016/j.neuropsychologia.2011.02.054
NR 78
TC 5
Z9 5
U1 0
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 2
BP 175
EP 195
DI 10.1080/23273798.2017.1376752
PG 21
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA FZ6UW
UT WOS:000427736300004
OA Green Accepted
DA 2021-02-24
ER

PT S
AU Monahan, PJ
AF Monahan, Philip J.
BE Liberman, M
   Partee, BH
TI Phonological Knowledge and Speech Comprehension
SO ANNUAL REVIEW OF LINGUISTICS, VOL 4
SE Annual Review of Linguistics
LA English
DT Article; Book Chapter
DE psycholinguistics; speech perception; cognitive neuroscience;
   distinctive features; prediction; speech comprehension
ID MISMATCH NEGATIVITY MMN; NEUROBIOLOGICAL EVIDENCE; NEURONAL
   OSCILLATIONS; ACOUSTIC LANDMARKS; BRAIN POTENTIALS; PROACTIVE BRAIN;
   AUDITORY-CORTEX; SENSORY MEMORY; LEXICAL ACCESS; VISUAL SPEECH
AB Comprehending speech in our native language is an impressionistically effortless and routine task. We often give little consideration to its complexity. Only in particularly challenging situations (e.g., in noisy environments, when hearing significantly accented speech) do some of these intricacies become apparent. Higher-order knowledge constrains sensory perception and has been demonstrated to play a crucial role in other domains of human language processing. Moreover, incorporating measures of brain activity during online speech comprehension has just begun to highlight the extent to which top-down information flow and predictive processes are integral to sensory perception. This review argues that our phonological system, at a relatively abstract level, is one such source of higher-order knowledge. In particular, I discuss the extent to which phonological distinctive features play a role in perception and predictive processing during speech comprehension with reference to behavioral and neurophysiological data. This line of research represents a tractable linking of linguistic theory with models of perception and speech comprehension in the brain.
C1 [Monahan, Philip J.] Univ Toronto Scarborough, Ctr French & Linguist, Toronto, ON M1C 1A4, Canada.
   [Monahan, Philip J.] Univ Toronto, Dept Linguist, Toronto, ON M5S 3G3, Canada.
RP Monahan, PJ (corresponding author), Univ Toronto Scarborough, Ctr French & Linguist, Toronto, ON M1C 1A4, Canada.; Monahan, PJ (corresponding author), Univ Toronto, Dept Linguist, Toronto, ON M5S 3G3, Canada.
EM philip.monahan@utoronto.ca
OI Monahan, Philip/0000-0001-8637-1889
CR Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Astikainen P, 2008, EUR J NEUROSCI, V28, P2319, DOI 10.1111/j.1460-9568.2008.06510.x
   Atienza M, 2002, INT J PSYCHOPHYSIOL, V46, P215, DOI 10.1016/S0167-8760(02)00113-7
   Avery P., 1989, PHONOLOGY, V6, P179, DOI DOI 10.1017/S0952675700001007
   Bar M, 2006, P NATL ACAD SCI USA, V103, P449, DOI 10.1073/pnas.0507062103
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005
   Bar M, 2009, PHILOS T R SOC B, V364, P1235, DOI 10.1098/rstb.2008.0310
   Bar M, 2009, PHILOS T R SOC B, V364, P1181, DOI 10.1098/rstb.2008.0321
   Bastos AM, 2015, NEURON, V85, P390, DOI 10.1016/j.neuron.2014.12.018
   Beckman ME, 2004, PHONETIC INTERPRETAT, P13
   Berent I., 2013, PHONOLOGICAL MIND
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   BLUMSTEIN SE, 1980, J ACOUST SOC AM, V67, P648, DOI 10.1121/1.383890
   BLUMSTEIN SE, 1979, J ACOUST SOC AM, V66, P1001, DOI 10.1121/1.383319
   Bonte ML, 2005, CLIN NEUROPHYSIOL, V116, P2765, DOI 10.1016/j.clinph.2005.08.012
   Brentari D., 2011, HDB PHONOLOGICAL THE, P691, DOI DOI 10.1002/9781444343069.CH21
   Browman CP., 1989, PHONOLOGY, V6, P201, DOI [10.1017/S0952675700001019, DOI 10.1017/S0952675700001019]
   Buzsaki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Carbonell KM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00427
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clements George N., 1985, PHONOLOGY YB, V2, P225, DOI DOI 10.1017/S0952675700000440
   Coleman J, 2003, J PHONETICS, V31, P351, DOI 10.1016/j.wocn.2003.10.001
   Coleman J, 1998, J NEUROLINGUIST, V11, P295, DOI 10.1016/S0911-6044(97)00014-6
   COOPER FS, 1952, J ACOUST SOC AM, V24, P597, DOI 10.1121/1.1906940
   Cornell SA, 2013, J EXP PSYCHOL HUMAN, V39, P757, DOI 10.1037/a0030862
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   CSEPE V, 1992, ELECTROEN CLIN NEURO, V84, P538, DOI 10.1016/0168-5597(92)90043-B
   CSEPE V, 1987, ELECTROEN CLIN NEURO, V66, P571, DOI 10.1016/0013-4694(87)90103-9
   DELL GS, 1993, COGNITIVE SCI, V17, P149, DOI 10.1016/0364-0213(93)90010-6
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Dresher BE, 2015, LINGUIST VAR, V15, P1, DOI 10.1075/lv.15.1.01dre
   Dresher BE, 2015, NORDLYD, V41, P165
   Dressler WU, 1984, PHONOLOGY, V19, P577
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Ettinger A, 2014, BRAIN LANG, V129, P14, DOI 10.1016/j.bandl.2013.11.004
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Fischer C, 2000, AUDIOL NEURO-OTOL, V5, P192, DOI 10.1159/000013880
   Flagg EJ, 2006, NEUROSCI LETT, V397, P263, DOI 10.1016/j.neulet.2005.12.034
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Gage N, 1998, BRAIN RES, V814, P236, DOI 10.1016/S0006-8993(98)01058-0
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   GAY T, 1968, J ACOUST SOC AM, V44, P1570, DOI 10.1121/1.1911298
   GESCHWIN.N, 1970, SCIENCE, V170, P940, DOI 10.1126/science.170.3961.940
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   GOMES H, 1995, J COGNITIVE NEUROSCI, V7, P81, DOI 10.1162/jocn.1995.7.1.81
   Gow DW, 2004, J MEM LANG, V51, P279, DOI 10.1016/j.jml.2004.05.004
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Greenberg S, 1999, SPEECH COMMUN, V29, P159, DOI 10.1016/S0167-6393(99)00050-3
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hagoort P, 2004, SCIENCE, V304, P438, DOI 10.1126/science.1095455
   Hale M., 2008, PHONOLOGICAL ENTERPR
   HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686
   Halle M, 2002, MEMORY SPEECH BACK
   Halle Morris, 1983, PROBLEM BOOK PHONOLO
   HARI R, 1992, ELECTROEN CLIN NEURO, V82, P152, DOI 10.1016/0013-4694(92)90159-F
   Harris J, 2002, FRONTIERS PHONOLOGY, P37
   Hestvik A, 2016, BRAIN LANG, V152, P28, DOI 10.1016/j.bandl.2015.10.007
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Hwang SOK, 2010, PHONOLOGY, V27, P205, DOI 10.1017/S0952675710000102
   Idsardi WJ, 2012, OXFORD HDB LAB PHONO, P593
   Idsardi WJ, 2016, NEUROBIOLOGY LANGUAG, P141
   Jakobson R. C., 1961, PRELIMINARIES SPEECH
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2010, J PHONETICS, V38, P127, DOI 10.1016/j.wocn.2009.11.001
   Jusczyk PW, 2002, EAR HEARING, V23, P2, DOI 10.1097/00003446-200202000-00002
   Kandylaki KD, 2016, J NEUROSCI, V36, P12180, DOI 10.1523/JNEUROSCI.4100-15.2016
   KATZ JJ, 1963, LANGUAGE, V39, P170, DOI 10.2307/411200
   Kazanina N, 2006, P NATL ACAD SCI USA, V103, P11381, DOI 10.1073/pnas.0604821103
   Kimberley TJ, 2007, PHYS THER, V87, P670, DOI 10.2522/ptj.20060149
   KLATT DH, 1989, LEXICAL REPRESENTATI, P169
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kraljic T, 2011, COGNITION, V121, P459, DOI 10.1016/j.cognition.2011.08.015
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Lahiri A, 2002, PHONOL PHONET, V4-1, P637
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Lawyer L, 2014, J NEUROLINGUIST, V27, P18, DOI 10.1016/j.jneuroling.2013.07.001
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   LIBERMAN AM, 1961, J EXP PSYCHOL, V61, P379, DOI 10.1037/h0049038
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1989, SCIENCE, V243, P489, DOI 10.1126/science.2643163
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liberman AM, 1996, SPEECH
   Lindblom Bjorn, 1992, PHONOLOGICAL DEV MOD, P131
   Lombardi L, 1991, LARYNGEAL FEATURES L
   Lotto AJ, 2009, TRENDS COGN SCI, V13, P110, DOI 10.1016/j.tics.2008.11.008
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   Maess B, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00591
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Mazaheri A, 2014, NEUROIMAGE, V87, P356, DOI 10.1016/j.neuroimage.2013.10.052
   MCCARTHY JJ, 1988, PHONETICA, V45, P84, DOI 10.1159/000261820
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   MESTER RA, 1989, LANGUAGE, V65, P258, DOI 10.2307/415333
   Mielke J., 2008, EMERGENCE DISTINCTIV
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   MILLER JD, 1989, J ACOUST SOC AM, V85, P2114, DOI 10.1121/1.397862
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   Mitterer H., 2007, P 16 INT C PHON SCI, P127
   MITTERER H, 2003, THESIS U MAASTRICHT
   MOHANAN KP, 1991, NAT LANG LINGUIST TH, V9, P285, DOI 10.1007/BF00134678
   Moisik SR, 2017, J SPEECH LANG HEAR R, V60, P540, DOI 10.1044/2016_JSLHR-S-16-0019
   Molinaro N, 2016, LANG COGN NEUROSCI, V31, P145, DOI 10.1080/23273798.2015.1077978
   Monahan PJ, 2010, LANG COGNITIVE PROC, V25, P808, DOI 10.1080/01690965.2010.490047
   Monahan PJ, 2013, CAMBRIDGE HDB BIOLIN, P233
   Morillon B, 2015, ANN NY ACAD SCI, V1337, P26, DOI 10.1111/nyas.12629
   MOWREY RA, 1990, J ACOUST SOC AM, V88, P1299, DOI 10.1121/1.399706
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Naatanen R., 2012, OXFORD HDB EVENT REL, P143
   Nashida T, 2000, SLEEP, V23, P821
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2003, NEUROIMAGE, V20, P1839, DOI 10.1016/j.neuroimage.2003.07.019
   Obleser J, 2012, CEREB CORTEX, V22, P2466, DOI 10.1093/cercor/bhr325
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   Penfield W, 1959, SPEECH BRAIN MECH
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Phillips C, 2000, J COGNITIVE NEUROSCI, V12, P1038, DOI 10.1162/08989290051137567
   Phillips C, 2001, COGNITIVE SCI, V25, P711, DOI 10.1016/S0364-0213(01)00049-0
   Picton TW, 2011, HUMAN AUDITORY EVOKE
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Poeppel D, 2012, COGN NEUROPSYCHOL, V29, P34, DOI 10.1080/02643294.2012.710600
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Port RF, 2005, LANGUAGE, V81, P927, DOI 10.1353/lan.2005.0195
   POTTER RK, 1950, J ACOUST SOC AM, V22, P807, DOI 10.1121/1.1906694
   Prince A., 2004, OPTIMALITY THEORY CO
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Reiss Charles, 2018, ROUTLEDGE HDB PHONOL
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Roberts TPL, 2000, J CLIN NEUROPHYSIOL, V17, P114, DOI 10.1097/00004691-200003000-00002
   Roberts TPL, 2004, NEUROREPORT, V15, P1679, DOI 10.1097/01.wnr.0000134928.96937.10
   Roelofs A, 1999, LANG COGNITIVE PROC, V14, P173, DOI 10.1080/016909699386338
   Sabri M, 2005, NEUROIMAGE, V25, P969, DOI 10.1016/j.neuroimage.2004.12.033
   SAGEY E, 1986, THESIS MIT CAMBRIDGE
   SAMS M, 1991, PSYCHOPHYSIOLOGY, V28, P21, DOI 10.1111/j.1469-8986.1991.tb03382.x
   Samuel AG, 2011, ANNU REV PSYCHOL, V62, P49, DOI 10.1146/annurev.psych.121208.131643
   Scharinger M, 2016, NEUROIMAGE, V128, P293, DOI 10.1016/j.neuroimage.2016.01.003
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Scharinger M, 2011, J COGNITIVE NEUROSCI, V23, P3972, DOI 10.1162/jocn_a_00056
   Schluter K, 2016, LANG COGN NEUROSCI, V31, P728, DOI 10.1080/23273798.2016.1151058
   Schluter KT, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00746
   SCHUBERTH RE, 1977, J EXP PSYCHOL HUMAN, V3, P27, DOI 10.1037/0096-1523.3.1.27
   Sculthorpe LD, 2009, BRAIN RES, V1290, P52, DOI 10.1016/j.brainres.2009.06.013
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Smith CL, 1997, J PHONETICS, V25, P471, DOI 10.1006/jpho.1997.0053
   SOLI SD, 1979, J ACOUST SOC AM, V66, P46, DOI 10.1121/1.382972
   Steriade D, 2005, HDB PHONOLOGICAL THE, P114
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   Stevens KN, 2010, J PHONETICS, V38, P10, DOI 10.1016/j.wocn.2008.10.004
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   Stevens KN., 2010, HDB PHONETIC SCI, P424, DOI [10.1002/9781444317251.ch12, DOI 10.1002/9781444317251.CH12]
   STUDDERT.M, 1972, COGNITIVE PSYCHOL, V3, P455, DOI 10.1016/0010-0285(72)90017-5
   STUDDERTKENNEDY M, 1970, J ACOUST SOC AM, V48, P579, DOI 10.1121/1.1912174
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Sussman H, 2000, BRAIN LANG, V71, P237, DOI 10.1006/brln.1999.2258
   Tales A, 1999, NEUROREPORT, V10, P3363, DOI 10.1097/00001756-199911080-00020
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870
   van der Hulst H, 2016, LANG LINGUIST COMPAS, V10, P83, DOI 10.1111/lnc3.12158
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vanhaudenhuyse A, 2008, NEUROCRIT CARE, V8, P262, DOI 10.1007/s12028-007-9016-0
   WANG MD, 1973, J ACOUST SOC AM, V54, P1248, DOI 10.1121/1.1914417
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Wijnen VJM, 2007, CLIN NEUROPHYSIOL, V118, P597, DOI 10.1016/j.clinph.2006.11.020
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002
NR 209
TC 4
Z9 4
U1 0
U2 9
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2333-9691
J9 ANNU REV LINGUIST
PY 2018
VL 4
BP 21
EP 47
DI 10.1146/annurev-linguistics-011817-045537
PG 27
WC Linguistics; Language & Linguistics
SC Linguistics
GA BJ5XS
UT WOS:000426399300002
DA 2021-02-24
ER

PT S
AU Fitch, WT
AF Fitch, W. Tecumseh
BE Liberman, M
   Partee, BH
TI The Biology and Evolution of Speech: A Comparative Analysis
SO ANNUAL REVIEW OF LINGUISTICS, VOL 4
SE Annual Review of Linguistics
LA English
DT Article; Book Chapter
DE human evolution; speech perception; speech production; evolution of
   language; monosynaptic connections; paleo-DNA
ID DUPLEX PERCEPTION; INHERITED SPEECH; AUDITORY-CORTEX; RHESUS-MONKEY;
   VOCAL CONTROL; NEURAL LATERALIZATION; LANGUAGE DISORDER; DESCENDED
   LARYNX; DEEP HOMOLOGY; ACOUSTIC CUES
AB I analyze the biological underpinnings of human speech from a comparative perspective. By first identifying mechanisms that are evolutionarily derived relative to other primates, we obtain members of the faculty of language, derived components (FLD). Understanding when and why these evolved is central to understanding the evolution of speech. There is little evidence for human-specific mechanisms in auditory perception, and the hypothesis that speech perception is "special" is poorly supported by comparative data. Regarding speech production, human peripheral vocal anatomy includes several derived characteristics (permanently descended larynx, loss of air sacs), but their importance has been overestimated. In contrast, the central neural mechanisms underlying speech production involve crucial derived characteristics (direct monosynaptic connections from motor cortex to laryngeal motor neurons, derived intracortical dorsal circuitry between auditory and motor regions). Paleo-DNA from fossil hominins provides an exciting new opportunity to determine when these derived speech production mechanisms arose during evolution.
C1 [Fitch, W. Tecumseh] Univ Vienna, Dept Cognit Biol, A-1090 Vienna, Austria.
RP Fitch, WT (corresponding author), Univ Vienna, Dept Cognit Biol, A-1090 Vienna, Austria.
CR ADRET P, 1993, NETH J ZOOL, V43, P125, DOI 10.1163/156854293X00250
   Alcock KJ, 2000, BRAIN LANG, V75, P34, DOI 10.1006/brln.2000.2323
   Alemseged Z, 2006, NATURE, V443, P296, DOI 10.1038/nature05047
   Andics A, 2014, CURR BIOL, V24, P574, DOI 10.1016/j.cub.2014.01.058
   ARENSBURG B, 1990, AM J PHYS ANTHROPOL, V83, P137, DOI 10.1002/ajpa.1330830202
   Baru AV, 1975, AUDITORY ANAL PERCEP, P91
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2006, PHILOS T R SOC B, V361, P2091, DOI 10.1098/rstb.2006.1933
   Belyk M, 2017, NEUROSCI BIOBEHAV R, V77, P177, DOI 10.1016/j.neubiorev.2017.03.014
   Brauer J, 2011, CEREB CORTEX, V21, P459, DOI 10.1093/cercor/bhq108
   Carstairs-McCarty Andrew, 1999, ORIGINS COMPLEX LANG
   Castellucci GA, 2016, SCI REP-UK, V6, DOI 10.1038/srep23305
   Charlton BD, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12739
   Charlton BD, 2012, ANIM COGN, V15, P999, DOI 10.1007/s10071-012-0527-5
   Charlton BD, 2011, J EXP BIOL, V214, P3414, DOI 10.1242/jeb.061358
   Clarey JC, 1992, MAMMALIAN AUDITORY P, P232
   Clegg M, 2000, AM J PHYS ANTHR S30, V126, P9482
   Crystal D., 2003, CAMBRIDGE ENCY LANGU
   CUTTING JE, 1974, PERCEPT PSYCHOPHYS, V16, P564, DOI 10.3758/BF03198588
   CUTTING JE, 1982, PERCEPT PSYCHOPHYS, V31, P462, DOI 10.3758/BF03204856
   de Boer B, 2010, J PHONETICS, V38, P679, DOI 10.1016/j.wocn.2010.10.003
   de Boer B, 2009, J ACOUST SOC AM, V126, P3329, DOI 10.1121/1.3257544
   DOOLING RJ, 1992, ADV BIOSCI, V83, P407
   Elder JH, 1934, J COMP PSYCHOL, V17, P157, DOI 10.1037/h0073798
   Elemans CPH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9978
   Eliades SJ, 2008, NATURE, V453, P1102, DOI 10.1038/nature06910
   Enard W, 2002, NATURE, V418, P869, DOI 10.1038/nature01025
   Enard W, 2009, CELL, V137, P961, DOI 10.1016/j.cell.2009.03.041
   Fant G., 1960, ACOUSTIC THEORY SPEE
   Fecteau S, 2004, NEUROIMAGE, V23, P840, DOI 10.1016/j.neuroimage.2004.09.019
   Fischer J., 2006, ENCY LANGUAGE LINGUI, P248
   Fischer J, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-14
   Fisher SE, 1998, NAT GENET, V18, P168, DOI 10.1038/ng0298-168
   Fisher SE, 2015, ANNU REV LINGUIST, V1, P289, DOI 10.1146/annurev-linguist-030514-125024
   Fitch W. T., 2009, CRADLE LANGUAGE, P112
   Fitch WT, 2006, J ACOUST SOC AM, V120, P2132, DOI 10.1121/1.2258499
   Fitch WT, 2017, PSYCHON B REV, V24, P3, DOI 10.3758/s13423-017-1236-5
   Fitch WT, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1600723
   Fitch WT, 2013, STRUNGMANN FORUM REP, P499
   Fitch W Tecumseh, 2011, Front Evol Neurosci, V3, P9, DOI 10.3389/fnevo.2011.00009
   Fitch WT, 2010, EVOLUTION OF LANGUAGE, PROCEEDINGS, P137
   Fitch WT, 2010, NEURON, V65, P795, DOI 10.1016/j.neuron.2010.03.011
   Fitch WT, 2000, PHONETICA, V57, P205
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   Fitch WT, 2005, COGNITION, V97, P179, DOI 10.1016/j.cognition.2005.02.005
   Fitch WT, 2000, TRENDS COGN SCI, V4, P258, DOI 10.1016/S1364-6613(00)01494-7
   Fitch WT, 2001, P ROY SOC B-BIOL SCI, V268, P1669, DOI 10.1098/rspb.2001.1704
   FOWLER CA, 1990, J EXP PSYCHOL HUMAN, V16, P742, DOI 10.1037/0096-1523.16.4.742
   French CA, 2007, GENESIS, V45, P440, DOI 10.1002/dvg.20305
   Frey R, 2003, ZOOL ANZ, V242, P33, DOI 10.1078/0044-5231-00086
   Friederici AD, 2017, PSYCHON B REV, V24, P41, DOI 10.3758/s13423-016-1090-x
   Fritzsch B, 2006, INT J COMP PSYCHOL, V19, P1
   Gazzaniga MS, 2009, COGNITIVE NEUROSCIEN, P873
   GEORGE SL, 1978, AM J PHYS ANTHROPOL, V49, P171, DOI 10.1002/ajpa.1330490204
   GESCHWIN.N, 1970, SCIENCE, V170, P940, DOI 10.1126/science.170.3961.940
   Ghazanfar AA, 2005, J NEUROSCI, V25, P5004, DOI 10.1523/JNEUROSCI.0799-05.2005
   Ghazanfar AA, 2007, CURR BIOL, V17, P425, DOI 10.1016/j.cub.2007.01.029
   Gil-da-Costa R, 2006, P ROY SOC B-BIOL SCI, V273, P2313, DOI 10.1098/rspb.2006.3580
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   GOPNIK M, 1990, NATURE, V344, P715, DOI 10.1038/344715a0
   Groszer M, 2008, CURR BIOL, V18, P354, DOI 10.1016/j.cub.2008.01.060
   Guilloud N. B., 1969, P143
   Haesler S, 2007, PLOS BIOL, V5, P2885, DOI 10.1371/journal.pbio.0050321
   Hage SR, 2016, J EXP BIOL, V219, P1744, DOI 10.1242/jeb.137653
   Hammerschmidt K, 2015, Genes Brain Behav, V14, P583, DOI 10.1111/gbb.12237
   Harley Trevor A., 2014, PSYCHOL LANGUAGE DAT
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Harris TR, 2006, ETHOLOGY, V112, P911, DOI 10.1111/j.1439-0310.2006.01247.x
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Hayes C., 1951, THE APE IN OUR HOUSE
   HEFFNER HE, 1986, J NEUROPHYSIOL, V56, P683, DOI 10.1152/jn.1986.56.3.683
   Heffner RS, 2004, ANAT REC PART A, V281A, P1111, DOI 10.1002/ar.a.20117
   Heimbauer LA, 2011, CURR BIOL, V21, P1210, DOI 10.1016/j.cub.2011.06.007
   HEMILA S, 1995, HEARING RES, V85, P31, DOI 10.1016/0378-5955(95)00031-X
   Herbst CT, 2012, SCIENCE, V337, P595, DOI 10.1126/science.1219712
   Hewitt G, 2002, FOLIA PRIMATOL, V73, P70, DOI 10.1159/000064786
   Hienz RD, 2004, J ACOUST SOC AM, V116, P1692, DOI 10.1121/1.1778902
   Holloway R.L., 2004, HUMAN FOSSIL RECORD
   IWATSUBO T, 1990, NEUROLOGY, V40, P309, DOI 10.1212/WNL.40.2.309
   Janik VM, 2000, ANIM BEHAV, V60, P1, DOI 10.1006/anbe.2000.1410
   Jungers WL, 2003, HUM BIOL, V75, P473, DOI 10.1353/hub.2003.0057
   JURGENS U, 1994, BEHAV BRAIN RES, V62, P107, DOI 10.1016/0166-4328(94)90017-5
   Jurgens U, 2002, NEUROSCI LETT, V328, P245, DOI 10.1016/S0304-3940(02)00525-6
   Jurgens U, 2002, NEUROSCI BIOBEHAV R, V26, P235, DOI 10.1016/S0149-7634(01)00068-9
   Kay RF, 1998, P NATL ACAD SCI USA, V95, P5417, DOI 10.1073/pnas.95.9.5417
   KELLOGG WN, 1968, SCIENCE, V162, P423, DOI 10.1126/science.162.3852.423
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   Knornschild M, 2014, CURR OPIN NEUROBIOL, V28, P80, DOI 10.1016/j.conb.2014.06.014
   KOJIMA S, 1990, FOLIA PRIMATOL, V55, P62, DOI 10.1159/000156501
   Krause J, 2007, CURR BIOL, V17, P1908, DOI 10.1016/j.cub.2007.10.008
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   KUYPERS HGJM, 1958, J COMP NEUROL, V110, P221, DOI 10.1002/cne.901100205
   Lai CSL, 2001, NATURE, V413, P519, DOI 10.1038/35097076
   LARSON CR, 1973, PHONETICA, V27, P100, DOI 10.1159/000259430
   Lemon RN, 2005, MUSCLE NERVE, V32, P261, DOI 10.1002/mus.20333
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   Li G, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000900
   LIBERMAN AM, 1981, PERCEPT PSYCHOPHYS, V30, P133, DOI 10.3758/BF03204471
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LIBERMAN AM, 1957, J ACOUST SOC AM, V29, P117, DOI 10.1121/1.1908635
   Lieberman DE, 2001, ARCH ORAL BIOL, V46, P117, DOI 10.1016/S0003-9969(00)00108-4
   LIEBERMAN P, 1972, AM ANTHROPOL, V74, P287, DOI 10.1525/aa.1972.74.3.02a00020
   LIEBERMAN PH, 1969, SCIENCE, V164, P1185, DOI 10.1126/science.164.3884.1185
   LOMBARD RE, 1979, BIOL J LINN SOC, V11, P19, DOI 10.1111/j.1095-8312.1979.tb00027.x
   Losin EAR, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002529
   Maclarnon A, 2004, EVOL ANTHROPOL, V13, P181, DOI 10.1002/evan.20032
   Manley GA, 2000, P NATL ACAD SCI USA, V97, P11736, DOI 10.1073/pnas.97.22.11736
   Maricic T, 2013, MOL BIOL EVOL, V30, P844, DOI 10.1093/molbev/mss271
   Marshall AJ, 1999, ANIM BEHAV, V58, P825, DOI 10.1006/anbe.1999.1219
   Martinez I, 2004, P NATL ACAD SCI USA, V101, P9976, DOI 10.1073/pnas.0403595101
   Martinez I, 2013, QUATERN INT, V295, P94, DOI 10.1016/j.quaint.2012.07.001
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   NELSON DA, 1989, SCIENCE, V244, P976, DOI 10.1126/science.2727689
   Nishimura T, 2006, J HUM EVOL, V51, P244, DOI 10.1016/j.jhevol.2006.03.005
   NOTTEBOHM F, 1971, J EXP ZOOL, V177, P229, DOI 10.1002/jez.1401770210
   Ohms VR, 2009, P R SOC LOND B
   Paabo S, 2014, CELL, V157, P216, DOI 10.1016/j.cell.2013.12.036
   Paracchini S, 2007, ANNU REV GENOM HUM G, V8, P57, DOI 10.1146/annurev.genom.8.080706.092312
   PASTORE RE, 1983, PERCEPT PSYCHOPHYS, V33, P469, DOI 10.3758/BF03202898
   Perrodin C, 2011, CURR BIOL, V21, P1408, DOI 10.1016/j.cub.2011.07.028
   PETERSEN MR, 1984, BEHAV NEUROSCI, V98, P779, DOI 10.1037/0735-7044.98.5.779
   Petkov CI, 2008, NAT NEUROSCI, V11, P367, DOI 10.1038/nn2043
   Pfenning AR, 2014, SCIENCE, V346, P1333, DOI 10.1126/science.1256846
   Pisanski K, 2016, SCI REP-UK, V6, DOI 10.1038/srep34389
   Ploog D., 1988, P195
   Poremba A, 2004, NATURE, V427, P448, DOI 10.1038/nature02268
   RAO MRKM, 1984, INDIAN VET J, V61, P618
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rauschecker JP, 2000, P NATL ACAD SCI USA, V97, P11800, DOI 10.1073/pnas.97.22.11800
   Reby D, 2005, P ROY SOC B-BIOL SCI, V272, P941, DOI 10.1098/rspb.2004.2954
   Reichmuth C, 2014, CURR OPIN NEUROBIOL, V28, P66, DOI 10.1016/j.conb.2014.06.011
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rilling JK, 2008, NAT NEUROSCI, V11, P426, DOI 10.1038/nn2072
   Rodel RMW, 2004, LARYNGOSCOPE, V114, P918
   Rodel RMW, 2003, ANN OTO RHINOL LARYN, V112, P71
   Rogers L.J., 2002, COMP VERTEBRATE LATE
   ROSEN SM, 1981, PERCEPT PSYCHOPHYS, V30, P156, DOI 10.3758/BF03204474
   SASAKI CT, 1977, ARCH OTOLARYNGOL, V103, P169
   Savage-Rumbaugh E S, 1993, Monogr Soc Res Child Dev, V58, P1
   Scharff C, 2011, PHILOS T R SOC B, V366, P2124, DOI 10.1098/rstb.2011.0001
   Schenker NM, 2010, CEREB CORTEX, V20, P730, DOI 10.1093/cercor/bhp138
   Schreiweis C, 2014, P NATL ACAD SCI USA, V111, P14253, DOI 10.1073/pnas.1414542111
   Shubin N, 2009, NATURE, V457, P818, DOI 10.1038/nature07891
   Simonyan K, 2003, BRAIN RES, V974, P43, DOI 10.1016/S0006-8993(03)02548-4
   Simonyan K, 2014, CURR OPIN NEUROBIOL, V28, P15, DOI 10.1016/j.conb.2014.05.006
   Simonyan K, 2011, NEUROSCIENTIST, V17, P197, DOI 10.1177/1073858410386727
   SINNOTT JM, 1987, J ACOUST SOC AM, V82, P1539, DOI 10.1121/1.395144
   Sinnott JM, 1999, J ACOUST SOC AM, V106, P929, DOI 10.1121/1.427107
   Skead D.M., 1980, Cormorant, V8, P27
   STRIEDTER GF, 1994, J COMP NEUROL, V343, P35, DOI 10.1002/cne.903430104
   SUGA N, 1990, NEURAL NETWORKS, V3, P3, DOI 10.1016/0893-6080(90)90043-K
   Suthers RA, 2016, VERTEBRATE SOUND PRO
   Taylor AM, 2010, J ZOOL, V280, P221, DOI 10.1111/j.1469-7998.2009.00661.x
   Thexton AJ, 1998, FRONT ORAL BIOL, V9, P168
   Tian B, 2001, SCIENCE, V292, P290, DOI 10.1126/science.1058911
   Titze I.R., 2006, MYOELASTIC AERODYNAM
   Trout JD, 2003, CURR DIR PSYCHOL SCI, V12, P155, DOI 10.1111/1467-8721.t01-1-01251
   Tucker AS, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2015.0483
   Vallortigara G, 2005, BEHAV BRAIN SCI, V28, P575, DOI 10.1017/S0140525X05000105
   VANDENBERG J, 1958, J SPEECH HEAR RES, V1, P227, DOI 10.1044/jshr.0103.227
   Vargha-Khadem F, 2005, NAT REV NEUROSCI, V6, P131, DOI 10.1038/nrn1605
   Vernes SC, 2017, PSYCHON B REV, V24, P111, DOI 10.3758/s13423-016-1060-3
   Wall C. E., 2001, ENCY LIFE SCI, P1
   Wang R, 2015, J COMP NEUROL, V523, P892, DOI 10.1002/cne.23719
   Wang VY, 2002, CURR BIOL, V12, P1611, DOI 10.1016/S0960-9822(02)01144-2
   Wang XQ, 2001, J NEUROPHYSIOL, V86, P2616
   Watkins KE, 2002, BRAIN, V125, P452, DOI 10.1093/brain/awf058
   Watkins KE, 2002, BRAIN, V125, P465, DOI 10.1093/brain/awf057
   Weissengruber GE, 2002, J ANAT, V201, P195, DOI 10.1046/j.1469-7580.2002.00088.x
   Wich SA, 2009, PRIMATES, V50, P56, DOI 10.1007/s10329-008-0117-y
   Wild JM, 1997, J NEUROBIOL, V33, P653, DOI 10.1002/(SICI)1097-4695(19971105)33:5<653::AID-NEU11>3.0.CO;2-A
   Wohlgemuth S, 2014, CURR OPIN NEUROBIOL, V28, P86, DOI 10.1016/j.conb.2014.06.009
   Yerkes R. M., 1929, GREAT APES
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   ZOLOTH SR, 1979, SCIENCE, V204, P870, DOI 10.1126/science.108805
NR 177
TC 19
Z9 19
U1 2
U2 18
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2333-9691
J9 ANNU REV LINGUIST
PY 2018
VL 4
BP 255
EP 279
DI 10.1146/annurev-linguistics-011817-045748
PG 25
WC Linguistics; Language & Linguistics
SC Linguistics
GA BJ5XS
UT WOS:000426399300013
OA Other Gold
DA 2021-02-24
ER

PT J
AU Hanulikova, A
AF Hanulikova, Adriana
TI The effect of perceived ethnicity on spoken text comprehension under
   clear and adverse listening conditions
SO LINGUISTICS VANGUARD
LA English
DT Article
DE language comprehension; stereotypes; evaluation of speakers; social
   effects on language processing; adverse listening conditions
ID EXPECTATIONS; DISCRIMINATION; INFORMATION; PERCEPTION; ATTITUDES
AB Social information such as ethnicity affects metalinguistic judgments, speech perception and evaluation. This study tested whether previously reported negative effects of perceived East-Asian ethnicity on language comprehension and accentedness ratings would also be found for Moroccan ethnicity and in a socio-cultural environment with a population used to being and communicating with nonnative speakers. The results showed that accentedness ratings and comprehension scores do not depend upon the ethnicity of the speaker. We then tested whether the effect would change under adverse listening conditions and found an effect of perceived ethnicity on accentedness ratings but not on comprehension scores, suggesting that the effect of ethnicity on language comprehension is not altered under adverse listening conditions. Effects of ethnicity on accentedness ratings thus replicate previous findings, but only under suboptimal listening conditions. Although the effect of ethnicity on comprehension was not replicated in regards to Moroccan ethnicity and in a linguistically experienced population, negative correlations between accentedness ratings and the corresponding comprehension scores underlie the contribution of listeners' characteristics to the comprehension and evaluation of nonnative speech.
C1 [Hanulikova, Adriana] Albert Ludwigs Univ Freiburg, Deutsch Seminar Germanist Linguist, Pl Univ 3, D-79098 Freiburg, Germany.
   [Hanulikova, Adriana] Freiburg Inst Adv Studies FRIAS, Freiburg, Germany.
RP Hanulikova, A (corresponding author), Albert Ludwigs Univ Freiburg, Deutsch Seminar Germanist Linguist, Pl Univ 3, D-79098 Freiburg, Germany.; Hanulikova, A (corresponding author), Freiburg Inst Adv Studies FRIAS, Freiburg, Germany.
EM Adriana.Hanulikova@germanistik.uni-freiburg.de
OI Hanulikova, Adriana/0000-0001-9010-4185
FU Max-Planck-Gesellschaft, GermanyMax Planck Society; FRIAS
FX We would like to thank Laurence Bruggeman for assistance in testing
   participants and Frank Eisner for help with voice manipulations and for
   comments on previous versions of this manuscript. This research was
   presented at the Cognitive Science Conference in Berlin, 2013. This
   research was funded by the Max-Planck-Gesellschaft, Germany, and FRIAS.
CR [Anonymous], 2016, EF ENGLISH PROFICIEN
   [Anonymous], 2013, EF ENGLISH PROFICIEN
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   CBS, 2017, STAT NETH
   CBS, 2013, STAT NETH
   Coenders M, 2008, J SOC ISSUES, V64, P269, DOI 10.1111/j.1540-4560.2008.00561.x
   Davies A., 2003, NATIVE SPEAKER MYTH
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Derwing T.M., 1997, STUDIES 2 LANGUAGE A, V19, P1, DOI [10.1017/s0272263197001010, DOI 10.1017/S0272263197001010]
   Fiske ST, 1999, DUAL-PROCESS THEORIES IN SOCIAL PSYCHOLOGY, P231
   Friedman A., 2015, ATLANTIC
   Furman N., 2007, ENROLLMENTS LANGUAGE
   Glock S, 2013, SOC PSYCHOL EDUC, V16, P111, DOI 10.1007/s11218-012-9197-z
   Hansen K, 2014, J LANG SOC PSYCHOL, V33, P68, DOI 10.1177/0261927X13499761
   Hanulikova A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01396
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   LAMBERT WE, 1960, J ABNORM SOC PSYCH, V60, P44, DOI 10.1037/h0044430
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lattner S, 2003, NEUROSCI LETT, V339, P191, DOI 10.1016/S0304-3940(03)00027-2
   Macrae CN, 2001, BRIT J PSYCHOL, V92, P239, DOI 10.1348/000712601162059
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Schalk-Soekar SRG, 2004, INT J INTERCULT REL, V28, P533, DOI 10.1016/j.ijintrel.2005.01.009
   Scharinger M, 2011, NEUROIMAGE, V56, P2329, DOI 10.1016/j.neuroimage.2011.04.007
   SrulL T.K, 1988, ADV SOCIAL COGNITION, V1, P1, DOI [10.4324/9781315801940, DOI 10.1037/0022-3514.56.1.5]
   Staum Casasanto Laura, 2008, P 30 ANN M COGN SCI
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   Yi HG, 2013, J ACOUST SOC AM, V134, pEL387, DOI 10.1121/1.4822320
   Zheng Y, 2017, ATTEN PERCEPT PSYCHO, V79, P1841, DOI 10.3758/s13414-017-1329-2
   Zick A, 2008, J SOC ISSUES, V64, P233, DOI 10.1111/j.1540-4560.2008.00559.x
NR 36
TC 1
Z9 1
U1 0
U2 5
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2199-174X
J9 LINGUIST VANGUARD
JI Linguist. Vanguard
PD JAN
PY 2018
VL 4
IS 1
AR 20170029
DI 10.1515/lingvan-2017-0029
PG 9
WC Linguistics; Language & Linguistics
SC Linguistics
GA FY6ZT
UT WOS:000427012100003
DA 2021-02-24
ER

PT J
AU Garcia, PB
   Froud, K
AF Garcia, Paula B.
   Froud, Karen
TI Perception of American English vowels by sequential Spanish-English
   bilinguals
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE ERPs; MMN; P300; vowel perception; second-language learners;
   bilingualism; attention; durational and spectral cues
ID MISMATCH NEGATIVITY MMN; L1-SPANISH SPEAKERS ACQUISITION;
   SPEECH-PERCEPTION; LEXICAL SELECTION; DURATION CHANGES; NATIVE ENGLISH;
   LANGUAGE; BRAIN; EXPERIENCE; CONTRAST
AB Research on American-English (AE) vowel perception by Spanish-English bilinguals has focused on the vowels /i/-/I/ (e.g., in sheep/ship). Other AE vowel contrasts may present perceptual challenges for this population, especially those requiring both spectral and durational discrimination. We used Event-Related Potentials (ERPs), MMN (Mismatch Negativity) and P300, to index discrimination of AE vowels /a/-/boolean AND/ by sequential adult Spanish-English bilingual listeners compared to AE monolinguals. Listening tasks were non-attended and attended, and vowels were presented with natural and neutralized durations. Regardless of vowel duration, bilingual listeners showed no MMN to unattended sounds, and P300 responses were elicited to /a/ but not /boolean AND/ in the attended condition. Monolingual listeners showed pre-attentive discrimination (MMN) for /a/ only; while both vowels elicited P300 responses when attended. Findings suggest that Spanish-English bilinguals recruit attentional and cognitive resources enabling native-like use of both spectral and durational cues to discriminate between AE vowels /a/ and /boolean AND/.
C1 [Garcia, Paula B.] Boys Town Natl Res Hosp, 555 North,30th St, Omaha, NE 68131 USA.
   [Froud, Karen] Columbia Univ Teachers Coll, Dept Biobehav Sci, New York, NY 10027 USA.
RP Garcia, PB (corresponding author), Boys Town Natl Res Hosp, 555 North,30th St, Omaha, NE 68131 USA.
EM paula.garcia@boystown.org
FU Teachers College, Columbia University; Boys Town National Research
   Hospital [P20 GM109023]; NATIONAL INSTITUTE OF GENERAL MEDICAL
   SCIENCESUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of General
   Medical Sciences (NIGMS) [P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023] Funding Source: NIH RePORTER
FX The research reported here was partially funded by a grant to the first
   author (Vice President's Student Research in Diversity Grant from
   Teachers College, Columbia University), and by P20 GM109023 (Boys Town
   National Research Hospital). It formed part of the first author's
   doctoral dissertation work. The authors thank the following people for
   assistance during the study: Dayna Moya, Guannan Shen, Lisa Levinson,
   Heather Green, Felicidad Garcia and Trey Avery in the Neurocognition of
   Language Lab, Teachers College, Columbia University. We are deeply
   thankful to Kanae Nishi, Michael Gorga, Rachel Scheperle, Ben Kirby,
   Erika Levy and Laura Sanchez for their comments and suggestions on the
   manuscript and on earlier versions of this work.
CR AALTONEN O, 1987, BIOL PSYCHOL, V24, P197, DOI 10.1016/0301-0511(87)90002-0
   Bent T, 2007, LANGUAGE EXPERIENCE, P331
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   BRADLOW AR, 1995, J ACOUST SOC AM, V97, P1916, DOI 10.1121/1.412064
   Campbell T, 2007, PSYCHOPHYSIOLOGY, V44, P530, DOI 10.1111/j.1469-8986.2007.00529.x
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Cohen JC, 1983, APPL MULTIPLE REGRES
   COWAN N, 1986, J ACOUST SOC AM, V79, P500, DOI 10.1121/1.393537
   CSEPE V, 1995, EAR HEARING, V16, P91, DOI 10.1097/00003446-199502000-00007
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   Deouell LY, 2003, NEUROSCI LETT, V335, P171, DOI 10.1016/S0304-3940(02)01189-8
   Dien J, 2003, COGNITIVE BRAIN RES, V17, P637, DOI 10.1016/S0926-6410(03)00188-5
   DONCHIN E, 1988, BEHAV BRAIN SCI, V11, P357, DOI 10.1017/S0140525X00058027
   Escudero P., 2005, THESIS, V113
   Escudero P., 2004, STUDIES 2 LANGUAGE A, V26, DOI [10.1017/S0272263104040021, DOI 10.1017/S0272263104040021]
   Escudero P, 2010, J ACOUST SOC AM, V128, pEL254, DOI 10.1121/1.3488794
   Ferree TC, 2001, CLIN NEUROPHYSIOL, V112, P536, DOI 10.1016/S1388-2457(00)00533-2
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1994, J ACOUST SOC AM, V95, P3623, DOI 10.1121/1.409931
   FLEGE JE, 1991, Q J EXP PSYCHOL-A, V43, P701, DOI 10.1080/14640749108400993
   Fogerty D, 2009, J ACOUST SOC AM, V126, P847, DOI 10.1121/1.3159302
   FOX RA, 1995, J ACOUST SOC AM, V97, P2540, DOI 10.1121/1.411974
   Fox RA, 2009, J ACOUST SOC AM, V126, P2603, DOI 10.1121/1.3212921
   GORDON PC, 1993, COGNITIVE PSYCHOL, V25, P1, DOI 10.1006/cogp.1993.1001
   Grimm S, 2004, NEUROSCI LETT, V356, P83, DOI 10.1016/j.neulet.2003.11.035
   Hammond RM, 2001, SOUNDS SPANISH ANAL
   Harris J., 1969, SPANISH PHONOLOGY, P105, DOI [10.1016/j.brainres.2010.08.092, DOI 10.1016/J.BRAINRES.2010.08.092]
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hisagi M, 2010, BRAIN RES, V1360, P89, DOI 10.1016/j.brainres.2010.08.092
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Ji A, 2014, INTERSPEECH, P721
   JOHNSON K, 1993, LANGUAGE, V69, P505, DOI 10.2307/416697
   Karypidis C, 2007, P 16 INT C PHON SCI, P657
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   Kirmse U, 2008, INT J PSYCHOPHYSIOL, V67, P131, DOI 10.1016/j.ijpsycho.2007.10.012
   Kondaurova MV, 2008, J ACOUST SOC AM, V124, P3959, DOI 10.1121/1.2999341
   Lipski SC, 2008, NEUROREPORT, V19, P1079, DOI 10.1097/WNR.0b013e3283056378
   Lipski SC, 2012, PSYCHOPHYSIOLOGY, V49, P638, DOI 10.1111/j.1469-8986.2011.01347.x
   Marian V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043230
   Minagawa-Kawai Y, 2004, NEUROREPORT, V15, P899, DOI 10.1097/00001756-200404090-00033
   Morrison G. S., 2006, SEL P 2 C LAB APPR S, P35
   Morrison GS, 2009, LANG SPEECH, V52, P437, DOI 10.1177/0023830909336583
   Morrison GS, 2008, LANG SPEECH, V51, P285, DOI 10.1177/0023830908099067
   Munro MJ, 2008, LANG LEARN, V58, P479, DOI 10.1111/j.1467-9922.2008.00448.x
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1997, AUDIOL NEURO-OTOL, V2, P341
   NAATANEN R, 1990, BEHAV BRAIN SCI, V13, P201, DOI 10.1017/S0140525X00078407
   NAATANEN R, 1995, EAR HEARING, V16, P6
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Nenonen S, 2005, BRAIN LANG, V92, P26, DOI 10.1016/j.bandl.2004.05.005
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   Nishi K, 2008, J ACOUST SOC AM, V124, P576, DOI 10.1121/1.2931949
   Ong JH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133446
   Peltola MS, 2012, BRAIN LANG, V121, P261, DOI 10.1016/j.bandl.2012.03.007
   Peltola MS, 2003, NEUROSCI LETT, V352, P25, DOI 10.1016/j.neulet.2003.08.013
   POLICH J, 1995, BIOL PSYCHOL, V41, P103, DOI 10.1016/0301-0511(95)05130-9
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004
   REPP BH, 1990, J ACOUST SOC AM, V88, P2080, DOI 10.1121/1.400105
   Rivera-Gaxiola M, 2000, BEHAV BRAIN RES, V111, P13, DOI 10.1016/S0166-4328(00)00139-X
   Schwartz JL, 2005, SPEECH COMMUN, V45, P425, DOI 10.1016/j.specom.2004.12.001
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Shafer VL, 2004, COGNITIVE BRAIN RES, V18, P242, DOI 10.1016/j.cogbrainres.2003.10.007
   Sharma A, 1997, EVOKED POTENTIAL, V104, P540, DOI 10.1016/S0168-5597(97)00050-6
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Spencer KM, 1999, PSYCHOPHYSIOLOGY, V36, P220, DOI 10.1111/1469-8986.3620220
   Strange W, 2007, J ACOUST SOC AM, V122, P1111, DOI 10.1121/1.2749716
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Sussman E, 2004, HEARING RES, V190, P128, DOI 10.1016/S0378-5955(04)00016-4
   Sussman E, 2002, CLIN NEUROPHYSIOL, V113, P1909, DOI 10.1016/S1388-2457(02)00300-0
   Tamminen H, 2013, INT J PSYCHOPHYSIOL, V87, P8, DOI 10.1016/j.ijpsycho.2012.10.003
   Tervaniemi M, 2006, EUR J NEUROSCI, V23, P2538, DOI 10.1111/j.1460-9568.2006.04752.x
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   Tremblay K, 1997, J ACOUST SOC AM, V102, P3762, DOI 10.1121/1.420139
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   vanOoijen B, 1996, MEM COGNITION, V24, P573, DOI 10.3758/BF03201084
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   Ylinen S, 2006, BRAIN RES, V1072, P175, DOI 10.1016/j.brainres.2005.12.004
   Ylinen S, 2005, NEUROREPORT, V16, P1857, DOI 10.1097/01.wnr.0000185959.11465.9b
   Ylinen S, 2010, J COGNITIVE NEUROSCI, V22, P1319, DOI 10.1162/jocn.2009.21272
NR 92
TC 0
Z9 0
U1 0
U2 6
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD JAN
PY 2018
VL 21
IS 1
BP 80
EP 103
DI 10.1017/S1366728916000808
PG 24
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA FY2QS
UT WOS:000426661200006
PM 29449782
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Van den Heuij, KML
   Neijenhuis, K
   Coene, M
AF Van den Heuij, Kirsten M. L.
   Neijenhuis, Karin
   Coene, Martine
TI Acoustic environments that support equally accessible oral higher
   education as a human right
SO INTERNATIONAL JOURNAL OF SPEECH-LANGUAGE PATHOLOGY
LA English
DT Article
DE Article 19; Universal Declaration of Human Rights; United Nations;
   higher education; tertiary education; acoustics; acoustic environment;
   speech perception; hearing disabilities; participation
ID LANGUAGE-DEVELOPMENT; COCHLEAR IMPLANTS; HEARING-LOSS; CHILDREN;
   CLASSROOM; PERFORMANCE; AGE
AB Purpose: People have the right to freedom of opinion and expression, as defined in Article 19 of the Universal Declaration of Human Rights. Higher education plays a major role in helping students to develop and express their own opinions and, therefore, should be equally accessible to all. This article focuses on how students judge the accessibility to oral instruction in higher education listening contexts.
   Method: We collected data from 191 students in higher education by means of a questionnaire, addressing understanding speech in different types of classrooms and various educational settings.
   Result: In lecture halls, understanding speech was judged to be significantly worse than in smaller classrooms. Two important negative factors were identified: background noise in classrooms and lecture halls and the non-use of a microphone.
   Conclusions: In lecture halls students achieve good or excellent speech perception only when lecturers are using a microphone. Nevertheless, this is not a standard practice. To achieve genuine inclusion in tertiary education programs, it is essential to remove acoustic barriers to understanding speech as much as possible. This study is a first step to identify communication facilitators to oral higher education instruction, for students with hearing loss or communication impairment.
C1 [Van den Heuij, Kirsten M. L.; Neijenhuis, Karin] Rotterdam Univ Appl Sci, Res Ctr Innovat Care, Rotterdam, Netherlands.
   [Van den Heuij, Kirsten M. L.; Coene, Martine] Vrije Univ Amsterdam, Dept Language & Commun, Amsterdam, Netherlands.
RP Van den Heuij, KML (corresponding author), Rotterdam Univ Appl Sci, Rochussenstr 198, NL-3015 EK Rotterdam, Netherlands.
EM k.m.l.van.den.heuij@hr.nl
RI Neijenhuis, Karin/L-5075-2019
OI Neijenhuis, Karin/0000-0002-1955-3639; Coene,
   Martine/0000-0001-9201-7667
CR ANDERSON K, 1998, LISTENING INVENTORIE
   Boothroyd A., 2004, ACCESS ACHIEVING CLE, P207
   CATTELL RB, 1966, MULTIVAR BEHAV RES, V1, P245, DOI 10.1207/s15327906mbr0102_10
   Coene M, 2011, LANG COGNITIVE PROC, V26, P1083, DOI 10.1080/01690965.2010.520540
   Conway JM, 2003, ORGAN RES METHODS, V6, P147, DOI 10.1177/1094428103251541
   Damen GWJA, 2006, ANN OTO RHINOL LARYN, V115, P542, DOI 10.1177/000348940611500709
   Eggenschwiler K., 2005, FORUM ACUSTICUM
   Field A., 2000, DISCOVERING STAT USI
   Hammer A, 2016, EAR HEARING, V37, P64, DOI 10.1097/AUD.0000000000000205
   IBM Corp, 2015, IBM SPSS STAT WIND V
   Jamieson Donald G, 2004, J Am Acad Audiol, V15, P508, DOI 10.3766/jaaa.15.7.5
   Kirk KI, 2002, ANN OTO RHINOL LARYN, V111, P69
   Klatte M, 2010, ENVIRON BEHAV, V42, P659, DOI 10.1177/0013916509336813
   Kline P, 1999, HDB PSYCHOL TESTING
   Mikulski W, 2011, ARCH ACOUST, V36, P777, DOI 10.2478/v10168-011-0052-6
   Neijenhuis K., 2005, MANUAL LIFE NL LISTE
   Neijenhuis K., 2005, STUDENT VERSION LIFE
   Nelson PB, 2000, LANG SPEECH HEAR SER, V31, P356, DOI 10.1044/0161-1461.3104.356
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Smaldino J.J., 2012, HDB ACOUSTIC ACCESSI
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p1S, DOI 10.1097/AUD.0000000000000220
   United Nations, 2015, TRANSF OUR WORLD 203
   United Nations (UN), 1948, UNIVERSAL DECLARATIO
   World Health Organization (WHO), 2001, INT CLASS FUNCT DIS
   Yoshinaga-Itano C, 1998, PEDIATRICS, V102, P1161, DOI 10.1542/peds.102.5.1161
NR 26
TC 1
Z9 1
U1 0
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1754-9507
EI 1754-9515
J9 INT J SPEECH-LANG PA
JI Int. J. Speech-Lang. Pathol.
PY 2018
VL 20
IS 1
SI SI
BP 108
EP 114
DI 10.1080/17549507.2017.1413136
PG 7
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FX0XR
UT WOS:000425771500019
PM 29271668
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Polonenko, MJ
   Papsin, BC
   Gordon, KA
AF Polonenko, Melissa Jane
   Papsin, Blake Croll
   Gordon, Karen Ann
TI Delayed access to bilateral input alters cortical organization in
   children with asymmetric hearing
SO NEUROIMAGE-CLINICAL
LA English
DT Article
DE Bimodal; Electro-acoustic stimulation; Development; Hearing loss;
   Deafness; Evoked related potential; Evoked potential; Electrophysiology;
   Beamformer; Cortex
ID SINGLE-SIDED DEAFNESS; AUDITORY-SYSTEM ACTIVITY; COCHLEAR IMPLANTS;
   BRAIN-STEM; AURAL PREFERENCE; MUSIC PERCEPTION; RECOGNITION; TIME;
   STIMULATION; ADOLESCENTS
AB Bilateral hearing in early development protects auditory cortices from reorganizing to prefer the better ear. Yet, such protection could be disrupted by mismatched bilateral input in children with asymmetric hearing who require electric stimulation of the auditory nerve from a cochlear implant in their deaf ear and amplified acoustic sound from a hearing aid in their better ear (bimodal hearing). Cortical responses to bimodal stimulation were measured by electroencephalography in 34 bimodal users and 16 age-matched peers with normal hearing, and compared with the same measures previously reported for 28 age-matched bilateral implant users. Both auditory cortices increasingly favoured the better ear with delay to implanting the deaf ear; the time course mirrored that occurring with delay to bilateral implantation in unilateral implant users. Preference for the implanted ear tended to occur with ongoing implant use when hearing was poor in the non-implanted ear. Speech perception deteriorated with longer deprivation and poorer access to high-frequencies. Thus, cortical preference develops in children with asymmetric hearing but can be avoided by early provision of balanced bimodal stimulation. Although electric and acoustic stimulation differ, these inputs can work sympathetically when used bilaterally given sufficient hearing in the non-implanted ear.
C1 [Polonenko, Melissa Jane; Gordon, Karen Ann] Univ Toronto, Inst Med Sci, Toronto, ON M5S 1A8, Canada.
   [Polonenko, Melissa Jane; Gordon, Karen Ann] Hosp Sick Children, Neurosci & Mental Hlth, Toronto, ON M5G 1X8, Canada.
   [Papsin, Blake Croll; Gordon, Karen Ann] Univ Toronto, Dept Otolaryngol Head & Neck Surg, Toronto, ON M5G 2N2, Canada.
   [Papsin, Blake Croll; Gordon, Karen Ann] Hosp Sick Children, Otolaryngol Head & Neck Surg, Toronto, ON M5G 1X8, Canada.
RP Polonenko, MJ (corresponding author), Hosp Sick Children, Archies Cochlear Implant Lab, Atrium Room 6D08,555 Univ Ave, Toronto, ON M5G 1X8, Canada.
EM melissa.polonenko@mail.utoronto.ca
OI Polonenko, Melissa/0000-0003-1914-6117
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP-97924, MFE-1748241]; Hospital for Sick Children
   Research Institute (Clinician-Scientist Training Program Studentship and
   Research Training Competition Award); Ontario Ministry of Ministry of
   Advanced Education and Skills Development; University of Toronto
   (Ontario Graduate Doctoral Scholarship); University of TorontoUniversity
   of Toronto
FX Funding for this project was provided by the Canadian Institutes of
   Health Research (MOP-97924 to KAG and BCP, MFE-1748241 to MJP), The
   Hospital for Sick Children Research Institute (Clinician-Scientist
   Training Program Studentship and Research Training Competition Award to
   MJP), and the Ontario Ministry of Ministry of Advanced Education and
   Skills Development with The University of Toronto (Ontario Graduate
   Doctoral Scholarship for MJP), and the University of Toronto
   (Studentship Funding for MJP).
CR Arndt S, 2017, HNO, V65, P98, DOI 10.1007/s00106-016-0297-5
   Arndt S, 2015, AUDIOL NEURO-OTOL, V20, P21, DOI 10.1159/000380744
   Bartov T, 2014, J SPEECH LANG HEAR R, V57, P1929, DOI 10.1044/2014_JSLHR-H-13-0190
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Brown AD, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516668303
   Cadieux JH, 2013, OTOL NEUROTOL, V34, P408, DOI 10.1097/MAO.0b013e31827850b8
   Ching T Y C, 2007, Trends Amplif, V11, P161, DOI 10.1177/1084713807304357
   Dalal SS, 2006, IEEE T BIO-MED ENG, V53, P1357, DOI 10.1109/TBME.2006.873752
   Easwar V, 2017, BRAIN BEHAV, V7, DOI 10.1002/brb3.638
   Easwar V, 2017, J NEUROSCI, V37, P2349, DOI 10.1523/JNEUROSCI.2538-16.2017
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Gfeller K, 2012, J MUSIC THER, V49, P68, DOI 10.1093/jmt/49.1.68
   Giannantonio S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136685
   Gordon KA, 2006, AUDIOL NEURO-OTOL, V11, P7, DOI 10.1159/000088851
   Gordon K, 2015, PEDIATRICS, V136, P141, DOI 10.1542/peds.2014-3520
   Gordon KA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114841
   Gordon KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00719
   Gordon KA, 2013, BRAIN, V136, P1609, DOI 10.1093/brain/awt052
   Gordon KA, 2010, OTOL NEUROTOL, V31, P1293, DOI 10.1097/MAO.0b013e3181e8f965
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   HARTMANN R, 1984, HEARING RES, V13, P47, DOI 10.1016/0378-5955(84)90094-7
   Hopyan T, 2016, CHILD NEUROPSYCHOL, V22, P366, DOI 10.1080/09297049.2014.992400
   Hopyan T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00425
   Jiwani S, 2016, HUM BRAIN MAPP, V37, P135, DOI 10.1002/hbm.23019
   Keating P, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00123
   Korver AMH, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2016.94
   Kral A, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00093
   Kral A, 2013, BRAIN, V136, P180, DOI 10.1093/brain/aws305
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kral A, 2009, J NEUROSCI, V29, P811, DOI 10.1523/JNEUROSCI.2424-08.2009
   Kuppler K, 2013, INT J PEDIATR OTORHI, V77, P617, DOI 10.1016/j.ijporl.2013.01.014
   Landsberger DM, 2015, EAR HEARING, V36, pE207, DOI 10.1097/AUD.0000000000000163
   Lieu JEC, 2013, OTOL NEUROTOL, V34, P1703, DOI 10.1097/MAO.0000000000000190
   Lieu JEC, 2010, PEDIATRICS, V125, pE1348, DOI 10.1542/peds.2009-2448
   Limb CJ, 2012, OTOLARYNG CLIN N AM, V45, P129, DOI 10.1016/j.otc.2011.08.021
   Litovsky RY, 2010, J ACOUST SOC AM, V127, P400, DOI 10.1121/1.3257546
   Macias AR, 2016, EUR ANN OTORHINOLARY, V133, pS15, DOI 10.1016/j.anorl.2016.04.017
   Petersson KM, 1999, PHILOS T R SOC B, V354, P1261, DOI 10.1098/rstb.1999.0478
   Pittman AL, 2003, EAR HEARING, V24, P198, DOI 10.1097/01.AUD.0000069226.22983.80
   Polley DB, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3547
   Polonenko M. J., 2017, SCI REP IN REVIEW
   Polonenko MJ, 2017, J ACOUST SOC AM, V141, P4494, DOI 10.1121/1.4985123
   Polonenko MJ, 2015, AUDIOL NEURO-OTOL, V20, P13, DOI 10.1159/000380743
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Popescu MV, 2010, NEURON, V65, P718, DOI 10.1016/j.neuron.2010.02.019
   R Core Team, 2016, R LANG ENV STAT COMP
   Rachakonda T, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00087
   Reiss LAJ, 2014, JARO-J ASSOC RES OTO, V15, P235, DOI 10.1007/s10162-013-0434-8
   ROSENHAMER HJ, 1981, SCAND AUDIOL, V10, P3, DOI 10.3109/01050398109076156
   Sherbecoe RL, 2004, INT J AUDIOL, V43, P442, DOI 10.1080/14992020400050056
   Shirvani S, 2016, ANN OTO RHINOL LARYN, V125, P470, DOI 10.1177/0003489415619943
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556
   Thomas JP, 2017, OTOL NEUROTOL, V38, P496, DOI 10.1097/MAO.0000000000001343
   Tibbetts K, 2011, OTOLARYNG HEAD NECK, V144, P602, DOI 10.1177/0194599810394954
   Tillein J, 2016, CEREB CORTEX, V26, P1762, DOI 10.1093/cercor/bhv351
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   Vrba J, 2001, METHODS, V25, P249, DOI 10.1006/meth.2001.1238
   Wang X, 2014, PLOS ONE, V9
   Wilke M, 2008, NEUROIMAGE, V41, P903, DOI 10.1016/j.neuroimage.2008.02.056
   Witt S, 2002, ANN OTO RHINOL LARYN, V111, P349, DOI 10.1177/000348940211100412
   Wong DDE, 2009, IEEE T BIO-MED ENG, V56, P2851, DOI 10.1109/TBME.2009.2029239
   Yang M, 2014, HEARING RES, V316, P37, DOI 10.1016/j.heares.2014.07.006
   Zirn S, 2015, HEARING RES, V328, P148, DOI 10.1016/j.heares.2015.08.010
NR 64
TC 10
Z9 12
U1 0
U2 5
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 2213-1582
J9 NEUROIMAGE-CLIN
JI NeuroImage-Clin.
PY 2018
VL 17
BP 415
EP 425
DI 10.1016/j.nicl.2017.10.036
PG 11
WC Neuroimaging
SC Neurosciences & Neurology
GA FX6GA
UT WOS:000426180300045
PM 29159054
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cai, T
   McPherson, B
   Li, CW
   Yang, F
AF Cai, Ting
   McPherson, Bradley
   Li, Caiwei
   Yang, Feng
TI Pure tone hearing profiles in children with otitis media with effusion
SO DISABILITY AND REHABILITATION
LA English
DT Article
DE Cluster analysis; conductive; middle ear; pure tone audiometry; speech
   perception
ID MIDDLE-EAR; MASKING; NOISE; PREVALENCE; AGE
AB Introduction: Otitis media with effusion (OME) is a common middle ear disease in children. The associated conductive hearing loss is a major concern for hearing health professionals. The aim of the present study was to describe the configuration of pure tone audiograms of children with OME and to design a statistical stratification algorithm to facilitate hearing loss profiling in children with OME.
   Methods: School age children with OME were recruited. Bone and air conduction thresholds were obtained using standard procedures. Hierarchical cluster analysis was employed to determine audiometric profile groups. The Mandarin Hearing in Noise Test was used to measure sentence perception in children for cluster analysis validity assessment.
   Results: Ninety-seven children (164 ears) aged between 72 months and 153 months were examined. Air conduction thresholds averaged for 500 Hz, 1000 Hz and 2000 Hz were in the range of 8.3-53.3 dB HL with a mean of 26.8 dB HL. Bone conduction thresholds were found to be influenced by middle ear pathology with a maximal elevation at 2000 Hz of 25 dB HL. Four audiometric profiles were identified. Cluster 1 contained 54 ears (32.9%) with normal or near normal hearing, Clusters 2 contained 37 ears (22.6%) with mild hearing loss, Cluster 3 included 48 ears (29.3%) and Cluster 4 included 25 ears (15.2%) with moderate hearing loss. Stability and validity of the four-cluster profiling procedure was examined and established with satisfactory results.
   Conclusions: OME in children is associated with pure tone hearing thresholds ranging from normal to moderate hearing loss. The hierarchical clustering algorithm proved useful as a novel means of profiling hearing loss in children with OME and may assist in identifying affected children at greater risk of auditory disadvantage.
   IMPLICATIONS FOR REHABILITATION
   A hierarchical cluster analysis method can be used to determine audiometric profiles in children with OME.
   This algorithm assists to identify children at greater risk of auditory disadvantage.
   Cluster groups with more elevated pure tone thresholds may be targeted for priority in clinical surveillance and medical/surgical intervention.
C1 [Cai, Ting; McPherson, Bradley] Univ Hong Kong, Div Speech & Hearing Sci, Fac Educ, Hong Kong, Hong Kong, Peoples R China.
   [Li, Caiwei] Shenzhen Childrens Hosp, Dept Otorhinolaryngol, Shenzhen, Peoples R China.
   [Yang, Feng] Shenzhen Childrens Hosp, Dept Speech Therapy, Shenzhen, Peoples R China.
RP Cai, T (corresponding author), Fac Educ, Div Speech & Hearing Sci, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM caiting13579@gmail.com
RI McPherson, Bradley/A-3140-2010
OI McPherson, Bradley/0000-0002-7982-1033
FU University of Hong KongUniversity of Hong Kong [201309176026]; Shenzhen
   Municipal Science and Technology Innovation Committee
   [JCYJ20140416141331555]
FX This study was supported by Small Project Funding (No. 201309176026) and
   Faculty of Education funding from the University of Hong Kong. This
   study was also supported by funding from Shenzhen Municipal Science and
   Technology Innovation Committee [No. JCYJ20140416141331555].
CR Aithal Venkatesh, 1995, Papua New Guinea Medical Journal, V38, P79
   American National Standard Institute, 2008, S3111999 ANSI
   American National Standards Institute, 2007, S3391987 ANSI
   [Anonymous], 1948, ACTA OTO-LARYNGOL, V5, P65
   Arick Daniel S, 2005, Ear Nose Throat J, V84, P567
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Calinski T., 1974, COMMUN STAT, V3, P1, DOI [DOI 10.1080/03610927408827101, 10.1080/03610927408827101]
   CARHART R, 1969, J ACOUST SOC AM, V45, P694, DOI 10.1121/1.1911445
   CARHART R, 1959, J SPEECH HEAR DISORD, V24, P330, DOI 10.1044/jshd.2404.330
   Chen CH, 2003, CLIN OTOLARYNGOL, V28, P442, DOI 10.1046/j.1365-2273.2003.00741.x
   Choi CY, 2005, INT J DISABIL DEV ED, V52, P345, DOI DOI 10.1080/10349120500348714
   FEAGANS L, 1987, J PEDIATR PSYCHOL, V12, P581, DOI 10.1093/jpepsy/12.4.581
   FRIA TJ, 1985, ARCH OTOLARYNGOL, V111, P10
   Goodman A., 1965, AM SPEECH HEAR ASS, V7, P262
   Guo H., 1996, ZHONG GUO HUAN JING, V3, P31
   Haggard MP, 2004, CLIN OTOLARYNGOL, V29, P497
   Hall AJ, 2007, INT J AUDIOL, V46, P355, DOI 10.1080/14992020701331570
   Hughson W, 1944, T AM ACADEMY OPHTH S, V48, P15
   JERGER J, 1970, ARCHIV OTOLARYNGOL, V92, P311
   Jerger J, 1980, OTOLARYNGOLOGY
   Keogh T, 2010, AUDIOL NEURO-OTOL, V15, P27, DOI 10.1159/000218360
   Kokko E, 1974, Acta Otolaryngol Suppl, V327, P1
   Lee CY, 2010, INT J AUDIOL, V49, P628, DOI 10.3109/14992021003796887
   Li J, 2008, ZHONG GUO TING LI YA, V6, P22
   Lou J., 2006, KE JI CHUANG YE YUE, P156
   MANDEL EM, 1989, ARCH OTOLARYNGOL, V115, P1217
   McArdle R., 2015, HDB CLIN AUDIOLOGY 7, P61
   Menyuk P., 1986, OTITIS MEDIA CHILD D, P83
   MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245
   Northern J. L., 2014, HEARING CHILDREN
   Paradise JL, 2000, PEDIATRICS, V105, P1119, DOI 10.1542/peds.105.5.1119
   Pett M.A., 2016, NONPARAMETRIC STAT H
   Pittman AL, 2003, EAR HEARING, V24, P198, DOI 10.1097/01.AUD.0000069226.22983.80
   Roeser R. J., 2013, ROESERS AUDIOLOGY DE
   Rosenfeld RM, 2016, OTOLARYNG HEAD NECK, V154, pS1, DOI 10.1177/0194599815623467
   Sabo Diane L., 2003, Ear and Hearing, V24, P38, DOI 10.1097/01.AUD.0000051988.23117.91
   SHAH N, 1991, J ROY SOC MED, V84, P581
   Silman S, 1994, J Am Acad Audiol, V5, P173
   Smaldino J., 2015, HDB CLIN AUDIOLOGY, P675
   Tong Michael, 2004, Zhonghua Er Bi Yan Hou Ke Za Zhi, V39, P429
   Tos M, 1983, Acta Otorhinolaryngol Belg, V37, P31
   Vaillancourt V, 2008, EAR HEARING, V29, P453, DOI 10.1097/01.aud.0000310792.55221.0c
   Velepic M, 2011, INT J PEDIATR OTORHI, V75, P686, DOI 10.1016/j.ijporl.2011.02.014
   Vernon- Feagans L., 2003, EVIDENCE BASED OTITI, P360
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Wong LLN, 2007, EAR HEARING, V28, p70S, DOI 10.1097/AUD.0b013e31803154d0
   Yamamah G., 2012, Eastern Mediterranean Health Journal, V18, P255
   Yuen KCP, 2002, DISABIL REHABIL, V24, P904, DOI 10.1080/09638280210148602
   [张鹏 ZHANG Peng], 2009, [中华耳科学杂志, Chinese Journal of Otology], V7, P367
   Zhang Q, 2011, ANN OTO RHINOL LARYN, V120, P617, DOI 10.1177/000348941112000911
   ZIELHUIS GA, 1990, CLIN OTOLARYNGOL, V15, P147, DOI 10.1111/j.1365-2273.1990.tb00448.x
   ZIELHUIS GA, 1990, CLIN OTOLARYNGOL, V15, P283, DOI 10.1111/j.1365-2273.1990.tb00787.x
NR 53
TC 7
Z9 7
U1 0
U2 3
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0963-8288
EI 1464-5165
J9 DISABIL REHABIL
JI Disabil. Rehabil.
PY 2018
VL 40
IS 10
BP 1166
EP 1175
DI 10.1080/09638288.2017.1290698
PG 10
WC Rehabilitation
SC Rehabilitation
GA FW9WP
UT WOS:000425689100008
PM 28637148
DA 2021-02-24
ER

PT J
AU Patri, JF
   Perrier, P
   Schwartz, JL
   Diard, J
AF Patri, Jean-Francois
   Perrier, Pascal
   Schwartz, Jean-Luc
   Diard, Julien
TI What drives the perceptual change resulting from speech motor
   adaptation? Evaluation of hypotheses in a Bayesian modeling framework
SO PLOS COMPUTATIONAL BIOLOGY
LA English
DT Article
ID DELAYED AUDITORY-FEEDBACK; SENSORIMOTOR ADAPTATION; SOMATOSENSORY
   FEEDBACK; FORMANT TRAJECTORIES; VERBAL FEEDBACK; INTERNAL-MODELS;
   COMPENSATION; PLASTICITY; CORTEX; PERTURBATIONS
AB Shifts in perceptual boundaries resulting from speech motor learning induced by perturbations of the auditory feedback were taken as evidence for the involvement of motor functions in auditory speech perception. Beyond this general statement, the precise mechanisms underlying this involvement are not yet fully understood. In this paper we propose a quantitative evaluation of some hypotheses concerning the motor and auditory updates that could result from motor learning, in the context of various assumptions about the roles of the auditory and somatosensory pathways in speech perception. This analysis was made possible thanks to the use of a Bayesian model that implements these hypotheses by expressing the relationships between speech production and speech perception in a joint probability distribution. The evaluation focuses on how the hypotheses can (1) predict the location of perceptual boundary shifts once the perturbation has been removed, (2) account for the magnitude of the compensation in presence of the perturbation, and (3) describe the correlation between these two behavioral characteristics. Experimental findings about changes in speech perception following adaptation to auditory feedback perturbations serve as reference. Simulations suggest that they are compatible with a framework in which motor adaptation updates both the auditory-motor internal model and the auditory characterization of the perturbed phoneme, and where perception involves both auditory and somatosensory pathways.
C1 [Patri, Jean-Francois; Perrier, Pascal; Schwartz, Jean-Luc] Univ Grenoble Alpes, CNRS, GIPSA Lab UMR 5216, F-38000 Grenoble, France.
   [Patri, Jean-Francois; Diard, Julien] Univ Grenoble Alpes, CNRS, LPNC UMR 5105, F-38000 Grenoble, France.
RP Patri, JF (corresponding author), Univ Grenoble Alpes, CNRS, GIPSA Lab UMR 5216, F-38000 Grenoble, France.; Patri, JF (corresponding author), Univ Grenoble Alpes, CNRS, LPNC UMR 5105, F-38000 Grenoble, France.
EM jeanfrancoispatri@gmail.com
RI Perrier, Pascal/AAQ-2687-2020
OI Perrier, Pascal/0000-0003-2192-4176; Diard, Julien/0000-0003-0673-477X
FU European Research Council under the European Community's Seventh
   Framework Programme (FP7) [339152]
FX The research leading to these results has received funding from the
   European Research Council under the European Community's Seventh
   Framework Programme (FP7/2007-2013 Grant Agreement no. 339152, "Speech
   Unit(e)s", PI: Jean-Luc-Schwartz). The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR ATAL BS, 1978, J ACOUST SOC AM, V63, P1535, DOI 10.1121/1.381848
   Barnaud ML, 2016, INTERSPEECH, P2080, DOI 10.21437/Interspeech.2016-396
   BARNAUD ML, 2016, 6 JOINT IEEE INT C D, P27
   Barnaud ML, BRAIN LANGU IN PRESS
   Bessiere P., 2013, BAYESIAN PROGRAMMING
   BLUMSTEIN SE, 1981, COGNITION, V10, P25, DOI 10.1016/0010-0277(81)90021-4
   Cai SQ, 2011, J NEUROSCI, V31, P16483, DOI 10.1523/JNEUROSCI.3653-11.2011
   Cai SQ, 2010, J ACOUST SOC AM, V128, P2033, DOI 10.1121/1.3479539
   Caudrelier T, 2016, INTERSPEECH, P2095, DOI 10.21437/Interspeech.2016-262
   Christoffels IK, 2007, HUM BRAIN MAPP, V28, P868, DOI 10.1002/hbm.20315
   Clayards M, 2007, P 16 INT C PHON SCI, P701
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cressman EK, 2009, J NEUROPHYSIOL, V102, P3505, DOI 10.1152/jn.00514.2009
   de Boer B, 2003, ACOUST RES LETT ONL, V4, P129, DOI 10.1121/1.1613311
   Diard J, 2015, BAYESIAN ALGORITHMIC
   Eliades SJ, 2008, NATURE, V453, P1102, DOI 10.1038/nature06910
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Fant G, 1983, FEATURE ANAL SWEDISH, P2
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Fowler C. A., 1986, STATUS REPORT SPEECH, P139
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Fu CHY, 2006, CEREB CORTEX, V16, P969, DOI 10.1093/cercor/bhj039
   Gilet E, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020387
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065
   Hahnloser RHR, 2016, PLOS ONE, P1
   Haith A., 2009, ADV NEURAL INF PROCE, P593
   Hashimoto Y, 2003, HUM BRAIN MAPP, V20, P22, DOI 10.1002/hbm.10119
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J SPEECH LANG HEAR R, V45, P295, DOI 10.1044/1092-4388(2002/023)
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Ito S, 2013, BIOL CYBERN, V107, P653, DOI 10.1007/s00422-013-0565-3
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1
   Katseff S, 2012, LANG SPEECH, V55, P295, DOI 10.1177/0023830911417802
   Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8
   Kleinschmidt D. F., 2011, ACL HLT 2011, P10
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Laurent R, 2017, PSYCHOL REV
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lindau M, 1978, VOWEL FEATURES, P541
   MacDonald EN, 2011, J ACOUST SOC AM, V129, P955, DOI 10.1121/1.3531932
   MacDonald EN, 2010, J ACOUST SOC AM, V127, P1059, DOI 10.1121/1.3278606
   Marr D. Vision, 1982, COMPUTATIONAL INVEST
   Mattar AAG, 2007, J NEUROPHYSIOL, V98, P3321, DOI 10.1152/jn.00576.2007
   Moulin-Frier C, 2012, LANG COGNITIVE PROC, V27, P1240
   Moulin-Frier C, 2015, J PHONETICS, V53, P5, DOI 10.1016/j.wocn.2015.06.001
   Nasir SM, 2008, NAT NEUROSCI, V11, P1217, DOI 10.1038/nn.2193
   Nasir SM, 2009, P NATL ACAD SCI USA, V106, P20470, DOI 10.1073/pnas.0907032106
   Ostry DJ, 2010, J NEUROSCI, V30, P5384, DOI 10.1523/JNEUROSCI.4571-09.2010
   Ostry DJ, 2003, EXP BRAIN RES, V153, P275, DOI 10.1007/s00221-003-1624-0
   Patri JF, 2016, INTERSPEECH, P3588, DOI 10.21437/Interspeech.2016-441
   Patri JF, 2015, BIOL CYBERN, V109, P611, DOI 10.1007/s00422-015-0664-4
   Patri JF, 2016, J E P, V1, P419
   Perkell J. S., 2008, P 8 INT SEM SPEECH P, P29
   Pilon JF, 2007, EXP BRAIN RES, V181, P49, DOI 10.1007/s00221-007-0901-8
   Purcell DW, 2006, J ACOUST SOC AM, V119, P2288, DOI 10.1121/1.2173514
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Robinson FR, 2003, J NEUROPHYSIOL, V90, P1235, DOI 10.1152/jn.00656.2002
   Rochet-Capellan A, 2012, J NEUROPHYSIOL, V107, P1711, DOI 10.1152/jn.00773.2011
   Rochet-Capellan A, 2011, J NEUROSCI, V31, P2657, DOI 10.1523/JNEUROSCI.6020-10.2011
   Sanguineti V, 1998, J ACOUST SOC AM, V103, P1615, DOI 10.1121/1.421296
   SAVARIAUX C, 1995, J ACOUST SOC AM, V98, P2428, DOI 10.1121/1.413277
   Schuerman WL, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00161
   Schuerman WL, 2017, J ACOUST SOC AM, V141, P2693, DOI 10.1121/1.4979791
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Scott SK, 2004, COGNITION, V92, P13, DOI 10.1016/j.cognition.2002.12.002
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Sober SJ, 2012, P NATL ACAD SCI USA, V109, P21099, DOI 10.1073/pnas.1213622109
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   Tourville JA, 2008, NEUROIMAGE, V39, P1429, DOI 10.1016/j.neuroimage.2007.09.054
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Tremblay S, 2008, J NEUROSCI, V28, P2426, DOI 10.1523/JNEUROSCI.4196-07.2008
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Wei KL, 2009, J NEUROPHYSIOL, V101, P655, DOI 10.1152/jn.90545.2008
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2
   YATES AJ, 1965, Q J EXP PSYCHOL, V17, P125, DOI 10.1080/17470216508416421
   Zheng ZZ, 2010, J COGNITIVE NEUROSCI, V22, P1770, DOI 10.1162/jocn.2009.21324
NR 82
TC 8
Z9 8
U1 0
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
EI 1553-7358
J9 PLOS COMPUT BIOL
JI PLoS Comput. Biol.
PD JAN
PY 2018
VL 14
IS 1
AR e1005942
DI 10.1371/journal.pcbi.1005942
PG 38
WC Biochemical Research Methods; Mathematical & Computational Biology
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA FU4TH
UT WOS:000423845000036
PM 29357357
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hearnshaw, S
   Baker, E
   Munro, N
AF Hearnshaw, Stephanie
   Baker, Elise
   Munro, Natalie
TI The speech perception skills of children with and without speech sound
   disorder
SO JOURNAL OF COMMUNICATION DISORDERS
LA English
DT Article
DE Speech sound disorder (SSD); Speech perception; Children; Assessment
ID PHONOLOGICAL AWARENESS SKILLS; AUDITORY-DISCRIMINATION; PHONEMIC
   PERCEPTION; SPEAKING CHILDREN; COVERT CONTRAST; ARTICULATION;
   IDENTIFICATION; ERRORS; PRESCHOOLERS; CONSISTENCY
AB Purpose: To investigate whether Australian-English speaking children with and without speech sound disorder (SSD) differ in their overall speech perception accuracy. Additionally, to investigate differences in the perception of specific phonemes and the association between speech perception and speech production skills.
   Method. Twenty-five Australian-English speaking children aged 48-60 months participated in this study. The SSD group included 12 children and the typically developing (TD) group included 13 children. Children completed routine speech and language assessments in addition to an experimental Australian-English lexical and phonetic judgement task based on Rvachew's Speech Assessment and Interactive Learning System (SAILS) program (Rvachew, 2009). This task included eight words across four word-initial phonemes-/k, (sic), integral, s/.
   Results: Children with SSD showed significantly poorer perceptual accuracy on the lexical and phonetic judgement task compared with TD peers. The phonemes /(sic)/ and /s/ were most frequently perceived in error across both groups. Additionally, the phoneme /(sic)/ was most commonly produced in error. There was also a positive correlation between overall speech perception and speech production scores.
   Conclusions: Children with SSD perceived speech less accurately than their typically developing peers. The findings suggest that an Australian-English variation of a lexical and phonetic judgement task similar to the SAILS program is promising and worthy of a larger scale study.
C1 [Hearnshaw, Stephanie; Baker, Elise; Munro, Natalie] Univ Sydney, 75 East St, Lidcombe, NSW 2141, Australia.
RP Hearnshaw, S (corresponding author), Univ Sydney, Discipline Speech Pathol, Fac Hlth Sci, POB 170, Lidcombe, NSW 1825, Australia.
EM sfor6076@uni.sydney.edu.au; elise.baker@sydney.edu.au;
   natalie.munro@sydney.edu.au
RI Baker, Elise/J-6162-2017; Munro, Natalie/J-6163-2017
OI Hearnshaw, Stephanie/0000-0002-7786-075X; Munro,
   Natalie/0000-0002-5870-6378
CR [Anonymous], 2012, MULT CHILDR SPEECH S
   AUNGST LF, 1964, J SPEECH HEAR DISORD, V29, P76, DOI 10.1044/jshd.2901.76
   BROEN PA, 1983, J SPEECH HEAR RES, V26, P601, DOI 10.1044/jshr.2604.601
   Bunnell H. T., 2007, INTERSPEECH 2007
   Byun TM, 2016, CLIN LINGUIST PHONET, V30, P249, DOI 10.3109/02699206.2015.1056884
   Byun TM, 2015, SEMIN SPEECH LANG, V36, P215, DOI 10.1055/s-0035-1562904
   Byun TM, 2012, CLIN LINGUIST PHONET, V26, P397, DOI 10.3109/02699206.2011.641060
   Cabbage KL, 2016, SPEECH COMMUN, V82, P14, DOI 10.1016/j.specom.2016.05.002
   Cabbage KL, 2015, SEMIN SPEECH LANG, V36, P234, DOI 10.1055/s-0035-1562907
   CHANEY C, 1988, J SPEECH HEAR DISORD, V53, P252, DOI 10.1044/jshd.5303.252
   Conant LL, 2014, NEUROIMAGE, V89, P192, DOI 10.1016/j.neuroimage.2013.11.055
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   DAVIS CS, 1991, STAT MED, V10, P1959, DOI 10.1002/sim.4780101210
   Dodd B, 2003, CLIN LINGUIST PHONET, V17, P617, DOI 10.1080/0269920031000111348
   Dodd B., 2002, DIAGNOSTIC EVALUATIO
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Edwards J, 2002, J SPEECH LANG HEAR R, V45, P231, DOI 10.1044/1092-4388(2002/018)
   Edwards J, 1999, J SPEECH LANG HEAR R, V42, P169, DOI 10.1044/jslhr.4201.169
   Edwards J, 1997, LANG SPEECH, V40, P203, DOI 10.1177/002383099704000204
   Elbert M, 1986, HANDBOOK OF CLINICAL
   Flipsen P, 2001, CLIN LINGUIST PHONET, V15, P603
   Gibbon FE, 2017, CLIN LINGUIST PHONET, V31, P4, DOI 10.1080/02699206.2016.1174739
   HOFFMAN PR, 1988, CLIN LINGUIST PHONET, V2, P17, DOI 10.3109/02699208808985241
   HOFFMAN PR, 1983, J SPEECH HEAR DISORD, V48, P210, DOI 10.1044/jshd.4802.210
   HOFFMAN PR, 1985, J SPEECH HEAR DISORD, V50, P46, DOI 10.1044/jshd.5001.46
   IBM, 2014, IBM SPSS STAT 22 SOF
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Kronvall EL, 1954, J SPEECH HEAR DISORD, V19, P335, DOI 10.1044/jshd.1903.335
   Leiden University. (n. d. ), STAT METH CTR M AN C
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LOCKE JL, 1980, J SPEECH HEAR DISORD, V45, P431, DOI 10.1044/jshd.4504.431
   LOCKE JL, 1980, J SPEECH HEAR DISORD, V45, P445, DOI 10.1044/jshd.4504.445
   MANN VA, 1985, J EXP CHILD PSYCHOL, V39, P252, DOI 10.1016/0022-0965(85)90040-2
   Martin N.A., 2011, EXPRESSIVE ONE WORD
   Mcleod S, 2014, CLIN LINGUIST PHONET, V28, P508, DOI 10.3109/02699206.2014.926994
   McLeod S, 2009, J SPEECH LANG HEAR R, V52, P1213, DOI 10.1044/1092-4388(2009/08-0085)
   McNutt J. C., 1990, J SPEECH LANGUAGE PA, V14, P41
   MCREYNOLDS LV, 1975, J SPEECH HEAR DISORD, V40, P327, DOI 10.1044/jshd.4003.327
   MORGAN RA, 1984, BRIT J DISORD COMMUN, V19, P89
   Munson B, 2005, TOP LANG DISORD, V25, P190, DOI 10.1097/00011363-200507000-00003
   Munson B, 2010, LAB PHONOLOGY, P381, DOI DOI 10.1515/9783110224917
   Munson B, 2010, CLIN LINGUIST PHONET, V24, P245, DOI 10.3109/02699200903532524
   Munzel U, 2002, BIOMETRICAL J, V44, P762, DOI 10.1002/1521-4036(200209)44:6<762::AID-BIMJ762>3.0.CO;2-A
   Nittrouer S, 2002, LANG SPEECH HEAR SER, V33, P237, DOI 10.1044/0161-1461(2002/020)
   OHDE RN, 1988, J SPEECH HEAR RES, V31, P556, DOI 10.1044/jshr.3104.556
   Paullin M., 2013, J ACOUST SOC AM, V133, P3336
   Preston JL, 2015, SEMIN SPEECH LANG, V36, P224, DOI 10.1055/s-0035-1562906
   Psychological Software Tools Inc, 2014, E PRIME
   RAAYMAKERS EMJA, 1988, J SPEECH HEAR DISORD, V53, P262, DOI 10.1044/jshd.5303.262
   Rvachew S, 2006, AM J SPEECH-LANG PAT, V15, P165, DOI 10.1044/1058-0360(2006/016)
   Rvachew S, 2006, J SPEECH LANG HEAR R, V49, P74, DOI 10.1044/1092-4388(2006/006)
   Rvachew S, 2004, AM J SPEECH-LANG PAT, V13, P250, DOI 10.1044/1058-0360(2004/026)
   Rvachew S, 2003, AM J SPEECH-LANG PAT, V12, P463, DOI 10.1044/1058-0360(2003/092)
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   RVACHEW S, 1994, J SPEECH HEAR RES, V37, P347, DOI 10.1044/jshr.3702.347
   Rvachew S., 2014, SAILS BACKGROUNDER
   Rvachew S., 2009, SPEECH ASSESSMENT IN
   Rvachew S, 2007, AM J SPEECH-LANG PAT, V16, P260, DOI 10.1044/1058-0360(2007/030)
   Shiller DM, 2010, CAN J SPEECH-LANG PA, V34, P181
   Shriberg LD, 2010, CLIN LINGUIST PHONET, V24, P795, DOI 10.3109/02699206.2010.503006
   Shuster LI, 1998, J SPEECH LANG HEAR R, V41, P941, DOI 10.1044/jslhr.4104.941
   Strombergsson S, 2014, CLIN LINGUIST PHONET, V28, P373, DOI 10.3109/02699206.2013.868928
   vanRiper C., 1939, SPEECH CORRECTION PR
   WALDMAN FR, 1978, LANG SPEECH, V21, P205
   Walker I, 2008, NULL HYPOTHESIS TEST
   WEINER FF, 1972, PERCEPT MOTOR SKILL, V34, P595, DOI 10.2466/pms.1972.34.2.595
   WOLFE VI, 1973, PERCEPT MOTOR SKILL, V37, P415, DOI 10.2466/pms.1973.37.2.415
NR 67
TC 15
Z9 16
U1 0
U2 10
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0021-9924
EI 1873-7994
J9 J COMMUN DISORD
JI J. Commun. Disord.
PD JAN-FEB
PY 2018
VL 71
BP 61
EP 71
DI 10.1016/j.jcomdis.2017.12.004
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FW3GT
UT WOS:000425195500006
PM 29306068
DA 2021-02-24
ER

PT J
AU Jaekel, BN
   Newman, RS
   Goupell, MJ
AF Jaekel, Brittany N.
   Newman, Rochelle S.
   Goupell, Matthew J.
TI Age effects on perceptual restoration of degraded interrupted sentences
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID COCHLEAR-IMPLANT USERS; NORMAL-HEARING LISTENERS; TOP-DOWN RESTORATION;
   SPEECH RECOGNITION; PHONEMIC RESTORATION; INTERVENING NOISE;
   WORKING-MEMORY; VERBAL FLUENCY; OLDER-ADULTS; BOTTOM-UP
AB Adult cochlear-implant (CI) users show small or non-existent perceptual restoration effects when listening to interrupted speech. Perceptual restoration is believed to be a top-down mechanism that enhances speech perception in adverse listening conditions, and appears to be particularly utilized by older normal-hearing participants. Whether older normal-hearing participants can derive any restoration benefits from degraded speech (as would be presented through a CI speech processor) is the focus of this study. Two groups of normal-hearing participants (younger: age <= 30 yrs; older: age >= 60 yrs) were tested for perceptual restoration effects in the context of interrupted sentences. Speech signal degradations were controlled by manipulating parameters of a noise vocoder and were used to analyze effects of spectral resolution and noise burst spectral content on perceptual restoration. Older normal-hearing participants generally showed larger and more consistent perceptual restoration benefits for vocoded speech than did younger normal-hearing participants, even in the lowest spectral resolution conditions. Reduced restoration in CI users thus may be caused by factors like noise reduction strategies or small dynamic ranges rather than an interaction of aging effects and low spectral resolution. (C) 2018 Acoustical Society of America.
C1 [Jaekel, Brittany N.; Newman, Rochelle S.; Goupell, Matthew J.] Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.
RP Jaekel, BN (corresponding author), Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.
EM jaekel@umd.edu
RI Goupell, Matthew/ABF-2342-2020; Newman, Rochelle/AAA-3185-2019
OI Goupell, Matthew/0000-0003-2662-3057; Newman,
   Rochelle/0000-0002-1626-4241; Jaekel, Brittany/0000-0001-6118-530X
FU National Institute on Aging of the National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Aging (NIA) [R01AG051603];
   National Institute of Deafness and Communicative Disorders of the
   National Institutes of Health [T32DC00046]; NATIONAL INSTITUTE ON
   AGINGUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)
   [R01AG051603, R01AG051603, R01AG051603, R01AG051603, R01AG051603,
   R01AG051603] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [T32DC000046, T32DC000046, T32DC000046, T32DC000046, T32DC000046,
   T32DC000046, T32DC000046, T32DC000046, T32DC000046, T32DC000046,
   T32DC000046, T32DC000046, T32DC000046, T32DC000046, T32DC000046,
   T32DC000046, T32DC000046, T32DC000046, T32DC000046, T32DC000046,
   T32DC000046, T32DC000046, T32DC000046, T32DC000046, T32DC000046,
   T32DC000046, T32DC000046, T32DC000046, T32DC000046] Funding Source: NIH
   RePORTER
FX Thank you to Kelly Miller, Stefanie Kuchinsky, Hannah Cohen, Stephen
   Fong, Hannah Johnson, Emily Waddington, Tracy Wilkinson, and Lauren
   Wilson for their assistance with data collection and analysis. Research
   reported in this publication was supported by the National Institute on
   Aging of the National Institutes of Health under Award No. R01AG051603.
   The content is solely the responsibility of the authors and does not
   necessarily represent the official views of the National Institutes of
   Health. This work was also supported by training Grant No. T32DC00046
   from the National Institute of Deafness and Communicative Disorders of
   the National Institutes of Health. Portions of this work were presented
   at the 40th MidWinter Meeting of the Association for Research in
   Otolaryngology and the 2017 Aging and Speech Communication Conference.
CR Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   BASHFORD JA, 1992, PERCEPT PSYCHOPHYS, V51, P211, DOI 10.3758/BF03212247
   Baskent D, 2012, JARO-J ASSOC RES OTO, V13, P683, DOI 10.1007/s10162-012-0334-3
   Benard MR, 2014, J ACOUST SOC AM, V135, pEL88, DOI 10.1121/1.4862879
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bhargava P, 2014, HEARING RES, V309, P113, DOI 10.1016/j.heares.2013.12.003
   Clarke J, 2016, J ACOUST SOC AM, V139, P395, DOI 10.1121/1.4939962
   CRYSTAL TH, 1990, J ACOUST SOC AM, V88, P101, DOI 10.1121/1.399955
   Drag LL, 2010, J GERIATR PSYCH NEUR, V23, P75, DOI 10.1177/0891988709358590
   Fetterman BL, 2002, OTOLARYNG HEAD NECK, V126, P257, DOI 10.1067/mhn.2002.123044
   Fitzgibbons P J, 1996, J Am Acad Audiol, V7, P183
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Glinberg and Associates Inc., 2016, NIH TOOLB VERS 1 7 M
   Gnansia D, 2010, HEARING RES, V265, P46, DOI 10.1016/j.heares.2010.02.012
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   Goupell MJ, 2017, EAR HEARING, V38, pE335, DOI 10.1097/AUD.0000000000000447
   Harrison JE, 2000, BRIT J CLIN PSYCHOL, V39, P181, DOI 10.1348/014466500163202
   Hox J. J., 2017, MULTILEVEL ANAL TECH
   Levelt WJM, 2001, P NATL ACAD SCI USA, V98, P13464, DOI 10.1073/pnas.231459498
   Litovsky RY, 2012, J AM ACAD AUDIOL, V23, P476, DOI 10.3766/jaaa.23.6.9
   Loebach JL, 2008, J ACOUST SOC AM, V123, P1126, DOI 10.1121/1.2823453
   Mauger SJ, 2012, J ACOUST SOC AM, V131, P327, DOI 10.1121/1.3665990
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nelson PB, 2004, J ACOUST SOC AM, V115, P2286, DOI 10.1121/1.1703538
   Park DC, 2002, PSYCHOL AGING, V17, P299, DOI 10.1037//0882-7974.17.2.299
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   POWERS GL, 1977, J ACOUST SOC AM, V61, P195, DOI 10.1121/1.381255
   Saija JD, 2014, JARO-J ASSOC RES OTO, V15, P139, DOI 10.1007/s10162-013-0422-z
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Schneider BA, 2010, SPRINGER HANDB AUDIT, V34, P167, DOI 10.1007/978-1-4419-0993-0_7
   Schoof T, 2015, J ACOUST SOC AM, V138, pEL181, DOI 10.1121/1.4929627
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sheldon S, 2008, J ACOUST SOC AM, V123, P489, DOI 10.1121/1.2783762
   Sladen DP, 2015, AM J AUDIOL, V24, P31, DOI 10.1044/2014_AJA-13-0066
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tombaugh TN, 1999, ARCH CLIN NEUROPSYCH, V14, P167, DOI 10.1016/S0887-6177(97)00095-4
   Tulsky DS, 2014, J INT NEUROPSYCH SOC, V20, P599, DOI 10.1017/S135561771400040X
   VERSCHUURE J, 1983, PERCEPT PSYCHOPHYS, V33, P232, DOI 10.3758/BF03202859
   Versfeld NJ, 2000, J ACOUST SOC AM, V107, P1671, DOI 10.1121/1.428451
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Whitmal NA, 2007, J ACOUST SOC AM, V122, P2376, DOI 10.1121/1.2773993
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
   Zarino B, 2014, NEUROL SCI, V35, P1405, DOI 10.1007/s10072-014-1729-1
NR 50
TC 3
Z9 3
U1 1
U2 5
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2018
VL 143
IS 1
BP 84
EP 97
DI 10.1121/1.5016968
PG 14
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FU7EL
UT WOS:000424014800018
PM 29390768
OA Green Published
DA 2021-02-24
ER

PT J
AU Park, KH
   Chung, WH
   Kwon, H
   Lee, JM
AF Park, Kye Hoon
   Chung, Won-Ho
   Kwon, Hunki
   Lee, Jong-Min
TI Evaluation of Cerebral White Matter in Prelingually Deaf Children Using
   Diffusion Tensor Imaging
SO BIOMED RESEARCH INTERNATIONAL
LA English
DT Article
ID COCHLEAR IMPLANTS; SPATIAL STATISTICS; SPEECH-PERCEPTION; CELL-DEATH;
   DEPRIVATION; ADOLESCENTS; CHILDHOOD; NEURONS; CORTEX; PERIOD
AB This study compared white matter development in prelingually deaf and normal-hearing children using a tract-based spatial statistics (TBSS) method. Diffusion tensor imaging (DTI) was performed in 21 prelingually deaf (DEAF group) and 20 normal-hearing (HEAR group) subjects aged from 1.7 to 7.7 years. Using TBSS, we evaluated the regions of significant difference in fractional anisotropy (FA) between the groups. Correlations between FA values and age in each group were also analyzed using voxel-wise correlation analyses on the TBSS skeleton. Lower FA values of the white matter tract of Heschl's gyrus, the inferior frontooccipital fasciculus, the uncinate fasciculus, the superior longitudinal fasciculus, and the forceps major were evident in the DEAF group compared with those in the HEAR group below 4 years of age, while the difference was not significant in older subjects. We also found that age-related development of the white matter tracts may continue until 8 years of age in deaf children. These results imply that development of the cerebral white matter tracts is delayed in prelingually deaf children.
C1 [Park, Kye Hoon] Soonchunhyang Univ, Coll Med, Dept Otorhinolaryngol Head & Neck Surg, Cheonan, South Korea.
   [Chung, Won-Ho] Sungkyunkwan Univ, Samsung Med Ctr, Sch Med, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
   [Kwon, Hunki] Yale Univ, Sch Med, Dept Neurol, New Haven, CT 06510 USA.
   [Lee, Jong-Min] Hanyang Univ, Dept Biomed Engn, Seoul, South Korea.
RP Chung, WH (corresponding author), Sungkyunkwan Univ, Samsung Med Ctr, Sch Med, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
EM whchung@skku.edu
FU Samsung Medical Center Clinical Research Development Program (CRDP)
   [CRS106-19-1]; Soonchunhyang University Research Fund
FX This study was supported by the Samsung Medical Center Clinical Research
   Development Program (CRDP) (Grant no. CRS106-19-1) and the Soonchunhyang
   University Research Fund.
CR Baldi A, 2000, EUR J NEUROSCI, V12, P2281, DOI 10.1046/j.1460-9568.2000.00119.x
   Ball G, 2010, NEUROIMAGE, V53, P94, DOI 10.1016/j.neuroimage.2010.05.055
   Berardi N, 2000, CURR OPIN NEUROBIOL, V10, P138, DOI 10.1016/S0959-4388(99)00047-1
   Campbell R, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00834
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Gordon KA, 2011, BRAIN TOPOGR, V24, P204, DOI 10.1007/s10548-011-0181-2
   Govaerts PJ, 2002, OTOL NEUROTOL, V23, P885, DOI 10.1097/00129492-200211000-00013
   Hermoye L, 2006, NEUROIMAGE, V29, P493, DOI 10.1016/j.neuroimage.2005.08.017
   Kammer T, 1997, MAGN RESON IMAGING, V15, P879, DOI 10.1016/S0730-725X(97)00021-0
   Kim DJ, 2009, NEUROREPORT, V20, P1032, DOI 10.1097/WNR.0b013e32832e0cdd
   Kral A, 2005, CEREB CORTEX, V15, P552, DOI 10.1093/cercor/bhh156
   Kral A, 2010, NEW ENGL J MED, V363, P1438, DOI 10.1056/NEJMra0911225
   Le Bihan D, 2001, J MAGN RESON IMAGING, V13, P534, DOI 10.1002/jmri.1076
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee HJ, 2005, HEARING RES, V203, P2, DOI 10.1016/j.heares.2004.11.005
   Li JH, 2012, BRAIN RES, V1430, P35, DOI 10.1016/j.brainres.2011.09.057
   Li YY, 2012, HUM BRAIN MAPP, V33, P349, DOI 10.1002/hbm.21215
   Melhem ER, 2002, AM J ROENTGENOL, V178, P3, DOI 10.2214/ajr.178.1.1780003
   Miao W, 2013, AM J NEURORADIOL, V34, P1264, DOI 10.3174/ajnr.A3370
   Mostafapour SP, 2002, J NEUROSCI, V22, P4670, DOI 10.1523/JNEUROSCI.22-11-04670.2002
   Nadol JB, 2001, ANN OTO RHINOL LARYN, V110, P883, DOI 10.1177/000348940111000914
   Nicholas JG, 2013, OTOL NEUROTOL, V34, P532, DOI 10.1097/MAO.0b013e318281e215
   Nishimura H, 1999, NATURE, V397, P116, DOI 10.1038/16376
   O'Donoghue GM, 2000, LANCET, V356, P466, DOI 10.1016/S0140-6736(00)02555-1
   Oh SH, 2003, ACTA OTO-LARYNGOL, V123, P148, DOI 10.1080/0036554021000028111
   Sherrard RM, 1998, CLIN EXP PHARMACOL P, V25, P487, DOI 10.1111/j.1440-1681.1998.tb02241.x
   Smith SM, 2006, NEUROIMAGE, V31, P1487, DOI 10.1016/j.neuroimage.2006.02.024
   Smith SM, 2009, NEUROIMAGE, V44, P83, DOI 10.1016/j.neuroimage.2008.03.061
   Striem-Amit E., SCI REPORTS, V6
NR 29
TC 4
Z9 4
U1 0
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2314-6133
EI 2314-6141
J9 BIOMED RES INT
JI Biomed Res. Int.
PY 2018
VL 2018
AR 6795397
DI 10.1155/2018/6795397
PG 7
WC Biotechnology & Applied Microbiology; Medicine, Research & Experimental
SC Biotechnology & Applied Microbiology; Research & Experimental Medicine
GA FU8LI
UT WOS:000424104100001
PM 29511689
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Schepman, A
   Rodway, P
   Cornmell, L
   Smith, B
   de Sa, SL
   Borwick, C
   Belfon-Thompson, E
AF Schepman, Astrid
   Rodway, Paul
   Cornmell, Louise
   Smith, Bethany
   de Sa, Sabrina Lauren
   Borwick, Ciara
   Belfon-Thompson, Elisha
TI Right-ear precedence and vocal emotion contagion: The role of the left
   hemisphere
SO LATERALITY
LA English
DT Article
DE Echo suppression; precedence effect; auditory lead-lag; interaural time
   difference; social affect
ID SPEECH-PERCEPTION; NEURAL SYSTEMS; INFERIOR COLLICULUS; FACIAL
   EXPRESSIONS; BRAIN ASYMMETRY; PREMOTOR CORTEX; MIRROR NEURONS; MOTOR
   THEORY; VALENCE; PROSODY
AB Much evidence suggests that the processing of emotions is lateralized to the right hemisphere of the brain. However, under some circumstances the left hemisphere might play a role, particularly for positive emotions and emotional experiences. We explored whether emotion contagion was right-lateralized, lateralized valence-specifically, or potentially left-lateralized. In two experiments, right-handed female listeners rated to what extent emotionally intoned pseudo-sentences evoked target emotions in them. These sound stimuli had a 7ms ear lead in the left or right channel, leading to stronger stimulation of the contralateral hemisphere. In both experiments, the results revealed that right ear lead stimuli received subtly but significantly higher evocation scores, suggesting a left hemisphere dominance for emotion contagion. A control experiment using an emotion identification task showed no effect of ear lead. The findings are discussed in relation to prior findings that have linked the processing of emotional prosody to left-hemisphere brain regions that regulate emotions, control orofacial musculature, are involved in affective empathy processing areas, or have an affinity for processing emotions socially. Future work is needed to eliminate alternative interpretations and understand the mechanisms involved. Our novel binaural asynchrony method may be useful in future work in auditory laterality.
C1 [Schepman, Astrid; Rodway, Paul; Cornmell, Louise; Smith, Bethany; de Sa, Sabrina Lauren; Borwick, Ciara; Belfon-Thompson, Elisha] Univ Chester, Dept Psychol, Chester, Cheshire, England.
RP Schepman, A (corresponding author), Univ Chester, Dept Psychol, Chester, Cheshire, England.
EM a.schepman@chester.ac.uk
OI Schepman, Astrid/0000-0002-7407-362X
FU University of Chester
FX The work was supported in part by two University of Chester internal
   research grants awarded to the first two authors.
CR Adolphs R, 2002, EMOTION, V2, P23, DOI 10.1037/1528-3542.2.1.23
   ALEXANDER MP, 1990, NEUROLOGY, V40, P353, DOI 10.1212/WNL.40.2.353
   Aucouturier JJ, 2016, P NATL ACAD SCI USA, V113, P948, DOI 10.1073/pnas.1506552113
   Aziz-Zadeh L, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008759
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Blauert J., 2005, FORUM ACOUSTICUM
   Borod JC, 1993, NEUROPSYCHOLOGY, V7, P445, DOI DOI 10.1037/0894-4105.7.4.445
   BOROD JC, 2001, HDB NEUROPSYCHOLOGY, V5, P181
   Brancucci A, 2004, EUR J NEUROSCI, V19, P2329, DOI 10.1111/j.0953-816X.2004.03302.x
   Brennand R, 2011, RES AUTISM SPECT DIS, V5, P1567, DOI 10.1016/j.rasd.2011.03.002
   Brown AD, 2015, JARO-J ASSOC RES OTO, V16, P1, DOI 10.1007/s10162-014-0496-2
   BRYDEN MP, 1982, NEUROPSYCHOLOGIA, V20, P83, DOI 10.1016/0028-3932(82)90089-6
   Cranford J L, 1992, J Am Acad Audiol, V3, P405
   Damaschke J, 2005, HEARING RES, V205, P157, DOI 10.1016/j.heares.2005.03.014
   Davidson R. J., 1984, EMOTIONS COGNITION B, P320
   Davidson RJ, 2004, BIOL PSYCHOL, V67, P219, DOI 10.1016/j.biopsycho.2004.03.008
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Fitzpatrick DC, 1999, J ACOUST SOC AM, V106, P3460, DOI 10.1121/1.428199
   FREEDMAN M, 1984, NEUROLOGY, V34, P409, DOI 10.1212/WNL.34.4.409
   Gainotti G, 2012, NEUROPSYCHOLOGIA, V50, P205, DOI 10.1016/j.neuropsychologia.2011.12.005
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Godfrey HK, 2016, LATERALITY, V21, P568, DOI 10.1080/1357650X.2015.1096940
   Harmon-Jones E, 2004, BIOL PSYCHOL, V67, P51, DOI 10.1016/j.biopsycho.2004.03.003
   HATFIELD E, 1992, EMOTION SOCIAL BEHAV, V14, P151
   Hatfield Elaine, 1994, EMOTIONAL CONTAGION
   Hecht D, 2010, NEUROSCI RES, V68, P77, DOI 10.1016/j.neures.2010.06.013
   Heyes C, 2010, NEUROSCI BIOBEHAV R, V34, P575, DOI 10.1016/j.neubiorev.2009.11.007
   Hickok G, 2010, LANG COGNITIVE PROC, V25, P749, DOI 10.1080/01690961003595572
   HUGDAHL K, 1993, CORTEX, V29, P325, DOI 10.1016/S0010-9452(13)80185-2
   Hugdahl K, 2000, REV ESP NEUROPSICOL, V2, P62
   Iacoboni M, 2008, J PHYSIOL-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003
   Jansari A, 2000, COGNITION EMOTION, V14, P341, DOI 10.1080/026999300378860
   Jansari A, 2011, BRAIN COGNITION, V76, P415, DOI 10.1016/j.bandc.2011.03.009
   JONES NA, 1992, BRAIN COGNITION, V20, P280, DOI 10.1016/0278-2626(92)90021-D
   Killgore WDS, 2007, SOC COGN AFFECT NEUR, V2, P240, DOI 10.1093/scan/nsm020
   Ley R G, 1982, Brain Cogn, V1, P3, DOI 10.1016/0278-2626(82)90002-1
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Litovsky RY, 1999, J ACOUST SOC AM, V106, P1633, DOI 10.1121/1.427914
   Litovsky RY, 1998, J NEUROPHYSIOL, V80, P1285
   Litovsky RY, 2002, HEARING RES, V165, P177, DOI 10.1016/S0378-5955(02)00304-0
   Lotto AJ, 2009, TRENDS COGN SCI, V13, P110, DOI 10.1016/j.tics.2008.11.008
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mitchell RLC, 2003, NEUROPSYCHOLOGIA, V41, P1410, DOI 10.1016/S0028-3932(03)00017-4
   Mukamel R, 2010, CURR BIOL, V20, P750, DOI 10.1016/j.cub.2010.02.045
   Najt P, 2013, EMOTION, V13, P159, DOI 10.1037/a0029723
   NAKASATO N, 1995, ELECTROEN CLIN NEURO, V94, P183, DOI 10.1016/0013-4694(94)00280-X
   Neumann R, 2000, J PERS SOC PSYCHOL, V79, P211, DOI 10.1037//0022-3514.79.2.211
   Nummenmaa L, 2008, NEUROIMAGE, V43, P571, DOI 10.1016/j.neuroimage.2008.08.014
   Ochsner KN, 2004, J COGNITIVE NEUROSCI, V16, P1746, DOI 10.1162/0898929042947829
   Pantev C, 1998, AUDIOL NEURO-OTOL, V3, P183, DOI 10.1159/000013789
   Papousek I, 2014, BIOL PSYCHOL, V103, P184, DOI 10.1016/j.biopsycho.2014.09.001
   Papousek I, 2012, PSYCHOPHYSIOLOGY, V49, P489, DOI 10.1111/j.1469-8986.2011.01324.x
   Prete G, 2015, NEUROPSYCHOLOGIA, V68, P94, DOI 10.1016/j.neuropsychologia.2015.01.002
   Rodway P, 2003, BRAIN COGNITION, V53, P452, DOI 10.1016/S0278-2626(03)00217-3
   Rodway P, 2007, BRAIN COGNITION, V63, P31, DOI 10.1016/j.bandc.2006.07.008
   Ross E, 1994, COGN BEHAV NEUROL, V7, P1
   Sauter DA, 2010, J COGNITIVE NEUROSCI, V22, P474, DOI 10.1162/jocn.2009.21215
   Schepman A, 2016, LATERALITY, V21, P606, DOI 10.1080/1357650X.2015.1105245
   Schepman A, 2012, BRAIN COGNITION, V79, P129, DOI 10.1016/j.bandc.2012.03.001
   Schwartz O, 1999, NEURAL NETWORKS, V12, P409, DOI 10.1016/S0893-6080(98)00027-6
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Sestito M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00368
   Shamay-Tsoory SG, 2008, BRAIN COGNITION, V67, P280, DOI 10.1016/j.bandc.2008.02.001
   Shamay-Tsoory SG, 2009, BRAIN, V132, P617, DOI 10.1093/brain/awn279
   SHOBE ER, 2014, FRONTIERS IN HUMAN N, V8, P372
   TOMARKEN AJ, 1992, J PERS SOC PSYCHOL, V62, P676, DOI 10.1037/0022-3514.62.4.676
   Trahiotis C, 2002, HEARING RES, V168, P55, DOI 10.1016/S0378-5955(02)00357-X
   Wild B, 2001, PSYCHIAT RES, V102, P109, DOI 10.1016/S0165-1781(01)00225-6
   Wildgruber D, 2005, NEUROIMAGE, V24, P1233, DOI 10.1016/j.neuroimage.2004.10.034
   Wildgruber D, 2002, NEUROIMAGE, V15, P856, DOI 10.1006/nimg.2001.0998
   Woolley JD, 2003, ANN NY ACAD SCI, V1000, P395, DOI 10.1196/annals.1280.039
   Yang XF, 1997, PERCEPT PSYCHOPHYS, V59, P1108, DOI 10.3758/BF03205525
   Zurek P.M., 1987, DIRECTIONAL HEARING, P85, DOI DOI 10.1007/978-1-4612-4738-8_4
NR 75
TC 0
Z9 0
U1 1
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1357-650X
EI 1464-0678
J9 LATERALITY
JI Laterality
PY 2018
VL 23
IS 3
BP 290
EP 317
DI 10.1080/1357650X.2017.1360902
PG 28
WC Psychology, Multidisciplinary; Psychology, Experimental
SC Psychology
GA FU2OO
UT WOS:000423689800003
PM 28764593
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Patro, C
   Mendel, LL
AF Patro, Chhayakanta
   Mendel, Lisa Lucks
TI Gated Word Recognition by Postlingually Deafened Adults With Cochlear
   Implants: Influence of Semantic Context
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID NORMAL-HEARING LISTENERS; INTERRUPTED SPEECH; GATING PARADIGM; CONSONANT
   RECOGNITION; SPECTRAL RESOLUTION; SIGNAL PROCESSORS; ACOUSTIC HEARING;
   SENTENCE CONTEXT; FINE-STRUCTURE; TEMPORAL CUES
AB Purpose: The main goal of this study was to investigate the minimum amount of sensory information required to recognize spoken words (isolation points [IPs]) in listeners with cochlear implants (CIs) and investigate facilitative effects of semantic contexts on the IPs.
   Method: Listeners with CIs as well as those with normal hearing (NH) participated in the study. In Experiment 1, the CI users listened to unprocessed (full-spectrum) stimuli and individuals with NH listened to full-spectrum or vocoder processed speech. IPs were determined for both groups who listened to gated consonant-nucleus-consonant words that were selected based on lexical properties. In Experiment 2, the role of semantic context on IPs was evaluated. Target stimuli were chosen from the Revised Speech Perception in Noise corpus based on the lexical properties of the final words.
   Results: The results indicated that spectrotemporal degradations impacted IPs for gated words adversely, and CI users as well as participants with NH listening to vocoded speech had longer IPs than participants with NH who listened to full-spectrum speech. In addition, there was a clear disadvantage due to lack of semantic context in all groups regardless of the spectral composition of the target speech (full spectrum or vocoded). Finally, we showed that CI users (and users with NH with vocoded speech) can overcome such word processing difficulties with the help of semantic context and perform as well as listeners with NH.
   Conclusion: Word recognition occurs even before the entire word is heard because listeners with NH associate an acoustic input with its mental representation to understand speech. The results of this study provide insight into the role of spectral degradation on the processing of spoken words in isolation and the potential benefits of semantic context. These results may also explain why CI users rely substantially on semantic context.
C1 [Patro, Chhayakanta] Heuser Hearing Inst, Louisville, KY 40222 USA.
   [Mendel, Lisa Lucks] Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.
RP Patro, C (corresponding author), Heuser Hearing Inst, Louisville, KY 40222 USA.
EM chhayakantpatro@gmail.com
FU U.S. National Science Foundation under CISE Grant [1231620]
FX This research was supported in part by the U.S. National Science
   Foundation under CISE Grant 1231620, awarded to Lisa Lucks Mendel. The
   authors thank Jerker Ronnberg and Shahram Moradi for their help during
   stimulus preparation and the subjects for their participation in the
   study.
CR Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Baskent D, 2006, J ACOUST SOC AM, V119, P1156, DOI 10.1121/1.2151825
   Baskent D, 2007, EAR HEARING, V28, P277
   Baskent D, 2012, JARO-J ASSOC RES OTO, V13, P683, DOI 10.1007/s10162-012-0334-3
   Baskent D, 2010, HEARING RES, V270, P127, DOI 10.1016/j.heares.2010.08.011
   Baskent D, 2009, J ACOUST SOC AM, V125, P3995, DOI 10.1121/1.3125329
   Benard MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058149
   Bhargava P, 2014, HEARING RES, V309, P113, DOI 10.1016/j.heares.2013.12.003
   Bhargava P, 2012, J ACOUST SOC AM, V131, pEL87, DOI 10.1121/1.3670000
   Bierer JA, 2011, EAR HEARING, V32, P436, DOI 10.1097/AUD.0b013e3181ff33ab
   Bilger RC., 1984, ASHA REPORTS, V14, P2
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Brown-Schmidt S., 2005, APPROACHES STUDYING, P153
   Chatterjee M, 1998, J ACOUST SOC AM, V103, P2565, DOI 10.1121/1.422777
   Chatterjee M, 2010, J ACOUST SOC AM, V127, pEL37, DOI 10.1121/1.3284544
   Ching T Y C, 2007, Trends Amplif, V11, P161, DOI 10.1177/1084713807304357
   Collison EA, 2004, J SPEECH LANG HEAR R, V47, P496, DOI 10.1044/1092-4388(2004/039)
   COTTON S, 1984, PERCEPT PSYCHOPHYS, V35, P41, DOI 10.3758/BF03205923
   CRAIG CH, 1990, J SPEECH HEAR RES, V33, P808, DOI 10.1044/jshr.3304.808
   Dirks DD, 2001, EAR HEARING, V22, P1, DOI 10.1097/00003446-200102000-00001
   Dorman MF, 2003, EAR HEARING, V24, P457, DOI 10.1097/01.AUD.0000090438.20404.D9
   DORMAN MF, 1991, Q J EXP PSYCHOL-A, V43, P585, DOI 10.1080/14640749108400988
   Dorman MF, 1998, J ACOUST SOC AM, V104, P3583, DOI 10.1121/1.423940
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603
   Dorman MF, 1998, EAR HEARING, V19, P162, DOI 10.1097/00003446-199804000-00008
   Dubno JR, 2000, J ACOUST SOC AM, V107, P538, DOI 10.1121/1.428322
   ELLIOTT LL, 1987, PERCEPT PSYCHOPHYS, V42, P150, DOI 10.3758/BF03210503
   Eskridge EN, 2012, J SPEECH LANG HEAR R, V55, P800, DOI 10.1044/1092-4388(2011/11-0124)
   Firszt JB, 2008, J REHABIL RES DEV, V45, P749, DOI 10.1682/JRRD.2007.08.0120
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P19, DOI 10.1007/s10162-004-5024-3
   Fu QJ, 1998, J ACOUST SOC AM, V104, P3586, DOI 10.1121/1.423941
   Fu QJ, 2004, JARO-J ASSOC RES OTO, V5, P253, DOI 10.1007/s10162-004-4046-1
   Fu QJ, 2002, J ACOUST SOC AM, V112, P1664, DOI 10.1121/1.1502901
   Gaskell MG, 2001, LANG COGNITIVE PROC, V16, P723, DOI 10.1080/01690960143000128
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Hardison DM, 2005, SPEECH COMMUN, V46, P73, DOI 10.1016/j.specom.2005.02.002
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Kaiser AR, 2003, J SPEECH LANG HEAR R, V46, P390, DOI 10.1044/1092-4388(2003/032)
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Khan AM, 2005, LARYNGOSCOPE, V115, P672, DOI 10.1097/01.mlg.0000161335.62139.80
   Lewis D, 2017, EAR HEARING, V38, pE180, DOI 10.1097/AUD.0000000000000395
   Litovsky R, 2006, EAR HEARING, V27, P714, DOI 10.1097/01.aud.0000246816.50820.42
   LIVELY SE, 1994, HDB PSYCHOLINGUISTIC, P265
   Loizou PC, 1998, IEEE SIGNAL PROC MAG, V15, P101, DOI 10.1109/79.708543
   Loizou PC, 1999, J ACOUST SOC AM, V106, P2097, DOI 10.1121/1.427954
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Metsala JL, 1997, J EDUC PSYCHOL, V89, P159, DOI 10.1037/0022-0663.89.1.159
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Molis MR, 2015, J SPEECH LANG HEAR R, V58, P481, DOI 10.1044/2015_JSLHR-H-14-0098
   Moradi S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00531
   Moradi S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00359
   Nelson PB, 2003, J ACOUST SOC AM, V113, P961, DOI 10.1121/1.1531983
   Nelson PB, 2004, J ACOUST SOC AM, V115, P2286, DOI 10.1121/1.1703538
   Norris P., 2000, VIRTUOUS CIRCLE POLI
   Obleser J, 2011, NEUROIMAGE, V55, P713, DOI 10.1016/j.neuroimage.2010.12.020
   Oh SH, 2016, EAR HEARING, V37, P582, DOI 10.1097/AUD.0000000000000298
   Patro C, 2016, J ACOUST SOC AM, V140, P1336, DOI 10.1121/1.4961450
   PERKELL J, 1992, J ACOUST SOC AM, V91, P2961, DOI 10.1121/1.402932
   PETERSON GE, 1962, J SPEECH HEAR DISORD, V27, P62, DOI 10.1044/jshd.2701.62
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   SALASOO A, 1985, J MEM LANG, V24, P210, DOI 10.1016/0749-596X(85)90025-7
   Shafiro V, 2015, J SPEECH LANG HEAR R, V58, P509, DOI 10.1044/2015_JSLHR-H-14-0312
   Shafiro V, 2012, TRENDS AMPLIF, V16, P83, DOI 10.1177/1084713812454225
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sheldon S, 2008, J ACOUST SOC AM, V123, P489, DOI 10.1121/1.2783762
   Sivonen P, 2006, NEUROSCI LETT, V408, P220, DOI 10.1016/j.neulet.2006.09.001
   SLOWIACZEK LM, 1987, J EXP PSYCHOL LEARN, V13, P64, DOI 10.1037/0278-7393.13.1.64
   Stickney GS, 2004, J ACOUST SOC AM, V116, P1081, DOI 10.1121/1.1772399
   Svirsky MA, 2001, ACTA OTO-LARYNGOL, V121, P262
   TYLER LK, 1985, PERCEPT PSYCHOPHYS, V38, P217, DOI 10.3758/BF03207148
   TYLER LK, 1983, PERCEPT PSYCHOPHYS, V34, P409, DOI 10.3758/BF03203056
   Van Deun L, 2010, EAR HEARING, V31, P702, DOI 10.1097/AUD.0b013e3181e40dfe
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Wagner AE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00398
   WALLEY AC, 1995, PERCEPT PSYCHOPHYS, V57, P343, DOI 10.3758/BF03213059
   Wang X, 2010, J ACOUST SOC AM, V128, P2100, DOI 10.1121/1.3483733
   WARREN P, 1987, PERCEPT PSYCHOPHYS, V41, P262, DOI 10.3758/BF03208224
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Wingfield A, 2000, J SPEECH LANG HEAR R, V43, P915, DOI 10.1044/jslhr.4304.915
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   Zeng FG, 2004, J ACOUST SOC AM, V116, P1351, DOI 10.1121/1.1777938
NR 95
TC 3
Z9 3
U1 0
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JAN
PY 2018
VL 61
IS 1
BP 145
EP 158
DI 10.1044/2017_JSLHR-H-17-0141
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FT4ER
UT WOS:000423106100013
PM 29242894
DA 2021-02-24
ER

PT J
AU Kumar, GV
   Kumar, N
   Roy, D
   Banerjee, A
AF Kumar, G. Vinodh
   Kumar, Neeraj
   Roy, Dipanjan
   Banerjee, Arpan
TI Segregation and Integration of Cortical Information Processing
   Underlying Cross-Modal Perception
SO MULTISENSORY RESEARCH
LA English
DT Article; Proceedings Paper
CT 17h International Multisensory Research Forum (IMRF)
CY JUN 15-18, 2016
CL Suzhou, PEOPLES R CHINA
DE EEG; network; multisensory; perception; ERP; spectral; coherence; timing
ID AUDIOVISUAL SPEECH-PERCEPTION; GAMMA-BAND ACTIVITY; VISUAL SPEECH;
   SEEING VOICES; HEARING LIPS; OSCILLATORY SYNCHRONIZATION; MULTISENSORY
   INTEGRATION; CONSCIOUS PERCEPTION; THETA OSCILLATIONS; BRAIN
AB Visual cues from the speaker's face influence the perception of speech. An example of this influence is demonstrated by the McGurk-effect where illusory (cross-modal) sounds are perceived following presentation of incongruent audio-visual (AV) stimuli. Previous studies report the engagement of specific cortical modules that are spatially distributed during cross-modal perception. However, the limits of the underlying representational space and the cortical network mechanisms remain unclear. In this combined psychophysical and electroencephalography (EEG) study, the participants reported their perception while listening to a set of synchronous and asynchronous incongruent AV stimuli. We identified the neural representation of subjective cross-modal perception at different organizational levels - at specific locations in sensor space and at the level of the large-scale brain network estimated from between-sensor interactions. We identified an enhanced positivity in the event-related potential peak around 300 ms following stimulus onset associated with cross-modal perception. At the spectral level, cross-modal perception involved an overall decrease in power at the frontal and temporal regions at multiple frequency bands and at all AV lags, along with an increased power at the occipital scalp region for synchronous AV stimuli. At the level of large-scale neuronal networks, enhanced functional connectivity at the gamma band involving frontal regions serves as a marker of AV integration. Thus, we report in one single study that segregation of information processing at individual brain locations and integration of information over candidate brain networks underlie multisensory speech perception.
C1 [Kumar, G. Vinodh; Kumar, Neeraj; Banerjee, Arpan] Natl Brain Res Ctr, Cognit Brain Lab, NH 8, Manesar 12205, Gurgaon, India.
   [Roy, Dipanjan] Univ Allahabad, Ctr Behav & Cognit Sci, Allahabad 211002, Uttar Pradesh, India.
RP Kumar, GV (corresponding author), Natl Brain Res Ctr, Cognit Brain Lab, NH 8, Manesar 12205, Gurgaon, India.
EM vinodh@nbrc.ac.in
RI Banerjee, Arpan/AAA-1382-2020
OI Roy, Dipanjan/0000-0002-1669-1083
FU NBRCDepartment of Biotechnology (DBT) India [BT/RLF/Re-entry/31/2011];
   Department of Biotechnology (DBT), Ministry of Science and Technology,
   Government of IndiaDepartment of Biotechnology (DBT) IndiaMinistry of
   Science and Technology, Government of India [BT/07/IYBA/2013];
   Ramalingaswami fellowship from the Department of Biotechnology (DBT),
   Ministry of Science and Technology, Government of India
   [BT/RLF/Re-entry/07/2014]
FX This research was funded by NBRC core, a Ramalingaswami fellowship grant
   (BT/RLF/Re-entry/31/2011) and an Innovative Young Bio-technologist Award
   (IYBA) (BT/07/IYBA/2013) from the Department of Biotechnology (DBT),
   Ministry of Science and Technology, Government of India to AB. DR is
   supported by a Ramalingaswami fellowship (BT/RLF/Re-entry/07/2014) from
   the Department of Biotechnology (DBT), Ministry of Science and
   Technology, Government of India.
CR Albright TD, 2012, NEURON, V74, P227, DOI 10.1016/j.neuron.2012.04.001
   Allman BL, 2009, P NATL ACAD SCI USA, V106, P5925, DOI 10.1073/pnas.0809483106
   Balazs S, 2016, CLIN EEG NEUROSCI, V47, P196, DOI 10.1177/1550059415601756
   Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0
   Bizley J. K., 2012, NEURAL BASEMULTISE, P31
   Bressler SL, 2001, TRENDS COGN SCI, V5, P26, DOI 10.1016/S1364-6613(00)01564-3
   Bressler SL, 2015, CURR OPIN NEUROBIOL, V31, P62, DOI 10.1016/j.conb.2014.08.010
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Calvert GA, 2004, J PHYSIOL-PARIS, V98, P191, DOI 10.1016/j.jphysparis.2004.03.018
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Guggisberg AG, 2008, ANN NEUROL, V63, P193, DOI 10.1002/ana.21224
   Hanslmayr S, 2011, BRAIN RES REV, V67, P331, DOI 10.1016/j.brainresrev.2011.04.002
   Hasson U, 2007, NEURON, V56, P1116, DOI 10.1016/j.neuron.2007.09.037
   Helfer KS, 1997, J SPEECH LANG HEAR R, V40, P432, DOI 10.1044/jslhr.4002.432
   Herrmann CS, 2001, NEUROSCI BIOBEHAV R, V25, P465, DOI 10.1016/S0149-7634(01)00027-6
   Hipp JF, 2011, NEURON, V69, P387, DOI 10.1016/j.neuron.2010.12.027
   Horwitz B, 2005, CR BIOL, V328, P109, DOI 10.1016/j.crvi.2004.10.015
   Jain Aditya, 2015, Int J Appl Basic Med Res, V5, P124, DOI 10.4103/2229-516X.157168
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Kaiser J, 2006, NEUROIMAGE, V30, P1376, DOI 10.1016/j.neuroimage.2005.10.042
   Kaiser J, 2005, CEREB CORTEX, V15, P646, DOI 10.1093/cercor/bhh166
   Kaiser J, 2005, NEUROREPORT, V16, P207, DOI 10.1097/00001756-200502280-00001
   Keil J, 2012, CEREB CORTEX, V22, P221, DOI 10.1093/cercor/bhr125
   Kelly SP, 2003, I IEEE EMBS C NEUR E, P83, DOI 10.1109/CNE.2003.1196761
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Kumar GV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01558
   Luria Aleksandr Romanovich, 1995, HIGHER CORTICAL FUNC
   Maris E, 2007, J NEUROSCI METH, V163, P161, DOI 10.1016/j.jneumeth.2007.02.011
   MASSARO DW, 1989, HUMAN INFORMATION PROCESSING, P367
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McIntosh AR, 2004, NEUROINFORMATICS, V2, P175, DOI 10.1385/NI:2:2:175
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Murray RF, 2002, J VISION, V2, P79, DOI 10.1167/2.1.6
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Nolte G, 2004, CLIN NEUROPHYSIOL, V115, P2292, DOI 10.1016/j.clinph.2004.04.029
   Nyhus E, 2010, NEUROSCI BIOBEHAV R, V34, P1023, DOI 10.1016/j.neubiorev.2009.12.014
   Payne L, 2013, J COGNITIVE NEUROSCI, V25, P1463, DOI 10.1162/jocn_a_00395
   Pitts MA, 2014, NEUROIMAGE, V101, P337, DOI 10.1016/j.neuroimage.2014.07.024
   PULVERMULLER F, 1995, NEUROREPORT, V6, P2059, DOI 10.1097/00001756-199510010-00025
   Railo H, 2011, CONSCIOUS COGN, V20, P972, DOI 10.1016/j.concog.2011.03.019
   Rutiku R, 2015, NEUROSCIENCE, V298, P180, DOI 10.1016/j.neuroscience.2015.04.029
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   Sauseng P, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01655
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Shelton J, 2010, NEUROSCI MED, V1, P30, DOI DOI 10.4236/NM.2010.11004
   Sigala R, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00036
   SIMSON R, 1977, ELECTROEN CLIN NEURO, V43, P864, DOI 10.1016/0013-4694(77)90009-8
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Talsma D, 2015, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00019
   Thakur B, 2016, SCI REP-UK, V6, DOI 10.1038/srep31280
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   VanRullen R, 2016, TRENDS COGN SCI, V20, P723, DOI 10.1016/j.tics.2016.07.006
   WALLACE MT, 1993, J NEUROPHYSIOL, V69, P1797
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008
NR 61
TC 2
Z9 3
U1 2
U2 17
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 5
SI SI
BP 481
EP 500
DI 10.1163/22134808-00002574
PG 20
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FT4HG
UT WOS:000423114100007
PM 31264600
DA 2021-02-24
ER

PT J
AU Giroud, N
   Hirsiger, S
   Muri, R
   Kegel, A
   Dillier, N
   Meyer, M
AF Giroud, Nathalie
   Hirsiger, Sarah
   Muri, Raphaela
   Kegel, Andrea
   Dillier, Norbert
   Meyer, Martin
TI Neuroanatomical and resting state EEG power correlates of central
   hearing loss in older adults
SO BRAIN STRUCTURE & FUNCTION
LA English
DT Article
DE Cortical thickness; Cortical surface area; Central hearing loss; Speech
   processing; Speech-in-noise; Resting state EEG power; Aging
ID SURFACE-BASED ANALYSIS; HUMAN CEREBRAL-CORTEX; SPEECH-PERCEPTION;
   CORTICAL THICKNESS; AUDITORY-CORTEX; AID USE; PREFRONTAL CORTEX; AGE;
   AREA; THRESHOLDS
AB To gain more insight into central hearing loss, we investigated the relationship between cortical thickness and surface area, speech-relevant resting state EEG power, and above-threshold auditory measures in older adults and younger controls. Twenty-three older adults and 13 younger controls were tested with an adaptive auditory test battery to measure not only traditional pure-tone thresholds, but also above individual thresholds of temporal and spectral processing. The participants' speech recognition in noise (SiN) was evaluated, and a T1-weighted MRI image obtained for each participant. We then determined the cortical thickness (CT) and mean cortical surface area (CSA) of auditory and higher speech-relevant regions of interest (ROIs) with FreeSurfer. Further, we obtained resting state EEG from all participants as well as data on the intrinsic theta and gamma power lateralization, the latter in accordance with predictions of the Asymmetric Sampling in Time hypothesis regarding speech processing (Poeppel, Speech Commun 41:245-255, 2003). Methodological steps involved the calculation of age-related differences in behavior, anatomy and EEG power lateralization, followed by multiple regressions with anatomical ROIs as predictors for auditory performance. We then determined anatomical regressors for theta and gamma lateralization, and further constructed all regressions to investigate age as a moderator variable. Behavioral results indicated that older adults performed worse in temporal and spectral auditory tasks, and in SiN, despite having normal peripheral hearing as signaled by the audiogram. These behavioral age-related distinctions were accompanied by lower CT in all ROIs, while CSA was not different between the two age groups. Age modulated the regressions specifically in right auditory areas, where a thicker cortex was associated with better auditory performance in older adults. Moreover, a thicker right supratemporal sulcus predicted more rightward theta lateralization, indicating the functional relevance of the right auditory areas in older adults. The question how age-related cortical thinning and intrinsic EEG architecture relates to central hearing loss has so far not been addressed. Here, we provide the first neuroanatomical and neurofunctional evidence that cortical thinning and lateralization of speech-relevant frequency band power relates to the extent of age-related central hearing loss in older adults. The results are discussed within the current frameworks of speech processing and aging.
C1 [Giroud, Nathalie; Muri, Raphaela; Meyer, Martin] Univ Zurich, Res Unit Neuroplast & Learning Hlth Aging Brai, Dept Psychol, Andreasstr 15-2, CH-8050 Zurich, Switzerland.
   [Giroud, Nathalie; Meyer, Martin] Univ Zurich, Univ Res Prior Program Dynam Hlth Aging, Dept Psychol, Andreasstr 15-2, CH-8050 Zurich, Switzerland.
   [Hirsiger, Sarah] Univ Zurich, Dept Psychiat Psychotherapy & Psychosomat, Psychiat Hosp, Lenggstr 31, CH-8032 Zurich, Switzerland.
   [Kegel, Andrea; Dillier, Norbert] Univ Zurich Hosp, Expt Audiol, Dept Otorhinolaryngol Head & Neck Surg, Frauenklin Str 24, CH-8091 Zurich, Switzerland.
   [Meyer, Martin] Univ Klagenfurt, Cognit Neurosci, Dept Psychol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
RP Giroud, N (corresponding author), Univ Zurich, Res Unit Neuroplast & Learning Hlth Aging Brai, Dept Psychol, Andreasstr 15-2, CH-8050 Zurich, Switzerland.; Giroud, N (corresponding author), Univ Zurich, Univ Res Prior Program Dynam Hlth Aging, Dept Psychol, Andreasstr 15-2, CH-8050 Zurich, Switzerland.
EM nathalie.giroud@uzh.ch; sarah.hirsiger@bli.uzh.ch; raphaela.muri@gmx.ch;
   andrea.kegel@usz.ch; norbert.dillier@usz.ch; martin.meyer@uzh.ch
RI Meyer, Martin/H-4307-2012
OI Meyer, Martin/0000-0003-2057-5533; Muri, Raphaela/0000-0001-6911-1313
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [105314_152905]; 'Fonds zur Forderung des
   akademischen Nachwuchses' (FAN) of the 'Zurcher Universitatsvereins'
   (ZUNIV); 'Forschungskredit' of the University of Zurich [K-60241-01-01]
FX This research was supported by the Swiss National Science Foundation
   (Grant no. 105314_152905 to MM), the 'Fonds zur Forderung des
   akademischen Nachwuchses' (FAN) of the 'Zurcher Universitatsvereins'
   (ZUNIV) (MM) and by the 'Forschungskredit' of the University of Zurich
   (Grant no. K-60241-01-01 to NG). We thank Dr. Susan Merillat and Prof.
   Lutz Jancke for their support in recruiting older participants through
   the lhab study (Zollig et al. 2011) and providing us with the
   T1-weighted MR sequence and cognitive tasks used in this study.
   Furthermore, we are indebted to Allison Christen for proofreading the
   manuscript. During the work on her dissertation, NG was a pre-doctoral
   fellow of the International Max Planck Research School on the Life
   Course.
CR Abe O, 2008, NEUROBIOL AGING, V29, P102, DOI 10.1016/j.neurobiolaging.2006.09.003
   Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Allen JS, 2005, NEUROBIOL AGING, V26, P1245, DOI 10.1016/j.neurobiolaging.2005.05.023
   Amlien IK, 2016, CEREB CORTEX, V26, P257, DOI 10.1093/cercor/bhu214
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Bertoli S, 2009, INT J AUDIOL, V48, P183, DOI 10.1080/14992020802572627
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   BRANT LJ, 1990, J ACOUST SOC AM, V88, P813, DOI 10.1121/1.399731
   Buhner M., 2006, Z NEUROPSYCHOL, V17, P191, DOI DOI 10.1024/1016-264X.17.3.191
   Cabeza R, 2002, NEUROIMAGE, V17, P1394, DOI 10.1006/nimg.2002.1280
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Cardinale F, 2014, NEUROINFORMATICS, V12, P535, DOI 10.1007/s12021-014-9229-2
   Chien W, 2012, ARCH INTERN MED, V172, P292, DOI 10.1001/archinternmed.2011.1408
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   DALE AM, 1993, J COGNITIVE NEUROSCI, V5, P162, DOI 10.1162/jocn.1993.5.2.162
   Davis SW, 2008, CEREB CORTEX, V18, P1201, DOI 10.1093/cercor/bhm155
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Eckert MA, 2012, JARO-J ASSOC RES OTO, V13, P703, DOI 10.1007/s10162-012-0332-5
   Engvig A, 2010, NEUROIMAGE, V52, P1667, DOI 10.1016/j.neuroimage.2010.05.041
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Fischl B, 2004, NEUROIMAGE, V23, pS69, DOI 10.1016/j.neuroimage.2004.07.016
   Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087
   Fischl B, 2001, IEEE T MED IMAGING, V20, P70, DOI 10.1109/42.906426
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Fischl B, 2002, NEURON, V33, P341, DOI 10.1016/S0896-6273(02)00569-X
   Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797
   Fjell AM, 2014, CEREB CORTEX, V24, P919, DOI 10.1093/cercor/bhs379
   Fjell AM, 2009, CEREB CORTEX, V19, P2001, DOI 10.1093/cercor/bhn232
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P175, DOI 10.1515/jbcpp-2013-0048
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fullgrabe C, 2013, AM J AUDIOL, V22, P313, DOI 10.1044/1059-0889(2013/12-0070)
   Gabrieli JDE, 1998, P NATL ACAD SCI USA, V95, P906, DOI 10.1073/pnas.95.3.906
   Giraud AL, 2002, NEUROPSYCHOLOGIA, V40, P1562, DOI 10.1016/S0028-3932(02)00023-4
   Giraud AL, 2001, NEURON, V30, P657, DOI 10.1016/S0896-6273(01)00318-X
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Giroud N, 2017, HEARING RES, V353, P162, DOI 10.1016/j.heares.2017.06.012
   Giroud N, 2017, BIOL PSYCHOL, V123, P25, DOI 10.1016/j.biopsycho.2016.11.007
   Gordon-Salant S, 1999, J SPEECH LANG HEAR R, V42, P300, DOI 10.1044/jslhr.4202.300
   Gordon-Salant S, 2015, J ACOUST SOC AM, V137, P884, DOI 10.1121/1.4906270
   Gordon-Salant S, 2010, J ACOUST SOC AM, V128, P3152, DOI 10.1121/1.3495940
   Grady C, 2012, NAT REV NEUROSCI, V13, P491, DOI 10.1038/nrn3256
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hogstrom LJ, 2013, CEREB CORTEX, V23, P2521, DOI 10.1093/cercor/bhs231
   Hopkins K, 2011, J ACOUST SOC AM, V130, P334, DOI 10.1121/1.3585848
   Huang Q, 2010, EUR ARCH OTO-RHINO-L, V267, P1179, DOI 10.1007/s00405-010-1270-7
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   Husain FT, 2011, BRAIN RES, V1369, P74, DOI 10.1016/j.brainres.2010.10.095
   Hutsler J, 2003, TRENDS NEUROSCI, V26, P429, DOI 10.1016/S0166-2236(03)00198-X
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Kreiner H, 2014, BRAIN LANG, V137, P91, DOI 10.1016/j.bandl.2014.08.004
   Kuehnel V, 1999, Z AUDIOL, V38, P4
   Kuperberg GR, 2003, J COGNITIVE NEUROSCI, V15, P272, DOI 10.1162/089892903321208204
   Lecluyse W, 2013, INT J AUDIOL, V52, P596, DOI 10.3109/14992027.2013.796530
   Lecluyse W, 2009, J ACOUST SOC AM, V126, P2570, DOI 10.1121/1.3238248
   Lee FS, 2005, EAR HEARING, V26, P1, DOI 10.1097/00003446-200502000-00001
   Lee NR, 2016, CEREB CORTEX, V26, P2982, DOI 10.1093/cercor/bhv107
   Lemaitre H, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2010.07.013
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Liem F, 2015, NEUROIMAGE, V108, P95, DOI 10.1016/j.neuroimage.2014.12.035
   Liem F, 2014, HUM BRAIN MAPP, V35, P1779, DOI 10.1002/hbm.22291
   Liem F, 2012, NEUROREPORT, V23, P1026, DOI 10.1097/WNR.0b013e32835abc5c
   Lundquist AP, 2009, THESIS
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   Lyall AE, 2015, CEREB CORTEX, V25, P2204, DOI 10.1093/cercor/bhu027
   Meyer M, 2014, CEREB CORTEX, V24, P2541, DOI 10.1093/cercor/bht094
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Moore DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107720
   Morillon B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00248
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   O'Brien LM, 2011, PSYCHIAT RES-NEUROIM, V193, P113, DOI 10.1016/j.pscychresns.2011.01.007
   Overath T, 2015, NAT NEUROSCI, V18, P903, DOI 10.1038/nn.4021
   Panizzon MS, 2009, CEREB CORTEX, V19, P2728, DOI 10.1093/cercor/bhp026
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Penhune VB, 1996, CEREB CORTEX, V6, P661, DOI 10.1093/cercor/6.5.661
   PERRIN F, 1987, ELECTROEN CLIN NEURO, V66, P75, DOI 10.1016/0013-4694(87)90141-6
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Pickles J, 2012, INTRO PHYSL HEARING
   Plack CJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514550621
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2001, COGNITIVE SCI, V25, P679, DOI 10.1016/S0364-0213(01)00050-7
   Popelka MM, 1998, J AM GERIATR SOC, V46, P1075, DOI 10.1111/j.1532-5415.1998.tb06643.x
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   Profant O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116692
   RAJKOWSKA G, 1995, CEREB CORTEX, V5, P323, DOI 10.1093/cercor/5.4.323
   RAKIC P, 1988, SCIENCE, V241, P170, DOI 10.1126/science.3291116
   RAKIC P, 1995, TRENDS NEUROSCI, V18, P383, DOI 10.1016/0166-2236(95)93934-P
   Rakic P, 2007, BRAIN RES REV, V55, P204, DOI 10.1016/j.brainresrev.2007.02.010
   Raz N, 1997, CEREB CORTEX, V7, P268, DOI 10.1093/cercor/7.3.268
   Reuter M, 2010, NEUROIMAGE, V53, P1181, DOI 10.1016/j.neuroimage.2010.07.020
   Reuter-Lorenz PA, 2010, J GERONTOL B-PSYCHOL, V65, P405, DOI 10.1093/geronb/gbq035
   Rosas HD, 2002, NEUROLOGY, V58, P695, DOI 10.1212/WNL.58.5.695
   Roth TN, 2011, EUR ARCH OTO-RHINO-L, V268, P1101, DOI 10.1007/s00405-011-1597-8
   Rufener KS, 2016, BRAIN TOPOGR, V29, P440, DOI 10.1007/s10548-015-0464-0
   Salat DH, 2004, CEREB CORTEX, V14, P721, DOI 10.1093/cercor/bhh032
   Schneider Bruce A., 2001, Seminars in Hearing, V22, P227, DOI 10.1055/s-2001-15628
   Segonne F, 2004, NEUROIMAGE, V22, P1060, DOI 10.1016/j.neuroimage.2004.03.032
   Sheppard JP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016510
   Sowell ER, 2003, NAT NEUROSCI, V6, P309, DOI 10.1038/nn1008
   Steinhauer K, 2010, NEUROSCI LETT, V472, P133, DOI 10.1016/j.neulet.2010.01.072
   Storsve AB, 2014, J NEUROSCI, V34, P8488, DOI 10.1523/JNEUROSCI.0391-14.2014
   Tisserand DJ, 2002, NEUROIMAGE, V17, P657, DOI 10.1006/nimg.2002.1173
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   Vermeire K, 2016, ANN OTO RHINOL LARYN, V125, P297, DOI 10.1177/0003489415611424
   Vigneau M, 2011, NEUROIMAGE, V54, P577, DOI 10.1016/j.neuroimage.2010.07.036
   Wagener K, 1999, Z AUDIOL, V38, P44, DOI DOI 10.3109/00206099909073001
   Wagener KC, 1999, AUDIOL ACOUST, V38, P8695
   Wiley TL, 2008, J AM ACAD AUDIOL, V19, P281, DOI 10.3766/jaaa.19.4.2
   Williams JT, 2016, BRAIN RES, V1633, P101, DOI 10.1016/j.brainres.2015.12.046
   WINGFIELD A, 1992, J GERONTOL, V47, pP350, DOI 10.1093/geronj/47.5.P350
   Wingfield A, 2000, J SPEECH LANG HEAR R, V43, P915, DOI 10.1044/jslhr.4304.915
   Wingfield A, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00035
   Wong PCM, 2008, J SPEECH LANG HEAR R, V51, P1026, DOI 10.1044/1092-4388(2008/075)
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Yu LD, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00030
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zimmermann P, 2002, TESTBATTERIE ZURAUFM
   Zollig J, 2011, GERONTOLOGY, V57, P190, DOI 10.1159/000324307
NR 131
TC 14
Z9 14
U1 0
U2 11
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1863-2653
EI 1863-2661
J9 BRAIN STRUCT FUNCT
JI Brain Struct. Funct.
PD JAN
PY 2018
VL 223
IS 1
BP 145
EP 163
DI 10.1007/s00429-017-1477-0
PG 19
WC Anatomy & Morphology; Neurosciences
SC Anatomy & Morphology; Neurosciences & Neurology
GA FT0VF
UT WOS:000422845500012
PM 28735495
DA 2021-02-24
ER

PT J
AU de Jong, K
   Hao, YC
AF de Jong, Kenneth
   Hao, Yen-chen
TI Featural generalization in second language identification Performance:
   Comparing learners with different L1 s
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Second Language Acquisition; Mandarin; Obstruents; L1 effects; Featural
   generalization
ID PRECEDING VOWEL DURATION; PERCEPTUAL EVIDENCE; SPEECH-PERCEPTION;
   AMERICAN ENGLISH; NATIVE SPEAKERS; LANGUAGE; DISCRIMINATION; CONSONANTS;
   CONTRASTS; SYSTEM
AB The current study examined identification responses by Taiwan Mandarin L1 speakers learning English. Stimuli were monosyllabic and disyllabic native English productions of voiced and voiceless, labial and corona], plosives and non-sibilant fricatives. Analyses correlated individual identification performance for laryngeal (hereafter, "voicing") contrasts and manner contrasts, obtained from different halves of the overall corpus. Manner accuracy correlations were strong, particularly between voiced and voiceless segments. Manner accuracy also correlated across consonants appearing in different prosodic locations, word-initial, word-final, and intervocalic post-stress and pre-stress positions. Voicing accuracy also correlated across prosodic positions, though not between word final position and the other positions. These results were interpreted with respect to a previously published corpus of Korean learners. The two corpora showed different patterns of correlation across prosodic positions for voicing, apparently due to the effects of different, prosodically-conditioned voicing allophony in the L1s. Finally, overall segmental and d-prime estimates were compared across the two language groups, revealing very strong similarities in the segmental accuracies for the two L1 groups. Analyses, however, also showed a persistent advantage for Mandarin listeners for manner contrasts. It was proposed that the difficulty of individual segments in specific prosodic locations, combined with the overall characteristics of the L1 phonological system, better account for learners' identification accuracies than does the correspondence of specific L1 and L2 segments. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [de Jong, Kenneth] Indiana Univ, Ballantine Hall 859, Bloomington, IN 47405 USA.
   [Hao, Yen-chen] Univ Tennessee, Knoxville, TN USA.
RP de Jong, K (corresponding author), Indiana Univ, Ballantine Hall 859, Bloomington, IN 47405 USA.
EM kdejong@indiana.edu
CR ALTENBERG EP, 1983, LANG LEARN, V33, P427, DOI 10.1111/j.1467-1770.1983.tb00943.x
   Bang H-Y., J PHONETICS IN PRESS
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Brannen K, 2002, CAN J LING/REV CAN L, V47, P1
   Brown C. A., 1997, THESIS
   CALABRESE A, 1995, LINGUIST INQ, V26, P373
   Chao KY., 2008, COMPUTATIONAL LINGUI, V13, P215
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   de Jong KJ, 2009, LANG LEARN, V59, P1, DOI 10.1111/j.1467-9922.2009.00499.x
   Eckman F, 2008, PHONOLOGY 2 LANGUAGE, P95, DOI [10.1075/sibil.36.06eck, DOI 10.1075/SIBIL.36.06ECK]
   Eckman FR, 2004, STUD SECOND LANG ACQ, V26, P513, DOI 10.1071/S027226310404001X
   ECKMAN FR, 1981, LANG LEARN, V31, P195, DOI 10.1111/j.1467-1770.1981.tb01379.x
   ECKMAN FR, 1977, LANG LEARN, V27, P315, DOI 10.1111/j.1467-1770.1977.tb00124.x
   Eckman Fred R, 1984, LANGUAGE UNIVERSALS, P79
   Ellen Broselow, 1998, STUDIES 2 LANGUAGE A, V20, P261, DOI DOI 10.1017/S0272263198002071
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1992, J ACOUST SOC AM, V92, P128, DOI 10.1121/1.404278
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   Greenberg J. H., 1978, UNIVERSALS HUMAN LAN, V2
   Hancin-Bhatt B. J., 1994, SECOND LANG RES, V10, P241, DOI DOI 10.1177/026765839401000304
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Harnsberger JD, 2001, J ACOUST SOC AM, V110, P489, DOI 10.1121/1.1371758
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Iverson P, 2007, J ACOUST SOC AM, V122, P2842, DOI 10.1121/1.2783198
   Jacobson R., 1968, CHILD LANGUAGE APHAS
   Jun S.-A., 1995, J ACOUST SOC AM, V98, P2893
   Kang KH, 2006, J ACOUST SOC AM, V119, P1672, DOI 10.1121/1.2166607
   Keating Patricia, 1984, UCLA WORKING PAPERS, V59, P29
   Kim HS, 1996, J PHONETICS, V24, P295, DOI 10.1006/jpho.1996.0016
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   Levy ES, 2009, J ACOUST SOC AM, V126, P2670, DOI 10.1121/1.3224715
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   Major RC, 1996, STUDIES 2 LANGUAGE A, V18, P69, DOI DOI 10.1017/S0272263100014686
   MCCLASKEY CL, 1983, PERCEPT PSYCHOPHYS, V34, P323, DOI 10.3758/BF03203044
   Ogasawara N, 2011, CONCENTRIC-STUD LING, V37, P155
   Park H, 2008, J PHONETICS, V36, P704, DOI 10.1016/j.wocn.2008.06.002
   Park H, 2017, J PHONETICS, V62, P12, DOI 10.1016/j.wocn.2017.01.005
   POLKA L, 1992, PERCEPT PSYCHOPHYS, V52, P37, DOI 10.3758/BF03206758
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Rochet B. L., 1991, Canadian Acoustics, V19, P105
   Schmidt AM, 1996, J ACOUST SOC AM, V99, P3201, DOI 10.1121/1.414804
   Simon E, 2009, SECOND LANG RES, V25, P377, DOI 10.1177/0267658309104580
   Tremblay K, 1997, J ACOUST SOC AM, V102, P3762, DOI 10.1121/1.420139
   WARDRIPFRUIN C, 1982, J ACOUST SOC AM, V71, P187, DOI 10.1121/1.387346
NR 50
TC 0
Z9 0
U1 2
U2 10
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JAN
PY 2018
VL 66
BP 15
EP 27
DI 10.1016/j.wocn.2017.09.002
PG 13
WC Linguistics; Language & Linguistics
SC Linguistics
GA FS8ZP
UT WOS:000422703600002
DA 2021-02-24
ER

PT J
AU Buckler, H
   Goy, H
   Johnson, EK
AF Buckler, Helen
   Goy, Huiwen
   Johnson, Elizabeth K.
TI What: infant-directed speech tells us about the development of
   compensation for assimilation
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Lexical development; Connected speech processes; Infant speech
   perception; Place assimilation; Speech register; Child-directed speech
ID SPOKEN WORD RECOGNITION; REGRESSIVE PLACE ASSIMILATION; USAGE-BASED
   ACCOUNT; CROSS-LANGUAGE; LEXICAL AMBIGUITY; ENGLISH; PERCEPTION;
   ACQUISITION; DISCRIMINATION; SENSITIVITY
AB In speech addressed to adults, words are seldom realized in their canonical, or citation, form. For example, the word 'green' in the phrase 'green beans' can often be realized as `greem' due to English place assimilation, where word-final coronals take on the place of articulation of neighboring velars. In such a situation, adult listeners readily 'undo' the assimilatory process and perceive the underlying intended lexical form of 'greem' (i.e. they access the lexical representation 'green'). An interesting developmental question is how children, with their limited lexical knowledge, come to cope with phonologically conditioned connected speech processes such as place assimilation. Here, we begin to address this issue by examining the occurrence of place assimilation in the input to English-learning 18-month-olds. Perceptual and acoustic analyses of elicited speech, as well as analysis of a corpus of spontaneous speech, all converge on the finding that caregivers do not spoon-feed their children canonical tokens of words. Rather, infant-directed speech contains just as many non-canonical realizations of words in place assimilation contexts as adult-directed speech. Implications for models of developmental speech perception are discussed. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Buckler, Helen] Univ Nottingham, Univ Pk, Nottingham NG7 2RD, England.
   [Goy, Huiwen] Ryerson Univ, 350 Victoria St, Toronto, ON M5B 2K3, Canada.
   [Johnson, Elizabeth K.] Univ Toronto, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
RP Buckler, H (corresponding author), Univ Nottingham, Univ Pk, Nottingham NG7 2RD, England.
EM helen.buckler@nottingham.ac.uk
OI Goy, Huiwen/0000-0003-4767-7863; Johnson, Elizabeth
   Kay/0000-0002-9941-9949
FU NWO Rubicon grant; SSHRCSocial Sciences and Humanities Research Council
   of Canada (SSHRC); NSERCNatural Sciences and Engineering Research
   Council of Canada (NSERC)
FX This research was funded by an NWO Rubicon grant awarded to Helen
   Buckler and SSHRC and NSERC grants awarded to Elizabeth K. Johnson. We
   thank Julie Kow for help designing stimuli and collecting recordings,
   and Kazuya Bamba and Natalie Fecher for assistance with classifying
   tokens.
CR Albin DD, 1996, INFANT BEHAV DEV, V19, P401, DOI 10.1016/S0163-6383(96)90002-8
   Anderson JL, 2003, LANG SPEECH, V46, P155, DOI 10.1177/00238309030460020601
   BARD EG, 1983, J CHILD LANG, V10, P265, DOI 10.1017/S0305000900007777
   BARD EG, 1994, J CHILD LANG, V21, P623, DOI 10.1017/S030500090000948X
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002
   Bates D., 2015, PACKAGE IME4
   Benders T, 2013, INFANT BEHAV DEV, V36, P847, DOI 10.1016/j.infbeh.2013.09.001
   Blomert L, 2004, J SPEECH LANG HEAR R, V47, P1030, DOI 10.1044/1092-4388(2004/077)
   Boersma P., 2011, PRAAT DOING PHONETIC
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   Chambers KE, 2003, COGNITION, V87, pB69, DOI 10.1016/S0010-0277(02)00233-0
   Chevrot JP, 2009, J CHILD LANG, V36, P557, DOI 10.1017/S0305000908009124
   Cho T, 2017, J PHONETICS, V64, P71, DOI 10.1016/j.wocn.2016.12.003
   Cho TH, 2004, J PHONETICS, V32, P141, DOI 10.1016/S0095-4470(03)00043-3
   Cristia A, 2014, J CHILD LANG, V41, P913, DOI 10.1017/S0305000912000669
   Darcy I., 2007, LAB PHONOLOGY, VIX, P411
   Darcy I., 2002, ISCA TUT RES WORKSH, P32
   Demuth K, 2006, LANG SPEECH, V49, P137, DOI 10.1177/00238309060490020201
   Dilley LC, 2007, J ACOUST SOC AM, V122, P2340, DOI 10.1121/1.2772226
   Dilley LC, 2014, J CHILD LANG, V41, P155, DOI 10.1017/S0305000912000670
   Donegan Patricia Jane, 1979, CURRENT APPROACHES P, P126
   Dugua C, 2009, J EXP CHILD PSYCHOL, V102, P342, DOI 10.1016/j.jecp.2008.07.006
   Durvasula K, 2016, J PHONETICS, V54, P15, DOI 10.1016/j.wocn.2015.08.002
   Englund K, 2006, INFANT CHILD DEV, V15, P139, DOI 10.1002/icd.445
   Englund Kjellrun T., 2005, FIRST LANG, V25, P219, DOI DOI 10.1177/0142723705050286
   Englund KT, 2005, J PSYCHOLINGUIST RES, V34, P259, DOI 10.1007/s10936-005-3640-7
   FENSON L, 1994, MONOGR SOC RES CHILD, V59, pR5
   FERGUSON CA, 1964, AM ANTHROPOL, V66, P103, DOI 10.1525/aa.1964.66.suppl_3.02a00060
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   Fish MS, 2017, J PHONETICS, V63, P19, DOI 10.1016/j.wocn.2017.04.003
   Gaskell MG, 2001, J MEM LANG, V44, P325, DOI 10.1006/jmla.2000.2741
   Golinkoff RM, 1995, J CHILD LANG, V22, P703, DOI 10.1017/S0305000900010011
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Gow DW, 2002, J EXP PSYCHOL HUMAN, V28, P163, DOI 10.1037//0096-1523.28.1.163
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   Jesse A, 2012, J EXP PSYCHOL HUMAN, V38, P1567, DOI 10.1037/a0027921
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Lahey M., 2013, LANGUAGE LEARNING DE, V10, P308
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   MacWhinney B., 2000, CHILDES PROJECT TOOL
   Marshall CR, 2010, COGN NEUROPSYCHOL, V27, P563, DOI 10.1080/02643294.2011.588693
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   Mitterer H, 2003, PERCEPT PSYCHOPHYS, V65, P956, DOI 10.3758/BF03194826
   Mitterer H, 2006, Q J EXP PSYCHOL, V59, P1395, DOI 10.1080/17470210500198726
   Mitterer H, 2006, COGNITIVE SCI, V30, P451, DOI 10.1207/s15516709cog0000_57
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   Mitterer H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00249
   Nakamura M, 2008, COMPUT SPEECH LANG, V22, P171, DOI 10.1016/j.csl.2007.07.003
   Ogden R, 1999, PHONOLOGY, V16, P55, DOI DOI 10.1017/S095267579900370X
   Otake T, 1996, J ACOUST SOC AM, V100, P3831, DOI 10.1121/1.417239
   PEPERKAMP S, 2002, PROCESS LANGUAGE ACQ, P359
   R Core Team, 2012, R LANG ENV STAT COMP
   RATNER NB, 1984, J CHILD LANG, V11, P557, DOI 10.1017/S030500090000595X
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   SCOTT DR, 1984, J VERB LEARN VERB BE, V23, P450, DOI 10.1016/S0022-5371(84)90291-3
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572
   SHOCKEY L, 1980, PHONETICA, V37, P267, DOI 10.1159/000259996
   Skoruppa K, 2013, INFANCY, V18, P1007, DOI 10.1111/infa.12020
   Skoruppa K, 2013, CHILD DEV, V84, P313, DOI 10.1111/j.1467-8624.2012.01845.x
   Smolensky P., 1996, RUTGERS OPTIMALITY A, V293
   Tuinman A, 2011, J ACOUST SOC AM, V130, P1643, DOI 10.1121/1.3619793
   Uther M, 2007, SPEECH COMMUN, V49, P2, DOI 10.1016/j.specom.2006.10.003
   Warner N, 2011, J ACOUST SOC AM, V130, P1606, DOI 10.1121/1.3621306
   Weber A, 2001, LANG SPEECH, V44, P95, DOI 10.1177/00238309010440010401
   Werker JF, 2007, COGNITION, V103, P147, DOI 10.1016/j.cognition.2006.03.006
   White KS, 2008, COGNITION, V107, P238, DOI 10.1016/j.cognition.2007.11.012
   Xu N, 2013, ANTHROZOOS, V26, P373, DOI 10.2752/175303713X13697429463592
   Zimmerer F, 2009, J ACOUST SOC AM, V125, P2307, DOI 10.1121/1.3021438
NR 73
TC 8
Z9 7
U1 2
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JAN
PY 2018
VL 66
BP 45
EP 62
DI 10.1016/j.wocn.2017.09.004
PG 18
WC Linguistics; Language & Linguistics
SC Linguistics
GA FS8ZP
UT WOS:000422703600004
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Crowhurst, MJ
AF Crowhurst, Megan J.
TI The influence of varying vowel phonation and duration on rhythmic
   grouping biases among Spanish and English speakers
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Vowel phonation; Creaky voicing; Rhythmic grouping
   biases; Iambic-Trochaic Law
ID VOCAL FRY; PERCEPTION; GLOTTALIZATION; BOUNDARIES; INTENSITY; CUES
AB Native Mexican Spanish and American English speakers were presented with streams of alternating syllables in which vowel duration and/or creaky phonation were rhythmically varied. Participants' grouping biases were measured as a function of their behaviour in segmenting sequences into recurrent bisyllabic units. Results indicated a creak-last grouping bias in both language groups. Duration varied singly was associated with a weak long-first grouping bias for Spanish and no consistent trend for English. When long creaky and short modal syllables were alternated, there was a significant creak-last bias and again no effect of duration in the English group. However, in the Spanish group, the long-first trend observed for duration varied singly was reversed and the effects of duration and creak were additive. Finally, when short creaky and long modal syllables were alternated, duration effects were highly significant in both language groups (fewer creak-last, more long-last groupings). Creak has been associated with final positions in higher-order prosodic domains in English, and less prevalently in Spanish. The current results show that both English and Spanish speakers can use this cue to segment rhythmic sequences into smaller, foot or word-sized units. This study is the first to establish that creak is perceptually salient for Spanish speakers and to demonstrate that the percept associated with duration can differ depending on whether it is varied singly or together with creak. More generally, the current findings show that grouping effects extend beyond intensity, pitch and duration, the features most often manipulated in rhythmic grouping studies inspired by the Iambic Trochaic Law. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Crowhurst, Megan J.] Univ Texas Austin, Austin, TX 78712 USA.
RP Crowhurst, MJ (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.
EM mcrowhurst@austin.utexas.edu
FU National Science Foundation of the United States of AmericaNational
   Science Foundation (NSF) [BCS-1147959]
FX The current research was funded by National Science Foundation of the
   United States of America grant BCS-1147959 (Megan Crowhurst, PI).
CR Abdelli-Beruh NB, 2014, J VOICE, V28, P185, DOI 10.1016/j.jvoice.2013.08.011
   Andreeva B., 2007, P 16 M ICPHS SAARBR
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barry W, 2009, PHONETICA, V66, P78, DOI 10.1159/000208932
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BECKLAKE MR, 1994, P 9 INT S EP OCC HLT, P1
   Beckman M. E., 1986, STRESS NONSTRESS ACC
   Bhatara A, 2013, J ACOUST SOC AM, V134, P3828, DOI 10.1121/1.4823848
   Bion RAH, 2011, LANG SPEECH, V54, P123, DOI 10.1177/0023830910388018
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bolton T. L., 1894, AM J PSYCHOL, V6, P145, DOI DOI 10.2307/1410948
   Carlson R, 2005, SPEECH COMMUN, V46, P326, DOI 10.1016/j.specom.2005.02.013
   Crowhurst M., 2016, LAB PHONOL, V1, P1
   Crowhurst MJ, 2016, J PHONETICS, V58, P48, DOI 10.1016/j.wocn.2016.06.001
   Crowhurst MJ, 2014, PHONOLOGY, V31, P51, DOI 10.1017/S0952675714000037
   de la Mora DM, 2013, ATTEN PERCEPT PSYCHO, V75, P92, DOI 10.3758/s13414-012-0371-3
   Dilley L, 1996, J PHONETICS, V24, P423, DOI 10.1006/jpho.1996.0023
   Ding H., 2006, P SPEECH PROS 2006, P851
   Fletcher Janet, 2010, HDB PHONETIC SCI, P521, DOI [10.1002/9781444317251.ch15, DOI 10.1002/9781444317251.CH15, 10.1002/9781444317251.ch15.]
   Garellek M., 2015, ANN M LING SOC AM PO
   Garellek M, 2016, INTERSPEECH, P1054, DOI 10.21437/Interspeech.2016-1472
   Gerfen H., 2013, PHONOLOGY PHONETICS, V48
   Gibson TA, 2017, J VOICE, V31, P62, DOI 10.1016/j.jvoice.2016.02.005
   Gordon M, 2001, J PHONETICS, V29, P383, DOI 10.1006/jpho.2001.0147
   Hay JSF, 2007, PERCEPT PSYCHOPHYS, V69, P113, DOI 10.3758/BF03194458
   Hayes Bruce, 1995, METRICAL STRESS THEO
   Henton C., 1988, CREAK SOCIOPHONETIC
   Hosmer D. W., 2004, APPL LOGISTIC REGRES
   Iversen JR, 2008, J ACOUST SOC AM, V124, P2263, DOI 10.1121/1.2973189
   Jeon H.-S., 2016, SPEECH PROSODY
   Jun S, 2014, PROSODIC TYPOLOGY, P520, DOI DOI 10.1093/ACPR0F:0S0/9780199567300.001.0001;HTTP://DX.D0I.0RG/10.1093/ACPR0F:0S0/9780199567300.003.0017
   Keating P., 2015, ANN M LING SOC AM 1
   Kelly N. E., 2014, P N E LING SOC BERK, V40, P215
   KREIMAN J, 1982, J PHONETICS, V10, P163, DOI 10.1016/S0095-4470(19)30955-6
   Kusumoto K., 1997, J ACOUST SOC AM, V105, P3204, DOI DOI 10.1121/1.420460
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Molnar M, 2016, COGNITION, V152, P150, DOI 10.1016/j.cognition.2016.03.023
   Molnar M, 2014, LANG LEARN, V64, P45, DOI 10.1111/lang.12069
   Oliveira G, 2016, J VOICE, V30, P684, DOI 10.1016/j.jvoice.2015.08.015
   Ortega-Llebaria M., 2007, SEGMENTAL PROSODIC I, P155, DOI DOI 10.1075/CILT.282.11ORT
   Ortega-Llebaria M, 2011, LANG SPEECH, V54, P73, DOI 10.1177/0023830910388014
   Patel A.D., 2010, MUSIC LANGUAGE BRAIN
   Prieto P, 2012, SPEECH COMMUN, V54, P681, DOI 10.1016/j.specom.2011.12.001
   R Core Team, 2016, R LANG ENV STAT COMP
   Rao Rajiv, 2010, SEL P 4 C LAB APPR S, P69
   Redi L, 2001, J PHONETICS, V29, P407, DOI 10.1006/jpho.2001.0145
   Rice CC, 1992, THESIS
   Sonnenschein A. H, 2005, THESIS
   Turk AE, 1996, J ACOUST SOC AM, V99, P3782, DOI 10.1121/1.414995
   Turk AE, 2000, J PHONETICS, V28, P397, DOI 10.1006/jpho.2000.0123
   Turk AE, 2007, J PHONETICS, V35, P445, DOI 10.1016/j.wocn.2006.12.001
   VOS PG, 1977, SCI AESTHET-SCI ART, V1, P183
   Wolk L, 2012, J VOICE, V26, pE111, DOI 10.1016/j.jvoice.2011.04.007
   Woodrow H, 1911, PSYCHOL REV, V18, P54, DOI 10.1037/h0075201
   Woodrow H, 1909, COLUMBIA U CONTRIBUT, VXVIII
   Yoshida KA, 2010, COGNITION, V115, P356, DOI 10.1016/j.cognition.2010.01.005
NR 56
TC 3
Z9 3
U1 1
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JAN
PY 2018
VL 66
BP 82
EP 99
DI 10.1016/j.wocn.2017.09.001
PG 18
WC Linguistics; Language & Linguistics
SC Linguistics
GA FS8ZP
UT WOS:000422703600006
DA 2021-02-24
ER

PT J
AU Shinohara, Y
   Iverson, P
AF Shinohara, Yasuaki
   Iverson, Paul
TI High variability identification and discrimination training for Japanese
   speakers learning English /r/-/l/
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Speech production; Second language; Phonetic training
ID L-VERTICAL-BAR; LONG-TERM RETENTION; CATEGORICAL PERCEPTION; LANGUAGE
   EXPERIENCE; LISTENERS; LEARNERS; ADULTS; PERFORMANCE; VOWELS
AB Second-language (L2) learners can benefit from exposure to phonetically variable speech during computer-based training. Moreover, this training can be effective even for L2 learners who have extensive exposure to their L2 in daily life, suggesting that there is something specific about the training task that aids learning. The present study compared traditional identification training with discrimination training to evaluate whether discrimination training could be effective, and whether different types of focused attention (i.e., on categorization vs. perceptual differences) could combine to provide a greater increase in learning. Adult Japanese speakers were given 10 sessions of identification and discrimination training, with pre/mid/post tests of identification, auditory discrimination, category discrimination, and /r/-/l/ production. The results demonstrated that both identification and discrimination training increased accuracy of Japanese speakers' perception and production of English /r/-/l/ in similar ways, but that there was little added benefit to using the two training methods in combination. It thus appears that identification and discrimination training have similar effects in second-language learners, as long as both training methods incorporate high variability. (C) 2017 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Shinohara, Yasuaki] Waseda Univ, Shinjuku Ku, 1-6-1 Nishi Waseda, Tokyo 1698050, Japan.
   UCL, Dept Speech Hearing & Phonet Sci, 2 Wakefield St, London WC1N 1PF, England.
RP Shinohara, Y (corresponding author), Waseda Univ, Shinjuku Ku, 1-6-1 Nishi Waseda, Tokyo 1698050, Japan.
EM y.shinohara@waseda.jp
OI Shinohara, Yasuaki/0000-0002-6730-2287
FU Japan Student Services Organization (JASSO)Japan Student Services
   Organization
FX The first author of this research was funded by Japan Student Services
   Organization (JASSO).
CR Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Bradlow A. R., 2008, PHONOLOGY 2 LANGUAGE, V36, P287, DOI [10.1075/sibil.36.14bra, DOI 10.1075/SIBIL.36.14BRA]
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Callan DE, 2003, NEUROIMAGE, V19, P113, DOI 10.1016/S1053-8119(03)00020-X
   Fairbanks G., 1960, VOICE ARTICULATION D, P127
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, ISSUES CLIN LINGUIST, P19
   Flege JE, 1996, J ACOUST SOC AM, V99, P1161, DOI 10.1121/1.414884
   Gerrits E, 2004, PERCEPT PSYCHOPHYS, V66, P363, DOI 10.3758/BF03194885
   Hattori K., 2009, THESIS
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   Hojen A, 2006, J ACOUST SOC AM, V119, P3072, DOI 10.1121/1.2184289
   Huensch A, 2015, J PHONETICS, V52, P105, DOI 10.1016/j.wocn.2015.06.007
   Hwang H., 2015, P 18 INT C PHON SCI, P1041
   Ingvalson EM, 2011, J PHONETICS, V39, P571, DOI 10.1016/j.wocn.2011.03.003
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Iverson P, 2016, J ACOUST SOC AM, V139, P1799, DOI 10.1121/1.4944755
   Iverson P, 2012, APPL PSYCHOLINGUIST, V33, P145, DOI 10.1017/S0142716411000300
   Jugler J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P806
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   LIVELY SE, 1994, J ACOUST SOC AM, V96, P2076, DOI 10.1121/1.410149
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   Sadakata M, 2013, J ACOUST SOC AM, V134, P1324, DOI 10.1121/1.4812767
   Sjerps MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P576, DOI 10.3758/s13414-012-0408-7
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P159
   Takagi N, 1995, APPL PSYCHOLINGUIST, V16, P379
   UNDERBAKKE M, 1988, J ACOUST SOC AM, V84, P90, DOI 10.1121/1.396878
   Yuan Jiahong, 2011, J SPEECH SCI, V1, P35, DOI DOI 10.1002/9780470753460.CH10
NR 37
TC 6
Z9 7
U1 1
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JAN
PY 2018
VL 66
BP 242
EP 251
DI 10.1016/j.wocn.2017.11.002
PG 10
WC Linguistics; Language & Linguistics
SC Linguistics
GA FS8ZP
UT WOS:000422703600013
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Valimaa, T
   Kunnari, S
   Laukkanen-Nevala, P
   Lonka, E
AF Valimaa, Taina
   Kunnari, Sari
   Laukkanen-Nevala, Paivi
   Lonka, Eila
CA Natl Clinical Res Team
TI Early vocabulary development in children with bilateral cochlear
   implants
SO INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS
LA English
DT Article
DE bilateral cochlear implant; composition of vocabulary; size of
   vocabulary; predictors
ID PROFOUND HEARING-LOSS; LANGUAGE-DEVELOPMENT; DEAF-CHILDREN; AGE;
   EXPERIENCE; WORDS
AB BackgroundChildren with unilateral cochlear implants (CIs) may have delayed vocabulary development for an extended period after implantation. Bilateral cochlear implantation is reported to be associated with improved sound localization and enhanced speech perception in noise. This study proposed that bilateral implantation might also promote early vocabulary development. Knowledge regarding vocabulary growth and composition in children with bilateral CIs and factors associated with it may lead to improvements in the content of early speech and language intervention and family counselling.
   AimsTo analyse the growth of early vocabulary and its composition during the first year after CI activation and to investigate factors associated with vocabulary growth.
   Methods & ProceduresThe participants were 20 children with bilateral CIs (12 boys; eight girls; mean age at CI activation = 12.9 months). Vocabulary size was assessed with the Finnish version of the MacArthur Communicative Development Inventories (CDI) Infant Form and compared with normative data. Vocabulary composition was analysed in relation to vocabulary size. Growth curve modelling was implemented using a linear mixed model to analyse the effects of the following variables on early vocabulary growth: time, gender, maternal education, residual hearing with hearing aids, age at first hearing aid fitting and age at CI activation.
   Outcomes & ResultsDespite clear vocabulary growth over time, children with bilateral CIs lagged behind their age norms in receptive vocabulary during the first 12 months after CI activation. In expressive vocabulary, 35% of the children were able to catch up with their age norms, but 55% of the children lagged behind them. In receptive and expressive vocabularies of 1-20 words, analysis of different semantic categories indicated that social terms constituted the highest proportion. Nouns constituted the highest proportion in vocabularies of 101-400 words. The proportion of verbs remained below 20% and the proportion of function words and adjectives remained below 10% in the vocabularies of 1-400 words. There was a significant main effect of time, gender, maternal education and residual hearing with hearing aids before implantation on early receptive vocabulary growth. Time and residual hearing with hearing aids had a significant main effect also on expressive vocabulary growth.
   Conclusions & ImplicationsVocabulary development of children with bilateral CIs may be delayed. Thus, early vocabulary development needs to be assessed carefully in order to provide children and families with timely and targeted early intervention for vocabulary acquisition.
C1 [Valimaa, Taina; Kunnari, Sari] Univ Oulu, Fac Humanities, Res Unit Logoped, Child Language Res Ctr, POB 1000, FI-90014 Oulu, Finland.
   [Laukkanen-Nevala, Paivi] Tilastoneuvonta, Oulu, Finland.
   [Lonka, Eila] Univ Helsinki, Inst Behav Sci, Helsinki, Finland.
RP Valimaa, T (corresponding author), Univ Oulu, Fac Humanities, Res Unit Logoped, Child Language Res Ctr, POB 1000, FI-90014 Oulu, Finland.
EM taina.valimaa@oulu.fi
OI Kunnari, Sari/0000-0001-5290-4851; Valimaa, Taina/0000-0002-4826-6401
CR BATES E, 1994, J CHILD LANG, V21, P85, DOI 10.1017/S0305000900008680
   Boons T, 2012, ARCH PEDIAT ADOL MED, V166, P28, DOI 10.1001/archpediatrics.2011.748
   British Society of Audiology, 2011, REC PROC PUR AIRC BO
   Caselli C, 1999, J CHILD LANG, V26, P69, DOI 10.1017/S0305000998003687
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   De Hoog B. E., 2015, INT J LANGUAGE COMMU
   Duchesne L, 2009, J DEAF STUD DEAF EDU, V14, P465, DOI 10.1093/deafed/enp010
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Guo LY, 2015, J SPEECH LANG HEAR R, V58, P987, DOI 10.1044/2015_JSLHR-H-14-0135
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Holman MA, 2013, OTOL NEUROTOL, V34, P251, DOI 10.1097/MAO.0b013e31827d0922
   Houston DM, 2012, DEVELOPMENTAL SCI, V15, P448, DOI 10.1111/j.1467-7687.2012.01140.x
   Houston Derek M, 2005, Volta Rev, V105, P41
   Johnson C, 2010, J SPEECH LANG HEAR R, V53, P237, DOI 10.1044/1092-4388(2009/08-0139)
   Johnston JC, 2009, INT J AUDIOL, V48, P601, DOI 10.1080/14992020802665967
   Karlsson F., 1999, FINNISH ESSENTIAL GR
   Kosaner J, 2013, INT J PEDIATR OTORHI, V77, P1947, DOI 10.1016/j.ijporl.2013.09.008
   Kunnari S., 2006, PUHE JA KIELI, V26, P71
   Kunnari S, 2002, FIRST LANG, V22, P119, DOI DOI 10.1177/014272370202206501
   Le Normand MT, 2003, BRAIN COGNITION, V53, P257, DOI 10.1016/S0278-2626(03)00122-2
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   Lyytinen P., 1999, VARHAISEN KOMMUNIKAA
   Morgan G, 2014, COGNITIVE DEV, V29, P41, DOI 10.1016/j.cogdev.2013.10.002
   Nieminen P, 2013, EPIDEMIOL BIOSTAT PU, V10, DOI 10.2427/8854
   Nott P, 2009, EAR HEARING, V30, P541, DOI 10.1097/AUD.0b013e3181aa00ea
   Rinaldi P, 2013, INT J LANG COMM DIS, V48, P715, DOI 10.1111/1460-6984.12046
   Sarant J, 2014, EAR HEARING, V35, P396, DOI 10.1097/AUD.0000000000000022
   Silven M, 2004, J EDUC PSYCHOL, V96, P152, DOI 10.1037/0022-0663.96.1.152
   Stolt S., 2008, FIRST LANG, DOI [DOI 10.1177/0142723708091051, 10.1177/0142723708091051]
   Storkel HL, 2002, LANG SPEECH HEAR SER, V33, DOI 10.1044/0161-1461(2002/003)
   Szagun G, 2000, AUDIOL NEURO-OTOL, V5, P39, DOI 10.1159/000013864
   Szagun G, 2012, J SPEECH LANG HEAR R, V55, P1640, DOI 10.1044/1092-4388(2012/11-0119)
   Thal D, 2007, AM J SPEECH-LANG PAT, V16, P54, DOI 10.1044/1058-0360(2007/007)
   Yoshinaga-Itano C, 2010, OTOL NEUROTOL, V31, P1268, DOI 10.1097/MAO.0b013e3181f1ce07
NR 35
TC 13
Z9 13
U1 2
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1368-2822
EI 1460-6984
J9 INT J LANG COMM DIS
JI Int. J. Lang. Commun. Disord.
PD JAN-FEB
PY 2018
VL 53
IS 1
BP 3
EP 15
DI 10.1111/1460-6984.12322
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FS3WY
UT WOS:000419716300001
PM 28621001
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Stewart, ME
   Petrou, AM
   Ota, M
AF Stewart, Mary E.
   Petrou, Alexandra M.
   Ota, Mitsuhiko
TI Categorical Speech Perception in Adults with Autism Spectrum Conditions
SO JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS
LA English
DT Article
DE Categorical speech perception; Autism; Auditory discrimination;
   Language; Phoneme
ID ASPERGER-SYNDROME; QUOTIENT AQ; DISCRIMINATION; DISORDERS; PITCH;
   INDIVIDUALS; CHILDREN; PROSODY; ABILITY; TRAITS
AB This study tested whether individuals with autism spectrum conditions (n = 23) show enhanced discrimination of acoustic differences that signal a linguistic contrast (i.e., /g/ versus /k/ as in 'goat' and 'coat') and whether they process such differences in a less categorical fashion as compared with 23 IQ-matched typically developed adults. Tasks administered were nonverbal IQ, verbal IQ, 5 language measures, a speech perception task, and the ADOS. The speech perception task measured the discrimination of paired exemplars along the /g/-/k/ continuum. Individuals with autism spectrum conditions did not show enhanced discrimination of speech perception. Categorical speech perception was correlated with verbal ability of reading, lexical decision, and verbal IQ in individuals with autism spectrum conditions.
C1 [Stewart, Mary E.; Petrou, Alexandra M.] Heriot Watt Univ, Edinburgh EH14 4AS, Midlothian, Scotland.
   [Petrou, Alexandra M.] Newcastle Univ, Inst Neurosci, Newcastle Upon Tyne NE1 4LP, Tyne & Wear, England.
   [Ota, Mitsuhiko] Univ Edinburgh, Philosophy Psychol & Language Sci, Edinburgh EH8 9AD, Midlothian, Scotland.
RP Petrou, AM (corresponding author), Heriot Watt Univ, Edinburgh EH14 4AS, Midlothian, Scotland.; Petrou, AM (corresponding author), Newcastle Univ, Inst Neurosci, Newcastle Upon Tyne NE1 4LP, Tyne & Wear, England.
EM alexandra.petrou@ncl.ac.uk
RI Ota, Mitsuhiko/J-8403-2019
OI Ota, Mitsuhiko/0000-0003-3693-8490; Stewart, Mary/0000-0002-4365-8916
FU School of Life Sciences, Heriot-Watt doctoral studentship
FX This research was supported by a School of Life Sciences, Heriot-Watt
   doctoral studentship to Alexandra M. Petrou.
CR American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th
   Ashwin C, 2007, NEUROPSYCHOLOGIA, V45, P2, DOI 10.1016/j.neuropsychologia.2006.04.014
   Austin EJ, 2005, PERS INDIV DIFFER, V38, P451, DOI 10.1016/j.paid.2004.04.022
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Bonnel A, 2010, NEUROPSYCHOLOGIA, V48, P2465, DOI 10.1016/j.neuropsychologia.2010.04.020
   Boraston Z, 2007, NEUROPSYCHOLOGIA, V45, P1501, DOI 10.1016/j.neuropsychologia.2006.11.010
   Clark AI, 2013, AUTISM RES, V6, P332, DOI 10.1002/aur.1293
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   DEARY IJ, 1994, INTELLIGENCE, V18, P189, DOI 10.1016/0160-2896(94)90027-2
   DePape AMR, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044084
   FOWLER AE, 1991, PHONOLOGICAL PROCESSES IN LITERACY, P97
   Foxton JM, 2003, BRAIN, V126, P2703, DOI 10.1093/brain/awg274
   Frith U., 2003, AUTISM EXPLAINING EN, V2
   Fugard AJB, 2011, AUTISM, V15, P327, DOI 10.1177/1362361310371798
   Grube M., 2013, COGNITIVE NEUROSCIEN, V4, P3
   Haesen B, 2011, RES AUTISM SPECT DIS, V5, P701, DOI 10.1016/j.rasd.2010.11.006
   Hamel R, 2006, EDUC PSYCHOL MEAS, V66, P1039, DOI 10.1177/0013164406288169
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Heaton P, 2005, J AUTISM DEV DISORD, V35, P787, DOI 10.1007/s10803-005-0024-7
   Heaton P, 1998, MUSIC PERCEPT, V15, P291
   Heaton P, 1999, NEUROCASE, V5, P503, DOI 10.1093/neucas/5.6.503
   Heaton P, 2003, J CHILD PSYCHOL PSYC, V44, P543, DOI 10.1111/1469-7610.00143
   Heaton P, 2008, COGN NEUROPSYCHOL, V25, P771, DOI 10.1080/02643290802336277
   Hoekstra RA, 2007, ARCH PEDIAT ADOL MED, V161, P372, DOI 10.1001/archpedi.161.4.372
   Jarvinen-Pasley A, 2008, J AUTISM DEV DISORD, V38, P239, DOI 10.1007/s10803-007-0386-0
   Jones CRG, 2009, NEUROPSYCHOLOGY, V23, P718, DOI 10.1037/a0016360
   Kargas N, 2015, J AUTISM DEV DISORD, V45, P658, DOI 10.1007/s10803-014-2219-2
   Kjelgaard MM, 2001, LANG COGNITIVE PROC, V16, P287, DOI 10.1080/01690960042000058
   KOBAYASHI R, 1992, J AUTISM DEV DISORD, V22, P395, DOI 10.1007/BF01048242
   Korpilahti P, 2007, J AUTISM DEV DISORD, V37, P1539, DOI 10.1007/s10803-006-0271-2
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kujala T, 2005, NEUROSCI LETT, V383, P260, DOI 10.1016/j.neulet.2005.04.048
   Lev-Ari S, 2017, NETWORK SCI COGNITIV
   Lev-Ari S, 2016, J ACOUST SOC AM, V139, P3076, DOI 10.1121/1.4950811
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   Lord C, 1997, HDB ASD PERVASIVE DE, V2, P195
   McCann J, 2003, INT J LANG COMM DIS, V38, P325, DOI 10.1080/1368282031000154204
   Meilleur AAS, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103781
   Mottron L, 2000, J CHILD PSYCHOL PSYC, V41, P1057, DOI 10.1111/1469-7610.00693
   Mottron L, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P131
   Plaisted K, 1998, J CHILD PSYCHOL PSYC, V39, P765, DOI 10.1111/1469-7610.00375
   Ramirez-Esparza N, 2014, DEVELOPMENTAL SCI, V17, P880, DOI 10.1111/desc.12172
   Raven J. C., 2003, ADV PROGR MATRICES M
   Snowling M., 2000, DYSLEXIA
   Soulieres I, 2007, J AUTISM DEV DISORD, V37, P481, DOI 10.1007/s10803-006-0172-4
   Stewart ME, 2018, J AUTISM DEV DISORD, V48, P1350, DOI 10.1007/s10803-015-2517-3
   Stewart ME, 2008, COGNITION, V109, P157, DOI 10.1016/j.cognition.2008.07.010
   Swan D, 1997, J EXP CHILD PSYCHOL, V66, P18, DOI 10.1006/jecp.1997.2375
   VENTER A, 1992, J CHILD PSYCHOL PSYC, V33, P489, DOI 10.1111/j.1469-7610.1992.tb00887.x
   WALLEY AC, 1993, DEV REV, V13, P286, DOI 10.1006/drev.1993.1015
   Wilkinson GS, 1993, WIDE RANGE ACHIEVEME
   Woodbury-Smith MR, 2005, J AUTISM DEV DISORD, V35, P331, DOI 10.1007/s10803-005-3300-7
   Yau SH, 2016, DEVELOPMENTAL SCI, V19, P834, DOI 10.1111/desc.12328
NR 56
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0162-3257
EI 1573-3432
J9 J AUTISM DEV DISORD
JI J. Autism Dev. Disord.
PD JAN
PY 2018
VL 48
IS 1
BP 72
EP 82
DI 10.1007/s10803-017-3284-0
PG 11
WC Psychology, Developmental
SC Psychology
GA FS4SX
UT WOS:000419784300007
PM 28894969
DA 2021-02-24
ER

PT J
AU Giroud, N
   Lemke, U
   Reich, P
   Bauer, J
   Widmer, S
   Meyer, M
AF Giroud, Nathalie
   Lemke, Ulrike
   Reich, Philip
   Bauer, Julia
   Widmer, Susann
   Meyer, Martin
TI Are you surprised to hear this? Longitudinal spectral speech exposure in
   older compared to middle-aged normal hearing adults
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE aging; auditory learning; cognitive hearing; longitudinal plasticity;
   speech processing
ID IN-NOISE PERCEPTION; TIME-COURSE; EVOKED-POTENTIALS; DEPENDENT CHANGES;
   DISCRIMINATION; P300; P3A; EXPERIENCE; COMPONENTS; PLASTICITY
AB Cognitive abilities such as attention or working memory can support older adults during speech perception. However, cognitive abilities as well as speech perception decline with age, leading to the expenditure of effort during speech processing. This longitudinal study therefore investigated age-related differences in electrophysiological processes during speech discrimination and assessed the extent of enhancement to such cognitive auditory processes through repeated auditory exposure. For that purpose, accuracy and reaction time were compared between 13 older adults (62-76years) and 15 middle-aged (28-52years) controls in an active oddball paradigm which was administered at three consecutive measurement time points at an interval of 2wk, while EEG was recorded. As a standard stimulus, the nonsense syllable /a:?a/was used, while the nonsense syllable /a:sa/ and a morphing between /a:?a/ and /a:sa/ served as deviants. N2b and P3b ERP responses were evaluated as a function of age, deviant, and measurement time point using a data-driven topographical microstate analysis. From middle age to old age, age-related decline in attentive perception (as reflected in the N2b-related microstates) and in memory updating and attentional processes (as reflected in the P3b-related microstates) was found, as indicated by both lower neural responses and later onsets of the respective cortical networks, and in age-related changes in frontal activation during attentional stimulus processing. Importantly, N2b- and P3b-related microstates changed as a function of repeated stimulus exposure in both groups. This research therefore suggests that experience with auditory stimuli can support auditory neurocognitive processes in normal hearing adults into advanced age.
C1 [Giroud, Nathalie; Reich, Philip; Bauer, Julia; Widmer, Susann; Meyer, Martin] Univ Zurich, Res Unit Neuroplast & Learning Healthy Aging Brai, Dept Psychol, Zurich, Switzerland.
   [Giroud, Nathalie; Meyer, Martin] Univ Zurich, Univ Res Prior Program Dynam Healthy Aging, Dept Psychol, Zurich, Switzerland.
   [Lemke, Ulrike] Phonak AG, Sci & Technol, Stafa, Switzerland.
   [Meyer, Martin] Univ Klagenfurt, Dept Psychol Cognit Neurosci, Klagenfurt, Austria.
RP Giroud, N (corresponding author), Univ Zurich, Res Unit Neuroplast & Learning Healthy Aging Brai, Dept Psychol, Zurich, Switzerland.
EM nathalie.giroud@uzh.ch
RI Meyer, Martin/H-4307-2012
OI Meyer, Martin/0000-0003-2057-5533
FU 'Fonds zur Forderung des akademischen Nachwuchses' (FAN) of the 'Zurcher
   Universitatsvereins' (ZUNIV); Forschungskredit 'of the University of
   Zurich' [K-60241-01-01]; Phonak AG
FX This research was supported by the 'Fonds zur Forderung des akademischen
   Nachwuchses' (FAN) of the 'Zurcher Universitatsvereins' (ZUNIV) (MM), by
   the, Forschungskredit 'of the University of Zurich' (grant nr.
   K-60241-01-01 to NG), and by the Phonak AG. We thank Prof. Lutz Jancke
   for providing his EEG laboratory to record the data for this study and
   Allison Christen for invaluable comments on an earlier version of the
   manuscript. During the work on her dissertation, NG was a pre-doctoral
   fellow of the International Max Planck Research School on the Life
   Course.
CR Abe O, 2008, NEUROBIOL AGING, V29, P102, DOI 10.1016/j.neurobiolaging.2006.09.003
   Allen JS, 2005, NEUROBIOL AGING, V26, P1245, DOI 10.1016/j.neurobiolaging.2005.05.023
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   Atienza M, 2002, LEARN MEMORY, V9, P138, DOI 10.1101/lm.46502
   Bertoli S, 2005, JARO-J ASSOC RES OTO, V6, P207, DOI 10.1007/s10162-005-5029-6
   Boretzki M., 2011, SOUND FDN EARLY AMPL, P201
   Bosnyak DJ, 2004, CEREB CORTEX, V14, P1088, DOI 10.1093/cercor/bhh068
   Brattico E, 2003, NEUROREPORT, V14, P2489, DOI 10.1097/00001756-200312190-00039
   BRYDEN MP, 1977, NEUROPSYCHOLOGIA, V15, P617, DOI 10.1016/0028-3932(77)90067-7
   Buschermohle M., 2015, Z AUDIOLOGIE, V54, P6
   Buschermohle M., 2014, Z AUDIOLOGIE, V53, P139
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Davis SW, 2008, CEREB CORTEX, V18, P1201, DOI 10.1093/cercor/bhm155
   Debener S, 2002, INT J PSYCHOPHYSIOL, V46, P77, DOI 10.1016/S0167-8760(02)00072-7
   Doherty KA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00721
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fullgrabe C, 2013, AM J AUDIOL, V22, P313, DOI 10.1044/1059-0889(2013/12-0070)
   Gaal ZA, 2007, BIOL PSYCHOL, V76, P196, DOI 10.1016/j.biopsycho.2007.07.009
   Getzmann S, 2015, NEUROPSYCHOLOGIA, V70, P43, DOI 10.1016/j.neuropsychologia.2015.02.009
   Giroud N., BRAIN STRUCT FUNCT, P1
   Giroud N, 2017, HEARING RES, V353, P162, DOI 10.1016/j.heares.2017.06.012
   Giroud N, 2017, BIOL PSYCHOL, V123, P25, DOI 10.1016/j.biopsycho.2016.11.007
   Hopkins K, 2011, J ACOUST SOC AM, V130, P334, DOI 10.1121/1.3585848
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   JOHNSON R, 1986, PSYCHOPHYSIOLOGY, V23, P367, DOI 10.1111/j.1469-8986.1986.tb00649.x
   Juckel G, 2012, NEUROIMAGE, V60, P2027, DOI 10.1016/j.neuroimage.2012.02.019
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   KARNI A, 1993, NATURE, V365, P250, DOI 10.1038/365250a0
   Katayama J, 1998, PSYCHOPHYSIOLOGY, V35, P23, DOI 10.1017/S0048577298961479
   Koenig T., 2009, ELECT NEUROIMAGING, V2009, DOI DOI 10.1017/CBO9780511596889.009
   Koenig T, 2014, BRAIN TOPOGR, V27, P72, DOI 10.1007/s10548-013-0310-1
   Koenig T, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/938925
   Kok A, 1997, BIOL PSYCHOL, V45, P19, DOI 10.1016/S0301-0511(96)05221-0
   Kuchinsky SE, 2016, EXP AGING RES, V42, P64, DOI 10.1080/0361073X.2016.1108712
   Lavie L, 2015, J SPEECH LANG HEAR R, V58, P1601, DOI 10.1044/2015_JSLHR-H-14-0225
   Lemaitre H, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2010.07.013
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   Menning H, 2000, NEUROREPORT, V11, P817, DOI 10.1097/00001756-200003200-00032
   Michel C., 2009, ELECT NEUROIMAGING, P111, DOI DOI 10.1017/CBO9780511596889
   Moore DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107720
   Murray MM, 2008, BRAIN TOPOGR, V20, P249, DOI 10.1007/s10548-008-0054-5
   Naatanen R., 1983, TUTORIALS EVENT RELA, P119, DOI [10.1016/S0166-4115(08)62036-1, DOI 10.1016/S0166-4115(08)62036-1]
   Parbery-Clark A, 2012, FRONT AGING NEUROSCI, V4, DOI 10.3389/fnagi.2012.00030
   Parbery-Clark A, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2011.12.015
   Park DC, 2009, ANNU REV PSYCHOL, V60, P173, DOI 10.1146/annurev.psych.59.103006.093656
   PASCUALMARQUI RD, 1995, IEEE T BIO-MED ENG, V42, P658, DOI 10.1109/10.391164
   PERRIN F, 1987, ELECTROEN CLIN NEURO, V66, P75, DOI 10.1016/0013-4694(87)90141-6
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Pickles J.O., 2012, AN INTRODUCTION TO T
   POLICH J, 1995, BIOL PSYCHOL, V41, P103, DOI 10.1016/0301-0511(95)05130-9
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Raz N, 1997, CEREB CORTEX, V7, P268, DOI 10.1093/cercor/7.3.268
   Reinke KS, 2003, COGNITIVE BRAIN RES, V17, P781, DOI 10.1016/S0926-6410(03)00202-7
   Reuter-Lorenz PA, 2008, CURR DIR PSYCHOL SCI, V17, P177, DOI 10.1111/j.1467-8721.2008.00570.x
   Reuter-Lorenz PA, 2010, J GERONTOL B-PSYCHOL, V65, P405, DOI 10.1093/geronb/gbq035
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   Schiff S, 2008, CLIN NEUROPHYSIOL, V119, P1795, DOI 10.1016/j.clinph.2008.04.007
   Schmitt N., 2015, J AM ACAD AUDIOL, V27, P1
   SIMSON R, 1977, ELECTROEN CLIN NEURO, V43, P864, DOI 10.1016/0013-4694(77)90009-8
   SKRANDIES W, 1990, Brain Topography, V3, P137, DOI 10.1007/BF01128870
   Smits C, 2006, CLIN OTOLARYNGOL, V31, P436, DOI 10.1111/j.1749-4486.2006.01195.x
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P492, DOI 10.1016/j.cogbrainres.2005.03.002
   Stewart R, 2009, J AM ACAD AUDIOL, V20, P147, DOI 10.3766/jaaa.20.2.7
   Tisserand DJ, 2002, NEUROIMAGE, V17, P657, DOI 10.1006/nimg.2002.1173
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Tremblay KL, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00028
   Tremblay KL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010283
   vansDinteren R., 2014, PLOS ONE, V9
   Volpe U, 2007, BRAIN RES BULL, V73, P220, DOI 10.1016/j.brainresbull.2007.03.003
   Wagner M, 2013, BRAIN RES, V1522, P31, DOI 10.1016/j.brainres.2013.04.045
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Zorn P., 2000, AUDIOMORPHING SPRACH
NR 76
TC 4
Z9 4
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD JAN
PY 2018
VL 47
IS 1
BP 58
EP 68
DI 10.1111/ejn.13772
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA FS0SZ
UT WOS:000419485300006
PM 29119612
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Herrmann, B
   Johnsrude, IS
AF Herrmann, Bjoern
   Johnsrude, Ingrid S.
TI Attentional State Modulates the Effect of an Irrelevant Stimulus
   Dimension on Perception
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE time-frequency illusion; amplitude modulation rate; auditory perception;
   attention; distractor task
ID PITCH VELOCITY MODEL; WORKING-MEMORY; INATTENTIONAL DEAFNESS; SELECTIVE
   ATTENTION; FUNDAMENTAL-FREQUENCY; INTENSITY DIFFERENCES;
   SPEECH-PERCEPTION; TIME PERCEPTION; VISUAL-CORTEX; AUDITORY-TAU
AB Covariations of acoustic features provide redundancy in rapidly changing soundscapes: Hearing one feature enables a listener to infer another if these 2 features normally covary. However, it is unknown whether situational demands affect the degree to which covariations influence perceptual inferences. We exploited a perceptual interdependency between modulation rate and frequency and examined, in 6 experiments, whether challenging situations would alter the degree to which people rely on frequency information to make decisions about modulation rate. Participants listened to amplitude-modulated (AM) sounds with modulation rates (similar to 5 Hz) either decreasing or increasing over time and identified the direction of the rate change. Participants were instructed to ignore carrier frequency, which either decreased or increased (similar to 1,300 Hz) over time. We observed that participants were more likely to perceive the modulation rate as slowing down when frequency decreased and as speeding up when frequency increased (AM-rate change illusion). The magnitude of the illusion increased when uninformative cues (compared with informative cues) prohibited regulation of attention to sounds, and under distraction introduced by a concurrent visual motion-tracking task. The evidence suggests that the attentional state affects how strongly people rely on featural covariations to make perceptual inferences.
C1 [Herrmann, Bjoern] Univ Western Ontario, Brain & Mind Inst, Dept Psychol, London, ON N6A 5B7, Canada.
   [Johnsrude, Ingrid S.] Univ Western Ontario, Brain & Mind Inst, Sch Commun Sci & Disorders, Dept Psychol, London, ON, Canada.
RP Herrmann, B (corresponding author), Univ Western Ontario, Brain & Mind Inst, Dept Psychol, London, ON N6A 5B7, Canada.
EM herrmann.b@gmail.com
RI Johnsrude, Ingrid S/G-4694-2011; Herrmann, Bjorn/H-8000-2019
OI Johnsrude, Ingrid S/0000-0002-7810-1333; Herrmann,
   Bjorn/0000-0001-6362-3043
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP133450]; Brain and Mind Institute at the University
   of Western Ontario
FX Research was supported by the Canadian Institutes of Health Research
   (MOP133450 to I.S. Johnsrude) and the Brain and Mind Institute at the
   University of Western Ontario (postdoctoral fellowship Award to B.
   Herrmann). We thank Jackie Tsang, Kristian McCarthy, and Suvarna Moharir
   for their help during data acquisition. We also thank Alexander J.
   Billig for his helpful feedback on a previous version of the article.
CR ALAIN C, 1993, J ACOUST SOC AM, V94, P2434, DOI 10.1121/1.407464
   Alards-Tomalin D, 2014, J EXP PSYCHOL LEARN, V40, P555, DOI 10.1037/a0035031
   Alards-Tomalin D, 2013, PSYCHOL RES-PSYCH FO, V77, P480, DOI 10.1007/s00426-012-0438-8
   Alvarez GA, 2007, J VISION, V7, DOI 10.1167/7.13.14
   BLACK JW, 1961, LANG SPEECH, V4, P196, DOI 10.1177/002383096100400402
   Boltz MG, 2011, MUSIC PERCEPT, V28, P367, DOI 10.1525/MP.2011.28.4.367
   Boltz MG, 1998, PERCEPT PSYCHOPHYS, V60, P1357, DOI 10.3758/BF03207998
   BOND RN, 1982, J PSYCHOLINGUIST RES, V11, P539, DOI 10.1007/BF01067611
   Broze Y, 2013, MUSIC PERCEPT, V31, P19, DOI 10.1525/MP.2013.31.1.19
   Cavanagh P, 2005, TRENDS COGN SCI, V9, P349, DOI 10.1016/j.tics.2005.05.009
   CROWDER RG, 1995, MUSIC PERCEPT, V12, P379
   Dalton P, 2009, Q J EXP PSYCHOL, V62, P2126, DOI 10.1080/17470210903023646
   de Fockert JW, 2001, SCIENCE, V291, P1803, DOI 10.1126/science.1056496
   de Lange FP, 2013, J NEUROSCI, V33, P1400, DOI 10.1523/JNEUROSCI.1094-12.2013
   Duncan J, 1997, NATURE, V387, P808, DOI 10.1038/42947
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   FELDSTEIN S, 1981, LANG SPEECH, V24, P387, DOI 10.1177/002383098102400408
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   GARNER WR, 1976, COGNITIVE PSYCHOL, V8, P98, DOI 10.1016/0010-0285(76)90006-2
   Green JA, 2011, EMOTION, V11, P1124, DOI 10.1037/a0024173
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Helbig HB, 2008, J VISION, V8, DOI 10.1167/8.1.21
   Henry MJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070646
   Henry MJ, 2009, ATTEN PERCEPT PSYCHO, V71, P1399, DOI 10.3758/APP.71.6.1399
   Henry MJ, 2009, J EXP PSYCHOL HUMAN, V35, P551, DOI 10.1037/0096-1523.35.2.551
   Herrmann B, 2014, NEUROIMAGE, V101, P370, DOI 10.1016/j.neuroimage.2014.07.026
   Herrmann B, 2013, J NEUROSCI, V33, P15799, DOI 10.1523/JNEUROSCI.1434-13.2013
   Hester R, 2005, MEM COGNITION, V33, P221, DOI 10.3758/BF03195311
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   HUANG YL, 1982, PERCEPT PSYCHOPHYS, V32, P7, DOI 10.3758/BF03204862
   Intaite M, 2014, J VISION, V14, DOI 10.1167/14.1.13
   JONES B, 1982, PSYCHOL BULL, V91, P128, DOI 10.1037/0033-2909.91.1.128
   Keitel C, 2013, NEUROIMAGE, V70, P240, DOI 10.1016/j.neuroimage.2012.12.046
   Kluender K. R, 2013, VOWEL INHERENT SPECT, P117
   Konstantinou N, 2013, J EXP PSYCHOL HUMAN, V39, P919, DOI 10.1037/a0033037
   Lake JI, 2014, ACTA PSYCHOL, V149, P169, DOI 10.1016/j.actpsy.2014.03.010
   Lavie N, 2005, PSYCHON B REV, V12, P669, DOI 10.3758/BF03196756
   Lavie N, 2005, TRENDS COGN SCI, V9, P75, DOI 10.1016/j.tics.2004.12.004
   Lavie N, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0205
   Leek MR, 2001, PERCEPT PSYCHOPHYS, V63, P1279, DOI 10.3758/BF03194543
   Lewicki MS, 2002, NAT NEUROSCI, V5, P356, DOI 10.1038/nn831
   Macdonald JSP, 2008, J EXP PSYCHOL HUMAN, V34, P1078, DOI 10.1037/0096-1523.34.5.1078
   Macdonald JSP, 2011, ATTEN PERCEPT PSYCHO, V73, P1780, DOI 10.3758/s13414-011-0144-4
   Macken WJ, 2003, J EXP PSYCHOL HUMAN, V29, P43, DOI 10.1037/0096-1523.29.1.43
   Macmillan N, 2004, DETECTION THEORY USE
   Masutomi K, 2016, J EXP PSYCHOL HUMAN, V42, P386, DOI 10.1037/xhp0000147
   Mattys SL, 2013, PSYCHOL SCI, V24, P1606, DOI 10.1177/0956797612474323
   Mattys SL, 2014, PSYCHOL AGING, V29, P150, DOI 10.1037/a0035387
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   MELARA RD, 1990, PERCEPT PSYCHOPHYS, V48, P169, DOI 10.3758/BF03207084
   MELARA RD, 1989, J EXP PSYCHOL HUMAN, V15, P69, DOI 10.1037/0096-1523.15.1.69
   Molloy K, 2015, J NEUROSCI, V35, P16046, DOI 10.1523/JNEUROSCI.2931-15.2015
   Neuhoff J. G., 2004, ECOLOGICAL PSYCHOACO, P249
   Neuhoff JG, 1999, J EXP PSYCHOL HUMAN, V25, P1050, DOI 10.1037/0096-1523.25.4.1050
   PASHLER H, 1994, PSYCHOL BULL, V116, P220, DOI 10.1037/0033-2909.116.2.220
   Pfeuty M, 2010, ATTEN PERCEPT PSYCHO, V72, P763, DOI 10.3758/APP.72.3.763
   Pisoni D. B., 1987, PSYCHOPHYSICS SPEECH, P155
   PYLYSHYN Z W, 1988, Spatial Vision, V3, P179, DOI 10.1163/156856888X00122
   Rahnev D, 2011, NAT NEUROSCI, V14, P1513, DOI 10.1038/nn.2948
   Raveh D, 2015, ATTEN PERCEPT PSYCHO, V77, P483, DOI 10.3758/s13414-014-0776-2
   Rees G, 2001, NEUROPSYCHOLOGIA, V39, P937, DOI 10.1016/S0028-3932(01)00016-1
   Reynolds JH, 2003, NEURON, V37, P853, DOI 10.1016/S0896-6273(03)00097-7
   Reynolds JH, 2000, NEURON, V26, P703, DOI 10.1016/S0896-6273(00)81206-4
   Rosenthal R, 2003, PSYCHOL METHODS, V8, P492, DOI 10.1037/1082-989X.8.4.492
   Schneider KA, 2011, J VISION, V11, DOI 10.1167/11.13.7
   Schneider KA, 2008, J VISION, V8, DOI 10.1167/8.15.3
   Scholl BJ, 2009, COMPUTATION, COGNITION, AND PYLYSHYN, P49
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   SHIGENO S, 1993, PERCEPT PSYCHOPHYS, V54, P682, DOI 10.3758/BF03211792
   SHIGENO S, 1986, PERCEPT PSYCHOPHYS, V40, P9, DOI 10.3758/BF03207588
   Smith EC, 2006, NATURE, V439, P978, DOI 10.1038/nature04485
   STERNBERG S, 1966, SCIENCE, V153, P652, DOI 10.1126/science.153.3736.652
   Summerfield C, 2016, TRENDS COGN SCI, V20, P401, DOI 10.1016/j.tics.2016.03.008
   Tombu M, 2008, COGNITION, V108, P1, DOI 10.1016/j.cognition.2007.12.014
   Topbas O, 2012, J COMMUN DISORD, V45, P173, DOI 10.1016/j.jcomdis.2012.02.001
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Treue S, 1999, NATURE, V399, P575, DOI 10.1038/21176
   Treue S, 2001, TRENDS NEUROSCI, V24, P295, DOI 10.1016/S0166-2236(00)01814-2
   Tyler LK, 2008, PHILOS T R SOC B, V363, P1037, DOI 10.1098/rstb.2007.2158
   Vallesi A, 2014, COGNITION, V130, P141, DOI 10.1016/j.cognition.2013.10.006
   Walsh V, 2003, TRENDS COGN SCI, V7, P483, DOI 10.1016/j.tics.2003.09.002
   Williford T, 2006, J NEUROPHYSIOL, V96, P40, DOI 10.1152/jn.01207.2005
   Wilson D., 2013, J VISION, V13, P1295
   Witt JK, 2015, PERCEPTION, V44, P289, DOI 10.1068/p7908
   Zaske R, 2016, ATTEN PERCEPT PSYCHO, V78, P1488, DOI 10.3758/s13414-016-1119-2
NR 86
TC 5
Z9 5
U1 0
U2 11
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD JAN
PY 2018
VL 44
IS 1
BP 89
EP 105
DI 10.1037/xhp0000432
PG 17
WC Psychology; Psychology, Experimental
SC Psychology
GA FR9IL
UT WOS:000419387200010
PM 28447846
DA 2021-02-24
ER

PT J
AU Stevenson, RA
   Baum, SH
   Krueger, J
   Newhouse, PA
   Wallace, MT
AF Stevenson, Ryan A.
   Baum, Sarah H.
   Krueger, Juliane
   Newhouse, Paul A.
   Wallace, Mark T.
TI Links Between Temporal Acuity and Multisensory Integration Across Life
   Span
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE multisensory integration; aging; speech perception; development;
   temporal processing
ID VISUAL SPEECH-PERCEPTION; AUDIOVISUAL SPEECH; BINDING WINDOW;
   DEVELOPMENTAL-CHANGES; SYNCHRONY DETECTION; AUTISM; CHILDREN; INFANTS;
   OLDER; ATTENTION
AB The temporal relationship between individual pieces of information from the different sensory modalities is one of the stronger cues to integrate such information into a unified perceptual gestalt, conveying numerous perceptual and behavioral advantages. Temporal acuity, however, varies greatly over the life span. It has previously been hypothesized that changes in temporal acuity in both development and healthy aging may thus play a key role in integrative abilities. This study tested the temporal acuity of 138 individuals ranging in age from 5 to 80. Temporal acuity and multisensory integration abilities were tested both within and across modalities (audition and vision) with simultaneity judgment and temporal order judgment tasks. We observed that temporal acuity, both within and across modalities, improved throughout development into adulthood and subsequently declined with healthy aging, as did the ability to integrate multisensory speech information. Of importance, throughout development, temporal acuity of simple stimuli (i.e., flashes and beeps) predicted individuals' abilities to integrate more complex speech information. However, in the aging population, although temporal acuity declined with healthy aging and was accompanied by declines in integrative abilities, temporal acuity was not able to predict integration at the individual level. Together, these results suggest that the impact of temporal acuity on multisensory integration varies throughout the life span. Although the maturation of temporal acuity drives the rise of multisensory integrative abilities during development, it is unable to account for changes in integrative abilities in healthy aging. The differential relationships between age, temporal acuity, and multisensory integration suggest an important role for experience in these processes.
   Public Significance Statement
   How individuals combine information across the senses, known as multisensory integration, greatly influences how they perceive the world around them. One driving factor in multisensory integration is the relative timing of this information-when individuals sense auditory and visual information at the same time, it is a strong indicator that they should perceive these two inputs as a single object or event. This study shows that throughout development, from childhood, through adolescence, and into adulthood, individuals' ability to perceive the timing of sensory inputs accurately drives their multisensory integrative abilities. Contrasting that, as they age and their ability to perceive the timing of sensory inputs declines, this does not lead to a decrease in their ability to combine sensory information across modalities. Taken together, this suggests that the impact of temporal perception on multisensory integration changes across the life span.
C1 [Stevenson, Ryan A.] Univ Western Ontario, Brain & Mind Inst, Dept Psychol, Westminster Hall,361 Windermere Rd, London, ON N6A 3K7, Canada.
   [Baum, Sarah H.] Univ Washington, Dept Psychol, Nashville, TN USA.
   [Baum, Sarah H.] Vanderbilt Brain Inst, Nashville, TN USA.
   [Krueger, Juliane; Wallace, Mark T.] Vanderbilt Univ, Nashville, TN 37235 USA.
   [Newhouse, Paul A.; Wallace, Mark T.] Vanderbilt Univ, Med Ctr, Nashville, TN 37235 USA.
   [Newhouse, Paul A.] Tennessee Valley Vet Affairs Med Ctr, Nashville, TN USA.
RP Stevenson, RA (corresponding author), Univ Western Ontario, Brain & Mind Inst, Dept Psychol, Westminster Hall,361 Windermere Rd, London, ON N6A 3K7, Canada.
EM rsteve28@uwo.ca
RI Miller, Sarah H. Baum/H-3252-2019
OI Miller, Sarah H. Baum/0000-0002-5588-5876
FU University of Western Ontario Faculty Development Research Fund; Social
   Sciences and Humanities Research Council of CanadaSocial Sciences and
   Humanities Research Council of Canada (SSHRC) [R5502A07]; National
   Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIH CA183492, NIH
   HD083211]; Autism Speaks Meixner Postdoctoral Fellowship in
   Translational Research [9717]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE
   OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH Eunice
   Kennedy Shriver National Institute of Child Health & Human Development
   (NICHD) [U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211] Funding Source: NIH RePORTER; NATIONAL CANCER
   INSTITUTEUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)
   [R21CA183492, R21CA183492] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [F32DC011993, F32DC011993] Funding Source: NIH RePORTER
FX Support for this work for Ryan A. Stevenson came from the University of
   Western Ontario Faculty Development Research Fund and Social Sciences
   and Humanities Research Council of Canada Insight Grant R5502A07.
   Support for this work for Mark T. Wallace came from National Institutes
   of Health Grants NIH CA183492 and NIH HD083211. Support for this work
   for Sarah H. Baum came from Autism Speaks Meixner Postdoctoral
   Fellowship in Translational Research #9717.
CR Altieri N, 2015, BRAIN TOPOGR, V28, P479, DOI 10.1007/s10548-013-0333-7
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Baart M, 2010, NEUROSCI LETT, V471, P100, DOI 10.1016/j.neulet.2010.01.019
   BAHRICK LE, 1987, INFANT BEHAV DEV, V10, P387, DOI 10.1016/0163-6383(87)90039-7
   BAHRICK LE, 1988, CHILD DEV, V59, P197, DOI 10.2307/1130402
   BAHRICK LE, 1983, INFANT BEHAV DEV, V6, P429, DOI 10.1016/S0163-6383(83)90241-2
   Barsz K, 2002, NEUROBIOL AGING, V23, P565, DOI 10.1016/S0197-4580(02)00008-8
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Chan YM, 2014, J VISION, V14, DOI 10.1167/14.11.13
   Chan YM, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00226
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Collignon O, 2013, CORTEX, V49, P1704, DOI 10.1016/j.cortex.2012.06.001
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   de Boer-Schellekens L, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00008
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Ernst MO, 2008, CURR BIOL, V18, pR519, DOI 10.1016/j.cub.2008.05.002
   Fiacconi CM, 2013, EXP AGING RES, V39, P179, DOI 10.1080/0361073X.2013.761896
   Fister JK, 2016, NEUROPSYCHOLOGIA, V88, P92, DOI 10.1016/j.neuropsychologia.2016.02.016
   GELFAND SA, 1980, J ACOUST SOC AM, V68, P1258, DOI 10.1121/1.385117
   Gordon MS, 2009, EXP AGING RES, V35, P202, DOI 10.1080/03610730902720398
   Gordon-Salant S, 1999, J SPEECH LANG HEAR R, V42, P300, DOI 10.1044/jslhr.4202.300
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Gori M, 2008, CURR BIOL, V18, P694, DOI 10.1016/j.cub.2008.04.036
   Grossman RB, 2015, AUTISM RES, V8, P307, DOI 10.1002/aur.1447
   Grossman RB, 2009, J CHILD PSYCHOL PSYC, V50, P491, DOI 10.1111/j.1469-7610.2008.02002.x
   Guest D, 2015, J VISION, V15, DOI 10.1167/15.14.10
   Hahn N, 2014, NEUROSCI BIOBEHAV R, V47, P384, DOI 10.1016/j.neubiorev.2014.09.007
   Hairston WD, 2005, EXP BRAIN RES, V166, P474, DOI 10.1007/s00221-005-2387-6
   Harrar V, 2014, CURR BIOL, V24, P531, DOI 10.1016/j.cub.2014.01.029
   HERSHENSON M, 1962, J EXP PSYCHOL, V63, P289, DOI 10.1037/h0039516
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Hillock-Dunn A, 2012, DEVELOPMENTAL SCI, V15, P688, DOI 10.1111/j.1467-7687.2012.01171.x
   Hockley N., 1994, J ACOUST SOC AM, V96, P3309, DOI DOI 10.1121/1.410782
   Hugenschmidt CE, 2009, EXP BRAIN RES, V198, P273, DOI 10.1007/s00221-009-1816-3
   Kaganovich N, 2016, DEV PSYCHOL, V52, P232, DOI 10.1037/dev0000073
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lewkowicz DJ, 2014, CHILD DEV, V85, P685, DOI 10.1111/cdev.12142
   Lewkowicz DJ, 1996, J EXP PSYCHOL HUMAN, V22, P1094, DOI 10.1037/0096-1523.22.5.1094
   LEWKOWICZ DJ, 1986, INFANT BEHAV DEV, V9, P335, DOI 10.1016/0163-6383(86)90008-1
   LEWKOWICZ DJ, 1992, INFANT BEHAV DEV, V15, P297, DOI 10.1016/0163-6383(92)80002-C
   Lovelace CT, 2003, COGNITIVE BRAIN RES, V17, P447, DOI 10.1016/S0926-6410(03)00160-5
   MASSARO DW, 1984, CHILD DEV, V55, P1777, DOI 10.1111/j.1467-8624.1984.tb00420.x
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Murray MM, 2011, NEURAL BASEMULTISE
   Nardini M, 2008, CURR BIOL, V18, P689, DOI 10.1016/j.cub.2008.04.021
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Ozmeral EJ, 2016, NEUROBIOL AGING, V43, P72, DOI 10.1016/j.neurobiolaging.2015.12.024
   Patten Elena, 2014, Autism Res Treat, V2014, P678346, DOI 10.1155/2014/678346
   Peiffer AM, 2007, NEUROREPORT, V18, P1077, DOI 10.1097/WNR.0b013e3281e72ae7
   Quinto L, 2010, ATTEN PERCEPT PSYCHO, V72, P1450, DOI 10.3758/APP.72.6.1450
   ROBIN DA, 1989, PSYCHOL AGING, V4, P144
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   Saul AB, 2002, J NEUROSCI, V22, P2945, DOI 10.1523/JNEUROSCI.22-07-02945.2002
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Senkowski D, 2007, NEUROPSYCHOLOGIA, V45, P561, DOI 10.1016/j.neuropsychologia.2006.01.013
   Setti A, 2011, NEUROREPORT, V22, P554, DOI 10.1097/WNR.0b013e328348c731
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   SPELKE ES, 1979, DEV PSYCHOL, V15, P626
   Stein B. E., 1993, MERGING SENSES
   Stein B. E., 2012, NEW HDB MULTISENSORY
   Stein BE, 1996, PROG BRAIN RES, V112, P289
   Stevenson R. A., AUTISM IN PRESS
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P3161, DOI 10.1007/s10803-014-2179-6
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stevenson RA, 2013, EXP BRAIN RES, V227, P249, DOI 10.1007/s00221-013-3507-3
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Stevenson RA, 2012, BRAIN TOPOGR, V25, P308, DOI 10.1007/s10548-012-0220-7
   Stevenson RA, 2012, EXP BRAIN RES, V219, P121, DOI 10.1007/s00221-012-3072-1
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Treisman A, 2006, VIS COGN, V14, P411, DOI 10.1080/13506280500195250
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   Tye-Murray N, 2010, EAR HEARING, V31, P636, DOI 10.1097/AUD.0b013e3181ddf7ff
   Van Ingelghem M, 2001, NEUROREPORT, V12, P3603, DOI 10.1097/00001756-200111160-00046
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Wallace MT, 1996, J NEUROPHYSIOL, V76, P1246
   Wang YC, 2005, CEREB CORTEX, V15, P403, DOI 10.1093/cercor/bhh143
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Yang Y, 2009, BRAIN RES, V1274, P21, DOI 10.1016/j.brainres.2009.04.015
NR 97
TC 19
Z9 19
U1 1
U2 21
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD JAN
PY 2018
VL 44
IS 1
BP 106
EP 116
DI 10.1037/xhp0000424
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA FR9IL
UT WOS:000419387200011
PM 28447850
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Lawyer, LA
   Corina, DP
AF Lawyer, Laurel A.
   Corina, David P.
TI Putting underspecification in context: ERP evidence for sparse
   representations in morphophonological alternations
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Underspecification; prefix processing; LAN; phonological alternation;
   phonological context
ID MISMATCH NEGATIVITY; SPEECH-PERCEPTION; ELECTROPHYSIOLOGICAL EVIDENCE;
   NEUROPHYSIOLOGICAL EVIDENCE; NEUROBIOLOGICAL EVIDENCE; BRAIN POTENTIALS;
   ASYMMETRIES; WORD; COMPONENT; RECOGNITION
AB Numerous studies have shown evidence for a sparse lexicon in speech perception, often in the guise of underspecification, where certain information is omitted in the specification of phonological forms. While previous work has made a good case for underspecifying certain features of single speech sounds, the role of phonological context in underspecification has been overlooked. Contextually-mediated underspecification is particularly relevant to conceptualizations of the lexicon, as it is couched in item-specific (as opposed to phoneme-specific) patterning. In this study, we present behavioural and ERP evidence that surrounding phonological context may trigger underspecified lexical forms, using regular morphophonological alternations in English.
C1 [Lawyer, Laurel A.] Univ Essex, Dept Language & Linguist, Colchester, Essex, England.
   [Corina, David P.] Univ Calif Davis, Dept Psychol, Dept Linguist, Davis, CA 95616 USA.
   [Corina, David P.] Univ Calif Davis, Ctr Mind & Brain, Davis, CA 95616 USA.
RP Lawyer, LA (corresponding author), Univ Essex, Dept Language & Linguist, Colchester, Essex, England.
EM l.lawyer@essex.ac.uk
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 DC014767-01]; UC
   Davis & Humanities Graduate Research Awards; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC014767, R01DC014767, R01DC014767, R01DC014767, R01DC014767,
   R01DC014767] Funding Source: NIH RePORTER
FX This work supported in part by the National Institutes of Health under
   Grant R01 DC014767-01 awarded to DP Corina and two UC Davis & Humanities
   Graduate Research Awards awarded to LA Lawyer.
CR Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Baldi P., 1985, HIST SEMANTICS HIST, V29, P33
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bauer Laurie, 1983, ENGLISH WORD FORMATI
   Boersma P., 2011, PRAAT DOING PHONETIC
   Brown J.I., 1993, NELSON DENNY READING
   Bybee J., 2010, LANGUAGE USAGE COGNI
   Bybee J., 2003, PHONOLOGY LANGUAGE U, V94
   Cheng XR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091988
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Cornell SA, 2013, J EXP PSYCHOL HUMAN, V39, P757, DOI 10.1037/a0030862
   Cornell SA, 2011, BRAIN RES, V1394, P79, DOI 10.1016/j.brainres.2011.04.001
   Coulson S, 1998, LANG COGNITIVE PROC, V13, P21, DOI 10.1080/016909698386582
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   FRIEDERICI AD, 1993, COGNITIVE BRAIN RES, V1, P183, DOI 10.1016/0926-6410(93)90026-2
   Friedrich Claudia K, 2006, Behav Brain Funct, V2, P36, DOI 10.1186/1744-9081-2-36
   Friedrich CK, 2008, J EXP PSYCHOL HUMAN, V34, P1545, DOI 10.1037/a0012481
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gaskell MG, 1998, J EXP PSYCHOL HUMAN, V24, P380, DOI 10.1037/0096-1523.24.2.380
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Hagoort P, 2000, NEUROPSYCHOLOGIA, V38, P1518, DOI 10.1016/S0028-3932(00)00052-X
   Halle M., 1959, SOUND PATTERN RUSSIA, V1
   Hasting AS, 2008, J COGNITIVE NEUROSCI, V20, P1207, DOI 10.1162/jocn.2008.20083
   Hestvik A, 2016, BRAIN LANG, V152, P28, DOI 10.1016/j.bandl.2015.10.007
   Hunter CR, 2013, BRAIN LANG, V127, P463, DOI 10.1016/j.bandl.2013.09.006
   Hwang SOK, 2010, PHONOLOGY, V27, P205, DOI 10.1017/S0952675710000102
   Inkelas Sharon, 1995, P N E LINGUISTIC SOC, V25, P287
   Johnson K., 2007, EXPT APPROACHES PHON, P25
   Kiparsky Paul, 1982, LINGUISTICS MORNING, P3
   Krott A, 2006, J COGNITIVE NEUROSCI, V18, P1616, DOI 10.1162/jocn.2006.18.10.1616
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lahiri A, 2002, PHONOL PHONET, V4-1, P637
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Lawyer LA, 2018, LANG COGN NEUROSCI, V33, P50, DOI 10.1080/23273798.2017.1359635
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   MCMAHON AMS, 1992, T PHILOL SOC, V90, P81, DOI 10.1111/j.1467-968X.1992.tb00424.x
   Mitterer H, 2003, PERCEPT PSYCHOPHYS, V65, P956, DOI 10.3758/BF03194826
   Mohanan Karuvannur P., 1982, THESIS
   Neurobehavioral Systems Inc, 2014, PRES SOFTW
   O'Rourke TB, 2002, BIOL PSYCHOL, V60, P121, DOI 10.1016/S0301-0511(02)00045-5
   Opitz A, 2013, LANGUAGE, V89, P231, DOI 10.1353/lan.2013.0033
   Perrin F, 2003, COGNITIVE BRAIN RES, V17, P36, DOI 10.1016/S0926-6410(03)00078-8
   Politzer-Ahles S, 2016, J EXP PSYCHOL HUMAN, V42, P1547, DOI 10.1037/xhp0000242
   PRAAMSTRA P, 1994, J COGNITIVE NEUROSCI, V6, P204, DOI 10.1162/jocn.1994.6.3.204
   Roll M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01004
   Rossi S, 2005, NEUROSCI LETT, V384, P228, DOI 10.1016/j.neulet.2005.04.077
   Rossi S, 2013, BRAIN LANG, V127, P404, DOI 10.1016/j.bandl.2013.02.009
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Scharinger M, 2010, J NEUROLINGUIST, V23, P383, DOI 10.1016/j.jneuroling.2010.02.005
   Schluter K, 2016, LANG COGN NEUROSCI, V31, P728, DOI 10.1080/23273798.2016.1151058
   Shen EY, 2013, LANG COGNITIVE PROC, V28, P498, DOI 10.1080/01690965.2011.650900
   Sumner M, 2005, J MEM LANG, V52, P322, DOI 10.1016/j.jml.2004.11.004
   Tavabi K, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004452
   The MathWorks I., 2012, MATLAB REL 2012A
   Trubetzkoy N., 1969, PRINCIPLES PHONOLOGY
NR 58
TC 2
Z9 2
U1 0
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2018
VL 33
IS 1
BP 50
EP 64
DI 10.1080/23273798.2017.1359635
PG 15
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA FQ9UM
UT WOS:000418707200005
PM 29963576
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Kalashnikova, M
   Goswami, U
   Burnham, D
AF Kalashnikova, Marina
   Goswami, Usha
   Burnham, Denis
TI Mothers speak differently to infants at-risk for dyslexia
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID DIRECTED SPEECH; FAMILIAL RISK; DEVELOPMENTAL DYSLEXIA; VOWEL
   HYPERARTICULATION; CHILDREN; AGE; PERCEPTION; ASSOCIATION; PRECURSORS;
   HEARING
AB Dyslexia is a neurodevelopmental disorder manifested in deficits in reading and spelling skills that is consistently associated with difficulties in phonological processing. Dyslexia is genetically transmitted, but its manifestation in a particular individual is thought to depend on the interaction of epigenetic and environmental factors. We adopt a novel interactional perspective on early linguistic environment and dyslexia by simultaneously studying two pre-existing factors, one maternal and one infant, that may contribute to these interactions; and two behaviours, one maternal and one infant, to index the effect of these factors. The maternal factor is whether mothers are themselves dyslexic or not (with/without dyslexia) and the infant factor is whether infants are at-/not-at family risk for dyslexia (due to their mother or father being dyslexic). The maternal behaviour is mothers' infant-directed speech (IDS), which typically involves vowel hyperarticulation, thought to benefit speech perception and language acquisition. The infant behaviour is auditory perception measured by infant sensitivity to amplitude envelope rise time, which has been found to be reduced in dyslexic children. Here, at-risk infants showed significantly poorer acoustic sensitivity than not-at-risk infants and mothers only hyperarticulated vowels to infants who were not at-risk for dyslexia. Mothers' own dyslexia status had no effect on IDS quality. Parental speech input is thus affected by infant risk status, with likely consequences for later linguistic development.
C1 [Kalashnikova, Marina; Burnham, Denis] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
   [Goswami, Usha] Univ Cambridge, Ctr Neurosci Educ, Cambridge, England.
RP Kalashnikova, M (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
EM m.kalashnikova@westernsydney.edu.au
RI Kalashnikova, Marina/B-6590-2019; Burnham, Denis/L-3742-2019
OI Kalashnikova, Marina/0000-0002-7924-8687; Burnham,
   Denis/0000-0002-1980-3458; Goswami, Usha/0000-0001-7858-2336
FU Australian Research CouncilAustralian Research Council [DP110105123]
FX This research was supported by Australian Research Council grant
   DP110105123, 'The Seeds of Literacy', to the third and second authors.
   We would like to thank all the parents and infants for their valuable
   time and interest in this research.
CR Boersma P., 2005, PRAAT DOING PHONETIC
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Breaux K. C., 2010, WECHSLER INDIVIDUAL
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   Burnham D., 2010, ASSTA M MELB AUSTR
   Englund K, 2006, INFANT CHILD DEV, V15, P139, DOI 10.1002/icd.445
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Gallagher A, 2000, J CHILD PSYCHOL PSYC, V41, P203, DOI 10.1111/1469-7610.00601
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2013, CORTEX, V49, P1363, DOI 10.1016/j.cortex.2012.05.005
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Goswami U, 2010, READ WRIT, V23, P995, DOI 10.1007/s11145-009-9186-6
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Guttorm TK, 2010, J LEARN DISABIL-US, V43, P391, DOI 10.1177/0022219409345005
   Hakvoort B, 2015, CORTEX, V63, P90, DOI 10.1016/j.cortex.2014.08.013
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hasson U, 2012, TRENDS COGN SCI, V16, P114, DOI 10.1016/j.tics.2011.12.007
   Igarashi Y, 2013, J ACOUST SOC AM, V134, P1283, DOI 10.1121/1.4812755
   Kaplan PS, 2002, PSYCHOL SCI, V13, P268, DOI 10.1111/1467-9280.00449
   Kitamura C, 2003, INFANCY, V4, P85, DOI 10.1207/S15327078IN0401_5
   Kitamura C, 2009, INFANCY, V14, P77, DOI 10.1080/15250000802569777
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Lam C, 2012, DEVELOPMENTAL SCI, V15, P212, DOI 10.1111/j.1467-7687.2011.01118.x
   Lam C, 2010, J SPEECH LANG HEAR R, V53, P543, DOI 10.1044/1092-4388(2010/09-0126)
   Leong V., 2014, INT SPEECH COMMUN AS, P2563
   Leppanen PHT, 2010, CORTEX, V46, P1362, DOI 10.1016/j.cortex.2010.06.003
   Leppanen PHT, 2002, DEV NEUROPSYCHOL, V22, P407, DOI 10.1207/S15326942dn2201_4
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   Lyytinen H, 2004, ANN DYSLEXIA, V54, P184, DOI 10.1007/s11881-004-0010-3
   Lyytinen P, 2003, J LEARN DISABIL-US, V36, P74, DOI 10.1177/00222194030360010901
   Ma WY, 2011, LANG LEARN DEV, V7, P185, DOI 10.1080/15475441.2011.579839
   Martin A, 2015, PSYCHOL SCI, V26, P341, DOI 10.1177/0956797614562453
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Munhall KG, 2009, J ACOUST SOC AM, V125, P384, DOI 10.1121/1.3035829
   Papousek M, 2007, INFANT BEHAV DEV, V30, P258, DOI 10.1016/j.infbeh.2007.02.003
   Parsons CE, 2010, PROG NEUROBIOL, V91, P220, DOI 10.1016/j.pneurobio.2010.03.001
   Pennington BF, 2001, CHILD DEV, V72, P816, DOI 10.1111/1467-8624.00317
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Petelin R., 2003, COOL EDIT PRO 2 USE
   Plakas A, 2013, CORTEX, V49, P1034, DOI 10.1016/j.cortex.2012.02.013
   Rashotte, 1999, TOWRE 2 TEST WORD RE
   Richardson U, 2003, DEV NEUROPSYCHOL, V23, P385, DOI 10.1207/S15326942DN2303_5
   SCARBOROUGH HS, 1993, FIRST LANG, V13, P51
   Schrank F.A., 2001, WOODCOCKJOHNSON III
   Smith NA, 2008, INFANCY, V13, P410, DOI 10.1080/15250000802188719
   Snowling M., 2000, DYSLEXIA
   Soderstrom M, 2008, J CHILD LANG, V35, P869, DOI 10.1017/S0305000908008763
   Song JY, 2010, J ACOUST SOC AM, V128, P389, DOI 10.1121/1.3419786
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   Uther M, 2007, SPEECH COMMUN, V49, P2, DOI 10.1016/j.specom.2006.10.003
   van der Leij A, 2013, DYSLEXIA, V19, P191, DOI 10.1002/dys.1463
   van Zuijen TL, 2013, DEVELOPMENTAL SCI, V16, P554, DOI 10.1111/desc.12049
   Wechsler D., 2014, WECHSLER ADULT INTEL
   Xu N, 2013, ANTHROZOOS, V26, P373, DOI 10.2752/175303713X13697429463592
NR 58
TC 13
Z9 13
U1 0
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD JAN
PY 2018
VL 21
IS 1
AR e12487
DI 10.1111/desc.12487
PG 15
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA FR1ZA
UT WOS:000418865300002
PM 27785865
OA Bronze
DA 2021-02-24
ER

PT J
AU Bonitz, H
   Kopp, B
   Buchner, A
   Lunner, T
   Lyxell, B
   Finke, M
AF Boenitz, Hanna
   Kopp, Bruno
   Buechner, Andreas
   Lunner, Thomas
   Lyxell, Bjorn
   Finke, Mareike
TI Event-related neuronal responses to acoustic novelty in single-sided
   deaf cochlear implant users: Initial findings
SO CLINICAL NEUROPHYSIOLOGY
LA English
DT Article
DE Cochlear implants; Event-related potential; Oddball paradigm; Novelty-P3
ID AUDITORY-EVOKED POTENTIALS; OPEN-SOURCE TOOLBOX; SPEECH-PERCEPTION;
   WORKING-MEMORY; ELECTROPHYSIOLOGICAL EVIDENCE; INDIVIDUAL-DIFFERENCES;
   CORTICAL POTENTIALS; MUSIC PERCEPTION; STIMULUS TYPE; SENTENCE TEST
AB Objective: A cochlear implant (CI) is an auditory prosthesis restoring profound hearing loss. However, CItransmitted sounds are degraded compared to normal acoustic hearing. We investigated cortical responses related to CI-degraded against acoustic listening.
   Methods: Event-related potentials (ERPs) were recorded from eight single-sided deaf CI users who performed a three-stimulus oddball task, separatelywith their normal hearing ear and CI ear. The oddball tones were occasionally intermitted by novel sounds. ERP responses were compared between electric and acoustic listening for the auditory (N1) and auditory-cognitive (Novelty P3, Target-P3) ERP components.
   Results: CI-degraded listening was associated with attenuated sensory processing (N1) and with attenuated early cortical responses to acoustic novelty whereas the late cortical responses to acoustic novelty and the target-P3 did not differ between NH and CI ears.
   Conclusion: The present study replicates the CI-attenuation of Novelty-P3 amplitudes in a within-subject comparison. Further, we show that the CI-attenuation of Novelty-P3 amplitudes extends to early cortical responses to acoustic novelty, but not to late novelty responses.
   Significance: The dissociation into CI-attenuated P3 early Novelty-P3 amplitudes and CI-unaffected late Novelty-P3 amplitudes represents a cortical fingerprint of CI-degraded listening. It further contributes to general claims of distinct auditory Novelty-P3 sub-components. (C) 2017 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.
C1 [Boenitz, Hanna; Buechner, Andreas; Finke, Mareike] Hannover Med Sch, Dept Otorhinolaryngol, Hannover, Germany.
   [Kopp, Bruno] Hannover Med Sch, Dept Neurol, Hannover, Germany.
   [Buechner, Andreas; Finke, Mareike] Cluster Excellence Hearing4all, Hannover, Germany.
   [Lunner, Thomas; Lyxell, Bjorn] Linkoping Univ, Linnaeus Ctr HEAD, Dept Behav Sci & Learning, Linkoping, Sweden.
   [Lunner, Thomas; Lyxell, Bjorn] Linkoping Univ, Swedish Inst Disabil Res, Linkoping, Sweden.
   [Lunner, Thomas] Oticon AS, Eriksholm Res Ctr, Snekkersten, Denmark.
   [Lyxell, Bjorn] Linkoping Univ, Dept Behav Sci & Learning, Linkoping, Sweden.
RP Finke, M (corresponding author), Hannover Med Sch, Carl Neuberg Str 1, D-30625 Hannover, Germany.
EM Finke.Mareike@mh-hannover.de
FU German Research Council (DFG Cluster of Excellence EXC 1077/1
   "Hearing4all"); Oticon Foundation
FX This work was supported by grants from the German Research Council (DFG
   Cluster of Excellence EXC 1077/1 "Hearing4all") and the Oticon
   Foundation.
CR Aschenbrenner S., 2000, REGENSBURGER WORTFLU
   Baldwin PA, 2017, J PSYCHOPATHOL BEHAV, V39, P313, DOI 10.1007/s10862-016-9577-3
   Barcelo F, 2003, BRAIN RES PROTOC, V11, P27, DOI 10.1016/S1385-299X(03)00013-8
   Barcelo F, 2006, J COGNITIVE NEUROSCI, V18, P1734, DOI 10.1162/jocn.2006.18.10.1734
   Barry RJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep31200
   Baskent D., 2016, SCI FDN AUDIOLOGY PE, P285
   Bertoli S, 2014, CLIN NEUROPHYSIOL, V125, P1030, DOI 10.1016/j.clinph.2013.09.045
   Beynon A J, 2005, J Am Acad Audiol, V16, P42, DOI 10.3766/jaaa.16.1.5
   Bidet-Caulet A, 2015, BRAIN TOPOGR, V28, P423, DOI 10.1007/s10548-014-0354-x
   Billings CJ, 2011, EAR HEARING, V32, P53, DOI 10.1097/AUD.0b013e3181ec5c46
   Ceponiene R, 2004, PSYCHOPHYSIOLOGY, V41, P130, DOI 10.1111/j.1469-8986.2003.00138.x
   Clayson PE, 2017, INT J PSYCHOPHYSIOL, V111, P68, DOI 10.1016/j.ijpsycho.2016.10.012
   Clayson PE, 2017, INT J PSYCHOPHYSIOL, V111, P57, DOI 10.1016/j.ijpsycho.2016.09.005
   Debener S, 2005, COGNITIVE BRAIN RES, V22, P309, DOI 10.1016/j.cogbrainres.2004.09.006
   Debener S, 2002, INT J PSYCHOPHYSIOL, V46, P77, DOI 10.1016/S0167-8760(02)00072-7
   Debener S, 2008, PSYCHOPHYSIOLOGY, V45, P20, DOI 10.1111/j.1469-8986.2007.00610.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dien J, 2003, COGNITIVE BRAIN RES, V15, P137, DOI 10.1016/S0926-6410(02)00147-7
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Dyke FB, 2015, INT J PSYCHOPHYSIOL, V95, P56, DOI 10.1016/j.ijpsycho.2014.12.008
   Escera C, 1998, J COGNITIVE NEUROSCI, V10, P590, DOI 10.1162/089892998562997
   Escera C., 2003, COGNITIVE NEUROSCIEN, P63
   Field A., 2013, DISCOVERING STAT USI
   Finke M, 2016, AUDIOL NEURO-OTOL, V21, P305, DOI 10.1159/000452123
   Finke M, 2016, NEUROPSYCHOLOGIA, V87, P169, DOI 10.1016/j.neuropsychologia.2016.05.019
   Finke M, 2011, BIOL PSYCHOL, V87, P358, DOI 10.1016/j.biopsycho.2011.04.006
   Friedman D, 2001, NEUROSCI BIOBEHAV R, V25, P355, DOI 10.1016/S0149-7634(01)00019-7
   Garcia-Garcia M, 2010, NEUROPSYCHOLOGIA, V48, P4136, DOI 10.1016/j.neuropsychologia.2010.10.005
   Garcia-Garcia M, 2010, EUR J NEUROSCI, V31, P754, DOI 10.1111/j.1460-9568.2010.07102.x
   Gevins A, 2000, CEREB CORTEX, V10, P829, DOI 10.1093/cercor/10.9.829
   Groenen P.A.P., 2009, SPEECH EVOKED CORTIC
   Groenen PAP, 2001, SCAND AUDIOL, V30, P31, DOI 10.1080/010503901750069554
   HAHLBROCK K H, 1953, Arch Ohren Nasen Kehlkopfheilkd, V162, P394, DOI 10.1007/BF02105664
   Harris J, 2014, INT J PEDIATR OTORHI, V78, P1908, DOI 10.1016/j.ijporl.2014.08.023
   Haumann S, 2010, ORL-J OTO-RHIN-LARYN, V72, P312, DOI 10.1159/000318872
   Heimler B, 2014, NEUROSCIENCE, V283, P44, DOI 10.1016/j.neuroscience.2014.08.003
   Henkin Y, 2002, AUDIOL NEURO-OTOL, V7, P228, DOI 10.1159/000063739
   Henkin Y, 2014, AUDIOL NEURO-OTOL, V19, P21, DOI 10.1159/000371602
   Henkin Y, 2009, AUDIOL NEURO-OTOL, V14, P39, DOI 10.1159/000153434
   Hey M., 2016, EUR ARCH OTO-RHINO-L, P1
   Hey M, 2014, INT J AUDIOL, V53, P895, DOI 10.3109/14992027.2014.938368
   HochmairDesoyer I, 1997, AM J OTOL, V18, pS83
   Jung TP, 2000, CLIN NEUROPHYSIOL, V111, P1745, DOI 10.1016/S1388-2457(00)00386-2
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Koelsch S, 2004, CLIN NEUROPHYSIOL, V115, P966, DOI 10.1016/j.clinph.2003.11.032
   Lange F, 2015, BIOL PSYCHOL, V105, P66, DOI 10.1016/j.biopsycho.2015.01.001
   Lehrl S., 1999, MEHRFACHWAHL WORTSCH
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Luck SJ, 2011, BIOL PSYCHIAT, V70, P28, DOI 10.1016/j.biopsych.2010.09.021
   Martens S, 2010, NEUROSCI BIOBEHAV R, V34, P947, DOI 10.1016/j.neubiorev.2009.12.005
   Mertens G, 2016, HEARING RES, V331, P1, DOI 10.1016/j.heares.2015.09.016
   MICCO AG, 1995, AM J OTOL, V16, P514
   Munivrana B, 2013, CLIN LINGUIST PHONET, V27, P472, DOI 10.3109/02699206.2013.771214
   Nager W, 2007, RESTOR NEUROL NEUROS, V25, P391
   POLICH J, 1995, BIOL PSYCHOL, V41, P103, DOI 10.1016/0301-0511(95)05130-9
   POLICH J, 1992, PERS INDIV DIFFER, V13, P533, DOI 10.1016/0191-8869(92)90194-T
   Polich J, 2000, INT J PSYCHOPHYSIOL, V38, P3, DOI 10.1016/S0167-8760(00)00127-6
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   RAYMOND JE, 1992, J EXP PSYCHOL HUMAN, V18, P849, DOI 10.1037/0096-1523.18.3.849
   Ronnberg J, 2016, INT J AUDIOL, V55, P623, DOI 10.1080/14992027.2016.1219775
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Sandmann P, 2015, CLIN NEUROPHYSIOL, V126, P594, DOI 10.1016/j.clinph.2014.06.029
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Sandmann P, 2009, BRAIN, V132, P1967, DOI 10.1093/brain/awp034
   SanMiguel I, 2008, J COGNITIVE NEUROSCI, V20, P1131, DOI 10.1162/jocn.2008.20078
   Scheer M, 2016, FRONT HUM NEUROSCI, P10
   Schomaker J, 2015, NEUROSCI BIOBEHAV R, V55, P268, DOI 10.1016/j.neubiorev.2015.05.002
   Schroger E, 1998, COGNITIVE BRAIN RES, V7, P71, DOI 10.1016/S0926-6410(98)00013-5
   Sorqvist P, 2010, MEMORY, V18, P310, DOI 10.1080/09658211003601530
   Soshi T, 2014, HEARING RES, V316, P110, DOI 10.1016/j.heares.2014.08.001
   Spencer KM, 2001, PSYCHOPHYSIOLOGY, V38, P343, DOI 10.1017/S0048577201000324
   Tavora-Vieira D, 2013, NEUROREPORT, V24, P724, DOI 10.1097/WNR.0b013e3283642a93
   Tenke CE, 2010, PSYCHOPHYSIOLOGY, V47, P133, DOI 10.1111/j.1469-8986.2009.00880.x
   Torppa R, 2012, CLIN NEUROPHYSIOL, V123, P1966, DOI 10.1016/j.clinph.2012.03.008
   Vincent C, 2015, AUDIOL NEURO-OTOL, V20, P87, DOI 10.1159/000380754
   Viola FC, 2011, PSYCHOPHYSIOLOGY, V48, P1470, DOI 10.1111/j.1469-8986.2011.01224.x
   Vogel EK, 1998, J EXP PSYCHOL HUMAN, V24, P1656, DOI 10.1037/0096-1523.24.6.1656
   Wetzel N, 2014, PSYCH J, V3, P72, DOI 10.1002/pchj.49
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Yago E, 2003, COGNITIVE BRAIN RES, V16, P383, DOI 10.1016/S0926-6410(03)00052-1
   Yurgil KA, 2013, PSYCHOPHYSIOLOGY, V50, P1263, DOI 10.1111/psyp.12140
   Zeng F. - G., 2013, COCHLEAR IMPLANTS AU, V20
   Zeng FG, 2011, SPRINGER HANDB AUDIT, V39, P1, DOI 10.1007/978-1-4419-9434-9_1
NR 84
TC 1
Z9 1
U1 0
U2 5
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 1388-2457
EI 1872-8952
J9 CLIN NEUROPHYSIOL
JI Clin. Neurophysiol.
PD JAN
PY 2018
VL 129
IS 1
BP 133
EP 142
DI 10.1016/j.clinph.2017.10.025
PG 10
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA FQ8GW
UT WOS:000418602000016
PM 29182915
DA 2021-02-24
ER

PT J
AU Strori, D
   Zaar, J
   Cooke, M
   Mattys, SL
AF Strori, Dorina
   Zaar, Johannes
   Cooke, Martin
   Mattys, Sven L.
TI Sound specificity effects in spoken word recognition: The effect of
   integrality between words and sounds
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Spoken word recognition; Long-term memory; Speech perception
ID SPEECH-PERCEPTION; MEMORY REPRESENTATIONS; ADAPTIVE MEMORY; LEXICAL
   ACCESS; MODEL; TALKER; VOICES; NOISE; INTELLIGIBILITY; COMPETITION
AB Recent evidence has shown that nonlinguistic sounds co-occurring with spoken words may be retained in memory and affect later retrieval of the words. This sound-specificity effect shares many characteristics with the classic voice-specificity effect. In this study, we argue that the sound-specificity effect is conditional upon the context in which the word and sound coexist. Specifically, we argue that, besides co-occurrence, integrality between words and sounds is a crucial factor in the emergence of the effect. In two recognition-memory experiments, we compared the emergence of voice and sound specificity effects. In Experiment 1 , we examined two conditions where integrality is high. Namely, the classic voice-specificity effect (Exp. 1a) was compared with a condition in which the intensity envelope of a background sound was modulated along the intensity envelope of the accompanying spoken word (Exp. 1b). Results revealed a robust voice-specificity effect and, critically, a comparable sound-specificity effect: A change in the paired sound from exposure to test led to a decrease in word-recognition performance. In the second experiment, we sought to disentangle the contribution of integrality from a mere co-occurrence context effect by removing the intensity modulation. The absence of integrality led to the disappearance of the sound-specificity effect. Taken together, the results suggest that the assimilation of background sounds into memory cannot be reduced to a simple context effect. Rather, it is conditioned by the extent to which words and sounds are perceived as integral as opposed to distinct auditory objects.
C1 [Strori, Dorina] Northwestern Univ, Dept Commun Sci & Disorders, Evanston, IL 60208 USA.
   [Zaar, Johannes] Tech Univ Denmark, Dept Elect Engn, Lyngby, Denmark.
   [Cooke, Martin] Ikerbasque Basque Sci Fdn, Bilbao, Spain.
   [Mattys, Sven L.] Univ York, Dept Psychol, York, N Yorkshire, England.
RP Strori, D (corresponding author), Northwestern Univ, Dept Commun Sci & Disorders, Evanston, IL 60208 USA.
EM dorina.strori@northwestern.edu
FU European UnionEuropean Commission [FP7-PEOPLE-2011-290000]
FX This research was funded by the European Union's Seventh Framework
   Programme for research, technological development and demonstration
   under Grant Agreement No. FP7-PEOPLE-2011-290000.
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen R. H., 2007, MENTAL LEXICON CORE, P81, DOI DOI 10.1163/9780080548692_006
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTWARE, V67
   Bonin P, 2014, MEM COGNITION, V42, P370, DOI 10.3758/s13421-013-0368-8
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Church B. A., 1994, J EXPT PSYCHOL LEARN, V20, P496
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Cooper A, 2015, ATTEN PERCEPT PSYCHO, V77, P1342, DOI 10.3758/s13414-015-0855-z
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Creel SC, 2012, LANG COGNITIVE PROC, V27, P1021, DOI 10.1080/01690965.2011.610597
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547
   Elman JL, 2004, TRENDS COGN SCI, V8, P301, DOI 10.1016/j.tics.2004.05.003
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Garner W., 1974, PROCESSING INFORM ST
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gaskell MG, 2002, COGNITIVE PSYCHOL, V45, P220
   Gaskell MG, 1999, COGNITIVE SCI, V23, P439
   GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325, DOI 10.1111/j.2044-8295.1975.tb01468.x
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Hinton G. E., 1986, PARALLEL DISTRIBUTED, V1, P77, DOI DOI 10.1146/ANNUREV-PSYCH-120710-100344
   HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037/0033-295X.93.4.411
   Jorgensen S, 2013, J ACOUST SOC AM, V134, P436, DOI 10.1121/1.4807563
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502
   Jusczyk P. W., 2002, STEVENS HDB EXPT PSY, P493
   Lachs L, 2003, RETHINKING IMPLICIT, P215
   Luce PA, 1998, MEM COGNITION, V26, P708, DOI 10.3758/BF03211391
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   Luce PA, 2005, BLACKW HBK LINGUIST, P591
   Mattys SL, 2008, PERCEPT PSYCHOPHYS, V70, P1235, DOI 10.3758/PP.70.7.1235
   McClelland J. L., 1986, PARALLEL DISTRIBUTED, VII, P58
   Moore BCJ, 2003, J PHONETICS, V31, P563, DOI 10.1016/S0095-4470(03)00011-1
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Nairne JS, 2013, PSYCHOL SCI, V24, P2099, DOI 10.1177/0956797613480803
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Patterson R. D., 1988, 2341 U CAMBR MED RES
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   Pisoni DB, 2007, OXFORD HDB PSYCHOLIN, P3
   Pufahl A, 2014, COGNITIVE PSYCHOL, V70, P1, DOI 10.1016/j.cogpsych.2014.01.001
   Sarah Hawkins, 2001, ITALIAN J LINGUISTIC, V13, P99
   SCHACTER DL, 1992, J EXP PSYCHOL LEARN, V18, P915, DOI 10.1037/0278-7393.18.5.915
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sheffert SM, 1998, MEM COGNITION, V26, P591, DOI 10.3758/BF03201165
   Sheffert SM, 1998, PERCEPT PSYCHOPHYS, V60, P1141, DOI 10.3758/BF03206164
   VanArsdall JE, 2013, EXP PSYCHOL, V60, P172, DOI 10.1027/1618-3169/a000186
   Vitevitch MS, 2003, J EXP PSYCHOL HUMAN, V29, P333, DOI 10.1037/0096-1523.29.2.333
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
NR 51
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JAN
PY 2018
VL 80
IS 1
BP 222
EP 241
DI 10.3758/s13414-017-1425-3
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA FQ4DI
UT WOS:000418307400019
PM 28975549
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Avivi-Reich, M
   Puka, K
   Schneider, BA
AF Avivi-Reich, Meital
   Puka, Klajdi
   Schneider, Bruce A.
TI Do age and linguistic background alter the audiovisual advantage when
   listening to speech in the presence of energetic and informational
   masking?
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Audiovisual speech perception; Sensory and cognitive aging;
   Informational and energetic masking
ID AUDITORY-VISUAL INTEGRATION; OLDER-ADULTS; NONNATIVE LISTENERS;
   CONSONANT RECOGNITION; 2ND-LANGUAGE SPEECH; ARTICULATION INDEX; YOUNGER
   ADULTS; PERCEPTION; HEARING; CUES
AB We examined how the type of masker presented in the background affected the extent to which visual information enhanced speech recognition, and whether the effect was dependent on or independent of age and linguistic competence. In the present study, young speakers of English as a first language (YEL1) and English as a second language (YEL2), as well as older speakers of English as a first language (OEL1), were asked to complete an audio (A) and an audiovisual (AV) speech recognition task in which they listened to anomalous target sentences presented against a background of one of three masker types (noise, babble, and competing speech). All three main effects were found to be statistically significant (group, masker type, A vs. AV presentation type). Interesting two-way interactions were found between masker type and group and between masker type and presentation type; however, no interactions were found between group (age and/or linguistic competence) and presentation type (A vs. AV). The results of this study, while they shed light on the effect of masker type on the AV advantage, suggest that age and linguistic competence have no significant effects on the extent to which a listener is able to use visual information to improve speech recognition in background noise.
C1 [Avivi-Reich, Meital; Puka, Klajdi; Schneider, Bruce A.] Univ Toronto Mississauga, Mississauga, ON, Canada.
   [Schneider, Bruce A.] Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd, N Mississauga, ON L5L 1C6, Canada.
RP Schneider, BA (corresponding author), Univ Toronto Mississauga, Mississauga, ON, Canada.; Schneider, BA (corresponding author), Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd, N Mississauga, ON L5L 1C6, Canada.
EM bruce.schneider@utoronto.ca
RI Puka, Klajdi/AAX-1604-2020
OI Puka, Klajdi/0000-0001-7763-988X
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP-15359, TEA-12497]; Natural Sciences and Engineering
   Research Council of CanadaNatural Sciences and Engineering Research
   Council of Canada (NSERC)CGIAR [RGPIN 9952-13]
FX This research was supported by grants from the Canadian Institutes of
   Health Research (MOP-15359, TEA-12497), and Natural Sciences and
   Engineering Research Council of Canada (RGPIN 9952-13). The authors
   thank Jane Carey and Lulu Li for assistance in recruiting participants
   and collecting data. The authors also thank James Qi for his work
CR Andersen GJ, 2008, VISION RES, V48, P109, DOI 10.1016/j.visres.2007.10.026
   Andersen GJ, 2006, PSYCHOL AGING, V21, P74, DOI 10.1037/0882-7974.21.1.74
   Atchley P, 1998, PSYCHOL AGING, V13, P297, DOI 10.1037/0882-7974.13.2.297
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Avivi-Reich M, 2015, J SPEECH LANG HEAR R, V58, P1570, DOI 10.1044/2015_JSLHR-H-14-0177
   Avivi-Reich M, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00021
   Ben-David BM, 2016, HEARING RES, V341, P9, DOI 10.1016/j.heares.2016.07.016
   Ben-David BM, 2012, HEARING RES, V290, P55, DOI 10.1016/j.heares.2012.04.022
   Bialystok E, 1999, CHILD DEV, V70, P636, DOI 10.1111/1467-8624.00046
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Birch J, 1997, OPHTHAL PHYSL OPT, V17, P403, DOI 10.1111/j.1475-1313.1997.tb00072.x
   BLAMEY P J, 1989, Journal of Rehabilitation Research and Development, V26, P15
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   BRANT LJ, 1990, J ACOUST SOC AM, V88, P813, DOI 10.1121/1.399731
   Brown JI, 1981, NELSON DENNY READING
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   CAMPBELL M, 2007, JARA, V40, P11
   Carlson SM, 2008, DEVELOPMENTAL SCI, V11, P282, DOI 10.1111/j.1467-7687.2008.00675.x
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Dey A, 2015, PSYCHOL AGING, V30, P634, DOI 10.1037/pag0000033
   Durlach N. I., 2002, J ACOUST SOC AM, V111, P2337
   Durlach NI, 2003, J ACOUST SOC AM, V114, P368, DOI 10.1121/1.1577562
   Erdener VD, 2005, LANG LEARN, V55, P191, DOI 10.1111/j.0023-8333.2005.00303.x
   Ezzatian P, 2015, EAR HEARING, V36, P482, DOI 10.1097/AUD.0000000000000139
   Ezzatian P, 2010, SPEECH COMMUN, V52, P919, DOI 10.1016/j.specom.2010.04.001
   Feld JE, 2009, J SPEECH LANG HEAR R, V52, P1555, DOI 10.1044/1092-4388(2009/08-0137)
   Fitzgibbons P J, 1996, J Am Acad Audiol, V7, P183
   Florentine M., 1985, J ACOUST SOC AM, V77, pS106, DOI DOI 10.1121/1.2022152
   Freiherr J, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00863
   Freyman RL, 2004, J ACOUST SOC AM, V115, P2246, DOI 10.1121/1.1689343
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Girin L, 2001, J ACOUST SOC AM, V109, P3007, DOI 10.1121/1.1358887
   Glyde H, 2011, TRENDS AMPLIF, V15, P116, DOI 10.1177/1084713811424885
   Gordon MS, 2009, EXP AGING RES, V35, P202, DOI 10.1080/03610730902720398
   GRANT KW, 1991, J ACOUST SOC AM, V89, P2952, DOI 10.1121/1.400733
   Grant KW, 2002, J ACOUST SOC AM, V112, P30, DOI 10.1121/1.1482076
   Grant KW, 1996, J ACOUST SOC AM, V100, P2415, DOI 10.1121/1.417950
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Hardison DM, 2005, APPL PSYCHOLINGUIST, V26, P579, DOI 10.1017/S0142716405050319
   Hardison DM, 1999, LANG LEARN, V49, P213, DOI 10.1111/0023-8333.49.s1.7
   Hardison DM, 2003, APPL PSYCHOLINGUIST, V24, P495, DOI 10.1017/S0142716403000250
   Hay-McCutcheon MJ, 2005, LARYNGOSCOPE, V115, P1887, DOI 10.1097/01.mlg.0000173197.94769.ba
   Hazan V, 2006, J ACOUST SOC AM, V119, P1740, DOI 10.1121/1.2166611
   Helfer KS, 2005, J ACOUST SOC AM, V117, P842, DOI 10.1121/1.1836832
   Helfer KS, 1997, J SPEECH LANG HEAR R, V40, P432, DOI 10.1044/jslhr.4002.432
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   Holladay JT, 1997, J REFRACT SURG, V13, P388
   Jiang JT, 2002, EURASIP J APPL SIG P, V2002, P1174, DOI 10.1155/S1110865702206046
   Kahneman D., 1973, ATTENTION EFFORT
   Kamachi M, 2003, CURR BIOL, V13, P1709, DOI 10.1016/j.cub.2003.09.005
   Kidd Gerald Jr., 2008, V29, P143
   KROLL JF, 1994, J MEM LANG, V33, P149, DOI 10.1006/jmla.1994.1008
   Krull V, 2016, EAR HEARING, V37, P164, DOI 10.1097/AUD.0000000000000234
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   Legault I, 2010, INT J AUDIOL, V49, P904, DOI 10.3109/14992027.2010.509112
   Lidestam B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00639
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   MacLeod A., 1990, BRIT J AUDIOL, V24, P24
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   Meador D, 2000, BILING-LANG COGN, V3, P55, DOI DOI 10.1017/S1366728900000134
   MIDDELWEERD MJ, 1987, J ACOUST SOC AM, V82, P2145, DOI 10.1121/1.395659
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Ortega-Llebaria M, 2001, P AVSP 2001 INT C AU, P149, DOI 10.1016/S0749-596X(03)00105-0
   PEAL E, 1962, PSYCHOL MONOGR, V76, P1, DOI 10.1037/h0093840
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   POLLACK I, 1975, J ACOUST SOC AM, V57, pS5, DOI 10.1121/1.1995329
   Raven J. C, 1965, MILL HILL VOCABULARY
   Rogers CL, 2008, J ACOUST SOC AM, V124, P1278, DOI 10.1121/1.2939127
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Schneider BA, 2007, J AM ACAD AUDIOL, V18, P559, DOI 10.3766/jaaa.18.7.4
   Schneider BA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00618
   Schneider BA, 2016, EXP AGING RES, V42, P40, DOI 10.1080/0361073X.2016.1108749
   Schneider BA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00474
   Schneider BA, 2010, SPRINGER HANDB AUDIT, V34, P167, DOI 10.1007/978-1-4419-0993-0_7
   Schneider Bruce A., 2001, Seminars in Hearing, V22, P227, DOI 10.1055/s-2001-15628
   Scialfa CT, 2002, CAN J EXP PSYCHOL, V56, P153, DOI 10.1037/h0087393
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Sekiyama K., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), P1481, DOI 10.1109/ICSLP.1996.607896
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Smayda KE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152773
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Soto-Faraco S, 2007, PERCEPT PSYCHOPHYS, V69, P218, DOI 10.3758/BF03193744
   Speranza F, 2000, PSYCHOL AGING, V15, P253, DOI 10.1037/0882-7974.15.2.253
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Tillberg I, 1996, SCAND AUDIOL, V25, P267, DOI 10.3109/01050399609074966
   TRICK GL, 1991, NEUROLOGY, V41, P1437, DOI 10.1212/WNL.41.9.1437
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Tye-Murray N, 2016, PSYCHOL AGING, V31, P380, DOI 10.1037/pag0000094
   Tye-Murray N, 2011, EAR HEARING, V32, P650, DOI 10.1097/AUD.0b013e31821a4578
   Tye-Murray N, 2010, EAR HEARING, V31, P636, DOI 10.1097/AUD.0b013e3181ddf7ff
   WALDEN BE, 1993, J SPEECH HEAR RES, V36, P431, DOI 10.1044/jshr.3602.431
   Watson CS, 1996, J ACOUST SOC AM, V100, P1153, DOI 10.1121/1.416300
   Wingfield A, 1996, J Am Acad Audiol, V7, P175
   WINGFIELD A, 1985, J GERONTOL, V40, P579, DOI 10.1093/geronj/40.5.579
   Wist ER, 2000, EXP BRAIN RES, V134, P295, DOI 10.1007/s002210000466
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
NR 109
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JAN
PY 2018
VL 80
IS 1
BP 242
EP 261
DI 10.3758/s13414-017-1423-5
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA FQ4DI
UT WOS:000418307400020
PM 29039045
OA Bronze
DA 2021-02-24
ER

PT J
AU Jansen, SD
   Keebler, JR
   Chaparro, A
AF Jansen, Samantha D.
   Keebler, Joseph R.
   Chaparro, Alex
TI Shifts in Maximum Audiovisual Integration with Age
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Maximum visual enhancement; audiovisual integration; audiovisual speech
   perception; signal-tonoise ratio; age; working memory capacity; contrast
   sensitivity; partial mediation
ID VISUAL SPEECH-PERCEPTION; SPATIAL-FREQUENCY REQUIREMENTS; FIELD-OF-VIEW;
   OLDER-ADULTS; HEARING-LOSS; WORKING-MEMORY; DISCOURSE COMPREHENSION;
   CONTRAST SENSITIVITY; COGNITIVE FUNCTION; RECOGNITION
AB Listeners attempting to understand speech in noisy environments rely on visual and auditory processes, typically referred to as audiovisual processing. Noise corrupts the auditory speech signal and listeners naturally leverage visual cues from the talker's face in an attempt to interpret the degraded auditory signal. Studies of speech intelligibility in noise show that the maximum improvement in speech recognition performance (i.e., maximum visual enhancement or VEmax), derived from seeing an interlocutor's face, is invariant with age. Several studies have reported that VEmax is typically associated with a signal-to-noise (SNR) of - 12 dB; however, few studies have systematically investigated whether the SNR associated with VEmax changes with age. We investigated if VEmax changes as a function of age, whether the SNR at VEmax changes as a function of age, and what perceptual/cognitive abilities account for or mediate such relationships. We measured VEmax on a nongeriatric adult sample (N = 64) ranging in age from 20 to 59 years old. We found that VEmax was age-invariant, replicating earlier studies. No perceptual/cognitive measures predicted VEmax, most likely due to limited variance in VEmax scores. Importantly, we found that the SNR at VEmax shifts toward higher (quieter) SNR levels with increasing age; however, this relationship is partially mediated by working memory capacity, where those with larger working memory capacities (WMCs) can identify speech under lower (louder) SNR levels than their age equivalents with smaller WMCs. The current study is the first to report that individual differences in WMC partially mediate the age-related shift in SNR at VEmax.
C1 [Jansen, Samantha D.] Wichita State Univ, Dept Psychol, Wichita, KS 67208 USA.
   [Keebler, Joseph R.; Chaparro, Alex] Embry Riddle Aeronaut Univ, Dept Human Factors & Behav Neurobiol, Daytona Beach, FL USA.
RP Jansen, SD (corresponding author), Wichita State Univ, Dept Psychol, Wichita, KS 67208 USA.
EM samantha.d.jansen@gmail.com
OI Keebler, Joseph/0000-0003-2246-7472
FU Regional Institute on Aging at Wichita State University
FX The authors would like to thank the Regional Institute on Aging at
   Wichita State University for the grant that supported this study. The
   authors would also like to thank Drs. Jerker Ronnberg and Thomas Lunner
   for sharing the Reading Span Test with our laboratory and Dr. David
   Downs for his impactful guidance on this project.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Alsius A, 2016, ATTEN PERCEPT PSYCHO, V78, P1472, DOI 10.3758/s13414-016-1109-4
   Ball K., 1992, J AM OPTOM ASSOC, V64, P71
   BALL KK, 1988, J OPT SOC AM A, V5, P2210, DOI 10.1364/JOSAA.5.002210
   BERGMAN M, 1976, J GERONTOL, V31, P533, DOI 10.1093/geronj/31.5.533
   Besser J, 2013, TRENDS AMPLIF, V17, P75, DOI 10.1177/1084713813495459
   COREN S, 1989, B PSYCHONOMIC SOC, V27, P42
   Cosatto E, 2000, IEEE T MULTIMEDIA, V2, P152, DOI 10.1109/6046.865480
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Edwards JD, 2006, ARCH CLIN NEUROPSYCH, V21, P275, DOI 10.1016/j.acn.2006.03.001
   Ellis RJ, 2013, INT J AUDIOL, V52, P14, DOI 10.3109/14992027.2012.721013
   Engle RW, 2002, CURR DIR PSYCHOL SCI, V11, P19, DOI 10.1111/1467-8721.00160
   ERBER NP, 1979, J SPEECH HEAR RES, V22, P212, DOI 10.1044/jshr.2202.212
   FERRIS FL, 1982, AM J OPHTHALMOL, V94, P91, DOI 10.1016/0002-9394(82)90197-0
   Field A., 2013, DISCOVERING STAT USI
   Francis AL, 2009, ATTEN PERCEPT PSYCHO, V71, P1360, DOI 10.3758/APP.71.6.1360
   Gordon-Salant S, 2005, J REHABIL RES DEV, V42, P9, DOI 10.1682/JRRD.2005.01.0006
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   Hugenschmidt CE, 2009, NEUROREPORT, V20, P349, DOI 10.1097/WNR.0b013e328323ab07
   Humes L. E., 2008, ASHA LEAD, V13, DOI [10.1044/leader.FTR1.13052008.10, DOI 10.1044/LEADER.FTR1.13052008.10]
   Humes LE, 2007, J AM ACAD AUDIOL, V18, P590, DOI 10.3766/jaaa.18.7.6
   Humes LE, 2015, AM J AUDIOL, V24, P79, DOI 10.1044/2015_AJA-14-0062
   Institute of Medicine, 2008, RET AG AM BUILD HLTH
   Janse E, 2014, Q J EXP PSYCHOL, V67, P1842, DOI 10.1080/17470218.2013.879391
   Janse E, 2012, AGING NEUROPSYCHOL C, V19, P741, DOI 10.1080/13825585.2011.652590
   Jansen S., 2016, THESIS
   Jansen S, 2013, P HUM FACT ERG SOC A, V57, P1199
   Jerger J, 1992, J Am Acad Audiol, V3, P33
   Killion M C, 1993, HEARING J, V46, P31
   Kjellberg A, 2008, APPL COGNITIVE PSYCH, V22, P1088, DOI 10.1002/acp.1422
   Kutz J. K., 2015, AUDIOLOGY PURE TONE
   Legault I, 2010, INT J AUDIOL, V49, P904, DOI 10.3109/14992027.2010.509112
   Liu XZ, 2007, J PATHOL, V211, P188, DOI 10.1002/path.2102
   Loebach J. L., 2012, LIP READING AB UNPUB
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   MACLEOD A, 1990, British Journal of Audiology, V24, P29, DOI 10.3109/03005369009077840
   Martin JS, 2005, J REHABIL RES DEV, V42, P25, DOI 10.1682/JRRD.2004.12.0164
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   Morris NL, 2012, VISION RES, V66, P49, DOI 10.1016/j.visres.2012.06.003
   Morris NJ., 2011, THESIS
   Mukari Siti Zamratol-Mai Sarah, 2014, Korean J Audiol, V18, P112, DOI 10.7874/kja.2014.18.3.112
   Munhall KG, 2004, PERCEPT PSYCHOPHYS, V66, P574, DOI 10.3758/BF03194902
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Murphy DR, 2000, PSYCHOL AGING, V15, P323, DOI 10.1037/0882-7974.15.2.323
   Narinesingh C, 2014, INVEST OPHTH VIS SCI, V55, P3158, DOI 10.1167/iovs.14-14140
   PELLI DG, 1988, CLIN VISION SCI, V2, P187
   Putzar L, 2007, NAT NEUROSCI, V10, P1243, DOI 10.1038/nn1978
   Putzar L, 2010, NEUROPSYCHOLOGIA, V48, P2158, DOI 10.1016/j.neuropsychologia.2010.04.007
   Putzar L, 2010, RESTOR NEUROL NEUROS, V28, P251, DOI 10.3233/RNN-2010-0526
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Reitan R.M., 1992, TRAIL MAKING TEST MA
   ROMANO PE, 1974, AM ANN DEAF, V119, P383
   RONNBERG J, 1989, J SPEECH HEAR RES, V32, P725, DOI 10.1044/jshr.3204.725
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   ROSS JE, 1985, BRIT J OPHTHALMOL, V69, P51, DOI 10.1136/bjo.69.1.51
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Sennott B., 2011, LIP READING AB UNPUB
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   Tye-Murray N, 2016, PSYCHOL AGING, V31, P380, DOI 10.1037/pag0000094
   Tye-Murray N, 2008, INT J AUDIOL, V47, pS31, DOI 10.1080/14992020802301662
   van Belle G., 2002, STAT RULES THUMB
   Wechsler D., 2008, WECHSLER ADULT INTEL, V4th ed
   Wilson AH, 2016, J SPEECH LANG HEAR R, V59, P601, DOI 10.1044/2016_JSLHR-S-15-0092
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
NR 73
TC 1
Z9 1
U1 0
U2 4
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 3-4
SI SI
BP 191
EP 212
DI 10.1163/22134808-00002599
PG 22
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FP2UW
UT WOS:000417475700004
PM 31264624
DA 2021-02-24
ER

PT J
AU Heikkila, J
   Fagerlund, P
   Tiippana, K
AF Heikkila, Jenni
   Fagerlund, Petra
   Tiippana, Kaisa
TI Semantically Congruent Visual Information Can Improve Auditory
   Recognition Memory in Older Adults
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Audiovisual; aging; memory; semantic congruency
ID AUDIOVISUAL SPEECH-PERCEPTION; AGE-DIFFERENCES; MULTISENSORY MEMORIES;
   OBJECT DISCRIMINATION; PROCESSING-SPEED; ENHANCEMENT; INTEGRATION;
   RETRIEVAL; YOUNGER; SIGNAL
AB In the course of normal aging, memory functions show signs of impairment. Studies of memory in the elderly have previously focused on a single sensory modality, although multisensory encoding has been shown to improve memory performance in children and young adults. In this study, we investigated how audiovisual encoding affects auditory recognition memory in older (mean age 71 years) and younger (mean age 23 years) adults. Participants memorized auditory stimuli (sounds, spoken words) presented either alone or with semantically congruent visual stimuli (pictures, text) during encoding. Subsequent recognition memory performance of auditory stimuli was better for stimuli initially presented together with visual stimuli than for auditory stimuli presented alone during encoding. This facilitation was observed both in older and younger participants, while the overall memory performance was poorer in older participants. However, the pattern of facilitation was influenced by age. When encoding spoken words, the gain was greater for older adults. When encoding sounds, the gain was greater for younger adults. These findings show that semantically congruent audiovisual encoding improves memory performance in late adulthood, particularly for auditory verbal material.
C1 [Heikkila, Jenni; Tiippana, Kaisa] Univ Helsinki, Dept Psychol & Logoped, Fac Med, POB 9, FIN-00014 Helsinki, Finland.
   [Fagerlund, Petra] Aalto Univ, Dept Neurosci & Biomed Engn, Sch Sci, Helsinki, Finland.
RP Heikkila, J (corresponding author), Univ Helsinki, Dept Psychol & Logoped, Fac Med, POB 9, FIN-00014 Helsinki, Finland.
EM jenni.heikkila@helsinki.fi
RI Heikkila, Jenni/AAF-3574-2020
OI Tiippana, Kaisa/0000-0002-2305-8104
CR Bopp KL, 2005, J GERONTOL B-PSYCHOL, V60, pP223, DOI 10.1093/geronb/60.5.P223
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Cohen MA, 2009, P NATL ACAD SCI USA, V106, P6008, DOI 10.1073/pnas.0811884106
   Diaconescu AO, 2013, NEUROIMAGE, V65, P152, DOI 10.1016/j.neuroimage.2012.09.057
   Diederich A, 2008, NEUROPSYCHOLOGIA, V46, P2556, DOI 10.1016/j.neuropsychologia.2008.03.026
   Gordon MS, 2009, EXP AGING RES, V35, P202, DOI 10.1080/03610730902720398
   GRADY CL, 1995, SCIENCE, V269, P218, DOI 10.1126/science.7618082
   Green D. M., 1966, SIGNAL DETECTION THE
   Heikkila J., MULTISENS R IN PRESS
   Heikkila J, 2016, EXP BRAIN RES, V234, P1199, DOI 10.1007/s00221-015-4341-6
   Heikkila J, 2015, EXP PSYCHOL, V62, P123, DOI 10.1027/1618-3169/a000279
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   Lehmann S, 2005, COGNITIVE BRAIN RES, V24, P326, DOI 10.1016/j.cogbrainres.2005.02.005
   Luo L, 2007, PSYCHOL AGING, V22, P269, DOI 10.1037/0882-7974.22.2.269
   MacMillan N. A., 2005, DETECTION THEORY USE
   Maguinness C, 2011, FRONT AGING NEUROSCI, V3, DOI 10.3389/fnagi.2011.00019
   Miller J, 1996, PERCEPT PSYCHOPHYS, V58, P65, DOI 10.3758/BF03205476
   Moran ZD, 2013, MULTISENS RES, V26, P581, DOI 10.1163/22134808-00002436
   Murdock B, 1982, HDB RES METHODS HUMA, P1
   Murray MM, 2004, NEUROIMAGE, V21, P125, DOI 10.1016/j.neuroimage.2003.09.035
   Old S. R., 2008, HDB COGNITIVE AGING, P151, DOI [10.4135/9781412976589.n9, DOI 10.4135/9781412976589.N9]
   Park D., 2002, PSYCHOL AGING, V17, P826
   Peiffer AM, 2007, NEUROREPORT, V18, P1077, DOI 10.1097/WNR.0b013e3281e72ae7
   Ronnlund M, 2005, PSYCHOL AGING, V20, P3, DOI 10.1037/0882-7974.20.1.3
   Salthouse TA, 2000, BIOL PSYCHOL, V54, P35, DOI 10.1016/S0301-0511(00)00052-1
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   Schneider TR, 2008, EXP PSYCHOL, V55, P121, DOI 10.1027/1618-3169.55.2.121
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Setti A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00575
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Spaniol J, 2006, J EXP PSYCHOL LEARN, V32, P101, DOI 10.1037/0278-7393.32.1.101
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Talsma D, 2010, TRENDS COGN SCI, V14, P400, DOI 10.1016/j.tics.2010.06.008
   Thelen A, 2015, COGNITION, V138, P148, DOI 10.1016/j.cognition.2015.02.003
   Tye-Murray N, 2008, INT J AUDIOL, V47, pS31, DOI 10.1080/14992020802301662
   Ueno D, 2015, NEUROREPORT, V26, P303, DOI 10.1097/WNR.0000000000000325
   Van Gerven PWM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00147
   Winneke AH, 2011, PSYCHOL AGING, V26, P427, DOI 10.1037/a0021683
   Yuval-Greenberg S, 2009, EXP BRAIN RES, V193, P603, DOI 10.1007/s00221-008-1664-6
NR 40
TC 3
Z9 3
U1 0
U2 1
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 3-4
SI SI
BP 213
EP 225
DI 10.1163/22134808-00002602
PG 13
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FP2UW
UT WOS:000417475700005
PM 31264630
OA Green Accepted
DA 2021-02-24
ER

PT J
AU MacDonald, J
AF MacDonald, John
TI Hearing Lips and Seeing Voices: the Origins and Development of the
   'McGurk Effect' and Reflections on Audio-Visual Speech Perception Over
   the Last 40 Years
SO MULTISENSORY RESEARCH
LA English
DT Article
DE McGurk effect; audiovisual speech perception; hearing lips and seeing
   voices
ID SPACE-PERCEPTION; EARLY INFANCY
AB In 1976 Harry McGurk and I published a paper in Nature, entitled 'Hearing Lips and Seeing Voices'. The paper described a new audio-visual illusion we had discovered that showed the perception of auditorily presented speech could be influenced by the simultaneous presentation of incongruent visual speech. This hitherto unknown effect has since had a profound impact on audiovisual speech perception research. The phenomenon has come to be known as the 'McGurk effect', and the original paper has been cited in excess of 4800 times. In this paper I describe the background to the discovery of the effect, the rationale for the generation of the initial stimuli, the construction of the exemplars used and the serendipitous nature of the finding. The paper will also cover the reaction (and nonreaction) to the Nature publication, the growth of research on, and utilizing the 'McGurk effect' and end with some reflections on the significance of the finding.
C1 [MacDonald, John] Univ West Scotland, Dept Psychol, Paisley PA1 2BE, Renfrew, Scotland.
RP MacDonald, J (corresponding author), Univ West Scotland, Dept Psychol, Paisley PA1 2BE, Renfrew, Scotland.
EM profjohnmac@btinternet.com
CR ARONSON E, 1971, SCIENCE, V172, P1161, DOI 10.1126/science.172.3988.1161
   BERNSTEIN LE, 2002, P 7 INT C SPOK LANG, P1445
   Blumstein S. E., 1986, INVARIANCE VARIABILI, P178
   Corballis Michael, 2002, HAND MOUTH ORIGINS L
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   DODD B, 1977, PERCEPTION, V6, P31, DOI 10.1068/p060031
   EIMAS PD, 1974, PERCEPT PSYCHOPHYS, V16, P513, DOI 10.3758/BF03198580
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   Gibson J., 1979, ECOLOGICAL APPROACH
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MACDONALD J, 1978, BEHAV RES METH INSTR, V10, P845, DOI 10.3758/BF03205410
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MacDonald J, 2000, PERCEPTION, V29, P1155, DOI 10.1068/p3020
   MacDonald J., 1999, P EUR BUD HOUGR, V3, P1283
   MacDonald J., 2001, 12 ESCOP 18 BPS COGN
   Massaro D. W., 1998, PERCEIVING TALKING F
   Mattingly I. G., 1991, MODULARITY MOTOR THE
   MCGURK H, 1978, INT J BEHAV DEV, V1, P229, DOI 10.1177/016502547800100303
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MCGURK H, 1974, SCIENCE, V186, P649, DOI 10.1126/science.186.4164.649
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
NR 22
TC 3
Z9 4
U1 0
U2 12
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 1-2
SI SI
BP 7
EP 18
DI 10.1163/22134808-00002548
PG 12
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FO8KE
UT WOS:000417134400002
PM 31264593
OA Other Gold
DA 2021-02-24
ER

PT J
AU Magnotti, JF
   Mallick, DB
   Beauchamp, MS
AF Magnotti, John F.
   Mallick, Debshila Basu
   Beauchamp, Michael S.
TI Reducing Playback Rate of Audiovisual Speech Leads to a Surprising
   Decrease in the McGurk Effect
SO MULTISENSORY RESEARCH
LA English
DT Article
DE McGurk effect; playback rate; audiovisual speech; multisensory
   integration; individual differences
ID INDIVIDUAL-DIFFERENCES; INTEGRATION; MODEL; PERCEPTION; FACE; CUE
AB We report the unexpected finding that slowing video playback decreases perception of the McGurk effect. This reduction is counter-intuitive because the illusion depends on visual speech influencing the perception of auditory speech, and slowing speech should increase the amount of visual information available to observers. We recorded perceptual data from 110 subjects viewing audiovisual syllables (either McGurk or congruent control stimuli) played back at one of three rates: the rate used by the talker during recording (the natural rate), a slow rate (50% of natural), or a fast rate (200% of natural). We replicated previous studies showing dramatic variability in McGurk susceptibility at the natural rate, ranging from 0-100% across subjects and from 26-76% across the eight McGurk stimuli tested. Relative to the natural rate, slowed playback reduced the frequency of McGurk responses by 11% (79% of subjects showed a reduction) and reduced congruent accuracy by 3% (25% of subjects showed a reduction). Fast playback rate had little effect on McGurk responses or congruent accuracy. To determine whether our results are consistent with Bayesian integration, we constructed a Bayes-optimal model that incorporated two assumptions: individuals combine auditory and visual information according to their reliability, and changing playback rate affects sensory reliability. The model reproduced both our findings of large individual differences and the playback rate effect. This work illustrates that surprises remain in the McGurk effect and that Bayesian integration provides a useful framework for understanding audiovisual speech perception.
C1 [Magnotti, John F.; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
   [Magnotti, John F.; Beauchamp, Michael S.] Baylor Coll Med, Core Adv MRI, Houston, TX 77030 USA.
   [Mallick, Debshila Basu] Rice Univ, Dept Psychol, Houston, TX 77251 USA.
RP Magnotti, JF (corresponding author), Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.; Magnotti, JF (corresponding author), Baylor Coll Med, Core Adv MRI, Houston, TX 77030 USA.
EM magnotti@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934; Basu Mallick,
   Debshila/0000-0002-0597-3528
CR Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Andersen TS, 2015, J ACOUST SOC AM, V137, P2884, DOI 10.1121/1.4916691
   Angelaki DE, 2009, CURR OPIN NEUROBIOL, V19, P452, DOI 10.1016/j.conb.2009.06.008
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bejjanki VR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019812
   Bortfeld H., 2013, THEORETICAL COMPUTAT, P153
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Fixmer E., 1998, P AUD VIS SPEECH PRO
   Golinkoff RM, 2015, CURR DIR PSYCHOL SCI, V24, P339, DOI 10.1177/0963721415595345
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Kuznetsova A., 2016, LMERTEST TESTS LINEA
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Magnotti JF, 2015, PSYCHON B REV, V22, P701, DOI 10.3758/s13423-014-0722-2
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mehoudar E, 2014, J VISION, V14, DOI 10.1167/14.7.6
   Miller G, 1981, LANGUAGE SPEECH
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Olasagasti I, 2015, CORTEX, V68, P61, DOI 10.1016/j.cortex.2015.04.008
   Peterson MF, 2013, PSYCHOL SCI, V24, P1216, DOI 10.1177/0956797612471684
   PORT RF, 1979, J PHONETICS, V7, P45, DOI 10.1016/S0095-4470(19)31032-0
   R Core Team, 2016, R LANG ENV STAT COMP
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Seilheimer RL, 2014, CURR OPIN NEUROBIOL, V25, P38, DOI 10.1016/j.conb.2013.11.008
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Stropahl M, 2017, PSYCHON B REV, V24, P863, DOI 10.3758/s13423-016-1148-9
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
NR 34
TC 4
Z9 5
U1 0
U2 1
PU BRILL
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 1-2
SI SI
BP 19
EP 38
DI 10.1163/22134808-00002586
PG 20
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FO8KE
UT WOS:000417134400003
PM 31264598
DA 2021-02-24
ER

PT J
AU Irwin, J
   Avery, T
   Brancazio, L
   Turcios, J
   Ryherd, K
   Landi, N
AF Irwin, Julia
   Avery, Trey
   Brancazio, Lawrence
   Turcios, Jacqueline
   Ryherd, Kayleigh
   Landi, Nicole
TI Electrophysiological Indices of Audiovisual Speech Perception: Beyond
   the McGurk Effect and Speech in Noise
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Audiovisual speech perception; ERP; phonemic restoration
ID VISUAL INFLUENCES; AUDITORY SPEECH; SEEING VOICES; CHILDREN; AUTISM;
   ILLUSION; INFORMATION; RESTORATION; INTEGRATION; ATTENTION
AB Visual information on a talker's face can influence what a listener hears. Commonly used approaches to study this include mismatched audiovisual stimuli (e.g., McGurk type stimuli) or visual speech in auditory noise. In this paper we discuss potential limitations of these approaches and introduce a novel visual phonemic restoration method. This method always presents the same visual stimulus (e.g.,/ba/) dubbed with a matched auditory stimulus (/ba/) or one that has weakened consonantal information and sounds more/a/-like). When this reduced auditory stimulus (or/a/) is dubbed with lthe visual/ba/, a visual influence will result in effectively 'restoring' the weakened auditory cues so that the stimulus is perceived as a/ba/. An oddball design in which participants are asked to detect the/a/among a stream of more frequently occurring/ba/s while either a speaking face or face with no visual speech was used. In addition, the same paradigm was presented for a second contrast in which participants detected/pa/among/ba/s, a contrast which should be unaltered by the presence of visual speech. Behavioral and some ERP findings reflect the expected phonemic restoration for the /ba/vs./a/contrast; specifically, we observed reduced accuracy and P300 response in the presence of visual speech. Further, we report an unexpected finding of reduced accuracy and P300 response for both speech contrasts in the presence of visual speech, suggesting overall modulation of the auditory signal in the presence of visual speech. Consistent with this, we observed a mismatch negativity (MMN) effect for the/ba/vs./pa/contrast only that was larger in absence of visual speech. We discuss the potential utility for this paradigm for listeners who cannot respond actively, such as infants and individuals with developmental disabilities.
C1 [Irwin, Julia; Avery, Trey; Brancazio, Lawrence; Turcios, Jacqueline; Ryherd, Kayleigh; Landi, Nicole] Haskins Labs Inc, New Haven, CT 06511 USA.
   [Ryherd, Kayleigh; Landi, Nicole] Univ Connecticut, Storrs, CT 06269 USA.
   [Irwin, Julia; Brancazio, Lawrence; Turcios, Jacqueline] Southern Connecticut State Univ, New Haven, CT USA.
RP Landi, N (corresponding author), Haskins Labs Inc, New Haven, CT 06511 USA.; Landi, N (corresponding author), Univ Connecticut, Storrs, CT 06269 USA.
EM Nicole.Landi@yale.edu
RI landi, nicole/ABG-5374-2020; Landi, Nicole/P-2954-2014
OI Landi, Nicole/0000-0003-2890-2519
CR Alcantara JI, 2004, J CHILD PSYCHOL PSYC, V45, P1107, DOI 10.1111/j.1469-7610.2004.t01-1-00303.x
   ALHO K, 1995, EAR HEARING, V16, P38, DOI 10.1097/00003446-199502000-00004
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Bergeson T. R, 2004, HDB MULTISENSORY PRO, P749
   Bernstein L. E., 2001, AVSP 2001 INT C AUD, P50
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Boersma P., 2013, PRAAT DOING PHONETIC
   Brancazio L, 2005, PERCEPT PSYCHOPHYS, V67, P759, DOI 10.3758/BF03193531
   Brancazio L, 2004, J EXP PSYCHOL HUMAN, V30, P445, DOI 10.1037/0096-1523.30.3.445
   Brancazio L., 2015, 27 ANN CONV ASS PSYC
   Brancazio L, 2006, LANG SPEECH, V49, P21, DOI 10.1177/00238309060490010301
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Eigsti IM, 2003, MENT RETARD DEV D R, V9, P205, DOI 10.1002/mrdd.10081
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   Ferree TC, 2001, CLIN NEUROPHYSIOL, V112, P536, DOI 10.1016/S1388-2457(00)00533-2
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Green Kerry, 1994, J ACOUST SOC AM, V95, P3014, DOI [10.1121/1.408802., DOI 10.1121/1.408802]
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Jerger S, 2014, J EXP CHILD PSYCHOL, V126, P295, DOI 10.1016/j.jecp.2014.05.003
   Kaganovich N, 2016, BRAIN LANG, V157, P14, DOI 10.1016/j.bandl.2016.04.010
   Kaganovich N, 2014, J SPEECH LANG HEAR R, V57, P1480, DOI 10.1044/2014_JSLHR-L-13-0192
   Kashino M, 2006, ACOUST SCI TECHNOL, V27, P318, DOI 10.1250/ast.27.318
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Lachs L, 2001, EAR HEARING, V22, P236, DOI 10.1097/00003446-200106000-00007
   LEGERSTEE M, 1990, INFANT BEHAV DEV, V13, P343, DOI 10.1016/0163-6383(90)90039-B
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Meltzoff A. N., 1994, DEV INTERSENSORY PER, P335
   Menard L, 2009, J ACOUST SOC AM, V126, P1406, DOI 10.1121/1.3158930
   Molholm S, 2002, COGNITIVE BRAIN RES, V14, P115, DOI 10.1016/S0926-6410(02)00066-6
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   PAYTON KL, 1994, J ACOUST SOC AM, V95, P1581, DOI 10.1121/1.408545
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Pizzagalli DA, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P56, DOI 10.1017/CBO9780511546396.003
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAMUEL AG, 1981, J EXP PSYCHOL HUMAN, V7, P1124, DOI 10.1037/0096-1523.7.5.1124
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   WALKER S, 1995, PERCEPT PSYCHOPHYS, V57, P1124, DOI 10.3758/BF03208369
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Windmann S, 2004, J MEM LANG, V50, P212, DOI 10.1016/j.jml.2003.10.001
NR 54
TC 5
Z9 6
U1 1
U2 7
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 1-2
SI SI
BP 39
EP 56
DI 10.1163/22134808-00002580
PG 18
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FO8KE
UT WOS:000417134400004
PM 31264595
DA 2021-02-24
ER

PT J
AU Sanchez-Garcia, C
   Kandel, S
   Savariaux, C
   Soto-Faraco, S
AF Sanchez-Garcia, Carolina
   Kandel, Sonia
   Savariaux, Christophe
   Soto-Faraco, Salvador
TI The Time Course of Audio-Visual Phoneme Identification: a High Temporal
   Resolution Study
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Audio-visual; multisensory integration; speech perception; gating
ID SPOKEN-WORD RECOGNITION; VISUAL LANGUAGE DISCRIMINATION;
   SPEECH-PERCEPTION; MULTISENSORY INTEGRATION; CONSONANT RECOGNITION;
   INVERSE EFFECTIVENESS; 2ND-LANGUAGE SOUNDS; EARLY BILINGUALS; AUDITORY
   SPEECH; HEARING LIPS
AB Speech unfolds in time and, as a consequence, its perception requires temporal integration. Yet, studies addressing audio-visual speech processing have often overlooked this temporal aspect. Here, we address the temporal course of audio-visual speech processing in a phoneme identification task using a Gating paradigm. We created disyllabic Spanish word-like utterances (e.g.,/pafa/,/pa.a/,...) from high-speed camera recordings. The stimuli differed only in the middle consonant (/f/,/./,/s/, /r/,/g/), which varied in visual and auditory saliency. As in classical Gating tasks, the utterances were presented in fragments of increasing length (gates), here in 10 ms steps, for identification and confidence ratings. We measured correct identification as a function of time (at each gate) for each critical consonant in audio, visual and audio-visual conditions, and computed the Identification Point and Recognition Point scores. The results revealed that audio-visual identification is a time-varying process that depends on the relative strength of each modality (i.e., saliency). In some cases, audio-visual identification followed the pattern of one dominant modality (either A or V), when that modality was very salient. In other cases, both modalities contributed to identification, hence resulting in audiovisual advantage or interference with respect to unimodal conditions. Both unimodal dominance and audio-visual interaction patterns may arise within the course of identification of the same utterance, at different times. The outcome of this study suggests that audio-visual speech integration models should take into account the time-varying nature of visual and auditory saliency.
C1 [Sanchez-Garcia, Carolina; Soto-Faraco, Salvador] Univ Pompeu Fabra, Dept Tecnol Informacio & Comunicac, Barcelona, Spain.
   [Kandel, Sonia; Savariaux, Christophe] Univ Grenoble Alpes, GIPSA Lab, CNRS, UMR 5216, Grenoble, France.
   [Soto-Faraco, Salvador] ICREA, Barcelona, Spain.
RP Soto-Faraco, S (corresponding author), Univ Pompeu Fabra, Dept Tecnol Informacio & Comunicac, Barcelona, Spain.; Soto-Faraco, S (corresponding author), ICREA, Barcelona, Spain.
EM salvador.soto@icrea.cat
RI Kandel, Sonia/K-6169-2019
CR Abel J., 2011, 9 INT SEM SPEECH PRO, P337
   ABRY C, 1996, NATO ASI SERIES F, V150, P247
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Alsius A, 2011, EXP BRAIN RES, V213, P175, DOI 10.1007/s00221-011-2624-0
   Altieri N, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00238
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Barros-Loscertales A, 2013, BRAIN LANG, V126, P253, DOI 10.1016/j.bandl.2013.05.009
   BENOI C, 1994, J SPEECH HEAR RES, V37, P1195, DOI 10.1044/jshr.3705.1195
   Birules-Muntane J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158409
   Boersma P., 2017, PRAAT VERSION 4 5 25
   Brunelliere A, 2013, INT J PSYCHOPHYSIOL, V89, P136, DOI 10.1016/j.ijpsycho.2013.06.016
   Burnham D., 1998, ADV PSYCHOL SPEECHRE, P27
   Calvert G., 2004, HDB MULTISENSORY PRO
   CAMPBELL R, 2004, ENCY LANGUAGE LINGUI
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Cathiard M. A., 1991, P 12 INT C PHON SCI, V4, P50
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Escudier P., 1990, J PHYS, V51
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   Fort M, 2013, LANG COGNITIVE PROC, V28, P1207, DOI 10.1080/01690965.2012.701758
   Fort M, 2010, SPEECH COMMUN, V52, P525, DOI 10.1016/j.specom.2010.02.005
   Grant KW, 1996, J ACOUST SOC AM, V100, P2415, DOI 10.1121/1.417950
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Grosjean F, 1996, LANG COGNITIVE PROC, V11, P597, DOI 10.1080/016909696386999
   Holmes NP, 2007, NEUROPSYCHOLOGIA, V45, P3340, DOI 10.1016/j.neuropsychologia.2007.05.025
   Jaekl P, 2015, NEUROPSYCHOLOGIA, V75, P402, DOI 10.1016/j.neuropsychologia.2015.06.025
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Luchsinger R., 1965, VOICE SPEECH LANGUAG
   Massaro D. W., 1998, PERCEIVING TALKING F
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Moradi S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00359
   Fernandez LM, 2015, NEUROIMAGE, V119, P272, DOI 10.1016/j.neuroimage.2015.06.052
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Munhall KG, 1998, J ACOUST SOC AM, V104, P530, DOI 10.1121/1.423300
   Navarra J, 2005, J EXP PSYCHOL HUMAN, V31, P912, DOI 10.1037/0096-1523.31.5.912
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Pannunzi M, 2015, J NEUROPHYSIOL, V113, P1800, DOI 10.1152/jn.00341.2014
   Plant RR, 2004, BEHAV RES METH INS C, V36, P291, DOI 10.3758/BF03195575
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Ronquest RE, 2010, ATTEN PERCEPT PSYCHO, V72, P1601, DOI 10.3758/APP.72.6.1601
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Sanchez-Garcia C, 2013, EXP BRAIN RES, V225, P499, DOI 10.1007/s00221-012-3390-3
   Sanchez-Garcia C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025198
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   SCHWARTZ MF, 1968, J ACOUST SOC AM, V43, P1178, DOI 10.1121/1.1910954
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Smeele P. M. T., 1992, P INT C SPOKEN LANGU, V1, P65
   Smeele P. M. T., 1994, THESIS
   Smits R, 2000, J PHONETICS, V28, P111, DOI 10.1006/jpho.2000.0107
   Smits R, 2003, J ACOUST SOC AM, V113, P563, DOI 10.1121/1.1525287
   Soto-Faraco S, 2007, PERCEPT PSYCHOPHYS, V69, P218, DOI 10.3758/BF03193744
   Stein BE, 2009, EXP BRAIN RES, V198, P113, DOI 10.1007/s00221-009-1880-8
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556
   Stevenson RA, 2012, BRAIN TOPOGR, V25, P308, DOI 10.1007/s10548-012-0220-7
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Summerfield Q., 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237
   Papai MS, 2017, SCI REP-UK, V7, DOI 10.1038/srep41684
   Troille E, 2010, SPEECH COMMUN, V52, P513, DOI 10.1016/j.specom.2009.12.005
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   WARREN P, 1988, PERCEPT PSYCHOPHYS, V43, P21, DOI 10.3758/BF03208969
   WARREN P, 1987, PERCEPT PSYCHOPHYS, V41, P262, DOI 10.3758/BF03208224
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   West P, 1999, J PHONETICS, V27, P405, DOI 10.1006/jpho.1999.0102
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
NR 69
TC 6
Z9 6
U1 0
U2 9
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 1-2
SI SI
BP 57
EP 78
DI 10.1163/22134808-00002560
PG 22
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FO8KE
UT WOS:000417134400005
PM 31264596
DA 2021-02-24
ER

PT J
AU Burnham, D
   Dodd, B
AF Burnham, Denis
   Dodd, Barbara
TI Language-General Auditory-Visual Speech Perception: Thai-English and
   Japanese-English McGurk Effects
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Auditory-visual integration; cross-language speech perception; phonetic
   and phonemic speech perception; the McGurk effect
ID INFORMATION; INTEGRATION; PLACE; ACTIVATION; CUES
AB Cross-language McGurk Effects are used to investigate the locus of auditory-visual speech integration. Experiment 1 uses the fact that [eta], as in 'sing', is phonotactically legal in word-final position in English and Thai, but in word-initial position only in Thai. English and Thai language participants were tested for 'n' perception from auditory [m]/visual [eta] (A[m] V[eta]) in word-initial and -final positions. Despite English speakers' native language bias to label word-initial [eta] as 'n', the incidence of 'n' percepts to A[m] V[eta] was equivalent for English and Thai speakers in final and initial positions. Experiment 2 used the facts that (i) [d] as in 'that' is not present in Japanese, and (ii) English speakers respond more often with 'tha' than 'da' to A[ba] V[ga], but more often with 'di' than 'thi' to A[bi] V[gi]. English and three groups of Japanese language participants (Beginner, Intermediate, Advanced English knowledge) were presented with A[ba] V[ga] and A[bi] V[gi] by an English (Experiment 2a) or a Japanese (Experiment 2b) speaker. Despite Japanese participants' native language bias to perceive 'd' more often than 'th', the four groups showed a similar phonetic level effect of [a]/[i] vowel context x 'th' vs. 'd' responses to A[b] V[g] presentations. In Experiment 2b this phonetic level interaction held, but was more one-sided as very few 'th' responses were evident, even in Australian English participants. Results are discussed in terms of a phonetic plus postcategorical model, in which incoming auditory and visual information is integrated at a phonetic level, after which there are post-categorical phonemic influences.
C1 [Burnham, Denis] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
   [Dodd, Barbara] Univ Queensland, Brisbane, Qld, Australia.
RP Burnham, D (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
EM denis.burnham@westernsydney.edu.au
OI Burnham, Denis/0000-0002-1980-3458
CR Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   BERNSTEIN LE, 2002, P 7 INT C SPOK LANG, P1445
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Burnham D., 1997, P WORKSH AUD VIS SPE, P93
   Burnham D., 1998, ADV PSYCHOL SPEECHRE, P27
   Burnham D., 2002, INTEGRATED VIEW LANG, P281
   Burnham D., 1996, SPEECHREADING HUMANS, P103
   Burnham D., 1998, ADV INFANCY RES, V12, P170
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Campbell R, 2001, COGNITIVE BRAIN RES, V12, P233, DOI 10.1016/S0926-6410(01)00054-4
   Choi J, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160660
   DAY RH, 1976, BRIT J PSYCHOL, V67, P537, DOI 10.1111/j.2044-8295.1976.tb01545.x
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   DODD B, 1988, VOLTA REV, V90, P45
   Green K. P., 1996, SPEECHREADING HUMANS, P55
   GREEN KP, 1991, J EXP PSYCHOL HUMAN, V17, P278, DOI 10.1037/0096-1523.17.1.278
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Green KP, 1997, J SPEECH LANG HEAR R, V40, P646, DOI 10.1044/jslhr.4003.646
   GREEN KP, 1985, PERCEPT PSYCHOPHYS, V38, P269, DOI 10.3758/BF03207154
   GREEN KP, 1989, PERCEPT PSYCHOPHYS, V45, P34, DOI 10.3758/BF03208030
   GREEN KP, 1998, HEARING EYE, V2, P3
   Hampson M., 2003, 03006 CASCNS BOST U
   Kuhl P. K., 1988, PERCEPTUAL DEV INFAN, V20, P235
   KUHL PK, 1984, INFANT BEHAV DEV, V7, P361, DOI 10.1016/S0163-6383(84)80050-8
   LIBERMAN AM, 1989, SCIENCE, V243, P489, DOI 10.1126/science.2643163
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MacDonald J, 2018, MULTISENS RES, V31, P7, DOI 10.1163/22134808-00002548
   Massaro D., 1984, J EXP CHILD PSYCHOL, V41, P93
   Massaro D. W., 1996, SPEECHREADING HUMANS, P79
   MASSARO DW, 1987, SPEECH PERCEPTION EY
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McGurk H., 1981, BIMODAL SPEECH UNPUB
   Mills A. E., 1987, HEARING EYE PSYCHOL, P145
   Mills A. E., 1980, LINGUISTISCHE BERICH, V68, P85
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Musacchia G, 2006, EXP BRAIN RES, V168, P1, DOI 10.1007/s00221-005-0071-5
   Robert-Ribes J., 1995, P 13 INT C PHON SCI, V3, P114
   Robert-Ribes J., 1996, SPEECHREADING MAN MA, V150, P193
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Saito DN, 2005, CEREB CORTEX, V15, P1750, DOI 10.1093/cercor/bhi052
   SALDANA HM, 1993, PERCEPT PSYCHOPHYS, V54, P406, DOI 10.3758/BF03205276
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   Sekiyama K., 1994, Journal of the Acoustical Society of Japan (E), V15, P143
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P303, DOI DOI 10.1111/J.1467-7687.2008.00677
   Sekiyama K., 1995, 13 INT C PHON SCI, V3, P214
   Shigeno S, 2000, JPN PSYCHOL RES, V42, P155, DOI 10.1111/1468-5884.00141
   Studdert-Kennedy M., 1986, PRECURSORS EARLY SPE, P205
   Studdert-Kennedy M., 1992, SR111112 HASK LAB, P89
   Summerfield Q., 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   WERKER JF, 1992, CAN J PSYCHOL, V46, P551, DOI 10.1037/h0084331
NR 55
TC 4
Z9 5
U1 0
U2 7
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 1-2
SI SI
BP 79
EP 110
DI 10.1163/22134808-00002590
PG 32
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FO8KE
UT WOS:000417134400006
PM 31264592
OA Other Gold
DA 2021-02-24
ER

PT J
AU Alsius, A
   Pare, M
   Munhall, KG
AF Alsius, Agnes
   Pare, Martin
   Munhall, Kevin G.
TI Forty Years After Hearing Lips and Seeing Voices: the McGurk Effect
   Revisited
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Speech perception; audiovisual integration; the McGurk effect
ID AUDIOVISUAL SPEECH-PERCEPTION; SUPERIOR TEMPORAL SULCUS;
   INDIVIDUAL-DIFFERENCES; MULTISENSORY INTEGRATION; LEARNING-DISABILITIES;
   MISMATCH NEGATIVITY; SPATIAL ATTENTION; FACIAL PARALYSIS; BINDING
   WINDOW; FRONT VOWELS
AB Since its discovery 40 years ago, the McGurk illusion has been usually cited as a prototypical paradigmatic case of multisensory binding in humans, and has been extensively used in speech perception studies as a proxy measure for audiovisual integration mechanisms. Despite the well-established practice of using the McGurk illusion as a tool for studying the mechanisms underlying audiovisual speech integration, the magnitude of the illusion varies enormously across studies. Furthermore, the processing of McGurk stimuli differs from congruent audiovisual processing at both phenomenological and neural levels. This questions the suitability of this illusion as a tool to quantify the necessary and sufficient conditions under which audiovisual integration occurs in natural conditions. In this paper, we review some of the practical and theoretical issues related to the use of the McGurk illusion as an experimental paradigm. We believe that, without a richer understanding of the mechanisms involved in the processing of the McGurk effect, experimenters should be really cautious when generalizing data generated by McGurk stimuli to matching audiovisual speech events.
C1 [Alsius, Agnes; Pare, Martin; Munhall, Kevin G.] Queens Univ, Dept Psychol, Humphrey Hall,62 Arch St, Kingston, ON K7L 3N6, Canada.
RP Alsius, A (corresponding author), Queens Univ, Dept Psychol, Humphrey Hall,62 Arch St, Kingston, ON K7L 3N6, Canada.
EM aalsius@gmail.com
FU NSERCNatural Sciences and Engineering Research Council of Canada
   (NSERC); CIHRCanadian Institutes of Health Research (CIHR)
FX The present work was made possible by a research grants from NSERC and
   CIHR.
CR Alm M, 2009, J ACOUST SOC AM, V126, P377, DOI 10.1121/1.3129508
   Aloufy S, 1996, BRAIN LANG, V53, P51, DOI 10.1006/brln.1996.0036
   Alsius A, 2016, ATTEN PERCEPT PSYCHO, V78, P1472, DOI 10.3758/s13414-016-1109-4
   Andersen TS, 2009, SPEECH COMMUN, V51, P184, DOI 10.1016/j.specom.2008.07.004
   Bastien-Toniazzo M., 2009, CURR PSYCHOL LETT, V25, P2
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Baum SH, 2012, NEUROIMAGE, V62, P1825, DOI 10.1016/j.neuroimage.2012.05.034
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Berger CC, 2013, CURR BIOL, V23, P1367, DOI 10.1016/j.cub.2013.06.012
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Bishop CW, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024016
   Bohning M, 2002, NEUROPSYCHOLOGIA, V40, P1396, DOI 10.1016/S0028-3932(01)00208-1
   Boliek C, 2010, CAN J SPEECH-LANG PA, V34, P124
   Brancazio L, 2005, PERCEPT PSYCHOPHYS, V67, P759, DOI 10.3758/BF03193531
   Brancazio L, 2004, J EXP PSYCHOL HUMAN, V30, P445, DOI 10.1037/0096-1523.30.3.445
   Brancazio L, 2003, PERCEPT PSYCHOPHYS, V65, P591, DOI 10.3758/BF03194585
   Buchan JN, 2011, PERCEPTION, V40, P1164, DOI 10.1068/p6939
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Colin C, 2005, EUR J COGN PSYCHOL, V17, P541, DOI 10.1080/09541440440000168
   Colin C, 2002, EUR J COGN PSYCHOL, V14, P475, DOI 10.1080/09541440143000203
   Cotton J C, 1935, Science, V82, P592, DOI 10.1126/science.82.2138.592
   de Gelder B, 2003, SCHIZOPHR RES, V59, P211, DOI 10.1016/S0920-9964(01)00344-9
   DEKLE DJ, 1992, PERCEPT PSYCHOPHYS, V51, P355, DOI 10.3758/BF03211629
   Delbeuck X, 2007, NEUROPSYCHOLOGIA, V45, P3315, DOI 10.1016/j.neuropsychologia.2007.05.001
   DEMOREST ME, 1992, J SPEECH HEAR RES, V35, P876, DOI 10.1044/jshr.3504.876
   Dery C, 2014, CONSCIOUS COGN, V24, P33, DOI 10.1016/j.concog.2013.12.010
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   EASTON RD, 1982, PERCEPT PSYCHOPHYS, V32, P562, DOI 10.3758/BF03204211
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   ERLEBACHER A, 1971, PERCEPT PSYCHOPHYS, V9, P315, DOI 10.3758/BF03212657
   Eskelund K, 2015, NEUROPSYCHOLOGIA, V66, P48, DOI 10.1016/j.neuropsychologia.2014.10.021
   Eskelund K, 2011, EXP BRAIN RES, V208, P447, DOI 10.1007/s00221-010-2495-9
   Fingelkurts AA, 2003, BRAIN LANG, V85, P297, DOI 10.1016/S0093-934X(03)00059-2
   Fingelkurts Alexander A, 2007, Cogn Process, V8, P183, DOI 10.1007/s10339-007-0175-x
   Fixmer E., 1998, P AUD VIS SPEECH PRO, P27
   Gagne J. P., 1994, J ACAD REHABIL AUDIO, V27, P135
   Gentilucci M, 2005, EXP BRAIN RES, V167, P66, DOI 10.1007/s00221-005-0008-z
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   GREEN KP, 1991, J EXP PSYCHOL HUMAN, V17, P278, DOI 10.1037/0096-1523.17.1.278
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Green KP, 1997, J SPEECH LANG HEAR R, V40, P646, DOI 10.1044/jslhr.4003.646
   Green KP, 1988, J ACOUST SOC AM, V84, pS155, DOI DOI 10.1121/1.2025888
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hardison DM, 1996, LANG LEARN, V46, P3, DOI 10.1111/j.1467-1770.1996.tb00640.x
   Hessler D, 2013, BRAIN LANG, V124, P213, DOI 10.1016/j.bandl.2012.12.006
   Hietanen JK, 2001, EUR J COGN PSYCHOL, V13, P395, DOI 10.1080/09541440042000025
   Hillock-Dunn A, 2016, NEUROPSYCHOLOGIA, V88, P74, DOI 10.1016/j.neuropsychologia.2016.02.017
   Hirvenkari L, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00017
   Irwin JR, 2006, PERCEPT PSYCHOPHYS, V68, P582, DOI 10.3758/BF03208760
   Irwin JR, 2011, J NEUROLINGUIST, V24, P611, DOI 10.1016/j.jneuroling.2011.05.001
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Jones J. A., 1997, Canadian Acoustics, V25, P13
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Jones JA, 2006, EXP BRAIN RES, V174, P588, DOI 10.1007/s00221-006-0634-0
   Jordan TR, 2000, LANG SPEECH, V43, P107, DOI 10.1177/00238309000430010401
   Jordan TR, 2000, PERCEPT PSYCHOPHYS, V62, P1394, DOI 10.3758/BF03212141
   Jordan TR, 1997, J EXP PSYCHOL HUMAN, V23, P388, DOI 10.1037/0096-1523.23.2.388
   Jordan TR, 2001, J EXP PSYCHOL HUMAN, V27, P1386, DOI 10.1037//0096-1523.27.6.1386
   Kanaya S, 2011, PSYCHON B REV, V18, P123, DOI 10.3758/s13423-010-0027-z
   Keane BP, 2010, RES AUTISM SPECT DIS, V4, P276, DOI 10.1016/j.rasd.2009.09.015
   Keil J, 2012, CEREB CORTEX, V22, P221, DOI 10.1093/cercor/bhr125
   Kislyuk DS, 2008, J COGNITIVE NEUROSCI, V20, P2175, DOI 10.1162/jocn.2008.20152
   Lansing IR, 2003, PERCEPT PSYCHOPHYS, V65, P536, DOI 10.3758/BF03194581
   Leybaert J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00422
   Lifshitz M, 2013, CORTEX, V49, P463, DOI 10.1016/j.cortex.2012.08.007
   Luckner JL, 2005, AM ANN DEAF, V150, P443, DOI 10.1353/aad.2006.0008
   Luttke CS, 2016, SCI REP-UK, V6, DOI 10.1038/srep32891
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MacDonald J, 2000, PERCEPTION, V29, P1155, DOI 10.1068/p3020
   MACLEOD A, 1990, British Journal of Audiology, V24, P29, DOI 10.3109/03005369009077840
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   Malfait N, 2014, J COGNITIVE NEUROSCI, V26, P1572, DOI 10.1162/jocn_a_00565
   Massaro D., 1997, PERCEPTION, V26, P129
   Massaro D. W., 1998, PERCEIVING TALKING F
   Massaro DW, 1996, PERCEPT PSYCHOPHYS, V58, P1047, DOI 10.3758/BF03206832
   MASSARO DW, 1993, AM J PSYCHOL, V106, P25, DOI 10.2307/1422864
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   MASSARO DW, 1986, J EXP CHILD PSYCHOL, V41, P93, DOI 10.1016/0022-0965(86)90053-6
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Munhall KG, 2009, CURR BIOL, V19, P735, DOI 10.1016/j.cub.2009.03.019
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Nahorna O, 2012, J ACOUST SOC AM, V132, P1061, DOI 10.1121/1.4728187
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Navarra J, 2010, INFORM FUSION, V11, P4, DOI 10.1016/j.inffus.2009.04.001
   Nelsen MA, 2000, J SPEECH LANG HEAR R, V43, P158, DOI 10.1044/jslhr.4301.158
   Norrix LW, 2006, J COMMUN DISORD, V39, P22, DOI 10.1016/j.jcomdis.2005.05.003
   Olson IR, 2002, COGNITIVE BRAIN RES, V14, P129, DOI 10.1016/S0926-6410(02)00067-8
   Palmer TD, 2012, COGNITION, V125, P353, DOI 10.1016/j.cognition.2012.08.003
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   Peynircioglu ZF, 2017, J GEN PSYCHOL, V144, P59, DOI 10.1080/00221309.2016.1258388
   Proverbio AM, 2016, SCI REP-UK, V6, DOI 10.1038/srep30423
   ROBERTS M, 1981, PERCEPT PSYCHOPHYS, V30, P309, DOI 10.3758/BF03206144
   Romero YR, 2015, J NEUROPHYSIOL, V113, P2342, DOI 10.1152/jn.00783.2014
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   ROSENBLUM LD, 1992, PERCEPT PSYCHOPHYS, V52, P461, DOI 10.3758/BF03206706
   Rosenblum LD, 2000, J EXP PSYCHOL HUMAN, V26, P806, DOI 10.1037//0096-1523.26.2.806
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAKAMOTO S, 2012, INTERDISCIP INF SCI, V18, P83, DOI DOI 10.4036/iis.2012.83
   SALDANA HM, 1994, J ACOUST SOC AM, V95, P3658, DOI 10.1121/1.409935
   Sams M, 1998, SPEECH COMMUN, V26, P75, DOI 10.1016/S0167-6393(98)00051-X
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   SEEWALD RC, 1985, J SPEECH HEAR RES, V28, P36, DOI 10.1044/jshr.2801.36
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 1998, P AUD VIS SPEECH PRO, V2, P33
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Sergeant P. C, 1998, HEARING EYE 2, P155
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   SOROKER N, 1995, J CLIN EXP NEUROPSYC, V17, P243
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1984, Q J EXP PSYCHOL-A, V36, P51, DOI 10.1080/14640748408401503
   Surguladze SA, 2001, PSYCHIAT RES-NEUROIM, V106, P1, DOI 10.1016/S0925-4927(00)00081-0
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Taylor N, 2010, J AUTISM DEV DISORD, V40, P1403, DOI 10.1007/s10803-010-1000-4
   Thomas SM, 2004, J EXP PSYCHOL HUMAN, V30, P873, DOI 10.1037/0096-1523.30.5.873
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tiippana K, 2011, SEEING PERCEIVING, V24, P67, DOI 10.1163/187847511X557308
   Traunmuller H, 2007, J PHONETICS, V35, P244, DOI 10.1016/j.wocn.2006.03.002
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   Tuomainen J, 2005, COGNITION, V96, pB13, DOI 10.1016/j.cognition.2004.10.004
   Valkenier B, 2012, J SPEECH LANG HEAR R, V55, P1788, DOI 10.1044/1092-4388(2012/11-0227)
   Van Engen KJ, 2017, ATTEN PERCEPT PSYCHO, V79, P396, DOI 10.3758/s13414-016-1238-9
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Venezia JH, 2016, ATTEN PERCEPT PSYCHO, V78, P583, DOI 10.3758/s13414-015-1026-y
   Ver Hulst P. J, 2006, THESIS
   Von Berg S, 2007, CLEFT PALATE-CRAN J, V44, P518, DOI 10.1597/06-071.1
   WALKER S, 1995, PERCEPT PSYCHOPHYS, V57, P1124, DOI 10.3758/BF03208369
   White TP, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00565
   Wiersinga-Post E, 2010, NEUROREPORT, V21, P1146, DOI 10.1097/WNR.0b013e328340cc47
   Wilson AH, 2016, J SPEECH LANG HEAR R, V59, P601, DOI 10.1044/2016_JSLHR-S-15-0092
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Yakel DA, 2000, PERCEPT PSYCHOPHYS, V62, P1405, DOI 10.3758/BF03212142
   Youse KM, 2004, BRAIN INJURY, V18, P825, DOI 10.1080/02699000410001671784
NR 149
TC 24
Z9 25
U1 1
U2 19
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PY 2018
VL 31
IS 1-2
SI SI
BP 111
EP 144
DI 10.1163/22134808-00002565
PG 34
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA FO8KE
UT WOS:000417134400007
PM 31264597
DA 2021-02-24
ER

PT J
AU Hochmann, JR
   Benavides-Varela, S
   Flo, A
   Nespor, M
   Mehler, J
AF Hochmann, Jean-Remy
   Benavides-Varela, Silvia
   Flo, Ana
   Nespor, Marina
   Mehler, Jacques
TI Bias for Vocalic Over Consonantal Information in 6-Month-Olds
SO INFANCY
LA English
DT Article
ID YOUNG INFANTS; SPEECH-PERCEPTION; VOWELS; REPRESENTATIONS; SOUNDS;
   WORDS; RECOGNITION; ACQUISITION; CATEGORIES; UTTERANCES
AB Human languages rely on the ability to learn and produce an indefinite number of words by combining consonants and vowels in a lawful manner. The categorization of speech representations into consonants and vowels is evidenced by the tendency of adult speakers, attested in many languages, to use consonants and vowels for different tasks. Consonants are favored in lexical tasks, while vowels are favored to learn structural regularities. Recent results suggest that this specialization is already observable at 12months of age in Italian participants. Here, we investigated the representations of younger infants. In a series of anticipatory looking experiments, we showed that Italian 6-month-olds rely more on vowels than on consonants when learning the predictions made by individual words (Experiment 1) and are better at generalizing a structure when it is implemented over vowels than when it is implemented over consonants (Experiments 2 and 3). Until 6months of age, infants thus show a general vocalic bias, which contrasts with the specialization previously observed at 12months. These results suggest the format of speech representations changes during the second semester of life.
C1 [Hochmann, Jean-Remy] Univ Lyon, Inst Sci Cognit Marc Jeannerod, CNRS, UMR 5304, 67 Bd Pinel, F-69675 Bron, France.
   [Benavides-Varela, Silvia] Univ Padua, Dept Dev Psychol & Socializat, Padua, Italy.
   [Flo, Ana; Nespor, Marina; Mehler, Jacques] Scuola Int Super Studi Avanzati, Cognit Neurosci Dept, SISSA, Trieste, TS, Italy.
RP Hochmann, JR (corresponding author), Univ Lyon, Inst Sci Cognit Marc Jeannerod, CNRS, UMR 5304, 67 Bd Pinel, F-69675 Bron, France.
EM jr.hochmann@gmail.com
RI Benavides-Varela, Silvia/K-5734-2016; Benavides-Varela,
   Silvia/ABG-7474-2020
OI Benavides-Varela, Silvia/0000-0003-4818-7372; Benavides-Varela,
   Silvia/0000-0003-4818-7372; Flo, Ana/0000-0002-3260-0559
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [269502-PASCAL]
FX This research was funded by the European Research Council grant
   269502-PASCAL awarded to J.M. We thank Francesca Gandolfo and Marijana
   Sjekloa for recruiting participants, Alessio Isaja for technical
   assistance, Liuba Papeo, Judit Gervain, and Susan Carey for precious
   comments on previous versions of the manuscript.
CR Aslin R. N., 1980, CHILD PHONOLOGY, V2, P67
   Aslin RN, 2002, J ACOUST SOC AM, V112, P1257, DOI 10.1121/1.1501904
   Benavides-Varela S, 2015, CHILD DEV, V86, P209, DOI 10.1111/cdev.12291
   Benavides-Varela S, 2012, P NATL ACAD SCI USA, V109, P17908, DOI 10.1073/pnas.1205413109
   BERTONCINI J, 1988, J EXP PSYCHOL GEN, V117, P21, DOI 10.1037/0096-3445.117.1.21
   Bertoncini J, 1995, LANG SPEECH, V38, P311, DOI 10.1177/002383099503800401
   BERTONCINI J, 1981, INFANT BEHAV DEV, V4, P247, DOI 10.1016/S0163-6383(81)80027-6
   BIJELJACBABIC R, 1993, DEV PSYCHOL, V29, P711, DOI 10.1037/0012-1649.29.4.711
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bonatti LL, 2007, PSYCHOL SCI, V18, P924, DOI 10.1111/j.1467-9280.2007.02002.x
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   CUTTING JE, 1974, PERCEPT PSYCHOPHYS, V16, P564, DOI 10.3758/BF03198588
   de la Mora DM, 2013, COGNITION, V126, P307, DOI 10.1016/j.cognition.2012.09.015
   Dehaene-Lambertz G, 1998, NEUROREPORT, V9, P1885, DOI 10.1097/00001756-199806010-00040
   DELGUTTE B, 1984, J ACOUST SOC AM, V75, P887, DOI 10.1121/1.390598
   DELGUTTE B, 1984, J ACOUST SOC AM, V75, P897, DOI 10.1121/1.390599
   Delle Luche C, 2017, INFANCY, V22, P362, DOI 10.1111/infa.12151
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   EIMAS PD, 1974, PERCEPT PSYCHOPHYS, V16, P513, DOI 10.3758/BF03198580
   Eimas PD, 1999, J ACOUST SOC AM, V105, P1901, DOI 10.1121/1.426726
   Eimas PD, 1975, INFANT PERCEPTION SE, P193
   Floccia C, 2014, J CHILD LANG, V41, P1085, DOI 10.1017/S0305000913000287
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Hochmann JR, 2016, COGNITIVE PSYCHOL, V86, P87, DOI 10.1016/j.cogpsych.2016.01.005
   Hochmann JR, 2014, PSYCHOL SCI, V25, P2038, DOI 10.1177/0956797614547918
   Hochmann JR, 2013, COGNITION, V128, P13, DOI 10.1016/j.cognition.2013.02.014
   Hochmann JR, 2011, DEVELOPMENTAL SCI, V14, P1445, DOI 10.1111/j.1467-7687.2011.01089.x
   Hochmann JR, 2010, COGNITION, V115, P444, DOI 10.1016/j.cognition.2010.03.006
   Hojen A, 2016, DEVELOPMENTAL SCI, V19, P41, DOI 10.1111/desc.12286
   JUSCZYK PW, 1987, DEV PSYCHOL, V23, P648, DOI 10.1037/0012-1649.23.5.648
   JUSCZYK PW, 1995, J EXP PSYCHOL HUMAN, V21, P822
   JUSCZYK PW, 1977, PERCEPT PSYCHOPHYS, V21, P50, DOI 10.3758/BF03199467
   Keidel JL, 2007, PSYCHOL SCI, V18, P922, DOI 10.1111/j.1467-9280.2007.02001.x
   Kovacs AM, 2014, LANG LEARN, V64, P65, DOI 10.1111/lang.12056
   Kovacs AM, 2009, SCIENCE, V325, P611, DOI 10.1126/science.1173947
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   Maddieson I., 1986, EXPT PHONOLOGY, P105
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   McMurray B, 2004, INFANCY, V6, P203, DOI 10.1207/s15327078in0602_4
   MEHLER J, 1981, PHILOS T ROY SOC B, V295, P333, DOI 10.1098/rstb.1981.0144
   Mersad K, 2016, DEVELOPMENTAL SCI, V19, P710, DOI 10.1111/desc.12325
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Nazzi T, 2016, CURR DIR PSYCHOL SCI, V25, P291, DOI 10.1177/0963721416655786
   NESPOR M, 2003, LINGUE LINGUAGGIO, V2, P201
   Nishibayashi LL, 2016, COGNITION, V155, P188, DOI 10.1016/j.cognition.2016.07.003
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Poltrock S, 2015, J EXP CHILD PSYCHOL, V131, P135, DOI 10.1016/j.jecp.2014.11.011
   Pons F, 2010, COGNITION, V116, P361, DOI 10.1016/j.cognition.2010.05.013
   Toro JM, 2008, PERCEPT PSYCHOPHYS, V70, P1515, DOI 10.3758/PP.70.8.1515
   Toro JM, 2008, PSYCHOL SCI, V19, P137, DOI 10.1111/j.1467-9280.2008.02059.x
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
NR 53
TC 10
Z9 10
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD JAN-FEB
PY 2018
VL 23
IS 1
BP 136
EP 151
DI 10.1111/infa.12203
PG 16
WC Psychology, Developmental
SC Psychology
GA FP0IT
UT WOS:000417283400008
DA 2021-02-24
ER

PT J
AU Wang, YF
   Zhou, W
   Cheng, YH
   Bian, XY
AF Wang, Yifang
   Zhou, Wei
   Cheng, Yanhong
   Bian, Xiaoying
TI Gaze Patterns in Auditory-Visual Perception of Emotion by Children with
   Hearing Aids and Hearing Children
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE hearing-impaired; emotion perception; eye-movement; auditory-visual
   perception; oral statement
ID SPEECH-PERCEPTION; COCHLEAR IMPLANTS; SIGN-LANGUAGE; FACIAL EXPRESSIONS;
   EYE CONTACT; FACE RECOGNITION; DEAF-CHILDREN; AUTISM; INFANTS; VOICE
AB This study investigated eye-movement patterns during emotion perception for children with hearing aids and hearing children. Seventy-eight participants aged from 3 to 7 were asked to watch videos with a facial expression followed by an oral statement, and these two cues were either congruent or incongruent in emotional valence. Results showed that while hearing children paid more attention to the upper part of the face, children with hearing aids paid more attention to the lower part of the face after the oral statement was presented, especially for the neutral facial expression/neutral oral statement condition. These results suggest that children with hearing aids have an altered eye contact pattern with others and a difficulty in matching visual and voice cues in emotion perception. The negative cause and effect of these gaze patterns should be avoided in earlier rehabilitation for hearing-impaired children with assistive devices.
C1 [Wang, Yifang; Zhou, Wei; Bian, Xiaoying] Capital Normal Univ, Sch Psychol, Beijing, Peoples R China.
   [Cheng, Yanhong] Wuhan Childrens Lib, Wuhan, Hubei, Peoples R China.
RP Zhou, W (corresponding author), Capital Normal Univ, Sch Psychol, Beijing, Peoples R China.
EM bnuzw@sina.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31371058, 31500886]; State Administration of
   Press, Publication, Radio, Film and Television of The People's Republic
   of China [GD1608]; Research Fund for the Talented Person of Beijing City
   Grant [2014000020124G238]
FX This research was funded by National Natural Science Foundation of China
   (grant no. 31371058 to YW), State Administration of Press, Publication,
   Radio, Film and Television of The People's Republic of China (grant no.
   GD1608 to YW) and National Natural Science Foundation of China (grant
   no. 31500886 to WZ), Research Fund for the Talented Person of Beijing
   City Grant (grant no. 2014000020124G238 to WZ).
CR Adams Jr R. B., 2016, HDB NONVERBAL COMMUN, P335, DOI DOI 10.1037/14669-013
   Agrafiotis D, 2003, ELECTRON LETT, V39, P1703, DOI 10.1049/el:20031140
   Aviezer H, 2008, PSYCHOL SCI, V19, P724, DOI 10.1111/j.1467-9280.2008.02148.x
   Banziger T, 2009, EMOTION, V9, P691, DOI 10.1037/a0017088
   Barrett LF, 2010, PSYCHOL SCI, V21, P595, DOI 10.1177/0956797610363547
   Bergeson TR, 2010, RESTOR NEUROL NEUROS, V28, P157, DOI 10.3233/RNN-2010-0522
   Borgi M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00411
   Brown JR, 1996, CHILD DEV, V67, P789, DOI 10.1111/j.1467-8624.1996.tb01764.x
   Campbell J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147793
   CAMPBELL R, 1986, BRAIN, V109, P509, DOI 10.1093/brain/109.3.509
   Codina CJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00050
   Corkum V, 1998, DEV PSYCHOL, V34, P28, DOI 10.1037/0012-1649.34.1.28
   DENHAM SA, 1994, DEV PSYCHOL, V30, P928, DOI 10.1037/0012-1649.30.6.928
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Dunn L. M., 2007, PPVTIV PEABODY PICTU
   Dyck M.J., 2003, J DEAF STUD DEAF EDU, V8, P348, DOI DOI 10.1093/DEAFED/ENG019
   Dyck MJ, 2004, J CHILD PSYCHOL PSYC, V45, P789, DOI 10.1111/j.1469-7610.2004.00272.x
   Ekman P., 1978, RIV PSICHIATR, V47, P126
   Falck-Ytter T, 2015, CHILD DEV, V86, P37, DOI 10.1111/cdev.12273
   Farroni T, 2002, P NATL ACAD SCI USA, V99, P9602, DOI 10.1073/pnas.152159999
   Geers AE, 2013, EAR HEARING, V34, P562, DOI 10.1097/AUD.0b013e31828d2bd6
   Gori M, 2017, NEUROPSYCHOLOGIA, V99, P350, DOI 10.1016/j.neuropsychologia.2017.03.025
   GRAY CD, 2001, CONTEXT COGNITION DE, P135
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Hess U., 2015, 11 IEEE INT C WORKSH, V3, P1, DOI DOI 10.1109/FG.2015.7284842
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   Horley K, 2004, PSYCHIAT RES, V127, P43, DOI 10.1016/j.psychres.2004.02.016
   Horley K, 2003, J ANXIETY DISORD, V17, P33, DOI 10.1016/S0887-6185(02)00180-9
   Hosie JA, 1998, MOTIV EMOTION, V22, P293, DOI 10.1023/A:1021352323157
   Klasen M, 2011, J NEUROSCI, V31, P13635, DOI 10.1523/JNEUROSCI.2833-11.2011
   KLEINKE CL, 1986, PSYCHOL BULL, V100, P78, DOI 10.1037/0033-2909.100.1.78
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   Kral A, 2007, INT J AUDIOL, V46, P479, DOI 10.1080/14992020701383027
   Kyle FE, 2016, RES DEV DISABIL, V48, P13, DOI 10.1016/j.ridd.2015.10.004
   Lee YM, 2010, ACTA OTO-LARYNGOL, V130, P924, DOI 10.3109/00016480903518026
   Letourneau SM, 2011, PERCEPTION, V40, P563, DOI 10.1068/p6858
   Liang Qi, 2013, Cochlear Implants Int, V14 Suppl 1, pS26, DOI 10.1179/1467010013Z.00000000080
   Lopes PN, 2004, PERS SOC PSYCHOL B, V30, P1018, DOI 10.1177/0146167204264762
   Luciano JM, 2001, AM ANN DEAF, V146, P39, DOI 10.1353/aad.2012.0092
   Mayer JD, 2004, PSYCHOL INQ, V15, P197, DOI 10.1207/s15327965pli1503_02
   MOST T, 1993, BRIT J AUDIOL, V27, P247, DOI 10.3109/03005369309076701
   Most T, 2012, J SPEECH LANG HEAR R, V55, P1148, DOI 10.1044/1092-4388(2011/11-0060)
   Most T, 2009, J DEAF STUD DEAF EDU, V14, P449, DOI 10.1093/deafed/enp007
   Muir LJ, 2005, J DEAF STUD DEAF EDU, V10, P390, DOI 10.1093/deafed/eni037
   Nakano T, 2010, P R SOC B, V277, P1027, DOI 10.1098/rspb.2009.1713
   Nummenmaa L, 2010, CEREB CORTEX, V20, P1780, DOI 10.1093/cercor/bhp244
   O'Donnell C, 2001, PERCEPTION, V30, P755, DOI 10.1068/p3027
   Peters K, 2009, LANG SPEECH HEAR SER, V40, P245, DOI 10.1044/0161-1461(2009/07-0079)
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   Riby DM, 2008, AM SCI, V96, P465
   Rieffe C, 2000, J CHILD PSYCHOL PSYC, V41, P601, DOI 10.1111/1469-7610.00647
   ROSENBERG EL, 1994, COGNITION EMOTION, V8, P201, DOI 10.1080/02699939408408938
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Salvucci Dario D., 2000, P 2000 S EYE TRACK R, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028, 10.1145/355017.355028.]
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schorr EA, 2005, P NATL ACAD SCI USA, V102, P18748, DOI 10.1073/pnas.0508862102
   Schurgin MW, 2014, J VISION, V14, DOI 10.1167/14.13.14
   Schyns PG, 2002, PSYCHOL SCI, V13, P402, DOI 10.1111/1467-9280.00472
   Senju A, 2008, CURR BIOL, V18, P668, DOI 10.1016/j.cub.2008.03.059
   Senju A, 2015, CURR BIOL, V25, P3086, DOI 10.1016/j.cub.2015.10.019
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Smith ML, 2005, PSYCHOL SCI, V16, P184, DOI 10.1111/j.0956-7976.2005.00801.x
   Vinette C, 2004, COGNITIVE SCI, V28, P289, DOI 10.1016/j.cogsci.2004.01.002
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   Wang DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00351
   Wang YF, 2011, RES DEV DISABIL, V32, P2583, DOI 10.1016/j.ridd.2011.06.019
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
   Weeks JW, 2013, DEPRESS ANXIETY, V30, P749, DOI 10.1002/da.22146
   Wiefferink CH, 2013, J DEAF STUD DEAF EDU, V18, P175, DOI 10.1093/deafed/ens042
   Ziv M, 2013, J DEAF STUD DEAF EDU, V18, P161, DOI 10.1093/deafed/ens073
   Zupan B, 2013, INTEGRATING FACE VOI, P299
   Zupan B, 2009, J COMMUN DISORD, V42, P381, DOI 10.1016/j.jcomdis.2009.04.002
NR 73
TC 0
Z9 0
U1 2
U2 23
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD DEC 22
PY 2017
VL 8
AR 2281
DI 10.3389/fpsyg.2017.02281
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA FQ9TH
UT WOS:000418704100003
PM 29312104
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Du, Y
   Zatorre, RJ
AF Du, Yi
   Zatorre, Robert J.
TI Musical training sharpens and bonds ears and tongue to hear speech
   better
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE musical training; speech in noise perception; auditory-motor
   integration; multivoxel pattern classification; functional connectivity
ID COCKTAIL-PARTY PROBLEM; AUDITORY SKILLS; WORKING-MEMORY; NON-MUSICIANS;
   IN-NOISE; PERCEPTION; BRAIN; PLASTICITY; NETWORKS; FMRI
AB The idea that musical training improves speech perception in challenging listening environments is appealing and of clinical importance, yet the mechanisms of any such musician advantage are not well specified. Here, using functional magnetic resonance imaging (fMRI), we found that musicians outperformed nonmusicians in identifying syllables at varying signal-to-noise ratios (SNRs), which was associated with stronger activation of the left inferior frontal and right auditory regions in musicians compared with nonmusicians. Moreover, musicians showed greater specificity of phoneme representations in bilateral auditory and speech motor regions (e.g., premotor cortex) at higher SNRs and in the left speech motor regions at lower SNRs, as determined by multivoxel pattern analysis. Musical training also enhanced the intrahemispheric and interhemispheric functional connectivity between auditory and speech motor regions. Our findings suggest that improved speech in noise perception in musicians relies on stronger recruitment of, finer phonological representations in, and stronger functional connectivity between auditory and frontal speech motor cortices in both hemispheres, regions involved in bottom-up spectrotemporal analyses and top-down articulatory prediction and sensorimotor integration, respectively.
C1 [Du, Yi] Chinese Acad Sci, Inst Psychol, CAS Key Lab Behav Sci, Beijing 100101, Peoples R China.
   [Du, Yi; Zatorre, Robert J.] McGill Univ, Montreal Neurol Inst, Montreal, PQ H3A 2B4, Canada.
   [Du, Yi] Univ Chinese Acad Sci, Dept Psychol, Beijing 100049, Peoples R China.
   [Zatorre, Robert J.] Int Lab Brain Mus & Sound Res, Montreal, PQ H3A 2B4, Canada.
   Ctr Res Brain Language & Mus, Montreal, PQ H3A 2B4, Canada.
RP Du, Y (corresponding author), Chinese Acad Sci, Inst Psychol, CAS Key Lab Behav Sci, Beijing 100101, Peoples R China.; Du, Y (corresponding author), McGill Univ, Montreal Neurol Inst, Montreal, PQ H3A 2B4, Canada.; Du, Y (corresponding author), Univ Chinese Acad Sci, Dept Psychol, Beijing 100049, Peoples R China.
EM duyi@psych.ac.cn
RI Du, Yi/R-3858-2016
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31671172]; Thousand Young Talent Plan;
   Canadian Institutes of Health Research (Foundation Grant)Canadian
   Institutes of Health Research (CIHR); Canada Fund for InnovationCanada
   Foundation for Innovation
FX This research was supported by grants from the National Natural Science
   Foundation of China (31671172) and the Thousand Young Talent Plan (to
   Y.D.) and the Canadian Institutes of Health Research (Foundation Grant)
   and an infrastructure grant from the Canada Fund for Innovation (to
   R.J.Z.).
CR Ahdesmaki M, 2010, ANN APPL STAT, V4, P503, DOI 10.1214/09-AOAS277
   Alain C, 2014, HEARING RES, V308, P162, DOI 10.1016/j.heares.2013.06.008
   Anderson S, 2010, J AM ACAD AUDIOL, V21, P575, DOI 10.3766/jaaa.21.9.3
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Chen JL, 2012, NEUROIMAGE, V59, P1200, DOI 10.1016/j.neuroimage.2011.08.012
   Coffey EBJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00479
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Du Y, 2011, NEUROSCI BIOBEHAV R, V35, P2046, DOI 10.1016/j.neubiorev.2011.05.008
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Halwani GF, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00156
   Herholz SC, 2016, CEREB CORTEX, V26, P3125, DOI 10.1093/cercor/bhv138
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Kraus N, 2012, ANN NY ACAD SCI, V1252, P100, DOI 10.1111/j.1749-6632.2012.06463.x
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lahav A, 2007, J NEUROSCI, V27, P308, DOI 10.1523/JNEUROSCI.4822-06.2007
   Lega C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163380
   McLaren DG, 2012, NEUROIMAGE, V61, P1277, DOI 10.1016/j.neuroimage.2012.03.068
   Mumford JA, 2012, NEUROIMAGE, V59, P2636, DOI 10.1016/j.neuroimage.2011.08.076
   Palomar-Garcia MA, 2017, CEREB CORTEX, V27, P2768, DOI 10.1093/cercor/bhw120
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schon D, 2015, ANN NY ACAD SCI, V1337, P32, DOI 10.1111/nyas.12635
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Varnet L, 2015, SCI REP-UK, V5, DOI 10.1038/srep14489
   Wechsler D., 1997, WECHSLER ADULT INTEL, P1
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
   Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152
   Zatorre RJ, 2013, SCIENCE, V342, P585, DOI 10.1126/science.1238414
   Zendel BR, 2015, J COGNITIVE NEUROSCI, V27, P1044, DOI 10.1162/jocn_a_00758
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
NR 43
TC 29
Z9 31
U1 3
U2 24
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD DEC 19
PY 2017
VL 114
IS 51
BP 13579
EP 13854
DI 10.1073/pnas.1712223114
PG 6
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FQ4IT
UT WOS:000418321600077
PM 29203648
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Cope, TE
   Sohoglu, E
   Sedley, W
   Patterson, K
   Jones, PS
   Wiggins, J
   Dawson, C
   Grube, M
   Carlyon, RP
   Griffiths, TD
   Davis, MH
   Rowe, JB
AF Cope, Thomas E.
   Sohoglu, E.
   Sedley, W.
   Patterson, K.
   Jones, P. S.
   Wiggins, J.
   Dawson, C.
   Grube, M.
   Carlyon, R. P.
   Griffiths, T. D.
   Davis, Matthew H.
   Rowe, James B.
TI Evidence for causal top-down frontal contributions to predictive
   processes in speech perception
SO NATURE COMMUNICATIONS
LA English
DT Article
ID PRIMARY-PROGRESSIVE-APHASIA; PRIMARY VISUAL-CORTEX; INTERACTIVE
   PROCESSES; SENSORY ATTENUATION; DEGRADED SPEECH; BROCAS AREA; EEG;
   LANGUAGE; OSCILLATIONS; RECOGNITION
AB Perception relies on the integration of sensory information and prior expectations. Here we show that selective neurodegeneration of human frontal speech regions results in delayed reconciliation of predictions in temporal cortex. These temporal regions were not atrophic, displayed normal evoked magnetic and electrical power, and preserved neural sensitivity to manipulations of sensory detail. Frontal neurodegeneration does not prevent the perceptual effects of contextual information; instead, prior expectations are applied inflexibly. The precision of predictions correlates with beta power, in line with theoretical models of the neural instantiation of predictive coding. Fronto-temporal interactions are enhanced while participants reconcile prior predictions with degraded sensory signals. Excessively precise predictions can explain several challenging phenomena in frontal aphasias, including agrammatism and subjective difficulties with speech perception. This work demonstrates that higher-level frontal mechanisms for cognitive and behavioural flexibility make a causal functional contribution to the hierarchical generative models underlying speech perception.
C1 [Cope, Thomas E.; Patterson, K.; Jones, P. S.; Wiggins, J.; Dawson, C.; Rowe, James B.] Univ Cambridge, Dept Clin Neurosci, Cambridge CB2 0SZ, England.
   [Sohoglu, E.; Patterson, K.; Carlyon, R. P.; Davis, Matthew H.; Rowe, James B.] Univ Cambridge, Cognit & Brain Sci Unit, MRC, Cambridge CB2 7EF, England.
   [Sedley, W.; Grube, M.; Griffiths, T. D.] Newcastle Univ, Inst Neurosci, Newcastle NE1 7RU, England.
RP Cope, TE (corresponding author), Univ Cambridge, Dept Clin Neurosci, Cambridge CB2 0SZ, England.
EM thomascope@gmail.com
RI Tick, Beata/ABA-1728-2020; Rowe, James/C-3661-2013
OI Rowe, James/0000-0001-7216-8679; Davis, Matt/0000-0003-2239-0778;
   Sohoglu, Ediz/0000-0002-0755-6445; Cope, Thomas/0000-0002-4751-1786;
   Griffiths, Timothy/0000-0001-8066-4381; Carlyon,
   Robert/0000-0002-6166-501X
FU National Institute for Health ResearchNational Institute for Health
   Research (NIHR); Association of British Neurologists; Wellcome Trust
   (JBR Senior Fellowship)Wellcome Trust [103838]; Evelyn Trust; Medical
   Research Council Cognition and Brain Sciences unitUK Research &
   Innovation (UKRI)Medical Research Council UK (MRC) [MC-A060-5PQ30,
   MC-A060-5PQ80]; Patrick Berthoud Charitable Trust (TEC fellowship);
   Medical Research CouncilUK Research & Innovation (UKRI)Medical Research
   Council UK (MRC) [MC_U105559842, MC_UU_00005/12, MC_UU_00005/3,
   MC_UU_00005/5, MC_U105597119, MC_U105580446] Funding Source:
   researchfish; National Institute for Health ResearchNational Institute
   for Health Research (NIHR) [ACF-2011-01-002, ACF-2013-14-007,
   CL-2015-01-001] Funding Source: researchfish; Wellcome TrustWellcome
   Trust [103838/Z/14/Z] Funding Source: researchfish
FX The authors would like to acknowledge assistance with the optimisation
   of stimulus presentation and MEG data acquisition from Maarten Van
   Casteren, statistical advice from Prof. Richard Henson,
   neuropathological opinion from Dr. Kieren Allinson, and contributions to
   behavioural interpretations from Dr. Dennis Norris. Most importantly, we
   would like to thank the patients and their families for giving so
   generously and freely of their time. This study was supported by the
   National Institute for Health Research, the Association of British
   Neurologists and Patrick Berthoud Charitable Trust (TEC fellowship); the
   Wellcome Trust (JBR Senior Fellowship, 103838); the Evelyn Trust; and
   the Medical Research Council Cognition and Brain Sciences unit
   (MC-A060-5PQ30, MC-A060-5PQ80).
CR Alink A, 2010, J NEUROSCI, V30, P2960, DOI 10.1523/JNEUROSCI.3730-10.2010
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038
   Bates E, 1997, LANG COGNITIVE PROC, V12, P507
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577
   Bowyer S. M., 2016, NEUROPSYCHIATRIC ELE, V2, P1, DOI DOI 10.1186/S40810-015-0015-7
   Brown H, 2013, COGN PROCESS, V14, P411, DOI 10.1007/s10339-013-0571-3
   Cope TE, 2017, NEUROPSYCHOLOGIA, V104, P201, DOI 10.1016/j.neuropsychologia.2017.08.022
   Cope TE, 2014, NEUROPSYCHOLOGIA, V52, P73, DOI 10.1016/j.neuropsychologia.2013.09.039
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   David O, 2006, NEUROIMAGE, V31, P1580, DOI 10.1016/j.neuroimage.2006.02.034
   Edwards MJ, 2012, BRAIN, V135, P3495, DOI 10.1093/brain/aws129
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Fedorenko E, 2012, CURR BIOL, V22, P2059, DOI 10.1016/j.cub.2012.09.011
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   Friederici AD, 2017, NAT HUM BEHAV, V1, P713, DOI 10.1038/s41562-017-0184-4
   Friston KJ, 2006, NEUROIMAGE, V30, P1097, DOI 10.1016/j.neuroimage.2006.02.007
   Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000081
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Giordano BL, 2017, ELIFE, V6, DOI 10.7554/eLife.24763
   Goll JC, 2010, BRAIN, V133, P272, DOI 10.1093/brain/awp235
   Gorno-Tempini ML, 2011, NEUROLOGY, V76, P1006, DOI 10.1212/WNL.0b013e31821103e6
   Gorno-Tempini ML, 2004, ANN NEUROL, V55, P335, DOI 10.1002/ana.10825
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027
   Grahn JA, 2009, J NEUROSCI, V29, P7540, DOI 10.1523/JNEUROSCI.2018-08.2009
   Grodzinsky Y, 2000, BEHAV BRAIN SCI, V23, P1, DOI 10.1017/S0140525X00002399
   Grube M, 2016, BRAIN, V139, P1817, DOI 10.1093/brain/aww067
   Henson RN, 2009, NEUROIMAGE, V47, P581, DOI 10.1016/j.neuroimage.2009.04.063
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Kilner JM, 2013, CLIN NEUROPHYSIOL, V124, P2062, DOI 10.1016/j.clinph.2013.03.024
   Kilner James M, 2007, Cogn Process, V8, P159, DOI 10.1007/s10339-007-0170-2
   Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303
   Kumar S, 2014, CORTEX, V52, P86, DOI 10.1016/j.cortex.2013.12.002
   Lotto AJ, 2009, TRENDS COGN SCI, V13, P110, DOI 10.1016/j.tics.2008.11.008
   Mackenzie IRA, 2011, ACTA NEUROPATHOL, V122, P111, DOI 10.1007/s00401-011-0845-8
   Mandelli ML, 2016, BRAIN, V139, P2778, DOI 10.1093/brain/aww195
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McQueen JM, 2006, TRENDS COGN SCI, V10, P533, DOI 10.1016/j.tics.2006.10.004
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   MILLER GA, 1963, J VERB LEARN VERB BE, V2, P217, DOI 10.1016/S0022-5371(63)80087-0
   Mognon A, 2011, PSYCHOPHYSIOLOGY, V48, P229, DOI 10.1111/j.1469-8986.2010.01061.x
   Mohandas E, 2009, Indian J Psychiatry, V51 Suppl 1, pS65
   Murray B, 2005, BIOCHEM SOC T, V33, P595, DOI 10.1042/BST0330595
   Murray SO, 2002, P NATL ACAD SCI USA, V99, P15164, DOI 10.1073/pnas.192579399
   Musmann H., 1979, IMAGE TRANSM TECH, V73, P112
   Muthukumaraswamy SD, 2013, NEUROIMAGE, V69, P223, DOI 10.1016/j.neuroimage.2012.12.038
   Nolte G, 2004, CLIN NEUROPHYSIOL, V115, P2292, DOI 10.1016/j.clinph.2004.04.029
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   Parees I, 2014, BRAIN, V137, P2916, DOI 10.1093/brain/awu237
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Phillips HN, 2016, CORTEX, V82, P192, DOI 10.1016/j.cortex.2016.05.001
   Ranasinghe KG, 2017, BRAIN, V140, P2737, DOI 10.1093/brain/awx217
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Rogalski E, 2011, J NEUROSCI, V31, P3344, DOI 10.1523/JNEUROSCI.5544-10.2011
   Rohrer JD, 2012, NEUROBIOL AGING, V33, P744, DOI 10.1016/j.neurobiolaging.2010.05.020
   Sajjadi SA, 2012, NEUROLOGY, V78, P1670, DOI 10.1212/WNL.0b013e3182574f79
   Sajjadi SA, 2014, NEUROLOGY, V82, P1127, DOI 10.1212/WNL.0000000000000271
   Schoffelen JM, 2017, P NATL ACAD SCI USA, V114, P8083, DOI 10.1073/pnas.1703155114
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Sedley W, 2016, ELIFE, V5, DOI 10.7554/eLife.11476
   Shankweiler D, 2008, DEV NEUROPSYCHOL, V33, P745, DOI 10.1080/87565640802418688
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sheldon S, 2008, J ACOUST SOC AM, V123, P489, DOI 10.1121/1.2783762
   Shipp S, 2013, TRENDS NEUROSCI, V36, P706, DOI 10.1016/j.tins.2013.09.004
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Taulu S, 2005, IEEE T SIGNAL PROCES, V53, P3359, DOI 10.1109/TSP.2005.853302
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   von Helmholtz H., 1925, HELMHOLTZS TREATISE, V3
   Wolpe N, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13034
   Wolpe N, 2014, BRAIN, V137, P208, DOI 10.1093/brain/awt302
NR 80
TC 41
Z9 41
U1 0
U2 14
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2041-1723
J9 NAT COMMUN
JI Nat. Commun.
PD DEC 18
PY 2017
VL 8
AR 2154
DI 10.1038/s41467-017-01958-7
PG 16
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FQ3HC
UT WOS:000418247100003
PM 29255275
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Deroche, MLD
   Nguyen, DL
   Gracco, VL
AF Deroche, Mickael L. D.
   Nguyen, Don L.
   Gracco, Vincent L.
TI Modulation of Speech Motor Learning with Transcranial Direct Current
   Stimulation of the Inferior Parietal Lobe
SO FRONTIERS IN INTEGRATIVE NEUROSCIENCE
LA English
DT Article
DE speech production; speech perception; sensorimotor adaptation; inferior
   parietal lobe; transcranial direct current stimulation
ID NONINVASIVE BRAIN-STIMULATION; SPOKEN LANGUAGE PRODUCTION; SENSORIMOTOR
   ADAPTATION; PSYCHOMETRIC FUNCTION; CORTEX; FEEDBACK; PERCEPTION;
   PLASTICITY; RECALIBRATION; COMPENSATION
AB The inferior parietal lobe (IPL) is a region of the cortex believed to participate in speech motor learning. In this study, we investigated whether transcranial direct current stimulation (tDCS) of the IPL could influence the extent to which healthy adults (1) adapted to a sensory alteration of their own auditory feedback, and (2) changed their perceptual representation. Seventy subjects completed three tasks: a baseline perceptual task that located the phonetic boundary between the vowels /e/ and /a/; a sensorimotor adaptation task in which subjects produced the word "head" under conditions of altered or unaltered feedback; and a post-adaptation perceptual task identical to the first. Subjects were allocated to four groups which differed in current polarity and feedback manipulation. Subjects who received anodal tDCS to their IPL (i.e., presumably increasing cortical excitability) lowered their first formant frequency (F1) by 10% in opposition to the upward shift in F1 in their auditory feedback. Subjects who received the same stimulation with unaltered feedback did not change their production. Subjects who received cathodal tDCS to their IPL (i.e., presumably decreasing cortical excitability) showed a 5% adaptation to the F1 alteration similar to subjects who received sham tDCS. A subset of subjects returned a few days later to reiterate the same protocol but without tDCS, enabling assessment of any facilitatory effects of the previous tDCS. All subjects exhibited a 5% adaptation effect. In addition, across all subjects and for the two recording sessions, the phonetic boundary was shifted toward the vowel /e/ being repeated, consistently with the selective adaptation effect, but a correlation between perception and production suggested that anodal tDCS had enhanced this perceptual shift. In conclusion, we successfully demonstrated that anodal tDCS could (1) enhance the motor adaptation to a sensory alteration, and (2) potentially affect the perceptual representation of those sounds, but we failed to demonstrate the reverse effect with the cathodal configuration. Overall, tDCS of the left IPL can be used to enhance speech performance but only under conditions in which new or adaptive learning is required.
C1 [Deroche, Mickael L. D.; Nguyen, Don L.; Gracco, Vincent L.] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Gracco, Vincent L.] Haskins Labs Inc, New Haven, CT USA.
RP Deroche, MLD (corresponding author), McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
EM mickael.deroche@mcgill.ca
RI Deroche, Mickael L. D./I-7516-2019
OI Deroche, Mickael L. D./0000-0002-8698-2249
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [DC-012502]; National Institute of Health grantUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USA
   [DC-012502]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC012502, R01DC012502,
   R01DC012502, R01DC012502, R01DC012502] Funding Source: NIH RePORTER
FX This work was supported by grants from the Natural Sciences and
   Engineering Research Council of Canada and the National Institute of
   Health grant (DC-012502) to VG.
CR Bachmann CG, 2010, CLIN NEUROPHYSIOL, V121, P2083, DOI 10.1016/j.clinph.2010.05.005
   Been G, 2007, BRAIN RES REV, V56, P346, DOI 10.1016/j.brainresrev.2007.08.001
   Blakemore SJ, 2003, EXP BRAIN RES, V153, P239, DOI 10.1007/s00221-003-1597-z
   Boersma P., 2013, PRAAT DOING PHONETIC
   Buch ER, 2017, CLIN NEUROPHYSIOL, V128, P589, DOI 10.1016/j.clinph.2017.01.004
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Clower DM, 2001, J NEUROSCI, V21, P6283
   Cressman EK, 2009, J NEUROPHYSIOL, V102, P3505, DOI 10.1152/jn.00514.2009
   Della-Maggiore V, 2004, J NEUROSCI, V24, P9971, DOI 10.1523/JNEUROSCI.2833-04.2004
   DEMONET JF, 1994, NEUROSCI LETT, V182, P25, DOI 10.1016/0304-3940(94)90196-1
   Deschamps I, 2014, NEUROPSYCHOLOGIA, V53, P39, DOI 10.1016/j.neuropsychologia.2013.10.015
   Desmurget M, 2000, TRENDS COGN SCI, V4, P423, DOI 10.1016/S1364-6613(00)01537-0
   Devlin JT, 2003, J COGNITIVE NEUROSCI, V15, P71, DOI 10.1162/089892903321107837
   Dhanjal NS, 2008, J NEUROSCI, V28, P9969, DOI 10.1523/JNEUROSCI.2607-08.2008
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   ELMAN JL, 1981, J ACOUST SOC AM, V70, P45, DOI 10.1121/1.386580
   Geranmayeh F, 2014, J NEUROSCI, V34, P8728, DOI 10.1523/JNEUROSCI.0428-14.2014
   Geranmayeh F, 2012, BRAIN LANG, V121, P47, DOI 10.1016/j.bandl.2012.02.005
   Hamilton R, 2011, NEUROLOGY, V76, P187, DOI 10.1212/WNL.0b013e318205d50d
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J SPEECH LANG HEAR R, V45, P295, DOI 10.1044/1092-4388(2002/023)
   Jacobson L, 2012, EXP BRAIN RES, V216, P1, DOI 10.1007/s00221-011-2891-9
   Jones JA, 2000, J ACOUST SOC AM, V108, P1246, DOI 10.1121/1.1288414
   Jones JA, 2005, CURR BIOL, V15, P1768, DOI 10.1016/j.cub.2005.08.063
   KAWAHARA H, 1995, P INT JOINT C ART IN, P143
   Kwon YH, 2008, NEUROSCI LETT, V435, P56, DOI 10.1016/j.neulet.2008.02.012
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Luce R. D., 1986, RESPONSE TIMES
   Molenberghs P, 2009, NEUROSCI BIOBEHAV R, V33, P975, DOI 10.1016/j.neubiorev.2009.03.010
   Mollaei F, 2013, MOVEMENT DISORD, V28, P1668, DOI 10.1002/mds.25588
   Nasir SM, 2009, P NATL ACAD SCI USA, V106, P20470, DOI 10.1073/pnas.0907032106
   Nitsche MA, 2000, J PHYSIOL-LONDON, V527, P633, DOI 10.1111/j.1469-7793.2000.t01-1-00633.x
   Priori A, 1998, NEUROREPORT, V9, P2257, DOI 10.1097/00001756-199807130-00020
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   Purcell DW, 2006, J ACOUST SOC AM, V119, P2288, DOI 10.1121/1.2173514
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rizzolatti Giacomo, 2006, Novartis Found Symp, V270, P129
   Rosenkranz K, 2000, NEUROSCI LETT, V296, P61, DOI 10.1016/S0304-3940(00)01621-9
   Schlaug G, 2008, ARCH NEUROL-CHICAGO, V65, P1571, DOI 10.1001/archneur.65.12.1571
   Seghier ML, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00281
   Shiller DM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012975
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Shiozawa P, 2014, INT J NEUROPSYCHOPH, V17, P1443, DOI 10.1017/S1461145714000418
   Shum M, 2011, EUR J NEUROSCI, V34, P1817, DOI 10.1111/j.1460-9568.2011.07889.x
   SWENSSON RG, 1972, PERCEPT PSYCHOPHYS, V12, P16, DOI 10.3758/BF03212837
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1314, DOI 10.3758/BF03194545
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Williams JA, 2009, J REHABIL MED, V41, P305, DOI 10.2340/16501977-0356
   Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5
   Zarate JM, 2008, NEUROIMAGE, V40, P1871, DOI 10.1016/j.neuroimage.2008.01.026
   Zarate JM, 2010, NEUROPSYCHOLOGIA, V48, P607, DOI 10.1016/j.neuropsychologia.2009.10.025
NR 55
TC 3
Z9 3
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-5145
J9 FRONT INTEGR NEUROSC
JI Front. Integr. Neurosci.
PD DEC 15
PY 2017
VL 11
AR 35
DI 10.3389/fnint.2017.00035
PG 14
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA FQ0KT
UT WOS:000418045600001
PM 29326563
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Liu, HM
   Tsao, FM
AF Liu, Huei-Mei
   Tsao, Feng-Ming
TI Speech Perception Deficits in Mandarin-Speaking School-Aged Children
   with Poor Reading Comprehension
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE speech perception; categorical speech perception; lexical tone
   perception; reading comprehension; Mandarin-speaking children
ID LANGUAGE IMPAIRMENT SLI; CATEGORICAL PERCEPTION; DEVELOPMENTAL DYSLEXIA;
   ORAL LANGUAGE; SKILLS; DISCRIMINATION; READERS; DIFFICULTIES; SOUNDS;
   RISK
AB Previous studies have shown that children learning alphabetic writing systems who have language impairment or dyslexia exhibit speech perception deficits. However, whether such deficits exist in children learning logographic writing systems who have poor reading comprehension remains uncertain. To further explore this issue, the present study examined speech perception deficits in Mandarin-speaking children with poor reading comprehension. Two self-designed tasks, consonant categorical perception task and lexical tone discrimination task were used to compare speech perception performance in children (n = 31, age range = 7; 4-10; 2) with poor reading comprehension and an age-matched typically developing group (n = 31, age range = 7; 7-9; 10). Results showed that the children with poor reading comprehension were less accurate in consonant and lexical tone discrimination tasks and perceived speech contrasts less categorically than the matched group. The correlations between speech perception skills (i.e., consonant and lexical tone discrimination sensitivities and slope of consonant identification curve) and individuals' oral language and reading comprehension were stronger than the correlations between speech perception ability and word recognition ability. In conclusion, the results revealed that Mandarin-speaking children with poor reading comprehension exhibit less-categorized speech perception, suggesting that imprecise speech perception, especially lexical tone perception, is essential to account for reading learning difficulties in Mandarin-speaking children.
C1 [Liu, Huei-Mei] Natl Taiwan Normal Univ, Dept Special Educ, Taipei, Taiwan.
   [Tsao, Feng-Ming] Natl Taiwan Univ, Dept Psychol, Taipei, Taiwan.
RP Liu, HM (corresponding author), Natl Taiwan Normal Univ, Dept Special Educ, Taipei, Taiwan.
EM liumei@ntnu.edu.tw
OI TSAO, FENG-MING/0000-0003-1597-7589
FU Ministry of Science and Technology (Taiwan)Ministry of Science and
   Technology, Taiwan [NSC 99-2420-H-003-004 -MY3, NSC 100-2628-H-003 -
   160]
FX This research was supported by the grants from the Ministry of Science
   and Technology (Taiwan) to H-ML (NSC 99-2420-H-003-004 -MY3; NSC
   100-2628-H-003 - 160).
CR Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   Bishop DVM, 2009, CHILD DEV, V80, P593, DOI 10.1111/j.1467-8624.2009.01281.x
   Blomert L, 2004, BRAIN LANG, V89, P21, DOI 10.1016/S0093-934X(03)00305-5
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Botting N, 2006, READ WRIT, V19, P77, DOI 10.1007/s11145-005-4322-4
   Breier JI, 2004, J EXP CHILD PSYCHOL, V88, P152, DOI 10.1016/j.jecp.2004.03.003
   Burlingame E, 2005, J SPEECH LANG HEAR R, V48, P805, DOI 10.1044/1092-4388(2005/056)
   Cain K., 2016, PERSPECTIVES LANGUAG, V42, P9
   Cain K, 2006, BRIT J EDUC PSYCHOL, V76, P683, DOI 10.1348/000709905X67610
   Catts H. W., 1999, SCI STUD READ, V3, P331, DOI DOI 10.1207/S1532799XSSR0304_2
   Catts HW, 2015, READ WRIT, V28, P1407, DOI 10.1007/s11145-015-9576-x
   Catts HW, 2012, J EDUC PSYCHOL, V104, P166, DOI 10.1037/a0025323
   Catts HW, 2006, J SPEECH LANG HEAR R, V49, P278, DOI 10.1044/1092-4388(2006/023)
   Chan DW, 2007, EDUC STUD, V33, P249, DOI 10.1080/03055690601068535
   Chen L. Y., 2010, B SPEC ED, V35, P1
   Clarke PJ, 2010, PSYCHOL SCI, V21, P1106, DOI 10.1177/0956797610375449
   Coady JA, 2005, J SPEECH LANG HEAR R, V48, P944, DOI 10.1044/1092-4388(2005/065)
   Coady JA, 2007, J SPEECH LANG HEAR R, V50, P41, DOI 10.1044/1092-4388(2007/004)
   Diakidoy IAN, 2005, READ PSYCHOL, V26, P55, DOI 10.1080/02702710590910584
   Dickinson DK, 2010, EDUC RESEARCHER, V39, P305, DOI 10.3102/0013189X10370204
   Edwards J, 2002, J SPEECH LANG HEAR R, V45, P231, DOI 10.1044/1092-4388(2002/018)
   Goswami U, 2013, J MEM LANG, V69, P1, DOI 10.1016/j.jml.2013.03.001
   Gough P.B., 1986, REMEDIAL SPECIAL ED, V7, DOI [DOI 10.1177/074193258600700104, https://doi.org/10.1177/074193258600700104, 10.1177/074193258600700104]
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Huang H. S., 2001, CHINESE CHARACTER RE
   Jeng J. Y., 2011, J SPEC EDUC, V34, P135, DOI DOI 10.6172/BSE201107.3602002
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   JUSCZYK P. W., 1997, DISCOVERY SPOKEN LAN
   Justice L, 2013, J RES READ, V36, P172, DOI 10.1111/j.1467-9817.2011.01498.x
   KO H. W., 2007, READING COMPREHENSIO
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Lepola J, 2016, READ RES QUART, V51, P373, DOI 10.1002/rrq.145
   Lervag A, 2018, CHILD DEV, V89, P1821, DOI 10.1111/cdev.12861
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Liu H. M., 2013, B ED PSYCHOL, V45, P221
   Lopez-Zamora M, 2012, SCI STUD READ, V16, P443, DOI 10.1080/10888438.2011.588763
   Lu L., 1998, PEABODY PICTURE VOCA
   Manis FR, 2005, CONNECTIONS BETWEEN LANGUAGE AND READING DISABILITIES, P77
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Nation K, 2004, J RES READ, V27, P342, DOI 10.1111/j.1467-9817.2004.00238.x
   Nation K, 2010, J CHILD PSYCHOL PSYC, V51, P1031, DOI 10.1111/j.1469-7610.2010.02254.x
   Nittrouer S, 2005, J ACOUST SOC AM, V118, P1072, DOI 10.1121/1.1940508
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Oakhill JV, 2012, SCI STUD READ, V16, P91, DOI 10.1080/10888438.2010.529219
   Garcia JR, 2014, REV EDUC RES, V84, P74, DOI 10.3102/0034654313499616
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   Serniclaes W, 2001, J SPEECH LANG HEAR R, V44, P384, DOI 10.1044/1092-4388(2001/032)
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Snowling M, 2000, J CHILD PSYCHOL PSYC, V41, P587, DOI 10.1111/1469-7610.00651
   Storch SA, 2002, DEV PSYCHOL, V38, P934, DOI 10.1037//0012-1649.38.6.934
   SUSSMAN JE, 1993, J SPEECH HEAR RES, V36, P1286, DOI 10.1044/jshr.3606.1286
   THIBODEAU LM, 1979, J PHONETICS, V7, P375, DOI 10.1016/S0095-4470(19)31071-X
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Vance M, 2009, INT J AUDIOL, V48, P708, DOI 10.1080/14992020902930550
   Vandewalle E, 2012, J SPEECH LANG HEAR R, V55, P1053, DOI 10.1044/1092-4388(2011/10-0308)
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Vellutino FR, 2007, SCI STUD READ, V11, P3, DOI 10.1207/s1532799xssr1101_2
   Veuillet E, 2007, BRAIN, V130, P2915, DOI 10.1093/brain/awm235
   Wayland RP, 2010, J PSYCHOLINGUIST RES, V39, P465, DOI 10.1007/s10936-009-9141-3
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Wong AMY, 2009, J SPEECH LANG HEAR R, V52, P1493, DOI 10.1044/1092-4388(2009/08-0170)
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wu W. T., 2006, TEST NONVERBAL INTEL
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Zhu H, 2006, PHONOLOGICAL DEV DIS
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
   Ziegler JC, 2011, J EXP CHILD PSYCHOL, V110, P362, DOI 10.1016/j.jecp.2011.05.001
NR 67
TC 2
Z9 2
U1 3
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD DEC 14
PY 2017
VL 8
AR 2144
DI 10.3389/fpsyg.2017.02144
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA FP9DE
UT WOS:000417946900001
PM 29312031
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU van der Jagt, AMA
   Kalkman, RK
   Briaire, JJ
   Verbist, BM
   Frijns, JHM
AF van der Jagt, Annerie M. A.
   Kalkman, Randy K.
   Briaire, Jeroen J.
   Verbist, Berit M.
   Frijns, Johan H. M.
TI Variations in cochlear duct shape revealed on clinical CT images with an
   automatic tracing method
SO SCIENTIFIC REPORTS
LA English
DT Article
ID INSERTION TRAUMA; ELECTRODE ARRAY; TEMPORAL BONE; DIMENSIONS;
   IMPLANTATION; MORPHOLOGY; POSITION; SCALAE; SIZE
AB Cochlear size and morphology vary greatly and may influence the course of a cochlear implant electrode array during insertion and its final intra-cochlear position. Detailed insight into these variations is valuable for characterizing each cochlea and offers the opportunity to study possible correlations with surgical or speech perception outcomes. This study presents an automatic tracing method to assess individual cochlear duct shapes from clinical CT images. On pre-operative CT scans of 479 inner ears the cochlear walls were discriminated by interpolating voxel intensities along radial and perpendicular lines within multiplanar reconstructions at 1 degree intervals from the round window. In all 479 cochleas, the outer wall could be traced automatically up to 720 degrees. The inner wall and floor of the scala tympani in 192 cochleas. The shape of the cochlear walls were modelled using a logarithmic spiral function including an offset value. The vertical trajectories of the scala tympani exhibited a non-monotonous spiral slope with specific regions at risk for CI-related insertion trauma, and three slope categories could be distinguished. This presented automatic tracing method allows the detailed description of cochlear morphology and can be used for both individual and large cohort evaluation of cochlear implant patients.
C1 [van der Jagt, Annerie M. A.; Kalkman, Randy K.; Briaire, Jeroen J.; Frijns, Johan H. M.] Leiden Univ, Med Ctr, Dept Otorhinolaryngol, Leiden, Netherlands.
   [Verbist, Berit M.] Leiden Univ, Med Ctr, Dept Radiol, Leiden, Netherlands.
   [Verbist, Berit M.] Radboud Univ Nijmegen, Med Ctr Nijmegen, Dept Radiol, Nijmegen, Netherlands.
   [Frijns, Johan H. M.] Leiden Univ, Med Ctr, Leiden Inst Brain & Cognit, Leiden, Netherlands.
RP van der Jagt, AMA (corresponding author), Leiden Univ, Med Ctr, Dept Otorhinolaryngol, Leiden, Netherlands.
EM M.A.van_der_Jagt@lumc.nl
RI Briaire, Jeroen J/A-7972-2008; Frijns, Johan H.M./H-6249-2011
OI Briaire, Jeroen J/0000-0003-4302-817X; Frijns, Johan
   H.M./0000-0002-1180-3314; van der Jagt, Annerie/0000-0003-3438-6784;
   Verbist, Berit/0000-0002-1010-2583
FU Advanced Bionics
FX This research was financially supported by Advanced Bionics through
   funding of the researchers. The content is solely the responsibility of
   the authors. Language editing of the manuscript was conducted by San
   Francisco Editing.
CR Aschendorff A, 2003, J LARYNGOL OTOL, V117, P527, DOI 10.1258/002221503322112932
   Avci E., 2017, 3 DIMENSIONAL FORCE, P168
   Avci E, 2014, J COMP NEUROL, V522, P3245, DOI 10.1002/cne.23594
   Bellos C, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/485783
   Biedron S, 2010, OTOL NEUROTOL, V31, P731, DOI 10.1097/MAO.0b013e3181d27b5e
   Braun K, 2012, ACTA OTO-LARYNGOL, V132, P603, DOI 10.3109/00016489.2011.653670
   Briaire J. J., 2015, EAR HEAR
   DIMOPOULOS P, 1990, ACTA RADIOL, V31, P439
   Erixon E, 2009, OTOL NEUROTOL, V30, P14, DOI 10.1097/MAO.0b013e31818a08e8
   Escude Bernard, 2006, Audiol Neurootol, V11 Suppl 1, P27, DOI 10.1159/000095611
   Eshraghi AA, 2003, LARYNGOSCOPE, V113, P415, DOI 10.1097/00005537-200303000-00005
   Kral A, 2015, C IMPL AUD PROSTH CI
   Pelliccia P, 2014, ACTA OTORHINOLARYNGO, V34, P42
   Rask-Andersen H, 2012, ANAT REC, V295, P1791, DOI 10.1002/ar.22599
   Rebscher SJ, 2008, J REHABIL RES DEV, V45, P731, DOI 10.1682/JRRD.2007.08.0119
   van der Marel KS, 2014, EAR HEARING, V35, pE9, DOI 10.1097/01.aud.0000436256.06395.63
   Verbist B, 2009, COCHLEAR IMAGING ERA
   Verbist BM, 2010, OTOL NEUROTOL, V31, P722, DOI 10.1097/MAO.0b013e3181d279e0
   Verbist BM, 2009, OTOL NEUROTOL, V30, P471, DOI 10.1097/MAO.0b013e3181a32c0d
   Wardrop P, 2005, HEARING RES, V203, P54, DOI 10.1016/j.heares.2004.11.006
   Wurfel W, 2014, HEARING RES, V316, P65, DOI 10.1016/j.heares.2014.07.013
   Wysocki J, 1999, HEARING RES, V135, P39, DOI 10.1016/S0378-5955(99)00088-X
   Yoo SK, 2000, IEEE T BIO-MED ENG, V47, P1392, DOI 10.1109/10.871413
   ZRUNEK M, 1980, ARCH OTO-RHINO-LARYN, V229, P159, DOI 10.1007/BF02565517
NR 24
TC 5
Z9 5
U1 0
U2 2
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD DEC 14
PY 2017
VL 7
AR 17566
DI 10.1038/s41598-017-16126-6
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FP8KO
UT WOS:000417892100017
PM 29242508
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wade, L
AF Wade, Lacey
TI The role of duration in the perception of vowel merger
SO LABORATORY PHONOLOGY
LA English
DT Article
DE vowel merger; sociophonetics; perception; production; duration
ID NEW-ZEALAND ENGLISH; AMERICAN-ENGLISH; ACOUSTIC CUES; SPEECH-PERCEPTION;
   SYLLABLE NUCLEI; CATEGORIZATION; RECOGNITION; VARIETIES; CONTRAST;
   JAPANESE
AB Speakers with vowel categories that are considered merged by traditional measures (e.g., F1 and F2 measurements at a single time point) may contrast vowel classes in dimensions beyond vowel quality, such as duration. Durational differences among vowel classes have been observed to persist even in cases of spectral overlap (e.g., Fridland et al., 2014; Labov & Baranowski, 2006), suggesting that duration may serve as a contrastive cue among spectrally-merged or near-merged vowel classes. This paper examines the role of duration in perception in two communities: Youngstown, OH, which exhibits multiple patterns of merger and distinction among POOL-, PULL-, and POLE-Class words, and Burlington, VT, whose residents are largely unmerged. This paper presents the results of a forced-choice identification task consisting of lexical stimuli with synthetically manipulated vowel-liquid durations, analyzed in light of participants' production data. Results indicate that duration influences vowel categorization and is utilized more extensively when spectral cues are diminished or unavailable.
C1 [Wade, Lacey] Univ Penn, Dept Linguist, Philadelphia, PA 19104 USA.
RP Wade, L (corresponding author), Univ Penn, Dept Linguist, Philadelphia, PA 19104 USA.
EM laceya@sas.upenn.edu
CR Ainsworth W. A., 1972, J ACOUST SOC AM, V99, P2350
   Arnold L. R., 2015, U PENNSYLVANIA WORKI, V21
   Becker M., 2014, EXPERIGEN ONLINE EXP
   Beddor PS, 2009, LANGUAGE, V85, P785
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   BENNETT DC, 1968, LANG SPEECH, V11, P65, DOI 10.1177/002383096801100201
   Benson EJ, 2011, AM SPEECH, V86, P271, DOI 10.1215/00031283-1503910
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Bowie David, 2000, THESIS
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Clark L, 2013, ENGL LANG LINGUIST, V17, P229, DOI 10.1017/S1360674313000014
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   de Jong NH, 2009, BEHAV RES METHODS, V41, P385, DOI 10.3758/BRM.41.2.385
   Diehl R. L., 1990, ADV SPEECH HEARING L, P243
   Drager KK, 2011, J PHONETICS, V39, P694, DOI 10.1016/j.wocn.2011.08.005
   Escudero Paola., 2000, THESIS
   Faber A., 1990, LANG VAR CHANGE, V2, P155, DOI DOI 10.1017/S0954394500000326
   Faber A., 1995, LANG VAR CHANGE, V7, P35, DOI DOI 10.1017/S0954394500000892
   FITCH HL, 1980, PERCEPT PSYCHOPHYS, V27, P343, DOI 10.3758/BF03206123
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Fridland V, 2014, J ACOUST SOC AM, V136, P341, DOI 10.1121/1.4883599
   Gahl S, 2008, LANGUAGE, V84, P474
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Hay J, 2010, LANG SPEECH, V53, P447, DOI 10.1177/0023830910372489
   Hay J, 2006, LINGUIST REV, V23, P321, DOI 10.1515/TLR.2006.013
   Hay J, 2013, ENGL LANG LINGUIST, V17, P241, DOI 10.1017/S1360674313000026
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Herold Ruth, 1990, THESIS
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Hisagi M, 2010, BRAIN RES, V1360, P89, DOI 10.1016/j.brainres.2010.08.092
   HOWELL P, 1993, J ACOUST SOC AM, V94, P2063, DOI 10.1121/1.407479
   Irons TL, 2007, LANG VAR CHANGE, V19, P137, DOI 10.1017/S0954394507070056
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Jacewicz E, 2007, AM SPEECH, V82, P367, DOI 10.1215/00031283-2007-024
   Jessen M., 1998, PHONETICS PHONOLOGY
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kingston J., 1995, PHONOLOGY PHONETIC E
   KOHLER KJ, 1979, PHONETICA, V36, P332, DOI 10.1159/000259970
   Labov W., 1972, QUANTITATIVE STUDY S, V1
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Labov W., 1991, LANG VAR CHANGE, V3, P33, DOI [10.1017/S0954394500000442, DOI 10.1017/S0954394500000442]
   Labov W., 2006, ATLAS N AM ENGLISH P
   Labov W., 2006, LANG VAR CHANGE, V18, P1
   Langstrof C, 2009, LANG VAR CHANGE, V21, P437, DOI 10.1017/S0954394509990159
   Lobanov B. M., 1971, J ACOUST SOC AM, V68, P1636
   Majors T, 2005, AM SPEECH, V80, P165, DOI 10.1215/00031283-80-2-165
   Milroy James, 1980, ENGL WORLD-WIDE, V1, P199, DOI DOI 10.1075/EWW.1.2.03MIL
   Nycz J, 2013, ENGL LANG LINGUIST, V17, P325, DOI 10.1017/S1360674313000051
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   REPP BH, 1983, SPEECH COMMUN, V2, P341, DOI 10.1016/0167-6393(83)90050-X
   Sato Y, 2012, DEV PSYCHOL, V48, P18, DOI 10.1037/a0025528
   Sawusch J. R., 1997, J ACOUST SOC AM, V101, P3111
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Tauberer J., 2009, INTRINSIC VOWEL DURA
   Thomas Brynmor, 2005, TE REO, V48, P69
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
   Warren Paul, 2006, COGNITION LANGUAGE D, P101
   Wassink AB, 2006, J ACOUST SOC AM, V119, P2334, DOI 10.1121/1.2168414
   Watson C. L., 1990, J ACOUST SOC AM, V106, P458
NR 64
TC 1
Z9 1
U1 0
U2 1
PU UBIQUITY PRESS LTD
PI LONDON
PA 6 WINDMILL ST, LONDON, W1T 2JB, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD DEC 13
PY 2017
VL 8
IS 1
AR 30
DI 10.5334/labphon.54
PG 34
WC Linguistics; Language & Linguistics
SC Linguistics
GA GB0MK
UT WOS:000428740300001
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Havy, M
   Zesiger, P
AF Havy, Melanie
   Zesiger, Pascal
TI Learning Spoken Words via the Ears and Eyes: Evidence from 30-Month-Old
   Children
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE audio-visual speech perception; word-learning; cross-modal recognition;
   lexical representation; child development
ID VISUAL SPEECH; AUDIOVISUAL SPEECH; PHONETIC INFORMATION; INFANTS LEARN;
   PERCEPTION; LANGUAGE; CATEGORIZATION; RECOGNITION; ADULTS; FACES
AB From the very first moments of their lives, infants are able to link specific movements of the visual articulators to auditory speech signals. However, recent evidence indicates that infants focus primarily on auditory speech signals when learning new words. Here, we ask whether 30-month-old children are able to learn new words based solely on visible speech information, and whether information from both auditory and visual modalities is available after learning in only one modality. To test this, children were taught new lexical mappings. One group of children experienced the words in the auditory modality (i.e., acoustic form of the word with no accompanying face). Another group experienced the words in the visual modality (seeing a silent talking face). Lexical recognition was tested in either the learning modality or in the other modality. Results revealed successful word learning in either modality. Results further showed cross-modal recognition following an auditory-only, but not a visual-only, experience of the words. Together, these findings suggest that visible speech becomes increasingly informative for the purpose of lexical learning, but that an auditory-only experience evokes a cross-modal representation of the words.
C1 [Havy, Melanie; Zesiger, Pascal] Univ Geneva, Fac Psychol & Educ Sci, Geneva, Switzerland.
RP Havy, M (corresponding author), Univ Geneva, Fac Psychol & Educ Sci, Geneva, Switzerland.
EM melanie.havy@gmail.com
FU SNSF grant [100014_159402]
FX This work was funded by a SNSF grant (100014_159402) to MH and PZ.
CR Althaus N, 2016, DEVELOPMENTAL SCI, V19, P770, DOI 10.1111/desc.12358
   Altvater-Mackensen N, 2016, DEV PSYCHOL, V52, P191, DOI 10.1037/a0039964
   Altvater-Mackensen N, 2015, CHILD DEV, V86, P362, DOI 10.1111/cdev.12320
   Baart M, 2015, J EXP CHILD PSYCHOL, V129, P157, DOI 10.1016/j.jecp.2014.08.002
   Baart M, 2014, COGNITION, V130, P31, DOI 10.1016/j.cognition.2013.09.006
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barutchu A, 2008, EUR J COGN PSYCHOL, V20, P1, DOI 10.1080/09541440601125623
   Bernstein LE, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00034
   BINNIE CA, 1974, J SPEECH HEAR RES, V17, P619, DOI 10.1044/jshr.1704.619
   Bornstein MH, 2010, DEV PSYCHOL, V46, P350, DOI 10.1037/a0018411
   Brancazio L, 2004, J EXP PSYCHOL HUMAN, V30, P445, DOI 10.1037/0096-1523.30.3.445
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Buchwald AB, 2009, LANG COGNITIVE PROC, V24, P580, DOI 10.1080/01690960802536357
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   de Urabain IRS, 2015, BEHAV RES METHODS, V47, P53, DOI 10.3758/s13428-014-0456-0
   Delle Luche C, 2015, INFANT BEHAV DEV, V40, P151, DOI 10.1016/j.infbeh.2015.05.005
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Eberhardt SP, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00829
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1
   Ferguson B, 2016, COGNITION, V146, P185, DOI 10.1016/j.cognition.2015.09.020
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Ferry AL, 2010, CHILD DEV, V81, P472, DOI 10.1111/j.1467-8624.2009.01408.x
   Floccia C, 2014, J CHILD LANG, V41, P1085, DOI 10.1017/S0305000913000287
   Fort M, 2013, LANG COGNITIVE PROC, V28, P1207, DOI 10.1080/01690965.2012.701758
   Fort M, 2012, INT J BEHAV DEV, V36, P457, DOI 10.1177/0165025412447752
   Fort M, 2010, SPEECH COMMUN, V52, P525, DOI 10.1016/j.specom.2010.02.005
   Frank MC, 2014, J EXP CHILD PSYCHOL, V118, P13, DOI 10.1016/j.jecp.2013.08.012
   Ganger J, 2004, DEV PSYCHOL, V40, P621, DOI 10.1037/0012-1649.40.4.621
   Grieco-Calub Tina M., 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920629
   Guellai B, 2011, VIS COGN, V19, P1212, DOI 10.1080/13506285.2011.620578
   Havy M, 2017, CHILD DEV, V88, P2043, DOI 10.1111/cdev.12715
   Havy M, 2016, INT J BEHAV DEV, V40, P41, DOI 10.1177/0165025415570646
   Havy M, 2009, INFANCY, V14, P439, DOI 10.1080/15250000902996532
   Hessels RS, 2016, BEHAV RES METHODS, V48, P1694, DOI 10.3758/s13428-015-0676-y
   JACKSON PL, 1976, J SPEECH HEAR RES, V19, P796, DOI 10.1044/jshr.1904.796
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jerger S, 2014, J EXP CHILD PSYCHOL, V126, P295, DOI 10.1016/j.jecp.2014.05.003
   Jerger S, 2009, J EXP CHILD PSYCHOL, V102, P40, DOI 10.1016/j.jecp.2008.08.002
   Johnson SP, 2010, COGNITIVE SCI, V34, P1158, DOI 10.1111/j.1551-6709.2010.01127.x
   Kern S., 2003, GLOSSA, V85, P48
   Kubicek C, 2014, INFANT BEHAV DEV, V37, P644, DOI 10.1016/j.infbeh.2014.08.010
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   KUHL PK, 1991, J EXP PSYCHOL HUMAN, V17, P829, DOI 10.1037/0096-1523.17.3.829
   Lalonde K, 2015, J SPEECH LANG HEAR R, V58, P135, DOI 10.1044/2014_JSLHR-H-13-0343
   Lewkowicz DJ, 2013, INT J BEHAV DEV, V37, P90, DOI 10.1177/0165025412467582
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Maidment DW, 2015, J SPEECH LANG HEAR R, V58, P61, DOI 10.1044/2014_JSLHR-S-14-0044
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McMurray B, 2007, SCIENCE, V317, P631, DOI 10.1126/science.1144073
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Perszyk DR, 2016, COGNITION, V153, P175, DOI 10.1016/j.cognition.2016.05.004
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Robinson CW, 2004, CHILD DEV, V75, P1387, DOI 10.1111/j.1467-8624.2004.00747.x
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Samuel AG, 2014, J EXP PSYCHOL HUMAN, V40, P1479, DOI 10.1037/a0036656
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Sheehan EA, 2007, BRAIN LANG, V101, P246, DOI 10.1016/j.bandl.2006.11.008
   Sloutsky VM, 2008, COGNITIVE SCI, V32, P342, DOI 10.1080/03640210701863495
   Streri A, 2016, INFANCY, V21, P177, DOI 10.1111/infa.12104
   Suanda SH, 2013, LANG LEARN DEV, V9, P50, DOI 10.1080/15475441.2012.723189
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Vlach HA, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00046
   Vouloumanos A, 2009, DEV PSYCHOL, V45, P1611, DOI 10.1037/a0016134
   Waxman SR, 2005, COGNITION, V95, pB59, DOI 10.1016/j.cognition.2004.09.003
   Weatherhead D, 2017, COGNITION, V160, P103, DOI 10.1016/j.cognition.2017.01.002
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Wojcik EH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00151
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
   Zamuner TS, 2014, DEVELOPMENTAL SCI, V17, P481, DOI 10.1111/desc.12149
NR 81
TC 3
Z9 3
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD DEC 8
PY 2017
VL 8
AR 2122
DI 10.3389/fpsyg.2017.02122
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA FP2WM
UT WOS:000417480700001
PM 29276493
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Golob, EJ
   Lewald, J
   Getzmann, S
   Mock, JR
AF Golob, Edward J.
   Lewald, Joerg
   Getzmann, Stephan
   Mock, Jeffrey R.
TI Numerical value biases sound localization
SO SCIENTIFIC REPORTS
LA English
DT Article
ID PRIMARY AUDITORY-CORTEX; EYE-POSITION; NUMBER MAGNITUDE; MENTAL
   REPRESENTATION; SPEECH-PERCEPTION; ACOUSTIC CONTEXT; FIELD POTENTIALS;
   3-CHANNEL MODEL; WORKING-MEMORY; VISUAL SPACE
AB Speech recognition starts with representations of basic acoustic perceptual features and ends by categorizing the sound based on long-term memory for word meaning. However, little is known about whether the reverse pattern of lexical influences on basic perception can occur. We tested for a lexical influence on auditory spatial perception by having subjects make spatial judgments of number stimuli. Four experiments used pointing or left/right 2-alternative forced choice tasks to examine perceptual judgments of sound location as a function of digit magnitude (1-9). The main finding was that for stimuli presented near the median plane there was a linear left-to-right bias for localizing smaller-tolarger numbers. At lateral locations there was a central-eccentric location bias in the pointing task, and either a bias restricted to the smaller numbers (left side) or no significant number bias (right side). Prior number location also biased subsequent number judgments towards the opposite side. Findings support a lexical influence on auditory spatial perception, with a linear mapping near midline and more complex relations at lateral locations. Results may reflect coding of dedicated spatial channels, with two representing lateral positions in each hemispace, and the midline area represented by either their overlap or a separate third channel.
C1 [Golob, Edward J.; Mock, Jeffrey R.] Tulane Univ, Dept Psychol, New Orleans, LA 70118 USA.
   [Golob, Edward J.] Tulane Univ, Program Neurosci, New Orleans, LA 70118 USA.
   [Lewald, Joerg; Getzmann, Stephan] Ruhr Univ Bochum, Fac Psychol, D-44780 Bochum, Germany.
   [Lewald, Joerg; Getzmann, Stephan] Leibniz Res Ctr Working Environm & Human Factors, Ardeystr 67, D-44139 Dortmund, Germany.
   [Golob, Edward J.; Mock, Jeffrey R.] Univ Texas San Antonio, Dept Psychol, San Antonio, TX 78249 USA.
RP Golob, EJ (corresponding author), Tulane Univ, Dept Psychol, New Orleans, LA 70118 USA.; Golob, EJ (corresponding author), Tulane Univ, Program Neurosci, New Orleans, LA 70118 USA.; Golob, EJ (corresponding author), Univ Texas San Antonio, Dept Psychol, San Antonio, TX 78249 USA.
EM edward.golob@utsa.edu
RI Lewald, Jorg/D-3034-2009
OI Lewald, Jorg/0000-0001-9351-0170; Mock, Jeffrey/0000-0003-0446-6687;
   Getzmann, Stephan/0000-0002-6382-0183
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-0844961]; National Institutes of HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA
   [R01DC014736]; Louisiana Board of Regents [NSF2011-LINK-63]; German
   Research Foundation (DFG)German Research Foundation (DFG) [GE 1920/3-1,
   LE 673/2-1]; German Federal Ministry of Education and Research
   (BMBF)Federal Ministry of Education & Research (BMBF) [01GQ1424E];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC014736, R01DC014736, R01DC014736,
   R01DC014736, R01DC014736] Funding Source: NIH RePORTER
FX This work was supported by grants from the National Science Foundation
   (BCS-0844961), National Institutes of Health (R01DC014736), and the
   Louisiana Board of Regents (NSF2011-LINK-63)(EG). SG was supported by a
   grant from the German Research Foundation (DFG; GE 1920/3-1), and JL was
   supported by grants from the German Research Foundation (DFG; LE
   673/2-1) and the German Federal Ministry of Education and Research
   (BMBF; 01GQ1424E). The funding sources had no role in the study design,
   data collection and analysis, writing the report, and the decision to
   submit the article for publication.
CR Abrahamse E, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00977
   Alards-Tomalin D, 2015, ACTA PSYCHOL, V160, P95, DOI 10.1016/j.actpsy.2015.07.004
   Anderson BA, 2011, P NATL ACAD SCI USA, V108, P10367, DOI 10.1073/pnas.1104047108
   Bachtold D, 1998, NEUROPSYCHOLOGIA, V36, P731, DOI 10.1016/S0028-3932(98)00002-5
   Blauert J., 1997, SPATIAL HEARING PSYC
   Bloom P., 1999, LANGUAGE SPACE
   Bridgeman B, 1997, PSYCHOL RES-PSYCH FO, V60, P238, DOI 10.1007/BF00419408
   Briley PM, 2016, JARO-J ASSOC RES OTO, V17, P331, DOI 10.1007/s10162-016-0571-y
   Briley PM, 2013, JARO-J ASSOC RES OTO, V14, P83, DOI 10.1007/s10162-012-0356-x
   BRUNER JS, 1947, J ABNORM SOC PSYCH, V42, P33, DOI 10.1037/h0058484
   BUTLER RA, 1962, J ACOUST SOC AM, V34, P1100, DOI 10.1121/1.1918252
   Campbell L., 2003, HDB LINGUISTICS, P81
   Casarotti M, 2007, COGNITION, V102, P101, DOI 10.1016/j.cognition.2006.09.001
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   Cicchini GM, 2014, P NATL ACAD SCI USA, V111, P7867, DOI 10.1073/pnas.1402785111
   Cui QN, 2010, J NEUROPHYSIOL, V103, P1020, DOI 10.1152/jn.00500.2009
   DEHAENE S, 1993, J EXP PSYCHOL GEN, V122, P371, DOI 10.1037/0096-3445.122.3.371
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Dingle RN, 2013, J ACOUST SOC AM, V133, P417, DOI 10.1121/1.4768799
   Dingle RN, 2012, J ACOUST SOC AM, V131, P4023, DOI 10.1121/1.3701877
   Dingle RN, 2010, HEARING RES, V268, P67, DOI 10.1016/j.heares.2010.04.017
   Fischer MH, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01315
   Fischer MH, 2003, NAT NEUROSCI, V6, P555, DOI 10.1038/nn1066
   Getzmann S, 2003, PERCEPT PSYCHOPHYS, V65, P1045, DOI 10.3758/BF03194833
   Gevers W, 2006, EXP PSYCHOL, V53, P58, DOI 10.1027/1618-3169.53.1.58
   Gevers W, 2006, J EXP PSYCHOL HUMAN, V32, P32, DOI 10.1037/0096-1523.32.1.32
   Gevers W, 2003, COGNITION, V87, pB87, DOI 10.1016/S0010-0277(02)00234-2
   Golob EJ, 2016, PERCEPTION, V45, P165, DOI 10.1177/0301006615599906
   Golob EJ, 2011, BRAIN RES, V1384, P128, DOI 10.1016/j.brainres.2011.01.089
   GUSKI R, 1990, PERCEPTION, V19, P819, DOI 10.1068/p190819
   HAMLIN R, 1974, PERCEPT MOTOR SKILL, V38, P839, DOI 10.2466/pms.1974.38.3.839
   Hansen T, 2006, NAT NEUROSCI, V9, P1367, DOI 10.1038/nn1794
   Hansen T, 2008, J VISION, V8, DOI 10.1167/8.8.8
   Hartmann M., 2016, Q J EXPT PSYCHOL
   Heller LM, 1996, J ACOUST SOC AM, V99, P3632, DOI 10.1121/1.414961
   Henmon V. A. C., 1906, TIME PERCEPTION MEAS
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Hubbard EM, 2005, NAT REV NEUROSCI, V6, P435, DOI 10.1038/nrn1684
   Ishihara M, 2006, NEUROPSYCHOLOGIA, V44, P1009, DOI 10.1016/j.neuropsychologia.2005.11.008
   JESTEADT W, 1977, J EXP PSYCHOL HUMAN, V3, P92, DOI 10.1037/0096-1523.3.1.92
   KITZES LM, 1980, J COMP NEUROL, V192, P455, DOI 10.1002/cne.901920306
   Kopco N, 2007, J ACOUST SOC AM, V121, P420, DOI 10.1121/1.2390677
   Krause F, 2017, PSYCHOL RES-PSYCH FO, V81, P664, DOI 10.1007/s00426-016-0771-4
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lee CC, 2011, NAT NEUROSCI, V14, P108, DOI 10.1038/nn.2713
   Lewald J, 2006, HEARING RES, V213, P99, DOI 10.1016/j.heares.2006.01.001
   Lewald J, 2004, NEUROPSYCHOLOGIA, V42, P1598, DOI 10.1016/j.neuropsychologia.2004.04.012
   Lewald J, 1996, EXP BRAIN RES, V108, P473
   Lewald J, 1997, BEHAV BRAIN RES, V87, P35, DOI 10.1016/S0166-4328(96)02254-1
   Lewald J, 2000, BEHAV BRAIN RES, V108, P105, DOI 10.1016/S0166-4328(99)00141-2
   Lewald J, 1998, HEARING RES, V115, P206, DOI 10.1016/S0378-5955(97)00190-1
   Lewald J, 2001, COGNITIVE BRAIN RES, V12, P153, DOI 10.1016/S0926-6410(01)00042-8
   Liu HS, 2009, NEURON, V62, P281, DOI 10.1016/j.neuron.2009.02.025
   Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045
   Mayer E, 1999, BRAIN, V122, P1107, DOI 10.1093/brain/122.6.1107
   McRae K., 2013, OXFORD HDB COGNITIVE, P206, DOI DOI 10.1093/OXFORDHB/9780195376746.013.0014
   MIDDLEBROOKS JC, 1981, J NEUROSCI, V1, P107
   MILLS AW, 1958, J ACOUST SOC AM, V30, P237, DOI 10.1121/1.1909553
   Mock JR, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00179
   MORAY N, 1959, Q J EXP PSYCHOL, V11, P56, DOI 10.1080/17470215908416289
   MOYER RS, 1967, NATURE, V215, P1519, DOI 10.1038/2151519a0
   Myachykov A, 2015, ACTA PSYCHOL, V161, P162, DOI 10.1016/j.actpsy.2015.09.006
   NOBRE AC, 1995, J NEUROSCI, V15, P1090
   Nuerk HC, 2005, EXP PSYCHOL, V52, P187, DOI 10.1027/1618-3169.52.3.187
   Ocklenburg S, 2010, BRAIN COGNITION, V72, P210, DOI 10.1016/j.bandc.2009.08.013
   Ono F, 2011, PSYCHOL SCI, V22, P472, DOI 10.1177/0956797611403319
   Paffen CLE, 2011, COGNITION, V119, P468, DOI 10.1016/j.cognition.2011.01.010
   Peissig JJ, 2007, ANNU REV PSYCHOL, V58, P75, DOI 10.1146/annurev.psych.58.102904.190114
   Petersen SE, 2012, ANNU REV NEUROSCI, V35, P73, DOI 10.1146/annurev-neuro-062111-150525
   Phillips DP, 2008, HEARING RES, V238, P124, DOI 10.1016/j.heares.2007.09.007
   Posner M. I., 1978, CHRONOMETRIC EXPLORA
   POSTMAN L, 1948, J ABNORM SOC PSYCH, V43, P142, DOI 10.1037/h0059765
   RAJAN R, 1990, J NEUROPHYSIOL, V64, P888
   Rayner K., 2013, OXFORD HDB COGNITIVE, P442, DOI DOI 10.1093/OXFORDHB/9780195376746.013.0028
   Razavi B, 2007, J NEUROSCI, V27, P10249, DOI 10.1523/JNEUROSCI.0938-07.2007
   RESTLE F, 1970, J EXP PSYCHOL, V83, P274, DOI 10.1037/h0028573
   Roelofs C., 1935, ARCH AUGENHEILKD, V109, P395
   Salmelin R, 2007, CLIN NEUROPHYSIOL, V118, P237, DOI 10.1016/j.clinph.2006.07.316
   Salminen NH, 2012, NEUROSCIENTIST, V18, P602, DOI 10.1177/1073858411434209
   Shaki S, 2012, J EXP PSYCHOL HUMAN, V38, P515, DOI 10.1037/a0026729
   SHEPARD RN, 1984, SCIENCE, V226, P1333, DOI 10.1126/science.226.4680.1333
   Song JH, 2008, COGNITION, V106, P994, DOI 10.1016/j.cognition.2007.03.014
   Stecker GC, 2005, PLOS BIOL, V3, P520, DOI 10.1371/journal.pbio.0030078
   Summerfield JJ, 2011, J NEUROSCI, V31, P14952, DOI 10.1523/JNEUROSCI.5541-10.2011
   Suzuki S, 1997, J EXP PSYCHOL HUMAN, V23, P443, DOI 10.1037/0096-1523.23.2.443
   Tabry V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00932
   THURLOW WR, 1973, J ACOUST SOC AM, V53, P1573, DOI 10.1121/1.1913505
   van Dijck JP, 2011, COGNITION, V119, P114, DOI 10.1016/j.cognition.2010.12.013
   Von Hornbostel E. M., 1926, HDB NORMALEN PATHOLO, P602
   WALLACH H, 1949, AM J PSYCHOL, V62, P315, DOI 10.2307/1418275
   Walsh V, 2003, TRENDS COGN SCI, V7, P483, DOI 10.1016/j.tics.2003.09.002
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Weis T, 2016, Q J EXP PSYCHOL, V69, P1366, DOI 10.1080/17470218.2015.1082142
   Witzel C, 2016, J EXP PSYCHOL HUMAN, V42, P540, DOI 10.1037/xhp0000154
   Wood G., 2008, PSYCHOL SCI Q, V50, P489, DOI DOI 10.1027/1618-3169.52.3.187
   Yost W., 1987, DIRECTIONAL HEARING
   Zanolie K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00987
NR 97
TC 1
Z9 1
U1 0
U2 3
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD DEC 8
PY 2017
VL 7
AR 17252
DI 10.1038/s41598-017-17429-4
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FP2QQ
UT WOS:000417463500051
PM 29222526
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rampinini, AC
   Handjaras, G
   Leo, A
   Cecchetti, L
   Ricciardi, E
   Marotta, G
   Pietrini, P
AF Rampinini, Alessandra Cecilia
   Handjaras, Giacomo
   Leo, Andrea
   Cecchetti, Luca
   Ricciardi, Emiliano
   Marotta, Giovanna
   Pietrini, Pietro
TI Functional and spatial segregation within the inferior frontal and
   superior temporal cortices during listening, articulation imagery, and
   production of vowels
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEECH-PERCEPTION EVIDENCE; FALSE DISCOVERY RATE; BROCAS AREA; HUMAN
   BRAIN; FMRI; CORTEX; LANGUAGE; GYRUS; REPRESENTATION; APHASIA
AB Classical models of language localize speech perception in the left superior temporal and production in the inferior frontal cortex. Nonetheless, neuropsychological, structural and functional studies have questioned such subdivision, suggesting an interwoven organization of the speech function within these cortices. We tested whether sub-regions within frontal and temporal speech-related areas retain specific phonological representations during both perception and production. Using functional magnetic resonance imaging and multivoxel pattern analysis, we showed functional and spatial segregation across the left fronto-temporal cortex during listening, imagery and production of vowels. In accordance with classical models of language and evidence from functional studies, the inferior frontal and superior temporal cortices discriminated among perceived and produced vowels respectively, also engaging in the non-classical, alternative function -i.e. perception in the inferior frontal and production in the superior temporal cortex. Crucially, though, contiguous and non-overlapping sub-regions within these hubs performed either the classical or non-classical function, the latter also representing non-linguistic sounds (i.e., pure tones). Extending previous results and in line with integration theories, our findings not only demonstrate that sensitivity to speech listening exists in production-related regions and vice versa, but they also suggest that the nature of such interwoven organisation is built upon lowlevel perception.
C1 [Rampinini, Alessandra Cecilia; Handjaras, Giacomo; Leo, Andrea; Cecchetti, Luca; Ricciardi, Emiliano; Pietrini, Pietro] IMT Sch Adv Studies, I-55100 Lucca, Italy.
   [Marotta, Giovanna] Univ Pisa, Dept Philol Literature & Linguist, I-56100 Pisa, Italy.
RP Ricciardi, E (corresponding author), IMT Sch Adv Studies, I-55100 Lucca, Italy.
EM emiliano.ricciardi@imtlucca.it
RI Pietrini, Pietro/Z-4202-2019; Ricciardi, Emiliano/E-6929-2011;
   Cecchetti, Luca/K-7060-2016
OI Ricciardi, Emiliano/0000-0002-7178-9534; Pietrini,
   Pietro/0000-0002-6768-5556; Cecchetti, Luca/0000-0001-5184-6477;
   Rampinini, Alessandra/0000-0002-3016-5231; Handjaras,
   Giacomo/0000-0001-5677-8434
CR Amunts K, 2012, TRENDS COGN SCI, V16, P418, DOI 10.1016/j.tics.2012.06.005
   Amunts K, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000489
   Andersson J. L., 2007, TR07JA2 FMRIB U OXF, V2
   Anwander A, 2007, CEREB CORTEX, V17, P816, DOI 10.1093/cercor/bhk034
   Ardila Alfredo, 2016, Front Hum Neurosci, V10, P249, DOI 10.3389/fnhum.2016.00249
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   BADDELEY A, 1984, Q J EXP PSYCHOL-A, V36, P233, DOI 10.1080/14640748408402157
   Basilakos A, 2015, STROKE, V46, P1561, DOI 10.1161/STROKEAHA.115.009211
   Bates E, 2003, NAT NEUROSCI, V6, P448, DOI 10.1038/nn1050
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bonte M, 2014, J NEUROSCI, V34, P4548, DOI 10.1523/JNEUROSCI.4339-13.2014
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Chakrabarti S, 2015, BIOMED ENG LETT, V5, P10, DOI 10.1007/s13534-015-0175-1
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Connolly AC, 2012, J NEUROSCI, V32, P2608, DOI 10.1523/JNEUROSCI.5547-11.2012
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   Cox Robert W, 2017, Proc Natl Acad Sci U S A, V114, pE3370, DOI 10.1073/pnas.1614961114
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Davis C, 2008, BRAIN LANG, V105, P50, DOI 10.1016/j.bandl.2008.01.012
   DEMONET JF, 1992, BRAIN, V115, P1753, DOI 10.1093/brain/115.6.1753
   Dronkers NF, 1996, NATURE, V384, P159, DOI 10.1038/384159a0
   Embick D, 2000, P NATL ACAD SCI USA, V97, P6150, DOI 10.1073/pnas.100098897
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Feng G., 2017, CEREB CORTEX, P1
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   Fonov V. S., 2009, NEUROIMAGE, V47, pS102, DOI DOI 10.1016/S1053-8119(09)70884-5
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Fullerton BC, 2007, J COMP NEUROL, V504, P470, DOI 10.1002/cne.21432
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037
   Goucha T, 2015, NEUROIMAGE, V114, P294, DOI 10.1016/j.neuroimage.2015.04.011
   Grush R, 2004, BEHAV BRAIN SCI, V27, P377, DOI 10.1017/S0140525X04000093
   Hagmann P, 2008, PLOS BIOL, V6, P1479, DOI 10.1371/journal.pbio.0060159
   Handjaras G, 2016, NEUROIMAGE, V135, P232, DOI 10.1016/j.neuroimage.2016.04.063
   Hardcastle W. J, 2010, HDB PHONETIC SCI
   Heim S, 2008, NEUROIMAGE, V40, P1362, DOI 10.1016/j.neuroimage.2008.01.009
   Hickok G, 2011, BRAIN LANG, V119, P214, DOI 10.1016/j.bandl.2011.08.001
   HINKE RM, 1993, NEUROREPORT, V4, P675, DOI 10.1097/00001756-199306000-00018
   Huang J, 2002, HUM BRAIN MAPP, V15, P39, DOI 10.1002/hbm.1060
   Iacoboni M, 2008, J PHYSIOL-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Josephs KA, 2006, BRAIN, V129, P1385, DOI 10.1093/brain/awl078
   Kauramaki J, 2010, J NEUROSCI, V30, P1314, DOI 10.1523/JNEUROSCI.1950-09.2010
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leo A, 2016, ELIFE, V5, DOI [10.7554/el.ife.13420, 10.7554/eLife.13420]
   Long MA, 2016, NEURON, V89, P1187, DOI 10.1016/j.neuron.2016.01.032
   Markiewicz CJ, 2016, NEUROIMAGE, V141, P174, DOI 10.1016/j.neuroimage.2016.07.023
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b
   Murakami T, 2015, J NEUROSCI, V35, P1411, DOI 10.1523/JNEUROSCI.0246-14.2015
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Obleser J, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00232
   Okada K, 2006, BRAIN LANG, V98, P112, DOI 10.1016/j.bandl.2006.04.006
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Papoutsi M, 2009, CEREB CORTEX, V19, P2156, DOI 10.1093/cercor/bhn239
   Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007
   Poldrack RA, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002707
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Rampinini A, 2017, STUD SAGGI LINGUIST, V55, P95
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Reiterer S, 2008, BRAIN IMAGING BEHAV, V2, P1, DOI 10.1007/s11682-007-9010-3
   Santoro R, 2017, P NATL ACAD SCI USA, V114, P4799, DOI 10.1073/pnas.1617622114
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Shergill SS, 2002, HUM BRAIN MAPP, V16, P219, DOI 10.1002/hbm.10046
   Shuster LI, 2005, BRAIN LANG, V93, P20, DOI 10.1016/j.bandl.2004.07.007
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Tankus A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1995
   Tian X, 2016, CORTEX, V77, P1, DOI 10.1016/j.cortex.2016.01.002
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   Troyer TW, 2000, J NEUROPHYSIOL, V84, P1204
   VIHMAN MM, 1993, J PHONETICS, V21, P61, DOI 10.1016/S0095-4470(19)31321-X
   Winhuisen L, 2005, STROKE, V36, P1759, DOI 10.1161/01.STR.0000174487.81126.ef
   Winkler AM, 2016, NEUROIMAGE, V141, P502, DOI 10.1016/j.neuroimage.2016.05.068
   Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]
   Zhang QT, 2016, EUR J NEUROSCI, V43, P773, DOI 10.1111/ejn.13164
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 84
TC 8
Z9 8
U1 2
U2 4
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD DEC 5
PY 2017
VL 7
AR 17029
DI 10.1038/s41598-017-17314-0
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FO7JX
UT WOS:000417051000079
PM 29208951
OA DOAJ Gold, Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Bergelson, E
   Aslin, RN
AF Bergelson, Elika
   Aslin, Richard N.
TI Nature and origins of the lexicon in 6-mo-olds
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE word learning; lexicon; cognitive development; language acquisition;
   environmental effects
ID WORD COMPREHENSION; SPEECH-PERCEPTION; 1ST YEAR; ACQUISITION; CHILDREN;
   INPUT
AB Recent research reported the surprising finding that even 6-moolds understand common nouns [Bergelson E, Swingley D (2012) Proc Natl Acad Sci USA 109:3253-3258]. However, is their early lexicon structured and acquired like older learners? We test 6-moolds for a hallmark of the mature lexicon: cross-word relations. We also examine whether properties of the home environment that have been linked with lexical knowledge in older children are detectable in the initial stage of comprehension. We use a new dataset, which includes in-lab comprehension and home measures from the same infants. We find evidence for cross-word structure: On seeing two images of common nouns, infants looked significantly more at named target images when the competitor images were semantically unrelated (e.g., milk and foot) than when they were related (e.g., milk and juice), just as older learners do. We further find initial evidence for home-lab links: common noun "copresence" (i.e., whether words' referents were present and attended to in home recordings) correlated with in-lab comprehension. These findings suggest that, even in neophyte word learners, cross-word relations are formed early and the home learning environment measurably helps shape the lexicon from the outset.
C1 [Bergelson, Elika] Duke Univ, Psychol & Neurosci, Durham, NC 27708 USA.
   [Bergelson, Elika; Aslin, Richard N.] Univ Rochester, Brain & Cognit Sci, Rochester, NY 14627 USA.
   [Aslin, Richard N.] Haskins Labs Inc, New Haven, CT 06511 USA.
RP Bergelson, E (corresponding author), Duke Univ, Psychol & Neurosci, Durham, NC 27708 USA.; Bergelson, E (corresponding author), Univ Rochester, Brain & Cognit Sci, Rochester, NY 14627 USA.
EM elika.bergelson@gmail.com
OI Bergelson, Elika/0000-0003-2742-4797
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [T32 DC000035,
   DP5-OD019812, HD-037082]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF
   CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH Eunice
   Kennedy Shriver National Institute of Child Health & Human Development
   (NICHD) [R01HD073890, R01HD037082, R01HD037082, R01HD037082,
   R01HD073890, R01HD037082, R01HD073890, R01HD049681, R01HD049681,
   R01HD037082, R01HD049681, R01HD049681, R01HD073890, R01HD049681] Funding
   Source: NIH RePORTER; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH &HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD037082, R01HD037082, R01HD049681, R01HD049681, R01HD037082,
   R01HD037082, R01HD037082, R01HD037082, R01HD049681, R01HD049681,
   R01HD037082, R01HD037082, R01HD037082, R01HD037082, R01HD037082,
   R01HD037082, R01HD037082, R01HD049681] Funding Source: NIH RePORTER;
   NATIONAL CENTER FOR ADVANCING TRANSLATIONAL SCIENCESUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Center for Advancing Translational Sciences (NCATS)
   [UL1TR001863, UL1TR001863, UL1TR001863, UL1TR001863, UL1TR001863,
   UL1TR001863, UL1TR001863, UL1TR001863, UL1TR001863] Funding Source: NIH
   RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [T32DC000035, T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035, T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035, T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035, T32DC000035,
   T32DC000035, T32DC000035, T32DC000035, T32DC000035] Funding Source: NIH
   RePORTER; OFFICE OF THE DIRECTOR, NATIONAL INSTITUTES OF HEALTHUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USA [DP5OD019812, DP5OD019812, DP5OD019812, DP5OD019812,
   DP5OD019812] Funding Source: NIH RePORTER
FX We thank SEEDLingS staff: Amatuni, Dailey, Koorathota, Schneider, Tor;
   research assistants at University of Rochester and Duke University; and
   National Institutes of Health Grants T32 DC000035 and DP5-OD019812 (to
   E.B.) and HD-037082 (to R.N.A.).
CR Arias-Trejo N, 2010, J EXP CHILD PSYCHOL, V105, P63, DOI 10.1016/j.jecp.2009.10.002
   Bergelson E, 2017, LANG LEARN DEV, V13, P481, DOI 10.1080/15475441.2017.1324308
   Bergelson E, 2018, CHILD DEV, V89, P1567, DOI 10.1111/cdev.12888
   Bergelson E, 2015, LANG LEARN DEV, V11, P369, DOI 10.1080/15475441.2014.979387
   Bergelson E, 2013, COGNITION, V127, P391, DOI 10.1016/j.cognition.2013.02.011
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Borovsky A, 2016, CHILD DEV, V87, P1893, DOI 10.1111/cdev.12554
   Brent MR, 2001, COGNITION, V81, pB33, DOI 10.1016/S0010-0277(01)00122-6
   Dahan D, 2005, PSYCHON B REV, V12, P453, DOI 10.3758/BF03193787
   Dale PS, 1996, BEHAV RES METH INS C, V28, P125, DOI 10.3758/BF03203646
   DEBARYSHE BD, 1993, J CHILD LANG, V20, P455, DOI 10.1017/S0305000900008370
   Delle Luche C, 2014, DEVELOPMENTAL SCI, V17, P948, DOI 10.1111/desc.12164
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   HART B, 1992, DEV PSYCHOL, V28, P1096, DOI 10.1037/0012-1649.28.6.1096
   Hoff E, 2002, CHILD DEV, V73, P418, DOI 10.1111/1467-8624.00415
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   Libertus K, 2013, INFANT BEHAV DEV, V36, P833, DOI 10.1016/j.infbeh.2013.09.007
   Lieven Elena V., 1994, INPUT INTERACTION LA, P56, DOI DOI 10.1017/CBO9780511620690.005
   MacWhinney B., 2000, CHILDES PROJECT TOOL, V2
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   McGillion ML, 2013, IEEE T AUTON MENT DE, V5, P240, DOI 10.1109/TAMD.2013.2275949
   Medina TN, 2011, P NATL ACAD SCI USA, V108, P9014, DOI 10.1073/pnas.1105040108
   Montag JL, 2015, PSYCHOL SCI, V26, P1489, DOI 10.1177/0956797615594361
   Neely JH., 1991, BASIC PROCESSES READ, V11, P264, DOI DOI 10.1016/J.BRAINRES.2007.05.058
   Parise E, 2012, PSYCHOL SCI, V23, P728, DOI 10.1177/0956797612438734
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Seidl A, 2006, DEVELOPMENTAL SCI, V9, P565, DOI 10.1111/j.1467-7687.2006.00534.x
   Shneidman LA, 2012, DEVELOPMENTAL SCI, V15, P659, DOI 10.1111/j.1467-7687.2012.01168.x
   Smith LB, 2002, PSYCHOL SCI, V13, P13, DOI 10.1111/1467-9280.00403
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   Vihman MM, 2004, J MEM LANG, V50, P336, DOI 10.1016/j.jml.2003.11.004
   Walle EA, 2014, DEV PSYCHOL, V50, P336, DOI 10.1037/a0033238
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wojcik EH, 2013, PSYCHOL SCI, V24, P1898, DOI 10.1177/0956797613478198
   Yurovsky D, 2013, DEVELOPMENTAL SCI, V16, P959, DOI 10.1111/desc.12036
NR 40
TC 30
Z9 30
U1 1
U2 9
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD DEC 5
PY 2017
VL 114
IS 49
BP 12916
EP 12921
DI 10.1073/pnas.1712966114
PG 6
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FP0ZS
UT WOS:000417339700031
PM 29158399
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Hannah, B
   Wang, Y
   Jongman, A
   Sereno, JA
   Cao, JG
   Nie, YL
AF Hannah, Beverly
   Wang, Yue
   Jongman, Allard
   Sereno, Joan A.
   Cao, Jiguo
   Nie, Yunlong
TI Cross-Modal Association between Auditory and Visuospatial Information in
   Mandarin Tone Perception in Noise by Native and Non-native Perceivers
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE cross-modal association; gesture; audio-visual; tone perception;
   Mandarin; English
ID VISUAL SPEECH; AUDIOVISUAL PERCEPTION; PROSODIC PROMINENCE; HAND
   GESTURES; PITCH; ATTENTION; LANGUAGE; LIPS; CUES; INTELLIGIBILITY
AB Speech perception involves multiple input modalities. Research has indicated that perceivers establish cross-modal associations between auditory and visuospatial events to aid perception. Such intermodal relations can be particularly beneficial for speech development and learning, where infants and non-native perceivers need additional resources to acquire and process new sounds. This study examines how facial articulatory cues and co-speech hand gestures mimicking pitch contours in space affect non-native Mandarin tone perception. Native English as well as Mandarin perceivers identified tones embedded in noise with either congruent or incongruent Auditory-Facial (AF) and Auditory-FacialGestural (AFG) inputs. Native Mandarin results showed the expected ceiling-level performance in the congruent AF and AFG conditions. In the incongruent conditions, while AF identification was primarily auditory-based, AFG identification was partially based on gestures, demonstrating the use of gestures as valid cues in tone identification. The English perceivers' performance was poor in the congruent AF condition, but improved significantly in AFG. While the incongruent AF identification showed some reliance on facial information, incongruent AFG identification relied more on gestural than auditory-facial information. These results indicate positive effects of facial and especially gestural input on non-native tone perception, suggesting that cross-modal (visuospatial) resources can be recruited to aid auditory perception when phonetic demands are high. The current findings may inform patterns of tone acquisition and development, suggesting how multi-modal speech enhancement principles may be applied to facilitate speech learning.
C1 [Hannah, Beverly; Wang, Yue] Simon Fraser Univ, Dept Linguist, Language & Brain Lab, Burnaby, BC, Canada.
   [Jongman, Allard; Sereno, Joan A.] Univ Kansas, Phonet & Psycholinguist Lab, Dept Linguist, Lawrence, KS 66045 USA.
   [Cao, Jiguo; Nie, Yunlong] Simon Fraser Univ, Dept Stat & Actuarial Sci, Burnaby, BC, Canada.
RP Jongman, A (corresponding author), Univ Kansas, Phonet & Psycholinguist Lab, Dept Linguist, Lawrence, KS 66045 USA.
EM jongman@ku.edu
RI jongman, allard/A-8377-2009
OI jongman, allard/0000-0002-7384-2036; Hannah, Beverly/0000-0001-8938-7173
FU Social Sciences and Humanities Research Council of Canada (SSHRC)
   research grant (SSHRC Insight Grant) [435-2012-1641]
FX This study was supported by a Social Sciences and Humanities Research
   Council of Canada (SSHRC) research grant (SSHRC Insight Grant
   435-2012-1641).
CR Alibali MW, 2001, J MEM LANG, V44, P169, DOI 10.1006/jmla.2000.2752
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Apfelstadt A., 1988, UPDATE APPL RES MUSI, V2, P27, DOI DOI 10.1177/875512338800700108
   Attina V., 2010, P AVSP 2010 HAK
   BARNETT MA, 1983, FOREIGN LANG ANN, V16, P173, DOI 10.1111/j.1944-9720.1983.tb01446.x
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   BERNSTEIN IH, 1971, J EXP PSYCHOL, V87, P241, DOI 10.1037/h0030524
   Biau E, 2013, BRAIN LANG, V124, P143, DOI 10.1016/j.bandl.2012.10.008
   Boersma P, 2015, PRAAT DOING PHONETIC
   Borghi AM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00214
   Burnham D., 2001, P 7 C SPEECH COMM TE, P395
   Burnham D., 2006, P ISSP 2006 UB
   Burnham D., 2001, P INT C AUD VIS SPEE, P155
   Casasanto D, 2003, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, PTS 1 AND 2, P1323
   Cave C, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2175, DOI 10.1109/ICSLP.1996.607235
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   Chen Y., 2007, P 16 INT C PHON SCI, P2177
   Connell L, 2013, BRAIN COGNITION, V81, P124, DOI 10.1016/j.bandc.2012.09.005
   Cooper A, 2012, J ACOUST SOC AM, V131, P4756, DOI 10.1121/1.4714355
   Ernst MO, 2007, J VISION, V7, DOI 10.1167/7.5.7
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Fujisaki W, 2007, VISION RES, V47, P1075, DOI 10.1016/j.visres.2007.01.021
   Gagne JP, 2002, SPEECH COMMUN, V37, P213, DOI 10.1016/S0167-6393(01)00012-7
   Gluhareva D, 2017, LANG TEACH RES, V21, P609, DOI 10.1177/1362168816651463
   Goldin-Meadow S, 2001, PSYCHOL SCI, V12, P516, DOI 10.1111/1467-9280.00395
   GOLDINMEADOW S, 1993, PSYCHOL REV, V100, P279, DOI 10.1037/0033-295X.100.2.279
   Gullberg M., 2006, IRAL-INT REV APPL LI, V44, P103, DOI [10.1515/IRAL.2006.004, DOI 10.1515/IRAL.2006.004]
   Hardison DM, 1999, LANG LEARN, V49, P213, DOI 10.1111/0023-8333.49.s1.7
   Hazan V, 2006, J ACOUST SOC AM, V119, P1740, DOI 10.1121/1.2166611
   Hazan V, 2005, SPEECH COMMUN, V47, P360, DOI 10.1016/j.specom.2005.04.007
   Hazan V, 2010, SPEECH COMMUN, V52, P996, DOI 10.1016/j.specom.2010.05.003
   Hirata Y, 2014, J SPEECH LANG HEAR R, V57, P2090, DOI 10.1044/2014_JSLHR-S-14-0049
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   Hostetter AB, 2011, PSYCHOL BULL, V137, P297, DOI 10.1037/a0022128
   Houlahan Micheal, 2008, KODALY TODAY COGNITI
   Huron D, 2013, J ACOUST SOC AM, V133, P2947, DOI 10.1121/1.4798801
   Jongman A, 2003, J SPEECH LANG HEAR R, V46, P1367, DOI 10.1044/1092-4388(2003/106)
   Kawase S, 2014, J ACOUST SOC AM, V136, P1352, DOI 10.1121/1.4892770
   Kelly S, 2017, COLLABRA-PSYCHOL, V3, DOI 10.1525/collabra.76
   Kelly SD, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00673
   Kelly SD, 2012, LANG COGNITIVE PROC, V27, P793, DOI 10.1080/01690965.2011.581125
   Kelly SD, 2009, LANG COGNITIVE PROC, V24, P313, DOI 10.1080/01690960802365567
   Kim J, 2014, COMPUT SPEECH LANG, V28, P598, DOI 10.1016/j.csl.2013.02.002
   Kim J, 2014, SPEECH COMMUN, V57, P317, DOI 10.1016/j.specom.2013.06.003
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Kussner MB, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00789
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Lansing CR, 1999, J SPEECH LANG HEAR R, V42, P526, DOI 10.1044/jslhr.4203.526
   LAVIE N, 1995, J EXP PSYCHOL HUMAN, V21, P451, DOI 10.1037/0096-1523.21.3.451
   Lazaraton A, 2004, LANG LEARN, V54, P79, DOI 10.1111/j.1467-9922.2004.00249.x
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Liao MY, 2008, INT J MUSIC EDUC, V26, P197, DOI 10.1177/0255761408092525
   Liao MY, 2007, INT J MUSIC EDUC, V25, P82, DOI 10.1177/0255761407074894
   Liao MY, 2016, INT J MUSIC EDUC, V34, P4, DOI 10.1177/0255761415614798
   MARKS LE, 1987, J EXP PSYCHOL HUMAN, V13, P384, DOI 10.1037/0096-1523.13.3.384
   McCafferty S. G., 2006, IRAL-INT REV APPL LI, V44, P197, DOI DOI 10.1515/IRAL.2006.008
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McNeill D., 2005, GESTURE THOUGHT
   McNeill D., 2000, LANGUAGE GESTURE
   Mixdorff H., 2005, P 9 EUR C SPEECH COM, P405
   Mixdorff H., 2008, P SPEECH PROS 2008 C, P261
   Morett LM, 2015, LANG COGN NEUROSCI, V30, P347, DOI 10.1080/23273798.2014.923105
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Parise CV, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005664
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Perception Research Systems, 2007, PAR STM PRES
   Rauscher FH, 1996, PSYCHOL SCI, V7, P226, DOI 10.1111/j.1467-9280.1996.tb00364.x
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   Smith D, 2012, J ACOUST SOC AM, V131, P1480, DOI 10.1121/1.3672703
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Sueyoshi A, 2005, LANG LEARN, V55, P661, DOI 10.1111/j.0023-8333.2005.00320.x
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Summerfield Q., 1983, HEARING SCI HEARING, P131
   Swerts M, 2008, J PHONETICS, V36, P219, DOI 10.1016/j.wocn.2007.05.001
   Tang LYW, 2015, SPEECH COMMUN, V75, P1, DOI 10.1016/j.specom.2015.09.008
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Wang Y, 2008, J ACOUST SOC AM, V124, P1716, DOI 10.1121/1.2956483
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   Welch G. F., 1985, PSYCHOL MUSIC, V13, P3, DOI DOI 10.1177/0305735685131001
   Wesp R, 2001, AM J PSYCHOL, V114, P591, DOI 10.2307/1423612
   Wu YC, 2007, BRAIN LANG, V101, P234, DOI 10.1016/j.bandl.2006.12.003
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 84
TC 8
Z9 8
U1 0
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD DEC 4
PY 2017
VL 8
AR 2051
DI 10.3389/fpsyg.2017.02051
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA FO5UO
UT WOS:000416926900001
PM 29255435
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Al-Zidi, MG
   Santhosh, J
   Ng, SC
   Bakar, ARA
   Ibrahim, IA
AF Al-Zidi, Mohammed G.
   Santhosh, Jayasree
   Ng, Siew-Cheok
   Bakar, Abdul Rauf A.
   Ibrahim, Ibrahim Amer
TI Cortical auditory evoked potentials as indicators of hearing aids
   performance in speech perception
SO JOURNAL OF ENGINEERING RESEARCH
LA English
DT Article
DE Cortical auditory evoked potentials; consonant vowels; hearing loss;
   sensorineural hearing loss; speech stimuli
ID EVENT-RELATED POTENTIALS; MISMATCH NEGATIVITY; BEHAVIORAL MEASURES;
   SOUND; REPRESENTATION; RESPONSES; COMPONENT; FEATURES; VOWELS
AB Cortical auditory evoked potentials represent summation of neural activity in the auditory pathways in response to sounds. They provide an objective measure of the brain's response to sound. For this reason, they are an effective tool for scientists and audiologists for investigating auditory function in normal people and those with hearing loss. The main objective of this study is to determine what components among the P1, N1, P2, N2, or P3 are most beneficial in assessing the speech detection and discrimination abilities of adult sensorineural hearing loss population. This study also intends to investigate whether changes in the amplitudes and latencies of these components occurring with sensorineural hearing loss and hearing aids differ in responses reflecting different stages of auditory processing. Auditory Potentials were recorded to /ba/ and /da/ stimuli from two Malay adult groups. A control group of 12 right-handed having normal hearing and a group of 10 right-handed with sensorineural hearing loss. The results showed that P2 and P3 components had the most benefits from the use of hearing aids in the hearing loss subjects and therefore could be used in both clinical and research applications as a predictor and objective indicator of hearing aids performance in speech perception. The study also showed that the brain processes both stimuli in a different pattern for both the normal and the aided hearing loss subjects. The present study could provide more diagnostic information for clinicians and could also offer better speech perception benefits for hearing-impaired individuals from their personal hearing aids. The findings also suggest that the aided hearing loss subjects, despite the benefits they get from the hearing aids, find it difficult to detect and discriminate the acoustic differences between the two speech stimuli.
C1 [Al-Zidi, Mohammed G.; Ng, Siew-Cheok; Bakar, Abdul Rauf A.] Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur, Malaysia.
   [Ibrahim, Ibrahim Amer] Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur, Malaysia.
   [Santhosh, Jayasree] Manipal Int Univ, Sch Sci & Engn, Dept Comp Engn, Nilai, Selangor, Malaysia.
   [Ibrahim, Ibrahim Amer] Univ Baghdad, Al Khwarizmi Engn, Baghdad, Iraq.
RP Ng, SC (corresponding author), Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur, Malaysia.
EM siewcng@um.edu.my
RI ABU BAKAR, ABDUL RAUF/AAZ-9611-2020; NG, SIEW CHEOK/B-9232-2010;
   Ibrahim, Ibrahim amer/AAJ-4270-2020
OI Ibrahim, Ibrahim amer/0000-0002-8011-5005
FU University Malaya Research Grant (UMRG) [RP016D-13AET]
FX This research was funded by the University Malaya Research Grant (UMRG),
   grant no.: RP016D-13AET. The authors express their gratitude to all
   volunteers participated and contributed in conducting the experiment.
   The authors declare no competing interests.
CR Agung K, 2006, J AM ACAD AUDIOL, V17, P559, DOI 10.3766/jaaa.17.8.3
   Alain C., 2013, HDB CLIN NEUROPHYSIO, V10, P177
   Anderson S, 2013, J ACOUST SOC AM, V133, P3030, DOI 10.1121/1.4799804
   Association ASLH, 2005, GUID MAN PUR TON THR
   Bertrand Delgutte D. C., 2005, BRAIN MECH HEARING S
   Billings CJ, 2007, AUDIOL NEURO-OTOL, V12, P234, DOI 10.1159/000101331
   BRANT LJ, 1990, J ACOUST SOC AM, V88, P813, DOI 10.1121/1.399731
   Csepe V, 1997, AUDIOL NEURO-OTOL, V2, P354, DOI 10.1159/000259256
   Dehaene-Lambertz G, 1998, NEUROREPORT, V9, P1885, DOI 10.1097/00001756-199806010-00040
   Donchin E., 1978, EVENT RELATED BRAIN, P349, DOI DOI 10.1016/B978-0-12-155150-6.50019-5
   DORMAN MF, 1974, PERCEPT PSYCHOPHYS, V15, P215, DOI 10.3758/BF03213935
   Durante AS, 2014, CODAS, V26, P367, DOI 10.1590/2317-1782/20142013085
   Easwar V, 2012, AM J AUDIOL, V21, P82, DOI 10.1044/1059-0889(2012/11-0039)
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Kopsinis Y, 2009, IEEE T SIGNAL PROCES, V57, P1351, DOI 10.1109/TSP.2009.2013885
   Korczak PA, 2005, EAR HEARING, V26, P165, DOI 10.1097/00003446-200504000-00005
   Korczak PA, 2010, EAR HEARING, V31, P491, DOI 10.1097/AUD.0b013e3181d8683d
   KRAUS N, 1995, EAR HEARING, V16, P19, DOI 10.1097/00003446-199502000-00003
   Lee CY, 2007, J FORMOS MED ASSOC, V106, P979, DOI 10.1016/S0929-6646(08)60072-8
   Martin BA, 1997, J ACOUST SOC AM, V101, P1585, DOI 10.1121/1.418146
   NAATANEN R, 1995, EAR HEARING, V16, P6
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Naatanen R, 1992, ATTENTION BRAIN FUNC
   Nathan GS, 1998, LANGUAGE, V74, P374, DOI 10.2307/417875
   Oates PA, 2002, EAR HEARING, V23, P399, DOI 10.1097/00003446-200210000-00002
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2003, COGNITIVE BRAIN RES, V15, P207, DOI 10.1016/S0926-6410(02)00193-3
   Obleser J, 2001, NEUROSCI LETT, V314, P131, DOI 10.1016/S0304-3940(01)02298-4
   Ostroff JM, 1998, EAR HEARING, V19, P290, DOI 10.1097/00003446-199808000-00004
   Picton TW, 2000, AUDIOL NEURO-OTOL, V5, P111, DOI 10.1159/000013875
   Purdy S, 2005, SOUND FDN EARLY AMPL, P115
   Purdy SC, 2001, AUDIOL NEURO-OTOL, V6, P211, DOI 10.1159/000046835
   RAPIN I, 1967, NEUROLOGY, V17, P881, DOI 10.1212/WNL.17.9.881
   Ray C, 2002, HDB CLIN AUDIOLOGY
   RAZ I, 1985, AUDIOLOGY, V24, P437
   Ruffini G, 2007, ENG MED BIOL SOC 200
   Ruffini G, 2006, SENSOR ACTUAT A-PHYS, V132, P34, DOI 10.1016/j.sna.2006.06.013
   Sharma A, 1997, EVOKED POTENTIAL, V104, P540, DOI 10.1016/S0168-5597(97)00050-6
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Stapells D. R., 2002, HDB CLIN AUDIOLOGY, P378
   STELMACHOWICZ PG, 1990, J SPEECH HEAR RES, V33, P380, DOI 10.1044/jshr.3302.380
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Wang T, 2013, BIOMED SIGNAL PROCES, V8, P858, DOI 10.1016/j.bspc.2013.08.004
   Wunderlich JL, 2006, HEARING RES, V212, P212, DOI 10.1016/j.heares.2005.11.008
   Wunderlich JL, 2001, J ACOUST SOC AM, V109, P1526, DOI 10.1121/1.1349184
NR 45
TC 1
Z9 1
U1 1
U2 6
PU ACADEMIC PUBLICATION COUNCIL
PI KHALDIYA
PA PO BOX 17225, KHALDIYA 72453, KUWAIT
SN 2307-1877
EI 2307-1885
J9 J ENG RES-KUWAIT
JI J. Eng. Res.
PD DEC
PY 2017
VL 5
IS 4
BP 76
EP 94
PG 19
WC Engineering, Multidisciplinary
SC Engineering
GA FT9LN
UT WOS:000423473700006
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Ting, HN
   Bakar, ARA
   Santhosh, J
   Al-Zidi, MG
   Ibrahim, IA
   Cheok, NS
AF Hua Nong Ting
   Bakar, Abdul Rauf A.
   Santhosh, Jayasree
   Al-Zidi, Mohammed G.
   Ibrahim, Ibrahim Amer
   Cheok, Ng Siew
TI Effects of Speech Phonological Features during Passive Perception on
   Cortical Auditory Evoked Potential in Sensorineural Hearing Loss
SO SAINS MALAYSIANA
LA English
DT Article
DE Consonant-vowel (CV); cortical auditory evoked potential (CAEP);
   electroencephalography (EEG); mismatch negativity (MMN); sensorineural
   hearing loss (SNHL)
ID EVENT-RELATED POTENTIALS; RECURRENCE QUANTIFICATION ANALYSIS; MISMATCH
   NEGATIVITY MMN; BEHAVIORAL MEASURES; SOUNDS; BRAIN; IDENTIFICATION;
   REPRESENTATION; EPILEPSY; TONES
AB The deficiency in the human auditory system of individuals suffering from sensorineural hearing loss (SNHL) is known to be associated with the difficulty in detecting of various speech phonological features that are frequently related to speech perception. This study investigated the effects of speech articulation features on the amplitude and latency of cortical auditory evoked potential (CAEP) components. The speech articulation features included the placing contrast and voicing contrast. 12 Malay subjects with normal hearing and 12 Malay subjects with SNHL were recruited for the study. The CAEPs response recorded at higher amplitude with longer latency when stimulated by voicing contrast cues compared to that of the placing contrast. Subjects with SNHL elicited greater amplitude with prolonged latencies in the majority of the CAEP components in both speech stimuli. The existence of different frequency spectral and time-varying acoustic cues of the speech stimuli was reflected by the CAEPs response strength and timing. We anticipate that the CAEPs responses could equip audiologist and clinicians with useful knowledge, concerning the potential deprivation experience by hearing impaired individuals, in auditory passive perception. This would help to determine what type of speech stimuli that might be useful in measuring speech perception abilities, especially in Malay Malaysian ethic group, for choosing a better rehabilitation program, since no such study conducted for evaluating speech perception among Malaysian clinical population.
C1 [Hua Nong Ting; Bakar, Abdul Rauf A.; Al-Zidi, Mohammed G.; Cheok, Ng Siew] Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
   [Santhosh, Jayasree] Manipal Int Univ, Sch Sci & Engn, Dept Comp Engn & Comp Sci, Nilai 71800, Negeri Sembilan, Malaysia.
   [Santhosh, Jayasree] Indian Inst Technol Delhi, Ctr Biomed Engn, New Delhi, India.
   [Ibrahim, Ibrahim Amer] Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur 50603, Malaysia.
RP Ting, HN (corresponding author), Univ Malaya, Fac Engn, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
EM tinghn@um.edu.my
RI ABU BAKAR, ABDUL RAUF/AAZ-9611-2020; TING, HUA NONG/B-5255-2010;
   Ibrahim, Ibrahim amer/AAJ-4270-2020; NG, SIEW CHEOK/B-9232-2010
OI Ibrahim, Ibrahim amer/0000-0002-8011-5005; 
FU University Malaya Research Grant [RP016D-13AET]
FX This research was funded by the University Malaya Research Grant (Grant
   Number: UMRG RP016D-13AET). The authors expressed their gratitude to all
   volunteers who participated in the experiment. The authors declared no
   conflict of interests.
CR ABBS JH, 1971, J SPEECH HEAR RES, V14, P23, DOI 10.1044/jshr.1401.23
   Acharya UR, 2015, EUR NEUROL, V74, P79, DOI 10.1159/000438457
   Acharya UR, 2013, KNOWL-BASED SYST, V45, P147, DOI 10.1016/j.knosys.2013.02.014
   Acharya UR, 2012, BIOMED SIGNAL PROCES, V7, P401, DOI 10.1016/j.bspc.2011.07.007
   Acharya UR, 2011, INT J NEURAL SYST, V21, P199, DOI 10.1142/S0129065711002808
   Agung K, 2006, J AM ACAD AUDIOL, V17, P559, DOI 10.3766/jaaa.17.8.3
   Ali R, 2013, SAINS MALAYS, V42, P403
   Anderson S, 2013, J ACOUST SOC AM, V133, P3030, DOI 10.1121/1.4799804
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   BABLOYANTZ A, 1985, PHYS LETT A, V111, P152, DOI 10.1016/0375-9601(85)90444-X
   Becker F, 2007, BRAIN LANG, V100, P69, DOI 10.1016/j.bandl.2006.09.004
   Becker F, 2013, APHASIOLOGY, V27, P20, DOI 10.1080/02687038.2012.676163
   Bidelman GM, 2015, J NEUROSCI METH, V241, P94, DOI 10.1016/j.jneumeth.2014.12.019
   Bien H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00056
   Boothroyd A., 1993, ACOUSTICAL FACTORS A, P277
   Carpenter AL, 2013, NEUROSCI LETT, V544, P56, DOI 10.1016/j.neulet.2013.03.041
   Chua K. C., 2009, Journal of Medical Engineering & Technology, V33, P42, DOI 10.1080/03091900701559408
   Chua KC, 2011, J MED SYST, V35, P1563, DOI 10.1007/s10916-010-9433-z
   Davies PL, 2010, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00016
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Jaramillo M, 2001, COGNITIVE BRAIN RES, V12, P459, DOI 10.1016/S0926-6410(01)00081-7
   Korczak PA, 2010, EAR HEARING, V31, P491, DOI 10.1097/AUD.0b013e3181d8683d
   Lehnertz K, 2008, J BIOL PHYS, V34, P253, DOI 10.1007/s10867-008-9090-3
   Li ZC, 2016, AUDIOL NEURO-OTOL, V21, P38, DOI 10.1159/000441709
   Luck S, 2005, INTRO EVENT RELATED
   Mormann F, 2003, EPILEPSY RES, V53, P173, DOI 10.1016/S0920-1211(03)00002-0
   Mormann F, 2005, CLIN NEUROPHYSIOL, V116, P569, DOI 10.1016/j.clinph.2004.08.025
   Mukari SZMS, 2016, SAINS MALAYS, V45, P1405
   Naatanen R, 2000, AUDIOL NEURO-OTOL, V5, P105, DOI 10.1159/000013874
   NAATANEN R, 1995, EAR HEARING, V16, P6
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   NAATANEN R, 1993, PSYCHOPHYSIOLOGY, V30, P436, DOI 10.1111/j.1469-8986.1993.tb02067.x
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Naatanen R, 1992, ATTENTION BRAIN FUNC
   Oates PA, 2002, EAR HEARING, V23, P399, DOI 10.1097/00003446-200210000-00002
   Picton T.W., 1995, HDB NEUROPSYCHOLOGY, V10
   Picton TW, 2000, PSYCHOPHYSIOLOGY, V37, P127, DOI 10.1111/1469-8986.3720127
   Pratt H, 2009, CLIN NEUROPHYSIOL, V120, P360, DOI 10.1016/j.clinph.2008.10.158
   Reis Ana Cláudia Mirândola Barbosa, 2007, Pró-Fono R. Atual. Cient., V19, P113, DOI 10.1590/S0104-56872007000100013
   Ruffini G, 2007, ENG MED BIOL SOC 200
   Ruffini G, 2006, SENSOR ACTUAT A-PHYS, V132, P34, DOI 10.1016/j.sna.2006.06.013
   SAMS M, 1985, ELECTROEN CLIN NEURO, V62, P437, DOI 10.1016/0168-5597(85)90054-1
   Scharinger M, 2016, NEUROIMAGE, V128, P293, DOI 10.1016/j.neuroimage.2016.01.003
   Schroder A, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00123
   Song IH, 2004, NEUROSCI LETT, V366, P148, DOI 10.1016/j.neulet.2004.05.025
   Stapells D. R., 2002, HDB CLIN AUDIOLOGY, P378
   Steinhauer K, 2014, APPL LINGUIST, V35, P393, DOI 10.1093/applin/amu028
   Tavabi K, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004452
   Ting HN, 2011, J VOICE, V25, pE305, DOI 10.1016/j.jvoice.2010.05.007
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Wang T, 2013, BIOMED SIGNAL PROCES, V8, P858, DOI 10.1016/j.bspc.2013.08.004
   Wunderlich JL, 2006, HEARING RES, V212, P185, DOI 10.1016/j.heares.2005.11.010
   Wunderlich JL, 2001, J ACOUST SOC AM, V109, P1526, DOI 10.1121/1.1349184
   Ylinen S, 2006, BRAIN RES, V1072, P175, DOI 10.1016/j.brainres.2005.12.004
NR 55
TC 1
Z9 1
U1 0
U2 1
PU UNIV KEBANGSAAN MALAYSIA
PI SELANGOR
PA FACULTY SCIENCE & TECHNOLOGY, BANGI, SELANGOR, 43600, MALAYSIA
SN 0126-6039
J9 SAINS MALAYS
JI Sains Malays.
PD DEC
PY 2017
VL 46
IS 12
BP 2477
EP 2488
DI 10.17576/jsm-2017-4612-25
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA FT0YO
UT WOS:000422856900025
OA Bronze
DA 2021-02-24
ER

PT J
AU Balling, LW
   Morris, DJ
   Tondering, J
AF Balling, Laura Winther
   Morris, David Jackson
   Tondering, John
TI Investigating lexical competition and the cost of phonemic restoration
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; INSIGHTS; MODEL
AB Due to phonemic restoration, listeners can reliably perceive words when a phoneme is replaced with noise. The cost associated with this process was investigated along with the effect of lexical uniqueness on phonemic restoration, using data from a lexical decision experiment where noise replaced phonemes that were either uniqueness points (the phoneme at which a word deviates from all nonrelated words that share the same onset) or phonemes immediately prior to these. A baseline condition was also included with no noise-interrupted stimuli. Results showed a significant cost of phonemic restoration, with 100 ms longer word identification times and a 14% decrease in word identification accuracy for interrupted stimuli compared to the baseline. Regression analysis of response times from the interrupted conditions showed no effect of whether the interrupted phoneme was a uniqueness point, but significant effects for several temporal attributes of the stimuli, including the duration and position of the interrupted segment. These results indicate that uniqueness points are not distinct breakpoints in the cohort reduction that occurs during lexical processing, but that temporal properties of the interrupted stimuli are central to auditory word recognition. These results are interpreted in the context of models of speech perception. (C) 2017 Acoustical Society of America.
C1 [Balling, Laura Winther] Copenhagen Business Sch, Dept Management Soc & Commun, Dalgas Have 15, DK-2000 Frederiksberg, Denmark.
   [Morris, David Jackson; Tondering, John] Univ Copenhagen, Dept Nord Studies & Linguist, Emil Holms Kanal 2, DK-2300 Copenhagen, Denmark.
   [Morris, David Jackson] Lund Univ, Humanities Lab, Helgonabacken 12, S-22100 Lund, Sweden.
RP Balling, LW (corresponding author), Copenhagen Business Sch, Dept Management Soc & Commun, Dalgas Have 15, DK-2000 Frederiksberg, Denmark.
EM lwb.msc@cbs.dk
OI Morris, David/0000-0003-4930-9896
FU Innovation Fund Denmark [162-2013-6]
FX D.J.M. is supported by the Innovation Fund Denmark, J. Nr. 162-2013-6.
   No other outside funding or grants in support of this work were
   received. The authors report no conflicts of interest, and alone are
   responsible for the content of this paper.
CR Altman G., 1989, Computer Speech and Language, V3, P265, DOI 10.1016/0885-2308(89)90022-3
   Balling LW, 2012, COGNITION, V125, P80, DOI 10.1016/j.cognition.2012.06.003
   Balling LW, 2008, LANG COGNITIVE PROC, V23, P1159, DOI 10.1080/01690960802201010
   BASHFORD JA, 1992, PERCEPT PSYCHOPHYS, V51, P211, DOI 10.3758/BF03212247
   BASHFORD JA, 1987, PERCEPT PSYCHOPHYS, V42, P114, DOI 10.3758/BF03210499
   Baskent D, 2010, HEARING RES, V260, P54, DOI 10.1016/j.heares.2009.11.007
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   CUTLER A, 1976, PERCEPT PSYCHOPHYS, V20, P55, DOI 10.3758/BF03198706
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Grose JH, 2016, EAR HEARING, V37, P48, DOI 10.1097/AUD.0000000000000200
   Grossberg S, 2011, J ACOUST SOC AM, V130, P440, DOI 10.1121/1.3589258
   Kuznetsova A., 2016, LMERTEST TESTS LINEA
   MARSLENWILSON W, 1984, ATTENTION PERFORM, V10, P125
   MARSLENWILSON W, 1990, ACL MIT NAT, P148
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Oxenham AJ, 2001, J ACOUST SOC AM, V109, P732, DOI 10.1121/1.1336501
   R Core Team, 2016, R LANG ENV STAT COMP
   SAMUEL AG, 1987, J MEM LANG, V26, P36, DOI 10.1016/0749-596X(87)90061-1
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   SAMUEL AG, 1986, J EXP PSYCHOL HUMAN, V12, P70, DOI 10.1037/0096-1523.12.1.70
   WARREN RM, 1974, PERCEPT PSYCHOPHYS, V16, P150, DOI 10.3758/BF03203268
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   WARREN RM, 1971, PERCEPT PSYCHOPHYS, V9, P358, DOI 10.3758/BF03212667
NR 24
TC 1
Z9 1
U1 1
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2017
VL 142
IS 6
BP 3603
EP 3612
DI 10.1121/1.5017603
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FR3FV
UT WOS:000418952300035
PM 29289097
OA Green Published
DA 2021-02-24
ER

PT J
AU Nagaraj, NK
   Magimairaj, BM
AF Nagaraj, Naveen K.
   Magimairaj, Beula M.
TI Role of working memory and lexical knowledge in perceptual restoration
   of interrupted speech
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID BOTTOM-UP CUES; PHONEMIC RESTORATION; HEARING-LOSS; DEGRADED SPEECH;
   INTELLIGIBILITY; NOISE; MODEL; AGE; RECOGNITION; RESOLUTION
AB The role of working memory (WM) capacity and lexical knowledge in perceptual restoration (PR) of missing speech was investigated using the interrupted speech perception paradigm. Speech identification ability, which indexed PR, was measured using low-context sentences periodically interrupted at 1.5 Hz. PR was measured for silent gated, low-frequency speech noise filled, and low-frequency fine-structure and envelope filled interrupted conditions. WM capacity was measured using verbal and visuospatial span tasks. Lexical knowledge was assessed using both receptive vocabulary and meaning from context tests. Results showed that PR was better for speech noise filled condition than other conditions tested. Both receptive vocabulary and verbal WM capacity explained unique variance in PR for the speech noise filled condition, but were unrelated to performance in the silent gated condition. It was only receptive vocabulary that uniquely predicted PR for fine-structure and envelope filled conditions. These findings suggest that the contribution of lexical knowledge and verbal WM during PR depends crucially on the information content that replaced the silent intervals. When perceptual continuity was partially restored by filler speech noise, both lexical knowledge and verbal WM capacity facilitated PR. Importantly, for fine-structure and envelope filled interrupted conditions, lexical knowledge was crucial for PR. (C) 2017 Acoustical Society of America.
C1 [Nagaraj, Naveen K.] Univ Arkansas Med Sci, Cognit Hearing Sci Lab, Little Rock, AR 72204 USA.
   [Nagaraj, Naveen K.] Univ Arkansas Little Rock, Little Rock, AR 72204 USA.
   [Magimairaj, Beula M.] Univ Cent Arkansas, Cognit & Language Lab, Commun Sci & Disorders, Conway, AR 72035 USA.
RP Nagaraj, NK (corresponding author), Univ Arkansas Med Sci, Cognit Hearing Sci Lab, Little Rock, AR 72204 USA.; Nagaraj, NK (corresponding author), Univ Arkansas Little Rock, Little Rock, AR 72204 USA.
EM nknagaraj@uams.edu
CR American Speech-Language-Hearing Association, 1997, GUID AUD SCREEN GUID
   Ardoint M, 2014, J ACOUST SOC AM, V136, pEL275, DOI 10.1121/1.4895096
   BASHFORD JA, 1992, PERCEPT PSYCHOPHYS, V51, P211, DOI 10.3758/BF03212247
   Bashford JA, 1996, PERCEPT PSYCHOPHYS, V58, P342, DOI 10.3758/BF03206810
   BASHFORD JA, 1987, PERCEPT PSYCHOPHYS, V42, P431, DOI 10.3758/BF03209750
   Benard MR, 2014, J ACOUST SOC AM, V135, pEL88, DOI 10.1121/1.4862879
   Benard MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058149
   Bregman AS, 2005, CAN PSYCHOL, V46, P32, DOI 10.1037/h0085822
   Brown L., 2010, TEST NONVERBAL INTEL
   Carrow-Woolfolk E., 2014, COMPREHENSIVE ASSESS
   Chatterjee M, 2010, J ACOUST SOC AM, V127, pEL37, DOI 10.1121/1.3284544
   Clarke J, 2016, J ACOUST SOC AM, V139, P395, DOI 10.1121/1.4939962
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Elliott EM, 2005, MEM COGNITION, V33, P664, DOI 10.3758/BF03195333
   Freyman RL, 2012, J ACOUST SOC AM, V132, P2514, DOI 10.1121/1.4747614
   GARDNER RC, 1987, EDUC PSYCHOL MEAS, V47, P849, DOI 10.1177/0013164487474001
   Grossberg S, 2011, J ACOUST SOC AM, V130, P440, DOI 10.1121/1.3589258
   Jin SH, 2010, J ACOUST SOC AM, V128, P881, DOI 10.1121/1.3458851
   Kane MJ, 2004, J EXP PSYCHOL GEN, V133, P189, DOI 10.1037/0096-3445.133.2.189
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kline R. B., 2011, PRINCIPLES PRACTICE
   Laures JS, 1999, J SPEECH LANG HEAR R, V42, P1148, DOI 10.1044/jslhr.4205.1148
   Li N, 2008, J ACOUST SOC AM, V123, P2287, DOI 10.1121/1.2839013
   Li N, 2007, J ACOUST SOC AM, V122, P1165, DOI 10.1121/1.2749454
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Nagaraj NK, 2017, J SPEECH LANG HEAR R, V60, P2949, DOI 10.1044/2017_JSLHR-H-17-0022
   Nagaraj NK, 2015, J ACOUST SOC AM, V138, pEL145, DOI 10.1121/1.4927635
   Nunnally J.C., 1994, PSYCHOMETRIC THEORY, V3rd
   Oxenham Andrew J, 2008, Trends Amplif, V12, P316, DOI 10.1177/1084713808325881
   Patro C, 2016, J ACOUST SOC AM, V140, P1336, DOI 10.1121/1.4961450
   Pedhazur E.J., 1997, MULTIPLE REGRESSION, V3rd ed.
   Redick TS, 2012, EUR J PSYCHOL ASSESS, V28, P164, DOI 10.1027/1015-5759/a000123
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   SALTHOUSE TA, 1991, DEV PSYCHOL, V27, P763, DOI 10.1037/0012-1649.27.5.763
   Shafiro V, 2016, J ACOUST SOC AM, V139, P455, DOI 10.1121/1.4939891
   Shafiro V, 2015, J ACOUST SOC AM, V137, P745, DOI 10.1121/1.4906275
   Shinn-Cunningham BG, 2008, J ACOUST SOC AM, V123, P295, DOI 10.1121/1.2804701
   Smith SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01394
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Srinivasan S, 2005, SPEECH COMMUN, V45, P63, DOI 10.1016/j.specom.2004.09.002
   Steinmetzger K, 2015, J ACOUST SOC AM, V138, P3586, DOI 10.1121/1.4936945
   Unsworth N, 2013, MEM COGNITION, V41, P242, DOI 10.3758/s13421-012-0261-x
   Unsworth N, 2009, MEMORY, V17, P635, DOI 10.1080/09658210902998047
   VERSCHUURE J, 1983, PERCEPT PSYCHOPHYS, V33, P232, DOI 10.3758/BF03202859
   Wang X, 2010, J ACOUST SOC AM, V128, P2100, DOI 10.1121/1.3483733
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   WARREN RM, 1971, PERCEPT PSYCHOPHYS, V9, P358, DOI 10.3758/BF03212667
   Zumbo BD, 1999, ADV SOC SCI, V5, P269
NR 53
TC 4
Z9 4
U1 1
U2 8
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2017
VL 142
IS 6
BP 3756
EP 3766
DI 10.1121/1.5018429
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FR3FV
UT WOS:000418952300049
PM 29289104
DA 2021-02-24
ER

PT J
AU Mixdorff, H
   Honemann, A
   Rilliard, A
   Lee, T
   Ma, MKH
AF Mixdorff, Hansjoerg
   Hoenemann, Angelika
   Rilliard, Albert
   Lee, Tan
   Ma, Matthew K. H.
TI Audio-visual expressions of attitude: How many different attitudes can
   perceivers decode?
SO SPEECH COMMUNICATION
LA English
DT Article
DE Social attitudes; Multi-modality; Speech perception; Speech production;
   Expressive speech; Prosodic analysis
ID EMOTION; CULTURE
AB Based on the paradigm by Rilliard et al. we collected audio-visual expressions of attitudes such as arrogance, irony, sincerity and politeness in German. In the experimental design subjects are immersed in sixteen different communicative situations in which they are supposed to portray a certain attitude in a short dialog. Attitudes can be propositional, that is, reactions to a factual situation and/or social, that is, with respect to the relationship with the collocutor. Furthermore, attitudes can be of positive or negative valence or neutral. Undeniably there is a large repertory of subtle differences in the way certain talkers express certain attitudes. The important question is, however, whether collocutors either from the same language or a different one can actually decode these attitudes reliably. On that account we carried out three perceptual experiments in which we presented our recordings of the portrayed attitudes audiovisually, audio -only and video -only. In the first study, German perceivers rated the expressions given the intended attitude, in the second study, they had to choose the most suitable in a choice of five attitudes, and in the third study raters were able to assign freely the term best matching each attitudinal expression. This last experiment was recently replicated by native speakers of Cantonese in Hong Kong. The current article reviews and reevaluates the results from the first three experiments with the German subjects under the premise that perceivers actually have a more limited set of attitudinal registers which they can reliably draw on. This means that expressions can be sorted into a much smaller number of categories than the projected sixteen. In addition we compare and contrast these resulting clusters with the new data from the Cantonese speaking group. Our results indicate indeed a small number of readily decoded attitudes forming four clusters depending on the experiment design" - which are also distinct acoustically. Clusters from the statistical analysis are very similar for the German and the Cantonese perceivers and overlap with basic emotions. This result suggests that expressions of attitudes with low identification rates are more complex to decode and require more pragmatic information, that is, more contextual and possibly idiosyncratic information to be interpreted correctly. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Mixdorff, Hansjoerg; Hoenemann, Angelika] Beuth Univ Appl Sci, Berlin, Germany.
   [Hoenemann, Angelika] Univ Bielefeld, Bielefeld, Germany.
   [Rilliard, Albert] Univ Paris Saclay, CNRS, LIMSI, Orsay, France.
   [Rilliard, Albert] Univ Fed Rio de Janeiro, CNPq, Rio De Janeiro, Brazil.
   [Lee, Tan; Ma, Matthew K. H.] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
RP Mixdorff, H (corresponding author), Beuth Univ Appl Sci, Berlin, Germany.
EM mixdorff@bht-berlin.de
RI Lee, Tan/D-5475-2011
OI Ma, Matthew King-Hang/0000-0001-9194-2498
FU DFG (Deutsche Forschungsgemeinschaft)German Research Foundation (DFG)
   [Mi 625-27]
FX This work was supported by DFG (Deutsche Forschungsgemeinschaft) grant
   Mi 625-27 funding a visit by Mixdorff to the Chinese University of Hong
   Kong.
CR Amir N, 2010, P SPEECH PROS 2010 C
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Brandt PA, 2008, 4 IT C SPEECH PROS C, P649
   Damasio AR, 2000, NAT NEUROSCI, V3, P1049, DOI 10.1038/79871
   Damasio AR, 1998, BRAIN RES REV, V26, P83, DOI 10.1016/S0165-0173(97)00064-7
   DANES F, 1994, J PRAGMATICS, V22, P251, DOI 10.1016/0378-2166(94)90111-2
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   ESCOFIER B, 1994, COMPUT STAT DATA AN, V18, P121, DOI 10.1016/0167-9473(94)90135-X
   Fazio R. H., 2003, SAGE HDB SOCIAL PSYC, P139
   Fujisaka H., 1984, Journal of the Acoustical Society of Japan (E), V5, P233
   Goudbeek M, 2010, J ACOUST SOC AM, V128, P1322, DOI 10.1121/1.3466853
   Greenberg Y, 2009, SPEECH COMMUN, V51, P585, DOI 10.1016/j.specom.2007.10.006
   Guerry M., 2015, P ICPHS GLASG SCOTL
   Gussenhoven Carlos, 2004, PHONOLOGY TONE INTON
   Honemann A., 2014, 7 FORUM ACUSTICUM
   Honemann A., 2015, FAAVSP 1 JOINT C FAC
   Husson F., 2010, EXPLORATORY MULTIVAR
   Mixdorff H, 2005, SPEECH COMMUN, V46, P310, DOI 10.1016/j.specom.2005.02.019
   Mixdorff H, 2000, INT CONF ACOUST SPEE, P1281, DOI 10.1109/ICASSP.2000.861811
   Mixdorff H., 2015, ACOUSTIC PROSODIC AN
   Mixdorff H., 2016, P SST SYDN AUSTR
   Moraes J. A, 2014, SPOKEN CORPORA LINGU, P233, DOI DOI 10.1075/SCL.61.09MOR
   Moraes J.A., 2016, INTONATIONAL GRAMMAR, V6, P135, DOI [10.1075/ihll.6.07mor, DOI 10.1075/IHLL.6.07MOR]
   Ohala John J., 1994, SOUND SYMBOLISM, P325
   Osgood C., 1975, CROSS CULTURAL UNIVE
   Rilliard A., 2016, SONORIDADES SONORITI, P149
   Rilliard A, 2013, INTERSPEECH, P1647
   Romney AK, 1996, P NATL ACAD SCI USA, V93, P4699, DOI 10.1073/pnas.93.10.4699
   Romney AK, 1998, ETHOS, V26, P314, DOI 10.1525/eth.1998.26.3.314
   Romney AK, 2000, P NATL ACAD SCI USA, V97, P518, DOI 10.1073/pnas.97.1.518
   Sanchez G., 2013, DISCRIMINER TOOLS TR
   Schauenburg G, 2015, BEHAV RES METHODS, V47, P720, DOI 10.3758/s13428-014-0494-7
   Scherer KR, 2013, J ANTHROPOL SCI, V91, P185, DOI [10.4436/JASS.91005, 10.4436/jass.91005]
   Scherer KR, 2009, PHILOS T R SOC B, V364, P3459, DOI 10.1098/rstb.2009.0141
   Schroder T., 2017, MODELING DYNAMIC IDE
   Shochi T., 2009, ROLE PROSODY AFFECTI, P31
   SpencerOatey H, 1996, J PRAGMATICS, V26, P1, DOI 10.1016/0378-2166(95)00047-X
   ULDALL E, 1960, LANG SPEECH, V3, P223, DOI 10.1177/002383096000300403
   von Thun F. Schulz, 2006, ALLGEMEINE PSYCHOL Z
   Watzlawick P., 2007, MENSCHLICHE KOMMUNIK, V11
   Wichmann A., 2002, P SPEECH PROS C, P11
   Widen SC, 2003, DEV PSYCHOL, V39, P114, DOI 10.1037//0012-1649.39.1.114
   WIERZBICKA A, 1992, COGNITIVE SCI, V16, P539, DOI 10.1207/s15516709cog1604_4
   Wierzbicka A, 2005, ETHOS, V33, P256, DOI 10.1525/eth.2005.33.2.256
   WIERZBICKA A, 1985, J PRAGMATICS, V9, P145, DOI 10.1016/0378-2166(85)90023-2
NR 46
TC 6
Z9 7
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD DEC
PY 2017
VL 95
BP 114
EP 126
DI 10.1016/j.specom.2017.08.009
PG 13
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA FR3NP
UT WOS:000418973700009
DA 2021-02-24
ER

PT J
AU Alghamdi, N
   Maddock, S
   Barker, J
   Brown, GJ
AF Alghamdi, Najwa
   Maddock, Steve
   Barker, Jon
   Brown, Guy J.
TI The impact of automatic exaggeration of the visual articulatory features
   of a talker on the intelligibility of spectrally distorted speech
SO SPEECH COMMUNICATION
LA English
DT Article
DE Audiovisual training; Cochlear-implant simulation; Visual-speech
   enhancement; Lombard speech
ID ADVERSE CONDITIONS; LOMBARD SPEECH; PERCEPTION; RECALIBRATION;
   RECOGNITION; HEARING; CONTEXT; NOISE; CUES; IDENTIFICATION
AB Visual speech information plays a key role in supporting speech perception, especially when acoustic features are distorted or inaccessible. Recent research suggests that for spectrally distorted speech, the use of visual speech in auditory training improves not only subjects' audiovisual speech recognition, but also their subsequent auditory-only speech recognition. Visual speech cues, however, can be affected by a number of facial visual signals that vary across talkers, such as lip emphasis and speaking style. In a previous study, we enhanced the visual speech videos used in perception training by automatically tracking and colouring a talker's lips. This improved the subjects' audiovisual and subsequent auditory speech recognition compared with those who were trained via unmodified videos or audio-only methods. In this paper, we report on two issues related to automatic exaggeration of the movement of the lips/mouth area. First, we investigate subjects' ability to adapt to the conflict between the articulation energy in the visual signals and the vocal effort in the acoustic signals (since the acoustic signals remained unexaggerated). Second, we have examined whether or not this visual exaggeration can improve the subjects' performance of auditory and audiovisual speech recognition when used in perception training. To test this concept, we used spectrally distorted speech to train groups of listeners using four different training regimes: (1) audio only, (2) audiovisual, (3) audiovisual visually exaggerated, and (4) audiovisual visually exaggerated and lip-coloured. We used spectrally distorted speech (cochlear-implant-simulated speech) because the longer-term aim of our work is to employ these concepts in a training system for cochlear implant (CI) users.
   The results suggest that after exposure to visually exaggerated speech, listeners had the ability to adapt alongside the conflicting audiovisual signals. In addition, subjects trained with enhanced visual cues (regimes 3 and 4) achieved better audiovisual recognition for a number of phoneme classes than those who were trained with unmodified visual speech (regime 2). There was no evidence of an improvement in the subsequent audio-only listening skills, however. The subjects' adaptation to the conflicting audiovisual signals may have slowed down auditory perceptual learning, and impeded the ability of the visual speech to improve the training gains. Crown Copyright (C) 2017 Published by Elsevier B.V. All rights reserved.
C1 [Alghamdi, Najwa; Maddock, Steve; Barker, Jon; Brown, Guy J.] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.
RP Alghamdi, N (corresponding author), Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.
EM amalghamdi1@sheffield.ac.uk; s.maddock@sheffield.ac.uk;
   j.p.barker@sheffield.ac.uk; g.j.brown@sheffield.ac.uk
RI Maddock, Steve/J-1849-2016
OI Maddock, Steve/0000-0003-3179-0263
FU Saudi Ministry of Education; King Saud University (KSU)King Saud
   University; Engineering and Physical Sciences Research
   CouncilEngineering & Physical Sciences Research Council (EPSRC)
   [EP/M026981/1] Funding Source: researchfish
FX This research has been supported by the Saudi Ministry of Education
   (http://www.moe.gov.sa/) and King Saud University (KSU). We would like
   to thank Dr. Hessa Alsalamah, the Vice Dean of the College of Computer
   and Information Sciences (CCIS) in KSU and Dr. Heyam Albaity, the Head
   of the IT department in CCIS for facilitating the visit to university
   premises to conduct the experiment. We also thank Dr. Abir BenAbid and
   Dr. Areej Alwabil, members of Software and Knowledge Engineering
   Research Group (SKERG) in CCIS for offering the HCl lab as a place to
   conduct the experiment. We also thank students and staff from KSU who
   participated in the experiment. Many thanks to Prof. Bernd Mobius and
   the two anonymous reviewers for their helpful comments.
CR Alghady R., UK SPEECH 2016 C U S
   Alghamdi N., 2015, ICPHS INT C PHON SCE
   Alghamdi N., 2015, FAAVSP
   AMAZI DK, 1982, J SPEECH HEAR RES, V25, P581, DOI 10.1044/jshr.2504.581
   Assmann P, 2004, PERCEPTION SPEECH AD, P231
   BERMANT RI, 1976, PERCEPT MOTOR SKILL, V43, P487, DOI 10.2466/pms.1976.43.2.487
   Bernstein LE, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00034
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Campbell R., 2010, SPEECHREADING INFORM
   Chen B., 1999, FORWARD IMAGE WARPIN, P89
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Cooke M, 2014, COMPUT SPEECH LANG, V28, P543, DOI 10.1016/j.csl.2013.08.003
   Cootes T., 2000, IMAGE PROCESSING ANA, V7, P223
   Daly N, 1997, J ACAD REH, V30, P63
   Dancer J., 1994, VOLTA REV
   Davis C., 2006, LOMBARD SPEECH AUDIT, P248
   Davis C., 2006, PERCEPTUAL PROCESSIN
   Davis C., 2012, SPEECH SCI TECHNOLOG, P46
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Erber N. P., 1982, AUDITORY TRAINING
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   Gamier M., 2006, 9 INT C SPOK LANG PR
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Hardison DM, 2003, APPL PSYCHOLINGUIST, V24, P495, DOI 10.1017/S0142716403000250
   Hazan V., 2002, INTERSPEECH
   JUNQUA JC, 1993, J ACOUST SOC AM, V93, P510, DOI 10.1121/1.405631
   Junqua JC, 1999, INT CONF ACOUST SPEE, P2083, DOI 10.1109/ICASSP.1999.758343
   Kaiser AR, 2003, J SPEECH LANG HEAR R, V46, P390, DOI 10.1044/1092-4388(2003/032)
   Kaplan Harriet, 1985, SPEECHREADING WAY IM
   Kawase T, 2009, NEUROREPORT, V20, P1231, DOI 10.1097/WNR.0b013e32832fbef8
   Kim J., 2005, VISUAL CONCOMITANT L, P17
   Kim J, 2014, BRAIN LANG, V137, P86, DOI 10.1016/j.bandl.2014.07.012
   Kim J, 2014, COMPUT SPEECH LANG, V28, P598, DOI 10.1016/j.csl.2013.02.002
   Kim J, 2011, PERCEPTION, V40, P853, DOI 10.1068/p6941
   KITANO Y, 1985, J COMMUN DISORD, V18, P373, DOI 10.1016/0021-9924(85)90027-9
   Kitanovski V, 2011, IEEE IMAGE PROC, P1093, DOI 10.1109/ICIP.2011.6115616
   Lander K, 2013, SPEECH COMMUN, V55, P600, DOI 10.1016/j.specom.2013.01.003
   Lazard D. S., 2013, MULTISENSORY INTERAC, P217
   Leyvand T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360637
   Li X, 2013, IEEE T NEUR SYS REH, V21, P684, DOI 10.1109/TNSRE.2013.2257853
   Lindblom B, 2012, SPEECH PROD SPEECH M, V55, P403
   Lombard E, 1911, ANN MALADIES OREILLE, V37, P25
   Lu Y, 2010, THESIS
   Lu YY, 2008, J ACOUST SOC AM, V124, P3261, DOI 10.1121/1.2990705
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   MASSARO DW, 1983, PERCEPT PSYCHOPHYS, V34, P338, DOI 10.3758/BF03203046
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McGrath M, 1985, THESIS
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Melacci S, 2010, PATTERN ANAL APPL, V13, P289, DOI 10.1007/s10044-009-0155-0
   MIDDELWEERD MJ, 1987, J ACOUST SOC AM, V82, P2145, DOI 10.1121/1.395659
   Nie K, 2006, EAR HEARING, V27, P208, DOI 10.1097/01.aud.0000202312.31837.25
   Pilling M, 2011, LANG SPEECH, V54, P487, DOI 10.1177/0023830911404958
   Preminger JE, 1998, J SPEECH LANG HEAR R, V41, P564, DOI 10.1044/jslhr.4103.564
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   SALDANA HM, 1993, PERCEPT PSYCHOPHYS, V54, P406, DOI 10.3758/BF03205276
   Scott V, 1987, BELONGING FLYING FIN
   Simko J., 2014, P 7 INT C SPEECH PRO
   Simko J, 2016, J ACOUST SOC AM, V139, P151, DOI 10.1121/1.4939495
   Skowronski MD, 2006, SPEECH COMMUN, V48, P549, DOI 10.1016/j.specom.2005.09.003
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Summerfield A. Q., 1989, HDB RES FACE PROCESS, P223
   Tabri D, 2011, INT J LANG COMM DIS, V46, P411, DOI 10.3109/13682822.2010.519372
   Theobald B., 2006, SPIE C OPT PHOT COUN
   Vroomen J, 2004, COGNITIVE BRAIN RES, V22, P32, DOI 10.1016/j.cogbrainres.2004.07.003
NR 71
TC 2
Z9 2
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD DEC
PY 2017
VL 95
BP 127
EP 136
DI 10.1016/j.specom.2017.08.010
PG 10
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA FR3NP
UT WOS:000418973700010
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Hut, SCA
   Helenius, P
   Leminen, A
   Makela, JP
   Lehtonen, M
AF Hut, Suzanne C. A.
   Helenius, Paivi
   Leminen, Alina
   Makela, Jyrki P.
   Lehtonen, Minna
TI Language control mechanisms differ for native languages: Neuromagnetic
   evidence from trilingual language switching
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Trilingualism; Language control; N400m; Language switching; Auditory
   speech perception
ID HIGHLY PROFICIENT BILINGUALS; WORD RECOGNITION; SPEECH PRODUCTION;
   TIME-COURSE; BRAIN; REPRESENTATION; INHIBITION; SELECTION; COST; L2
AB How does the brain process and control languages that are learned at a different age, when proficiency in all these languages is high? Early acquired strong languages are likely to have higher baseline activation levels than later learned less-dominant languages. However, it is still largely unknown how the activation levels of these different languages are controlled, and how interference from an irrelevant language is prevented. In this magnetoencephalography (MEG) study on language switching during auditory perception, early Finnish Swedish bilinguals (N = 18) who mastered English with high proficiency after childhood were presented with spoken words in each of the three languages, while performing a simple semantic categorisation task. Switches from the later learned English to either of the native languages resulted in increased neural activation in the superior temporal gyrus (STG) 400-600 ms after word onset (N400m response), whereas such increase was not detected for switches from native languages to English or between the native languages. In an earlier time window of 350-450 ms, English non-switch trials showed higher activation levels in the inferior frontal gyms (IFG), pointing to ongoing inhibition of the native languages during the use of English. Taken together, these asymmetric switch costs suggest that native languages are suppressed during the use of a non-native language, despite the receptive nature of the language task. This effect seems to be driven mostly by age of acquisition or language exposure, rather than proficiency. Our results indicate that mechanisms of control between two native languages differ from those of a later learned language, as upbringing in an early bilingual environment has likely promoted automatiation of language control specifically for the native languages.
C1 [Hut, Suzanne C. A.; Leminen, Alina; Lehtonen, Minna] Univ Helsinki, Fac Med, Dept Psychol & Logoped, Cognit Brain Res Unit, Helsinki, Finland.
   [Hut, Suzanne C. A.] Univ Helsinki, Inst Behav Sci, Helsinki, Finland.
   [Helenius, Paivi] Univ Helsinki, Cent Hosp, Div Child Neurol, Helsinki, Finland.
   [Leminen, Alina] Aarhus Univ, Ctr Functionally Integrat Neurosci, Dept Clin Med, Aarhus, Denmark.
   [Makela, Jyrki P.] Univ Helsinki, Cent Hosp, HUS Med Imaging Ctr, BioMag Lab, Helsinki, Finland.
   [Lehtonen, Minna] Abo Akad Univ, Dept Psychol, Turku, Finland.
RP Hut, SCA (corresponding author), Univ Helsinki, Inst Behav Sci, Cognit Brain Res Unit, POB 9, FIN-00014 Helsinki, Finland.
EM suzanne.hut@helsinki.fi
RI Leminen, Alina/W-9127-2019; Lehtonen, Minna/K-3672-2012; Lehtonen,
   Minna/AAN-8202-2020; Makela, Jyrki/M-1215-2019; Helenius,
   Paivi/W-9470-2019
OI Leminen, Alina/0000-0003-1527-6715; Lehtonen, Minna/0000-0002-6137-8854;
   Helenius, Paivi/0000-0001-8842-7065; Hut, Suzanne/0000-0001-5129-0472
FU PsyCo Graduate School; Academy of FinlandAcademy of FinlandEuropean
   Commission [137511, 288880]; Lundbeck FoundationLundbeckfonden
   [2013-12951]; KONE Foundation; University of Helsinki 3-year funds; Emil
   Aaltonen Foundation
FX This study was supported by PsyCo Graduate School (first author), the
   Academy of Finland (Grants 137511 and 288880), the Lundbeck Foundation
   (Grant 2013-12951), KONE Foundation, University of Helsinki 3-year funds
   (last author) and the Emil Aaltonen Foundation (last author). We would
   like to express our gratitude to all of our participants, and to Camilla
   Hannuksela for her help with the recordings of the stimuli. We would
   further like to thank Lena Henke for her assistance during the
   re-analysis of the neural sources.
CR Abutalebi J, 2008, ACTA PSYCHOL, V128, P466, DOI 10.1016/j.actpsy.2008.03.014
   Abutalebi J, 2007, J NEUROSCI, V27, P13762, DOI 10.1523/JNEUROSCI.3294-07.2007
   Abutalebi J, 2007, J NEUROLINGUIST, V20, P242, DOI 10.1016/j.jneuroling.2006.10.003
   Alvarez RP, 2003, BRAIN LANG, V87, P290, DOI 10.1016/S0093-934X(03)00108-1
   Blanco-Elorrieta E, 2016, J NEUROSCI, V36, P290, DOI 10.1523/JNEUROSCI.2597-15.2016
   Bobb SC, 2013, J COGN PSYCHOL, V25, P568, DOI 10.1080/20445911.2013.792822
   Chauncey K, 2008, BRAIN LANG, V105, P161, DOI 10.1016/j.bandl.2007.11.006
   Chauncey K, 2011, MEM COGNITION, V39, P291, DOI 10.3758/s13421-010-0006-7
   COHEN D, 1983, ELECTROEN CLIN NEURO, V56, P38, DOI 10.1016/0013-4694(83)90005-6
   Consonni M, 2013, CORTEX, V49, P1252, DOI 10.1016/j.cortex.2012.04.009
   Costa A, 2004, J MEM LANG, V50, P491, DOI 10.1016/j.jml.2004.02.002
   Costa A, 2006, J EXP PSYCHOL LEARN, V32, P1057, DOI 10.1037/0278-7393.32.5.1057
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   de Bruin A, 2014, NEUROIMAGE, V90, P348, DOI 10.1016/j.neuroimage.2013.12.049
   DeKeyser RM, 2005, LANG LEARN, V55, P1, DOI 10.1111/j.0023-8333.2005.00294.x
   Demonet JF, 2005, PHYSIOL REV, V85, P49, DOI 10.1152/physrev.00049.2003
   Dijkstra T, 1998, PSYCHOL BELG, V38, P177
   Dijkstra T, 2002, BILING-LANG COGN, V5, P175, DOI 10.1017/S1366728902003012
   Dijkstra T, 2010, J MEM LANG, V62, P284, DOI 10.1016/j.jml.2009.12.003
   Elston-Guttler KE, 2009, J COGNITIVE NEUROSCI, V21, P180, DOI 10.1162/jocn.2009.21015
   Fiebach CJ, 2003, NEUROIMAGE, V19, P1627, DOI 10.1016/S1053-8119(03)00227-1
   Finkbeiner M, 2006, J EXP PSYCHOL LEARN, V32, P1075, DOI 10.1037/0278-7393.32.5.1075
   Gollan TH, 2009, J EXP PSYCHOL LEARN, V35, P640, DOI 10.1037/a0014981
   Grainger J, 2009, LANG LINGUIST COMPAS, V3, P128, DOI 10.1111/j.1749-818x.2008.00121.x
   Green D. W., 1998, BILING-LANG COGN, V1, P67, DOI [10.1017/S1366728998000133, DOI 10.1017/S1366728998000133]
   Green DW, 2013, J COGN PSYCHOL, V25, P515, DOI 10.1080/20445911.2013.796377
   Grosjean F. M. J., 1988, LANG COGNITIVE PROC, V3, P233, DOI DOI 10.1080/01690968808402089
   Hagoort P, 2008, PHILOS T R SOC B, V363, P1055, DOI 10.1098/rstb.2007.2159
   HAMALAINEN M, 1993, REV MOD PHYS, V65, P413, DOI 10.1103/RevModPhys.65.413
   Helenius P, 2009, BRAIN, V132, P1918, DOI 10.1093/brain/awp134
   Hernandez AE, 2006, BILING-LANG COGN, V9, P177, DOI 10.1017/S1366728906002525
   Hosoda C, 2012, J NEUROLINGUIST, V25, P44, DOI 10.1016/j.jneuroling.2011.08.007
   Ille N, 2002, J CLIN NEUROPHYSIOL, V19, P113, DOI 10.1097/00004691-200203000-00002
   Jackson G.M., 2001, BILING-LANG COGN, V4, P169, DOI DOI 10.1017/S1366728901000268
   Kroll JF, 2006, BILING-LANG COGN, V9, P119, DOI 10.1017/S1366728906002483
   Laine M., 1999, WORDMILL LEXICAL SEA
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Lenneberg LH, 1967, BIOL FDN LANGUAGE
   Lewy N., 2008, STUDYING BILINGUALS, P201
   Luk G, 2012, LANG COGNITIVE PROC, V27, P1479, DOI 10.1080/01690965.2011.613209
   Luk G, 2011, BILING-LANG COGN, V14, P588, DOI 10.1017/S1366728911000010
   Macizo P, 2012, SECOND LANG RES, V28, P131, DOI 10.1177/0267658311434893
   Meuter RFI, 1999, J MEM LANG, V40, P25, DOI 10.1006/jmla.1998.2602
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Moreno EM, 2002, BRAIN LANG, V80, P188, DOI 10.1006/brln.2001.2588
   Pellikka J, 2015, BRAIN LANG, V142, P8, DOI 10.1016/j.bandl.2015.01.006
   Perani D, 2005, CURR OPIN NEUROBIOL, V15, P202, DOI 10.1016/j.conb.2005.03.007
   Perani D, 2003, HUM BRAIN MAPP, V19, P170, DOI 10.1002/hbm.10110
   Philipp AM, 2007, EUR J COGN PSYCHOL, V19, P395, DOI 10.1080/09541440600758812
   Piske T, 2002, PHONETICA, V59, P49, DOI 10.1159/000056205
   Pylkkanen L, 2006, J COGNITIVE NEUROSCI, V18, P97, DOI 10.1162/089892906775250003
   Ruigendijk E, 2016, SECOND LANG RES, V32, P197, DOI 10.1177/0267658315614614
   Runnqvist E., 2012, HDB BILINGUALISM MUL, P244, DOI [10.1002/9781118332382.ch10, DOI 10.1002/9781118332382]
   Salmelin R., 2010, MEG INTRO METHODS, P124
   Stein M, 2009, NEUROPSYCHOLOGIA, V47, P2712, DOI 10.1016/j.neuropsychologia.2009.05.023
   Tarlowski A, 2013, J PSYCHOLINGUIST RES, V42, P103, DOI 10.1007/s10936-012-9203-9
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   Thomas MSC, 2000, J MEM LANG, V43, P44, DOI 10.1006/jmla.1999.2700
   Tu L, 2015, CORTEX, V64, P8, DOI 10.1016/j.cortex.2014.09.019
   Ullman MT, 2001, NAT REV NEUROSCI, V2, P717, DOI 10.1038/35094573
   Van der Meij M, 2011, PSYCHOPHYSIOLOGY, V48, P44, DOI 10.1111/j.1469-8986.2010.01039.x
   van Heuven WJB, 2010, BRAIN RES REV, V64, P104, DOI 10.1016/j.brainresrev.2010.03.002
   Venkatraman V, 2006, J COGNITIVE NEUROSCI, V18, P64, DOI 10.1162/089892906775250030
   Verhoef K, 2009, COGNITION, V110, P84, DOI 10.1016/j.cognition.2008.10.013
   Verreyt N, 2016, BILING-LANG COGN, V19, P181, DOI 10.1017/S1366728914000352
   von Studnitz RE, 2002, BILING-LANG COGN, V5, P241, DOI 10.1017/S1366728902003036
   Wartenburger I, 2003, NEURON, V37, P159, DOI 10.1016/S0896-6273(02)01150-9
NR 67
TC 6
Z9 7
U1 3
U2 13
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD DEC
PY 2017
VL 107
BP 108
EP 120
DI 10.1016/j.neuropsychologia.2017.11.016
PG 13
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FR3SK
UT WOS:000418986600013
PM 29146464
DA 2021-02-24
ER

PT J
AU Coles-Harris, EH
AF Coles-Harris, Evan Hugh
TI Perspectives on the motivations for phonetic convergence
SO LANGUAGE AND LINGUISTICS COMPASS
LA English
DT Article
ID SPEECH-PERCEPTION; LANGUAGE; ACCOMMODATION; IMITATION; COMMUNICATION;
   RESPONSES; GENDER; ACCENT; MODEL
AB The motivations for spontaneous phonetic convergence have implications for theories of memory, speech production and perception, social cognition, contact-induced language change, and any number of other phenomena. Thus, this paper examines two distinct but related theoretical positions commonly taken on the motivations for spontaneous phonetic convergence: the Automatist stance and the Interventionist stance. Automatists argue that phonetic convergence is the automatic result of the unmediated action of a perception-production link; of the action of general psychological processes such as priming and simulation effects on linguistic representations in the brain. Interventionists, on the other hand, argue that convergence is the product of the very mediation of the perception-production link, be it linguistic or social mediation, typically for the purpose of managing the social distance between interlocutors. I argue that these seemingly diametrically opposed stances are in fact complementary, not contra-dictory-having been developed to describe data at various points along a continuum of sociality-and that it is most productive to understand one's own position on the issue from this standpoint. Topics such as exemplar theory, gestural drift, entrainment, and communication accommodation theory are discussed for their relevance to the question at hand.
C1 [Coles-Harris, Evan Hugh] Univ Colorado Boulder, Dept Linguist, Hellems 290,295 UCB, Boulder, CO 80309 USA.
RP Coles-Harris, EH (corresponding author), Univ Colorado Boulder, Dept Linguist, Hellems 290,295 UCB, Boulder, CO 80309 USA.
EM evan.colesharris@colorado.edu
OI Coles-Harris, Evan/0000-0001-5064-2851
CR Abrego-Collier C., 2011, P INT C PHON SCI 17, P192
   ANDERSON AH, 1991, LANG SPEECH, V34, P351, DOI 10.1177/002383099103400404
   Aronsson K., 1987, J LANG SOC PSYCHOL, V6, P99, DOI DOI 10.1177/0261927X8700600202
   Azuma S, 1997, DISCOURSE SOC, V8, P189, DOI 10.1177/0957926597008002003
   Babel M, 2014, LAB PHONOL, V5, P123, DOI 10.1515/lp-2014-0006
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Babel Molly, 2009, THESIS
   BEEK P J, 1992, Ecological Psychology, V4, P65, DOI 10.1207/s15326969eco0402_1
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Bell Allan, 2001, STYLE SOCIOLINGUISTI, P139, DOI DOI 10.1017/CBO9780511613258.010
   Berger C. R., 1982, LANGUAGE SOCIAL KNOW
   BILOUS FR, 1988, LANG COMMUN, V8, P183, DOI 10.1016/0271-5309(88)90016-X
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   Bourhis R. Y., 1977, LANGUAGE ETHNICITY I, V13, P119
   Bourhis R. Y., 1979, LANGUAGE SOCIAL PSYC, P158
   Bourhis Richard, 1983, J MULTILING MULTICUL, V4, P163, DOI DOI 10.1080/01434632.1983.9994109
   Branigan HP, 2000, COGNITION, V75, pB13, DOI 10.1016/S0010-0277(99)00081-5
   Byrne D. E., 1971, PERSONALITY AND PSYC, V11
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Cargile A., 1996, RACIAL ETHNIC CONFLI, P189
   DEBOYSSONBARDIES B, 1991, LANGUAGE, V67, P297, DOI 10.2307/415108
   DEBOYSSONBARDIES B, 1989, J CHILD LANG, V16, P1, DOI 10.1017/S0305000900013404
   Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914
   Dijksterhuis A, 2001, ADV EXP SOC PSYCHOL, V33, P1, DOI 10.1016/S0065-2601(01)80003-4
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   Fowler C. A., 1990, HASKINS LAB STATUS R, V101/102, P110
   FOWLER CA, 1991, MODULARITY AND THE MOTOR THEORY OF SPEECH PERCEPTION, P33
   FOWLER CA, 1990, J ACOUST SOC AM, V88, P1236, DOI 10.1121/1.399701
   FOWLER CA, 1990, J EXP PSYCHOL HUMAN, V16, P742, DOI 10.1037/0096-1523.16.4.742
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   FOWLER CA, 1996, THE JOURNAL OF THE A, V99, P1730
   Gagne CL, 2002, MEM COGNITION, V30, P637, DOI 10.3758/BF03194965
   Gentilucci M, 2007, NEUROPSYCHOLOGIA, V45, P608, DOI 10.1016/j.neuropsychologia.2006.04.004
   GILES H, 1973, ANTHROPOL LINGUIST, V15, P87
   Giles H., 1991, CONTEXTS ACCOMMODATI, P1, DOI [10.1017/CBO9780511663673.001, DOI 10.1017/CBO9780511663673.001]
   Giles H., 1987, ANN INT COMMUNICATIO, V10, P13, DOI [10.1080/23808985.1987.11678638, DOI 10.1080/23808985.1987.11678638]
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger Stephen D., 2000, P SWAP SPOK WORD ACC, P155
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Greenwald AG, 2003, J PERS SOC PSYCHOL, V85, P197, DOI 10.1037/0022-3514.85.2.197
   HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037/0033-295X.93.4.411
   INGLE D, 1973, SCIENCE, V181, P1053, DOI 10.1126/science.181.4104.1053
   JEANNEROD M, 1994, BEHAV BRAIN SCI, V17, P187, DOI 10.1017/S0140525X00034026
   Jeannerod M., 1997, FUNDAMENTALS COGNITI, V1
   KENT RD, 1982, J ACOUST SOC AM, V72, P353, DOI 10.1121/1.388089
   Kozhevnikov VA, 1965, SPEECH ARTICULATION
   KUHL PK, 1996, THE JOURNAL OF THE A, V100, P2425
   Labov W., 1980, LOCATING LANGUAGE TI, P251
   Lawson-Sako S., 1996, LANGUAGE IDENTITY MI, P61
   LEVIN H, 1988, LANG COMMUN, V8, P195, DOI 10.1016/0271-5309(88)90017-1
   Levitan R., 2011, P INT, V5, P3081
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MacKay D. G., 1987, ORG PERCEPTION ACTIO
   Manson JH, 2013, EVOL HUM BEHAV, V34, P419, DOI 10.1016/j.evolhumbehav.2013.08.001
   Mattingly I. G., 1988, AUDITORY FUNCTION
   MCHUGO GJ, 1985, J PERS SOC PSYCHOL, V49, P1513
   MELTZOFF AN, 1983, CHILD DEV, V54, P702, DOI 10.2307/1130058
   Miller RM, 2010, ATTEN PERCEPT PSYCHO, V72, P1614, DOI 10.3758/APP.72.6.1614
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   MOISE LC, 1994, CANADIAN ETHNIC STUD, V26, P86
   Mukamel R, 2010, CURR BIOL, V20, P750, DOI 10.1016/j.cub.2010.02.045
   Namy LL, 2002, J LANG SOC PSYCHOL, V21, P422, DOI 10.1177/026192702237958
   NATALE M, 1975, J PERS SOC PSYCHOL, V32, P790, DOI 10.1037/0022-3514.32.5.790
   Nielsen K., 2008, THESIS
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nye PW, 2003, J PHONETICS, V31, P63, DOI 10.1016/S0095-4470(02)00072-4
   Pardo J. S., 2013, J ACOUST SOC AM, V133, P3433
   Pardo JS, 2017, ATTEN PERCEPT PSYCHO, V79, P637, DOI 10.3758/s13414-016-1226-0
   Pardo JS, 2013, J MEM LANG, V69, P183, DOI 10.1016/j.jml.2013.06.002
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   PAUS T, 1993, J NEUROPHYSIOL, V70, P453
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   PORTER RJ, 1980, J SPEECH HEAR RES, V23, P593, DOI 10.1044/jshr.2303.593
   PORTER RJ, 1980, J ACOUST SOC AM, V67, P1349, DOI 10.1121/1.384187
   PULVERMULLER F, 2006, IN PROCEEDINGS OF TH, V103, P7865, DOI DOI 10.1073/PNAS.0509989103
   Reitter D., 2006, P 28 ANN C COGN SCI, P685
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Shepard CA., 2001, NEW HDB LANGUAGE SOC, P33
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Street Robert. L., 1982, SOCIAL COGNITION COM, P193
   Tajfel H., 1978, DIFFERENTIATION SOCI
   TRIANDIS HC, 1960, HUM RELAT, V13, P175, DOI 10.1177/001872676001300206
   Trudgill P, 2008, LANG SOC, V37, P241, DOI 10.1017/S0047404508080287
   van Bezooijen R, 2005, SPEECH COMMUN, V47, P15, DOI 10.1016/j.specom.2005.04.010
   Von Holst E, 1973, BEHAV PHYSL ANIMAL M, P133
   Ward A., 2007, SLATE SPEECH LANGUAG
   Willemyns M, 1997, J LANG SOC PSYCHOL, V16, P3, DOI 10.1177/0261927X970161001
   YAEGERDROR M, 1991, LANG COMMUN, V11, P309, DOI 10.1016/0271-5309(91)90035-T
   YUEN I, 2010, IN PROCEEDINGS OF TH, V107, P592, DOI DOI 10.1073/PNAS.0904774107
   Zajonc R. B., 1982, AFFECT COGNITION, P211
   Zellou G, 2016, J ACOUST SOC AM, V140, P3560, DOI 10.1121/1.4966232
NR 95
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1749-818X
J9 LANG LINGUIST COMPAS
JI Lang. Linguist. Compass
PD DEC
PY 2017
VL 11
IS 12
AR e12268
DI 10.1111/lnc3.12268
PG 21
WC Language & Linguistics
SC Linguistics
GA FR0OE
UT WOS:000418760900001
DA 2021-02-24
ER

PT J
AU Friedrich, P
   Ocklenburg, S
   Heins, N
   Schluter, C
   Fraenz, C
   Beste, C
   Gunturkun, O
   Genc, E
AF Friedrich, Patrick
   Ocklenburg, Sebastian
   Heins, Nina
   Schlueter, Caroline
   Fraenz, Christoph
   Beste, Christian
   Guentuerkuen, Onur
   Genc, Erhan
TI Callosal microstructure affects the timing of electrophysiological
   left-right differences
SO NEUROIMAGE
LA English
DT Article
DE Hemispheric asymmetries; Interhemispheric interaction; Corpus callosum;
   EEG; DTI
ID INTERHEMISPHERIC-TRANSFER TIME; WHITE-MATTER ASYMMETRIES; HUMAN
   CORPUS-CALLOSUM; HUMAN BRAIN; HEMISPHERIC-SPECIALIZATION;
   INTERINDIVIDUAL DIFFERENCES; ELECTROMAGNETIC TOMOGRAPHY;
   SPEECH-PERCEPTION; PLANUM TEMPORALE; WATER DIFFUSION
AB The neural architecture of the corpus callosum shows pronounced inter-individual differences. These differences are thought to affect timing of interhemispheric interactions and, in turn, functional hemispheric asymmetries. The present study aimed at elucidating the neuronal mechanisms underlying this relationship. To this end, we used a combined DTI and EEG study design. In 103 right-handed and healthy adult participants, we determined the microstructural integrity of the posterior third of the corpus callosum and examined in how far this micro-structural integrity was related to between-hemisphere timing differences in neurophysiological correlates of attentional processes in the dichotic listening task. The results show that microstructural integrity of the posterior callosal third correlated with attentional timing differences in a verbal dichotic listening condition but not in a noise control condition. Hence, this association between callosal microstructure and between-hemisphere timing differences is specific for stimuli, which trigger hemispheric bottom-up processing in an asymmetric fashion. Specifically, higher microstructural integrity was associated with decreased left-right differences in the latency of the N1 event-related potential component and hence more symmetric processing of dichotic stimuli between the two hemispheres. Our data suggest that microstructure of the posterior callosal third affects functional hemispheric asymmetries by modulating the timing of interhemispheric interactions.
C1 [Friedrich, Patrick; Ocklenburg, Sebastian; Heins, Nina; Schlueter, Caroline; Fraenz, Christoph; Guentuerkuen, Onur; Genc, Erhan] Ruhr Univ Bochum, Dept Psychol, Inst Cognit Neurosci, Biopsychol, Bochum, Germany.
   [Beste, Christian] Tech Univ Dresden, Dept Child & Adolescent Psychiat, Fac Med, Cognit Neurophysiol, Dresden, Germany.
   [Beste, Christian] Natl Inst Mental Hlth, Expt Neurobiol, Klecany, Czech Republic.
RP Friedrich, P (corresponding author), Ruhr Univ Bochum, Fak Psychol, Inst Kognit Neurowissensch, Abt Biopsychol, Univ Str 150, D-44780 Bochum, Germany.
EM patrick.friedrich@rub.de
RI Schluter, Caroline/E-4000-2019; Genc, Erhan/T-9376-2018; Friedrich,
   Patrick/Y-1778-2019; Ocklenburg, Sebastian/O-5867-2017
OI Genc, Erhan/0000-0001-6514-5479; Friedrich, Patrick/0000-0001-5120-5880;
   Ocklenburg, Sebastian/0000-0001-5882-3200; Gunturkun,
   Onur/0000-0003-4173-5233
FU Deutsche Forschungsgemeinschaft (DFG)German Research Foundation (DFG)
   [Gu227/16-1, GE2777/2-1];  [BE4045/26-1]
FX This work was supported by the Deutsche Forschungsgemeinschaft (DFG)
   grant number Gu227/16-1 and GE2777/2-1 and partly by BE4045/26-1. The
   authors thank Katharina Berger and Carsten Siebert for support with the
   EEG measurements as well as Tobias Otto for technical support. The
   authors declare no competing financial interests.
CR ABOITIZ F, 1992, BRAIN RES, V598, P143, DOI 10.1016/0006-8993(92)90178-C
   Ardila Alfredo, 2016, Neurosci J, V2016, P4962562, DOI 10.1155/2016/4962562
   Bamiou DE, 2007, BRAIN RES REV, V56, P170, DOI 10.1016/j.brainresrev.2007.07.003
   Barazany D, 2009, BRAIN, V132, P1210, DOI 10.1093/brain/awp042
   Basser PJ, 1996, J MAGN RESON SER B, V111, P209, DOI 10.1016/j.jmr.2011.09.022
   Bayazit O, 2009, NEUROPSYCHOLOGIA, V47, P536, DOI 10.1016/j.neuropsychologia.2008.10.002
   Beaulieu C, 2002, NMR BIOMED, V15, P435, DOI 10.1002/nbm.782
   Beaulieu C, 2009, DIFFUSION MRI: FROM QUANTITATIVE MEASUREMENT TO IN VIVO NEUROANATOMY, P105, DOI 10.1016/B978-0-12-374709-9.00006-7
   Behrens TEJ, 2007, NEUROIMAGE, V34, P144, DOI 10.1016/j.neuroimage.2006.09.018
   Beste C., 2015, BRAIN STRUCT FUNCT
   Beste C, 2010, NEUROPSYCHOLOGIA, V48, P1248, DOI 10.1016/j.neuropsychologia.2009.12.025
   Bethmann A, 2007, BRAIN RES, V1133, P145, DOI 10.1016/j.brainres.2006.11.057
   Bloom JS, 2005, NEUROPSYCHOL REV, V15, P59, DOI 10.1007/s11065-005-6252-y
   BRYDEN MP, 1994, BEHAV BRAIN RES, V64, P119, DOI 10.1016/0166-4328(94)90124-4
   Caminiti R, 2009, P NATL ACAD SCI USA, V106, P19551, DOI 10.1073/pnas.0907655106
   Catani M, 2002, NEUROIMAGE, V17, P77, DOI 10.1006/nimg.2002.1136
   Chance SA, 2006, NEUROSCIENCE, V143, P1041, DOI 10.1016/j.neuroscience.2006.08.057
   CIPOLLONI PB, 1985, EXP BRAIN RES, V57, P381
   CLARKE JM, 1993, NEUROPSYCHOLOGIA, V31, P547, DOI 10.1016/0028-3932(93)90051-Z
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Dippel G, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7587
   Dorsaint-Pierre R, 2006, BRAIN, V129, P1164, DOI 10.1093/brain/awl055
   Eichele T, 2005, COGNITIVE BRAIN RES, V24, P405, DOI 10.1016/j.cogbrainres.2005.02.017
   Fields RD, 2008, TRENDS NEUROSCI, V31, P361, DOI 10.1016/j.tins.2008.04.001
   Foundas AL, 2006, CORTEX, V42, P79, DOI 10.1016/S0010-9452(08)70324-1
   Gazzaniga MS, 2000, BRAIN, V123, P1293, DOI 10.1093/brain/123.7.1293
   Genc E, 2015, BEHAV BRAIN RES, V293, P1, DOI 10.1016/j.bbr.2015.07.016
   Genc E, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00161
   Genc E, 2011, CURR BIOL, V21, P1494, DOI 10.1016/j.cub.2011.08.003
   Gootjes L, 2006, NEUROPSYCHOLOGIA, V44, P208, DOI 10.1016/j.neuropsychologia.2005.05.002
   Greenblatt RE, 2005, IEEE T SIGNAL PROCES, V53, P3403, DOI 10.1109/TSP.2005.853201
   Herrmann CS, 2001, NEUROSCI BIOBEHAV R, V25, P465, DOI 10.1016/S0149-7634(01)00027-6
   Herve PY, 2013, TRENDS COGN SCI, V17, P69, DOI 10.1016/j.tics.2012.12.004
   Hirnstein M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00058
   Hiscock M, 2011, BRAIN COGNITION, V76, P263, DOI 10.1016/j.bandc.2011.03.016
   Hofer S, 2006, NEUROIMAGE, V32, P989, DOI 10.1016/j.neuroimage.2006.05.044
   Horowitz A, 2015, BRAIN STRUCT FUNCT, V220, P1791, DOI 10.1007/s00429-015-1031-x
   Hugdahl K, 2016, NEUROPSYCHOLOGIA, V93, P466, DOI 10.1016/j.neuropsychologia.2015.12.011
   Hugdahl K, 2011, BRAIN COGNITION, V76, P211, DOI 10.1016/j.bandc.2011.03.006
   Hutsler J, 2003, TRENDS NEUROSCI, V26, P429, DOI 10.1016/S0166-2236(03)00198-X
   Jancke L, 2002, NEUROLOGY, V58, P736, DOI 10.1212/WNL.58.5.736
   Josse G, 2004, BRAIN RES REV, V44, P1, DOI 10.1016/j.brainresrev.2003.10.001
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   Kimura D, 2011, BRAIN COGNITION, V76, P214, DOI 10.1016/j.bandc.2010.11.009
   KINSBOURNE M, 1970, ACTA PSYCHOL, V33, P193, DOI 10.1016/0001-6918(70)90132-0
   LAMANTIA AS, 1990, J COMP NEUROL, V291, P520, DOI 10.1002/cne.902910404
   Laule C, 2007, NEUROTHERAPEUTICS, V4, P460, DOI 10.1016/j.nurt.2007.05.004
   Luders E, 2010, J NEUROSCI, V30, P10985, DOI 10.1523/JNEUROSCI.5122-09.2010
   Madler B, 2008, MAGN RESON IMAGING, V26, P874, DOI 10.1016/j.mri.2008.01.047
   Mazziotta J, 2001, PHILOS T R SOC B, V356, P1293, DOI 10.1098/rstb.2001.0915
   McManus C., 2004, RIGHT HAND LEFT HAND
   Mori S, 2006, NEURON, V51, P527, DOI 10.1016/j.neuron.2006.08.012
   Muckschel M, 2014, CEREB CORTEX, V24, P2120, DOI 10.1093/cercor/bht066
   Mulert C, 2004, NEUROIMAGE, V22, P83, DOI 10.1016/j.neuroimage.2003.10.051
   Musiek FE, 2011, BRAIN COGNITION, V76, P225, DOI 10.1016/j.bandc.2011.03.011
   Ocklenburg S, 2017, MOL NEUROBIOL, V54, P7908, DOI 10.1007/s12035-016-0285-5
   Ocklenburg S, 2016, REV NEUROSCIENCE, V27, P465, DOI 10.1515/revneuro-2015-0052
   Ocklenburg S, 2013, NEUROIMAGE, V83, P1088, DOI 10.1016/j.neuroimage.2013.07.076
   Ocklenburg S, 2013, BRAIN LANG, V126, P279, DOI 10.1016/j.bandl.2013.07.001
   Ocklenburg S, 2012, BRAIN COGNITION, V78, P148, DOI 10.1016/j.bandc.2011.11.001
   Olbrich S, 2009, NEUROIMAGE, V45, P319, DOI 10.1016/j.neuroimage.2008.11.014
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Park HJ, 2008, HUM BRAIN MAPP, V29, P503, DOI 10.1002/hbm.20314
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   PASCUALMARQUI RD, 1994, INT J PSYCHOPHYSIOL, V18, P49, DOI 10.1016/0167-8760(84)90014-X
   Peru A, 2003, NEUROPSYCHOLOGIA, V41, P634, DOI 10.1016/S0028-3932(02)00203-8
   Pollmann S, 2002, NEUROPSYCHOLOGY, V16, P56, DOI 10.1037//0894-4105.16.1.56
   RINGO JL, 1994, CEREB CORTEX, V4, P331, DOI 10.1093/cercor/4.4.331
   Ross B, 2010, CEREB CORTEX, V20, P1360, DOI 10.1093/cercor/bhp201
   Sammler D, 2010, BRAIN, V133, P2643, DOI 10.1093/brain/awq231
   Schulte T, 2005, CEREB CORTEX, V15, P1384, DOI 10.1093/cercor/bhi020
   Sekihara K, 2005, NEUROIMAGE, V25, P1056, DOI 10.1016/j.neuroimage.2004.11.051
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Takahashi M, 2002, P NATL ACAD SCI USA, V99, P16192, DOI 10.1073/pnas.252249999
   Van der Haegen L, 2013, NEUROPSYCHOLOGIA, V51, P91, DOI 10.1016/j.neuropsychologia.2012.11.002
   Van Schependom J, 2017, MAGN RESON IMAGING, V40, P109, DOI 10.1016/j.mri.2017.04.010
   Wedeen VJ, 2005, MAGN RESON MED, V54, P1377, DOI 10.1002/mrm.20642
   Westerhausen R, 2006, J PSYCHOPHYSIOL, V20, P147
   Westerhausen R, 2006, NEUROPSYCHOLOGY, V20, P272, DOI 10.1037/0894-4105.20.3.272
   Westerhausen R, 2008, NEUROSCI BIOBEHAV R, V32, P1044, DOI 10.1016/j.neubiorev.2008.04.005
   Westerhausen R, 2006, NEUROSCI LETT, V409, P140, DOI 10.1016/j.neulet.2006.09.028
   Westerhausen R, 2009, CEREB CORTEX, V19, P1322, DOI 10.1093/cercor/bhn173
   YAZGAN MY, 1995, NEUROPSYCHOLOGIA, V33, P769, DOI 10.1016/0028-3932(95)00018-X
   Zarei M, 2006, J ANAT, V209, P311, DOI 10.1111/j.1469-7580.2006.00615.x
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zatorre RJ, 2012, NAT NEUROSCI, V15, P528, DOI 10.1038/nn.3045
   Zhang H, 2012, NEUROIMAGE, V61, P1000, DOI 10.1016/j.neuroimage.2012.03.072
NR 87
TC 6
Z9 6
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD DEC
PY 2017
VL 163
BP 310
EP 318
DI 10.1016/j.neuroimage.2017.09.048
PG 9
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA FQ8VR
UT WOS:000418641800027
PM 28951351
DA 2021-02-24
ER

PT J
AU Hubbard, DJ
   Faso, DJ
   Assmann, PF
   Sasson, NJ
AF Hubbard, Daniel J.
   Faso, Daniel J.
   Assmann, Peter F.
   Sasson, Noah J.
TI Production and perception of emotional prosody by adults with autism
   spectrum disorder
SO AUTISM RESEARCH
LA English
DT Article
DE Autism spectrum disorder; emotion; affective prosody; expressive speech;
   vocal affect; speech production; speech perception
ID DIAGNOSTIC OBSERVATION SCHEDULE; CHILDREN; COMMUNICATION; EXPRESSION;
   SPEECH; VOICE; ADOLESCENTS; INTONATION; SPEAKERS; MODEL
AB This study examined production and perception of affective prosody by adults with autism spectrum disorder (ASD). Previous research has reported increased pitch variability in talkers with ASD compared to typically developing (TD) controls in grammatical speaking tasks (e.g., comparing interrogative vs. declarative sentences), but it is unclear whether this pattern extends to emotional speech. In this study, speech recordings in five emotion contexts (angry, happy, interested, sad, and neutral) were obtained from 15 adult males with ASD and 15 controls (Experiment 1), and were later presented to 52 listeners (22 with ASD) who were asked to identify the emotion expressed and rate the level of naturalness of the emotion in each recording (Experiment 2). Compared to the TD group, talkers with ASD produced phrases with greater intensity, longer durations, and increased pitch range for all emotions except neutral, suggesting that their greater pitch variability was specific to emotional contexts. When asked to identify emotion from speech, both groups of listeners were more accurate at identifying the emotion context from speech produced by ASD speakers compared to TD speakers, but rated ASD emotional speech as sounding less natural. Collectively, these results reveal differences in emotional speech production in talkers with ASD that provide an acoustic basis for reported perceptions of oddness in the speech presentation of adults with ASD. Autism Res2017, 10: 1991-2001. (c) 2017 International Society for Autism Research, Wiley Periodicals, Inc.
   Lay SummaryThis study examined emotional speech communication produced and perceived by adults with autism spectrum disorder (ASD) and typically-developing (TD) controls. Compared to the TD group, talkers with ASD produced emotional phrases that were louder, longer, and more variable in pitch. Both ASD and TD listeners were more accurate at identifying emotion in speech produced by ASD speakers compared to TD speakers, but rated ASD emotional speech as sounding less natural.
C1 [Hubbard, Daniel J.; Faso, Daniel J.; Assmann, Peter F.; Sasson, Noah J.] Univ Texas Dallas, Sch Behav & Brain Sci, GR41,800 West Campbell Rd, Dallas, TX 75080 USA.
RP Hubbard, DJ (corresponding author), Univ Texas Dallas, Sch Behav & Brain Sci, GR41,800 West Campbell Rd, Dallas, TX 75080 USA.
EM dhubbard@utdallas.edu
FU National Institute of Mental Health at National Institutes of Health
   [R15 MH1015945]; National Science FoundationNational Science Foundation
   (NSF) [1124479]; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Mental Health (NIMH) [R15MH101594]
   Funding Source: NIH RePORTER
FX The authors wish to thank the individuals who participated in the study,
   and the Nonpareil Institute of Plano, TX for helping with participant
   recruitment. We thank the reviewers for their comments on a previous
   version of the manuscript. This research was funded in part by a grant
   from the National Institute of Mental Health at National Institutes of
   Health (R15 MH1015945, PI Sasson). This work is based on a doctoral
   dissertation by DH, who was supported in part by a grant from the
   National Science Foundation (1124479, PI Assmann).
CR Banziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Begeer S, 2008, DEV REV, V28, P342, DOI 10.1016/j.dr.2007.09.001
   Boersma P., 2014, PRAAT DOING PHONETIC
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P123, DOI 10.1016/j.rasd.2011.03.012
   Fairbanks G, 1939, SPEECH MONOGR, V6, P87, DOI 10.1080/03637753909374863
   Faso DJ, 2015, J AUTISM DEV DISORD, V45, P75, DOI 10.1007/s10803-014-2194-7
   Fosnot S. M., 1999, P 14 INT C PHON SCI, P1925
   Golan O, 2007, J AUTISM DEV DISORD, V37, P1096, DOI 10.1007/s10803-006-0252-5
   Green H., 2009, INT J SPEECH LANGUAG, V11, P308, DOI [10.1080/17549500903003060, DOI 10.1080/17549500903003060]
   Grossman RB, 2012, RES AUTISM SPECT DIS, V6, P1150, DOI 10.1016/j.rasd.2012.03.006
   Hubbard K, 2007, J PSYCHOLINGUIST RES, V36, P159, DOI 10.1007/s10936-006-9037-4
   Hudenko WJ, 2012, AUTISM, V16, P641, DOI 10.1177/1362361311402856
   Hurley RSE, 2007, J AUTISM DEV DISORD, V37, P1679, DOI 10.1007/s10803-006-0299-3
   Hus V, 2014, J AUTISM DEV DISORD, V44, P1996, DOI 10.1007/s10803-014-2080-3
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   Lyons M, 2014, AUTISM RES, V7, P181, DOI 10.1002/aur.1355
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Nadig A, 2012, J AUTISM DEV DISORD, V42, P499, DOI 10.1007/s10803-011-1264-3
   Paul R, 2005, J AUTISM DEV DISORD, V35, P205, DOI 10.1007/s10803-004-1999-1
   Paul R, 2008, RES AUTISM SPECT DIS, V2, P110, DOI 10.1016/j.rasd.2007.04.001
   Peppe S, 2003, CLIN LINGUIST PHONET, V17, P345, DOI 10.1080/0269920031000079994
   Peppe S, 2007, J SPEECH LANG HEAR R, V50, P1015, DOI 10.1044/1092-4388(2007/071)
   R Core Team, 2015, R LANG ENV STAT COMP
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Rutherford MD, 2002, J AUTISM DEV DISORD, V32, P189, DOI 10.1023/A:1015497629971
   Sasson NJ, 2017, SCI REP-UK, V7, DOI 10.1038/srep40700
   Sasson NJ, 2013, AUTISM RES, V6, P134, DOI 10.1002/aur.1272
   Sasson NJ, 2011, J NEURODEV DISORD, V3, P87, DOI 10.1007/s11689-010-9068-x
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Scherer KR, 1979, EMOTIONS PERSONALITY, P495
   Shriberg LD, 2011, J AUTISM DEV DISORD, V41, P405, DOI 10.1007/s10803-010-1117-5
   Stewart ME, 2013, AUTISM, V17, P6, DOI 10.1177/1362361311424572
   Uljarevic M, 2013, J AUTISM DEV DISORD, V43, P1517, DOI 10.1007/s10803-012-1695-5
   Van Bourgondien M. E., 1992, HIGH FUNCTIONING IND, P227, DOI 10.1007/978-1-4899-2456-8_12
   Wang AT, 2007, ARCH GEN PSYCHIAT, V64, P698, DOI 10.1001/archpsyc.64.6.698
   Wechsler D, 1999, WASI WECHSLER ABBREV
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Wundt W., 1909, GRUNDRISS PSYCHOL AC
NR 44
TC 9
Z9 9
U1 2
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-3792
EI 1939-3806
J9 AUTISM RES
JI Autism Res.
PD DEC
PY 2017
VL 10
IS 12
BP 1991
EP 2001
DI 10.1002/aur.1847
PG 11
WC Behavioral Sciences; Psychology, Developmental
SC Behavioral Sciences; Psychology
GA FQ2ED
UT WOS:000418168800008
PM 28815940
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Asaei, A
   Cernak, M
   Bourlard, H
AF Asaei, Afsaneh
   Cernak, Milos
   Bourlard, Herve
TI Perceptual Information Loss due to Impaired Speech Production
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
LA English
DT Article
DE Information transmission; motor speech disorders; speech production;
   speech perception
ID CORTICAL ORGANIZATION; RECOGNITION; DEEP
AB Phonological classes define articulatory-free and articulatory-bound phone attributes. Deep neural network is used to estimate the probability of phonological classes from the speech signal. In theory, a unique combination of phone attributes form a phoneme identity. Probabilistic inference of phonological classes thus enables estimation of their compositional phoneme probabilities. A novel information theoretic framework is devised to quantify the information conveyed by each phone attribute, and assess the speech production quality for perception of phonemes. As a use case, we hypothesize that disruption in speech production leads to information loss in phone attributes, and thus confusion in phoneme identification. We quantify the amount of information loss due to dysarthric articulation recorded in the TORGO database. A novel information measure is formulated to evaluate the deviation from an ideal phone attribute production leading us to distinguish healthy production from pathological speech.
C1 [Asaei, Afsaneh; Cernak, Milos; Bourlard, Herve] Ctr Parc, Idiap Res Inst, CH-1920 Martigny, Switzerland.
   [Asaei, Afsaneh] Tech Univ Munich, UnternehmerTUM, Ctr Innovat & Business Creat, D-80333 Munich, Germany.
   [Bourlard, Herve] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
RP Asaei, A (corresponding author), Tech Univ Munich, UnternehmerTUM, Ctr Innovat & Business Creat, D-80333 Munich, Germany.
EM afsaneh.asaei@idiap.ch; milos.cernak@idiap.ch; herve.bourlard@idiap.ch
RI Cernak, Milos/AAC-6408-2019
OI Cernak, Milos/0000-0002-5569-9491
FU Swiss NSF project on "Parsimonious hierarchical automatic speech
   recognition and query detection" PHASER; PHASER-QUAD [200021-153507,
   200020-169398]
FX The work of A. Asaei was supported by Swiss NSF project on "Parsimonious
   hierarchical automatic speech recognition and query detection" PHASER
   and PHASER-QUAD under Grants 200021-153507 and 200020-169398. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Sin-Horng Chen. (Corresponding
   author: Afsaneh Asaei.)
CR Allen JB, 1994, IEEE T SPEECH AUDI P, V2, P567, DOI 10.1109/89.326615
   Asaei A., 2016, P 7 WORKSH SPEECH LA, P50
   Asaei A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P418
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Bourlard H, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P426
   Browman Catherine, 1986, PHONOLOGY YB, V3, P219, DOI DOI 10.1017/S0952675700000658
   BROWMAN CP, 1990, J PHONETICS, V18, P299, DOI 10.1016/S0095-4470(19)30376-6
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Browman CP., 1989, PHONOLOGY, V6, P201, DOI [10.1017/S0952675700001019, DOI 10.1017/S0952675700001019]
   Cernak M, 2016, INTERSPEECH, P988, DOI 10.21437/Interspeech.2016-235
   Cernak M, 2017, COMPUT SPEECH LANG, V42, P100, DOI 10.1016/j.csl.2016.10.001
   Cernak M, 2016, SPEECH COMMUN, V84, P36, DOI 10.1016/j.specom.2016.08.004
   Cernak M, 2016, IEEE-ACM T AUDIO SPE, V24, P2301, DOI 10.1109/TASLP.2016.2604566
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Dronkers N, 2004, BRAIN, V127, P1461, DOI 10.1093/brain/awh233
   Enderby P. M., 1983, FRENCHAY DYSARTHRIA
   Fowler CA, 2016, PSYCHOL REV, V123, P125, DOI 10.1037/rev0000013
   Gold B., 2011, SPEECH AUDIO SIGNAL
   Guenther Frank H, 2015, Handb Clin Neurol, V129, P161, DOI 10.1016/B978-0-444-62630-1.00009-3
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kim J, 2015, COMPUT SPEECH LANG, V29, P132, DOI 10.1016/j.csl.2014.02.001
   Levelt WJ, 1989, SPEAKING INTENTION A
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lippmann RP, 1997, SPEECH COMMUN, V22, P1, DOI 10.1016/S0167-6393(97)00021-6
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Oosthuizen DJJ, 2016, SPEECH COMMUN, V82, P53, DOI 10.1016/j.specom.2016.06.003
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357
   Povey D., 2011, P IEEE WORKSH AUT SP, P1, DOI DOI 10.1017/CBO9781107415324.004
   Rudzicz F, 2012, LANG RESOUR EVAL, V46, P523, DOI 10.1007/s10579-011-9145-0
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Swanepoel R, 2012, J ACOUST SOC AM, V132, P2652, DOI 10.1121/1.4751543
   Timme N, 2014, J COMPUT NEUROSCI, V36, P119, DOI 10.1007/s10827-013-0458-4
   Weide RL., 1998, CMU PRONOUNCING DICT
   Yu D, 2012, INT CONF ACOUST SPEE, P4169, DOI 10.1109/ICASSP.2012.6288837
   Zen H., 2007, P ISCA SSW6, P131
NR 40
TC 2
Z9 2
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-9290
J9 IEEE-ACM T AUDIO SPE
JI IEEE-ACM Trans. Audio Speech Lang.
PD DEC
PY 2017
VL 25
IS 12
BP 2433
EP 2443
DI 10.1109/TASLP.2017.2738445
PG 11
WC Acoustics; Engineering, Electrical & Electronic
SC Acoustics; Engineering
GA FP6NW
UT WOS:000417743800017
DA 2021-02-24
ER

PT J
AU Vaughn, CR
   Bradlow, AR
AF Vaughn, Charlotte R.
   Bradlow, Ann R.
TI Processing Relationships Between Language-Being-Spoken and Other Speech
   Dimensions in Monolingual and Bilingual Listeners
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech perception; bilingualism; indexical information; Garner task;
   selective attention
ID SPEEDED CLASSIFICATION; TALKER IDENTIFICATION; FORMANT FREQUENCIES;
   VOICE IDENTIFICATION; COGNITIVE CONTROL; NATIVE SPEAKERS; PERCEPTION;
   INFORMATION; DEPENDENCIES; RECOGNITION
AB While indexical information is implicated in many levels of language processing, little is known about the internal structure of the system of indexical dimensions, particularly in bilinguals. A series of three experiments using the speeded classification paradigm investigated the relationship between various indexical and non-linguistic dimensions of speech in processing. Namely, we compared the relationship between a lesser-studied indexical dimension relevant to bilinguals, which language is being spoken (in these experiments, either Mandarin Chinese or English), with: talker identity (Experiment 1), talker gender (Experiment 2), and amplitude of speech (Experiment 3). Results demonstrate that language-being-spoken is integrated in processing with each of the other dimensions tested, and that these processing dependencies seem to be independent of listeners' bilingual status or experience with the languages tested. Moreover, the data reveal processing interference asymmetries, suggesting a processing hierarchy for indexical, non-linguistic speech features.
C1 [Vaughn, Charlotte R.] Univ Oregon, Eugene, OR 97403 USA.
   [Vaughn, Charlotte R.; Bradlow, Ann R.] Northwestern Univ, Evanston, IL USA.
RP Vaughn, CR (corresponding author), 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
EM cvaughn@uoregon.edu
OI Bradlow, Ann/0000-0001-5560-6059
FU National Institutes of Health - National Institute on Deafness and Other
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01-DC005794];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC005794, R01DC005794, R01DC005794,
   R01DC005794, R01DC005794, R01DC005794, R01DC005794, R01DC005794,
   R01DC005794] Funding Source: NIH RePORTER
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported in part by National Institutes of Health - National
   Institute on Deafness and Other Communication Disorders [R01-DC005794].
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Adesope OO, 2010, REV EDUC RES, V80, P207, DOI 10.3102/0034654310368803
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707
   Ben-Artzi E, 1999, J EXP PSYCHOL HUMAN, V25, P579, DOI 10.1037/0096-1523.25.3.579
   Bialystok E, 2004, DEVELOPMENTAL SCI, V7, P325, DOI 10.1111/j.1467-7687.2004.00351.x
   Bialystok E, 2004, PSYCHOL AGING, V19, P290, DOI 10.1037/0882-7974.19.2.290
   Bialystok E., 2005, INT J BILINGUAL, V9, P103, DOI DOI 10.1177/13670069050090010701
   Bialystok E, 2008, J EXP PSYCHOL LEARN, V34, P859, DOI 10.1037/0278-7393.34.4.859
   Bialystok E, 2012, TRENDS COGN SCI, V16, P240, DOI 10.1016/j.tics.2012.03.001
   BIEDERMA.I, 1970, J EXP PSYCHOL, V83, P486, DOI 10.1037/h0028841
   Bradlow A. R., 2010, ALLSSTAR ARCHIVE L1
   Bradlow Ann R, 2011, Proc Int Congr Phon Sci, P356
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   CARRELL TD, 1981, PERCEPT PSYCHOPHYS, V29, P1, DOI 10.3758/BF03198833
   CHILDERS DG, 1991, J ACOUST SOC AM, V90, P1841, DOI 10.1121/1.401664
   COLEMAN RO, 1971, J SPEECH HEAR RES, V14, P565, DOI 10.1044/jshr.1403.565
   Cox DR., 1970, ANAL BINARY DATA
   Cutler A., 2011, P 17 INT C PHON SCI, P552
   EIMAS PD, 1978, PERCEPT PSYCHOPHYS, V23, P12, DOI 10.3758/BF03214289
   FLEGE JE, 1988, J ACOUST SOC AM, V83, P729, DOI 10.1121/1.396115
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   Ganel T, 2004, J EXP PSYCHOL HUMAN, V30, P583, DOI 10.1037/0096-1523.30.3.583
   Garner W., 1974, PROCESSING INFORM ST
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   GREEN KP, 1997, ATTEN PERCEPT PSYCHO, V59, P675
   Hilchey MD, 2011, PSYCHON B REV, V18, P625, DOI 10.3758/s13423-011-0116-7
   Hillenbrand JM, 2009, ATTEN PERCEPT PSYCHO, V71, P1150, DOI 10.3758/APP.71.5.1150
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jerger S, 1999, J EXP CHILD PSYCHOL, V74, P44, DOI 10.1006/jecp.1999.2504
   JERGER S, 1993, ATTEN PERCEPT PSYCHO, V54, P310
   Kaganovich N, 2006, BRAIN RES, V1114, P161, DOI 10.1016/j.brainres.2006.07.049
   KLATT DH, 1990, J ACOUST SOC AM, V87, P857
   Koster O., 1995, P 13 INT C PHON SCI, P306
   LEE L, 1993, PERCEPT PSYCHOPHYS, V53, P157, DOI 10.3758/BF03211726
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Maddox WT, 1996, J EXP PSYCHOL HUMAN, V22, P795, DOI 10.1037/0096-1523.22.4.795
   MARTIN CS, 1989, J EXP PSYCHOL LEARN, V15, P676, DOI 10.1037/0278-7393.15.4.676
   MELARA RD, 1990, J EXP PSYCHOL LEARN, V16, P539, DOI 10.1037/0278-7393.16.4.539
   MILLER JL, 1978, PERCEPT PSYCHOPHYS, V24, P175, DOI 10.3758/BF03199546
   Mitchel AD, 2010, LANG COGNITIVE PROC, V25, P456, DOI 10.1080/01690960903209888
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Muthusamy Y. K., 1994, AC SPEECH SIGN PROC, VVolme 1, P1
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   NYGAARD LC, 1995, ATTEN PERCEPT PSYCHO, V57, P989
   Paap KR, 2013, COGNITIVE PSYCHOL, V66, P232, DOI 10.1016/j.cogpsych.2012.12.002
   Peirce C. S., 1940, PHILOS PEIRCE SELECT
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Perrachione TK, 2009, J EXP PSYCHOL HUMAN, V35, P1950, DOI 10.1037/a0015869
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Skuk VG, 2014, J SPEECH LANG HEAR R, V57, P285, DOI 10.1044/1092-4388(2013/12-0314)
   Soli SD, 2008, INT J AUDIOL, V47, P356, DOI 10.1080/14992020801895136
   STOCKMAL V, 1996, SPOKEN LANGUAGE 1996, V5, P1748
   Stockmal V., 1995, THESIS
   Sundara M, 2011, J PHONETICS, V39, P505, DOI 10.1016/j.wocn.2010.08.006
   THOMPSON CP, 1987, APPL COGNITIVE PSYCH, V1, P121, DOI 10.1002/acp.2350010205
   Tong YX, 2008, LANG COGNITIVE PROC, V23, P689, DOI 10.1080/01690960701728261
   VANLANCKER D, 1985, J PHONETICS, V13, P39, DOI 10.1016/S0095-4470(19)30724-7
   Vaughn C., 2015, P 18 INT C PHON SCI
   Vaughn C, 2014, THESIS
   Vaughn C., 2013, P M AC, VVolume 19
   von Bastian CC, 2016, J EXP PSYCHOL GEN, V145, P246, DOI 10.1037/xge0000120
   WALDEN BE, 1978, J SPEECH HEAR RES, V21, P265, DOI 10.1044/jshr.2102.265
   Weiss DJ, 2009, LANG LEARN DEV, V5, P30, DOI 10.1080/15475440802340101
   Wester M, 2012, SPEECH COMMUN, V54, P781, DOI 10.1016/j.specom.2012.01.006
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   Wong LLN, 2007, EAR HEARING, V28, p70S, DOI 10.1097/AUD.0b013e31803154d0
   WOOD CC, 1975, J EXP PSYCHOL HUMAN, V104, P3
   Xie X, 2015, J ACOUST SOC AM, V137, P419, DOI 10.1121/1.4904699
NR 74
TC 0
Z9 0
U1 0
U2 4
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2017
VL 60
IS 4
BP 530
EP 561
DI 10.1177/0023830916669536
PG 32
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA FP5ZN
UT WOS:000417701900002
PM 29216813
DA 2021-02-24
ER

PT J
AU Schwartz, G
AF Schwartz, Geoffrey
TI The perception of sandhi-blocking in Polish vowel-initial words
SO FOLIA LINGUISTICA
LA English
DT Article
DE vowel glottalization; speech perception; sandhi; onset prominence
ID STRESS
AB This paper presents data from two experiments on the perception of phrase-medial word-initial vowels in Polish. Previous research has suggested that Polish resembles German in its resistance to the types of sandhi linking processes found in English or French. In production, glottalization frequently intervenes to block such processes involving vowel-initial words. In the listening tests described here, glottalization had an impact on response time only in the word monitoring task, in which other top-down factors may have played a role. It is therefore suggested Polish listeners have only minimal perceptual sensitivity to glottalization, a feature that is prevalent in production. This largely negative result may be interpreted as evidence that when it appears, glottalization in Polish is not due to the insertion of a boundary marker, which would be perceptually more salient. Rather, glottalization reflects the preservation of the prosodic well-formedness of vowel-initial syllables in Polish, as formulated in the Onset Prominence representational framework.
C1 [Schwartz, Geoffrey] Adam Mickiewicz Univ, Fac English, Al Niepodleglosci 4, PL-61874 Poznan, Poland.
RP Schwartz, G (corresponding author), Adam Mickiewicz Univ, Fac English, Al Niepodleglosci 4, PL-61874 Poznan, Poland.
EM geoff@wa.amu.edu.pl
OI Schwartz, Geoffrey/0000-0002-0728-7820
FU Polish National Science Centre (Narodowe Centrum Nauki)
   [UMO-2012/05/B/HS2/04036]
FX The research reported in this paper was supported by a grant from the
   Polish National Science Centre (Narodowe Centrum Nauki), Project Nr.
   UMO-2012/05/B/HS2/04036, "Sandhi in second language speech". Thanks to
   Adam Olender for help with the statistical analysis, to Halszka Bak for
   technical assistance with E-Prime, and of course to the experimental
   participants. I am also grateful to two anonymous reviewers, and the
   editor of Folia Linguistica. Any remaining errors are my own
   responsibility.
CR Benus S, 2014, J PHONETICS, V44, P110, DOI 10.1016/j.wocn.2013.12.005
   Bethin Christina, 1984, INT J SLAV LING POET, V29, P17
   Bissiri Maria Paola, 2011, P INT 2011, P165
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Brunner J., 2011, P 17 INT C PHON SCI, P376
   Clements G. N., 1983, CV PHONOLOGY GENERAT
   Cook Ann, 2000, AM ACCENT TRAINING
   Crosswhite K, 2003, P 15 INT C PHON SCI, V2, P767
   Cruttenden A., 2001, GIMSONS PRONUNCIATIO
   Cyran Eugeniusz, 2013, POLISH VOICING PHONO
   Dilley L, 1996, J PHONETICS, V24, P423, DOI 10.1006/jpho.1996.0023
   Dluska M., 1974, PROZODIA JEZYKA POLS
   DOGIL G, 1980, LINGUIST ANAL, V6, P221
   Dogil G, 1999, WORD PROSODIC SYSTEM, P273
   Dogil Grzegorz, 1979, POZNAN STUDIES CONT, V9, P63
   Downing LJ, 1998, NAT LANG LINGUIST TH, V16, P1, DOI 10.1023/A:1005968714712
   Dukiewicz Leonida, 1995, GRAMATYKA WSPOLCZESN
   GARELLEK MARC, 2012, UCLA WORKING PAPERS, V110, P1
   GUSSMANN E, 1992, LINGUIST INQ, V23, P29
   Gussmann Edmund, 2007, PHONOLOGY POLISH
   Kraska-Szlenk I., 2003, PHONOLOGY STRESS POL
   Levi SV, 2008, LINGUA, V118, P1956, DOI 10.1016/j.lingua.2007.10.003
   Lleo C, 2004, INT J BILINGUAL, V8, P79, DOI DOI 10.1177/13670069040080010601
   Malisz Z, 2013, LAB PHONOL, V4, P119, DOI 10.1515/lp-2013-0006
   Malisz Zofia, 2015, 37 ANN M GERM LING S
   MARLETT SA, 1983, LINGUIST INQ, V14, P617
   Nespor Marina, 1986, PROSODIC PHONOLOGY
   Newlin-Kukowicz L, 2012, PHONOLOGY, V29, P271, DOI 10.1017/S0952675712000139
   Odden David, 1995, OHIO STATE U WORKING, V47, P89
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Prince A., 2004, OPTIMALITY THEORY CO
   Rochon Marzena, 2002, ASYMMETRIEN ASYMMETR, P297
   RUBACH J, 1990, NAT LANG LINGUIST TH, V8, P427, DOI 10.1007/BF00135620
   RUBACH J, 1985, LINGUA, V66, P281, DOI 10.1016/0024-3841(85)90032-4
   Rubach J, 1996, LINGUIST INQ, V27, P69
   Schwartz G, 2014, CONCORDIA WORK PAP A, V4, P637
   Schwartz G, 2016, LINGUA, V171, P37, DOI 10.1016/j.lingua.2015.11.005
   Schwartz G, 2013, POZ STUD CONTEMP LIN, V49, P557, DOI 10.1515/psicl-2013-0021
   Schwartz G, 2013, J LINGUIST, V49, P613, DOI 10.1017/S0022226712000436
   Schwartz Geoffrey, 2016, SECOND LANG RES, V32, P1
   Schwartz Geoffrey, 2015, RES LANGUAGE, V13, P61
   STERIADE D, 1993, PHONETICS PHONOLOGY, V5, P401, DOI DOI 10.1016/B978-0-12-360380-7.50018-1
   Volin Jan, 2012, RES LANGUAGE, V10, P173
   Wiese R., 1996, PHONOLOGY GERMAN
   Wright R., 2004, PHONETICALLY BASED P, P34, DOI [DOI 10.1017/CBO9780511486401.002, 10.1017/cbo9780511486401.002]
   Wright Richard, 1997, 21 IND U BLOOM
   Yip M, 2003, LINGUA, V113, P779, DOI 10.1016/S0024-3841(02)00130-4
NR 47
TC 0
Z9 0
U1 0
U2 2
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 0165-4004
EI 1614-7308
J9 FOLIA LINGUIST
JI Folia Linguist.
PD DEC
PY 2017
VL 51
IS 3
BP 671
EP 693
DI 10.1515/flin-2017-0025
PG 23
WC Linguistics; Language & Linguistics
SC Linguistics
GA FO5RV
UT WOS:000416919300008
DA 2021-02-24
ER

PT J
AU Grover, M
   Sharma, S
   Bhargava, S
   Singh, SN
   Gupta, G
   Sharma, MP
AF Grover, Mohnish
   Sharma, Shitanshu
   Bhargava, Shruti
   Singh, Shashank Nath
   Gupta, Gaurav
   Sharma, Man Prakash
TI Cochlear Implantation in Children with Anomalous Cochleovestibular
   Anatomy: Our Experience
SO INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY
LA English
DT Article
DE Inner ear malformations; Cochleovestibular anomalies; Cochlear
   implantation; Cerebrospinal fluid gusher
ID INNER-EAR MALFORMATIONS; CONGENITAL-MALFORMATIONS; MONDINI
AB To report operative findings, postoperative course, and postimplantation performance in patients with cochlear malformations who underwent cochlear implantation. Seventeen patients with malformations which included enlarged vestibular aqueduct (n = 6), Mondini's dysplasia (n = 5) common cavity deformity (n = 3) and incomplete partition type 2 (n = 3) underwent cochlear implantation with Nucleus 22 straight array device at our center. Operative findings described facial nerve anatomy and cerebrospinal fluid leak. Standard tests of speech perception were used to evaluate the postoperative performance for each subject. Operative findings included cerebrospinal fluid leak (thirteen patients) all of which were repaired successfully with graft. None had abnormal facial nerve anatomy. No surgical complications occurred. All the patients except two with common cavity had complete insertion. Electrode thresholds and discomfort levels were variable for several months after implantation. All patients demonstrated improved performance after implantation. Patients with enlarged vestibular aqueduct fared better than patients with other inner ear malformations. Cochlear implantation can be a successful method of rehabilitation in patients with congenital deafness who have cochlear malformations.
C1 [Grover, Mohnish; Sharma, Shitanshu; Singh, Shashank Nath; Sharma, Man Prakash] SMS Med Coll & Hosp, Dept Otorhinolaryngol & Head Neck Surg, Jaipur 302004, Rajasthan, India.
   [Bhargava, Shruti] SMS Med Coll & Hosp, Dept Pathol, Jaipur, Rajasthan, India.
   [Gupta, Gaurav] SP Med Coll, Dept Otorhinolaryngol & Head Neck Surg, Bikaner, India.
RP Sharma, S (corresponding author), SMS Med Coll & Hosp, Dept Otorhinolaryngol & Head Neck Surg, Jaipur 302004, Rajasthan, India.
EM shsharma811@gmail.com
RI Grover, Mohnish/AAF-7658-2020
OI Grover, Mohnish/0000-0002-8895-2254
CR Bille J, 2015, EUR ARCH OTO-RHINO-L, V272, P583, DOI 10.1007/s00405-014-2883-z
   Buchman CA, 2004, LARYNGOSCOPE, V114, P309, DOI 10.1097/00005537-200402000-00025
   JACKLER RK, 1987, LARYNGOSCOPE, V97, P2
   Jansen S, 1969, ACTA RADIOL, V286, P1
   JOHNSSON LG, 1984, AM J OTOLARYNG, V5, P242, DOI 10.1016/S0196-0709(84)80034-4
   Lo WWM, 1999, AM J NEURORADIOL, V20, P1442
   Luntz M, 1997, ARCH OTOLARYNGOL, V123, P974
   MONSELL EM, 1987, LARYNGOSCOPE, V97, P18
   OTTE J, 1978, LARYNGOSCOPE, V88, P1231
   Papsin Blake C, 2005, Laryngoscope, V115, P1, DOI 10.1097/00005537-200501001-00001
   Park AH, 2000, LARYNGOSCOPE, V110, P1715, DOI 10.1097/00005537-200010000-00029
   PHELPS PD, 1994, AM J OTOL, V15, P551
   Sennaroglu L, 2009, COCHLEAR IMPLANTS IN
   Xia J, 2015, ACTA OTO-LARYNGOL, V135, P459, DOI 10.3109/00016489.2014.990054
NR 14
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 2231-3796
EI 0973-7707
J9 INDIAN J OTOLARYNGOL
JI Indian J. Otolaryngol. Head Neck Surg.
PD DEC
PY 2017
VL 69
IS 4
BP 504
EP 508
DI 10.1007/s12070-017-1209-z
PG 5
WC Surgery
SC Surgery
GA FO5QF
UT WOS:000416914900013
PM 29238682
OA Green Published
DA 2021-02-24
ER

PT J
AU Baltzell, LS
   Srinivasan, R
   Richards, VM
AF Baltzell, Lucas S.
   Srinivasan, Ramesh
   Richards, Virginia M.
TI The effect of prior knowledge and intelligibility on the cortical
   entrainment response to speech
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE attention; EEG; entrainment; intelligibility; prior knowledge
ID AUDITORY-CORTEX; NEURONAL OSCILLATIONS; THETA-OSCILLATIONS; PHASE;
   COMPREHENSION; PERCEPTION; EEG; MODULATION; MECHANISM; ATTENTION
AB It has been suggested that cortical entrainment plays an important role in speech perception by helping to parse the acoustic stimulus into discrete linguistic units. However, the question of whether the entrainment response to speech depends on the intelligibility of the stimulus remains open. Studies addressing this question of intelligibility have, for the most part, significantly distorted the acoustic properties of the stimulus to degrade the intelligibility of the speech stimulus, making it difficult to compare across "intelligible" and "unintelligible" conditions. To avoid these acoustic confounds, we used priming to manipulate the intelligibility of vocoded speech. We used EEG to measure the entrainment response to vocoded target sentences that are preceded by natural speech (nonvocoded) prime sentences that are either valid (match the target) or invalid (do not match the target). For unintelligible speech, valid primes have the effect of restoring intelligibility. We compared the effect of priming on the entrainment response for both 3-channel (unintelligible) and 16-channel (intelligible) speech. We observed a main effect of priming, suggesting that the entrainment response depends on prior knowledge, but not a main effect of vocoding (16 channels vs. 3 channels). Furthermore, we found no difference in the effect of priming on the entrainment response to 3-channel and 16-channel vocoded speech, suggesting that for vocoded speech, entrainment response does not depend on intelligibility.
   NEW & NOTEWORTHY Neural oscillations have been implicated in the parsing of speech into discrete, hierarchically organized units. Our data suggest that these oscillations track the acoustic envelope rather than more abstract linguistic properties of the speech stimulus. Our data also suggest that prior experience with the stimulus allows these oscillations to better track the stimulus envelope.
C1 [Baltzell, Lucas S.; Srinivasan, Ramesh; Richards, Virginia M.] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92697 USA.
   [Srinivasan, Ramesh] Univ Calif Irvine, Dept Biomed Engn, Irvine, CA 92697 USA.
RP Baltzell, LS (corresponding author), Univ Calif Irvine, SSL 184, Irvine, CA 92697 USA.
EM baltzell@uci.edu
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Baltzell LS, 2016, BRAIN RES, V1644, P203, DOI 10.1016/j.brainres.2016.05.029
   Buchweitz Augusto, 2009, Psychol. Neurosci., V2, P111, DOI 10.3922/j.psns.2009.2.003
   Buzsaki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Canolty RT, 2006, SCIENCE, V313, P1626, DOI 10.1126/science.1128115
   Cohen L, 2002, BRAIN, V125, P1054, DOI 10.1093/brain/awf094
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Fries P, 2001, SCIENCE, V291, P1560, DOI 10.1126/science.1055465
   Garofolo J., 1993, TIMIT ACOUSTIC PHONE
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Hertrich I, 2013, BRAIN LANG, V124, P9, DOI 10.1016/j.bandl.2012.10.006
   Horton C, 2013, J NEUROPHYSIOL, V109, P3082, DOI 10.1152/jn.01026.2012
   Howard MF, 2010, J NEUROPHYSIOL, V104, P2500, DOI 10.1152/jn.00251.2010
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Loizou PC, 1999, J ACOUST SOC AM, V106, P2097, DOI 10.1121/1.427954
   Millman RE, 2015, J COGNITIVE NEUROSCI, V27, P533, DOI 10.1162/jocn_a_00719
   Nie KB, 2005, IEEE T BIO-MED ENG, V52, P64, DOI 10.1109/TBME.2004.839799
   Nunez PL., 2006, ELECT FIELDS BRAIN N
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   THOMPSON LW, 1965, PSYCHOL REP, V16, P339, DOI 10.2466/pr0.1965.16.2.339
   Zoefel B, 2016, NEUROIMAGE, V124, P16, DOI 10.1016/j.neuroimage.2015.08.054
NR 36
TC 4
Z9 4
U1 0
U2 12
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD DEC
PY 2017
VL 118
IS 6
BP 3144
EP 3151
DI 10.1152/jn.00023.2017
PG 8
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA FO4AX
UT WOS:000416783000014
PM 28877963
OA Green Published
DA 2021-02-24
ER

PT J
AU Swaminathan, S
   Schellenberg, EG
AF Swaminathan, Swathi
   Schellenberg, E. Glenn
TI Musical competence and phoneme perception in a foreign language
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Music; Rhythm; Speech; Foreign language; Plasticity; Transfer;
   Modularity
ID INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION; SKILLS; CHILDREN; ABILITY;
   DISCRIMINATION; PITCH; ASSOCIATIONS; CONTRASTS; DYSLEXIA
AB We investigated whether musical competence was associated with the perception of foreign-language phonemes. The sample comprised adult native-speakers of English who varied in music training. The measures included tests of general cognitive abilities, melody and rhythm perception, and the perception of consonantal contrasts that were phonemic in Zulu but not in English. Music training was associated positively with performance on the tests of melody and rhythm perception, but not with performance on the phoneme-perception task. In other words, we found no evidence for transfer of music training to foreign-language speech perception. Rhythm perception was not associated with the perception of Zulu clicks, but such an association was evident when the phonemes sounded more similar to English consonants. Moreover, it persisted after controlling for general cognitive abilities and music training. By contrast, there was no association between melody perception and phoneme perception. The findings are consistent with proposals that music- and speech-perception rely on similar mechanisms of auditory temporal processing, and that this overlap is independent of general cognitive functioning. They provide no support, however, for the idea that music training improves speech perception.
C1 [Swaminathan, Swathi; Schellenberg, E. Glenn] Univ Toronto, Dept Psychol, Mississauga, ON L5L 1C6, Canada.
   [Schellenberg, E. Glenn] Univ Toronto, Fac Mus, Toronto, ON M5S 2C5, Canada.
RP Schellenberg, EG (corresponding author), Univ Toronto, Dept Psychol, Mississauga, ON L5L 1C6, Canada.; Schellenberg, EG (corresponding author), Univ Toronto, Fac Mus, Toronto, ON M5S 2C5, Canada.
EM g.schellenberg@utoronto.ca
RI Swaminathan, Swathi/AAA-3718-2021
OI Swaminathan, Swathi/0000-0003-0940-6448; Schellenberg,
   Glenn/0000-0003-3681-6020
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
FX We thank Catherine Best for providing us with Zulu speech tokens and
   Sarah Selvadurai for assistance with data collection. Funded by the
   Natural Sciences and Engineering Research Council of Canada.
CR Anvari SH, 2002, J EXP CHILD PSYCHOL, V83, P111, DOI 10.1016/S0022-0965(02)00124-8
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Bhatara A, 2015, J EXP PSYCHOL HUMAN, V41, P277, DOI 10.1037/a0038736
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Bors DA, 1998, EDUC PSYCHOL MEAS, V58, P382, DOI 10.1177/0013164498058003002
   Carr KW, 2014, P NATL ACAD SCI USA, V111, P14559, DOI 10.1073/pnas.1406219111
   Corrigall KA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00282
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   Corrigall KA, 2011, MUSIC PERCEPT, V29, P147, DOI 10.1525/MP.2011.29.2.147
   Dege F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Gordon RL, 2015, DEVELOPMENTAL SCI, V18, P635, DOI 10.1111/desc.12230
   Goswami U., 2012, LANGUAGE AND MUSIC A, P292
   Grube M, 2013, COGN NEUROSCI-UK, V4, P225, DOI 10.1080/17588928.2013.825236
   Grube M, 2012, P ROY SOC B-BIOL SCI, V279, P4496, DOI 10.1098/rspb.2012.1817
   Hambrick D.Z., 2016, SCI AM
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Kempe V, 2015, BRIT J PSYCHOL, V106, P349, DOI 10.1111/bjop.12092
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Moritz C, 2013, READ WRIT, V26, P739, DOI 10.1007/s11145-012-9389-0
   Overy K, 2003, DYSLEXIA, V9, P18, DOI 10.1002/dys.233
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Posedel J, 2012, PSYCHOL MUSIC, V40, P508, DOI 10.1177/0305735611415145
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schellenberg EG, 2006, J EDUC PSYCHOL, V98, P457, DOI 10.1037/0022-0663.98.2.457
   Schellenberg EG, 2015, ANN NY ACAD SCI, V1337, P170, DOI 10.1111/nyas.12627
   Schellenberg EG, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P499, DOI 10.1016/B978-0-12-381460-9.00012-2
   Skoe E, 2012, J NEUROSCI, V32, P11507, DOI 10.1523/JNEUROSCI.1949-12.2012
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Swaminathan S., 2013, PSYCHOL STUD, V58, P164, DOI DOI 10.1007/S12646-013-0180-3
   Tallal P, 2006, TRENDS NEUROSCI, V29, P382, DOI 10.1016/j.tins.2006.06.003
   Thomson JM, 2013, READ WRIT, V26, P139, DOI 10.1007/s11145-012-9359-6
   Tierney AT, 2013, BRAIN LANG, V124, P225, DOI 10.1016/j.bandl.2012.12.014
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   Yang H, 2014, SCI REP-UK, V4, DOI 10.1038/srep05854
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 44
TC 11
Z9 11
U1 1
U2 9
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD DEC
PY 2017
VL 24
IS 6
BP 1929
EP 1934
DI 10.3758/s13423-017-1244-5
PG 6
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA FN9DU
UT WOS:000416329000019
PM 28204984
OA Bronze
DA 2021-02-24
ER

PT J
AU Couper, G
AF Couper, Graeme
TI Teacher Cognition of Pronunciation Teaching: Teachers' Concerns and
   Issues
SO TESOL QUARTERLY
LA English
DT Article
ID LANGUAGE; INSTRUCTION; ENGLISH
AB This article reports on teachers' knowledge and perceptions and the issues they are concerned about in relation to pronunciation teaching. Understanding teacher cognition helps to ensure research and pedagogical advice are appropriately directed. However, there has been only a limited amount of research in this area. The researcher collected data for this study through semistructured interviews with 19 English language teachers in New Zealand. A number of themes emerged, including a lack of initial training and knowledge of phonology, leading to uncertainty about exactly what should be taught and how. This often meant pronunciation was neglected, especially in areas such as stress and intonation. It was also found that much teaching was ad hoc and in response to errors. Concerns included how to teach pronunciation in mixed-first language classes and how to help learners with speech perception. The findings raise questions for reflective practice, teacher education, and professional development; recent research has found some answers, but these are not all represented in the knowledge base of teachers, teacher education courses, or classroom textbooks. The issues raised also underline the need for more research in a number of areas.
C1 [Couper, Graeme] Auckland Univ Technol, Sch Language & Culture, Auckland, New Zealand.
RP Couper, G (corresponding author), Auckland Univ Technol, Sch Language & Culture, Auckland, New Zealand.
CR Baker A, 2014, TESOL QUART, V48, P136, DOI 10.1002/tesq.99
   Baker AA, 2011, TESOL J, V2, P263, DOI 10.5054/tj.2011.259955
   Borg S., 2003, LANG TEACHING, V36, P81, DOI DOI 10.1017/S0261444803001903
   Breitkreutz J. A., 2001, TESL CANADA J, V19, P51, DOI DOI 10.18806/TESL.V19I1.919
   Burns A., 2006, TESL REPORTER, V39, P34
   Burns A, 2015, MOD LANG J, V99, P585, DOI 10.1111/modl.12245
   Catford J. C., 1987, CURRENT PERSPECTIVES, P83
   CELCE-MURCIA Marianne, 2010, TEACHING PRONUNCIATI
   Couper G., 2006, PROSPECT, V21, P46
   Couper G., 2016, J 2 LANGUAGE PRONUNC, V2, P29
   Couper G, 2015, BLACKW HBK LINGUIST, P413
   Couper G, 2011, LANG AWARE, V20, P159, DOI 10.1080/09658416.2011.570347
   Derwing T., 2014, PRONUNCIATION MYTHS, P56
   Derwing T., 2015, PRONUNCIATION FUNDAM
   Derwing TM, 1998, LANG LEARN, V48, P393, DOI 10.1111/0023-8333.00047
   Derwing TM, 2005, TESOL QUART, V39, P379, DOI 10.2307/3588486
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Foote JA, 2011, TESL CAN J, V29, P1
   Foote JA, 2016, LANG LEARN J, V44, P181, DOI 10.1080/09571736.2013.784345
   Fraser H, 2000, COORDINATING IMPROVE
   Fraser H., 2009, STUDIES APPL LINGUIS, P289
   Fraser H, 2010, APPL COGN LINGUIST, V17, P357
   Gilbert J., 2012, CLEAR SPEECH PRONUNC, V4th ed.
   Grant L., 2014, PRONUNCIATION MYTHS, P1
   Henderson A., 2015, RES LANGUAGE, V13, P1, DOI 10.1515/rela-2015-0009<original-structure ref = info:doi/10.1515/rela-2015-0009></original-structure>
   Henderson A., 2012, RES LANGUAGE, V10, P1, DOI 10.2478/v10015-011-0047-4<original-structure ref = info:doi/10.2478/v10015-011-0047-4></original-structure>
   Jenkins J, 2006, TESOL QUART, V40, P157, DOI 10.2307/40264515
   Jenkins Jennifer, 2007, ENGLISH LINGUA FRANC
   Kennedy S, 2014, FOREIGN LANG ANN, V47, P79, DOI 10.1111/flan.12066
   Kubanyiova M, 2015, MOD LANG J, V99, P435, DOI 10.1111/modl.12239
   Kvale S, 2007, DOING INTERVIEWS, P102, DOI 10.4135/9781849208963.n9
   Lantolf J., 2011, HDB RES 2 LANGUAGE T, VII, P303, DOI DOI 10.4324/9780203836507.CH19
   Macdonald S., 2002, PROSPECT ADELAIDE, V17, P3
   Mompean J., 2014, BLOOMSBURY COMPANION, P253
   Murphy J., 2014, PRONUNCIATION MYTHS, P188
   Murphy JM, 2014, SYSTEM, V42, P258, DOI 10.1016/j.system.2013.12.007
   Polkinghorne D.E., 1995, INT J QUAL STUD ED, V8, P5, DOI [10.1080/0951839950080103, DOI 10.1080/0951839950080103]
   Saito K, 2012, LANG LEARN, V62, P595, DOI 10.1111/j.1467-9922.2011.00639.x
   Sifakis NC, 2005, TESOL QUART, V39, P467, DOI 10.2307/3588490
   Spencer S., 2000, SYSTEM, V28, P191, DOI DOI 10.1016/S0346-251X(00)00007-5
   Starfield S., 2010, CONTINUUM COMPANION, P50
   Swan M., 2001, LEARNER ENGLISH TEAC
   Thomson RI, 2012, LANG LEARN, V62, P1231, DOI 10.1111/j.1467-9922.2012.00724.x
   Zielinski B., 2014, PRONUNCIATION MYTHS, P56
NR 44
TC 19
Z9 19
U1 4
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0039-8322
EI 1545-7249
J9 TESOL QUART
JI Tesol Q.
PD DEC
PY 2017
VL 51
IS 4
BP 820
EP 843
DI 10.1002/tesq.354
PG 24
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA FN3UH
UT WOS:000415926000004
DA 2021-02-24
ER

PT J
AU Abavisani, A
   Allen, JB
AF Abavisani, Ali
   Allen, Jont B.
TI Evaluating hearing aid amplification using idiosyncratic consonant
   errors
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-RECEPTION THRESHOLD; PERCEPTUAL FEATURES; STOP CONSONANTS; NOISE;
   RECOGNITION; VARIABILITY; CONFUSIONS; LISTENERS; INDEX
AB The goal of this study is to provide a metric for evaluating a given hearing-aid insertion gain using a consonant recognition based measure. The basic question addressed is how treatment impacts phone recognition at the token level, relative to a flat insertion gain, at the most-comfortable-level (MCL). These tests are directed at fine-tuning a treatment, with the ultimate goal of improving speech perception, and to identify when a hearing level gain-based treatment degrades phone recognition. Eight subjects with hearing loss were tested under two conditions: flat-gain and a treatment insertion gain, based on subject's hearing level. The speech corpus consisted of consonant-vowel tokens at different signal to speech-weighted noise conditions, presented at the subject's MCL. The treatment caused the average score to improve for 31% of the trials and decrease for 12%. An analysis method based on the accumulated error differences was devised to quantify the benefit each individual ear received from the treatment. Using this measure, the effect of the treatment could be evaluated, providing precise characterization of idiosyncratic phone recognition. This analysis directs the audiologist toward the most susceptible subject-dependent tokens, to focus in the process of fine-tuning the insertion gain of the hearing-aid. (C) 2017 Acoustical Society of America.
C1 [Abavisani, Ali; Allen, Jont B.] Univ Illinois, Beckman Inst, Dept Elect & Comp Engn, 405 North Mathews Ave, Urbana, IL 61801 USA.
RP Abavisani, A (corresponding author), Univ Illinois, Beckman Inst, Dept Elect & Comp Engn, 405 North Mathews Ave, Urbana, IL 61801 USA.
EM aliabavi@illinois.edu
FU Phonak; NIH R21United States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA
FX The authors thank Phonak and Stefan Launer, who funded this study. Most
   importantly, thanks to Woojae Han for collecting the data, with
   technical support from Riya Singh. The data collection was funded by an
   NIH R21.
CR Abavisani A., 2017, J ACOUST SOC AM, V141, P3633
   Allen J. B., 2016, J ACOUST SOC AM, V139, P2188
   Allen JB, 2005, J ACOUST SOC AM, V117, P2212, DOI 10.1121/1.1856231
   ALLEN JB, 2005, ARTICULATION INTELLI
   Allen JB, 1994, IEEE T SPEECH AUDI P, V2, P567, DOI 10.1109/89.326615
   Allen JB, 2009, IEEE SIGNAL PROC MAG, V26, P73, DOI 10.1109/MSP.2009.932564
   Apoux F, 2004, J ACOUST SOC AM, V116, P1671, DOI 10.1121/1.1781329
   Cole C. L., 2017, THESIS
   Dillon H., 2001, HEARING AIDS, P239
   Fousek P., 2004, P INT C SPOK LANG PR, P2749
   Han W, 2011, THESIS
   Kapoor A, 2012, J ACOUST SOC AM, V131, P478, DOI 10.1121/1.3665991
   Li FP, 2011, IEEE T AUDIO SPEECH, V19, P496, DOI 10.1109/TASL.2010.2050731
   Li FP, 2010, J ACOUST SOC AM, V127, P2599, DOI 10.1121/1.3295689
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Phatak SA, 2007, J ACOUST SOC AM, V121, P2312, DOI 10.1121/1.2642397
   Phatak SA, 2009, J ACOUST SOC AM, V126, P2683, DOI 10.1121/1.3238257
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   PLOMP R, 1986, J SPEECH HEAR RES, V29, P146, DOI 10.1044/jshr.2902.146
   Regnier MS, 2008, J ACOUST SOC AM, V123, P2801, DOI 10.1121/1.2897915
   Rhebergen KS, 2006, J ACOUST SOC AM, V120, P3988, DOI 10.1121/1.2358008
   Scheidiger C, 2017, J ACOUST SOC AM, V141, P1739, DOI 10.1121/1.4976066
   Singh R, 2012, J ACOUST SOC AM, V131, P3051, DOI 10.1121/1.3682054
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   Steinberg JC, 1940, J ACOUST SOC AM, V11, P270, DOI 10.1121/1.1916033
   Toscano JC, 2014, J SPEECH LANG HEAR R, V57, P2293, DOI 10.1044/2014_JSLHR-H-13-0244
   Trevino A. C., 2013, THESIS
   Trevino A, 2013, J ACOUST SOC AM, V134, P607, DOI 10.1121/1.4807474
   Trevino Andrea, 2013, Seminars in Hearing, V34, P74, DOI 10.1055/s-0033-1341345
   Valero MD, 2016, HEARING RES, V332, P29, DOI 10.1016/j.heares.2015.11.005
   Vysochanskij D. F., 1980, THEORY PROBABILITY M, V21, P25
   WANG MD, 1978, J SPEECH HEAR RES, V21, P5, DOI 10.1044/jshr.2101.05
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
   Yoon YS, 2012, J SPEECH LANG HEAR R, V55, P460, DOI 10.1044/1092-4388(2011/10-0239)
   Zaar J, 2015, J ACOUST SOC AM, V138, P1253, DOI 10.1121/1.4928142
   ZUREK PM, 1987, J ACOUST SOC AM, V82, P1548, DOI 10.1121/1.395145
NR 36
TC 1
Z9 1
U1 1
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2017
VL 142
IS 6
BP 3736
EP 3745
DI 10.1121/1.5016852
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FR3FV
UT WOS:000418952300047
PM 29289077
OA Green Published
DA 2021-02-24
ER

PT J
AU Zeng, B
   Mattys, SL
AF Zeng, Biao
   Mattys, Sven L.
TI Separability of Tones and Rhymes in Chinese Speech Perception: Evidence
   from Perceptual Migrations
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech perception; Chinese; tones; migration paradigm; autosegmental
   theory
ID SPOKEN WORD RECOGNITION; LEXICAL TONE; CANTONESE; AWARENESS;
   SEGMENTATION; INFORMATION; SYLLABLES; ILLUSIONS; PARADIGM; MANDARIN
AB This study used the perceptual-migration paradigm to explore whether Mandarin tones and syllable rhymes are processed separately during Mandarin speech perception. Following the logic of illusory conjunctions, we calculated the cross-ear migration of tones, rhymes, and their combination in Chinese and English listeners. For Chinese listeners, tones migrated more than rhymes. For English listeners, the opposite pattern was found. The results lend empirical support to autosegmental theory, which claims separability and mobility between tonal and segmental representations. They also provide evidence that such representations and their involvement in perception are deeply shaped by a listener's linguistic experience.
C1 [Zeng, Biao] Bournemouth Univ, Dept Psychol, Poole BH12 5BB, Dorset, England.
   [Mattys, Sven L.] Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
RP Zeng, B (corresponding author), Bournemouth Univ, Dept Psychol, Poole BH12 5BB, Dorset, England.; Mattys, SL (corresponding author), Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
EM bzeng@bournemouth.ac.uk; sven.mattys@york.ac.uk
FU Overseas Research Scholarship (ORS) scheme
FX This study was made possible thanks to a studentship from the Overseas
   Research Scholarship (ORS) scheme to Biao Zeng.
CR Cutler A, 1997, PERCEPT PSYCHOPHYS, V59, P165, DOI 10.3758/BF03211886
   Demolin Didier, 1991, LANGAGES, V101, P30
   Duanmu S., 2002, PHONOLOGY STANDARD C
   GOLDSMITH J, 1979, AUTOSEGMENTAL PHONOL
   Hombert J. M., 1986, EXPT PHONOLOGY, P175
   Kolinsky R, 1996, LANG COGNITIVE PROC, V11, P611
   KOLINSKY R, 1995, J MEM LANG, V34, P19, DOI 10.1006/jmla.1995.1002
   Kolinsky R., 1992, ANAL APPROACHES HUMA, P133
   Kung C, 2014, NEUROPSYCHOLOGIA, V53, P293, DOI 10.1016/j.neuropsychologia.2013.11.020
   LEE L, 1993, PERCEPT PSYCHOPHYS, V53, P157, DOI 10.3758/BF03211726
   Liu SY, 2007, LANG COGNITIVE PROC, V22, P566, DOI 10.1080/01690960600989600
   Ma JKY, 2006, J ACOUST SOC AM, V120, P3978, DOI 10.1121/1.2363927
   MARCEL AJ, 1983, COGNITIVE PSYCHOL, V15, P238, DOI 10.1016/0010-0285(83)90010-5
   Mattys SL, 2005, LANG SPEECH, V48, P223, DOI 10.1177/00238309050480020501
   Mattys SL, 1997, J MEM LANG, V36, P87, DOI 10.1006/jmla.1996.2472
   MORAIS J, 1979, COGNITION, V7, P323, DOI 10.1016/0010-0277(79)90020-9
   MORAIS J, 1994, COGNITION, V50, P287, DOI 10.1016/0010-0277(94)90032-9
   MORAIS J, 1985, LINGUISTICS, V23, P707, DOI 10.1515/ling.1985.23.5.707
   MORAIS J, 1987, THE QUARTERLY JOURNA, V39, P451
   Nakamura M, 2014, LANG SPEECH, V57, P513, DOI 10.1177/0023830913508077
   Schirmer A, 2005, J COGNITIVE NEUROSCI, V17, P1, DOI 10.1162/0898929052880057
   Sereno JA, 2015, LANG SPEECH, V58, P131, DOI 10.1177/0023830914522956
   SPEER SR, 1989, LANG SPEECH, V32, P337, DOI 10.1177/002383098903200403
   Tong Y., 2008, LANG COGNITIVE PROC, V23, P698
   TREISMAN A, 1982, COGNITIVE PSYCHOL, V14, P107, DOI 10.1016/0010-0285(82)90006-8
   TREISMAN A, 1984, J EXP PSYCHOL HUMAN, V10, P12, DOI 10.1037/0096-1523.10.1.12
   WOO N, 1970, INT J AM LINGUIST, V36, P18, DOI 10.1086/465085
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Yip M., 2002, TONE
   ZHOU XL, 1994, LANG COGNITIVE PROC, V9, P393, DOI 10.1080/01690969408402125
NR 30
TC 1
Z9 1
U1 1
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2017
VL 60
IS 4
BP 562
EP 570
DI 10.1177/0023830916675897
PG 9
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA FP5ZN
UT WOS:000417701900003
PM 29216812
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Manan, HA
   Yusoff, AN
   Franz, EA
   Mukari, SZMS
AF Manan, H. A.
   Yusoff, A. N.
   Franz, E. A.
   Mukari, S. Z. -M. S.
TI Effects of Aging and Background Babble Noise on Speech Perception
   Processing: An fMRI Study
SO NEUROPHYSIOLOGY
LA English
DT Article
DE speech perception; fMRI; aging; background babble noise; speech stimuli;
   dedifferentiation
ID HUMAN AUDITORY-SYSTEM; STOCHASTIC RESONANCE; AGE-DIFFERENCES;
   WORKING-MEMORY; BRAIN ACTIVITY; OLDER ADULTS; ATTENTION; ACTIVATION;
   COGNITION; TASK
AB Speech perception processing in a noisy environment is subjected to age-related decline. We used functional magnetic resonance imaging (fMRI) to examine cortical activation associated with such processing across four groups of participants with age ranges of 23-29, 30-37, 41-47 and 50-65 years old. All participants performed a forward repeat task in quiet environment (SQ) and in the presence of multi-talker babble noise (SN; 5-dB signal-to-noise ratio, SNR). Behavioral test results demonstrated a decrease in the performance accuracy associated with increasing age for both SQ and SN. However, a significant difference in the performance accuracy between these conditions could only be seen among the elderly (60-65 years old) subjects. The fMRI results across the four age groups showed a nearly similar pattern of brain activation in the auditory, speech, and attention areas during SQ and SN. Comparisons between SQ and SN demonstrated significantly lower brain activation in the left precentral gyrus, left postcentral gyrus, left Heschly's gyrus, and right middle temporal gyrus under the latter condition. Other activated brain areas showed no significant differences in brain activation between SQ and SN. The decreases in cortical activation in the activated regions positively correlated with the decrease in the behavioral performance across age groups. These findings are discussed based on a dedifferentiation hypothesis that states that increased brain activation among older participants, as compared to young participants, is due to the age-related deficits in neural communication.
C1 [Manan, H. A.; Yusoff, A. N.] Univ Kebangsaan, Sch Diagnost & Appl Hlth Sci, Fac Hlth Sci, Kuala Lumpur, Malaysia.
   [Manan, H. A.] Univ Sains Malaysia, Ctr Neurosci Serv & Res P3Neuro, Kubang Kerian, Malaysia.
   [Manan, H. A.] Pusat Perubatan Univ Kebangsaan Malaysia, Dept Radiol, Makmal Pemprosesan Imej Kefungsian, Jalan Yaacob Latif, Kuala Lumpur 56000, Malaysia.
   [Franz, E. A.] Univ Otago, Dept Psychol, Dunedin, New Zealand.
   [Franz, E. A.] Univ Otago, fMRI, Dunedin, New Zealand.
   [Mukari, S. Z. -M. S.] Univ Kebangsaan Malaysia, Sch Rehabil Sci, Fac Hlth Sci, Kuala Lumpur, Malaysia.
RP Yusoff, AN (corresponding author), Univ Kebangsaan, Sch Diagnost & Appl Hlth Sci, Fac Hlth Sci, Kuala Lumpur, Malaysia.
EM nazlimtrw@ukm.edu.my
RI Yusoff, Ahmad Nazlim/I-9674-2019
FU  [UKM GUP-SK-07-020-205]
FX We thank S. Samian from the Department of Radiology, Universiti
   Kebangsaan Malaysia Medical Centre, for the assistance in fMRI scans. We
   also thank M. Hairol Isa from the Jabatan Kesihatan Masyarakat
   Universiti Kebangsaan Medical Centre for his valuable help in managing
   older participants. This work has been supported by the Research
   University Grant UKM GUP-SK-07-020-205.
CR Abdul Manan H, 2013, NEUROL PSYCHIAT BR, V19, P207
   Abdul Manan H, 2014, NEUROL PSYCHIAT BR, V20, P76, DOI [10.1016/j.npbr.2014.08.001, DOI 10.1016/J.NPBR.2014.08.001]
   Anstey KJ, 2001, J GERONTOL B-PSYCHOL, V56, pP3, DOI 10.1093/geronb/56.1.P3
   Benedict RHB, 1998, NEUROREPORT, V9, P121, DOI 10.1097/00001756-199801050-00024
   Cabeza R, 2004, CEREB CORTEX, V14, P364, DOI 10.1093/cercor/bhg133
   Cabeza R, 2002, NEUROIMAGE, V17, P1394, DOI 10.1006/nimg.2002.1280
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Cabeza R., 2012, FRONTAL LOBES, P628, DOI [10.1093/acprof:oso/9780195134971.001.0001, DOI 10.1093/ACPROF:OSO/9780195134971.001.0001]
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Grady CL, 2003, J NEUROSCI, V23, P986, DOI 10.1523/jneurosci.23-03-00986.2003
   Grady CL, 2002, PSYCHOL AGING, V17, P3, DOI 10.1037/0882-7974.17.1.3
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Kujala T, 2004, PSYCHOPHYSIOLOGY, V41, P875, DOI 10.1111/j.1469-8986.2004.00244.x
   Kujala T, 2009, BIOL PSYCHOL, V81, P135, DOI 10.1016/j.biopsycho.2009.03.010
   Li KZH, 2002, NEUROSCI BIOBEHAV R, V26, P777, DOI 10.1016/S0149-7634(02)00073-8
   Li S. C., 1999, COGN NEUROSCI MEMORY
   Lim S., CEREB CORTEX, DOI [10.1093/cercor/bht33, DOI 10.1093/CERCOR/BHT33]
   Lockwood AH, 1999, CEREB CORTEX, V9, P65, DOI 10.1093/cercor/9.1.65
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1
   Manan H. A., 2015, NEUROL PSYCHIAT BR, V21, P64, DOI DOI 10.1016/j.npbr.2014.09.001
   Manan HA, 2013, BRAIN RES, V19, P180
   Manan HA, 2015, AGING CLIN EXP RES, V27, P27, DOI 10.1007/s40520-014-0240-0
   Manan Hanani Abdul, 2012, Psychol. Neurosci., V5, P247, DOI 10.3922/j.psns.2012.2.16
   Martin JS, 2005, J REHABIL RES DEV, V42, P25, DOI 10.1682/JRRD.2004.12.0164
   Mather M., 2005, TRENDS COGN SCI, V9, P296, DOI [10.1016/j.tics.2005.04.010, DOI 10.1016/J.TICS.2005.04.010]
   Moss F, 2004, CLIN NEUROPHYSIOL, V115, P267, DOI 10.1016/j.clinph.2003.09.014
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Park DC, 2002, NEUROSCI BIOBEHAV R, V26, P859, DOI 10.1016/S0149-7634(02)00072-6
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.ne.13.030190.000325
   Reuter-Lorenz PA, 2005, CURR OPIN NEUROBIOL, V15, P245, DOI 10.1016/j.conb.2005.03.016
   Reuter-Lorenz PA, 2000, J COGNITIVE NEUROSCI, V12, P174, DOI 10.1162/089892900561814
   Rousseau D, 2004, PHYS LETT A, V321, P280, DOI 10.1016/j.physleta.2003.12.042
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   Salvi RJ, 2002, HEARING RES, V170, P96, DOI 10.1016/S0378-5955(02)00386-6
   Schmahmann JD, 2008, CORTEX, V44, P1037, DOI 10.1016/j.cortex.2008.04.004
   Shimizu T, 2002, AURIS NASUS LARYNX, V29, P121, DOI 10.1016/S0385-8146(01)00133-X
   Stevens MC, 2005, NEUROIMAGE, V26, P782, DOI 10.1016/j.neuroimage.2005.02.044
   Turner CW, 1998, J ACOUST SOC AM, V104, P1580, DOI 10.1121/1.424370
   Walton JP, 2002, J NEUROPHYSIOL, V88, P565, DOI 10.1152/jn.2002.88.2.565
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Yamamoto Y, 2002, PHYSICA A, V314, P53, DOI 10.1016/S0378-4371(02)01183-4
   Yusoff A. N., 2006, J SAINS KESIHATAN MA, V4, P21
   Yusoff A.N., 2013, J SAINS KESIHAT MALA, V11, P41
   Yusoff Ahmad Nazlim, 2008, J SAINS KES MAL, V6, P35
   YUSOFF AN, 2010, J SAINS KESIHAT MALA, V8, P43
NR 47
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0090-2977
EI 1573-9007
J9 NEUROPHYSIOLOGY+
JI Neurophysiology
PD DEC
PY 2017
VL 49
IS 6
BP 441
EP 452
DI 10.1007/s11062-018-9707-5
PG 12
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA GB9VE
UT WOS:000429421400007
DA 2021-02-24
ER

PT J
AU Badenhorst, W
   Hanekom, T
   Hanekom, JJ
AF Badenhorst, Werner
   Hanekom, Tania
   Hanekom, Johan J.
TI Analysis of a purely conductance-based stochastic nerve fibre model as
   applied to compound models of populations of human auditory nerve fibres
   used in cochlear implant simulations
SO BIOLOGICAL CYBERNETICS
LA English
DT Article
DE Cochlear implant; Compound auditory nerve fibre model; Conductance
   based; Stochastic nerve fibre model; Temporal characteristics;
   Population nerve fibre model; Volume conduction model
ID ELECTRICALLY STIMULATED COCHLEA; SPIRAL GANGLION-CELLS; NEURAL
   DEGENERATION; COMPUTATIONAL MODEL; SPEECH-PERCEPTION; PULSE TRAINS;
   SINGLE; RESPONSES; SODIUM; EXCITATION
AB The study presents the application of a purely conductance-based stochastic nerve fibre model to human auditory nerve fibres within finite element volume conduction models of a semi-generic head and user-specific cochleae. The stochastic, threshold and temporal characteristics of the human model are compared and successfully validated against physiological feline results with the application of a mono-polar, bi-phasic, cathodic first stimulus. Stochastic characteristics validated include: (i) the log(Relative Spread) versus log(fibre diameter) distribution for the discharge probability versus stimulus intensity plots and (ii) the required exponential membrane noise versus transmembrane voltage distribution. Intra-user, and to a lesser degree inter-user, comparisons are made with respect to threshold and dynamic range at short and long pulse widths for full versus degenerate single fibres as well as for populations of degenerate fibres of a single user having distributed and aligned somas with varying and equal diameters. Temporal characteristics validated through application of different stimulus pulse rates and different stimulus intensities include: (i) discharge rate, latency and latency standard deviation versus stimulus intensity, (ii) period histograms and (iii) interspike interval histograms. Although the stochastic population model does not reduce the modelled single deterministic fibre threshold, the simulated stochastic and temporal characteristics show that it could be used in future studies to model user-specific temporally encoded information, which influences the speech perception of CI users.
C1 [Badenhorst, Werner; Hanekom, Tania; Hanekom, Johan J.] Univ Pretoria, Dept Elect Elect & Comp Engn, Lynnwood Rd, ZA-0002 Pretoria, South Africa.
RP Badenhorst, W (corresponding author), Univ Pretoria, Dept Elect Elect & Comp Engn, Lynnwood Rd, ZA-0002 Pretoria, South Africa.
EM werner.badenhorst@up.ac.za
OI Badenhorst, Werner/0000-0003-2387-1100; Hanekom,
   Johan/0000-0003-4025-5019; Hanekom, Tania/0000-0003-2455-7332
CR Agterberg MJH, 2010, HEARING RES, V269, P169, DOI 10.1016/j.heares.2010.06.015
   Arora K, 2009, INT J AUDIOL, V48, P561, DOI 10.1080/14992020902858967
   Badenhorst W, 2016, BIOL CYBERN, V110, P403, DOI 10.1007/s00422-016-0694-6
   Briaire JJ, 2006, HEARING RES, V214, P17, DOI 10.1016/j.heares.2006.01.015
   Briaire JJ, 2005, HEARING RES, V205, P143, DOI 10.1016/j.heares.2005.03.020
   Bruce IC, 1999, IEEE T BIO-MED ENG, V46, P630, DOI 10.1109/10.764939
   Bruce IC, 1999, IEEE T BIO-MED ENG, V46, P617, DOI 10.1109/10.764938
   Cartee LA, 2000, HEARING RES, V146, P143, DOI 10.1016/S0378-5955(00)00109-X
   Coco A, 2007, HEARING RES, V225, P60, DOI 10.1016/j.heares.2006.12.004
   Dangerfield CE, 2010, PROCEDIA COMPUT SCI, V1, P1581, DOI 10.1016/j.procs.2010.04.178
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Felder E, 1997, HEARING RES, V105, P183, DOI 10.1016/S0378-5955(96)00209-2
   Ferguson WD, 2003, HEARING RES, V180, P101, DOI 10.1016/S0378-5955(03)00111-4
   Firszt JB, 2004, EAR HEARING, V25, P375, DOI 10.1097/01.AUD.0000134552.22205.EE
   FRIJNS JHM, 1994, IEEE T BIO-MED ENG, V41, P556, DOI 10.1109/10.293243
   FRIJNS JHM, 1995, HEARING RES, V87, P170, DOI 10.1016/0378-5955(95)00090-Q
   Fu QJ, 2000, J ACOUST SOC AM, V107, P589, DOI 10.1121/1.428325
   Galvin JJ, 2005, JARO-J ASSOC RES OTO, V6, P269, DOI 10.1007/s10162-005-0007-6
   Goldwyn JH, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002247
   Goldwyn JH, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.041908
   Govender N, 2006, BRIEF ANAL CERTAIN N
   Haenggeli A, 1998, AUDIOLOGY, V37, P353
   Hales JP, 2004, J PHYSIOL-LONDON, V559, P953, DOI 10.1113/jphysiol.2004.068726
   Hanekom T, 2001, EAR HEARING, V22, P300, DOI 10.1097/00003446-200108000-00005
   Hanekom T, 2016, NETWORK-COMP NEURAL, V27, P67, DOI 10.3109/0954898X.2016.1171411
   Higham DJ, 2001, SIAM REV, V43, P525, DOI 10.1137/S0036144500378302
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Huang YD, 2013, PHYS LETT A, V377, P3223, DOI 10.1016/j.physleta.2013.10.008
   Imennov NS, 2009, IEEE T BIO-MED ENG, V56, P2493, DOI 10.1109/TBME.2009.2016667
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   JAVEL E, 1987, ANN OTO RHINOL LARYN, V96, P26
   Javel E, 2000, HEARING RES, V140, P45, DOI 10.1016/S0378-5955(99)00186-0
   Javel E, 1990, COCHLEAR IMPLANTS MO, P247, DOI DOI 10.1007/978-1-4612-3256-8_17
   Kalkman RK, 2016, NETWORK-COMP NEURAL, V27, P107, DOI 10.3109/0954898X.2016.1171412
   Kalkman RK, 2015, HEARING RES, V322, P89, DOI 10.1016/j.heares.2014.12.004
   Kalkman RK, 2014, HEARING RES, V315, P10, DOI 10.1016/j.heares.2014.06.003
   Kreft HA, 2004, J ACOUST SOC AM, V116, P2258, DOI 10.1121/1.1786871
   Kwon BJ, 2006, J ACOUST SOC AM, V119, P2994, DOI 10.1121/1.2184128
   Litvak L, 2001, J ACOUST SOC AM, V110, P368, DOI 10.1121/1.1375140
   LU CB, 1994, AM J OTOL, V15, P74
   Macherey O, 2007, JARO-J ASSOC RES OTO, V8, P84, DOI 10.1007/s10162-006-0066-3
   Malherbe TK, 2015, HEARING RES, V327, P126, DOI 10.1016/j.heares.2015.06.003
   Malherbe TK, 2013, MED ENG PHYS, V35, P926, DOI 10.1016/j.medengphy.2012.09.001
   Malherbe TK, 2009, DEV METHOD CREATE SU
   Middlebrooks JC, 2004, J ACOUST SOC AM, V116, P452, DOI 10.1121/1.1760795
   Miller CA, 2008, JARO-J ASSOC RES OTO, V9, P122, DOI 10.1007/s10162-007-0108-5
   NADOL JB, 1990, HEARING RES, V49, P141, DOI 10.1016/0378-5955(90)90101-T
   Nadol JB, 1997, OTOLARYNG HEAD NECK, V117, P220, DOI 10.1016/S0194-5998(97)70178-5
   NADOL JB, 1989, ANN OTO RHINOL LARYN, V98, P411, DOI 10.1177/000348948909800602
   Negm MH, 2014, IEEE T BIO-MED ENG, V61, P2749, DOI 10.1109/TBME.2014.2327055
   O'Brien GE, 2016, NETWORK-COMP NEURAL, V27, P135, DOI 10.3109/0954898X.2016.1162338
   O'Brien GE, 2016, BIOPHYSICAL POPULATI
   OTTE J, 1978, LARYNGOSCOPE, V88, P1231
   RATTAY F, 1987, J THEOR BIOL, V125, P339, DOI 10.1016/S0022-5193(87)80066-8
   Rattay F, 2001, HEARING RES, V153, P43, DOI 10.1016/S0378-5955(00)00256-2
   Rattay F, 2001, HEARING RES, V153, P64, DOI 10.1016/S0378-5955(00)00257-4
   Rattay F., 1990, ELECT NERVE STIMULAT
   Rattay F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079256
   RUBINSTEIN JT, 1995, BIOPHYS J, V68, P779, DOI 10.1016/S0006-3495(95)80252-3
   SACHS MB, 1983, J NEUROPHYSIOL, V50, P27
   SCHWARZ JR, 1987, PFLUG ARCH EUR J PHY, V409, P569, DOI 10.1007/BF00584655
   Shepherd RK, 1999, HEARING RES, V130, P171, DOI 10.1016/S0378-5955(99)00011-8
   Shepherd RK, 1997, HEARING RES, V108, P112, DOI 10.1016/S0378-5955(97)00046-4
   SIGWORTH FJ, 1980, J PHYSIOL-LONDON, V307, P97, DOI 10.1113/jphysiol.1980.sp013426
   Skinner MW, 2003, ANN OTO RHINOL LARYN, V112, P4
   Smit JE, 2010, HEARING RES, V269, P12, DOI 10.1016/j.heares.2010.08.004
   Smit JE, 2009, J NEUROSCI METH, V180, P363, DOI 10.1016/j.jneumeth.2009.03.024
   Snel-Bongers J, 2012, EAR HEARING, V33, P367, DOI 10.1097/AUD.0b013e318234efd5
   SPOENDLIN H, 1989, HEARING RES, V43, P25, DOI 10.1016/0378-5955(89)90056-7
   van Gendt MJ, 2017, HEARING RES, V351, P19, DOI 10.1016/j.heares.2017.05.007
   van Gendt MJ, 2016, HEARING RES, V341, P130, DOI 10.1016/j.heares.2016.08.011
   Vandali AE, 2000, EAR HEARING, V21, P608, DOI 10.1097/00003446-200012000-00008
   VANDENHONERT C, 1987, HEARING RES, V29, P207, DOI 10.1016/0378-5955(87)90168-7
   VERVEEN A. A., 1962, ACTA MORPHOL NEERLANDO SCAND, V5, P79
   VERVEEN AA, 1968, PR INST ELECTR ELECT, V56, P906, DOI 10.1109/PROC.1968.6443
   Xu J, 1997, HEARING RES, V105, P1, DOI 10.1016/S0378-5955(96)00193-1
NR 76
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0340-1200
EI 1432-0770
J9 BIOL CYBERN
JI Biol. Cybern.
PD DEC
PY 2017
VL 111
IS 5-6
BP 439
EP 458
DI 10.1007/s00422-017-0736-8
PG 20
WC Computer Science, Cybernetics; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA FM9XH
UT WOS:000415625500008
PM 29063191
DA 2021-02-24
ER

PT J
AU McMurray, B
   Farris-Trimble, A
   Rigler, H
AF McMurray, Bob
   Farris-Trimble, Ashley
   Rigler, Hannah
TI Waiting for lexical access: Cochlear implants or severely degraded input
   lead listeners to process speech less incrementally
SO COGNITION
LA English
DT Article
DE Speech perception; Spoken word recognition; Cochlear implants;
   Incremental processing; Vocoded speech; Lexical access
ID SPOKEN-WORD-RECOGNITION; WORKING-MEMORY SPAN; DEAF-CHILDREN;
   EYE-MOVEMENTS; TIME-COURSE; PERCEPTION PERFORMANCE; LANGUAGE IMPAIRMENT;
   NORMAL-HEARING; OLDER-ADULTS; MODEL
AB Spoken language unfolds over time. Consequently, there are brief periods of ambiguity, when incomplete input can match many possible words. Typical listeners solve this problem by immediately activating multiple candidates which compete for recognition. In two experiments using the visual world paradigm, we examined realtime lexical competition in prelingually deaf cochlear implant (CI) users, and normal hearing (NH) adults listening to severely degraded speech. In Experiment 1, adolescent CI users and NH controls matched spoken words to arrays of pictures including pictures of the target word and phonological competitors. Eye-movements to each referent were monitored as a measure of how strongly that candidate was considered over time. Relative to NH controls, CI users showed a large delay in fixating any object, less competition from onset competitors (e.g., sandwich after hearing sandal), and increased competition from rhyme competitors (e.g., candle after hearing sandal). Experiment 2 observed the same pattern with NH listeners hearing highly degraded speech. These studies suggests that in contrast to all prior studies of word recognition in typical listeners, listeners recognizing words in severely degraded conditions can exhibit a substantively different pattern of dynamics, waiting to begin lexical access until substantial information has accumulated.
C1 [McMurray, Bob; Rigler, Hannah] Univ Iowa, Dept Psychol & Brain Sci, Iowa City, IA 52242 USA.
   [McMurray, Bob] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA 52242 USA.
   [McMurray, Bob] Univ Iowa, Dept Otolaryngol, Iowa City, IA 52242 USA.
   [McMurray, Bob] Univ Iowa, DeLTA Ctr, Iowa City, IA 52242 USA.
   [Farris-Trimble, Ashley] Simon Fraser Univ, Dept Linguist, Burnaby, BC, Canada.
RP McMurray, B (corresponding author), Univ Iowa, Dept Psychol, Iowa City, IA 52242 USA.
EM Bob-mcmurray@uiowa.edu
OI McMurray, Bob/0000-0002-6532-284X; Farris-Trimble,
   Ashley/0000-0001-6627-4301
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [DC008089, DC011669, DC000242];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, R01DC008089, F32DC011669,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, F32DC011669, P50DC000242, R01DC008089,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC008089, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, R01DC008089,
   R01DC008089, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC008089, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, R01DC008089,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   R01DC008089, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   R01DC008089, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   R01DC008089, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242] Funding Source: NIH RePORTER
FX This project was supported by NIH grants DC008089 awarded to BM;
   DC011669 to AFT, and DC000242 awarded to Bruce Gantz. We thank Tyler
   Ellis for assisting with the construction of Experiment 2, Jamie Klein
   for assistance with data collection, and Camille Dunn and Bruce Gantz
   for assistance with patient coordination and helpful background
   discussions on cochlear implantation. We also thank Matt Goldrick for
   helpful comments on an earlier draft. An Open Science Framework
   repository for this project and can be seen at https://osf.io/4yz8k/.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   BIRREN JE, 1995, ANNU REV PSYCHOL, V46, P329, DOI 10.1146/annurev.ps.46.020195.001553
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brough S., 2015, J PSYCHOLINGUISTIC R, P1
   Brouwer S, 2012, LANG COGNITIVE PROC, V27, P539, DOI 10.1080/01690965.2011.555268
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cleary M, 2000, VOLTA REV, V102, P259
   Clopper CG, 2017, LANG SPEECH, V60, P85, DOI 10.1177/0023830916643737
   Coady JA, 2007, J SPEECH LANG HEAR R, V50, P41, DOI 10.1044/1092-4388(2007/004)
   Conway CM, 2011, DEVELOPMENTAL SCI, V14, P69, DOI 10.1111/j.1467-7687.2010.00960.x
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   Davidson Lisa S, 2011, Ear Hear, V32, p19S, DOI 10.1097/AUD.0b013e3181ffdb8b
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Dollaghan C, 1998, APPL PSYCHOLINGUIST, V19, P193, DOI 10.1017/S0142716400010031
   Donaldson GS, 2006, EAR HEARING, V27, P658, DOI 10.1097/01.aud.0000240543.31567.54
   DORMAN MF, 1991, Q J EXP PSYCHOL-A, V43, P585, DOI 10.1080/14640749108400988
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   Eisenberg LS, 2002, EAR HEARING, V23, P450, DOI 10.1097/00003446-200210000-00007
   Farris-Trimble A, 2014, J EXP PSYCHOL HUMAN, V40, P308, DOI 10.1037/a0034353
   Farris-Trimble A, 2013, J SPEECH LANG HEAR R, V56, P1328, DOI 10.1044/1092-4388(2012/12-0145)
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fernald A, 2001, CHILD DEV, V72, P1003, DOI 10.1111/1467-8624.00331
   Francis HW, 2002, LARYNGOSCOPE, V112, P1482, DOI 10.1097/00005537-200208000-00028
   Frauenfelder U., 2001, LANG COGNITIVE PROC, V16, P563
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu Q.-J., 2012, ANGELSIM COCHLEAR IM
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Geers AE, 2013, OTOL NEUROTOL, V34, P396, DOI 10.1097/MAO.0b013e318277a0cb
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   Grieco-Calub TM, 2009, J SPEECH LANG HEAR R, V52, P1390, DOI 10.1044/1092-4388(2009/08-0154)
   Gstoettner WK, 2000, ACTA OTO-LARYNGOL, V120, P209
   Harm MW, 1999, PSYCHOL REV, V106, P491, DOI 10.1037/0033-295X.106.3.491
   Harrison RV, 2005, DEV PSYCHOBIOL, V46, P252, DOI 10.1002/dev.20052
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Jung KH, 2012, AUDIOL NEURO-OTOL, V17, P189, DOI 10.1159/000336407
   KAIL R, 1991, PSYCHOL BULL, V109, P490, DOI 10.1037/0033-2909.109.3.490
   Kapnoula EC, 2016, J EXP PSYCHOL GEN, V145, P8, DOI 10.1037/xge0000123
   Kirk KI, 2002, ANN OTO RHINOL LARYN, V111, P69
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B., 2017, WAITING LEXICAL ACCE
   McMurray B, 2016, EAR HEARING, V37, pe37, DOI 10.1097/AUD.0000000000000207
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   McMurray B, 2012, PSYCHOL REV, V119, P831, DOI 10.1037/a0029872
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McQueen JM, 2012, J ACOUST SOC AM, V131, P509, DOI 10.1121/1.3664087
   Miller CA, 2001, J SPEECH LANG HEAR R, V44, P416, DOI 10.1044/1092-4388(2001/034)
   Miyamoto RT, 1999, ACTA OTO-LARYNGOL, V119, P219
   Nicholas JG, 2006, EAR HEARING, V27, P286, DOI 10.1097/01.aud.0000215973.76912.c6
   Niparko J. K., 2009, COCHLEAR IMPLANTS PR
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Peterson NR, 2010, RESTOR NEUROL NEUROS, V28, P237, DOI 10.3233/RNN-2010-0535
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Pisoni DB, 2000, ANN OTO RHINOL LARYN, V109, P92
   Revill KP, 2012, PSYCHOL AGING, V27, P80, DOI 10.1037/a0024113
   Rigler H, 2015, DEV PSYCHOL, V51, P1690, DOI 10.1037/dev0000044
   Sekerina IA, 2007, J EXP CHILD PSYCHOL, V98, P20, DOI 10.1016/j.jecp.2007.04.005
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Swingley D, 1999, COGNITION, V71, P73, DOI 10.1016/S0010-0277(99)00021-9
   Tomblin JB, 1999, J SPEECH LANG HEAR R, V42, P497, DOI 10.1044/jslhr.4202.497
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Uziel AS, 2007, OTOL NEUROTOL, V28, P615, DOI 10.1097/01.mao.0000281802.59444.02
   Waltzman SB, 2002, OTOLARYNG HEAD NECK, V126, P505, DOI 10.1067/mhn.2002.124472
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
   Wu YH, 2014, EAR HEARING, V35, P623, DOI 10.1097/AUD.0000000000000079
   Yee E, 2008, J COGNITIVE NEUROSCI, V20, P592, DOI 10.1162/jocn.2008.20056
   ZWITSERLOOD P, 1989, COGNITION, V32, P25, DOI 10.1016/0010-0277(89)90013-9
NR 85
TC 20
Z9 20
U1 1
U2 26
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD DEC
PY 2017
VL 169
BP 147
EP 164
DI 10.1016/j.cognition.2017.08.013
PG 18
WC Psychology, Experimental
SC Psychology
GA FK1YV
UT WOS:000413280400014
PM 28917133
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Buckler, H
   Oczak-Arsic, S
   Siddiqui, N
   Johnson, EK
AF Buckler, Helen
   Oczak-Arsic, Sara
   Siddiqui, Nazia
   Johnson, Elizabeth K.
TI Input matters: Speed of word recognition in 2-year-olds exposed to
   multiple accents
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Word recognition; Speech perception; Language acquisition; Accents;
   Multicultural; Multilingual
ID DUAL LANGUAGE EXPOSURE; FOREIGN ACCENT; CHILDRENS PERCEPTION; INFANTS;
   COMPREHENSION; VARIABILITY; REPRESENTATION; FLEXIBILITY; GAINS
AB Although studies investigating language abilities in young children exposed to more than one language have become common, there is still surprisingly little research examining language development in children exposed to more than one accent. Here, we report two looking-while-listening experiments examining the impact of routine home exposure to multiple accents on 2-year-olds' word recognition abilities. In Experiment 1, we found that monolingual English-learning 24-month-olds who routinely receive exposure to both Canadian English and a non-native variant of English are less efficient in their recognition of familiar words spoken in Canadian English than monolingual English-learning 24-month-olds who hear only Canadian English at home. In Experiment 2, we found that by 34 months of age all children recognize words equally quickly regardless of their accent exposure at home. We conclude that monolingual toddlers in some locations may form a less homogeneous population than past work has assumed, a factor that should be considered when drawing generalizations about language development across different populations. (C) 2017 The Authors. Published by Elsevier Inc.
C1 [Buckler, Helen; Oczak-Arsic, Sara; Siddiqui, Nazia; Johnson, Elizabeth K.] Univ Toronto, Mississauga, ON L5L 1C6, Canada.
RP Buckler, H (corresponding author), Univ Nottingham, Univ Pk, Nottingham NG7 2RD, England.
EM helen.buckler@nottingham.ac.uk
OI Buckler, Helen/0000-0002-9039-0406; Johnson, Elizabeth
   Kay/0000-0002-9941-9949
FU NWO (Netherlands Organisation for Scientific Research) Rubicon
   grantNetherlands Organization for Scientific Research (NWO); Social
   Sciences and Humanities Research Council (SSHRC)Social Sciences and
   Humanities Research Council of Canada (SSHRC); Natural Sciences and
   Engineering Research Council of Canada (NSERC)Natural Sciences and
   Engineering Research Council of Canada (NSERC)
FX This research was funded by an NWO (Netherlands Organisation for
   Scientific Research) Rubicon grant awarded to Helen Buckler and Social
   Sciences and Humanities Research Council (SSHRC) and Natural Sciences
   and Engineering Research Council of Canada (NSERC) grants awarded to
   Elizabeth K. Johnson.
CR Bates E, 1997, LANG COGNITIVE PROC, V12, P507
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Buckler H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00540
   Creel SC, 2012, CHILD DEV, V83, P2042, DOI 10.1111/j.1467-8624.2012.01816.x
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   CUTLER ANNE., 2010, LAB PHONOLOGY, V1, P301, DOI [10.1515/labphon.2010.016, DOI 10.1515/LABPHON.2010.016]
   Durrant S, 2015, J CHILD LANG, V42, P447, DOI 10.1017/S0305000914000063
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Fenson L., 1993, MACARTHUR COMMUNICAT
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fernald A, 2001, CHILD DEV, V72, P1003, DOI 10.1111/1467-8624.00331
   Fernald A, 2008, DEVELOPMENTAL PSYCHOLINGUISTICS: ON-LINE METHODS IN CHILDREN'S LANGUAGE PROCESSING, P97
   Floccia C, 2012, COGNITION, V124, P95, DOI 10.1016/j.cognition.2012.03.011
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Hammer CS, 2012, J SPEECH LANG HEAR R, V55, P1251, DOI 10.1044/1092-4388(2012/11-0016)
   Hanulikova A, 2012, ATTEN PERCEPT PSYCHO, V74, P613, DOI 10.3758/s13414-011-0259-7
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   Johnson E, 2010, LANG LEARN LANG TEAC, V27, P73
   Kinzler KD, 2009, SOC COGNITION, V27, P623, DOI 10.1521/soco.2009.27.4.623
   Kovacs AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   Mulak KE, 2013, CHILD DEV, V84, P2064, DOI 10.1111/cdev.12087
   MUNSON B, 2001, CONT ISSUES COMMUNIC, V28, P20
   Nathan L, 1998, J CHILD LANG, V25, P343, DOI 10.1017/S0305000998003444
   Newman RS, 2011, INFANCY, V16, P447, DOI 10.1111/j.1532-7078.2010.00062.x
   Newton C, 2016, CHILD LANG TEACH THE, V32, P111, DOI 10.1177/0265659015578464
   Paquette-Smith M., 2015, P 18 INT C PHON SCI
   Paquette-Smith M, 2016, ATTEN PERCEPT PSYCHO, V78, P2329, DOI 10.3758/s13414-016-1186-4
   Place S, 2016, BILING-LANG COGN, V19, P1023, DOI 10.1017/S1366728915000322
   Place S, 2011, CHILD DEV, V82, P1834, DOI 10.1111/j.1467-8624.2011.01660.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Schmale R, 2015, DEVELOPMENTAL SCI, V18, P664, DOI 10.1111/desc.12244
   Schmale R, 2011, J CHILD LANG, V38, P1096, DOI 10.1017/S0305000910000619
   Schmale R, 2012, DEVELOPMENTAL SCI, V15, P732, DOI 10.1111/j.1467-7687.2012.01175.x
   Schmale R, 2010, INFANCY, V15, P650, DOI 10.1111/j.1532-7078.2010.00032.x
   Schmale R, 2009, DEVELOPMENTAL SCI, V12, P583, DOI 10.1111/j.1467-7687.2009.00809.x
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Souza AL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00953
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   van der Feest SVH, 2016, LANG ACQUIS, V23, P89, DOI 10.1080/10489223.2015.1047096
   van Heugten M, 2015, LANG LEARN DEV, V11, P41, DOI 10.1080/15475441.2013.879636
   van Heugten M, 2014, J EXP PSYCHOL GEN, V143, P340, DOI 10.1037/a0032192
   Wade T, 2007, PHONETICA, V64, P122, DOI 10.1159/000107913
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
   Zangl R, 2007, LANG LEARN DEV, V3, P199, DOI 10.1080/15475440701360564
   Zangl R, 2005, J COGN DEV, V6, P179, DOI 10.1207/s15327647jcd0602_2
NR 47
TC 8
Z9 7
U1 0
U2 14
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD DEC
PY 2017
VL 164
BP 87
EP 100
DI 10.1016/j.jecp.2017.06.017
PG 14
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA FI2NW
UT WOS:000411776600007
PM 28783524
OA Other Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Liu, LQ
   Kager, R
AF Liu, Liquan
   Kager, Rene
TI Statistical learning of speech sounds is most robust during the period
   of perceptual attunement
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Infant; Language development; Distributional learning; Perceptual
   attunement; Speech perception; Lexical tone
ID PHONETIC PERCEPTION; DEVELOPMENTAL-CHANGES; TONE PERCEPTION; MANDARIN
   TONES; LEXICAL TONE; 1ST YEAR; INFANTS; LANGUAGE; DISCRIMINATION;
   REORGANIZATION
AB Although statistical learning has been shown to be a domain general mechanism, its constraints, such as its interactions with perceptual development, are less well understood and discussed. This study is among the first to investigate the distributional learning of lexical pitch in non-tone-language-learning infants, exploring its interaction with language-specific perceptual attunement during the first 2 years after birth. A total of 88 normally developing Dutch infants of 5, 11, and 14 months were tested via a distributional learning paradigm and were familiarized on a unimodal or bimodal distribution of high-level versus high-falling tones in Mandarin Chinese. After familiarization, they were tested on a tonal contrast that shared equal distributional information in either modality. At 5 months, infants in both conditions discriminated the contrast, whereas 11-month-olds showed discrimination only in the bimodal condition. By 14 months, infants failed to discriminate the contrast in either condition. Results indicate interplay between infants' long-term linguistic experience throughout development and short-term distributional learning during the experiment, and they suggest that the influence of tonal distributional learning varies along the perceptual attunement trajectory, such that opportunities for distributional learning effects appear to be constrained in the beginning and at the end of perceptual attunement. The current study contributes to previous research by demonstrating an effect of age on learning from distributional cues. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Liu, Liquan; Kager, Rene] Western Sydney Univ, Sch Social Sci & Psychol, Postbox 1797, Penrith, NSW 2751, Australia.
   [Liu, Liquan] Univ Utrecht, Utrecht Inst Linguist OTS, NL-3512 JK Utrecht, Netherlands.
RP Liu, LQ (corresponding author), Western Sydney Univ, Sch Social Sci & Psychol, Postbox 1797, Penrith, NSW 2751, Australia.
EM l.liu@westernsydney.edu.au
OI Kager, Rene/0000-0002-5811-839X; Liu, Liquan/0000-0001-8671-5098
CR Anderson JL, 2003, LANG SPEECH, V46, P155, DOI 10.1177/00238309030460020601
   Aslin R. N., 1980, CHILD PHONOLOGY, V2, P67
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Boersma P., 2009, PRAAT DOING PHONETIC
   Burnham D, 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI 10.1017/S0142716414000496
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Butler J, 2016, LANG LEARN DEV, V12, P1, DOI 10.1080/15475441.2015.1020376
   Chen A, 2016, INFANT CHILD DEV, V25, P426, DOI 10.1002/icd.1944
   Chen A, 2016, LANG COGN NEUROSCI, V31, P751, DOI 10.1080/23273798.2016.1156715
   Conboy B., 2008, 16 INT C INF STUD VA
   Conway CM, 2005, J EXP PSYCHOL LEARN, V31, P24, DOI 10.1037/0278-7393.31.1.24
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Escudero P, 2014, COGNITION, V133, P408, DOI 10.1016/j.cognition.2014.07.002
   Flom R, 2007, DEV PSYCHOL, V43, P238, DOI 10.1037/0012-1649.43.1.238
   Flom R, 2014, DEV PSYCHOBIOL, V56, P1442, DOI 10.1002/dev.21238
   Frota S., 2008, 3 C TON INT TIE3 LIS
   Frota S, 2014, INFANCY, V19, P194, DOI 10.1111/infa.12037
   Gomez R, 2005, INFANCY, V7, P183, DOI 10.1207/s15327078in0702_4
   Grossmann T, 2006, DEVELOPMENTAL SCI, V9, P309, DOI 10.1111/j.1467-7687.2006.00494.x
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Hollich G., 2000, MONOGRAPHS SOC RES C, V65, pv, DOI 10.1111/1540-5834.00090
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Krogh L, 2013, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00598, 10.3389/fpsyg.2012.00048]
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lany J, 2011, DEVELOPMENTAL SCI, V14, P1207, DOI 10.1111/j.1467-7687.2011.01073.x
   Liu L., 2013, P 37 ANN BOST U C LA, P231
   Liu L., LANGUAGE LI IN PRESS, V18
   Liu L., 2011, ICPHS, V17, P1270
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Liu LQ, 2011, PROC ANN BUCLD, P404
   Mannel C, 2009, J COGNITIVE NEUROSCI, V21, P1988, DOI 10.1162/jocn.2009.21221
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McMurray B, 2007, SCIENCE, V317, P631, DOI 10.1126/science.1144073
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Nazzi T, 2000, INFANCY, V1, P123, DOI 10.1207/S15327078IN0101_11
   Nelson NL, 2011, J EXP CHILD PSYCHOL, V110, P52, DOI 10.1016/j.jecp.2011.03.014
   Newport E. L., 1988, LANG SCI, V10, P147, DOI DOI 10.1016/0388-0001(88)90010-1
   Ong JH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133446
   Pannekamp A, 2006, NEUROREPORT, V17, P675, DOI 10.1097/00001756-200604240-00024
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Potter CE, 2017, COGNITIVE SCI, V41, P913, DOI 10.1111/cogs.12473
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   Santelmann LM, 1998, COGNITION, V69, P105, DOI 10.1016/S0010-0277(98)00060-2
   Seidl A, 2008, DEVELOPMENTAL SCI, V11, P596, DOI 10.1111/j.1467-7687.2008.00704.x
   Shukla M, 2007, COGNITIVE PSYCHOL, V54, P1, DOI 10.1016/j.cogpsych.2006.04.002
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   Singh L, 2016, J PHONETICS, V55, P109, DOI 10.1016/j.wocn.2015.12.005
   Singh L, 2009, INFANCY, V14, P654, DOI 10.1080/15250000903263973
   Sundara M., 2015, P 18 INT C PHON SCI
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Thiessen ED, 2003, DEV PSYCHOL, V39, P706, DOI 10.1037/0012-1649.39.4.706
   Thiessen ED, 2013, FRONT PSYCHOL, V3, P590, DOI [10.3389/fpsyg.2012.00590, DOI 10.3389/FPSYG.2012.00590]
   Turk-Browne NB, 2005, J EXP PSYCHOL GEN, V134, P552, DOI 10.1037/0096-3445.134.4.552
   Vanrell M. M., 2010, P SPEECH PROS 2010 C
   Veenker T. J. G, 2007, ZEP COMPUTER PROGRAM
   Wang Y, 2001, BRAIN LANG, V78, P332, DOI 10.1006/brln.2001.2474
   Wanrooij K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00077
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   Yeung HH, 2014, CHILD DEV, V85, P1036, DOI 10.1111/cdev.12185
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
NR 78
TC 3
Z9 4
U1 2
U2 20
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD DEC
PY 2017
VL 164
BP 192
EP 208
DI 10.1016/j.jecp.2017.05.013
PG 17
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA FI2NW
UT WOS:000411776600014
PM 28687119
DA 2021-02-24
ER

PT J
AU Sottile, SY
   Hackett, TA
   Cai, R
   Ling, L
   Llano, DA
   Caspary, DM
AF Sottile, Sarah Y.
   Hackett, Troy A.
   Cai, Rui
   Ling, Lynne
   Llano, Daniel A.
   Caspary, Donald M.
TI Presynaptic Neuronal Nicotinic Receptors Differentially Shape Select
   Inputs to Auditory Thalamus and Are Negatively Impacted by Aging
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE aging; attention; auditory; nicotinic; sensory processing; thalamus
ID MEDIAL GENICULATE-BODY; CENTRAL-NERVOUS-SYSTEM; ACETYLCHOLINE-RECEPTORS;
   RETICULAR NUCLEUS; MAMMALIAN BRAIN; CORTICOTHALAMIC PROJECTION;
   CORTICOFUGAL MODULATION; SUSTAINED ATTENTION; INFERIOR COLLICULUS;
   SYNAPTIC PROPERTIES
AB Acetylcholine (ACh) is a potent neuromodulator capable of modifying patterns of acoustic information flow. In auditory cortex, cholinergic systems have been shown to increase salience/gain while suppressing extraneous information. However, the mechanism by which cholinergic circuits shape signal processing in the auditory thalamus (medial geniculate body, MGB) is poorly understood. The present study, in male Fischer Brown Norway rats, seeks to determine the location and function of presynaptic neuronal nicotinic ACh receptors (nAChRs) at the major inputs to MGB and characterize how nAChRs change during aging. In vitro electrophysiological/optogenetic methods were used to examine responses of MGB neurons after activation of nAChRs during a paired-pulse paradigm. Presynaptic nAChR activation increased responses evoked by stimulation of excitatory corticothalamic and inhibitory tectothalamic terminals. Conversely, nAChRactivation appeared to have little effect on evoked responses from inhibitory thalamic reticular nucleus and excitatory tectothalamic terminals. In situ hybridization data showed nAChR subunit transcripts in GABAergic inferior colliculus neurons and glutamatergic auditory cortical neurons supporting the present slice findings. Responses to nAChR activation at excitatory corticothalamic and inhibitory tectothalamic inputs were diminished by aging. These findings suggest that cholinergic input to the MGB increases the strength of tectothalamic inhibitory projections, potentially improving the signal-to-noise ratio and signal detection while increasing corticothalamic gain, which may facilitate top-down identification of stimulus identity. These mechanisms appear to be affected negatively by aging, potentially diminishing speech perception in noisy environments. Cholinergic inputs to the MGB appear to maximize sensory processing by adjusting both top-down and bottom-up mechanisms in conditions of attention and arousal.
C1 [Sottile, Sarah Y.; Cai, Rui; Ling, Lynne; Caspary, Donald M.] Southern Illinois Univ, Sch Med, Dept Pharmacol, Springfield, IL 62702 USA.
   [Caspary, Donald M.] Southern Illinois Univ, Sch Med, Dept Surg, Div Otolaryngol, 801 N Rutledge St, Springfield, IL 62702 USA.
   [Hackett, Troy A.] Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, Nashville, TN 37232 USA.
   [Llano, Daniel A.] Univ Illinois, Neurosci Program, Urbana, IL 61801 USA.
   [Llano, Daniel A.] Univ Illinois, Dept Mol & Integrat Physiol, Urbana, IL 61801 USA.
RP Caspary, DM (corresponding author), Southern Illinois Univ, Sch Med, Dept Surg, Div Otolaryngol, 801 N Rutledge St, Springfield, IL 62702 USA.
EM dcaspary@siumed.edu
RI Llano, Daniel/X-8184-2019
OI Llano, Daniel/0000-0003-0933-1837
FU National Institute on Deafness and Other Communication
   Disorders-National Institutes of Health (NIH) [DC000151-34, DC 015388];
   Office of Naval ResearchOffice of Naval Research [N00014-15-1-2866];
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC015388, R01DC000151, R01DC013073, R01DC015388,
   R01DC013073, R01DC015388, R01DC013073, R01DC000151, R01DC000151,
   R01DC015388, R56DC000151, R01DC000151, R01DC000151, R01DC000151,
   R01DC000151, R01DC013073, R01DC000151, R01DC013073, R01DC000151,
   R21DC014765, R01DC000151, R01DC000151, R01DC000151, R01DC000151,
   R01DC000151, R01DC000151, R21DC014765, R01DC015388, R01DC000151,
   R01DC013073, R01DC000151, R01DC000151, R01DC015388, F31DC000151,
   R01DC000151, R01DC000151, R01DC000151, R01DC000151, R01DC000151,
   R01DC000151, R01DC000151, R01DC000151, R01DC000151, F31DC000151] Funding
   Source: NIH RePORTER
FX This work was supported by the National Institute on Deafness and Other
   Communication Disorders-National Institutes of Health (NIH Grants
   DC000151-34 (D.M.C.) and DC 015388 (T.A.H.)). FBN rats were provided by
   the National Institute on Aging-NIH. We thank Dr. Brandon Cox for
   critical review of this manuscript and Dr. Thomas Brozoski for
   assistance with statistical analysis of these data. Southern Illinois
   University School of Medicine Research imaging facility equipment used
   was supported by the Office of Naval Research (Grant N00014-15-1-2866).
CR Abrams DA, 2011, HEARING RES, V272, P125, DOI 10.1016/j.heares.2010.10.009
   Alain C, 2004, PSYCHOL AGING, V19, P125, DOI 10.1037/0882-7974.19.1.125
   Andolina IM, 2013, J NEUROPHYSIOL, V109, P889, DOI 10.1152/jn.00194.2012
   AUBERT I, 1992, J NEUROCHEM, V58, P529, DOI 10.1111/j.1471-4159.1992.tb09752.x
   BAJO VM, 1995, HEARING RES, V83, P161, DOI 10.1016/0378-5955(94)00199-Z
   Barroso-Chinea P, 2007, J COMP NEUROL, V501, P703, DOI 10.1002/cne.21265
   Bartlett EL, 2013, BRAIN LANG, V126, P29, DOI 10.1016/j.bandl.2013.03.003
   Bartlett EL, 2011, J NEUROPHYSIOL, V105, P2647, DOI 10.1152/jn.00238.2010
   Bartlett EL, 1999, J NEUROPHYSIOL, V81, P1999
   Bartlett EL, 2002, NEUROSCIENCE, V113, P957, DOI 10.1016/S0306-4522(02)00240-3
   Bartlett EL, 2000, NEUROSCIENCE, V100, P811, DOI 10.1016/S0306-4522(00)00340-7
   BARTUS RT, 1982, SCIENCE, V217, P408, DOI 10.1126/science.7046051
   Bertoli S, 2001, PSYCHOPHYSIOLOGY, V38, P334, DOI 10.1017/S0048577201000439
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Boucetta S, 2014, J NEUROSCI, V34, P4708, DOI 10.1523/JNEUROSCI.2617-13.2014
   Cardin JA, 2010, NAT PROTOC, V5, P247, DOI 10.1038/nprot.2009.228
   Cope DW, 2005, J NEUROSCI, V25, P11553, DOI 10.1523/JNEUROSCI.3362-05.2005
   Cotillon-Williams N, 2008, J NEUROPHYSIOL, V99, P1137, DOI 10.1152/jn.01159.2007
   Cox BC, 2008, J NEUROCHEM, V105, P1924, DOI 10.1111/j.1471-4159.2008.05282.x
   Dani JA, 2007, ANNU REV PHARMACOL, V47, P699, DOI 10.1146/annurev.pharmtox.47.120505.105214
   EDELINE JM, 1991, BEHAV NEUROSCI, V105, P618, DOI 10.1037/0735-7044.105.5.618
   Froemke RC, 2007, NATURE, V450, P425, DOI 10.1038/nature06289
   Guillery RW, 1998, TRENDS NEUROSCI, V21, P28, DOI 10.1016/S0166-2236(97)01157-0
   Guo W, 2017, NEURON, V95, P180, DOI 10.1016/j.neuron.2017.05.019
   Hackett TA, 2016, BRAIN STRUCT FUNCT, V221, P2619, DOI 10.1007/s00429-015-1062-3
   Hackett TA, 2011, HEARING RES, V274, P129, DOI 10.1016/j.heares.2010.11.001
   Harris KC, 2012, EAR HEARING, V33, P330, DOI 10.1097/AUD.0b013e31823fb585
   Harvey SC, 1996, J NEUROSCI, V16, P3798
   He JF, 2003, EXP BRAIN RES, V153, P579, DOI 10.1007/s00221-003-1680-5
   Homma NY, 2017, J NEUROSCI, V37, P6149, DOI 10.1523/JNEUROSCI.0397-17.2017
   HU B, 1989, NEUROSCIENCE, V31, P1, DOI 10.1016/0306-4522(89)90026-2
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   Ito T, 2012, FRONT NEURAL CIRCUIT, V6, DOI 10.3389/fncir.2012.00048
   Ito T, 2010, FRONT NEUROANAT, V4, DOI 10.3389/fnana.2010.00135
   Jensen AA, 2005, J MED CHEM, V48, P4705, DOI 10.1021/jm040219e
   JONES BE, 1991, PROG BRAIN RES, V88, P533
   Karadottir R, 2006, NAT PROTOC, V1, P1977, DOI 10.1038/nprot.2006.261
   Kozak R, 2005, EXP BRAIN RES, V162, P257, DOI 10.1007/s00221-004-2143-3
   LEDOUX JE, 1990, J NEUROSCI, V10, P1043
   Lee CC, 2010, P NATL ACAD SCI USA, V107, P372, DOI 10.1073/pnas.0907873107
   LENNARTZ RC, 1992, BEHAV NEUROSCI, V106, P484, DOI 10.1037/0735-7044.106.3.484
   Llano DA, 2008, J COMP NEUROL, V507, P1209, DOI 10.1002/cne.21602
   Llano DA, 2014, J NEUROPHYSIOL, V111, P197, DOI 10.1152/jn.00605.2013
   Llinas RR, 2006, J NEUROPHYSIOL, V95, P3297, DOI 10.1152/jn.00166.2006
   Llinas RR, 2002, P NATL ACAD SCI USA, V99, P449, DOI 10.1073/pnas.012604899
   LUETJE CW, 1991, J NEUROSCI, V11, P837
   Mansvelder HD, 2006, PSYCHOPHARMACOLOGY, V184, P292, DOI 10.1007/s00213-005-0070-z
   McCormick DA, 1997, ANNU REV NEUROSCI, V20, P185, DOI 10.1146/annurev.neuro.20.1.185
   Metherate R, 2012, FRONT BEHAV NEUROSCI, V6, DOI 10.3389/fnbeh.2012.00044
   Millar NS, 2009, NEUROPHARMACOLOGY, V56, P237, DOI 10.1016/j.neuropharm.2008.07.041
   MORLEY BJ, 1981, BRAIN RES REV, V3, P81, DOI 10.1016/0165-0173(81)90013-8
   Moser N, 2007, J NEUROCHEM, V102, P479, DOI 10.1111/j.1471-4159.2007.04498.x
   Nathanson JL, 2009, NEUROSCIENCE, V161, P441, DOI 10.1016/j.neuroscience.2009.03.032
   Peruzzi D, 1997, J NEUROSCI, V17, P3766
   Pinault D, 2004, BRAIN RES REV, V46, P1, DOI 10.1016/j.brainresrev.2004.04.008
   Quick MW, 2002, J NEUROBIOL, V53, P457, DOI 10.1002/neu.10109
   Richardson BD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016508
   Rouiller EM, 2004, NEUROSCI LETT, V358, P49, DOI 10.1016/j.neulet.2004.01.008
   Rouiller EM, 2000, BRAIN RES BULL, V53, P727, DOI 10.1016/S0361-9230(00)00364-6
   Sarter M, 2001, BRAIN RES REV, V35, P146, DOI 10.1016/S0165-0173(01)00044-3
   Sarter M, 2000, NEUROSCIENCE, V95, P933
   Schieber F, 2003, SOCIET IMPACT AGING, P42
   Schofield BR, 2011, HEARING RES, V279, P85, DOI 10.1016/j.heares.2010.12.019
   Smith PH, 2007, J NEUROPHYSIOL, V98, P681, DOI 10.1152/jn.00235.2007
   Smith PH, 2012, J COMP NEUROL, V520, P34, DOI 10.1002/cne.22682
   Sottile SY, 2017, J PHYSIOL-LONDON, V595, P5375, DOI 10.1113/JP274467
   STERIADE M, 1987, J NEUROPHYSIOL, V57, P260
   Suga N, 2003, NAT REV NEUROSCI, V4, P783, DOI 10.1038/nrn1222
   Sun YG, 2013, J NEUROSCI, V33, P2048, DOI 10.1523/JNEUROSCI.3177-12.2013
   Venkataraman Y, 2013, J NEUROPHYSIOL, V109, P2866, DOI 10.1152/jn.00021.2013
   WADA E, 1989, J COMP NEUROL, V284, P314, DOI 10.1002/cne.902840212
   Wang F, 2012, J MOL DIAGN, V14, P22, DOI 10.1016/j.jmoldx.2011.08.002
   Winer JA, 1996, P NATL ACAD SCI USA, V93, P3083, DOI 10.1073/pnas.93.7.3083
   Winer JA, 2005, INFERIOR COLLICULUS, P1, DOI 10.1007/0-387-27083-3_1
   Winer JA, 2001, J COMP NEUROL, V430, P27
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   Wonnacott S, 1997, TRENDS NEUROSCI, V20, P92, DOI 10.1016/S0166-2236(96)10073-4
   WOOLF NJ, 1991, PROG NEUROBIOL, V37, P475, DOI 10.1016/0301-0082(91)90006-M
   Wu Y, 2007, J NEUROSCI, V27, P10651, DOI 10.1523/JNEUROSCI.1320-07.2007
   Xiao YX, 2004, J PHARMACOL EXP THER, V310, P98, DOI 10.1124/jpet.104.066787
   Xu W, 1999, J NEUROSCI, V19, P9298
   Yu YQ, 2004, J NEUROSCI, V24, P3060, DOI 10.1523/JNEUROSCI.4897-03.2004
   Zhang F, 2010, NAT PROTOC, V5, P439, DOI 10.1038/nprot.2009.226
   Zhang YF, 2008, CEREB CORTEX, V18, P1521, DOI 10.1093/cercor/bhm188
   Zikopoulos B, 2007, REV NEUROSCIENCE, V18, P417
NR 85
TC 8
Z9 9
U1 1
U2 8
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
J9 J NEUROSCI
JI J. Neurosci.
PD NOV 22
PY 2017
VL 37
IS 47
BP 11377
EP 11389
DI 10.1523/JNEUROSCI.1795-17.2017
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA FO2HB
UT WOS:000416595200009
PM 29061702
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Cooper, A
   Bradlow, AR
AF Cooper, Angela
   Bradlow, Ann R.
TI Talker and background noise specificity in spoken word recognition
   memory
SO LABORATORY PHONOLOGY
LA English
DT Article
DE speech perception; recognition memory; noise
ID SPEECH-PERCEPTION; FUNDAMENTAL-FREQUENCY; STIMULUS VARIABILITY; VOICE;
   LEXICON; REPRESENTATIONS; IDENTIFICATION; FAMILIARITY; IMPLICIT
AB Prior research has demonstrated that listeners are sensitive to changes in the indexical (talker-specific) characteristics of speech input, suggesting that these signal-intrinsic features are integrally encoded in memory for spoken words. Given that listeners frequently must contend with concurrent environmental noise, to what extent do they also encode signal-extrinsic details? Native English listeners' explicit memory for spoken English monosyllabic and disyllabic words was assessed as a function of consistency versus variation in the talker's voice (talker condition) and background noise (noise condition) using a delayed recognition memory paradigm. The speech and noise signals were spectrally-separated, such that changes in a simultaneously presented non-speech signal (background noise) from exposure to test would not be accompanied by concomitant changes in the target speech signal. The results revealed that listeners can encode both signal-intrinsic talker and signal-extrinsic noise information into integrated cognitive representations, critically even when the two auditory streams are spectrally non-overlapping. However, the extent to which extra-linguistic episodic information is encoded alongside linguistic information appears to be modulated by syllabic characteristics, with specificity effects found only for monosyllabic items. These findings suggest that encoding and retrieval of episodic information during spoken word processing may be modulated by lexical characteristics.
C1 [Cooper, Angela] Univ Toronto, Dept Psychol, Mississauga, ON, Canada.
   [Bradlow, Ann R.] Northwestern Univ, Dept Linguist, Evanston, IL USA.
RP Cooper, A (corresponding author), Univ Toronto, Dept Psychol, Mississauga, ON, Canada.
EM angela.cooper@utoronto.ca
FU NIH-NIDCD grant [R01-DC005794]
FX This research was supported by NIH-NIDCD grant R01-DC005794 awarded to
   Ann R. Bradlow. We thank Chun Liang Chan, Emily Kahn, and Victoria
   Kuritza for their research and technical support. Portions of this work
   were presented at Architecture and Mechanisms of Language Processing
   (AMLaP 2014) in Edinburgh, UK.
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   CHURCH BA, 1994, J EXP PSYCHOL LEARN, V20, P521, DOI 10.1037/0278-7393.20.3.521
   Cooper A, 2015, ATTEN PERCEPT PSYCHO, V77, P1342, DOI 10.3758/s13414-015-0855-z
   Creel SC, 2012, LANG COGNITIVE PROC, V27, P1021, DOI 10.1080/01690965.2011.610597
   Cutler A, 2008, Q J EXP PSYCHOL, V61, P1601, DOI 10.1080/13803390802218542
   Goh WD, 2005, J EXP PSYCHOL LEARN, V31, P40, DOI 10.1037/0278-7393.31.1.40
   Goldinger S. D., 2007, 16 INT C PHON SCI, P49
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Gonzalez J, 2007, J EXP PSYCHOL HUMAN, V33, P410, DOI 10.1037/0096-1523.33.2.410
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Kaganovich N, 2006, BRAIN RES, V1114, P161, DOI 10.1016/j.brainres.2006.07.049
   Krestar ML, 2013, Q J EXP PSYCHOL, V66, P1793, DOI 10.1080/17470218.2013.766897
   Mattys SL, 2008, PERCEPT PSYCHOPHYS, V70, P1235, DOI 10.3758/PP.70.7.1235
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McLennan CT, 2012, ATTEN PERCEPT PSYCHO, V74, P824, DOI 10.3758/s13414-012-0315-y
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Newman RS, 2007, J PHONETICS, V35, P85, DOI 10.1016/j.wocn.2005.10.004
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   PISONI DB, 1985, SPEECH COMMUN, V4, P75, DOI 10.1016/0167-6393(85)90037-8
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   Pufahl A, 2014, COGNITIVE PSYCHOL, V70, P1, DOI 10.1016/j.cogpsych.2014.01.001
   SCHACTER DL, 1992, J EXP PSYCHOL LEARN, V18, P915, DOI 10.1037/0278-7393.18.5.915
   SHEFFERT SM, 1995, J MEM LANG, V34, P665, DOI 10.1006/jmla.1995.1030
   Sommers MS, 2006, J ACOUST SOC AM, V119, P2406, DOI 10.1121/1.2171836
   Strori D., 2016, SPECIFICITY EFFECTS
   Theodore R. M., 2015, ATTENTION PERCEPTION
   Tuft S. E., 2016, Q J EXPT PSYCHOL, V218
   Vaden K., 2009, IRVINE PHONOTACTIC O
NR 36
TC 3
Z9 3
U1 0
U2 4
PU UBIQUITY PRESS LTD
PI LONDON
PA 6 WINDMILL ST, LONDON, W1T 2JB, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD NOV 21
PY 2017
VL 8
IS 1
AR 29
DI 10.5334/labphon.99
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA FN5FR
UT WOS:000416032500001
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zou, Z
   Chau, BKH
   Ting, KH
   Chan, CCH
AF Zou, Zhi
   Chau, Bolton K. H.
   Ting, Kin-Hung
   Chan, Chetwyn C. H.
TI Aging Effect on Audiovisual Integrative Processing in Spatial
   Discrimination Task
SO FRONTIERS IN AGING NEUROSCIENCE
LA English
DT Article
DE aging; ERP; spatial discrimination; sensory integration; multisensory
ID AGE-RELATED-CHANGES; MULTISENSORY INTEGRATION; OLDER-ADULTS; SELECTIVE
   ATTENTION; WORKING-MEMORY; SOUND LOCALIZATION; EXECUTIVE FUNCTION;
   TEMPORAL DYNAMICS; SPEECH-PERCEPTION; VISUAL-STIMULI
AB Multisensory integration is an essential process that people employ daily, from conversing in social gatherings to navigating the nearby environment. The aim of this study was to investigate the impact of aging on modulating multisensory integrative processes using event-related potential (ERP), and the validity of the study was improved by including "noise" in the contrast conditions. Older and younger participants were involved in perceiving visual and/or auditory stimuli that contained spatial information. The participants responded by indicating the spatial direction (far vs. near and left vs. right) conveyed in the stimuli using different wrist movements. electroencephalograms (EEGs) were captured in each task trial, along with the accuracy and reaction time of the participants' motor responses. Older participants showed a greater extent of behavioral improvements in the multisensory (as opposed to unisensory) condition compared to their younger counterparts. Older participants were found to have fronto-centrally distributed super-additive P2, which was not the case for the younger participants. The P2 amplitude difference between the multisensory condition and the sum of the unisensory conditions was found to correlate significantly with performance on spatial discrimination. The results indicated that the age-related effect modulated the integrative process in the perceptual and feedback stages, particularly the evaluation of auditory stimuli. Audiovisual (AV) integration may also serve a functional role during spatial-discrimination processes to compensate for the compromised attention function caused by aging.
C1 [Zou, Zhi; Chau, Bolton K. H.; Ting, Kin-Hung; Chan, Chetwyn C. H.] Hong Kong Polytech Univ, Dept Rehabil Sci, Appl Cognit Neurosci Lab, Kowloon, Hong Kong, Peoples R China.
RP Chan, CCH (corresponding author), Hong Kong Polytech Univ, Dept Rehabil Sci, Appl Cognit Neurosci Lab, Kowloon, Hong Kong, Peoples R China.
EM chetwyn.chan@polyu.edu.hk
OI Chan, Chetwyn C. H./0000-0003-0307-6337; Chau, Bolton K
   H/0000-0002-6854-5176
CR Aiken L., 1991, MULTIPLE REGRESSION
   Alain C, 1999, PSYCHOL AGING, V14, P507, DOI 10.1037/0882-7974.14.3.507
   Amedi A, 2007, NAT NEUROSCI, V10, P687, DOI 10.1038/nn1912
   Andres P, 2006, NEUROPSYCHOLOGIA, V44, P2564, DOI 10.1016/j.neuropsychologia.2006.05.005
   Bargh J.A., 2000, HDB RES METHODS SOCI, P253, DOI DOI 10.1017/CBO9780511996481.017
   Barry RJ, 2009, INT J PSYCHOPHYSIOL, V71, P124, DOI 10.1016/j.ijpsycho.2008.09.009
   Bauer J, 2015, NEURAL NETWORKS, V65, P44, DOI 10.1016/j.neunet.2015.01.004
   Baumann O, 2007, CEREB CORTEX, V17, P1433, DOI 10.1093/cercor/bhl055
   Beierholm UR, 2009, J VISION, V9, DOI 10.1167/9.5.23
   Bell AH, 2005, J NEUROPHYSIOL, V93, P3659, DOI 10.1152/jn.01214.2004
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Callan A, 2015, CEREB CORTEX, V25, P4248, DOI 10.1093/cercor/bhu306
   Calvert GA, 2001, NEUROIMAGE, V14, P427, DOI 10.1006/nimg.2001.0812
   Cappe C, 2010, J NEUROSCI, V30, P12572, DOI 10.1523/JNEUROSCI.1099-10.2010
   Ceponiene R, 2005, PSYCHOPHYSIOLOGY, V42, P391, DOI 10.1111/j.1469-8986.2005.00305.x
   Chan CCH, 2012, HUM BRAIN MAPP, V33, P2714, DOI 10.1002/hbm.21395
   Chan SCC, 2017, J ALZHEIMERS DIS, V58, P735, DOI 10.3233/JAD-170024
   Ciaramitaro VM, 2007, J NEUROPHYSIOL, V98, P2399, DOI 10.1152/jn.00580.2007
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Corneil BD, 2002, J NEUROPHYSIOL, V88, P438, DOI 10.1152/jn.2002.88.1.438
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   Diederich A, 2008, NEUROPSYCHOLOGIA, V46, P2556, DOI 10.1016/j.neuropsychologia.2008.03.026
   Dobreva MS, 2011, J NEUROPHYSIOL, V105, P2471, DOI 10.1152/jn.00951.2010
   Freigang C, 2015, CELL TISSUE RES, V361, P371, DOI 10.1007/s00441-015-2230-8
   Freigang C, 2014, EXP BRAIN RES, V232, P1157, DOI 10.1007/s00221-014-3825-0
   Gajewski PD, 2008, BRAIN RES, V1189, P127, DOI 10.1016/j.brainres.2007.10.076
   Getzmann S, 2013, NEUROBIOL AGING, V34, P1952, DOI 10.1016/j.neurobiolaging.2013.02.014
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Gondan M, 2006, BRAIN RES, V1073, P389, DOI 10.1016/j.brainres.2005.12.050
   GUTHRIE D, 1991, PSYCHOPHYSIOLOGY, V28, P240, DOI 10.1111/j.1469-8986.1991.tb00417.x
   Hecht T, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P242, DOI 10.1109/DEVLRN.2015.7346148
   HEGERL U, 1993, BIOL PSYCHIAT, V33, P173, DOI 10.1016/0006-3223(93)90137-3
   Hillyard SA, 1998, CURR OPIN NEUROBIOL, V8, P202, DOI 10.1016/S0959-4388(98)80141-4
   Hsu JL, 2015, ALZHEIMERS RES THER, V7, DOI 10.1186/s13195-015-0156-8
   Hugenschmidt CE, 2009, NEUROREPORT, V20, P349, DOI 10.1097/WNR.0b013e328323ab07
   Jennings JM, 2007, AGING NEUROPSYCHOL C, V14, P353, DOI 10.1080/13825580600788837
   Karnath HO, 2001, NATURE, V411, P950, DOI 10.1038/35082075
   Klemen J, 2009, EUR J NEUROSCI, V29, P2426, DOI 10.1111/j.1460-9568.2009.06774.x
   Klemen J, 2010, J COGNITIVE NEUROSCI, V22, P437, DOI 10.1162/jocn.2009.21204
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   Lijffijt M, 2009, PSYCHOPHYSIOLOGY, V46, P1059, DOI 10.1111/j.1469-8986.2009.00845.x
   Lister JJ, 2011, INT J AUDIOL, V50, P211, DOI 10.3109/14992027.2010.526967
   Liu H., 2014, Q J CHIN STUD, V3, P26
   Mahoney JR, 2011, BRAIN RES, V1426, P43, DOI 10.1016/j.brainres.2011.09.017
   Marsic A, 2015, J CLIN PSYCHOL, V71, P250, DOI 10.1002/jclp.22136
   Martin JS, 2005, J REHABIL RES DEV, V42, P25, DOI 10.1682/JRRD.2004.12.0164
   Melara RD, 2002, J EXP PSYCHOL HUMAN, V28, P279, DOI 10.1037//0096-1523.28.2.279
   Mishra J, 2007, J NEUROSCI, V27, P4120, DOI 10.1523/JNEUROSCI.4912-06.2007
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Nardo D, 2014, HUM BRAIN MAPP, V35, P1597, DOI 10.1002/hbm.22276
   Noguchi Y, 2015, BRAIN TOPOGR, V28, P437, DOI 10.1007/s10548-014-0410-6
   NOVAK G, 1992, PSYCHOPHYSIOLOGY, V29, P398, DOI 10.1111/j.1469-8986.1992.tb01713.x
   Ozmeral EJ, 2016, J NEUROPHYSIOL, V116, P2720, DOI 10.1152/jn.00560.2016
   Peiffer AM, 2007, NEUROREPORT, V18, P1077, DOI 10.1097/WNR.0b013e3281e72ae7
   Poliakoff E, 2006, NEUROPSYCHOLOGIA, V44, P507, DOI 10.1016/j.neuropsychologia.2005.07.004
   Potts GF, 2004, BRAIN COGNITION, V56, P5, DOI 10.1016/j.bandc.2004.03.006
   Ritchie SJ, 2014, CURR BIOL, V24, pR681, DOI 10.1016/j.cub.2014.06.012
   Ross B, 2007, J NEUROSCI, V27, P11172, DOI 10.1523/JNEUROSCI.1813-07.2007
   Ryan L, 2012, HIPPOCAMPUS, V22, P1978, DOI 10.1002/hipo.22069
   Saito DN, 2005, CEREB CORTEX, V15, P1750, DOI 10.1093/cercor/bhi052
   Santangelo V, 2008, PSYCHON B REV, V15, P398, DOI 10.3758/PBR.15.2.398
   Santangelo V, 2008, EXP BRAIN RES, V185, P269, DOI 10.1007/s00221-007-1151-5
   Santangelo V, 2007, J EXP PSYCHOL HUMAN, V33, P1311, DOI 10.1037/0096-1523.33.6.1311
   Stanford TR, 2007, NEUROREPORT, V18, P787, DOI 10.1097/WNR.0b013e3280c1e315
   Staub B, 2014, PSYCHOL AGING, V29, P684, DOI 10.1037/a0037067
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Stekelenburg JJ, 2013, SCHIZOPHR RES, V147, P253, DOI 10.1016/j.schres.2013.04.038
   Stephen JM, 2010, NEUROSCI LETT, V484, P76, DOI 10.1016/j.neulet.2010.08.023
   Tallus J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139318
   Talsma D, 2005, J COGNITIVE NEUROSCI, V17, P1098, DOI 10.1162/0898929054475172
   Tao Q, 2015, BRAIN TOPOGR, V28, P506, DOI 10.1007/s10548-013-0339-1
   Tiitinen H, 2006, NEUROSCI LETT, V396, P17, DOI 10.1016/j.neulet.2005.11.018
   Townsend J. T., 1978, COGNITIVE THEORY, V3, P200
   Treder MS, 2010, BEHAV BRAIN FUNCT, V6, DOI 10.1186/1744-9081-6-28
   Van Wanrooij MM, 2009, EXP BRAIN RES, V198, P425, DOI 10.1007/s00221-009-1815-4
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vetter P, 2014, CURR BIOL, V24, P1256, DOI 10.1016/j.cub.2014.04.020
   Vidal J, 2008, CLIN NEUROPHYSIOL, V119, P763, DOI 10.1016/j.clinph.2007.11.178
   von Saldern S, 2013, J NEUROSCI, V33, P8841, DOI 10.1523/JNEUROSCI.3020-12.2013
   Wild-Wall N, 2012, NEURAL PLAST, V2012, DOI 10.1155/2012/529057
   Wild-Wall N, 2010, BIOL PSYCHOL, V83, P27, DOI 10.1016/j.biopsycho.2009.09.011
   Yang L, 2007, J GERONTOL B-PSYCHOL, V62, pP230, DOI 10.1093/geronb/62.4.P230
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152
NR 85
TC 5
Z9 7
U1 0
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA PO BOX 110, EPFL INNOVATION PARK, BUILDING I, LAUSANNE, 1015,
   SWITZERLAND
SN 1663-4365
J9 FRONT AGING NEUROSCI
JI Front. Aging Neurosci.
PD NOV 14
PY 2017
VL 9
AR 374
DI 10.3389/fnagi.2017.00374
PG 12
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA FM5FL
UT WOS:000415056900001
PM 29184494
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zhang, J
   Meng, YX
   Wu, CG
   Zhou, DQ
AF Zhang, Juan
   Meng, Yaxuan
   Wu, Chenggang
   Zhou, Danny Q.
TI Writing System Modulates the Association between Sensitivity to Acoustic
   Cues in Music and Reading Ability: Evidence from Chinese-English
   Bilingual Children
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE music; language; reading; writing system; Chinese
ID DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION; MORPHOLOGICAL AWARENESS;
   PHONOLOGICAL AWARENESS; AUDITORY-SENSITIVITY; LANGUAGE; SKILLS; TONE;
   MODELS
AB Music and language share many attributes and a large body of evidence shows that sensitivity to acoustic cues in music is positively related to language development and even subsequent reading acquisition. However, such association was mainly found in alphabetic languages. What remains unclear is whether sensitivity to acoustic cues in music is associated with reading in Chinese, a morphosyllabic language. The present study aimed to answer this question by measuring music (i.e., musical metric perception and pitch discrimination), language (i.e., phonological awareness, lexical tone sensitivity), and reading abilities (i.e., word recognition) among 54 third-grade Chinese-English bilingual children. After controlling for age and non-verbal intelligence, we found that both musical metric perception and pitch discrimination accounted for unique variance of Chinese phonological awareness while pitch discrimination rather than musical metric perception predicted Chinese lexical tone sensitivity. More importantly, neither musical metric perception nor pitch discrimination was associated with Chinese reading. As for English, musical metric perception and pitch discrimination were correlated with both English phonological awareness and English reading. Furthermore, sensitivity to acoustic cues in music was associated with English reading through the mediation of English phonological awareness. The current findings indicate that the association between sensitivity to acoustic cues in music and reading may be modulated by writing systems. In Chinese, the mapping between orthography and phonology is not as transparent as in alphabetic languages such as English. Thus, this opaque mapping may alter the auditory perceptual sensitivity in music to Chinese reading.
C1 [Zhang, Juan; Meng, Yaxuan; Wu, Chenggang; Zhou, Danny Q.] Univ Macau, Fac Educ, Macau, Peoples R China.
RP Meng, YX; Wu, CG (corresponding author), Univ Macau, Fac Educ, Macau, Peoples R China.
EM yb57105@umac.mo; chenggang.wu@connect.umac.mo
RI Wu, Chenggang/J-2449-2019
OI Wu, Chenggang/0000-0003-3837-3841
FU University of Macau in Macau [MYRG2017-00217-FED, MYRG2016-00193-FED,
   MYRG2015-00221-FED]
FX This study was supported by MYRG2017-00217-FED, MYRG2016-00193-FED, and
   MYRG2015-00221-FED from the University of Macau in Macau.
CR Antoniou M, 2015, APPL PSYCHOLINGUIST, V36, P1493, DOI 10.1017/S0142716414000514
   Anvari SH, 2002, J EXP CHILD PSYCHOL, V83, P111, DOI 10.1016/S0022-0965(02)00124-8
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Belsky J, 2005, DEV PSYCHOL, V41, P428, DOI 10.1037/0012-1649.41.2.428
   Cheung H, 2009, J CHILD PSYCHOL PSYC, V50, P726, DOI 10.1111/j.1469-7610.2008.02001.x
   Chung WL, 2017, READ WRIT, V30, P1407, DOI 10.1007/s11145-017-9730-8
   Cogo-Moreira H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059984
   Dege F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Dellatolas G, 2009, ARCH CLIN NEUROPSYCH, V24, P555, DOI 10.1093/arclin/acp044
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Forgeard M, 2008, MUSIC PERCEPT, V25, P383, DOI 10.1525/MP.2008.25.4.383
   Foxton JM, 2003, NAT NEUROSCI, V6, P343, DOI 10.1038/nn1035
   Gordon E., 1965, B COUNCIL RES MUSIC, V6, P12
   Gordon E., 1986, INTERMEDIATE MEASURE
   Gordon RL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01777
   Goswami U, 2013, CORTEX, V49, P1363, DOI 10.1016/j.cortex.2012.05.005
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Gromko JE, 2005, J RES MUSIC EDUC, V53, P199, DOI 10.2307/3598679
   Ho CS-H., 2000, HONG KONG TEST SPECI
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Jiang J, 2015, J AUTISM DEV DISORD, V45, P2067, DOI 10.1007/s10803-015-2370-4
   Katz L., 1992, ORTHOGRAPHY PHONOLOG, P67, DOI DOI 10.1016/S0166-4115(08)62789-2
   Kraus N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01403
   Lonigan C. J., 2007, VOCABULARY ACQUISITI, P15
   Lu CI, 2016, PSYCHOL MUSIC, V44, P369, DOI 10.1177/0305735614568881
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   McBride C., 2015, CHILDRENS LITERACY D
   McBride CA, 2016, EDUC PSYCHOL REV, V28, P523, DOI 10.1007/s10648-015-9318-2
   McBride-Chang C, 2003, J EDUC PSYCHOL, V95, P743, DOI 10.1037/0022-0663.95.4.743
   McBride-Chang C, 2008, SCI STUD READ, V12, P171, DOI 10.1080/10888430801917290
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Miller J. F., 2006, LEARNING DISABILITIE, V21, P30, DOI [10.1111/j.1540-5826.2006.00205.x, DOI 10.1111/J.1540-5826.2006.00205.X]
   Mok PKP, 2012, J ACOUST SOC AM, V132, P2711, DOI 10.1121/1.4747010
   Moreno S, 2011, MUSIC PERCEPT, V29, P165, DOI 10.1525/MP.2011.29.2.165
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Moritz C, 2013, READ WRIT, V26, P739, DOI 10.1007/s11145-012-9389-0
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 1998, J COGNITIVE NEUROSCI, V10, P717, DOI 10.1162/089892998563121
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Perfetti CA, 2013, LANG LEARN DEV, V9, P296, DOI 10.1080/15475441.2013.813828
   Proverbio AM, 2013, NEUROPSYCHOLOGIA, V51, P538, DOI 10.1016/j.neuropsychologia.2012.12.001
   Register D, 2004, J MUSIC THER, V41, P2, DOI 10.1093/jmt/41.1.2
   Seidenberg M. S., 2011, DYSLEXIA LANGUAGES O, P151
   Shu H, 2006, J EDUC PSYCHOL, V98, P122, DOI 10.1037/0022-0663.98.1.122
   Shu H, 2003, CHILD DEV, V74, P27, DOI 10.1111/1467-8624.00519
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Slevc LR, 2012, WIRES COGN SCI, V3, P483, DOI 10.1002/wcs.1186
   Song S, 2016, SCI STUD READ, V20, P99, DOI 10.1080/10888438.2015.1088543
   Strait DL, 2011, BEHAV BRAIN FUNCT, V7, DOI 10.1186/1744-9081-7-44
   Tan LH, 2005, P NATL ACAD SCI USA, V102, P8781, DOI 10.1073/pnas.0503523102
   Tang W, 2016, NEUROPSYCHOLOGIA, V91, P247, DOI 10.1016/j.neuropsychologia.2016.08.003
   Thomson JM, 2013, READ WRIT, V26, P139, DOI 10.1007/s11145-012-9359-6
   Tierney A, 2013, PROG BRAIN RES, V207, P209, DOI 10.1016/B978-0-444-63327-9.00008-4
   Tong XL, 2010, DEV PSYCHOL, V46, P1662, DOI 10.1037/a0020611
   Wang HLS, 2012, READ WRIT, V25, P509, DOI 10.1007/s11145-010-9284-5
   Wu H, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00436
   Yang J., 2008, P 13 ANN C COGN SCI
   Yang JF, 2009, J MEM LANG, V61, P238, DOI 10.1016/j.jml.2009.05.001
   Yeung PS, 2011, SCI STUD READ, V15, P285, DOI 10.1080/10888438.2010.482149
   Zhang J, 2014, DEV PSYCHOL, V50, P1001, DOI 10.1037/a0035086
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
NR 63
TC 2
Z9 2
U1 0
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD NOV 9
PY 2017
VL 8
AR 1965
DI 10.3389/fpsyg.2017.01965
PG 11
WC Psychology, Multidisciplinary
SC Psychology
GA FM1HN
UT WOS:000414725700001
PM 29170647
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hallam, S
AF Hallam, Susan
TI The impact of making music on aural perception and language skills: A
   research synthesis
SO LONDON REVIEW OF EDUCATION
LA English
DT Article
DE music; language; aural perception; interventions; education
ID HUMAN BRAIN-STEM; AUDITORY-CORTEX; CORTICAL REPRESENTATION;
   INDIVIDUAL-DIFFERENCES; BIOLOGICAL IMPACT; SPEECH-PERCEPTION;
   FOREIGN-LANGUAGE; PITCH; EXPERIENCE; CHILDREN
AB This paper provides a synthesis of research on the relationship between music and language, drawing on evidence from neuroscience, psychology, sociology and education. It sets out why it has become necessary to justify the role of music in the school curriculum and summarizes the different methodologies adopted by researchers in the field. It considers research exploring the way that music and language are processed, including differences and commonalities; addresses the relative importance of genetics versus length of time committed to, and spent, making music; discusses theories of modularity and sensitive periods; sets out the OPERA hypothesis; critically evaluates research comparing musicians with non-musicians; and presents detailed accounts of intervention studies with children and those from deprived backgrounds, taking account of the importance of the nature of the musical training. It concludes that making music has a major impact on the development of language skills.
C1 [Hallam, Susan] UCL, UCL Inst Educ, London, England.
RP Hallam, S (corresponding author), UCL, UCL Inst Educ, London, England.
EM s.hallam@ucl.ac.uk
CR Alexander J. A., 2005, P INT 2005 LISB PORT
   [Anonymous], J NEUROSCIENCE, V35, P1240
   Anvari SH, 2002, J EXP CHILD PSYCHOL, V83, P111, DOI 10.1016/S0022-0965(02)00124-8
   Baharloo S, 1998, AM J HUM GENET, V62, P224, DOI 10.1086/301704
   BARWICK J, 1989, BRIT J EDUC PSYCHOL, V59, P253, DOI 10.1111/j.2044-8279.1989.tb03097.x
   Bengtsson SL, 2005, NAT NEUROSCI, V8, P1148, DOI 10.1038/nn1516
   Besson M., 2007, RESTORATIVE NEUROLOG, V25, P399
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bever TG, 2009, J NEUROPSYCH CLIN N, V21, P94, DOI 10.1176/appi.neuropsych.21.1.94
   Bhatara A, 2011, J EXP PSYCHOL HUMAN, V37, P921, DOI 10.1037/a0021922
   Bidebnan GM, 2010, BRAIN RES, V1355, P112, DOI 10.1016/j.brainres.2010.07.100
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060676
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Bigand E, 2006, COGNITION, V100, P100, DOI 10.1016/j.cognition.2005.11.007
   Brandt A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00327
   Carpentier SM, 2016, J COGNITIVE NEUROSCI, V28, P1603, DOI 10.1162/jocn_a_00988
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Chobert J, 2011, J COGNITIVE NEUROSCI, V23, P3874, DOI 10.1162/jocn_a_00088
   Cohen MA, 2011, PSYCHON B REV, V18, P586, DOI 10.3758/s13423-011-0074-0
   Cooper A., 2010, J ACOUST SOC AM, V128, P2478, DOI DOI 10.1121/1.3508890
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   Corrigall KA, 2009, ANN NY ACAD SCI, V1169, P164, DOI 10.1111/j.1749-6632.2009.04769.x
   Dege F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Delogu F, 2010, EUR J COGN PSYCHOL, V22, P46, DOI 10.1080/09541440802708136
   Dittinger E, 2016, J COGNITIVE NEUROSCI, V28, P1584, DOI 10.1162/jocn_a_00997
   ELBERT T, 1995, SCIENCE, V270, P305, DOI 10.1126/science.270.5234.305
   Elmer S, 2014, J COGNITIVE NEUROSCI, V26, P2356, DOI 10.1162/jocn_a_00632
   Elmer S, 2012, CEREB CORTEX, V22, P650, DOI 10.1093/cercor/bhr142
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   Fiveash A, 2014, PSYCHOL MUSIC, V42, P190, DOI 10.1177/0305735612463949
   FLOHR JW, 2000, MUSIC EDUC J, V87, P28, DOI DOI 10.2307/3399645
   Forgeard M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003566
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Gaab N, 2005, ANN NY ACAD SCI, V1060, P82, DOI 10.1196/annals.1360.040
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Gordon RL, 2015, DEVELOPMENTAL SCI, V18, P635, DOI 10.1111/desc.12230
   Gromko JE, 2005, J RES MUSIC EDUC, V53, P199, DOI 10.2307/3598679
   Habibi A, 2016, DEV COGN NEUROS-NETH, V21, P1, DOI 10.1016/j.dcn.2016.04.003
   Hallam S, 2009, MUSIC EDUC RES, V11, P221, DOI 10.1080/14613800902924508
   Herdener M, 2014, CEREB CORTEX, V24, P836, DOI 10.1093/cercor/bhs367
   Ho YC, 2003, NEUROPSYCHOLOGY, V17, P439, DOI 10.1037/0894-4105.17.3.439
   Hudziak JJ, 2014, J AM ACAD CHILD PSY, V53, P1153, DOI 10.1016/j.jaac.2014.06.015
   Hurwitz I., 1975, J LEARNING DISABILIT, V8, P45
   Hutchinson S, 2003, CEREB CORTEX, V13, P943, DOI 10.1093/cercor/13.9.943
   Hutka S, 2015, NEUROPSYCHOLOGIA, V71, P52, DOI 10.1016/j.neuropsychologia.2015.03.019
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Jakobson LS, 2008, MUSIC PERCEPT, V26, P41, DOI 10.1525/MP.2008.26.1.41
   Jakobson LS, 2003, MUSIC PERCEPT, V20, P307, DOI 10.1525/mp.2003.20.3.307
   Jantzen MG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00876
   Jantzen MG, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00171
   Jentschke S, 2009, NEUROIMAGE, V47, P735, DOI 10.1016/j.neuroimage.2009.04.090
   Jones JL, 2009, J COMMUN DISORD, V42, P226, DOI 10.1016/j.jcomdis.2009.01.001
   Jung H, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01762
   Kilgour AR, 2000, MEM COGNITION, V28, P700, DOI 10.3758/BF03198404
   Koelsch S, 2005, TRENDS COGN SCI, V9, P578, DOI 10.1016/j.tics.2005.10.001
   Koelsch S, 2003, J COGNITIVE NEUROSCI, V15, P683, DOI 10.1162/jocn.2003.15.5.683
   Koelsch S, 2002, NEUROIMAGE, V17, P956, DOI 10.1016/S1053-8119(02)91154-7
   Koelsch S, 2011, FRONT PSYCHOL, V2, DOI [10.3389/fpsyg.2011.00110, 10.3389/fpsyg.2011.00308]
   Koeneke S, 2004, NEUROREPORT, V15, P1279, DOI 10.1097/01.wnr.0000127463.10147.e7
   Kotilahti K, 2010, HUM BRAIN MAPP, V31, P595, DOI 10.1002/hbm.20890
   Kraus N, 2017, NEUROSCIENTIST, V23, P287, DOI 10.1177/1073858416653593
   Kraus N, 2016, ANNU REV PSYCHOL, V67, P83, DOI 10.1146/annurev-psych-122414-033318
   Kraus N, 2015, ANN NY ACAD SCI, V1337, P163, DOI 10.1111/nyas.12631
   Kraus N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01403
   Kraus N, 2014, J NEUROSCI, V34, P11913, DOI 10.1523/JNEUROSCI.1881-14.2014
   Kraus N, 2014, SPRINGER HANDB AUDIT, V50, P299, DOI 10.1007/978-1-4614-9102-6_17
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Kuhnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Kunert R, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00330
   LaCroix AN, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01138
   Lamb S. J., 1993, ED PSYCHOL, V13, p19?27, DOI DOI 10.1080/0144341930130103
   Lee CY, 2008, J ACOUST SOC AM, V124, P3235, DOI 10.1121/1.2990713
   Lee H, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00868
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lipscomb S. D., 2008, 10 INT C MUS PERC CO
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P294, DOI 10.1162/jocn.2010.21413
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Martinez-Montes E, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00084
   Merrete DL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00606
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Milovanou R, 2008, BRAIN RES, V1194, P81, DOI 10.1016/j.brainres.2007.11.042
   Milovanov R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00321
   Mok PKP, 2012, J ACOUST SOC AM, V132, P2711, DOI 10.1121/1.4747010
   Moreno S, 2006, PSYCHOPHYSIOLOGY, V43, P287, DOI 10.1111/j.1469-8986.2006.00401.x
   Moreno S, 2015, CHILD DEV, V86, P394, DOI 10.1111/cdev.12297
   Moreno S, 2011, MUSIC PERCEPT, V29, P165, DOI 10.1525/MP.2011.29.2.165
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Munte TF, 2003, ANN NY ACAD SCI, V999, P131, DOI 10.1196/annals.1284.014
   Musacchia G, 2008, HEARING RES, V241, P34, DOI 10.1016/j.heares.2008.04.013
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Norman-Haignere S, 2015, NEURON, V88, P1281, DOI 10.1016/j.neuron.2015.11.035
   Norton A, 2005, BRAIN COGNITION, V59, P124, DOI 10.1016/j.bandc.2005.05.009
   Ott CGM, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00195
   Overy K, 2003, ANN NY ACAD SCI, V999, P497, DOI 10.1196/annals.1284.060
   Pantev A., 2003, COGNITIVE NEUROSCIEN, P382
   Pantev C, 2001, ANN NY ACAD SCI, V930, P300, DOI 10.1111/j.1749-6632.2001.tb05740.x
   Pantev C, 1998, NATURE, V392, P811, DOI 10.1038/33918
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Pascual-Leone A, 2001, ANN NY ACAD SCI, V930, P315, DOI 10.1111/j.1749-6632.2001.tb05741.x
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003
   Patel AD, 2017, PSYCHON B REV, V24, P177, DOI 10.3758/s13423-016-1088-4
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Patston LLM, 2011, MUSIC PERCEPT, V29, P173, DOI 10.1525/MP.2011.29.2.173
   Penhune VB, 2011, CORTEX, V47, P1126, DOI 10.1016/j.cortex.2011.05.010
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Perfors A, 2012, P 34 ANN C COGN SCI, P839
   Perruchet P, 2013, PSYCHON B REV, V20, P310, DOI 10.3758/s13423-012-0344-5
   Peynircioglu ZF, 2002, J RES READ, V25, P68, DOI DOI 10.1111/1467-9817.00159
   Pinheiro AP, 2015, BRAIN LANG, V140, P24, DOI 10.1016/j.bandl.2014.10.009
   Pitts S. E., 2016, INT J ED ARTS, V17, P1
   Putkinen V, 2013, EUR J NEUROSCI, V37, P654, DOI 10.1111/ejn.12049
   Putkinen V, 2014, DEVELOPMENTAL SCI, V17, P282, DOI 10.1111/desc.12109
   Rauscher F.H., 2009, OXFORD HDB MUSIC PSY, P244, DOI DOI 10.1093/OXFORDHB/0780199298457.013.0023
   Rauscher F. H., 2005, ROYAL COLL MUS LOND
   Rauscher FH, 2011, MUSIC PERCEPT, V29, P215, DOI 10.1525/MP.2011.29.2.215
   Roberts N., 2016, 06798 HOUS COMM LIB
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Sadakata M, 2011, ACTA PSYCHOL, V138, P1, DOI 10.1016/j.actpsy.2011.03.007
   Sammler D, 2007, PSYCHOPHYSIOLOGY, V44, P293, DOI 10.1111/j.1469-8986.2007.00497.x
   Schellenberg EG, 2015, ANN NY ACAD SCI, V1337, P170, DOI 10.1111/nyas.12627
   Schellenberg EG, 2004, PSYCHOL SCI, V15, P511, DOI 10.1111/j.0956-7976.2004.00711.x
   SCHLAUG G, 1995, NEUROPSYCHOLOGIA, V33, P1047, DOI 10.1016/0028-3932(95)00045-5
   SCHLAUG G, 1995, SCIENCE, V267, P699, DOI 10.1126/science.7839149
   Schlaug G, 2015, PROG BRAIN RES, V217, P37, DOI 10.1016/bs.pbr.2014.11.020
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Schon D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060
   Seither-Preisler A, 2014, J NEUROSCI, V34, P10937, DOI 10.1523/JNEUROSCI.5315-13.2014
   Shahin A, 2004, NEUROREPORT, V15, P1917, DOI 10.1097/00001756-200408260-00017
   Shahin AJ, 2008, NEUROIMAGE, V41, P113, DOI 10.1016/j.neuroimage.2008.01.067
   Shahin AJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00126
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Slater J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113383
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   Slevc LR, 2015, PSYCHON B REV, V22, P637, DOI 10.3758/s13423-014-0712-4
   Stoesz BM, 2007, MUSIC PERCEPT, V25, P153, DOI 10.1525/MP.2007.25.2.153
   Strait D, 2011, MUSIC PERCEPT, V29, P133, DOI 10.1525/MP.2011.29.2.133
   Strait DL, 2014, CEREB CORTEX, V24, P2512, DOI 10.1093/cercor/bht103
   Strait DL, 2014, HEARING RES, V308, P109, DOI 10.1016/j.heares.2013.08.004
   Strait DL, 2013, DEV COGN NEUROS-NETH, V6, P51, DOI 10.1016/j.dcn.2013.06.003
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Strait DL, 2011, BEHAV BRAIN FUNCT, V7, DOI 10.1186/1744-9081-7-44
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   Strait DL, 2009, EUR J NEUROSCI, V29, P661, DOI 10.1111/j.1460-9568.2009.06617.x
   Tallal P, 2006, TRENDS NEUROSCI, V29, P382, DOI 10.1016/j.tins.2006.06.003
   Tervaniemi M, 1997, NEUROSCI LETT, V226, P1, DOI 10.1016/S0304-3940(97)00217-6
   Thompson WF, 2003, ANN NY ACAD SCI, V999, P530, DOI 10.1196/annals.1284.067
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Tierney A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00855
   Tierney AT, 2015, P NATL ACAD SCI USA, V112, P10062, DOI 10.1073/pnas.1505114112
   Trainor LJ, 2003, ANN NY ACAD SCI, V999, P506, DOI 10.1196/annals.1284.061
   van Zuijen TL, 2005, COGNITIVE BRAIN RES, V23, P270, DOI 10.1016/j.cogbrainres.2004.10.007
   Weidema JL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00817
   White EJ, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00090
   White-Schwoch T, 2013, J NEUROSCI, V33, P17667, DOI 10.1523/JNEUROSCI.2560-13.2013
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Yang H, 2014, SCI REP-UK, V4, DOI 10.1038/srep05854
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zendel BR, 2009, J COGNITIVE NEUROSCI, V21, P1488, DOI 10.1162/jocn.2009.21140
   Zhao TC, 2016, P NATL ACAD SCI USA, V113, P5212, DOI 10.1073/pnas.1603984113
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 177
TC 0
Z9 1
U1 1
U2 7
PU UCL IOE PRESS, UCL INST EDUCATION
PI LONDON
PA 20 BEDFORD WAY, LONDON, WC1H OAL, ENGLAND
SN 1474-8460
EI 1474-8479
J9 LOND REV EDUC
JI Lond. Rev. Educ.
PD NOV
PY 2017
VL 15
IS 3
BP 388
EP 406
DI 10.18546/LRE.15.3.05
PG 19
WC Education & Educational Research
SC Education & Educational Research
GA FY3OM
UT WOS:000426729900005
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Dijkgraaf, A
   Hartsuiker, RJ
   Duyck, W
AF Dijkgraaf, Aster
   Hartsuiker, Robert J.
   Duyck, Wouter
TI Predicting upcoming information in native-language and
   non-native-language auditory word recognition
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE bilingualism; prediction; speech perception; visual world paradigm
ID LEXICAL COMPETITION; SENTENCE CONTEXT; BILINGUALS; 2ND-LANGUAGE; BRAIN;
   COMPREHENSION; PROFICIENCY; ACCENTS; NORMS
AB Monolingual listeners continuously predict upcoming information. Here, we tested whether predictive language processing occurs to the same extent when bilinguals listen to their native language vs. a non-native language. Additionally, we tested whether bilinguals use prediction to the same extent as monolinguals. Dutch-English bilinguals and English monolinguals listened to constraining and neutral sentences in Dutch (bilinguals only) and in English, and viewed target and distractor pictures on a display while their eye movements were measured. There was a bias of fixations towards the target object in the constraining condition, relative to the neutral condition, before information from the target word could affect fixations. This prediction effect occurred to the same extent in native processing by bilinguals and monolinguals, but also in non-native processing. This indicates that unbalanced, proficient bilinguals can quickly use semantic information during listening to predict upcoming referents to the same extent in both of their languages.
C1 [Dijkgraaf, Aster; Hartsuiker, Robert J.; Duyck, Wouter] Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.
RP Dijkgraaf, A (corresponding author), Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.
EM aster.dijkgraaf@ugent.be
RI Hartsuiker, Robert J./N-1668-2019
OI Duyck, Wouter/0000-0003-2114-6212
FU Concerted Research Action (GOA) from the Special Research Fund, Ghent
   University
FX This research was supported by a Concerted Research Action (GOA) from
   the Special Research Fund, Ghent University.
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Baayen H., 1995, CELEX LEXICAL DATABA
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002
   Boland JE, 2005, COGNITION, V95, P237, DOI 10.1016/j.cognition.2004.01.008
   Broersma P., 2014, PRAAT DOING PHONETIC
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Chambers CG, 2009, J EXP PSYCHOL LEARN, V35, P1029, DOI 10.1037/a0015901
   Cook Vivian, 1997, TUTORIALS BILINGUALI, P279
   De Deyne S, 2013, BEHAV RES METHODS, V45, P480, DOI 10.3758/s13428-012-0260-7
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504
   Dussias PE, 2013, STUD SECOND LANG ACQ, V35, P353, DOI 10.1017/S0272263112000915
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   FitzPatrick I., 2007, P COGNITIVE NEUROSCI, P43
   Foucart A., 2015, BILING-LANG COGN, P1
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756
   Gollan TH, 2008, J MEM LANG, V58, P787, DOI 10.1016/j.jml.2007.07.001
   Hahne A, 2001, J PSYCHOLINGUIST RES, V30, P251, DOI 10.1023/A:1010490917575
   Hopp H., 2015, INT REV APPL LINGUIS
   Hopp H, 2013, SECOND LANG RES, V29, P33, DOI 10.1177/0267658312461803
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Kaan E, 2014, LINGUIST APPROACH BI, V4, P257, DOI 10.1075/lab.4.2.05kaa
   Kamide Y, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00072.x
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643
   Koehne J, 2015, COGNITIVE SCI, V39, P849, DOI 10.1111/cogs.12178
   Kutas M., 2011, PREDICTIONS BRAIN US, P190, DOI DOI 10.1093/ACPROF:OSO/9780195395518.003.0065
   Lagrou E, 2013, PSYCHON B REV, V20, P963, DOI 10.3758/s13423-013-0405-4
   Lagrou E, 2013, BILING-LANG COGN, V16, P508, DOI 10.1017/S1366728912000508
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   MacDonald M. C, 2013, FRONTIERS PSYCHOL, V4
   MacWhinney B., 2015, BILING-LANG COGN, V19, P19
   Mandera P., J MEMORY LA IN PRESS
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001
   MATIN E, 1993, PERCEPT PSYCHOPHYS, V53, P372, DOI 10.3758/BF03206780
   McQueen JM, 2012, J ACOUST SOC AM, V131, P509, DOI 10.1121/1.3664087
   Misra M, 2012, J MEM LANG, V67, P224, DOI 10.1016/j.jml.2012.05.001
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   R Core Team, 2013, R LANG ENV STAT COMP
   Rommers J, 2015, ATTEN PERCEPT PSYCHO, V77, P720, DOI 10.3758/s13414-015-0873-x
   SASLOW MG, 1967, J OPT SOC AM, V57, P1030, DOI 10.1364/JOSA.57.001030
   Schepens J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063006
   Severens E, 2005, ACTA PSYCHOL, V119, P159, DOI 10.1016/j.actpsy.2005.01.002
   Van Berkum JJA, 2010, ITAL J LINGUIST, V22, P181
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Weber A., 2012, ENCY APPL LINGUISTIC
   Weber A, 2014, J PHONETICS, V46, P34, DOI 10.1016/j.wocn.2014.05.002
   Woumans E, 2015, J EXP PSYCHOL LEARN, V41, P1579, DOI 10.1037/xlm0000107
   Zirnstein M., 2015, INT S BIL
NR 57
TC 6
Z9 6
U1 2
U2 14
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD NOV
PY 2017
VL 20
IS 5
BP 917
EP 930
DI 10.1017/S1366728916000547
PG 14
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA FQ6LV
UT WOS:000418476900004
DA 2021-02-24
ER

PT J
AU Tao, L
   Taft, M
AF Tao, Lily
   Taft, Marcus
TI Effects of early home language environment on perception and production
   of speech
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE speech perception; accent perception; accent in speech; heritage
   language; bilingualism
ID BILINGUAL-CHILDREN; FOREIGN ACCENT; SEX-DIFFERENCES; 2ND-LANGUAGE;
   ADAPTATION; ADVANTAGE; REPRESENTATION; ACQUISITION; 1ST; PLASTICITY
AB The effects of exposure to non-English heritage languages versus exposure to foreign-accented English during early childhood on language performances later in life were investigated. Three groups of young adult participants who differed in their early home language environment were examined on a series of linguistic tasks. Results showed that people who were mostly exposed to accented English in the early home environment are more native-like in various aspects of English language performance than those who were mostly exposed to their non-English heritage language, including vocabulary, pronunciation, and processing of certain types of speech stimuli. Early and extended exposure to accented speech, however, does not appear to enhance the ability to perceive foreign accents in general, and may in fact produce a disadvantage when listening to unfamiliar accents. These findings provide some initial insight into the consequences of migrant parents choosing to speak one language over the other with their children.
C1 [Tao, Lily] East China Normal Univ, Inst Cognit Neurosci, Shanghai, Peoples R China.
   [Tao, Lily; Taft, Marcus] UNSW Australia, Sch Psychol, Sydney, NSW, Australia.
RP Taft, M (corresponding author), Univ New South Wales, Sch Psychol, Sydney, NSW 2052, Australia.
EM m.taft@unsw.edu.au
CR Abrahamsson N, 2009, LANG LEARN, V59, P249, DOI 10.1111/j.1467-9922.2009.00507.x
   Dunabeitia JA, 2014, EXP PSYCHOL, V61, P234, DOI 10.1027/1618-3169/a000243
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Bialystok E, 2008, J EXP PSYCHOL LEARN, V34, P859, DOI 10.1037/0278-7393.34.4.859
   Bialystok Ellen, 2009, Psychol Sci Public Interest, V10, P89, DOI 10.1177/1529100610387084
   Bialystok E, 2010, BILING-LANG COGN, V13, P525, DOI 10.1017/S1366728909990423
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bradlow A, 2010, SPEECH COMMUN, V52, P930, DOI 10.1016/j.specom.2010.06.003
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brown J.I., 1993, NELSON DENNY READING
   Burman DD, 2008, NEUROPSYCHOLOGIA, V46, P1349, DOI 10.1016/j.neuropsychologia.2007.12.021
   Carlson SM, 2008, DEVELOPMENTAL SCI, V11, P282, DOI 10.1111/j.1467-7687.2008.00675.x
   Carroll J., 1971, AM HERITAGE WORD FRE
   Chambers J. K., 2002, J SOCIOLING, P117, DOI [10.1111/1467-9481.00180, DOI 10.1111/1467-9481.00180]
   Chiu MM, 2006, SCI STUD READ, V10, P331, DOI 10.1207/s1532799xssr1004_1
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Costa A, 2009, COGNITION, V113, P135, DOI 10.1016/j.cognition.2009.08.001
   Creativity Tools, 2007, RANDOM SENTENCE GENE
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   DeKeyser R., 2012, ROUTLEDGE HDB 2 LANG, P442, DOI DOI 10.1006/COGP.2001.0769
   Durrant S, 2015, J CHILD LANG, V42, P447, DOI 10.1017/S0305000914000063
   Evans B. G., 2007, 16 INT C PHON SCI SA
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   Flege James, 2002, INTEGRATED VIEW LANG, P217
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   Floccia C, 2012, COGNITION, V124, P95, DOI 10.1016/j.cognition.2012.03.011
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Goodglass H., 1972, ASSESSMENT APHASIA R
   Hyltenstam K, 2000, STUD LINGUISTICA, V54, P150, DOI 10.1111/1467-9582.00056
   Khattab G, 2013, LINGUISTICS, V51, P439, DOI 10.1515/ling-2013-0017
   Khattab G, 2009, CAMB HB LANG LINGUIS, P142
   Kousaie S, 2012, BRAIN RES, V1446, P71, DOI 10.1016/j.brainres.2012.01.052
   Larsson JP, 2008, J COGNITIVE NEUROSCI, V20, P76, DOI 10.1162/jocn.2008.20004
   Marks G., 2000, MEASUREMENT SOCIOECO
   Marzecova A, 2013, BILING-LANG COGN, V16, P608, DOI 10.1017/S1366728912000569
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   McCarthy KM, 2014, CHILD DEV, V85, P1965, DOI 10.1111/cdev.12275
   Montrul S., 2008, INCOMPLETE ACQUISTIO
   Munro M. J., 1994, LANG TEST, V11, P253, DOI DOI 10.1177/026553229401100302
   Nguyen-Hoan M, 2010, BILING-LANG COGN, V13, P217, DOI 10.1017/S1366728909990551
   OYAMA S, 1976, J PSYCHOLINGUIST RES, V5, P261, DOI 10.1007/BF01067377
   Paap KR, 2015, CORTEX, V69, P265, DOI 10.1016/j.cortex.2015.04.014
   Paap KR, 2013, COGNITIVE PSYCHOL, V66, P232, DOI 10.1016/j.cogpsych.2012.12.002
   Pallier C, 2003, CEREB CORTEX, V13, P155, DOI 10.1093/cercor/13.2.155
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   Polinsky M, 2011, STUD SECOND LANG ACQ, V33, P305, DOI 10.1017/S027226311000077X
   Portocarrero JS, 2007, ARCH CLIN NEUROPSYCH, V22, P415, DOI 10.1016/j.acn.2007.01.015
   Raven J, 1998, MANUAL RAVENS PROGRE
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Sebastian-Galles N, 2002, J EXP PSYCHOL HUMAN, V28, P974, DOI 10.1037//0096-1523.28.4.974
   Sebastian-Galles N, 2009, J COGNITIVE NEUROSCI, V21, P2343, DOI 10.1162/jocn.2008.21152
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Sirin SR, 2005, REV EDUC RES, V75, P417, DOI 10.3102/00346543075003417
   Staunton R., 1994, FIRST LANG, V14, P241, DOI [10.1177/014272379401404216, DOI 10.1177/014272379401404216]
   Stevens C, 2009, DEVELOPMENTAL SCI, V12, P634, DOI 10.1111/j.1467-7687.2009.00807.x
   Tao LL, 2015, J INT NEUROPSYCH SOC, V21, P531, DOI 10.1017/S1355617715000521
   Tao L, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00123
   THOMPSON I, 1991, LANG LEARN, V41, P177, DOI 10.1111/j.1467-1770.1991.tb00683.x
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Unsworth S., 2016, LIFESPAN PERSPECTIVE, P136, DOI DOI 10.1037/14939-007
   Ventureyra VAG, 2004, J NEUROLINGUIST, V17, P79, DOI 10.1016/S0911-6044(03)00053-8
   Wallentin M, 2009, BRAIN LANG, V108, P175, DOI 10.1016/j.bandl.2008.07.001
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
NR 67
TC 2
Z9 2
U1 2
U2 17
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD NOV
PY 2017
VL 20
IS 5
BP 1030
EP 1044
DI 10.1017/S1366728916000730
PG 15
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA FQ6LV
UT WOS:000418476900012
DA 2021-02-24
ER

PT J
AU Elmer, S
   Kuhnis, J
   Rauch, P
   Valizadeh, SA
   Jancke, L
AF Elmer, Stefan
   Kuehnis, Juerg
   Rauch, Piyush
   Valizadeh, Seyed Abolfazl
   Jaencke, Lutz
TI Functional connectivity in the dorsal stream and between bilateral
   auditory-related cortical areas differentially contribute to speech
   decoding depending on spectro-temporal signal integrity and performance
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Speech learning; EEG; Functional connectivity; Spectro-temporal
   processing; Auditory cortex; Dorsal stream
ID GERBIL MERIONES-UNGUICULATUS; PLANUM-TEMPORALE; HUMAN-BRAIN;
   RECEPTIVE-FIELDS; LANGUAGE PATHWAYS; COMPLEX SOUNDS; RHESUS-MONKEY;
   MOTOR THEORY; IN-VIVO; CORTEX
AB Speech processing relies on the interdependence between auditory perception, sensorimotor integration, and verbal memory functions. Functional and structural connectivity between bilateral auditory-related cortical areas (ARCAs) facilitates spectro-temporal analyses, whereas the dynamic interplay between ARCAs and Broca's area (i.e., dorsal pathway) contributes to verbal memory functions, articulation, and sound-to-motor mapping. However, it remains unclear whether these two neural circuits are preferentially driven by spectral or temporal acoustic information, and whether their recruitment is predictive of speech perception performance and learning. Therefore, we evaluated EEG-based intracranial (eLORETA) functional connectivity (lagged coherence) in both pathways (i.e., between bilateral ARCAs and in the dorsal stream) while good- (GPs, N = 12) and poor performers (PPs, N = 13) learned to decode natural pseudowords (CLEAN) or comparable items (speech-noise chimeras) manipulated in the envelope (ENV) or in the fine-structure (FS). Learning to decode degraded speech was generally associated with increased functional connectivity in the theta, alpha, and beta frequency range in both circuits. Furthermore, GPs exhibited increased connectivity in the left dorsal stream compared to PPs, but only during the FS condition and in the theta frequency band. These results suggest that both pathways contribute to the decoding of spectro-temporal degraded speech by increasing the communication between brain regions involved in perceptual analyses and verbal memory functions. Otherwise, the left-hemispheric recruitment of the dorsal stream in GPs during the FS condition points to a contribution of this pathway to articulatory based memory processes that are dependent on the temporal integrity of the speech signal. These results enable to better comprehend the neural circuits underlying word-learning as a function of temporal and spectral signal integrity and performance.
C1 [Elmer, Stefan; Kuehnis, Juerg; Rauch, Piyush; Valizadeh, Seyed Abolfazl; Jaencke, Lutz] Univ Zurich, Inst Psychol, Auditory Res Grp Zurich, Div Neuropsychol, Zurich, Switzerland.
   [Jaencke, Lutz] Univ Zurich, Ctr Integrat Human Physiol ZIHP, Zurich, Switzerland.
   [Jaencke, Lutz] Univ Zurich, INAPIC, Zurich, Switzerland.
   [Jaencke, Lutz] Univ Zurich, Univ Res Prior Program URPP Dynam Hlth Aging, Zurich, Switzerland.
   [Jaencke, Lutz] King Abdulaziz Univ, Dept Special Educ, Jeddah, Saudi Arabia.
RP Elmer, S (corresponding author), Univ Zurich, Inst Psychol, Div Neuropsychol, Binzmuhlestr 14-25, CH-8050 Zurich, Switzerland.
EM s.elmer@psychologie.uzh.ch; juerg.kuehnis@uzh.ch;
   piyush.rauch@students.unibe.ch; valizadeh@hest.ethz.ch;
   lutz.jaencke@uzh.ch
RI Valizadeh, Seyed Abolfazl/S-5593-2017; Elmer, Stefan/F-7840-2011
OI Valizadeh, Seyed Abolfazl/0000-0003-0856-8541; Elmer,
   Stefan/0000-0003-1721-450X
FU Swiss National Science Foundation (SNSF)Swiss National Science
   Foundation (SNSF) [320030_163149]
FX This study was supported by a grant of the Swiss National Science
   Foundation (SNSF, Grant Number: 320030_163149) to Lutz Jancke. The
   authors declare no conflicts of interests.
CR Aboitiz Francisco, 2012, Front Evol Neurosci, V4, P2, DOI 10.3389/fnevo.2012.00002
   Amitay S, 2006, NAT NEUROSCI, V9, P1446, DOI 10.1038/nn1787
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Bastos AM, 2016, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00175
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bornkessel-Schlesewsky I, 2013, BRAIN LANG, V125, P60, DOI 10.1016/j.bandl.2013.01.010
   Brett M, 2002, NAT REV NEUROSCI, V3, P243, DOI 10.1038/nrn756
   Budinger E, 2006, NEUROSCIENCE, V143, P1065, DOI 10.1016/j.neuroscience.2006.08.035
   Budinger E, 2000, EUR J NEUROSCI, V12, P2452, DOI 10.1046/j.1460-9568.2000.00143.x
   Budinger E, 2000, EUR J NEUROSCI, V12, P2425, DOI 10.1046/j.1460-9568.2000.00142.x
   Buxhoeveden D, 2000, LATERALITY, V5, P315
   Buxhoeveden DR, 2001, BRAIN BEHAV EVOLUT, V57, P349, DOI 10.1159/000047253
   Catani M, 2007, P NATL ACAD SCI USA, V104, P17163, DOI 10.1073/pnas.0702116104
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   De Niear MA, 2016, EXP BRAIN RES, V234, P3269, DOI 10.1007/s00221-016-4724-3
   ELMER S, 2016, FRONT HUM NEUROSCI, V10
   Elmer S, 2016, BRAIN STRUCT FUNCT, V221, P331, DOI 10.1007/s00429-014-0910-x
   Elmer S, 2015, J NEUROSCI, V35, P366, DOI 10.1523/JNEUROSCI.3009-14.2015
   Elmer S, 2012, CEREB CORTEX, V22, P650, DOI 10.1093/cercor/bhr142
   Fedorenko E, 2012, CURR BIOL, V22, P2059, DOI 10.1016/j.cub.2012.09.011
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Fritz J, 2005, HEARING RES, V206, P159, DOI 10.1016/j.heares.2005.01.015
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Fritz JB, 2007, J NEUROPHYSIOL, V98, P2337, DOI 10.1152/jn.00552.2007
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   GALABURDA AM, 1978, ARCH NEUROL-CHICAGO, V35, P812, DOI 10.1001/archneur.1978.00500360036007
   Galuske RAW, 2000, SCIENCE, V289, P1946, DOI 10.1126/science.289.5486.1946
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Glasser MF, 2008, CEREB CORTEX, V18, P2471, DOI 10.1093/cercor/bhn011
   Griffiths TD, 2002, TRENDS NEUROSCI, V25, P348, DOI 10.1016/S0166-2236(02)02191-4
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013
   Harasty J, 2001, AUST J PSYCHOL, V53, P180
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   JANCKE L, 1993, NEUROREPORT, V5, P169
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Klarborg B, 2013, HUM BRAIN MAPP, V34, P3216, DOI 10.1002/hbm.22139
   Klein C, 2016, HUM BRAIN MAPP, V37, P536, DOI 10.1002/hbm.23045
   Kuhnis J, 2014, J COGNITIVE NEUROSCI, V26, P2750, DOI 10.1162/jocn_a_00674
   Kuhnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Kuhnis J, 2013, BRAIN TOPOGR, V26, P110, DOI 10.1007/s10548-012-0237-y
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   Lehmann D, 2006, J PHYSIOLOGY-PARIS, V99, P29, DOI 10.1016/j.jphysparis.2005.06.005
   Lehrl S., 1991, THEORIE MESSUNG GEIS
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lopez-Barroso D, 2013, P NATL ACAD SCI USA, V110, P13168, DOI 10.1073/pnas.1301696110
   MacNeilage PF, 2001, CURR OPIN NEUROBIOL, V11, P696, DOI 10.1016/S0959-4388(01)00271-9
   Makris N, 2005, CEREB CORTEX, V15, P854, DOI 10.1093/cercor/bhh186
   Mazziotta J, 2001, PHILOS T R SOC B, V356, P1293, DOI 10.1098/rstb.2001.0915
   Nolte G, 2004, CLIN NEUROPHYSIOL, V115, P2292, DOI 10.1016/j.clinph.2004.04.029
   PERRIN F, 1987, ELECTROEN CLIN NEURO, V66, P75, DOI 10.1016/0013-4694(87)90141-6
   PETRIDES M, 1984, J COMP NEUROL, V228, P105, DOI 10.1002/cne.902280110
   Rauschecker AM, 2008, HUM BRAIN MAPP, V29, P1231, DOI 10.1002/hbm.20460
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rauschecker JP, 1998, CURR OPIN NEUROBIOL, V8, P516, DOI 10.1016/S0959-4388(98)80040-8
   Rodriguez-Fornells A, 2009, PHILOS T R SOC B, V364, P3711, DOI 10.1098/rstb.2009.0130
   Scheich H, 2007, HEARING RES, V229, P213, DOI 10.1016/j.heares.2007.01.025
   Schulze K, 2012, P NATL ACAD SCI USA, V109, P7121, DOI 10.1073/pnas.1204717109
   SELDON HL, 1981, BRAIN RES, V229, P277, DOI 10.1016/0006-8993(81)90994-X
   SELDON HL, 1981, BRAIN RES, V229, P295, DOI 10.1016/0006-8993(81)90995-1
   Shapleske J, 1999, BRAIN RES REV, V29, P26, DOI 10.1016/S0165-0173(98)00047-2
   SMITH CR, 1975, J SPEECH HEAR RES, V18, P795, DOI 10.1044/jshr.1804.795
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Stam CJ, 2012, NEUROIMAGE, V62, P1415, DOI 10.1016/j.neuroimage.2012.05.050
   Steinmetz H, 1996, NEUROSCI BIOBEHAV R, V20, P587, DOI 10.1016/0149-7634(95)00071-2
   Sturm W., 1999, VERBALER LERNTEST NO
   Thatcher RW, 2012, DEV NEUROPSYCHOL, V37, P476, DOI 10.1080/87565641.2011.619241
   Vandermosten M., 2015, BRAIN STRUCT FUNCT
   Ward LM, 2003, TRENDS COGN SCI, V7, P553, DOI 10.1016/j.tics.2003.10.012
   Zaehle T, 2004, EUR J NEUROSCI, V20, P2447, DOI 10.1111/j.1460-9568.2004.03687.x
   Zaehle T, 2008, BRAIN RES, V1220, P179, DOI 10.1016/j.brainres.2007.11.013
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
NR 74
TC 3
Z9 3
U1 0
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD NOV
PY 2017
VL 106
BP 398
EP 406
DI 10.1016/j.neuropsychologia.2017.10.030
PG 9
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA FQ1HS
UT WOS:000418108200040
PM 29106999
DA 2021-02-24
ER

PT J
AU Baart, M
   Lindborg, A
   Andersen, TS
AF Baart, Martijn
   Lindborg, Alma
   Andersen, Tobias S.
TI Electrophysiological evidence for differences between fusion and
   combination illusions in audiovisual speech perception
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE audiovisual speech integration; ERPs; P2 suppression; phonetic
   audiovisual (in)congruency
ID SEEING VOICES; FACILITATION; INTEGRATION; SYLLABLES; SOUNDS
AB Incongruent audiovisual speech stimuli can lead to perceptual illusions such as fusions or combinations. Here, we investigated the underlying audiovisual integration process by measuring ERPs. We observed that visual speech-induced suppression of P2 amplitude (which is generally taken as a measure of audiovisual integration) for fusions was similar to suppression obtained with fully congruent stimuli, whereas P2 suppression for combinations was larger. We argue that these effects arise because the phonetic incongruency is solved differently for both types of stimuli.
C1 [Baart, Martijn] Tilburg Univ, Dept Cognit Neuropsychol, Warandelaan 2, NL-5000 LE Tilburg, Netherlands.
   [Baart, Martijn] BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
   [Lindborg, Alma; Andersen, Tobias S.] Tech Univ Denmark, DTU Compute, Sect Cognit Syst, Lyngby, Denmark.
RP Baart, M (corresponding author), Tilburg Univ, Dept Cognit Neuropsychol, Warandelaan 2, NL-5000 LE Tilburg, Netherlands.
EM m.baart@uvt.nl
RI Andersen, Tobias/I-5317-2013; Baart, Martijn/L-2910-2013
OI Andersen, Tobias/0000-0002-0263-1354; Baart, Martijn/0000-0002-5015-4265
FU Spanish Ministry of Economy and Competitiveness (MINECO)
   [FPDI-2013-15661]; Netherlands Organization for Scientific Research (NWO
   VENI)Netherlands Organization for Scientific Research (NWO) [275-89-027]
FX MB was supported by the Spanish Ministry of Economy and Competitiveness
   (MINECO grant FPDI-2013-15661) and the Netherlands Organization for
   Scientific Research (NWO VENI grant 275-89-027).
CR Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Besle J, 2004, COGN PROCESS, V5, P189, DOI DOI 10.1007/S10339-004-0026-Y
   Carpenter AL, 2013, NEUROSCI LETT, V544, P56, DOI 10.1016/j.neulet.2013.03.041
   Colin C, 2002, EUR J COGN PSYCHOL, V14, P475, DOI 10.1080/09541440143000203
   DIESCH E, 1995, Q J EXP PSYCHOL-A, V48, P320, DOI 10.1080/14640749508401393
   Digeser FM, 2009, EAR HEARING, V30, P704, DOI 10.1097/AUD.0b013e3181b1d42d
   Giard MH, 2010, MULTISENSORY OBJECT PERCEPTION IN THE PRIMATE BRAIN, P55, DOI 10.1007/978-1-4419-5615-6_4
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Tuomainen J, 2005, COGNITION, V96, pB13, DOI 10.1016/j.cognition.2004.10.004
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
NR 23
TC 6
Z9 6
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD NOV
PY 2017
VL 46
IS 10
BP 2578
EP 2583
DI 10.1111/ejn.13734
PG 6
WC Neurosciences
SC Neurosciences & Neurology
GA FO8VK
UT WOS:000417165900004
PM 28976045
OA Green Accepted, Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Drozdova, P
   van Hout, R
   Scharenborg, O
AF Drozdova, Polina
   van Hout, Roeland
   Scharenborg, Odette
TI L2 voice recognition: The role of speaker-, listener-, and
   stimulus-related factors
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPOKEN-WORD RECOGNITION; HUMAN AUDITORY-CORTEX; SPEECH-PERCEPTION;
   TALKER IDENTIFICATION; FAMILIAR VOICES; WORKING-MEMORY; TERM-MEMORY;
   LANGUAGE; CHILDREN; COMMUNICATION
AB Previous studies examined various factors influencing voice recognition and learning with mixed results. The present study investigates the separate and combined contribution of these various speaker-, stimulus-, and listener-related factors to voice recognition. Dutch listeners, with arguably incomplete phonological and lexical knowledge in the target language, English, learned to recognize the voice of four native English speakers, speaking in English, during four-day training. Training was successful and listeners' accuracy was shown to be influenced by the acoustic characteristics of speakers and the sound composition of the words used in the training, but not by lexical frequency of the words, nor the lexical knowledge of the listeners or their phonological aptitude. Although not conclusive, listeners with a lower working memory capacity seemed to be slower in learning voices than listeners with a higher working memory capacity. The results reveal that speaker-related, listener-related, and stimulus-related factors accumulate in voice recognition, while lexical information turns out not to play a role in successful voice learning and recognition. This implies that voice recognition operates at the prelexical processing level. (C) 2017 Acoustical Society of America.
C1 [Drozdova, Polina; van Hout, Roeland; Scharenborg, Odette] Radboud Univ Nijmegen, Ctr Language Studies, Erasmuspl 1,POB 9103, NL-6500 HD Nijmegen, Netherlands.
   [Drozdova, Polina] IMPRS Language Sci, Nijmegen, Netherlands.
   [Drozdova, Polina] Wundtlaan 1,POB 310, NL-6500 AH Nijmegen, Netherlands.
   [Scharenborg, Odette] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Kapittelweg 29,POB 9101, NL-6500 HB Nijmegen, Netherlands.
RP Drozdova, P (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, Erasmuspl 1,POB 9103, NL-6500 HD Nijmegen, Netherlands.; Drozdova, P (corresponding author), IMPRS Language Sci, Nijmegen, Netherlands.; Drozdova, P (corresponding author), Wundtlaan 1,POB 310, NL-6500 AH Nijmegen, Netherlands.
EM p.drozdova@let.ru.nl
FU Vidi-grant from the Netherlands Organization for Scientific Research
   (NWO) [276-89-003]
FX This research is supported by a Vidi-grant from the Netherlands
   Organization for Scientific Research (NWO; Grant Number 276-89-003)
   awarded to O.S.
CR Abercrombie D., 1967, ELEMENTS GEN PHONETI, P203
   Abrams DA, 2016, P NATL ACAD SCI USA, V113, P6295, DOI 10.1073/pnas.1602948113
   Alloway TP, 2004, J EXP CHILD PSYCHOL, V87, P85, DOI 10.1016/j.jecp.2003.10.002
   Amino K., 2008, J ACOUST SOC AM, V123, P3328
   Amino K, 2006, ACOUST SCI TECHNOL, V27, P233, DOI 10.1250/ast.27.233
   Amino Kanae, 2007, SPEAKER CLASSIFICATI, V4441, P83
   Andics A., 2007, P 16 INT C PHON SCI, P1829
   Andics A., 2006, NIJMEGEN CNS, V1, P47
   Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   Baddeley A., 1986, WORKING MEMORY, P304
   Baumann O, 2010, PSYCHOL RES-PSYCH FO, V74, P110, DOI 10.1007/s00426-008-0185-z
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   BRICKER PD, 1966, J ACOUST SOC AM, V40, P1441, DOI 10.1121/1.1910246
   Bull R, 2008, DEV NEUROPSYCHOL, V33, P205, DOI 10.1080/87565640801982312
   Chen A, 2004, LANG SPEECH, V47, P311, DOI 10.1177/00238309040470040101
   Collins B., 1999, PHONETICS ENGLISH DU, P363
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Eatock J. P., 1994, ACOUSTICS SPEECH SIG, V1, P1
   Gallardo LF, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1047
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   Granena, 2013, SENSITIVE PERIODS LA, P105, DOI DOI 10.1075/LLLT.35.04GRA
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jimenez S, 2012, EFFECT LANGUAGE ABIL
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Koster O, 1997, FORENSIC LINGUIST, V4, P18, DOI DOI 10.1558/IJSLL.V4I1.18
   Latinus M, 2013, CURR BIOL, V23, P1075, DOI 10.1016/j.cub.2013.04.055
   Latinus M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00175
   LAVER JDM, 1968, BRIT J DISORD COMMUN, V3, P43
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Levi S., 2009, P M AC, V6, P1
   Levi S. V., 2007, 28 IND U SPEECH RES, P369
   Levi SV, 2015, J CHILD LANG, V42, P843, DOI 10.1017/S0305000914000506
   Levi SV, 2014, PHONETICA, V71, P201, DOI 10.1159/000370160
   Levi SV, 2013, J SPEECH LANG HEAR R, V56, P913, DOI 10.1044/1092-4388(2012/12-0095)
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Meara P, 2005, LLAMA LANGUAGE APTIT, P22
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Neger TM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00628
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Nygaard LC, 2005, BLACKW HBK LINGUIST, P390, DOI 10.1002/9780470757024.ch16
   Olsthoorn NM, 2014, INT J BILINGUAL, V18, P663, DOI 10.1177/1367006912466314
   Owren MJ, 2006, J ACOUST SOC AM, V119, P1727, DOI 10.1121/1.2161431
   PAPCUN G, 1989, J ACOUST SOC AM, V85, P913, DOI 10.1121/1.397564
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Rosenthal EN, 2006, ARCH CLIN NEUROPSYCH, V21, P131, DOI 10.1016/j.acn.2005.08.004
   Sheffert SM, 2002, J EXP PSYCHOL HUMAN, V28, P1447, DOI 10.1037//0096-1523.28.6.1447
   Sidtis D, 2012, INTEGR PSYCHOL BEHAV, V46, P146, DOI 10.1007/s12124-011-9177-4
   Snijders TAB, 2012, MULTILEVEL ANAL INTR, P368
   Speciale G, 2004, APPL PSYCHOLINGUIST, V25, P293, DOI 10.1017/S0142716404001146
   Torgesen J, 1999, COMPREHENSIVE TEST P
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521
   Wechsler D., 2004, WECHSLER ADULT INTEL
   White KS, 2013, J MEM LANG, V68, P362, DOI 10.1016/j.jml.2013.01.003
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   Xie X, 2015, J ACOUST SOC AM, V137, P419, DOI 10.1121/1.4904699
   Yovel G, 2013, TRENDS COGN SCI, V17, P263, DOI 10.1016/j.tics.2013.04.004
   Zarate JM, 2015, SCI REP-UK, V5, DOI 10.1038/srep11475
NR 61
TC 2
Z9 2
U1 3
U2 7
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2017
VL 142
IS 5
BP 3058
EP 3068
DI 10.1121/1.5010169
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FO4RJ
UT WOS:000416832300042
PM 29195438
OA Green Published
DA 2021-02-24
ER

PT J
AU Zaar, J
   Schmitt, N
   Derleth, RP
   DiNino, M
   Arenberg, JG
   Dau, T
AF Zaar, Johannes
   Schmitt, Nicola
   Derleth, Ralph-Peter
   DiNino, Mishaela
   Arenberg, Julie G.
   Dau, Torsten
TI Predicting effects of hearing-instrument signal processing on consonant
   perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-INTELLIGIBILITY; COCHLEAR IMPLANT; PSYCHOACOUSTIC METHOD; CHANNEL
   INTERACTIONS; IMPAIRED LISTENERS; AUDITORY MODEL; NOISE; RECOGNITION;
   CONFUSIONS; DESIGN
AB This study investigated the influence of hearing-aid (HA) and cochlear-implant (CI) processing on consonant perception in normal-hearing (NH) listeners. Measured data were compared to predictions obtained with a speech perception model [Zaar and Dau (2017). J. Acoust. Soc. Am. 141, 1051-1064] that combines an auditory processing front end with a correlation-based template-matching back end. In terms of HA processing, effects of strong nonlinear frequency compression and impulse-noise suppression were measured in 10 NH listeners using consonant-vowel stimuli. Regarding CI processing, the consonant perception data from DiNino et al. [(2016). J. Acoust. Soc. Am. 140, 4404-4418] were considered, which were obtained with noise-vocoded vowel-consonant-vowel stimuli in 12 NH listeners. The inputs to the model were the same stimuli as were used in the corresponding experiments. The model predictions obtained for the two data sets showed a large agreement with the perceptual data both in terms of consonant recognition and confusions, demonstrating the model's sensitivity to supra-threshold effects of hearing-instrument signal processing on consonant perception. The results could be useful for the evaluation of hearing-instrument processing strategies, particularly when combined with simulations of individual hearing impairment. (C) 2017 Author(s).
C1 [Zaar, Johannes; Dau, Torsten] Tech Univ Denmark, Dept Elect Engn, Hearing Syst Grp, DK-2800 Lyngby, Denmark.
   [Schmitt, Nicola; Derleth, Ralph-Peter] Sonova AG, CH-8712 Stafa, Switzerland.
   [DiNino, Mishaela; Arenberg, Julie G.] Univ Washington, Dept Speech & Hearing Sci, 1417 NE 42nd St,Box 354875, Seattle, WA 98105 USA.
RP Zaar, J (corresponding author), Tech Univ Denmark, Dept Elect Engn, Hearing Syst Grp, DK-2800 Lyngby, Denmark.
EM jzaar@elektro.dtu.dk
RI Dau, Torsten/AAJ-3709-2020
OI Dau, Torsten/0000-0001-8110-4343
FU European CommissionEuropean CommissionEuropean Commission Joint Research
   Centre [FP7-PEOPLE-2011-290000]
FX This research was funded with support from the European Commission under
   Contract No. FP7-PEOPLE-2011-290000. The authors wish to thank Leonid
   Litvak for providing the vocoder simulation code used in experiment 2.
CR BASHFORD JA, 1992, PERCEPT PSYCHOPHYS, V51, P211, DOI 10.3758/BF03212247
   Bierer JA, 2010, TRENDS AMPLIF, V14, P84, DOI 10.1177/1084713810375249
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959
   Dau T, 1997, J ACOUST SOC AM, V102, P2892, DOI 10.1121/1.420344
   DiNino M, 2016, J ACOUST SOC AM, V140, P4404, DOI 10.1121/1.4971420
   Glista D, 2009, INT J AUDIOL, V48, P632, DOI 10.1080/14992020902971349
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354
   Jepsen ML, 2014, J ACOUST SOC AM, V135, pEL179, DOI 10.1121/1.4869256
   Jurgens T, 2014, J ACOUST SOC AM, V135, P1506, DOI 10.1121/1.4864293
   Jurgens T, 2009, J ACOUST SOC AM, V126, P2635, DOI 10.1121/1.3224721
   Kashino M, 2006, ACOUST SCI TECHNOL, V27, P318, DOI 10.1250/ast.27.318
   Kimlinger C, 2015, J AM ACAD AUDIOL, V26, P128, DOI 10.3766/jaaa.26.2.3
   Li FP, 2012, J ACOUST SOC AM, V132, P2663, DOI 10.1121/1.4747008
   Li FP, 2010, J ACOUST SOC AM, V127, P2599, DOI 10.1121/1.3295689
   Litvak LM, 2007, J ACOUST SOC AM, V122, P982, DOI 10.1121/1.2749413
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Nielsen JB, 2011, INT J AUDIOL, V50, P202, DOI 10.3109/14992027.2010.524254
   Nielsen JB, 2009, INT J AUDIOL, V48, P729, DOI 10.1080/14992020903019312
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   PAVLOVIC CV, 1987, J ACOUST SOC AM, V82, P413, DOI 10.1121/1.395442
   Phatak SA, 2008, J ACOUST SOC AM, V124, P1220, DOI 10.1121/1.2913251
   Phatak SA, 2007, J ACOUST SOC AM, V121, P2312, DOI 10.1121/1.2642397
   Phatak SA, 2009, J ACOUST SOC AM, V126, P2683, DOI 10.1121/1.3238257
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Scheidiger C, 2017, J ACOUST SOC AM, V141, P1739, DOI 10.1121/1.4976066
   Schmitt N, 2016, J AM ACAD AUDIOL, V27, P367, DOI 10.3766/jaaa.15037
   Simpson A, 2005, INT J AUDIOL, V44, P281, DOI 10.1080/14992020500060636
   Stickney GS, 2006, HEARING RES, V211, P33, DOI 10.1016/j.heares.2005.08.008
   Trevino A, 2013, J ACOUST SOC AM, V134, P607, DOI 10.1121/1.4807474
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080
   WANG MD, 1973, J ACOUST SOC AM, V54, P1248, DOI 10.1121/1.1914417
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   WHITE MW, 1984, ARCH OTOLARYNGOL, V110, P493
   Wolfe J, 2011, INT J AUDIOL, V50, P396, DOI 10.3109/14992027.2010.551788
   Zaar J, 2017, J ACOUST SOC AM, V141, P1051, DOI 10.1121/1.4976054
   Zaar J, 2015, J ACOUST SOC AM, V138, P1253, DOI 10.1121/1.4928142
NR 39
TC 0
Z9 0
U1 1
U2 5
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2017
VL 142
IS 5
BP 3216
EP 3226
DI 10.1121/1.5011737
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FO4RJ
UT WOS:000416832300056
PM 29195458
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Carbonell, KM
AF Carbonell, Kathy M.
TI Reliability of individual differences in degraded speech perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID WORKING-MEMORY; HEARING; NOISE; INTELLIGIBILITY; INTELLIGENCE; LISTENERS
AB Listeners' speech perception abilities vary extensively in challenging listening conditions. There is little evidence as to whether this variability is a result of true, stable individual differences or just variability arising from measurement error. This study examines listeners' word recognition abilities across multiple sessions and a variety of degraded speech tasks (noise-vocoded, time-compressed, and speech in babble noise). Participants transcribed isolated single syllable words presented in all three degradation types and repeated these tasks (with different words) on a separate day. Correlations of transcription accuracy demonstrate that individual differences in performance are reliable across sessions. In addition, performance on all three degradation types was correlated. These results suggest that differences in performance on degraded speech perception tasks for normal hearing listeners are robust and that there are underlying factors that promote the ability to understand degraded speech regardless of the specific manner of degradation. Uncovering these general performance factors may provide insight into the salient performance variance observed in listeners with hearing impairment. (C) 2017 Acoustical Society of America
C1 [Carbonell, Kathy M.] Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32610 USA.
RP Carbonell, KM (corresponding author), Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32610 USA.
EM kathycarbonell@phhp.ufl.edu
CR Adobe Systems Inc, 2004, AD AUD 1 5
   Boersma P., 2005, PRAAT DOING PHONETIC
   Carbonell K. M., 2013, 166 M AC SOC AM DEC
   Choe Y-k., 2009, AM SPEECH LANGUAGE H
   Fu QJ, 1998, J ACOUST SOC AM, V104, P3586, DOI 10.1121/1.423941
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Ghitza O, 2010, NEUROPHYSIOLOGICAL BASES OF AUDITORY PERCEPTION, P393, DOI 10.1007/978-1-4419-5686-6_37
   Hillenbrand J. M., 2003, JSLHR, V48, P45
   Janse E, 2003, SPEECH COMMUN, V41, P287, DOI 10.1016/S0167-6393(02)00130-9
   Lunner T, 2003, INT J AUDIOL, V42, pS49
   MIDDELWEERD MJ, 1990, AUDIOLOGY, V29, P1
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Rudner M, 2011, J AM ACAD AUDIOL, V22, P156, DOI 10.3766/jaaa.22.3.4
   Spearman C, 1904, AM J PSYCHOL, V15, P201, DOI 10.2307/1412107
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Vitela AD, 2015, J ACOUST SOC AM, V137, pEL65, DOI 10.1121/1.4903917
   WATSON BU, 1991, J SPEECH HEAR RES, V34, P621, DOI 10.1044/jshr.3403.621
   Wilson RH, 2007, J AM ACAD AUDIOL, V18, P522
   Wilson Richard H, 2003, J Am Acad Audiol, V14, P453
NR 20
TC 2
Z9 2
U1 1
U2 6
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2017
VL 142
IS 5
BP EL461
EP EL466
DI 10.1121/1.5010148
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FO4RJ
UT WOS:000416832300006
PM 29195433
OA Bronze
DA 2021-02-24
ER

PT J
AU Hauser, I
AF Hauser, Ivy
TI A revised metric for calculating acoustic dispersion applied to stop
   inventories
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PLACE; SPEECH; ARTICULATION; CONSONANTS; PERCEPTION; EVOLUTION;
   DISTANCE; SYSTEMS; CUES
AB Dispersion Theory [DT; Liljencrants and Lindblom (1972). Language 12(1), 839-862] claims that acoustically dispersed vowel inventories should be typologically common. Dispersion is often quantified using triangle area between three mean vowel formant points. This approach is problematic; it ignores distributions, which affect speech perception [Clayards, Tanenhaus, Aslin, and Jacobs (2008). Cognition 108, 804-809]. This letter proposes a revised metric for calculating dispersion which incorporates covariance. As a test case, modeled vocal tract articulatory-acoustic data of stop consonants [Schwartz, Boe, Badin, and Sawallis (2012). J. Phonetics 40, 20-36] are examined. Although the revised metric does not recover DT predictions for stop inventories, it changes results, showing that dispersion results depend on metric choice, which is often overlooked. The metric can be used in any acoustic space to include information about within-category variation when calculating dispersion. (C) 2017 Acoustical Society of America
C1 [Hauser, Ivy] Univ Massachusetts Amherst, Dept Linguist, 650 North Pleasant St, Amherst, MA 01003 USA.
RP Hauser, I (corresponding author), Univ Massachusetts Amherst, Dept Linguist, 650 North Pleasant St, Amherst, MA 01003 USA.
EM ihauser@linguist.umass.edu
OI Hauser, Ivy/0000-0002-9923-5242
FU National Science Foundation Graduate Research FellowshipNational Science
   Foundation (NSF) [1451512]
FX Many thanks to Schwartz et al. (2012) for providing the data for use in
   this project and helpful commentary. Thanks are also due to Kristine Yu,
   John Kingston, UMass Sound Workshop, Robert Staubs, Joe Pater, and
   audiences at the ASA 2017 Boston meeting. The author is supported by the
   National Science Foundation Graduate Research Fellowship under Grant No.
   1451512. Any opinions, findings, and conclusions or recommendations
   expressed in this material are those of the author and do not
   necessarily reflect the views of the National Science Foundation.
CR Andruski J. E., 1999, P 14 INT C PHON SCI, V3
   Boersma P, 2008, PHONOLOGY, V25, P217, DOI 10.1017/S0952675708001474
   Bruzzone L, 1995, IEEE T GEOSCI REMOTE, V33, P1318, DOI 10.1109/36.477187
   Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9
   Clarke C. M., 2005, U BUFFALO WORKING PA, V2, P362
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Esling J. H., 2003, P 15 INT C PHON SCI, V2
   Jacewicz E., 2007, INT C PHON SCI, V16
   Jolad S., 2012, P 5 INT C PATT REC A
   Kobayashi H., 1967, P 5 ANN ALL C CIRC S
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   LINDBLOM B., 1986, EXPT PHONOLOGY, P13
   MacNeilage PF, 1998, BEHAV BRAIN SCI, V21, P499, DOI 10.1017/S0140525X98001265
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   Mielke J., 2008, EMERGENCE DISTINCTIV
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   R Core Team, 2013, R LANG ENV STAT COMP
   Schwartz JL, 2012, J PHONETICS, V40, P20, DOI 10.1016/j.wocn.2011.10.004
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   SUSSMAN HM, 1991, J ACOUST SOC AM, V90, P1309, DOI 10.1121/1.401923
   WALLEY AC, 1983, J ACOUST SOC AM, V73, P1011, DOI 10.1121/1.389149
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
NR 22
TC 0
Z9 0
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2017
VL 142
IS 5
BP EL500
EP EL506
DI 10.1121/1.5012098
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA FO4RJ
UT WOS:000416832300013
PM 29195437
OA Bronze
DA 2021-02-24
ER

PT J
AU Flipsen, P
AF Flipsen, Peter, Jr.
TI Predicting the Future: A Case Study in Prognostication
SO AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY
LA English
DT Article
ID COCHLEAR IMPLANTS; FOLLOW-UP; CHILDREN; OUTCOMES; AGE; COMMUNICATION;
   ADVANTAGE; ABILITY; DISEASE; SCHOOL
AB Purpose: Clinicians are regularly asked to make long-term prognoses. The aim of the current report was to present one systematic approach to doing so. A case example from a malpractice case involving a child fitted with a cochlear implant was presented. Implantation occurred at age 17 months (activation 1 month later), but due to a procedural error, the implant was not functional for 19 months. The problem was ultimately rectified, but the legal case hinged largely on whether the child would be able to make up for the lost time.
   Method: A review of the literature on long-term outcomes in children with cochlear implants was conducted. Using 4 studies measuring outcomes 7-10 years later, outcomes were compared between children implanted at age 17-18 months and those implanted at age 36-37 months.
   Results: Analysis suggested no potential impact on nonverbal cognitive skills. However, analysis in the areas of speech perception, word comprehension, speech intelligibility, and reading suggested that after 7-10 years, this child would potentially continue to be approximately 1-2 years behind where she might otherwise have been.
   Conclusions: This case illustrated the possibility of deriving a long-term prognosis using a systematic examination of the existing outcomes literature. Such an approach is consistent with our mandate to engage in evidence-based practice.
C1 [Flipsen, Peter, Jr.] Pacific Univ, Forest Grove, OR 97116 USA.
RP Flipsen, P (corresponding author), Pacific Univ, Forest Grove, OR 97116 USA.
EM flipsen@pacificu.edu
CR American Speech-Language-Hearing Association (ASHA), 2005, EV BAS PRACT COMM DI
   [Anonymous], 2016, COD OF ETH
   Archbold S, 2008, INT J PEDIATR OTORHI, V72, P1471, DOI 10.1016/j.ijporl.2008.06.016
   Black Jane, 2011, Cochlear Implants Int, V12, P67, DOI 10.1179/146701010X486417
   Ching Teresa Y C, 2009, Cochlear Implants Int, V10 Suppl 1, P23, DOI 10.1179/cim.2009.10.Supplement-1.23
   Colletti L, 2011, INT J PEDIATR OTORHI, V75, P504, DOI 10.1016/j.ijporl.2011.01.005
   Croft P, 2015, BMC MED, V13, DOI 10.1186/s12916-014-0265-4
   Douglas JM, 2016, J SPEECH LANG HEAR R, V59, P511, DOI 10.1044/2015_JSLHR-L-15-0025
   Flipsen P, 2008, INT J PEDIATR OTORHI, V72, P1663, DOI 10.1016/j.ijporl.2008.08.001
   Geers A, 2008, INT J AUDIOL, V47, pS21, DOI 10.1080/14992020802339167
   Henkin Y, 2008, OTOL NEUROTOL, V29, P489, DOI 10.1097/MAO.0b013e31816fd6e5
   Khan S, 2005, AUDIOL NEURO-OTOL, V10, P117, DOI 10.1159/000083367
   Maatta S, 2016, J SPEECH LANG HEAR R, V59, P1357, DOI 10.1044/2016_JSLHR-L-15-0209
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nikolopoulos TP, 2015, INT J PEDIATR OTORHI, V79, P635, DOI 10.1016/j.ijporl.2015.02.010
   Nittrouer Susan, 2009, Trends Amplif, V13, P190, DOI 10.1177/1084713809346160
   Rektorova I, 2016, PARKINSONISM RELAT D, V29, P90, DOI 10.1016/j.parkreldis.2016.05.018
   Smith AB, 2014, CLIN LINGUIST PHONET, V28, P143, DOI 10.3109/02699206.2013.839746
   Straatman LV, 2010, J ACOUST SOC AM, V128, P1884, DOI 10.1121/1.3474236
   Svirsky M.A., 2007, AUDIOL MED, V5, P293, DOI DOI 10.1080/16513860701727847
   Uziel AS, 2007, OTOL NEUROTOL, V28, P615, DOI 10.1097/01.mao.0000281802.59444.02
   Young NM, 2011, ARCH OTOLARYNGOL, V137, P230, DOI 10.1001/archoto.2011.4
NR 22
TC 0
Z9 0
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1058-0360
EI 1558-9110
J9 AM J SPEECH-LANG PAT
JI Am. J. Speech-Lang. Pathol.
PD NOV
PY 2017
VL 26
IS 4
BP 1057
EP 1065
DI 10.1044/2017_AJSLP-17-0022
PG 9
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FN3BC
UT WOS:000415869600001
PM 28973121
DA 2021-02-24
ER

PT J
AU Preston, JL
   Leece, MC
AF Preston, Jonathan L.
   Leece, Megan C.
TI Intentsive Treatment for Persisting Rhotic Distortions: A Case Series
SO AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY
LA English
DT Article
ID MAXIMUM PERFORMANCE-TASKS; SCHOOL-AGED CHILDREN; SPEECH-PERCEPTION;
   VISUAL FEEDBACK; PHONOLOGICAL AWARENESS; PHONEMIC PERCEPTION; TREATMENT
   INTENSITY; CHILDHOOD APRAXIA; CHALLENGE POINT; VERTICAL-BAR
AB Purpose: The study explored changes in accuracy of American English rhotics as a result of an intensive 1-week therapy program for adolescents and young adults with residual speech sound errors that had not resolved with previous therapy.
   Method: Four case reports are presented of individuals aged 13, 17, 21, and 22 years with residual /(sic)/ distortions. Each participant attended a 1-week intensive program consisting of pretreatment assessments, 14 hr of therapy, and posttreatment assessment. Treatment sessions included structured motor-based practice, ultrasound visual feedback of the tongue, and auditory speech perception training. To assess generalization, untreated words and sentences with rhotics were recorded before and after therapy; these were rated by listeners who were blind to when the recordings were taken.
   Results: All participants showed measurable and statistically significant improvement in speech sound accuracy. Averaged across the 4 participants, rhotic accuracy at the word level improved from 35% to 83%. At the sentence level, rhotic accuracy increased from 11% pretreatment to 66% posttreatment in 1 week.
   Conclusion: The promise of an intensive treatment program that includes motor-based practice, biofeedback, and auditory perception training is illustrated by the case presentations in which substantial improvements in speech sound accuracy were observed.
C1 [Preston, Jonathan L.; Leece, Megan C.] Syracuse Univ, Dept Commun Sci & Disorders, Syracuse, NY 13244 USA.
   [Preston, Jonathan L.] Haskins Labs Inc, 270 Crown St, New Haven, CT 06511 USA.
RP Preston, JL (corresponding author), Syracuse Univ, Dept Commun Sci & Disorders, Syracuse, NY 13244 USA.; Preston, JL (corresponding author), Haskins Labs Inc, 270 Crown St, New Haven, CT 06511 USA.
EM jopresto@syr.edu
RI Preston, Jonathan/E-9310-2010
OI Preston, Jonathan/0000-0001-9971-6321
FU NIH GrantUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R03DC013152]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R03DC013152, R03DC013152, R03DC013152] Funding Source: NIH RePORTER
FX This study was supported by NIH Grant R03DC013152, which was granted to
   Jonathan L. Preston, PI. Thanks to Nina Chu, Kara Comins, Kerry
   McNamara, Lauren Peduto, Stephanie Urlass, Monique Uy, and Haley Weaver
   for their assistance with this project.
CR Adler-Bock M, 2007, AM J SPEECH-LANG PAT, V16, P128, DOI 10.1044/1058-0360(2007/017)
   ALBERY L, 1984, BRIT J DISORD COMMUN, V19, P115
   Allen MM, 2013, J SPEECH LANG HEAR R, V56, P865, DOI 10.1044/1092-4388(2012/11-0076)
   Audacity Team, 2008, AUD VERS 2 0 3
   Bacsfalvi P, 2010, CAN J SPEECH-LANG PA, V34, P206
   Bacsfalvi P, 2011, CLIN LINGUIST PHONET, V25, P1034, DOI 10.3109/02699206.2011.618236
   Beeson PM, 2006, NEUROPSYCHOL REV, V16, P161, DOI 10.1007/s11065-006-9013-7
   Bernhardt BM, 2008, CLIN LINGUIST PHONET, V22, P149, DOI 10.1080/02699200701801225
   BIRD J, 1992, EUR J DISORDER COMM, V27, P289
   Boersma P, 2015, PRAAT DOING PHONETIC
   Boyce SE, 2015, SEMIN SPEECH LANG, V36, P257, DOI 10.1055/s-0035-1562909
   Brandel J, 2011, LANG SPEECH HEAR SER, V42, P461, DOI 10.1044/0161-1461(2011/10-0019)
   Byun TM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00567
   Byun TM, 2016, INT J LANG COMM DIS, V51, P384, DOI 10.1111/1460-6984.12215
   Byun TM, 2014, J SPEECH LANG HEAR R, V57, P2116, DOI 10.1044/2014_JSLHR-S-14-0034
   Byun TM, 2012, AM J SPEECH-LANG PAT, V21, P207, DOI 10.1044/1058-0360(2012/11-0083)
   Cabbage KL, 2016, SPEECH COMMUN, V82, P14, DOI 10.1016/j.specom.2016.05.002
   Cleland J, 2015, CLIN LINGUIST PHONET, V29, P575, DOI 10.3109/02699206.2015.1016188
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Fabus R., 2015, INT J LINGUISTICS CO, V3, P11
   Flipsen P, 2015, SEMIN SPEECH LANG, V36, P217, DOI 10.1055/s-0035-1562905
   Gibbon F, 2015, SEMIN SPEECH LANG, V36, P271, DOI 10.1055/s-0035-1562910
   Goldman R, 2000, GOLDMAN FRISTOE TEST
   Guadagnoli MA, 2004, J MOTOR BEHAV, V36, P212, DOI 10.3200/JMBR.36.2.212-224
   Hitchcock ER, 2015, SEMIN SPEECH LANG, V36, P283, DOI 10.1055/s-0035-1562911
   Hitchcock ER, 2015, CLIN LINGUIST PHONET, V29, P59, DOI 10.3109/02699206.2014.956232
   Huang H, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-11
   Kaipa R, 2016, INT J SPEECH-LANG PA, V18, P507, DOI 10.3109/17549507.2015.1126640
   Klein HB, 2013, AM J SPEECH-LANG PAT, V22, P540, DOI 10.1044/1058-0360(2013/12-0137)
   KOEGEL LK, 1986, J SPEECH HEAR DISORD, V51, P24, DOI 10.1044/jshd.5101.24
   KOEGEL RL, 1988, J SPEECH HEAR DISORD, V53, P392, DOI 10.1044/jshd.5304.392
   Maas E, 2008, AM J SPEECH-LANG PAT, V17, P277, DOI 10.1044/1058-0360(2008/025)
   McCormack J, 2009, INT J SPEECH-LANG PA, V11, P155, DOI 10.1080/17549500802676859
   Miccio AW, 2002, AM J SPEECH-LANG PAT, V11, P221, DOI 10.1044/1058-0360(2002/023)
   Modha G, 2008, INT J LANG COMM DIS, V43, P323, DOI 10.1080/13682820701449943
   Namasivayam AK, 2015, INT J LANG COMM DIS, V50, P529, DOI 10.1111/1460-6984.12154
   NEWELL KM, 1990, J MOTOR BEHAV, V22, P536
   Nijland L, 2009, CLIN LINGUIST PHONET, V23, P222, DOI 10.1080/02699200802399947
   OHDE RN, 1988, J SPEECH HEAR RES, V31, P556, DOI 10.1044/jshr.3104.556
   Preston JL, 2007, LANG SPEECH HEAR SER, V38, P297, DOI 10.1044/0161-1461(2007/032)
   Preston JL, 2017, INT J LANG COMM DIS, V52, P80, DOI 10.1111/1460-6984.12259
   Preston Jonathan L, 2016, Front Hum Neurosci, V10, P440, DOI 10.3389/fnhum.2016.00440
   Preston JL, 2015, SEMIN SPEECH LANG, V36, P224, DOI 10.1055/s-0035-1562906
   Preston JL, 2014, J SPEECH LANG HEAR R, V57, P2102, DOI 10.1044/2014_JSLHR-S-14-0031
   Preston JL, 2012, J SPEECH LANG HEAR R, V55, P1068, DOI 10.1044/1092-4388(2011/11-0056)
   R Core Team, 2015, R LANG ENV STAT COMP
   RUSCELLO DM, 1995, J COMMUN DISORD, V28, P279, DOI 10.1016/0021-9924(95)00058-X
   RUSCELLO DM, 1979, J SPEECH HEAR DISORD, V44, P504, DOI 10.1044/jshd.4404.504
   Rvachew S, 2004, AM J SPEECH-LANG PAT, V13, P250, DOI 10.1044/1058-0360(2004/026)
   Rvachew S, 2003, AM J SPEECH-LANG PAT, V12, P463, DOI 10.1044/1058-0360(2003/092)
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   RVACHEW S, 1994, J SPEECH HEAR RES, V37, P347, DOI 10.1044/jshr.3702.347
   Rvachew S, 1999, AM J SPEECH-LANG PAT, V8, P33, DOI 10.1044/1058-0360.0801.33
   Rvachew S, 2005, CAN J SPEECH-LANG PA, V29, P146
   Schmidt AM., 2007, ADV SPEECH LANG PATH, V9, P73
   Schmidt R. A., 2011, MOTOR CONTROL LEARNI
   Shriberg L.D., 1987, LANGUAGE SPEECH HEAR, V18, DOI [10.1044/0161-1461.1802.144, DOI 10.1044/0161-1461.1802.144]
   Shriberg LD, 2009, SPEECH SOUND DISORDE
   Shuster L. I., 1992, AM J SPEECH-LANG PAT, V1, P29, DOI DOI 10.1044/1058-0360.0103.29
   Shuster LI, 1998, J SPEECH LANG HEAR R, V41, P941, DOI 10.1044/jslhr.4104.941
   Silverman FH, 1989, LANG SPEECH HEAR SER, V20, P219
   Skelton SL, 2014, AM J SPEECH-LANG PAT, V23, P599, DOI 10.1044/2014_AJSLP-12-0169
   Thoonen G, 1996, CLIN LINGUIST PHONET, V10, P311, DOI 10.3109/02699209608985178
   Thoonen G, 1999, CLIN LINGUIST PHONET, V13, P1, DOI 10.1080/026992099299211
   Unicomb R, 2015, J SPEECH LANG HEAR R, V58, P728, DOI 10.1044/2015_JSLHR-S-14-0158
   VanRiper C., 1963, SPEECH CORRECTION PR
   Wagner R. K., 2013, COMPREHENSIVE TEST P
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Wiig E.H., 2013, CLIN EVALUATION LANG
NR 70
TC 8
Z9 8
U1 1
U2 8
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1058-0360
EI 1558-9110
J9 AM J SPEECH-LANG PAT
JI Am. J. Speech-Lang. Pathol.
PD NOV
PY 2017
VL 26
IS 4
BP 1066
EP 1079
DI 10.1044/2017_AJSLP-16-0232
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA FN3BC
UT WOS:000415869600002
PM 29114774
OA Green Published
DA 2021-02-24
ER

PT J
AU Muller, B
   Schaadt, G
   Boltze, J
   Emmrich, F
   Skeide, MA
   Neef, NE
   Kraft, I
   Brauer, J
   Friederici, AD
   Kirsten, H
   Wilcke, A
AF Mueller, Bent
   Schaadt, Gesa
   Boltze, Johannes
   Emmrich, Frank
   Skeide, Michael A.
   Neef, Nicole E.
   Kraft, Indra
   Brauer, Jens
   Friederici, Angela D.
   Kirsten, Holger
   Wilcke, Arndt
CA LEGASCREEN Consortium
TI ATP2C2 and DYX1C1 are putative modulators of dyslexia-related MMR
SO BRAIN AND BEHAVIOR
LA English
DT Article
DE auditory discrimination; child; dyslexia; electroencephalography; eQTL;
   genetic predisposition to disease; German language; intermediate
   phenotype; mismatch negativity; single-nucleotide polymorphism
ID MISMATCH NEGATIVITY MMN; PARIETAL WHITE-MATTER; GENE-EXPRESSION;
   DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION; CANDIDATE GENE; TRANS-EQTLS;
   HUMAN BRAIN; ASSOCIATION; CHILDREN
AB BackgroundDyslexia is a specific learning disorder affecting reading and spelling abilities. Its prevalence is 5% in German-speaking individuals. Although the etiology of dyslexia largely remains to be determined, comprehensive evidence supports deficient phonological processing as a major contributing factor. An important prerequisite for phonological processing is auditory discrimination and, thus, essential for acquiring reading and spelling skills. The event-related potential Mismatch Response (MMR) is an indicator for auditory discrimination capabilities with dyslexics showing an altered late component of MMR in response to auditory input.
   MethodsIn this study, we comprehensively analyzed associations of dyslexia-specific late MMRs with genetic variants previously reported to be associated with dyslexia-related phenotypes in multiple studies comprising 25 independent single-nucleotide polymorphisms (SNPs) within 10 genes.
   ResultsFirst, we demonstrated validity of these SNPs for dyslexia in our sample by showing that additional inclusion of a polygenic risk score improved prediction of impaired writing compared with a model that used MMR alone. Secondly, a multifactorial regression analysis was conducted to uncover the subset of the 25 SNPs that is associated with the dyslexia-specific late component of MMR. In total, four independent SNPs within DYX1C1 and ATP2C2 were found to be associated with MMR stronger than expected from multiple testing. To explore potential pathomechanisms, we annotated these variants with functional data including tissue-specific expression analysis and eQTLs.
   ConclusionOur findings corroborate the late component of MMR as a potential endophenotype for dyslexia and support tripartite relationships between dyslexia-related SNPs, the late component of MMR and dyslexia.
C1 [Mueller, Bent; Boltze, Johannes; Emmrich, Frank; Kirsten, Holger; Wilcke, Arndt] Fraunhofer Inst Cell Therapy & Immunol, Leipzig, Germany.
   [Schaadt, Gesa; Skeide, Michael A.; Neef, Nicole E.; Kraft, Indra; Brauer, Jens; Friederici, Angela D.] Max Planck Inst Human Cognit & Brain Sci, Dept Neuropsychol, Leipzig, Germany.
   [Schaadt, Gesa] Humboldt Univ, Dept Psychol, Berlin, Germany.
   [Boltze, Johannes] Fraunhofer Res Inst Marine Biotechnol, Dept Med Cell Technol, Lubeck, Germany.
   [Boltze, Johannes] Univ Lubeck, Inst Med & Marine Biotechnol, Lubeck, Germany.
   [Kirsten, Holger] Univ Leipzig, Inst Med Informat Stat & Epidemiol, Leipzig, Germany.
   [Kirsten, Holger] Univ Leipzig, LIFE Leipzig Res Ctr Civilizat Dis, Leipzig, Germany.
RP Muller, B (corresponding author), Fraunhofer Inst Cell Therapy & Immunol, Leipzig, Germany.
RI Neef, Nicole E./F-4103-2018; Kirsten, Holger/AAP-7250-2020
OI Neef, Nicole E./0000-0003-2414-7595; Kirsten,
   Holger/0000-0002-3126-7950; Boltze, Johannes/0000-0003-3956-4164;
   Muller, Bent/0000-0001-8308-6193
FU Fraunhofer Society; Max Planck SocietyMax Planck Society; Leipzig
   Interdisciplinary Research Cluster of Genetic Factors, Clinical
   Phenotypes and Environment
FX Fraunhofer Society; Max Planck Society; Leipzig Interdisciplinary
   Research Cluster of Genetic Factors, Clinical Phenotypes and Environment
CR Alonso-Bua B, 2006, INT J PSYCHOPHYSIOL, V59, P159, DOI 10.1016/j.ijpsycho.2005.03.020
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   [Anonymous], 1996, BRIT MED J, V313, P1448
   Ardlie KG, 2015, SCIENCE, V348, P648, DOI 10.1126/science.1262110
   Bellini G, 2005, J MOL NEUROSCI, V27, P311, DOI 10.1385/JMN:27:3:311
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Borel C, 2011, GENOME RES, V21, P68, DOI 10.1101/gr.109371.110
   Boyle AP, 2012, GENOME RES, V22, P1790, DOI 10.1101/gr.137323.112
   Brkanac Z, 2007, AM J MED GENET B, V144B, P556, DOI 10.1002/ajmg.b.30471
   Champely S., 2015, PWR BASIC FUNCTIONS
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Cope N, 2005, AM J HUM GENET, V76, P581, DOI 10.1086/429131
   Czamara D, 2011, BEHAV GENET, V41, P110, DOI 10.1007/s10519-010-9413-6
   Darki F, 2012, BIOL PSYCHIAT, V72, P671, DOI 10.1016/j.biopsych.2012.05.008
   de Kovel CGF, 2004, J MED GENET, V41, P652, DOI 10.1136/jmg.2003.012294
   Dimas AS, 2009, SCIENCE, V325, P1246, DOI 10.1126/science.1174148
   Dixon AL, 2007, NAT GENET, V39, P1202, DOI 10.1038/ng2109
   Doeller CF, 2003, NEUROIMAGE, V20, P1270, DOI 10.1016/S1053-8119(03)00389-6
   Fehrmann RSN, 2011, PLOS GENET, V7, DOI 10.1371/journal.pgen.1002197
   Feng MY, 2010, CELL, V143, P84, DOI 10.1016/j.cell.2010.08.040
   Francks C, 2004, AM J HUM GENET, V75, P1046, DOI 10.1086/426404
   Gottesman II, 2003, AM J PSYCHIAT, V160, P636, DOI 10.1176/appi.ajp.160.4.636
   Greenawalt DM, 2011, GENOME RES, V21, P1008, DOI 10.1101/gr.112821.110
   Grundberg E, 2009, GENOME RES, V19, P1942, DOI 10.1101/gr.095224.109
   Harlaar N, 2005, J CHILD PSYCHOL PSYC, V46, P373, DOI 10.1111/j.1469-7610.2004.00358.x
   Heim S, 2008, ACTA NEUROBIOL EXP, V68, P73
   Hommet C, 2009, NEUROPSYCHOLOGIA, V47, P761, DOI 10.1016/j.neuropsychologia.2008.12.010
   Kaufman AS, 2009, KAUFMAN ASSESSMENT B
   Kim S, 2012, TRANSL PSYCHIAT, V2, DOI 10.1038/tp.2012.42
   Kirsten H, 2015, HUM MOL GENET, V24, P4746, DOI 10.1093/hmg/ddv194
   Klingberg T, 2000, NEURON, V25, P493, DOI 10.1016/S0896-6273(00)80911-3
   Kraft I, 2015, BRAIN, V138, DOI 10.1093/brain/awv036
   Kundu S, 2014, PREDICTABEL ASSESSME
   Lai CSL, 2001, NATURE, V413, P519, DOI 10.1038/35097076
   Landerl K, 1997, COGNITION, V63, P315, DOI 10.1016/S0010-0277(97)00005-X
   Lin PI, 2007, AM J HUM GENET, V80, P531, DOI 10.1086/512133
   Liu Y, 2008, FEBS LETT, V582, P359, DOI 10.1016/j.febslet.2007.12.035
   Lohmueller KE, 2003, NAT GENET, V33, P177, DOI 10.1038/ng1071
   Lovio R, 2010, BRAIN RES, V1335, P53, DOI 10.1016/j.brainres.2010.03.097
   Luciano M, 2007, BIOL PSYCHIAT, V62, P811, DOI 10.1016/j.biopsych.2007.03.007
   Marco-Pallares J, 2005, NEUROIMAGE, V25, P471, DOI 10.1016/j.neuroimage.2004.11.028
   Marino C, 2007, GENES BRAIN BEHAV, V6, P640, DOI 10.1111/j.1601-183X.2006.00291.x
   Marino C, 2005, EUR J HUM GENET, V13, P491, DOI 10.1038/sj.ejhg.5201356
   Matys V, 2006, NUCLEIC ACIDS RES, V34, pD108, DOI 10.1093/nar/gkj143
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   McArthur GM, 2000, J CHILD PSYCHOL PSYC, V41, P869, DOI 10.1111/1469-7610.00674
   Mehta D, 2013, EUR J HUM GENET, V21, P48, DOI 10.1038/ejhg.2012.106
   Moll K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103537
   Muller B, 2016, HUM GENET, V135, P259, DOI 10.1007/s00439-016-1636-z
   Myers AJ, 2007, NAT GENET, V39, P1494, DOI 10.1038/ng.2007.16
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Neuhoff N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034909
   Newbury DF, 2011, BEHAV GENET, V41, P90, DOI 10.1007/s10519-010-9424-3
   Newbury DF, 2009, AM J HUM GENET, V85, P264, DOI 10.1016/j.ajhg.2009.07.004
   Peter B, 2011, J NEURODEV DISORD, V3, P39, DOI 10.1007/s11689-010-9065-0
   Petretto E, 2006, PLOS GENET, V2, P1625, DOI 10.1371/journal.pgen.0020172
   Pinel P, 2012, J NEUROSCI, V32, P817, DOI 10.1523/JNEUROSCI.5996-10.2012
   Pique-Regi R, 2011, GENOME RES, V21, P447, DOI 10.1101/gr.112623.110
   Plomin R, 2005, PSYCHOL BULL, V131, P592, DOI 10.1037/0033-2909.131.4.592
   Purcell S, 2007, AM J HUM GENET, V81, P559, DOI 10.1086/519795
   Quinque D, 2006, ANAL BIOCHEM, V353, P272, DOI 10.1016/j.ab.2006.03.021
   R Core Team, 2013, R LANG ENV STAT COMP
   Ramasamy A, 2014, NAT NEUROSCI, V17, P1418, DOI 10.1038/nn.3801
   Roeske D, 2011, MOL PSYCHIATR, V16, P97, DOI 10.1038/mp.2009.102
   SAMS M, 1993, J COGNITIVE NEUROSCI, V5, P363, DOI 10.1162/jocn.1993.5.3.363
   Saviour Pushpa, 2008, Indian J Hum Genet, V14, P99, DOI 10.4103/0971-6866.45002
   Scerri TS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050321
   Scerri TS, 2011, BIOL PSYCHIAT, V70, P237, DOI 10.1016/j.biopsych.2011.02.005
   Scerri TS, 2004, J MED GENET, V41, P853, DOI 10.1136/jmg.2004.018341
   Schaadt G., 2015, DEVELOPMENTAL SCI, V19, P1020
   Schadt EE, 2008, PLOS BIOL, V6, P1020, DOI 10.1371/journal.pbio.0060107
   Schroder A, 2013, PHARMACOGENOMICS J, V13, P12, DOI 10.1038/tpj.2011.44
   Schulte-Korne G, 1998, NEUROREPORT, V9, P337, DOI 10.1097/00001756-199801260-00029
   Schulte-Korne G, 2001, INT J PSYCHOPHYSIOL, V40, P77, DOI 10.1016/S0167-8760(00)00152-5
   Shaywitz SE, 1998, P NATL ACAD SCI USA, V95, P2636, DOI 10.1073/pnas.95.5.2636
   Shulman JM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011244
   Skeide MA, 2015, NEUROIMAGE, V118, P414, DOI 10.1016/j.neuroimage.2015.06.024
   Stock C., 2008, DTSCH RECHTSCHREIBTE
   Taipale M, 2003, P NATL ACAD SCI USA, V100, P11553, DOI 10.1073/pnas.1833911100
   Uhlen M, 2015, SCIENCE, V347, DOI 10.1126/science.1260419
   van Ermingen-Marbach M, 2013, ACTA NEUROBIOL EXP, V73, P404
   van Nas A, 2010, GENETICS, V185, P1059, DOI 10.1534/genetics.110.116087
   Vernes SC, 2008, NEW ENGL J MED, V359, P2337, DOI 10.1056/NEJMoa0802828
   Veyrieras JB, 2008, PLOS GENET, V4, DOI 10.1371/journal.pgen.1000214
   Wang Y, 2006, NEUROSCIENCE, V143, P515, DOI 10.1016/j.neuroscience.2006.08.022
   Westra HJ, 2013, NAT GENET, V45, P1238, DOI 10.1038/ng.2756
   Wigg KG, 2004, MOL PSYCHIATR, V9, P1111, DOI 10.1038/sj.mp.4001543
   Wilcke A, 2012, EUR J HUM GENET, V20, P224, DOI 10.1038/ejhg.2011.160
   Wimmer H, 1996, READ WRIT, V8, P171, DOI 10.1007/BF00555368
   Xia K, 2012, BIOINFORMATICS, V28, P451, DOI 10.1093/bioinformatics/btr678
   Zeller T, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010693
NR 92
TC 0
Z9 0
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN, NJ 07030 USA
SN 2162-3279
J9 BRAIN BEHAV
JI Brain Behav.
PD NOV
PY 2017
VL 7
IS 11
AR e00851
DI 10.1002/brb3.851
PG 12
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA FN5QR
UT WOS:000416063200016
PM 29201552
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wahab, NAA
   Zakaria, MN
   Rahman, AHA
   Sidek, D
   Wahab, S
AF Wahab, Noor Alaudin Abdul
   Zakaria, Mohd. Normani
   Rahman, Abdul Hamid Abdul
   Sidek, Dinsuhaimi
   Wahab, Suzaily
TI Listening to Sentences in Noise: Revealing Binaural Hearing Challenges
   in Patients with Schizophrenia
SO PSYCHIATRY INVESTIGATION
LA English
DT Article
DE Schizophrenia; Binaural hearing; Spatial hearing; Auditory processing
ID SPATIAL RELEASE; AUDITORY HALLUCINATIONS; SOUND LOCALIZATION;
   SPEECH-PERCEPTION; MASKING; CHILDREN; BRAIN; ASYMMETRY; DEFICITS;
   COMPREHENSION
AB Objective The present, case-control, study investigates binaural hearing performance in schizophrenia patients towards sentences presented in quiet and noise.
   Methods Participants were twenty-one healthy controls and sixteen schizophrenia patients with normal peripheral auditory functions. The binaural hearing was examined in four listening conditions by using the Malay version of hearing in noise test. The syntactically and semantically correct sentences were presented via headphones to the randomly selected subjects. In each condition, the adaptively obtained reception thresholds for speech (RTS) were used to determine RTS noise composite and spatial release from masking.
   Results Schizophrenia patients demonstrated significantly higher mean RTS value relative to healthy controls (p=0.018). The large effect size found in three listening conditions, i.e., in quiet (d=1.07), noise right (d=0.88) and noise composite (d=0.90) indicates statistically significant difference between the groups. However, noise front and noise left conditions show medium (d=0.61) and small (d=0.50) effect size respectively. No statistical difference between groups was noted in regards to spatial release from masking on right (p=0.305) and left (p=0.970) ear.
   Conclusion The present findings suggest an abnormal unilateral auditory processing in central auditory pathway in schizophrenia patients. Future studies to explore the role of binaural and spatial auditory processing were recommended.
C1 [Wahab, Noor Alaudin Abdul; Zakaria, Mohd. Normani] Univ Sains Malaysia, Sch Hlth Sci, Audiol Programme, Kelantan, Malaysia.
   [Wahab, Noor Alaudin Abdul] Univ Kebangsaan Malaysia, Fac Hlth Sci, Sch Rehabil Sci, Audiol Programme, Kuala Lumpur, Malaysia.
   [Rahman, Abdul Hamid Abdul; Wahab, Suzaily] Univ Kebangsaan Malaysia, Fac Med, Dept Psychiat, Kuala Lumpur 56000, Malaysia.
   [Sidek, Dinsuhaimi] Univ Sains Malaysia, Sch Med, Dept Otorhinolaryngol, Kelantan, Malaysia.
RP Wahab, S (corresponding author), Univ Kebangsaan Malaysia, Fac Med, Dept Psychiat, Kuala Lumpur 56000, Malaysia.
EM suzailywhb@yahoo.com
RI Zakaria, Mohd Normani/J-2754-2015
OI Zakaria, Mohd Normani/0000-0002-3694-3460
FU Centre for Research and Instrumentation Management (CRIM), Universiti
   Kebangsaan Malaysia (UKM) [GGPM-2012-090]
FX The research was funded under the Centre for Research and
   Instrumentation Management (CRIM), Universiti Kebangsaan Malaysia (UKM)
   grant scheme (GGPM-2012-090).
CR Aboitiz F, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00183
   Brown Thomas E, 2008, Curr Psychiatry Rep, V10, P407, DOI 10.1007/s11920-008-0065-7
   Cameron S, 2006, J AM ACAD AUDIOL, V17, P306, DOI 10.3766/jaaa.17.5.2
   Carter JD, 2010, SCHIZOPHR RES, V122, P104, DOI 10.1016/j.schres.2010.03.019
   Ching TYC, 2011, J ACOUST SOC AM, V129, P368, DOI 10.1121/1.3523295
   Collinson SL, 2009, SCHIZOPHR RES, V112, P24, DOI 10.1016/j.schres.2009.03.034
   CONSTANTINIDES H, 2003, INT C SER, V1254, P481, DOI DOI 10.1016/S0531-5131(03)010
   Danielyan A, 2009, PSYCHIAT CLIN N AM, V32, P719, DOI 10.1016/j.psc.2009.08.004
   Favrod J, 2012, BMC PSYCHIATRY, V12, DOI 10.1186/1471-244X-12-161
   Gonzalez JC, 2003, ACTAS ESP PSIQUIATRI, V31, P10
   GRILLON C, 1990, ARCH GEN PSYCHIAT, V47, P171
   Grothe B, 2011, HEARING RES, V279, P43, DOI 10.1016/j.heares.2011.03.013
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   Hawley ML, 2004, J ACOUST SOC AM, V115, P833, DOI 10.1121/1.1639908
   Hugdahl K, 2012, SCHIZOPHR RES, V140, P59, DOI 10.1016/j.schres.2012.06.019
   Hugdahl Kenneth, 2008, Cogn Neuropsychiatry, V13, P166, DOI 10.1080/13546800801906808
   IGATA M, 1994, JPN J PSYCHIAT NEUR, V48, P571
   Iliadou V, 2006, INT J AUDIOL, V45, P74, DOI 10.1080/14992020500376529
   Iliadou V, 2013, AM J AUDIOL, V22, P201, DOI 10.1044/1059-0889(2013/12-0073)
   Kallstrand J, 2012, PSYCHIAT RES, V196, P188, DOI 10.1016/j.psychres.2011.08.024
   Kehne J. H., 2012, TARGETS EMERGING THE, P425
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Krieger S, 2005, AM J PSYCHIAT, V162, P1206, DOI 10.1176/appi.ajp.162.6.1206
   Kronmuller KT, 2011, COMPR PSYCHIAT, V52, P102, DOI 10.1016/j.comppsych.2010.04.014
   Lazard DS, 2012, LARYNGOSCOPE, V122, P167, DOI 10.1002/lary.22370
   Lee SH, 2004, ACTA NEUROPSYCHIATR, V16, P154, DOI 10.1111/j.0924-2708.2004.00071.x
   Leucht S, 2005, BRIT J PSYCHIAT, V187, P366, DOI 10.1192/bjp.187.4.366
   Litovsky R. Y., 2012, ACOUST TODAY, V8, P18
   Litovsky RY, 2002, HEARING RES, V165, P177, DOI 10.1016/S0378-5955(02)00304-0
   Mishra J, 2016, TRANSL PSYCHIAT, V6, DOI 10.1038/tp.2016.45
   Misurelli SM, 2012, J ACOUST SOC AM, V132, P380, DOI 10.1121/1.4725760
   Nam EC, 2005, J LARYNGOL OTOL, V119, P352, DOI 10.1258/0022215053945796
   O'Connor WT, 2015, PHARMACOL THERAPEUT, V150, P47, DOI 10.1016/j.pharmthera.2015.01.005
   Page P, 2014, INT J SPORTS PHYS TH, V9, P726
   Pesciarelli F, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00799
   Quar TK, 2008, INT J AUDIOL, V47, P379, DOI 10.1080/14992020801886796
   Ross LA, 2007, SCHIZOPHR RES, V97, P173, DOI 10.1016/j.schres.2007.08.008
   Schafer EC., 2010, J ED AUDIOL, V16, P4
   Schminky MM, 1999, DEAF BLIND PERSPECT, V7, P1
   Schultz SK, 1999, LANCET, V353, P1425, DOI 10.1016/S0140-6736(98)07549-7
   Seidman LJ, 2012, NEUROPSYCHOLOGY, V26, P288, DOI 10.1037/a0027970
   SHAM PC, 1994, ACTA PSYCHIAT SCAND, V89, P135, DOI 10.1111/j.1600-0447.1994.tb01501.x
   Shtyrov Y, 1998, NEUROSCI LETT, V251, P141, DOI 10.1016/S0304-3940(98)00529-1
   Shtyrov Y, 1999, NEUROREPORT, V10, P2189, DOI 10.1097/00001756-199907130-00034
   Smucny J, 2013, SCHIZOPHR RES, V147, P196, DOI 10.1016/j.schres.2013.03.025
   Soli SD, 2008, INT J AUDIOL, V47, P356, DOI 10.1080/14992020801895136
   Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1
   Tandon R, 2010, SCHIZOPHR RES, V122, P1, DOI 10.1016/j.schres.2010.05.025
   Tarasenko MA, 2014, FRONT PSYCHIATRY, V5, DOI 10.3389/fpsyt.2014.00142
   Tollin DJ, 2005, J NEUROSCI, V25, P10648, DOI 10.1523/JNEUROSCI.1609-05.2005
   Vaillancourt V, 2008, INT J AUDIOL, V47, P383, DOI 10.1080/14992020802055300
   van Os J, 2009, LANCET, V374, P635, DOI 10.1016/S0140-6736(09)60995-8
   Veuillet E, 2001, J NEUROL NEUROSUR PS, V70, P88, DOI 10.1136/jnnp.70.1.88
   Vinkers CH, 2010, EXPERT OPIN INV DRUG, V19, P1217, DOI 10.1517/13543784.2010.513382
   Wahab NAA, 2016, PSYCHIAT INVEST, V13, P82, DOI 10.4306/pi.2016.13.1.82
   Wahab S, 2015, PSYCHIAT RES, V228, P462, DOI 10.1016/j.psychres.2015.06.014
   WHO, 2001, MENT HLTH REP 2001
   Wong M. Y., 2002, THESIS
   Wu C, 2012, SCHIZOPHR RES, V134, P33, DOI 10.1016/j.schres.2011.09.019
   Yuen KCP, 2014, J SPEECH LANG HEAR R, V57, P2005, DOI 10.1044/2014_JSLHR-H-13-0060
NR 60
TC 0
Z9 0
U1 0
U2 1
PU KOREAN NEUROPSYCHIATRIC ASSOC
PI SEOUL
PA RN 522, G-FIVE CENTRAL PLAZA 1685-8 SEOCHO 4-DONG, SEOCHO-GU, SEOUL,
   137-882, SOUTH KOREA
SN 1738-3684
EI 1976-3026
J9 PSYCHIAT INVEST
JI Psychiatry Investig.
PD NOV
PY 2017
VL 14
IS 6
BP 786
EP 794
DI 10.4306/pi.2017.14.6.786
PG 9
WC Psychiatry
SC Psychiatry
GA FM5TQ
UT WOS:000415103900010
PM 29209382
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Foss-Feig, JH
   Schauder, KB
   Key, AP
   Wallace, MT
   Stone, WL
AF Foss-Feig, Jennifer H.
   Schauder, Kimberly B.
   Key, Alexandra P.
   Wallace, Mark T.
   Stone, Wendy L.
TI Audition-specific temporal processing deficits associated with language
   function in children with autism spectrum disorder
SO AUTISM RESEARCH
LA English
DT Article
DE ASD; audition; vision; temporal processing; language; low level
   perception
ID PERVASIVE DEVELOPMENTAL DISORDERS; EVENT-RELATED POTENTIALS; FREQUENCY
   DISCRIMINATION; MISMATCH FIELD; GAP DETECTION; SPEECH; IMPAIRMENT;
   ABNORMALITIES; INDIVIDUALS; PERCEPTION
AB Sensory processing alterations are highly prevalent in autism spectrum disorder (ASD). Neurobiologically-based theories of ASD propose that abnormalities in the processing of temporal aspects of sensory input could underlie core symptoms of ASD. For example, rapid auditory temporal processing is critical for speech perception, and language difficulties are central to the social communication deficits defining the disorder. This study assessed visual and auditory temporal processing abilities and tested their relation to core ASD symptoms. 53 children (26 ASD, 27 TD) completed visual and auditory psychophysical gap detection tasks to measure gap detection thresholds (i.e., the minimum interval between sequential stimuli needed for individuals to perceive an interruption between the stimuli) in each domain. Children were also administered standardized language assessments such that the relation between individual differences in auditory gap detection thresholds and degree of language and communication difficulties among children with ASD could be assessed. Children with ASD had substantially higher auditory gap detection thresholds compared to children with TD, and auditory gap detection thresholds were correlated significantly with several measures of language processing in this population. No group differences were observed in the visual temporal processing. Results indicate a domain-specific impairment in rapid auditory temporal processing in ASD that is associated with greater difficulties in language processing. Findings provide qualified support for temporal processing theories of ASD and highlight the need for future research testing the nature, extent, and universality of auditory temporal processing deficits in this population. Autism Res2017, 10: 1845-1856. (c) 2017 International Society for Autism Research, Wiley Periodicals, Inc.
   Lay SummarySensory symptoms are common in ASD. Temporal processing alterations are often implicated, but understudied. The ability to process rapid sensory information, particularly auditory input, is critical for language functioning. This study tested auditory and visual temporal processing in ASD and controls. Findings suggest that rapid auditory (but not visual) processing is impaired in ASD and related to language functioning. These results could provide mechanistic clues to understanding core symptoms and lead to novel intervention targets.
C1 [Foss-Feig, Jennifer H.] Mt Sinai Hosp, Icahn Sch Med, Dept Psychiat, New York, NY 10029 USA.
   [Foss-Feig, Jennifer H.] Mt Sinai Hosp, Icahn Sch Med, Seaver Autism Ctr, New York, NY 10029 USA.
   [Schauder, Kimberly B.] Univ Rochester, Dept Psychol, Meliora Hall, Rochester, NY 14627 USA.
   [Key, Alexandra P.; Wallace, Mark T.] Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, Nashville, TN USA.
   [Key, Alexandra P.; Wallace, Mark T.] Vanderbilt Kennedy Ctr, Nashville, TN USA.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Psychol, Nashville, TN 37240 USA.
   [Stone, Wendy L.] Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
RP Foss-Feig, JH (corresponding author), Mt Sinai Hosp, Icahn Sch Med, Dept Psychiat, Seaver Autism Ctr Res & Treatment, One Gustave Levy Pl,Box 1230, New York, NY 10029 USA.
EM jennifer.foss-feig@mssm.edu
FU Dennis Weatherstone Predoctoral Fellowship from Autism Speaks; Marino
   Autism Research Institute; Brain and Behavior Research Foundation NARSAD
   Young Investigator Award; Autism Science Foundation Accelerator grant;
   Seaver Foundation; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Mental Health (NIMH) [R21MH115297,
   R21MH115297] Funding Source: NIH RePORTER
FX This study was supported by a Dennis Weatherstone Predoctoral Fellowship
   from Autism Speaks to JHF and a Marino Autism Research Institute grant
   to APK and JHF. Jennifer Foss-Feig's effort was also funded in part by a
   Brain and Behavior Research Foundation NARSAD Young Investigator Award
   to JHF, an Autism Science Foundation Accelerator grant to JHF, and the
   Seaver Foundation. The authors would like to acknowledge Rebecca
   Johnston, Caroline Oates, and Holly Black for their assistance with
   recruitment and data collection. They also would like to thank the
   children and families who participated in this study.
CR Allman MJ, 2012, FRONT INTEGR NEUROSC, V6, DOI [10.3389/fnint.2012.00007, 10.3389/fnint.2011.00002]
   American Psychiatric Association, 2013, DSM 5 AM PSYCHAIT AS
   Belmonte MK, 2004, J NEUROSCI, V24, P9228, DOI 10.1523/JNEUROSCI.3340-04.2004
   Bhatara A, 2013, J AUTISM DEV DISORD, V43, P2312, DOI 10.1007/s10803-013-1778-y
   Brock J, 2002, DEV PSYCHOPATHOL, V14, P209, DOI 10.1017/S0954579402002018
   BUSNEL MC, 1992, ANN NY ACAD SCI, V662, P118, DOI 10.1111/j.1749-6632.1992.tb22857.x
   Cardy JEO, 2008, INT J PSYCHOPHYSIOL, V68, P170, DOI 10.1016/j.ijpsycho.2007.10.015
   Cardy JEO, 2005, NEUROREPORT, V16, P521, DOI 10.1097/00001756-200504040-00021
   Cardy JEO, 2005, NEUROREPORT, V16, P329, DOI 10.1097/00001756-200503150-00005
   Caron MJ, 2006, BRAIN, V129, P1789, DOI 10.1093/brain/awl072
   Dawson G, 2000, J AUTISM DEV DISORD, V30, P415, DOI 10.1023/A:1005547422749
   Edgar JC, 2015, MOL AUTISM, V6, DOI 10.1186/s13229-015-0065-5
   Ennis D.M., 1993, J SENS STUD, V8, P353, DOI DOI 10.1111/J.1745-459X.1993.TB00225.X
   Falter CM, 2012, Q J EXP PSYCHOL, V65, P2093, DOI 10.1080/17470218.2012.690770
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   FORMBY C, 1989, AUDIOLOGY, V28, P250
   Foss-Feig JH, 2013, J NEUROSCI, V33, P8243, DOI 10.1523/JNEUROSCI.1608-12.2013
   Foss-Feig JH, 2012, INT REV RES DEV DISA, V43, P87, DOI 10.1016/B978-0-12-398261-2.00003-9
   Green D. M., 1966, SIGNAL DETECTION THE
   HARVEY LO, 1986, BEHAV RES METH INSTR, V18, P623, DOI 10.3758/BF03201438
   Jeste SS, 2009, J AUTISM DEV DISORD, V39, P495, DOI 10.1007/s10803-008-0652-9
   Just MA, 2004, BRAIN, V127, P1811, DOI 10.1093/brain/awh199
   Kanner L, 1943, NERV CHILD, V2, P217
   Kellerman GR, 2005, CNS SPECTRUMS, V10, P748, DOI 10.1017/S1092852900019738
   Kujala T, 2013, NEUROSCI BIOBEHAV R, V37, P697, DOI 10.1016/j.neubiorev.2013.01.006
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lepisto T, 2006, CLIN NEUROPHYSIOL, V117, P2161, DOI 10.1016/j.clinph.2006.06.709
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Lumley T, 2002, ANNU REV PUBL HEALTH, V23, P151, DOI 10.1146/annurev.publhealth.23.100901.140546
   MacMillan N. A., 2005, DETECTION THEORY USE
   ONeill M, 1997, J AUTISM DEV DISORD, V27, P283, DOI 10.1023/A:1025850431170
   Orekhova EV, 2009, CLIN NEUROPHYSIOL, V120, P520, DOI 10.1016/j.clinph.2008.12.034
   Poldrack RA, 2001, J COGNITIVE NEUROSCI, V13, P687, DOI 10.1162/089892901750363235
   Rapin I, 2003, BRAIN DEV-JPN, V25, P166, DOI 10.1016/S0387-7604(02)00191-2
   Rippon G, 2007, INT J PSYCHOPHYSIOL, V63, P164, DOI 10.1016/j.ijpsycho.2006.03.012
   Roberts TPL, 2011, BIOL PSYCHIAT, V70, P263, DOI 10.1016/j.biopsych.2011.01.015
   Roberts TPL, 2010, AUTISM RES, V3, P8, DOI 10.1002/aur.111
   Rogers SJ, 2005, J CHILD PSYCHOL PSYC, V46, P1255, DOI 10.1111/j.1469-7610.2005.01431.x
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rutter M., 2003, SCQ SOCIAL COMMUNICA
   Scheuffgen K, 2000, DEV PSYCHOPATHOL, V12, P83, DOI 10.1017/S095457940000105X
   Semel E., 2003, CLIN EVALUATION LANA
   SHAILER MJ, 1987, J ACOUST SOC AM, V81, P1110, DOI 10.1121/1.394631
   Sigman M., 1997, CHILDREN AUTISM DEV
   Simmons DR, 2009, VISION RES, V49, P2705, DOI 10.1016/j.visres.2009.08.005
   Sutcliffe P, 2005, J EXP CHILD PSYCHOL, V91, P249, DOI 10.1016/j.jecp.2005.03.004
   Szelag E, 2004, BRIT J PSYCHOL, V95, P269, DOI 10.1348/0007126041528167
   Tager-Flusberg H, 2007, PEDIATR CLIN N AM, V54, P469, DOI 10.1016/j.pcl.2007.02.011
   Tager-Flusberg H, 2006, CLIN NEUROSCI RES, V6, P219, DOI 10.1016/j.cnr.2006.06.007
   TALLAL P, 1973, NEUROPSYCHOLOGIA, V11, P389, DOI 10.1016/0028-3932(73)90025-0
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x
   Van Ingelghem M, 2001, NEUROREPORT, V12, P3603, DOI 10.1097/00001756-200111160-00046
   Wagner R, 1999, COMPREHENSIVE TEST P
   Wallace GL, 2009, J AUTISM DEV DISORD, V39, P809, DOI 10.1007/s10803-008-0684-1
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
   Weschsler D., 1999, WASI WECHSLER ABBREV
   Williams D, 2008, PSYCHOL BULL, V134, P944, DOI 10.1037/a0013743
   Wimpory D, 2002, J INTELL DISABIL RES, V46, P352, DOI 10.1046/j.1365-2788.2002.00423.x
   Worley JA, 2012, RES AUTISM SPECT DIS, V6, P965, DOI 10.1016/j.rasd.2011.12.012
   Wright BA, 1997, NATURE, V387, P176, DOI 10.1038/387176a0
NR 62
TC 11
Z9 11
U1 2
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-3792
EI 1939-3806
J9 AUTISM RES
JI Autism Res.
PD NOV
PY 2017
VL 10
IS 11
BP 1845
EP 1856
DI 10.1002/aur.1820
PG 12
WC Behavioral Sciences; Psychology, Developmental
SC Behavioral Sciences; Psychology
GA FM6DC
UT WOS:000415138000010
PM 28632303
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Yu, KM
AF Yu, Kristine M.
TI The role of time in phonetic spaces: Temporal resolution in Cantonese
   tone perception
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Tone perception; Tone recognition; Temporal integration; Temporal
   resolution; Cantonese; Interrupted speech
ID FUNDAMENTAL-FREQUENCY; MANDARIN TONES; FALLING CONTOURS; VOICE QUALITY;
   SPEECH; PITCH; RECOGNITION; ALIGNMENT; EXPERIENCE; IDENTIFICATION
AB The role of temporal resolution in speech perception (e.g. whether tones are parameterized with fundamental frequency sampled every 10 ms, or just twice in the syllable) is sometimes overlooked, and the temporal resolution relevant for tonal perception is still an open question. The choice of temporal resolution matters because how we understand the recognition, dispersion, and learning of phonetic categories is entirely predicated on what parameters we use to define the phonetic space that they lie in. Here, we present a tonal perception experiment in Cantonese where we used interrupted speech in trisyllabic stimuli to study the effect of temporal resolution on human tonal identification. We also performed acoustic classification of the stimuli with support vector machines. Our results show that just a few samples per syllable are enough for humans and machines to classify Cantonese tones with reasonable accuracy, without much difference in performance from having the full speech signal available. The confusion patterns and machine classification results suggest that loss of detailed information about the temporal alignment and shape of fundamental frequency contours was a major cause of decreasing accuracy as resolution decreased. Moreover, machine classification experiments show that for accurate identification of rising tones in Cantonese, it is crucial to extend the temporal window for sampling to the following syllable, due to peak delay. (C) 2017 The Author(s). Published by Elsevier Ltd.
C1 [Yu, Kristine M.] Univ Massachusetts, Dept Linguist, Amherst, MA 01003 USA.
RP Yu, KM (corresponding author), Univ Massachusetts, Dept Linguist, Amherst, MA 01003 USA.
EM krisyu@linguist.umass.edu
OI Yu, Kristine/0000-0001-8668-7242
FU NSF graduate fellowshipNational Science Foundation (NSF)
FX We wish to acknowledge Hiu Wai Lam for piloting and recording the
   stimuli and testing the participants in Hong Kong, Eric Zee for so
   kindly allowing us to test participants in his laboratory at the City
   University of Hong Kong, Wai Ting Lam for testing participants in Los
   Angeles, Keelan Evanini for help with implementing RAPT, and Edward
   Stabler, Megha Sundara and also Patricia Keating, John Kingston, Mark
   Liberman, and Colin Wilson for illuminating discussions, and three
   anonymous referees for valuable comments and suggestions. An earlier
   version of this work was presented at the conference on The
   Psycholinguistic Representation of Tone in Hong Kong, China in August
   2011, and this paper is based in part on the author's Ph.D. dissertation
   work at the University of California, Los Angeles. This research was
   supported by an NSF graduate fellowship. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the authors and do not necessarily reflect the views of the National
   Science Foundation.
CR Alexander Jennifer, 2010, THESIS
   Andruski J. E., 2004, J INT PHON ASSOC, V34, P125
   Andruski JE, 2006, J PHONETICS, V34, P388, DOI 10.1016/j.wocn.2005.07.001
   Andruski Jean E., 2000, J INT PHON ASSOC, V30, P37, DOI DOI 10.1017/S0025100300006654
   Arvaniti A, 1998, J PHONETICS, V26, P3, DOI 10.1006/jpho.1997.0063
   BARNES J., 2012, LAB PHONOLOGY, V3, P337, DOI DOI 10.1515/LP-2012-0017
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barry JG, 2004, J ACOUST SOC AM, V116, P1739, DOI 10.1121/1.1779272
   BASHFORD JA, 1992, PERCEPT PSYCHOPHYS, V51, P211, DOI 10.3758/BF03212247
   Bashford JA, 1996, PERCEPT PSYCHOPHYS, V58, P342, DOI 10.3758/BF03206810
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Bauer R. S., 2003, LANG VAR CHANGE, V15, P211, DOI DOI 10.1017/S0954394503152039
   Becker-Kristal R., 2010, THESIS
   Bennett K. P., 2000, P 17 INT C MACH LEAR, P57
   Bishop J, 2012, J ACOUST SOC AM, V132, P1100, DOI 10.1121/1.4714351
   BLICHER DL, 1990, J PHONETICS, V18, P37, DOI 10.1016/S0095-4470(19)30357-2
   Boersma P., 2010, PRAAT DOING PHONETIC, V5, P32
   Boyd S., 2004, CONVEX OPTIMIZATION
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Bruce G., 1977, SWEDISH WORD ACCENTS
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chandrasekaran B, 2007, NEUROREPORT, V18, P1963, DOI 10.1097/WNR.0b013e3282f213c5
   Chang Chih-Chung, 2001, LIBSVM LIB SUPPORT V
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chao Yuen Ren, 1968, GRAMMAR SPOKEN CHINE
   Chen MM, 2014, IEEE IJCNN, P1154, DOI 10.1109/IJCNN.2014.6889515
   CIOCCA V, 1987, PERCEPT PSYCHOPHYS, V42, P476, DOI 10.3758/BF03209755
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   D'Imperio M, 2012, OXFORD HDB LAB PHONO, P275
   DANNENBRING GL, 1976, CAN J PSYCHOL, V30, P99, DOI 10.1037/h0082053
   de Boer B, 2003, ACOUST RES LETT ONL, V4, P129, DOI 10.1121/1.1613311
   De Looze C, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P2891
   DELEEUW J, 2009, J STAT SOFTW, V31, P1
   DiCanio Christian [T.], 2014, 4 INT S TON ASP LANG, P203
   Dillon B, 2013, COGNITIVE SCI, V37, P344, DOI 10.1111/cogs.12008
   Evanini K., 2010, J ACOUST SOC AM, V128, P2291
   Evanini K, 2011, 85 ANN M LING SOC AM
   Feldman NH, 2013, PSYCHOL REV, V120, P751, DOI 10.1037/a0034245
   Fu Q-J, 2000, ASIA PAC J SPEECH LA, V5, P45, DOI DOI 10.1179/136132800807547582
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   GANDOUR J, 1981, J CHINESE LINGUIST, V9, P20
   Gandour J, 1992, LINGUISTICS TIBETO B, V15
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garellek M, 2013, J ACOUST SOC AM, V133, P1078, DOI 10.1121/1.4773259
   Gauthier B, 2007, COGNITION, V103, P80, DOI 10.1016/j.cognition.2006.03.002
   Gottfried TL, 1997, J PHONETICS, V25, P207, DOI 10.1006/jpho.1997.0042
   Grassi M, 2009, BEHAV RES METHODS, V41, P20, DOI 10.3758/BRM.41.1.20
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hant JJ, 2003, SPEECH COMMUN, V40, P291, DOI 10.1016/S0167-6393(02)00068-7
   Hermes D. J., 2006, METHODS EMPIRICAL PR, P29
   Hess W., 1983, PITCH DETERMINATION
   Hirst D.J., 1993, TRAVAUX I PHONETIQUE, V15, P71
   House D, 1990, TONAL PERCEPTION SPE
   House D., 2004, P INT S TON ASP LANG, P93
   House D, 2004, TRADITIONAL PHONOLOG, P189
   Ishi CT, 2008, IEEE T AUDIO SPEECH, V16, P47, DOI 10.1109/TASL.2007.910791
   Ishi CT, 2005, INT 2005 INT SPEECH, P481
   James G, 2013, INTRO STAT LEARNING
   Jansen A, 2008, J ACOUST SOC AM, V124, P1739, DOI 10.1121/1.2956472
   Jansen A, 2009, SPEECH COMMUN, V51, P1155, DOI 10.1016/j.specom.2009.05.008
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   Kim K.-O, 1974, J PHONETICS, V22, P477
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   Krishnan A, 2017, J NEUROLINGUIST, V41, P38, DOI 10.1016/j.jneuroling.2016.09.005
   Krishnan A, 2015, J NEUROLINGUIST, V33, P128, DOI 10.1016/j.jneuroling.2014.08.002
   Krishnan A, 2014, NEUROPSYCHOLOGIA, V59, P1, DOI 10.1016/j.neuropsychologia.2014.04.006
   Krishnan A, 2009, NEUROREPORT, V20, P408, DOI 10.1097/WNR.0b013e3283263000
   Kruschke JK, 2013, J EXP PSYCHOL GEN, V142, P573, DOI 10.1037/a0029146
   Kuang JJ, 2013, PHONETICA, V70, P1, DOI 10.1159/000353853
   Labov William, 2006, ATLAS N AM ENGLISH
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   LADEFOGED P, 1980, LANGUAGE, V56, P485, DOI 10.2307/414446
   Lam Y. T., 2014, THESIS
   Laniran Yetunde O., 1992, THESIS
   Lee CY, 2008, J PHONETICS, V36, P537, DOI 10.1016/j.wocn.2008.01.002
   Lee CY, 2009, J PHONETICS, V37, P1, DOI 10.1016/j.wocn.2008.08.001
   Lee CY, 2009, J ACOUST SOC AM, V125, P1125, DOI 10.1121/1.3050322
   Lee T, 2007, P INT 2007, P2677
   Levow G.-A, 2006, P HLT NAACL, P224
   Levow Gina-Anne, 2005, ANN C INT SPEECH COM, P1809
   Li Q, 2016, J PHONETICS, V54, P123, DOI 10.1016/j.wocn.2015.10.002
   Li Y.-H., 2008, P 2 INT C DISTR SMAR, P1, DOI DOI 10.1080/10286600802284373
   Li Yong, 2002, Pacific Rim Workshop on Transducers and Micro/Nano Technologies, P127
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   Lisker L, 1978, SR54 HASK LAB STAT R, P127
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   Luce R. D., 1963, HDB MATH PSYCHOL, P103
   Matthews S., 1994, CANTONESE COMPREHENS
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Meyer D., 2012, E1071 MISC FUNCTIONS
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Moren B, 2006, NAT LANG LINGUIST TH, V24, P113, DOI 10.1007/s11049-004-5454-y
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Peng G, 2004, 2004 INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, P233
   Peng G, 2005, SPEECH COMMUN, V45, P49, DOI 10.1016/j.specom.2004.09.004
   Peperkamp S, 2006, COGNITION, V101, pB31, DOI 10.1016/j.cognition.2005.10.006
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PIERREHUMBERT J, 1981, J ACOUST SOC AM, V70, P985, DOI 10.1121/1.387033
   Pierrehumbert J., 1988, JAPANESE TONE STRUCT
   Pierrehumbert J., 1980, THESIS
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pisarn C, 2006, LECT NOTES ARTIF INT, V4139, P388
   Prom-on S, 2009, J ACOUST SOC AM, V125, P405, DOI 10.1121/1.3037222
   Prukkanon N, 2016, AEU-INT J ELECTRON C, V70, P681, DOI 10.1016/j.aeue.2016.02.006
   Qdejobi OA, 2008, COMPUT SPEECH LANG, V22, P39, DOI 10.1016/j.csl.2007.05.002
   Qian Y, 2004, SPEECH PROSODY, P467
   Qian Y, 2007, J ACOUST SOC AM, V121, P2936, DOI 10.1121/1.2717413
   R Core Team, 2014, R LANG ENV STAT COMP
   Reddy S., 2015, LINGUISTICS VANGUARD, V1, P15, DOI DOI 10.1515/LINGVAN-2015-0002
   Remijsen B, 2014, PHONOLOGY, V31, P435, DOI 10.1017/S0952675714000219
   Remijsen B, 2013, LANGUAGE, V89, P297, DOI 10.1353/lan.2013.0023
   Rosenfelder I, 2014, FAVE FORCED ALIGNMEN, DOI [10.5281/zenodo.22281, DOI 10.5281/ZENODO.22281]
   Rosenfelder I., 2011, FAVE FORCED ALIGNMEN
   Salomon A, 2004, J ACOUST SOC AM, V115, P1296, DOI 10.1121/1.1646400
   Samuel A, 1996, LANG COGNITIVE PROC, V11, P647, DOI 10.1080/016909696387051
   Shen J, 2013, J ACOUST SOC AM, V133, P3016, DOI 10.1121/1.4795775
   Shih C, 2015, J PHONETICS, V51, P6, DOI 10.1016/j.wocn.2015.02.002
   Shui-ping Wang, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P710, DOI 10.1109/ICISE.2009.1313
   Silbert N, 2014, VISUALIZING CONFUSIO
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   STRANGE W, 1983, J ACOUST SOC AM, V74, P695, DOI 10.1121/1.389855
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Talkin D., 1995, SPEECH CODING SYNTHE, P495
   Taylor P, 2000, J ACOUST SOC AM, V107, P1697, DOI 10.1121/1.428453
   Tian Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P105
   UCLA: Statistical Consulting Group, 2011, R LIB CONTR COD SYST
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Vapnik V., 1995, NATURE STAT LEARNING
   Wang SW, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1101
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Wong P. W.-Y, 2010, INTERSPEECH 2010
   Wong PCM, 2003, J SPEECH LANG HEAR R, V46, P413, DOI 10.1044/1092-4388(2003/034)
   Wong Y. W, 2006, P SPEECH PROS 2009 D
   Xu Y, 2001, PHONETICA, V58, P26, DOI 10.1159/000028487
   Xu Y, 1997, J PHONETICS, V25, P61, DOI 10.1006/jpho.1996.0034
   Xu Y, 1998, PHONETICA, V55, P179, DOI 10.1159/000028432
   Yu K. M., 2011, P ICPHS 17
   Yu KM, 2014, J ACOUST SOC AM, V136, P1320, DOI 10.1121/1.4887462
   Zee E, 1977, UCLA WORKING PAPERS, V45, P150
   Zhang JS, 2004, SPEECH COMMUN, V42, P447, DOI 10.1016/j.specom.2004.01.001
   Zhang JS, 2000, INT CONF ACOUST SPEE, P1419, DOI 10.1109/ICASSP.2000.861859
   Zhou N, 2008, EAR HEARING, V29, P326, DOI 10.1097/AUD.0b013e3181662c42
   Zsiga E, 2007, LANG SPEECH, V50, P343, DOI 10.1177/00238309070500030301
NR 150
TC 2
Z9 3
U1 1
U2 7
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2017
VL 65
BP 126
EP 144
DI 10.1016/j.wocn.2017.06.004
PG 19
WC Linguistics; Language & Linguistics
SC Linguistics
GA FM4WD
UT WOS:000415028600008
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wong, P
   Babel, M
AF Wong, Phoebe
   Babel, Molly
TI Perceptual identification of talker ethnicity in Vancouver English
SO JOURNAL OF SOCIOLINGUISTICS
LA English
DT Article
DE Ethnolinguistic variation; speech perception; indexical recognition;
   accent familiarity; Canadian English
ID AMERICAN ENGLISH; SPEECH-PERCEPTION; AFRICAN-AMERICAN; MONTREAL ENGLISH;
   REPERTOIRE; DIALECTS; INTELLIGIBILITY; INTEGRATION; LANGUAGE; TORONTO
AB Studies of ethnolinguistic variation typically begin by describing the speech production variables used to index social groups. In this study, we begin with indexical recognition - the perceptual identification of speakers' self-identified ethnic groups - to determine whether speakers produce ethnolinguistic variation and whether listeners are sensitive to it. Speech samples were recorded from thirty individuals from Metro Vancouver who self-identified as Chinese, East Indian, or White Canadian. These utterances were used in a perception task where listeners categorized speakers' ethnicities. Listeners' social networks were labeled according to the ethnic group with which they reported spending the most time. Analyses indicate that while speakers vary in their productive expression of ethnolinguistic variation, listeners are consistent in their labeling choices. Listener accuracy was higher for voices from the listeners' reported social group and White voices. These results suggest that familiarity with ethnic groups through social networks and mainstream culture influences indexical recognition.
   Les etudes de variation ethnolinguistique commencent typiquement par une description des variables de la production de la parole qui sont utilisees pour indexer les groupes sociales. Dans cette etude, nous commencons par la reconnaissance indicielle - l'identification perceptive des groupes ethniques auxquels les locuteurs s'identifient - pour determiner si les locuteurs produisent de la variation ethnolinguistique et si les auditeurs sont capables de la percevoir. Des echantillons de paroles ont ete enregistres avec trente individus de Metro Vancouver qui se sont identifies comme canadien chinois, est-indien, ou blanc. Ces enonces ont ete utilises pour une tache de perception dans laquelle les auditeurs ont classifie l'origine ethnique des locuteurs. Les reseaux sociaux des auditeurs ont ete etiquetes selon le groupe ethnique avec lequel ils rapportaient passer le plus de temps. Les analyses indiquent que, tandis que les locuteurs varient dans leur expression productive des ethnolectes, les choix d'etiquette des auditeurs sont coherents. La precision des auditeurs etait plus haute pour les voix de leur groupe social rapporte et pour les voix des blancs. Ces resultats suggerent que la familiarite avec des groupes ethniques a cause des reseaux sociaux et de la culture dominante influence la reconnaissance indicielle.
C1 [Wong, Phoebe; Babel, Molly] Univ British Columbia, Vancouver, BC, Canada.
RP Babel, M (corresponding author), Univ British Columbia, Linguist, Totem Field Studios, 2613 West Mall, Vancouver, BC V6T 1Z4, Canada.
EM molly.babel@ubc.ca
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Ball J, 2008, CLIN LINGUIST PHONET, V22, P570, DOI 10.1080/02699200802221620
   Battisti M, 2014, CAN PUBLIC POL, V40, P182, DOI 10.3138/cpp.2012-093
   Baxter Laura, 2013, P METH 14 PAP 14 INT, VXIV, P125
   Becker K, 2014, LANG COMMUN, V35, P43, DOI 10.1016/j.langcom.2013.12.007
   Benor SB, 2010, J SOCIOLING, V14, P159, DOI 10.1111/j.1467-9841.2010.00440.x
   Boberg C, 2004, J SOCIOLING, V8, P538, DOI 10.1111/j.1467-9841.2004.00273.x
   Boberg C, 2014, CAN J LING/REV CAN L, V59, P55
   Chambers J. K., 2006, WORLD ENGLISHES CRIT, V1, P383
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Clopper Cynthia G, 2006, Lang Var Change, V18, P193
   Clopper CG, 2006, SPEECH COMMUN, V48, P633, DOI 10.1016/j.specom.2005.09.010
   Clopper Cynthia G, 2004, Lang Var Change, V16, P31
   Clopper CG, 2009, J PHONETICS, V37, P436, DOI 10.1016/j.wocn.2009.07.004
   Clopper CG, 2008, LANG SPEECH, V51, P175, DOI 10.1177/0023830908098539
   De Wolf Gaelan T, 2004, OCCASIONAL PAPERS, V5
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Gessner Suzanne, 2014, REPORT STATUS BC 1 N
   Hack J, 2012, INT J SPEECH-LANG PA, V14, P509, DOI 10.3109/17549507.2012.718361
   Hall-Lew L., 2009, THESIS
   Hall-Lew Lauren, 2014, INDEXING AUTHENTICIT, P55
   Hanna D.B., 1997, U PENNSYLVANIA WORKI, V4, P141
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Hoffman MF, 2010, AM SPEECH, V85, P121, DOI 10.1215/00031283-2010-007
   Hoffman MF, 2010, LANG VAR CHANGE, V22, P37, DOI 10.1017/S0954394509990238
   Hung T. T. N., 2000, WORLD ENGLISH, V19, P337, DOI DOI 10.1111/1467-971X.00183
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Leung G, 2012, INT MULTILING RES J, V6, P104, DOI 10.1080/19313152.2011.651427
   Leyer Rhoda, 1972, N WIND SUN
   Luce R. D., 1963, HDB MATH PSYCHOL, P103
   MacDonald Bruce, 1992, VANCOUVER VISUAL HIS
   MacMillan N. A., 2005, DETECTION THEORY USE
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   McMillan Alan D., 2004, 1 PEOPLES CANADA
   Metro Vancouver, 2017, REG PLANN MAP
   MILROY J, 1985, J LINGUIST, V21, P339, DOI 10.1017/S0022226700010306
   Mok P, 2008, P SPEECH PROS 2008 C, V4, P423
   Nayar K. E., 2012, PUNJABIS BRIT COLUMB
   Nayar K.E., 2004, SIKH DIASPORA VANCOU
   Newman M, 2011, AM SPEECH, V86, P152, DOI 10.1215/00031283-1336992
   NG WING CHUNG, 1999, CHINESE VANCOUVER 19
   Purnell T, 1999, J LANG SOC PSYCHOL, V18, P10, DOI 10.1177/0261927X99018001002
   R Core Team, 2013, R LANG ENV STAT COMP
   Sharma D, 2011, LANG VAR CHANGE, V23, P399, DOI 10.1017/S0954394511000159
   Sharma D, 2011, J SOCIOLING, V15, P464, DOI 10.1111/j.1467-9841.2011.00503.x
   Silverstein M, 2003, LANG COMMUN, V23, P193, DOI 10.1016/S0271-5309(03)00013-2
   Suttles W., 1990, HDB N AM INDIANS, V7, P453
   Szakay A., 2007, THESIS
   Thomas ER, 2004, J SOCIOLING, V8, P54, DOI 10.1111/j.1467-9841.2004.00251.x
   Tuan M., 1998, FOREVER FOREIGNERS H
   Valdes G., 2000, LEARNING TEACHING SL, P375
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Wolfram W, 2007, LANG LINGUIST COMPAS, V1, P292, DOI 10.1111/j.1749-818x.2007.00016.x
   Wong Phoebe, 2014, THESIS
   Yee Paul, 2006, SALTWATER CITY ILLUS
NR 58
TC 2
Z9 2
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1360-6441
EI 1467-9841
J9 J SOCIOLING
JI J. Socioling.
PD NOV
PY 2017
VL 21
IS 5
BP 603
EP 628
DI 10.1111/josl.12264
PG 26
WC Linguistics
SC Linguistics
GA FM6GH
UT WOS:000415147600002
DA 2021-02-24
ER

PT J
AU Begby, E
AF Begby, Endre
TI Perceptual expansion under cognitive guidance: Lessons from language
   processing
SO MIND & LANGUAGE
LA English
DT Article
DE cognitive penetration; high-level perception; perception;
   perception-cognition interface; perceptual constancies; perceptual
   learning
ID THEORETICAL NEUTRALITY; CATEGORICAL PERCEPTION; SPEECH-PERCEPTION;
   DYSLEXIA; PLASTICITY
AB This paper aims to provide an empirically informed sketch of how our perceptual capacities can interact with cognitive processes to give rise to new perceptual attributives. In section 1, I present ongoing debates about the reach of perception and direct focus toward arguments offered in recent work by Tyler Burge and Ned Block. In section 2, I draw on empirical evidence relating to language processing to argue against the claim that we have no acquired, culture-specific, high-level perceptual attributives. In section 3, I turn to the cognitive dimension; I outline how cognitive procedures (including conceptual representation and explicit inference) can be involved in the acquisition of what ought to, nonetheless, be recognized as genuinely perceptual capacities. Finally, in section 4, I argue for the importance of distinguishing these conclusions from more familiar and radical claims about rampant cognitive penetration into the perceptual domain.
C1 [Begby, Endre] Simon Fraser Univ, Dept Philosophy, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
RP Begby, E (corresponding author), Simon Fraser Univ, Dept Philosophy, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
EM endre.begby@gmail.com
CR Baker SA, 2005, MEM COGNITION, V33, P887, DOI 10.3758/BF03193083
   Bayne T, 2009, PHILOS QUART, V59, P385, DOI 10.1111/j.1467-9213.2009.631.x
   Begby E., 2011, NOTRE DAME PHILOS RE, V2011
   Best CT, 2010, ATTEN PERCEPT PSYCHO, V72, P747, DOI 10.3758/APP.72.3.747
   Block N, 2014, PHILOS PHENOMEN RES, V89, P560, DOI 10.1111/phpr.12135
   Bolger P, 2009, WRIT LANG LIT, V12, P116, DOI 10.1075/wll.12.1.06bol
   Brogaard B, 2015, PAC PHILOS QUART, V96, P469, DOI 10.1111/papq.12111
   Brogaard B, 2013, PHILOS STUD, V162, P35, DOI 10.1007/s11098-012-9985-5
   Burge T., 2010, ORIGINS OBJECTIVITY
   Burge T, 2014, PHILOS PHENOMEN RES, V89, P573, DOI 10.1111/phpr.12136
   Cairns Helen S., 2010, FUNDAMENTALS PSYCHOL
   Casserly ED, 2010, WIRES COGN SCI, V1, P629, DOI 10.1002/wcs.63
   Castles A, 2014, MIND LANG, V29, P270, DOI 10.1111/mila.12050
   Castles A, 2010, WIRES COGN SCI, V1, P426, DOI 10.1002/wcs.16
   CHURCHLAND PM, 1988, PHILOS SCI, V55, P167, DOI 10.1086/289425
   Dehaene S, 2001, NAT NEUROSCI, V4, P752, DOI 10.1038/89551
   Dehaene S., 2009, READING BRAIN SCI EV
   Dretske F., 1995, NATURALIZING MIND
   Emmorey K, 2003, LANG COGNITIVE PROC, V18, P21, DOI 10.1080/01690960143000416
   Firestone C, 2016, BEHAV BRAIN SCI, P39
   Fish W, 2013, PHILOS STUD, V162, P43, DOI 10.1007/s11098-012-9986-4
   Fodor J.A., 1983, MODULARITY MIND ESSA
   FODOR JA, 1988, PHILOS SCI, V55, P188, DOI 10.1086/289426
   Fodor JA., 1974, PSYCHOL LANGUAGE INT
   Frith U, 1985, SURFACE DYSLEXIA NEU
   GIBSON EJ, 1962, AM J PSYCHOL, V75, P554, DOI 10.2307/1420279
   Goldstone RL, 2015, COGNITION, V135, P24, DOI 10.1016/j.cognition.2014.11.027
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Hannagan T, 2015, TRENDS COGN SCI, V19, P374, DOI 10.1016/j.tics.2015.05.006
   Hawley K., 2011, ADMISSIBLE CONTENTS
   Jusczyk PW, 2003, MIND, BRAIN, AND LANGUAGE: MULTIDISCIPLINARY PERSPECTIVES, P61
   Kluender K. R., 2006, HDB PSYCHOLINGUISTIC
   Krival K., 2011, ENCY CLIN NEUROPSYCH
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lupker SJ, 2012, J EXP PSYCHOL HUMAN, V38, P1491, DOI 10.1037/a0026886
   Macpherson F, 2012, PHILOS PHENOMEN RES, V84, P24, DOI 10.1111/j.1933-1592.2010.00481.x
   Marinus E, 2011, Q J EXP PSYCHOL, V64, P504, DOI 10.1080/17470218.2010.509803
   Masrour F, 2011, PHILOS PHENOMEN RES, V83, P366, DOI 10.1111/j.1933-1592.2010.00443.x
   McCandliss BD, 2003, TRENDS COGN SCI, V7, P293, DOI 10.1016/S1364-6613(03)00134-7
   O'Callaghan C, 2011, PHILOS QUART, V61, P783, DOI 10.1111/j.1467-9213.2011.704.x
   OCallaghan Casey, 2014, STANFORD ENCY PHILOS
   Ozernov-Palchik O, 2016, WIRES COGN SCI, V7, P156, DOI 10.1002/wcs.1383
   Pegado F, 2014, P NATL ACAD SCI USA, V111, pE5233, DOI 10.1073/pnas.1417347111
   Pinker S, 2005, COGNITION, V95, P201, DOI 10.1016/j.cognition.2004.08.004
   Polk TA, 2002, J EXP PSYCHOL GEN, V131, P65, DOI 10.1037//0096-3445.131.1.65
   Prinz J., 2005, COGNITION BRAIN PHIL
   Pylyshyn Z, 1999, BEHAV BRAIN SCI, V22, P341, DOI 10.1017/S0140525X99002022
   Pylyshyn Z. W., 1984, COMPUTATION COGNITIO
   Reid T., 1764, WORKS T REID, V1
   Reid T., 1785, WORKS T REID, V1
   Reiland I, 2014, AM PHILOS QUART, V51, P177
   Rey A, 2000, COGNITION, V75, pB1, DOI 10.1016/S0010-0277(99)00078-5
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Siegel S., 2010, CONTENTVISUAL EXPE
   Siegel S, 2006, PERCEPTUAL EXPERIENC
   Silins N, 2016, PHILOS COMPASS, V11, P24, DOI 10.1111/phc3.12292
   Stokes D, 2013, PHILOS COMPASS, V8, P646, DOI 10.1111/phc3.12043
   Trout JD, 2001, PSYCHOL REV, V108, P523, DOI 10.1037//0033-295X.108.3.523
   Tye M., 1995, 10 PROBLEMS CONSCIOU
   Watson MR, 2012, CONSCIOUS COGN, V21, P1533, DOI 10.1016/j.concog.2012.06.004
   Werker JF, 2002, INFANT BEHAV DEV, V25, P121, DOI 10.1016/S0163-6383(02)00093-0
   Zeimbekis John, 2015, COGNITIVE PENETRABIL
NR 63
TC 2
Z9 2
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0268-1064
EI 1468-0017
J9 MIND LANG
JI Mind Lang.
PD NOV
PY 2017
VL 32
IS 5
BP 564
EP 578
DI 10.1111/mila.12159
PG 15
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA FM6AM
UT WOS:000415126600003
DA 2021-02-24
ER

PT J
AU Hardy, CJD
   Hwang, YT
   Bond, RL
   Marshall, CR
   Ridha, BH
   Crutch, SJ
   Rossor, MN
   Warren, JD
AF Hardy, Chris J. D.
   Hwang, Yun T.
   Bond, Rebecca L.
   Marshall, Charles R.
   Ridha, Basil H.
   Crutch, Sebastian J.
   Rossor, Martin N.
   Warren, Jason D.
TI Donepezil enhances understanding of degraded speech in Alzheimer's
   disease
SO ANNALS OF CLINICAL AND TRANSLATIONAL NEUROLOGY
LA English
DT Article
ID DEMENTIA; MEMORY; PERCEPTION; MODULATION
AB Auditory dysfunction under complex, dynamic listening conditions is a clinical hallmark of Alzheimer's disease (AD) but challenging to measure and manage. Here, we assessed understanding of sinewave speech (a paradigm of degraded speech perception) and general cognitive abilities in 17 AD patients, before and following a 10 mg dose of donepezil. Relative to healthy older individuals, patients had impaired sinewave speech comprehension that was selectively ameliorated by donepezil. Our findings demonstrate impaired perception of degraded speech in AD but retained perceptual learning capacity that can be harnessed by acetylcholinesterase inhibition, with implications for designing communication interventions and acoustic environments in dementia.
C1 [Hardy, Chris J. D.; Hwang, Yun T.; Bond, Rebecca L.; Marshall, Charles R.; Ridha, Basil H.; Crutch, Sebastian J.; Rossor, Martin N.; Warren, Jason D.] UCL, Dementia Res Ctr, Dept Neurodegenerat Dis, Inst Neurol, London, England.
RP Warren, JD (corresponding author), UCL, Inst Neurol, Dementia Res Ctr, Queen Sq, London WC1N 3BG, England.
EM jason.warren@ucl.ac.uk
RI Rossor, Martin/C-1598-2008
OI Crutch, Sebastian/0000-0002-4160-0139; Hardy, Chris/0000-0002-4900-6492;
   Rossor, Martin/0000-0001-8215-3120; Marshall,
   Charles/0000-0002-8227-2354; Warren, Jason/0000-0002-5405-0826
FU Alzheimer's Research UKAlzheimer's Research UK (ARUK) [ART-SRF2010-3];
   Brain Research Trust; Wolfson Foundation; Alzheimer's Society
   [AS-PG-16-007]; National Institute for Health Research University
   College London Hospitals Biomedical Research Centre [CBRC 161]; UCL
   Leonard Wolfson Experimental Neurology Centre [PR/ylr/18575]; DANA
   Foundation; Medical Research CouncilUK Research & Innovation
   (UKRI)Medical Research Council UK (MRC)European Commission; Wellcome
   TrustWellcome TrustEuropean Commission [091673/Z/10/Z]; Medical Research
   CouncilUK Research & Innovation (UKRI)Medical Research Council UK (MRC)
   [MR/M009106/1, 1332624, 1332163] Funding Source: researchfish; National
   Institute for Health ResearchNational Institute for Health Research
   (NIHR) [NF-SI-0512-10033] Funding Source: researchfish
FX The Dementia Research Centre is supported by Alzheimer's Research UK,
   Brain Research Trust, and The Wolfson Foundation. This work was
   supported by the Alzheimer's Society (AS-PG-16-007), the National
   Institute for Health Research University College London Hospitals
   Biomedical Research Centre (CBRC 161), the UCL Leonard Wolfson
   Experimental Neurology Centre (PR/ylr/18575) and the DANA Foundation.
   Individual authors were supported by the Medical Research Council (PhD
   Studentships to CJDH and RLB), the Wolfson Foundation (Clinical Research
   Fellowship to CRM), Alzheimer's Research UK (ART-SRF2010-3 to SJC) and
   the Wellcome Trust (091673/Z/10/Z to JDW).
CR Bentley P, 2009, BRAIN, V132, P2356, DOI 10.1093/brain/awp176
   Dhanjal NS, 2013, ANN NEUROL, V73, P294, DOI 10.1002/ana.23789
   Dubois B, 2010, LANCET NEUROL, V9, P1118, DOI 10.1016/S1474-4422(10)70223-4
   Furey ML, 2000, SCIENCE, V290, P2315, DOI 10.1126/science.290.5500.2315
   Gates GA, 2011, ARCH OTOLARYNGOL, V137, P390, DOI 10.1001/archoto.2011.28
   GIBSON EJ, 1963, ANNU REV PSYCHOL, V14, P29, DOI 10.1146/annurev.ps.14.020163.000333
   Golden HL, 2015, NEUROIMAGE-CLIN, V7, P699, DOI 10.1016/j.nicl.2015.02.019
   Hailstone JC, 2012, NEUROPSYCHOLOGIA, V50, P2233, DOI 10.1016/j.neuropsychologia.2012.05.027
   Hailstone JC, 2011, BRAIN, V134, P2535, DOI 10.1093/brain/awr205
   Hardy CJD, 2016, J NEUROL, V263, P2339, DOI 10.1007/s00415-016-8208-y
   Herholz K, 2008, NEUROPSYCHOLOGIA, V46, P1642, DOI 10.1016/j.neuropsychologia.2007.11.024
   Hillenbrand JM, 2011, J ACOUST SOC AM, V129, P3991, DOI 10.1121/1.3573980
   Kim NG, 2010, NEUROPSYCHOLOGIA, V48, P1464, DOI 10.1016/j.neuropsychologia.2010.01.016
   Marsh JE, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00136
   Metherate R, 2011, NEUROSCI BIOBEHAV R, V35, P2058, DOI 10.1016/j.neubiorev.2010.11.010
   Moran RJ, 2013, J NEUROSCI, V33, P8227, DOI 10.1523/JNEUROSCI.4255-12.2013
   Pekkonen E, 2005, NEUROIMAGE, V27, P387, DOI 10.1016/j.neuroimage.2005.04.018
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Voss P, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/1801979
NR 20
TC 7
Z9 7
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2328-9503
J9 ANN CLIN TRANSL NEUR
JI Ann. Clin. Transl. Neurol.
PD NOV
PY 2017
VL 4
IS 11
BP 835
EP 840
DI 10.1002/acn3.471
PG 6
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA FM4EC
UT WOS:000414963500009
PM 29159197
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Havy, M
   Foroud, A
   Fais, L
   Werker, JF
AF Havy, Melanie
   Foroud, Afra
   Fais, Laurel
   Werker, Janet F.
TI The Role of Auditory and Visual Speech in Word Learning at 18Months and
   in Adulthood
SO CHILD DEVELOPMENT
LA English
DT Article
ID EARLY LEXICAL REPRESENTATIONS; AUDIOVISUAL SPEECH; 14-MONTH-OLD INFANTS;
   PERCEPTION; CONSONANTS; CHILDREN; VOWELS; RECOGNITION; INTEGRATION;
   CHILDHOOD
AB Visual information influences speech perception in both infants and adults. It is still unknown whether lexical representations are multisensory. To address this question, we exposed 18-month-old infants (n=32) and adults (n=32) to new word-object pairings: Participants either heard the acoustic form of the words or saw the talking face in silence. They were then tested on recognition in the same or the other modality. Both 18-month-old infants and adults learned the lexical mappings when the words were presented auditorily and recognized the mapping at test when the word was presented in either modality, but only adults learned new words in a visual-only presentation. These results suggest developmental changes in the sensory format of lexical representations.
C1 [Havy, Melanie; Foroud, Afra; Fais, Laurel; Werker, Janet F.] Univ British Columbia, Vancouver, BC, Canada.
   [Havy, Melanie] Univ Geneva, Geneva, Switzerland.
RP Havy, M (corresponding author), Univ Geneva, Geneva, Switzerland.; Havy, M (corresponding author), Univ Geneva, FAPSE, Blvd Pont dArve 40, CH-1211 Geneva 4, Switzerland.
EM melanie.havy@gmail.com
OI Werker, Janet F./0000-0002-1168-9013
FU Fyssen Foundation; Canada Institutes for Health Research (CIHR)
   Postdoctoral FellowshipCanadian Institutes of Health Research (CIHR);
   Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR;
   Canadian Institutes for Advanced Research (CIFAR); EUNICE KENNEDY
   SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child
   Health & Human Development (NICHD) [R21HD079260, R21HD079260] Funding
   Source: NIH RePORTER
FX We thank Eric Vatikiotis-Bateson for the use of his laboratory and
   equipment for video recording the audio-visual speech stimuli, Mark
   Scott for assistance with creating the words used in the study, Iris
   Ka-Ching Tung for assistance with video recording audio-visual speech
   stimuli, Meaghan Delaney for performing as the model for our stimuli,
   Haley Galvon for assistance with data analysis, and the Werker lab for
   their insight and comments throughout the design and implementation of
   the study. This work was in part funded by a Fyssen Foundation grant to
   Melanie Havy, a Canada Institutes for Health Research (CIHR)
   Postdoctoral Fellowship to Afra Foroud, and both a Discovery Grant from
   the Natural Sciences and Engineering Research Council of Canada to Janet
   F. Werker and funding from the National Institutes of Health to Janet F.
   Werker, as well as support from the Canadian Institutes for Advanced
   Research (CIFAR) to Janet F. Werker
CR Althaus N, 2015, COGNITION, V139, P1, DOI 10.1016/j.cognition.2015.02.004
   Baart M, 2015, J EXP CHILD PSYCHOL, V129, P157, DOI 10.1016/j.jecp.2014.08.002
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barutchu A, 2008, EUR J COGN PSYCHOL, V20, P1, DOI 10.1080/09541440601125623
   Bernstein LE, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00034
   BINNIE CA, 1974, J SPEECH HEAR RES, V17, P619, DOI 10.1044/jshr.1704.619
   Brancazio L, 2004, J EXP PSYCHOL HUMAN, V30, P445, DOI 10.1037/0096-1523.30.3.445
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Buchwald AB, 2009, LANG COGNITIVE PROC, V24, P580, DOI 10.1080/01690960802536357
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   DeCoster J., 2001, TRANSFORMING RESTRUC
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   Fort M, 2013, LANG COGNITIVE PROC, V28, P1207, DOI 10.1080/01690965.2012.701758
   Fort M, 2012, INT J BEHAV DEV, V36, P457, DOI 10.1177/0165025412447752
   Fort M, 2010, SPEECH COMMUN, V52, P525, DOI 10.1016/j.specom.2010.02.005
   Havy M., 2015, BOST U C LANG DEV BU
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Hazan V, 2006, J ACOUST SOC AM, V119, P1740, DOI 10.1121/1.2166611
   JACKSON PL, 1976, J SPEECH HEAR RES, V19, P796, DOI 10.1044/jshr.1904.796
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jerger S, 2014, J EXP CHILD PSYCHOL, V126, P295, DOI 10.1016/j.jecp.2014.05.003
   Jerger S, 2009, J EXP CHILD PSYCHOL, V102, P40, DOI 10.1016/j.jecp.2008.08.002
   Kim J, 2004, COGNITION, V93, pB39, DOI 10.1016/j.cognition.2003.11.003
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kushnerenko E, 2013, EUR J NEUROSCI, V38, P3363, DOI 10.1111/ejn.12317
   Lalonde K, 2015, J SPEECH LANG HEAR R, V58, P135, DOI 10.1044/2014_JSLHR-H-13-0343
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P249, DOI 10.1111/j.1467-7687.2010.00975.x
   Maidment DW, 2015, J SPEECH LANG HEAR R, V58, P61, DOI 10.1044/2014_JSLHR-S-14-0044
   Mani N, 2007, J MEM LANG, V57, P252, DOI 10.1016/j.jml.2007.03.005
   Mattys SL, 2002, PERCEPT PSYCHOPHYS, V64, P667, DOI 10.3758/BF03194734
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   Ostrand R., 2011, P ANN M COGN SCI SOC, P1376
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Samuel AG, 2014, J EXP PSYCHOL HUMAN, V40, P1479, DOI 10.1037/a0036656
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Sheehan EA, 2007, BRAIN LANG, V101, P246, DOI 10.1016/j.bandl.2006.11.008
   Soto-Faraco S., 2012, MULTISENSORY DEV, P435
   Streri A, 2016, INFANCY, V21, P177, DOI 10.1111/infa.12104
   Suanda SH, 2013, LANG LEARN DEV, V9, P50, DOI 10.1080/15475441.2012.723189
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Tye-Murray Nancy, 2007, Trends Amplif, V11, P233, DOI 10.1177/1084713807307409
   von Kriegstein K, 2008, P NATL ACAD SCI USA, V105, P6747, DOI 10.1073/pnas.0710826105
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   White KS, 2008, J MEM LANG, V59, P114, DOI 10.1016/j.jml.2008.03.001
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
NR 58
TC 8
Z9 8
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0009-3920
EI 1467-8624
J9 CHILD DEV
JI Child Dev.
PD NOV-DEC
PY 2017
VL 88
IS 6
BP 2043
EP 2059
DI 10.1111/cdev.12715
PG 17
WC Psychology, Educational; Psychology, Developmental
SC Psychology
GA FM0GZ
UT WOS:000414642100022
PM 28124795
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Ross, LA
   Del Bene, VA
   Molholm, S
   Woo, YJ
   Andrade, GN
   Abrahams, BS
   Foxe, JJ
AF Ross, Lars A.
   Del Bene, Victor A.
   Molholm, Sophie
   Woo, Young Jae
   Andrade, Gizely N.
   Abrahams, Brett S.
   Foxe, John J.
TI Common variation in the autism risk gene CNTNAP2, brain structural
   connectivity and multisensory speech integration
SO BRAIN AND LANGUAGE
LA English
DT Article
DE CNTNAP2; Autism; Speech perception in noise; Multisensory; Iffusion
   tensor imaging; Mediation analysis; Fractional anisotropy; Language;
   Genetics; Tract based spatial statistics; Development; Connectome
ID SPECTRUM DISORDER; LANGUAGE IMPAIRMENT; AUDIOVISUAL SPEECH;
   INTERINDIVIDUAL DIFFERENCES; BROCAS AREA; PERCEPTION; HEARING;
   IMITATION; CHILDREN; GESTURES
AB Three lines of evidence motivated this study. 1) CNTNAP2 variation is associated with autism risk and speech-language development. 2) CNTNAP2 variations are associated with differences in white matter (WM) tracts comprising the speech-language circuitry. 3) Children with autism show impairment in multisensory speech perception. Here, we asked whether an autism risk-associated CNTNAP2 single nucleotide polymorphism in neurotypical adults was associated with multisensory speech perception performance, and whether such a genotype-phenotype association was mediated through white matter tract integrity in speech-language circuitry. Risk genotype at rs7794745 was associated with decreased benefit from visual speech and lower fractional anisotropy (FA) in several WM tracts (right precentral gyrus, left anterior corona radiata, right retrolenticular internal capsule). These structural connectivity differences were found to mediate the effect of genotype on audiovisual speech perception, shedding light on possible pathogenic pathways in autism and biological sources of inter-individual variation in audiovisual speech processing in neurotypicals. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Ross, Lars A.; Del Bene, Victor A.; Molholm, Sophie; Andrade, Gizely N.; Foxe, John J.] Albert Einstein Coll Med, Dept Pediat, CERC, Sheryl & Daniel R Tishman Cognit Neurophysiol Lab, Bronx, NY 10461 USA.
   [Ross, Lars A.; Del Bene, Victor A.; Molholm, Sophie; Andrade, Gizely N.; Foxe, John J.] Montefiore Med Ctr, Bronx, NY 10461 USA.
   [Del Bene, Victor A.] Albert Einstein Coll Med, Ferkauf Grad Sch Psychol, Bronx, NY 10461 USA.
   [Woo, Young Jae; Abrahams, Brett S.] Albert Einstein Coll Med, Dept Genet, Bronx, NY 10461 USA.
   [Molholm, Sophie; Abrahams, Brett S.; Foxe, John J.] Albert Einstein Coll Med, Rose F Kennedy Intellectual & Dev Disabil Res Ctr, Dept Neurosci, Bronx, NY 10461 USA.
   [Foxe, John J.] Univ Rochester, Sch Med & Dent, Dept Neurosci, Ernest J Del Monte Inst Neurosci, Rochester, NY 14642 USA.
RP Ross, LA (corresponding author), Albert Einstein Coll Med, Dept Pediat, CERC, Sheryl & Daniel R Tishman Cognit Neurophysiol Lab, Bronx, NY 10461 USA.; Foxe, JJ (corresponding author), Montefiore Med Ctr, Bronx, NY 10461 USA.
EM lars.ross@einstein.yu.edu; john_foxe@urmc.rochester.edu
RI Del Bene, Victor/AAD-8017-2021
OI Woo, Young/0000-0002-9233-5099
FU U.S. National Institute of Mental HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute of Mental Health (NIMH) [NIMH RO1 MH085322]; Eunice
   Kennedy Shriver National Institute of Child Health & Human
   DevelopmentUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [NICHD U54
   HD090260]; Sheryl and Daniel R. Tishman Charitable Foundation; EUNICE
   KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [U54HD090260,
   U54HD090260, U54HD090260, U54HD090260, U54HD090260, U54HD090260,
   U54HD090260, U54HD090260, U54HD090260, U54HD090260, U54HD090260,
   U54HD090260, U54HD090260, U54HD090260, U54HD090260, U54HD090260,
   U54HD090260, U54HD090260, U54HD090260, U54HD090260, U54HD090260,
   U54HD090260, U54HD090260, U54HD090260, U54HD090260, U54HD090260,
   U54HD090260, U54HD090260, U54HD090260, U54HD090260, U54HD090260,
   U54HD090260, U54HD090260, U54HD090260, U54HD090260, U54HD090260,
   U54HD090260, U54HD090260, U54HD090260] Funding Source: NIH RePORTER;
   NATIONAL INSTITUTE OF MENTAL HEALTHUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) [R01MH085322, R01MH085322,
   R01MH085322, R01MH085322, R01MH085322] Funding Source: NIH RePORTER
FX This work was primarily supported by a grant from the U.S. National
   Institute of Mental Health (NIMH RO1 MH085322 to JJF and SM). The Human
   Clinical Phenotyping Core, where the participants enrolled in this study
   were recruited and evaluated, is a facility of the Rose F. Kennedy
   Intellectual and Developmental Disabilities Research Center (RFK-IDDRC)
   which is funded by a center grant from the Eunice Kennedy Shriver
   National Institute of Child Health & Human Development (NICHD U54
   HD090260). Ongoing support of The Cognitive Neurophysiology Laboratory
   at Einstein is provided through a grant from the Sheryl and Daniel R.
   Tishman Charitable Foundation.
CR Alarcon M, 2008, AM J HUM GENET, V82, P150, DOI 10.1016/j.ajhg.2007.09.005
   Anney R, 2012, HUM MOL GENET, V21, P4781, DOI 10.1093/hmg/dds301
   Arking DE, 2008, AM J HUM GENET, V82, P160, DOI 10.1016/j.ajhg.2007.09.015
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bernstein LE, 2001, J SPEECH LANG HEAR R, V44, P5, DOI 10.1044/1092-4388(2001/001)
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Bishop CW, 2009, J COGNITIVE NEUROSCI, V21, P1790, DOI 10.1162/jocn.2009.21118
   Boucher J, 2012, J CHILD PSYCHOL PSYC, V53, P219, DOI 10.1111/j.1469-7610.2011.02508.x
   Centanni TM, 2015, AM J MED GENET B, V168, P536, DOI 10.1002/ajmg.b.32325
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Dupont S, 2005, ZAS PAPERS LINGUISTI, V40, P1
   Eigsti IM, 2007, J AUTISM DEV DISORD, V37, P1007, DOI 10.1007/s10803-006-0239-2
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Feld JE, 2009, J SPEECH LANG HEAR R, V52, P1555, DOI 10.1044/1092-4388(2009/08-0137)
   Foxe J. J., 2013, CEREBRAL CORTEX
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   Gentilucci M, 2005, EXP BRAIN RES, V167, P66, DOI 10.1007/s00221-005-0008-z
   Hayes AF, 2009, COMMUN MONOGR, V76, P408, DOI 10.1080/03637750903310360
   Hayes AF, 2009, BEHAV RES METHODS, V41, P924, DOI 10.3758/BRM.41.3.924
   Herringshaw A., 2016, AUTISM RES
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Jeffers J., 1971, SPEECHREADING LIPREA
   Jenkinson M, 2001, MED IMAGE ANAL, V5, P143, DOI 10.1016/S1361-8415(01)00036-6
   Jin S., 2000, J ACOUST SOC AM, V107, P2888, DOI [10.1121/1.428736, DOI 10.1121/1.428736]
   Kos M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046995
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Lazenby DC, 2016, J AUTISM DEV DISORD, V46, P899, DOI 10.1007/s10803-015-2632-1
   Lyxell B, 2000, BRIT J EDUC PSYCHOL, V70, P505, DOI 10.1348/000709900158272
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   Mcgurk Harry, 1976, HEARING LIPS SEEING
   MELTZOFF AN, 1977, SCIENCE, V198, P75, DOI 10.1126/science.198.4312.75
   MELTZOFF AN, 1983, CHILD DEV, V54, P702, DOI 10.2307/1130058
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Miniscalco C, 2014, INT J LANG COMM DIS, V49, P369, DOI 10.1111/1460-6984.12085
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   Newbury DF, 2011, BEHAV GENET, V41, P90, DOI 10.1007/s10519-010-9424-3
   Newbury DF, 2005, TRENDS COGN SCI, V9, P528, DOI 10.1016/j.tics.2005.09.002
   Nishitani N, 2002, NEURON, V36, P1211, DOI 10.1016/S0896-6273(02)01089-9
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Olson IR, 2015, DEV COGN NEUROS-NETH, V14, P50, DOI 10.1016/j.dcn.2015.06.003
   Olson IR, 2002, COGNITIVE BRAIN RES, V14, P129, DOI 10.1016/S0926-6410(02)00067-8
   Paulesu E, 2003, J NEUROPHYSIOL, V90, P2005, DOI 10.1152/jn.00926.2002
   Peter B, 2011, J NEURODEV DISORD, V3, P39, DOI 10.1007/s11689-010-9065-0
   Petrin AL, 2010, AM J MED GENET A, V152A, P3164, DOI 10.1002/ajmg.a.33749
   Poot M, 2010, NEUROGENETICS, V11, P81, DOI 10.1007/s10048-009-0205-1
   Preacher KJ, 2004, BEHAV RES METH INS C, V36, P717, DOI 10.3758/BF03206553
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   Rhone AE, 2016, LANG COGN NEUROSCI, V31, P284, DOI 10.1080/23273798.2015.1101145
   Rodenas-Cuadrado P, 2016, BMC MED GENET, V17, DOI 10.1186/s12881-016-0272-8
   Rodenas-Cuadrado P, 2014, EUR J HUM GENET, V22, P171, DOI 10.1038/ejhg.2013.100
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ross LA, 2007, SCHIZOPHR RES, V97, P173, DOI 10.1016/j.schres.2007.08.008
   Ross LA, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00185
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Scott-Van Zeeland AA, 2010, SCI TRANSL MED, V2, DOI 10.1126/scitranslmed.3001344
   Seery AM, 2013, DEV COGN NEUROS-NETH, V5, P10, DOI 10.1016/j.dcn.2012.11.007
   Shtyrov Y, 2005, NEUROIMAGE, V27, P37, DOI 10.1016/j.neuroimage.2005.02.003
   Skipper JI, 2007, BRAIN LANG, V101, P260, DOI 10.1016/j.bandl.2007.02.008
   Smith S, 2007, TR07A1 FMRIB U OXF
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Smith SM, 2006, NEUROIMAGE, V31, P1487, DOI 10.1016/j.neuroimage.2006.02.024
   Smith SM, 2009, NEUROIMAGE, V44, P83, DOI 10.1016/j.neuroimage.2008.03.061
   Strauss KA, 2006, NEW ENGL J MED, V354, P1370, DOI 10.1056/NEJMoa052773
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   Tye-Murray N, 2014, J SPEECH LANG HEAR R, V57, P556, DOI 10.1044/2013_JSLHR-H-12-0273
   Tzourio-Mazoyer N, 2016, CORTEX
   Vernes SC, 2008, NEW ENGL J MED, V359, P2337, DOI 10.1056/NEJMoa0802828
   von Hohenberg CC, 2013, J PSYCHIATR RES, V47, P1349, DOI 10.1016/j.jpsychires.2013.07.002
   Voyles R, 2001, INT ROB SYST 2001 P
   Whalley HC, 2011, AM J MED GENET B, V156B, P941, DOI 10.1002/ajmg.b.31241
   Whitehouse AJO, 2011, GENES BRAIN BEHAV, V10, P451, DOI 10.1111/j.1601-183X.2011.00684.x
   Zambrana IM, 2013, CHILD DEV, V84, P560, DOI 10.1111/j.1467-8624.2012.01872.x
NR 77
TC 4
Z9 4
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD NOV
PY 2017
VL 174
BP 50
EP 60
DI 10.1016/j.bandl.2017.07.005
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA FI8LJ
UT WOS:000412253800006
PM 28738218
DA 2021-02-24
ER

PT J
AU Dufour, S
   Nguyen, N
AF Dufour, Sophie
   Nguyen, Noel
TI Does Talker-Specific Information Influence Lexical Competition? Evidence
   From Phonological Priming
SO COGNITIVE SCIENCE
LA English
DT Article
DE Spoken word recognition; Lexical competition; Abstract representations;
   Talker-specific representations; Phonological priming
ID SPOKEN WORD-RECOGNITION; SPEECH-PERCEPTION; AUDITORY WORD; ACCESS;
   MODEL; DYNAMICS; TARGETS; BIAS; FORM
AB In this study, we examined whether the lexical competition process embraced by most models of spoken word recognition is sensitive to talker-specific information. We used a lexical decision task and a long lag priming experiment in which primes and targets sharing all phonemes except the last one (e.g., /bagaR/fight vs. /baga?/luggage) were presented in two separate blocks of stimuli. In Experiment 1, the competitor prime block was presented only once to listeners, and no modulation of the competitor priming effect as a function of a talker change between the primes and targets was observed. However, attenuation in the competitor priming effect in the case of a talker change between the primes and targets was observed in Experiment 2 in which the competitor prime block was presented five times to listeners. We discuss our findings in reference to hybrid models of spoken word recognition in which repetition of words with the same talker could be a key factor in the formation and access to talker-dependent representations.
C1 [Dufour, Sophie; Nguyen, Noel] Aix Marseille Univ, CNRS, UMR 7309, LPL, Aix En Provence, France.
   [Dufour, Sophie; Nguyen, Noel] Aix Marseille Univ, Brain & Language Res Inst, Aix En Provence, France.
RP Dufour, S (corresponding author), Aix Marseille Univ, CNRS, Lab Parole & Langage, 5 Ave Pasteur, F-13604 Aix En Provence, France.
EM sophie.dufour@lpl-aix.fr
RI Nguyen, Noel/R-5231-2017
OI Nguyen, Noel/0000-0003-3424-5340
CR Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Davis MH, 2009, J COGNITIVE NEUROSCI, V21, P803, DOI 10.1162/jocn.2009.21059
   Dufour S, 2003, MEM COGNITION, V31, P1271, DOI 10.3758/BF03195810
   Dufour S, 2003, COGNITION, V88, pB33, DOI 10.1016/S0010-0277(03)00046-5
   Dufour S, 2002, ANN PSYCHOL, V102, P725
   Dufour S, 2014, J COGN PSYCHOL, V26, P256, DOI 10.1080/20445911.2014.890204
   Dumay N, 2007, PSYCHOL SCI, V18, P35, DOI 10.1111/j.1467-9280.2007.01845.x
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   GOLDINGER SD, 1992, J EXP PSYCHOL LEARN, V18, P1211, DOI 10.1037/0278-7393.18.6.1211
   Grossberg S, 2000, PSYCHOL REV, V107, P735, DOI 10.1037//0033-295X.107.4.735
   GROSSBERG S, 1986, PSYCHOL REV, V93, P46, DOI 10.1037/0033-295X.93.1.46
   GROSSBERG S, 1986, PATTERN RECOGN, V1, P187, DOI DOI 10.1037/0033-295X.93.1.46
   Hamburger M, 1996, PSYCHON B REV, V3, P520, DOI 10.3758/BF03214558
   Hamburger M, 1999, PSYCHON B REV, V6, P352, DOI 10.3758/BF03212341
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   LUCE PA, 1990, ACL MIT NAT, P122
   Maibauer AM, 2014, ATTEN PERCEPT PSYCHO, V76, P11, DOI 10.3758/s13414-013-0600-4
   MarslenWilson W, 1996, J EXP PSYCHOL HUMAN, V22, P1376, DOI 10.1037/0096-1523.22.6.1376
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McLennan CT, 2012, ATTEN PERCEPT PSYCHO, V74, P824, DOI 10.3758/s13414-012-0315-y
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   Monsell S, 1998, J EXP PSYCHOL LEARN, V24, P1495, DOI 10.1037/0278-7393.24.6.1495
   MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   POSNER MI, 1970, J EXP PSYCHOL, V83, P304, DOI 10.1037/h0028558
   RADEAU M, 1995, J EXP PSYCHOL HUMAN, V21, P1297, DOI 10.1037/0096-1523.21.6.1297
   SCHACTER DL, 1978, J VERB LEARN VERB BE, V17, P721, DOI 10.1016/S0022-5371(78)90443-7
   SLOWIACZEK LM, 1992, J EXP PSYCHOL LEARN, V18, P1239, DOI 10.1037/0278-7393.18.6.1239
NR 30
TC 4
Z9 4
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD NOV
PY 2017
VL 41
IS 8
BP 2221
EP 2233
DI 10.1111/cogs.12472
PG 13
WC Psychology, Experimental
SC Psychology
GA FL5ZC
UT WOS:000414324000008
PM 27943403
OA Bronze
DA 2021-02-24
ER

PT J
AU Ylinen, S
   Bosseler, A
   Junttila, K
   Huotilainen, M
AF Ylinen, Sari
   Bosseler, Alexis
   Junttila, Katja
   Huotilainen, Minna
TI Predictive coding accelerates word recognition and learning in the early
   stages of language development
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID MISMATCH NEGATIVITY; COGNITIVE-PROCESSES; CORTICAL RESPONSES;
   SOCIAL-INTERACTION; SPEECH-PERCEPTION; AUDITORY-CORTEX; SPOKEN WORDS;
   INFANTS; ATTENTION; BRAIN
AB The ability to predict future events in the environment and learn from them is a fundamental component of adaptive behavior across species. Here we propose that inferring predictions facilitates speech processing and word learning in the early stages of language development. Twelve- and 24-month olds' electrophysiological brain responses to heard syllables are faster and more robust when the preceding word context predicts the ending of a familiar word. For unfamiliar, novel word forms, however, word-expectancy violation generates a prediction error response, the strength of which significantly correlates with children's vocabulary scores at 12 months. These results suggest that predictive coding may accelerate word recognition and support early learning of novel words, including not only the learning of heard word forms but also their mapping to meanings. Prediction error may mediate learning via attention, since infants' attention allocation to the entire learning situation in natural environments could account for the link between prediction error and the understanding of word meanings. On the whole, the present results on predictive coding support the view that principles of brain function reported across domains in humans and non-human animals apply to language and its development in the infant brain. A video abstract of this article can be viewed at: http://hy.fi/unitube/video/e1cbb495-41d8-462e-8660-0864a1abd02c. [Correction added on 27 January 2017, after first online publication: The video abstract link was added.]
C1 [Ylinen, Sari; Bosseler, Alexis; Junttila, Katja; Huotilainen, Minna] Univ Helsinki, Inst Behav Sci, Cognit Brain Res Unit, POB 9, FIN-00014 Helsinki, Finland.
   [Huotilainen, Minna] Finnish Inst Occupat Hlth, Helsinki, Finland.
RP Ylinen, S (corresponding author), Univ Helsinki, Inst Behav Sci, Cognit Brain Res Unit, POB 9, FIN-00014 Helsinki, Finland.
EM sari.ylinen@helsinki.fi
RI ; Ylinen, Sari/B-5942-2015
OI Junttila, Katja/0000-0003-1841-7560; Ylinen, Sari/0000-0001-5897-3030;
   Huotilainen, Minna/0000-0002-7251-6984
FU Academy of FinlandAcademy of FinlandEuropean Commission [131963, 274058,
   268231]
FX The authors thank the participants and their families, Miika Leminen and
   Tommi Makkonen for technical assistance, Jenni Vare and Leena Wallendahr
   for assistance with the recordings, and two anonymous reviewers for
   constructive comments on the manuscript. This work was supported by the
   Academy of Finland (grant numbers 131963, 274058, and 268231).
CR Basirat A, 2014, COGNITION, V132, P137, DOI 10.1016/j.cognition.2014.03.013
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Cartmill EA, 2013, P NATL ACAD SCI USA, V110, P11278, DOI 10.1073/pnas.1309518110
   Conboy BT, 2011, DEVELOPMENTAL SCI, V14, P242, DOI 10.1111/j.1467-7687.2010.00973.x
   Fenson L., 1994, MONOGRAPHS SOC RES C, V59, P242
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fernald A, 2001, CHILD DEV, V72, P1003, DOI 10.1111/1467-8624.00331
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015
   Garagnani M, 2008, EUR J NEUROSCI, V27, P492, DOI 10.1111/j.1460-9568.2008.06015.x
   Garagnani M, 2011, NEUROIMAGE, V54, P170, DOI 10.1016/j.neuroimage.2010.08.031
   Garagnani M, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.010.2009
   Goldstein MH, 2003, P NATL ACAD SCI USA, V100, P8030, DOI 10.1073/pnas.1332441100
   Haden GP, 2015, BRAIN RES, V1626, P14, DOI 10.1016/j.brainres.2015.02.048
   He C, 2009, NEUROPSYCHOLOGIA, V47, P218, DOI 10.1016/j.neuropsychologia.2008.07.019
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   Lyytinen P., 1999, COMMUNICATIVE LANGUA
   MacGregor LJ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1715
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Mills DL, 2005, COGNITIVE DEV, V20, P19, DOI 10.1016/j.cogdev.2004.07.001
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 2010, BRAIN RES REV, V64, P123, DOI 10.1016/j.brainresrev.2010.03.001
   Pernet CR, 2013, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00606
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Pouget A, 2013, NAT NEUROSCI, V16, P1170, DOI 10.1038/nn.3495
   Pulvermuller F, 1999, BEHAV BRAIN SCI, V22, P253, DOI 10.1017/S0140525X9900182X
   Pulvermuller F, 2001, NEUROIMAGE, V14, P607, DOI 10.1006/nimg.2001.0864
   Pulvermuller F, 2004, PSYCHOPHYSIOLOGY, V41, P106, DOI 10.1111/j.1469-8986.2003.00135.x
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sanders LD, 2006, NEUROPSYCHOLOGIA, V44, P2126, DOI 10.1016/j.neuropsychologia.2005.10.007
   Schroger E, 2015, EUR J NEUROSCI, V41, P641, DOI 10.1111/ejn.12816
   Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   Steinberg EE, 2013, NAT NEUROSCI, V16, P966, DOI 10.1038/nn.3413
   Tomasello M, 2009, CAMB HB LANG LINGUIS, P69
   Trainor LJ, 2012, INT J PSYCHOPHYSIOL, V83, P256, DOI 10.1016/j.ijpsycho.2011.12.008
   Travis KE, 2011, CEREB CORTEX, V21, P1832, DOI 10.1093/cercor/bhq259
   Verboven S, 2005, CHEMOMETR INTELL LAB, V75, P127, DOI 10.1016/j.chemolab.2004.06.003
   Wacongne C, 2011, P NATL ACAD SCI USA, V108, P20754, DOI 10.1073/pnas.1117807108
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Ylinen S, 2016, BRAIN LANG, V162, P72, DOI 10.1016/j.bandl.2016.08.007
NR 49
TC 10
Z9 10
U1 3
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD NOV
PY 2017
VL 20
IS 6
AR e12472
DI 10.1111/desc.12472
PG 13
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA FL0KT
UT WOS:000413901000015
PM 27747989
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Fernandez, LM
   Macaluso, E
   Soto-Faraco, S
AF Moris Fernandez, Luis
   Macaluso, Emiliano
   Soto-Faraco, Salvador
TI Audiovisual Integration as Conflict Resolution: The Conflict of the
   McGurk Illusion
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE speech perception; audiovisual speech; multisensory integration;
   illusion; McGurk illusion; gyrus cinguli; prefrontal cortex; magnetic
   resonance imaging
ID ANTERIOR CINGULATE CORTEX; SPEECH-PERCEPTION; SPATIAL ATTENTION;
   VISUAL-ATTENTION; SEEING VOICES; HEARING LIPS; NEURAL BASIS; FMRI;
   INFORMATION; DISCRIMINATION
AB There are two main behavioral expressions of multisensory integration (MSI) in speech; the perceptual enhancement produced by the sight of the congruent lip movements of the speaker, and the illusory sound perceived when a speech syllable is dubbed with incongruent lip movements, in the McGurk effect. These two models have been used very often to study MSI. Here, we contend that, unlike congruent audiovisually (AV) speech, the McGurk effect involves brain areas related to conflict detection and resolution. To test this hypothesis, we used fMRI to measure blood oxygen level dependent responses to AV speech syllables. We analyzed brain activity as a function of the nature of the stimuli-McGurk or non-McGurk-and the perceptual outcome regarding MSI-integrated or not integrated responsein a 2 x 2 factorial design. The results showed that, regardless of perceptual outcome, AV mismatch activated general-purpose conflict areas (e.g., anterior cingulate cortex) as well as specific AV speech conflict areas (e.g., inferior frontal gyrus), compared with AV matching stimuli. Moreover, these conflict areas showed stronger activation on trials where the McGurk illusion was perceived compared with non-illusory trials, despite the stimuli where physically identical. We conclude that the AV incongruence in McGurk stimuli triggers the activation of conflict processing areas and that the process of resolving the cross-modal conflict is critical for the McGurk illusion to arise. (C) 2017 Wiley Periodicals, Inc.
C1 [Moris Fernandez, Luis; Soto-Faraco, Salvador] Univ Pompeu Fabra, Ctr Brain & Cognit, Multisensory Res Grp, Barcelona, Spain.
   [Macaluso, Emiliano] Santa Lucia Fdn, Neuroimaging Lab, Rome, Italy.
   [Macaluso, Emiliano] CNRS 5292, Lyon Neurosci Res Ctr, INSERM 1028, UCBL1,ImpAct Team, Lyon, France.
   [Soto-Faraco, Salvador] Inst Catalana Recerca & Estudis Avancats ICREA, Barcelona, Spain.
RP Fernandez, LM (corresponding author), Dept Tecnol Informacio & Comunicac, Off 24-516,C Ramon Trias Fargas 25-27, Barcelona 08005, Spain.
EM luis.moris.fernandez@gmail.com
RI Macaluso, Emiliano/AAE-9185-2019; Fernandez, Luis Moris/AAQ-2418-2020;
   Macaluso, Emiliano/H-3139-2017
OI Macaluso, Emiliano/0000-0002-1919-5288; Fernandez, Luis
   Moris/0000-0001-5247-7503; Macaluso, Emiliano/0000-0002-1919-5288
FU Ministerio de Economia y CompetitividadSpanish Government
   [PSI2016-75558-PAEI/FEDER]; AGAUR Generalitat de CatalunyaAgencia de
   Gestio D'Ajuts Universitaris de Recerca Agaur (AGAUR)Generalitat de
   Catalunya [2014SGR856, 2012BE100392]; European Research CouncilEuropean
   Research Council (ERC)European Commission [StG-2010 263145]; Italian
   Ministry of HealthMinistry of Health, Italy; program "Investissements
   d'Avenir"French National Research Agency (ANR) [ANR-11-IDEX0007];
   program "BQR Accueil EC 16" of University Claude Bernard Lyon 1
FX This research was supported by the Ministerio de Economia y
   Competitividad (PSI2016-75558-PAEI/FEDER), AGAUR Generalitat de
   Catalunya (2014SGR856 and 2012BE100392), and the European Research
   Council (StG-2010 263145). The Neuroimaging Laboratory of the Fondazione
   Santa Lucia is supported by the Italian Ministry of Health. EM is
   supported by the program "Investissements d'Avenir" (ANR-11-IDEX0007)
   and by the program "BQR Accueil EC 16" of University Claude Bernard Lyon
   1.
CR Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2017, MULTISENS R IN PRESS
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Andersen TS, 2009, SPEECH COMMUN, V51, P184, DOI 10.1016/j.specom.2008.07.004
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   BERNSTEIN LE, 2004, HDB MULTISENSORY PRO, P203
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Bernstein LE, 2008, BRAIN RES, V1242, P172, DOI 10.1016/j.brainres.2008.04.018
   Bhaganagarapu K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00343
   Brett M., 2002, 8 INT C FUNCT MAPP H
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   DEKLE DJ, 1992, PERCEPT PSYCHOPHYS, V51, P355, DOI 10.3758/BF03211629
   Fairhall SL, 2009, EUR J NEUROSCI, V29, P1247, DOI 10.1111/j.1460-9568.2009.06688.x
   Freeman ED, 2013, CORTEX, V49, P2875, DOI 10.1016/j.cortex.2013.03.006
   GREEN KP, 1991, J EXP PSYCHOL HUMAN, V17, P278, DOI 10.1037/0096-1523.17.1.278
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Hasson U, 2007, NEURON, V56, P1116, DOI 10.1016/j.neuron.2007.09.037
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Jordan TR, 2000, PERCEPT PSYCHOPHYS, V62, P1394, DOI 10.3758/BF03212141
   Keil J, 2014, CEREB CORTEX, V24, P1278, DOI 10.1093/cercor/bhs409
   Keil J, 2012, CEREB CORTEX, V22, P221, DOI 10.1093/cercor/bhr125
   Kislyuk DS, 2008, J COGNITIVE NEUROSCI, V20, P2175, DOI 10.1162/jocn.2008.20152
   Lange J, 2014, BEHAV BRAIN RES, V271, P294, DOI 10.1016/j.bbr.2014.06.015
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   Massaro DW, 1998, AM SCI, V86, P236, DOI 10.1511/1998.25.861
   Matchin W, 2014, J COGNITIVE NEUROSCI, V26, P606, DOI 10.1162/jocn_a_00515
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Fernandez LM, 2015, NEUROIMAGE, V119, P272, DOI 10.1016/j.neuroimage.2015.06.052
   Mottonen R, 2002, COGNITIVE BRAIN RES, V13, P417, DOI 10.1016/S0926-6410(02)00053-8
   Nahorna O, 2012, J ACOUST SOC AM, V132, P1061, DOI 10.1121/1.4728187
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nee DE, 2007, COGN AFFECT BEHAV NE, V7, P1, DOI 10.3758/CABN.7.1.1
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Orr JM, 2009, CEREB CORTEX, V19, P703, DOI 10.1093/cercor/bhn119
   Pekkola J, 2006, NEUROIMAGE, V29, P797, DOI 10.1016/j.neuroimage.2005.09.069
   Roberts KL, 2008, J COGNITIVE NEUROSCI, V20, P1063, DOI 10.1162/jocn.2008.20074
   Romero YR, 2015, J NEUROPHYSIOL, V113, P2342, DOI 10.1152/jn.00783.2014
   ROSENBLUM LD, 1992, PERCEPT PSYCHOPHYS, V52, P461, DOI 10.3758/BF03206706
   Sams M, 1998, SPEECH COMMUN, V26, P75, DOI 10.1016/S0167-6393(98)00051-X
   Seghier ML, 2013, NEUROSCIENTIST, V19, P43, DOI 10.1177/1073858412440596
   Shenhav A, 2013, NEURON, V79, P217, DOI 10.1016/j.neuron.2013.07.007
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Soto-Faraco S, 2005, PSYCHON B REV, V12, P1024, DOI 10.3758/BF03206438
   Soto-Faraco S, 2004, COGNITION, V92, pB13, DOI 10.1016/j.cognition.2003.10.005
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   SUMMERFIELD Q, 1984, Q J EXP PSYCHOL-A, V36, P51, DOI 10.1080/14640748408401503
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Szycik GR, 2009, HUM BRAIN MAPP, V30, P1990, DOI 10.1002/hbm.20640
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tiippana K, 2011, SEEING PERCEIVING, V24, P67, DOI 10.1163/187847511X557308
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Weissman DH, 2004, J NEUROSCI, V24, P10941, DOI 10.1523/JNEUROSCI.3669-04.2004
   Wilson AH, 2016, J SPEECH LANG HEAR R, V59, P601, DOI 10.1044/2016_JSLHR-S-15-0092
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Zimmer U, 2010, NEUROIMAGE, V52, P606, DOI 10.1016/j.neuroimage.2010.04.245
NR 71
TC 14
Z9 15
U1 0
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD NOV
PY 2017
VL 38
IS 11
BP 5691
EP 5705
DI 10.1002/hbm.23758
PG 15
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA FJ2JX
UT WOS:000412553900025
PM 28792094
OA Bronze, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Shi, RS
   Santos, E
   Gao, J
   Li, AJ
AF Shi, Rushen
   Santos, Elsa
   Gao, Jun
   Li, Aijun
TI Perception of Similar and Dissimilar Lexical Tones by Non-Tone-Learning
   Infants
SO INFANCY
LA English
DT Article
ID MANDARIN CHINESE TONES; SPEECH-PERCEPTION; NONNATIVE LISTENERS; PHONETIC
   PERCEPTION; LANGUAGE EXPERIENCE; FRENCH LISTENERS; 1ST YEAR;
   REORGANIZATION; DISCRIMINATION; IDENTIFICATION
AB This study examined the perception of Mandarin lexical tones by non-tone-learning infants. We tested French-learning 4-, 8-, and 11-month-olds on Tone 2 (rising) versus Tone 3 (dipping), the most acoustically similar contrast in Mandarin, and on Tone 1 (high) versus Tone 4 (falling), acoustically more dissimilar contrast. We hypothesized that sensitivity should decline with age for the similar contrast, and the dissimilar contrast should remain more discriminable. Infants were habituated to one tone and tested with the same tone versus the contrastive tone. Results showed that the dissimilar T1-T4 contrast was consistently discriminated by all three ages, whereas the discrimination of the similar T2-T3 contrast revealed a tendency to decline over the ages. These results suggest that relative to consonants and vowels, perceptual sensitivity to lexical tones remains stronger in non-tone-learning infants. Discrimination of lexical tones is affected by both acoustic salience and perceptual attunement to the native-language phonology.
C1 [Shi, Rushen; Santos, Elsa] Univ Quebec, Montreal, PQ, Canada.
   [Gao, Jun; Li, Aijun] Chinese Acad Social Sci, Inst Linguist, Beijing, Peoples R China.
RP Shi, RS (corresponding author), Univ Quebec, Dept Psychol, CP 8888,Succursale Ctr Ville, Montreal, PQ H3C 3P8, Canada.
EM shi.rushen@uqam.ca
FU CFI (Canadian Foundation for Innovation)Canada Foundation for
   Innovation; NSERC (Natural Sciences and Engineering Research Council of
   Canada)Natural Sciences and Engineering Research Council of Canada
   (NSERC); SSHRC (Social Sciences and Humanities Research Council of
   Canada)Social Sciences and Humanities Research Council of Canada
   (SSHRC); China Scholarship CouncilChina Scholarship Council
FX This research was supported by CFI (Canadian Foundation for Innovation),
   NSERC (Natural Sciences and Engineering Research Council of Canada), and
   SSHRC (Social Sciences and Humanities Research Council of Canada) grants
   to the first author. The third author received a scholarship from the
   China Scholarship Council for this work. We are grateful to Andre Achim
   for his valuable assistance on data analysis. We thank all the families
   who participated in the study.
CR Best C., 1995, SPEECH PERCEPTION LI, P171
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lee CY, 2010, LANG SPEECH, V53, P217, DOI 10.1177/0023830909357160
   Li XQ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143097
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Pierce LJ, 2014, P NATL ACAD SCI USA, V111, P17314, DOI 10.1073/pnas.1409411111
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   SHEN XNS, 1991, LANG SPEECH, V34, P145, DOI 10.1177/002383099103400202
   Shi RS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01117
   Singh L, 2017, J CHILD LANG, V44, P924, DOI 10.1017/S0305000916000325
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Tsao F.-M., 2008, CHINESE J PSYCHOL, V50, P111, DOI [10.6129/CJP.2008.5002.01, DOI 10.6129/CJP.2008.5002.01]
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Xu Y, 2001, SPEECH COMMUN, V33, P319, DOI 10.1016/S0167-6393(00)00063-7
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE
NR 27
TC 7
Z9 7
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD NOV-DEC
PY 2017
VL 22
IS 6
BP 790
EP 800
DI 10.1111/infa.12191
PG 11
WC Psychology, Developmental
SC Psychology
GA FJ6TL
UT WOS:000412890800005
DA 2021-02-24
ER

PT J
AU Chen, F
   Peng, G
   Yan, N
   Wang, L
AF Chen, Fei
   Peng, Gang
   Yan, Nan
   Wang, Lan
TI The development of categorical perception of Mandarin tones in four- to
   seven-year-old children
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
ID SPEECH-PERCEPTION; LANGUAGE EXPERIENCE; PHONETIC PERCEPTION; LEXICAL
   TONES; DISCRIMINATION; PITCH; ACQUISITION; CHINESE; CANTONESE;
   IDENTIFICATION
AB To track the course of development in children's fine-grained perception of Mandarin tones, the present study explored how categorical perception (CP) of Mandarin tones emerges along age among 70 four- to seven-year-old children and 16 adults. Prominent discrimination peaks were found for both the child and the adult groups, and they were well aligned with the corresponding identification crossovers. Moreover, six-year-olds showed a much narrower width (i.e. a sharper slope) compared to younger children, and have already acquired adult-like identification competence of Mandarin high-level and mid-rising tones. Although the ability to discriminate within-category tone pairs did not change, the between-category discrimination accuracies were positively correlated with chronological ages among child participants. We assume that the perceptual refinement of Mandarin tones in young children may be driven by an accumulation of perceptual development from the tonal information of the ambient sound input.
C1 [Chen, Fei; Peng, Gang; Yan, Nan; Wang, Lan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Key Lab Human Machine Intelligence Synergy Syst, Shenzhen, Peoples R China.
   [Peng, Gang] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Hong Kong, Peoples R China.
RP Yan, N (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Key Lab Human Machine Intelligence Synergy Syst, Shenzhen, Peoples R China.; Peng, G (corresponding author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Hong Kong, Peoples R China.
EM gpengjack@gmail.com; nan.yan@siat.ac.cn
RI Chen, Fei/G-4674-2018
OI Chen, Fei/0000-0002-6988-492X; Peng, Gang/0000-0002-1465-1301; CHEN,
   Fei/0000-0002-4500-2590
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61135003, 11474300, 91420301];
   Shenzhen Speech Rehabilitation Technology Laboratory; Shenzhen
   Fundamental Research Program [JCYJ20130401170306806]
FX This work was partially supported by grants from National Natural
   Science Foundation of China (NSFC: 61135003, 11474300, 91420301),
   Shenzhen Speech Rehabilitation Technology Laboratory, and Shenzhen
   Fundamental Research Program JCYJ20130401170306806. We thank all the
   child participants, from Guangming Central Kindergarten, Taoyuan
   Secondary Kindergarten, and Taoyuan Zhuoya Primary School, and their
   parents, for their participation and cooperation.
CR Bent T, 2006, J EXP PSYCHOL HUMAN, V32, P97, DOI 10.1037/0096-1523.32.1.97
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Boersma P., 2009, PRAAT DOING PHONETIC
   Chao Y. R., 1951, SEMITIC ORIENTAL STU, P27
   Clumeck H., 1980, CHILD PHONOLOGY, P257
   DURLACH NI, 1969, J ACOUST SOC AM, V46, P372, DOI 10.1121/1.1911699
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   ELLIOTT LL, 1989, PERCEPT PSYCHOPHYS, V46, P181, DOI 10.3758/BF03204981
   Finney D. J., 1971, PROBIT ANAL
   Francis AL, 2003, PERCEPT PSYCHOPHYS, V65, P1029, DOI 10.3758/BF03194832
   Fromkin V.A., 1978, TONE LINGUISTIC SURV
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Fujisaki H., 1971, Annual Report of the Engineering Research Institute, Faculty of Engineering, University of Tokyo, V30, P59
   Gandour J, 1998, NEUROREPORT, V9, P2115, DOI 10.1097/00001756-199806220-00038
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Hua Z, 2000, J CHILD LANG, V27, P3, DOI 10.1017/S030500099900402X
   Hua Z., 2002, PHONOLOGICAL DEV SPE
   JENSEN JK, 1993, PSYCHOL SCI, V4, P104, DOI 10.1111/j.1467-9280.1993.tb00469.x
   Jiang CM, 2012, MEM COGNITION, V40, P1109, DOI 10.3758/s13421-012-0208-2
   JOHNSON K, 1994, PHONETICA, V51, P195, DOI 10.1159/000261975
   Kuhl P.K., 2009, COGNITIVE NEUROSCIEN, P837
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kuo YC, 2008, J ACOUST SOC AM, V123, P2815, DOI 10.1121/1.2896755
   LENNEBERG EH, 1967, BIOLOGICAL FDN LANGU
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   LIBERMAN AM, 1961, J EXP PSYCHOL, V61, P379, DOI 10.1037/h0049038
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Liu C, 2013, J ACOUST SOC AM, V134, P3011, DOI 10.1121/1.4820887
   MACMILLAN NA, 1988, J ACOUST SOC AM, V84, P1262, DOI 10.1121/1.396626
   MACMILLAN NA, 1977, PSYCHOL REV, V84, P452, DOI 10.1037/0033-295X.84.5.452
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J., 2000, THESIS U ARIZONA TUC
   MILLER JL, 1977, J ACOUST SOC AM, V61, P835, DOI 10.1121/1.381373
   MOULINES E, 1995, SPEECH COMMUN, V16, P175, DOI 10.1016/0167-6393(94)00054-E
   Nenonen S, 2003, COGNITIVE BRAIN RES, V16, P492, DOI 10.1016/S0926-6410(03)00055-7
   Ning C. Y., 2013, TEST LANGUAGE ABILIT
   Peng G, 2013, J CHINESE LINGUIST, V41, P447
   Peng G, 2012, J SPEECH LANG HEAR R, V55, P579, DOI 10.1044/1092-4388(2011/11-0025)
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Raven J.C., 1976, STANDARD PROGR MATRI
   Saffran J. R., 2006, HDB CHILD DEV, P58, DOI DOI 10.1002/9780470147658.CHPSY0202
   Saffran JR, 2001, J MEM LANG, V44, P493, DOI 10.1006/jmla.2000.2759
   STREETER LA, 1976, NATURE, V259, P39, DOI 10.1038/259039a0
   To CKS, 2013, J SPEECH LANG HEAR R, V56, P103, DOI 10.1044/1092-4388(2012/11-0080)
   TSE JKP, 1978, J CHILD LANG, V5, P191, DOI 10.1017/S0305000900007418
   WANG WSY, 1973, SCI AM, V228, P50, DOI 10.1038/scientificamerican0273-50
   WANG WSY, 1976, ANN NY ACAD SCI, V280, P61, DOI 10.1111/j.1749-6632.1976.tb25472.x
   Wang WSY, 1978, LINGUISTICS 70S DIRE, V8, P63
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wong P, 2013, J ACOUST SOC AM, V133, P434, DOI 10.1121/1.4768883
   Wong PS, 2012, J PHONETICS, V40, P141, DOI 10.1016/j.wocn.2011.10.005
   [席洁 XI Jie], 2009, [心理学报, Acta Psychologica Sinica], V41, P572
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yang J., 2008, J ACOUST SOC AM, V124, P2498
   Yang J., 2012, INT J ASIAN LANGUAGE, V22, P49
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
NR 68
TC 11
Z9 11
U1 4
U2 15
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD NOV
PY 2017
VL 44
IS 6
BP 1413
EP 1434
DI 10.1017/S0305000916000581
PG 22
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA FK0HC
UT WOS:000413159900006
PM 27916015
DA 2021-02-24
ER

PT J
AU Kormos, J
   Prefontaine, Y
AF Kormos, Judit
   Prefontaine, Yvonne
TI Affective factors influencing fluent performance: French learners'
   appraisals of second language speech tasks
SO LANGUAGE TEACHING RESEARCH
LA English
DT Article; Proceedings Paper
CT 2nd Annual Language Research Forum (SLRF) Conference
CY SEP, 2016
CL Columbia Univ, Teachers College, NY
HO Columbia Univ
DE Affect; fluency; language assessment; second language learning; tasks;
   speech production; speech perception
ID PERCEPTIONS; DIFFICULTY; CLASSROOM
AB The present mixed-methods study examined the role of learner appraisals of speech tasks in second language (L2) French fluency. Forty adult learners in a Canadian immersion program participated in the study that compared four sources of data: (1) objectively measured utterance fluency in participants' performances of three narrative tasks differing in their conceptualization and formulation demands, (2) a questionnaire on their interest, task-related anxiety, task motivation, and perceived success in task-completion, (3) an interview in which they elaborated on their perceptions of the tasks, and (4) subjective ratings of their performances by three native speakers. Findings showed the cognitive demands of tasks were associated with learners' affective responses to tasks as well as objective and subjective measures of fluency. Furthermore, task-related anxiety and perceived success in task completion were the most important affective factors associated with fluent task performance, whereas interest and task motivation were correlated with native speakers' fluency ratings. These results are discussed in terms of how task design and implementation can contribute to enhanced task motivation and performance in the classroom.
C1 [Kormos, Judit] Univ Lancaster, Language Acquisit 2, Lancaster, England.
   [Prefontaine, Yvonne] Oracle Corp, Redwood City, CA USA.
RP Kormos, J (corresponding author), Univ Lancaster, Dept Linguist & English Language, Lancaster LA1 4YL, England.
EM j.kormos@lancaster.ac.uk
OI Kormos, Judit/0000-0002-2643-7222
CR Boersma P., 2010, PRAAT DOING PHONETIC
   Bosker HR, 2013, LANG TEST, V30, P159, DOI 10.1177/0265532212455394
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Council of Europe, 2001, COMM EUR FRAM REF LA
   de Jong N. H., 2012, DIMENSIONS L2 PERFOR, P121
   de Jong NH, 2009, BEHAV RES METHODS, V41, P385, DOI 10.3758/BRM.41.2.385
   Dornyei Z., 2002, INDIVIDUAL DIFFERENC, V2, P137, DOI DOI 10.1075/LLLT.2
   Dornyei Z., 2000, LANG TEACH RES, V4, P275, DOI DOI 10.1177/136216880000400305
   Dornyei Zoltaan, 2015, PSYCHOL LANGUAGE LEA
   Ejzenberg R., 2000, PERSPECTIVES FLUENCY, P287
   Ericsson K.A., 1993, PROTOCOL ANAL VERBAL
   ERICSSON KA, 1980, PSYCHOL REV, V87, P215, DOI 10.1037/0033-295X.87.3.215
   Freed B. F., 2000, PERSPECTIVES FLUENCY, P243
   Freed BF, 2004, STUD SECOND LANG ACQ, V26, P275, DOI 10.1017/S0272263104062060
   Garcia O., 2009, BILINGUAL ED 21 CENT
   Gilabert R., 2007, IRAL-INT REV APPL LI, V45, P215, DOI DOI 10.1515/IRAL.2007.010
   Harackiewicz JM, 2008, J EDUC PSYCHOL, V100, P105, DOI 10.1037/0022-0663.100.1.105
   Hidi, 2015, INTEREST MATH SCI LE
   Hidi S., 1992, ROLE INTEREST LEARNI, P433
   Hidi S, 2006, EDUC PSYCHOL-US, V41, P111, DOI 10.1207/s15326985ep4102_4
   HORWITZ EK, 1986, MOD LANG J, V70, P125, DOI 10.2307/327317
   Jackson DO, 2013, LANG LEARN, V63, P330, DOI 10.1111/lang.12008
   JULKUNEN K, 1989, SITUATION TASK SPECI
   Kormos J, 2000, LANG LEARN, V50, P343, DOI 10.1111/0023-8333.00120
   Kormos J., 2011, 2 LANGUAGE TASK COMP, P39
   Kormos J., 2004, SYSTEM, V32, P145, DOI DOI 10.1016/J.SYSTEM.2004.01.001
   Kormos J., 2004, Z INTERKULTURELLEN F, V9, P1
   Kormos J, 2012, LANG LEARN, V62, P439, DOI 10.1111/j.1467-9922.2012.00695.x
   Lambert C, 2017, LANG TEACH RES, V21, P665, DOI 10.1177/1362168816683559
   Lantz B, 2013, J MOD APPL STAT METH, V12, P105
   LENNON P, 1990, LANG LEARN, V40, P387, DOI 10.1111/j.1467-1770.1990.tb00669.x
   Lennon P., 2000, PERSPECTIVES FLUENCY, P25
   Levelt WJ, 1989, SPEAKING INTENTION A
   MACINTYRE PD, 1994, LANG LEARN, V44, P283, DOI 10.1111/j.1467-1770.1994.tb01103.x
   Maehr M. L., 2002, ADV MOTIVATION ACHIE, V12, P77
   Poupore G, 2014, CAN J APPL LINGUIST, V17, P69
   Poupore G, 2013, CAN MOD LANG REV, V69, P91, DOI 10.3138/cmlr.1139
   Prefontaine Y, 2016, IRAL-INT REV APPL LI, V54, P151, DOI 10.1515/iral-2016-9995
   Prefontaine Y, 2016, LANG TEST, V33, P53, DOI 10.1177/0265532215579530
   Prefontaine Y, 2015, MOD LANG J, V99, P96, DOI 10.1111/modl.12186
   RIGGENBACH H, 1991, DISCOURSE PROCESS, V14, P423, DOI 10.1080/01638539109544795
   Robinson P, 2001, APPL LINGUIST, V22, P27, DOI 10.1093/applin/22.1.27
   Robinson P., 2007, IRAL-INT REV APPL LI, V45, P161, DOI DOI 10.1515/IRAL.2007.007
   Rubin H.J., 2005, QUALITATIVE INTERVIE
   Segalowitz Norman, 2010, COGNITIVE BASES 2 LA
   Spielberger C. D., 1983, MANUAL STATE TRAIT A
   Towell R, 1996, APPL LINGUIST, V17, P84, DOI 10.1093/applin/17.1.84
   Vygotsky L., 1962, THOUGHT LANGUAGE
NR 48
TC 11
Z9 11
U1 3
U2 22
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1362-1688
EI 1477-0954
J9 LANG TEACH RES
JI Lang. Teach Res.
PD NOV
PY 2017
VL 21
IS 6
SI SI
BP 699
EP 716
DI 10.1177/1362168816683562
PG 18
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA FK7EQ
UT WOS:000413668100004
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Billings, CJ
   Grush, LD
   Maamor, N
AF Billings, Curtis J.
   Grush, Leslie D.
   Maamor, Nashrah
TI Acoustic change complex in background noise: phoneme level and timing
   effects
SO PHYSIOLOGICAL REPORTS
LA English
DT Article
DE Acoustic change complex; cortical auditory; evoked potentials; neural
   refractory period; signal-to-noise ratio; speech stimuli
ID EVENT-RELATED POTENTIALS; SPEECH; REFRACTORINESS; RECOVERY; STIMULI
AB The effects of background noise on speech-evoked cortical auditory evoked potentials (CAEPs) can provide insight into the physiology of the auditory system. The purpose of this study was to determine background noise effects on neural coding of different phonemes within a syllable. CAEPs were recorded from 15 young normal-hearing adults in response to speech signals /s/, /a/, and /sa/. Signals were presented at varying signal-to-noise ratios (SNRs). The effects of SNR and context (in isolation or within syllable) were analyzed for both phonemes. For all three stimuli, latencies generally decreased and amplitudes generally increased as SNR improved, and context effects were not present; however, the amplitude of the /a/response was the exception, showing no SNR effect and a significant context effect. Differential coding of /s/and /a/likely result from level and timing differences. Neural refractoriness may result in the lack of a robust SNR effect on amplitude in the syllable context. The stable amplitude across SNRs in response to the vowel in /sa/suggests the combined effects of (1) acoustic characteristics of the syllable and noise at poor SNRs and (2) refractory effects resulting from phoneme timing at good SNRs. Results provide insights into the coding of multiple-onset speech syllables in varying levels of background noise and, together with behavioral measures, may help to improve our understanding of speech-perception-in-noise difficulties.
C1 [Billings, Curtis J.; Grush, Leslie D.; Maamor, Nashrah] Vet Affairs Portland Hlth Care Syst, Natl Ctr Rehabilitat Auditory Res, 3710 SW US Vet Hosp Rd,P5-NCRAR, Portland, OR 97239 USA.
   [Billings, Curtis J.] Oregon Hlth & Sci Univ, Dept Otolaryngol, Portland, OR 97201 USA.
   [Maamor, Nashrah] Natl Univ Malaysia, Fac Hlth Sci, Sch Rehabil Sci, Audiol Program, Kuala Lumpur, Malaysia.
RP Billings, CJ (corresponding author), Vet Affairs Portland Hlth Care Syst, Natl Ctr Rehabilitat Auditory Res, 3710 SW US Vet Hosp Rd,P5-NCRAR, Portland, OR 97239 USA.
EM Curtis.Billings2@va.gov
FU United States (U.S.) National Institutes of HealthUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [NIDCD-DC10914, DC15240]; U.S. Department of Veterans AffairsUS
   Department of Veterans Affairs [RRD-C8006W]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC015240, R01DC015240, R03DC010914, R01DC015240, R03DC010914,
   R03DC010914, R01DC015240, R01DC015240] Funding Source: NIH RePORTER;
   Veterans AffairsUS Department of Veterans Affairs [IK2RX000714,
   IK2RX000714, IK2RX000714, IK2RX000714] Funding Source: NIH RePORTER
FX This work was supported by the United States (U.S.) National Institutes
   of Health (NIDCD-DC10914 & DC15240) and by the U.S. Department of
   Veterans Affairs (RR&D-C8006W).
CR Berry MJ, 1998, J NEUROSCI, V18, P2200
   Billings CJ, 2015, EAR HEARING, V36, P710, DOI 10.1097/AUD.0000000000000191
   Billings CJ, 2011, EAR HEARING, V32, P53, DOI 10.1097/AUD.0b013e3181ec5c46
   Budd TW, 1998, INT J PSYCHOPHYSIOL, V31, P51, DOI 10.1016/S0167-8760(98)00040-3
   DAVIS H, 1966, ELECTROEN CLIN NEURO, V21, P105, DOI 10.1016/0013-4694(66)90118-0
   Ganapathy M. K., 2016, INT J HLTH SCI RES, V6, P356
   Gilley PM, 2005, CLIN NEUROPHYSIOL, V116, P648, DOI 10.1016/j.clinph.2004.09.009
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   HAWKINS JE, 1950, J ACOUST SOC AM, V22, P6, DOI 10.1121/1.1906581
   Martin BA, 1999, EAR HEARING, V20, P33, DOI 10.1097/00003446-199902000-00004
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Ostroff JM, 1998, EAR HEARING, V19, P290, DOI 10.1097/00003446-199808000-00004
   PAPANICOLAOU AC, 1984, NEUROBIOL AGING, V5, P291, DOI 10.1016/0197-4580(84)90005-8
   ROTH WT, 1976, ELECTROEN CLIN NEURO, V40, P623, DOI 10.1016/0013-4694(76)90137-1
   Tremblay Kelly L, 2004, J Am Acad Audiol, V15, P226
   Tremblay KL, 2006, EAR HEARING, V27, P93, DOI 10.1097/01.aud.0000202288.21315.bd
   Umbricht D, 2004, BRAIN RES, V1019, P189, DOI 10.1016/j.brainres.2004.05.097
NR 18
TC 4
Z9 4
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2051-817X
J9 PHYSIOL REP
JI PHYSIOL. REP.
PD NOV
PY 2017
VL 5
IS 20
AR e13464
DI 10.14814/phy2.13464
PG 8
WC Physiology
SC Physiology
GA FL1HL
UT WOS:000413965200006
PM 29051305
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cummings, A
   Madden, J
   Hefta, K
AF Cummings, Alycia
   Madden, John
   Hefta, Kathryn
TI Converging evidence for [coronal] underspecification in English-speaking
   adults
SO JOURNAL OF NEUROLINGUISTICS
LA English
DT Article
DE ERP; EEG; MMN; Phonological representations; Underspecification; LIMO;
   Single-subject
ID EVENT-RELATED POTENTIALS; MISMATCH NEGATIVITY; PHONOLOGICAL VARIATION;
   SPEECH-PERCEPTION; REPRESENTATION; MECHANISMS; MEMORY; WORDS;
   ASSIMILATION; MATURATION
AB The goal of this study was to test the predictions of the Featurally Underspecified Lexicon (FUL) theory by examining event-related potential (ERP) indices of phonological representation. Two English consonants differing in place of articulation were selected: [labial]/b/and [coronal]/d/. It was assumed that the phonological representation of/d/contained less distinctive feature information due to its [coronal] place of articulation, as compared to/b/. English-speaking adults were presented with two syllables,/ba/anclida/, in an ERP oddball paradigm where both syllables served as the standard and deviant stimulus in opposite stimulus sets. Three types of analyses were conducted: traditional mean amplitude measurements, cluster-based permutation tests, and single-trial general linear model (GLM) analyses of group-level and single-subject data. The less specified/do/deviant elicited a large MMN while no MMN was elicited by the more specified deviant/ba/. Additionally, the/de/standard syllable elicited larger responses than did the/be/standard, while deviant syllables did not differ. This implies that the MMN was driven by responses elicited by the standards rather than the deviants. At the single-subject level, not all participants demonstrated significant MMN responses, though all had measurable differences between the standard syllables. Thus, to continue to propose that [coronal] underspecification is a language universal phenomenon, ERP indices other than the MMN should be examined. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Cummings, Alycia; Madden, John; Hefta, Kathryn] Univ North Dakota, Grand Forks, ND 58201 USA.
   [Cummings, Alycia] Idaho State Univ, Pocatello, ID 83209 USA.
RP Cummings, A (corresponding author), 290 Centennial Dr,Stop 8040, Grand Forks, ND 58202 USA.
EM alycia.cummings@und.edu
RI Cummings, Alycia/X-9842-2019
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R15DC013359]; National Center for
   Research ResourcesUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Center for
   Research Resources (NCRR) [C06RR022088]; NATIONAL CENTER FOR RESEARCH
   RESOURCESUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Center for Research
   Resources (NCRR) [C06RR022088, C06RR022088] Funding Source: NIH
   RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R15DC013359] Funding Source: NIH
   RePORTER
FX This research was supported by NIH grant numbers R15DC013359 (from the
   National Institute On Deafness And Other Communication Disorders) and
   C06RR022088 (from the National Center for Research Resources) awarded to
   the first author. The content is solely the responsibility of the
   authors and does not necessarily represent the official views of the
   National Institutes of Health. We would like to thank Janet Babchishin,
   Brianna Jallo, Megan Nauman, Meghan Macaulay, Courtney Rowan, and Sheila
   Cassidy for help with the testing of the participants. The authors do
   not have any financial or non -financial relationships relevant to the
   content of this manuscript.
CR Bieniek MM, 2012, J VISION, V12, DOI 10.1167/12.13.12
   Bishop DVM, 2010, PSYCHOPHYSIOLOGY, V47, P697, DOI 10.1111/j.1469-8986.2009.00970.x
   Brandmeyer A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068261
   Bullmore ET, 1999, IEEE T MED IMAGING, V18, P32, DOI 10.1109/42.750253
   Bybee J., 2010, LANGUAGE USAGE COGNI
   Bybee Joan, 2002, LANG VAR CHANGE, V14, P261, DOI DOI 10.1017/S0954394502143018
   Bybee Joan, 2001, PHONOLOGY LANGUAGE U
   Ceponiene R, 2002, INT J PSYCHOPHYSIOL, V43, P199, DOI 10.1016/S0167-8760(01)00172-6
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Cornell SA, 2013, J EXP PSYCHOL HUMAN, V39, P757, DOI 10.1037/a0030862
   Cornell SA, 2011, BRAIN RES, V1394, P79, DOI 10.1016/j.brainres.2011.04.001
   CSEPE V, 1995, EAR HEARING, V16, P91, DOI 10.1097/00003446-199502000-00007
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dien J, 2004, PSYCHOPHYSIOLOGY, V41, P665, DOI 10.1111/j.1469-8986.2004.00193.x
   Diesch E, 1997, EXP BRAIN RES, V116, P139, DOI 10.1007/PL00005734
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Friedrich Claudia K, 2006, Behav Brain Funct, V2, P36, DOI 10.1186/1744-9081-2-36
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gaskell MG, 1998, J EXP PSYCHOL HUMAN, V24, P380, DOI 10.1037/0096-1523.24.2.380
   Gimson Alfred C., 1989, INTRO PRONUNCIATION
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Horvath J, 2008, BIOL PSYCHOL, V79, P139, DOI 10.1016/j.biopsycho.2008.04.001
   Jakobson R., 1952, 13 AC LAB
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Jung TP, 2000, CLIN NEUROPHYSIOL, V111, P1745, DOI 10.1016/S1388-2457(00)00386-2
   Kabak B, 2007, LINGUA, V117, P1378, DOI 10.1016/j.lingua.2006.04.010
   Kiparsky Paul, 1985, PHONOLOGY YB, V2, P85, DOI DOI 10.1017/S0952675700000397
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426
   Ladefoged P, 2007, LANGUAGE, V83, P161, DOI 10.1353/lan.2007.0026
   Lahiri A, 2002, PHONOL PHONET, V4-1, P637
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lahiri A., 2007, 16 INT C PHON SCI SA
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Luck S., 2012, ERPLAB TOOLBOX VERSI
   Luck S. J., 2005, INTRO EVENT RELATED
   Maddieson I., 1984, PATTERNS SOUNDS
   Manly B. F. J., 2006, RANDOMIZATION BOOTST
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Michal T., 2002, MEASUREMENT SCI REV, V2, P1, DOI DOI 10.1021/PR070350L
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1992, NEUROREPORT, V3, P493
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   NAATANEN R, 1995, EAR HEARING, V16, P6
   NAATANEN R, 1989, NEUROSCI LETT, V107, P347, DOI 10.1016/0304-3940(89)90844-6
   Paradis C., 1991, SPECIAL STATUS CORON
   Pernalete C, 2011, CIENC ING, P1, DOI 10.1155/2011/831409
   Pettigrew CM, 2004, EAR HEARING, V25, P284, DOI 10.1097/01.AUD.0000130800.88987.03
   Picton TW, 2000, AUDIOL NEURO-OTOL, V5, P111, DOI 10.1159/000013875
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   PISONI DB, 1993, SPEECH COMMUN, V13, P109, DOI 10.1016/0167-6393(93)90063-Q
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Rinne T, 2006, BRAIN RES, V1077, P135, DOI 10.1016/j.brainres.2006.01.043
   ROUSSELET GA, 2011, FRONT PSYCHOL, V2
   Rousselet GA, 2016, EUR J NEUROSCI, V44, P2647, DOI 10.1111/ejn.13400
   Salvia E, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00422
   Scharinger M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040953
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Scharinger M, 2011, BRAIN LANG, V116, P71, DOI 10.1016/j.bandl.2010.11.002
   Shafer VL, 2000, EAR HEARING, V21, P242, DOI 10.1097/00003446-200006000-00008
   Snoeren ND, 2009, J EXP PSYCHOL LEARN, V35, P542, DOI 10.1037/a0014509
   Stemberger J.P., 1991, SPECIAL STATUS CORON, P181, DOI [10.1016/B978-0-12-544966-3.50015-4, DOI 10.1016/B978-0-12-544966-3.50015-4]
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
   Walter M. A., 2004, 9 14 BIENN C BOST MA
   Wheeldon L, 2004, BRAIN LANG, V90, P401, DOI 10.1016/S0093-934X(03)00451-6
   Wilcox R.R., 2005, INTRO ROBUST ESTIMAT, V2nd ed.
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Woodman GF, 2010, ATTEN PERCEPT PSYCHO, V72, P2031, DOI 10.3758/APP.72.8.2031
   YIP M, 1991, SPECIAL STATUS CORON, P61
   Zimmerer F, 2009, J ACOUST SOC AM, V125, P2307, DOI 10.1121/1.3021438
NR 76
TC 2
Z9 2
U1 1
U2 12
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0911-6044
J9 J NEUROLINGUIST
JI J. Neurolinguist.
PD NOV
PY 2017
VL 44
BP 147
EP 162
DI 10.1016/j.jneuroling.2017.05.003
PG 16
WC Linguistics; Neurosciences; Psychology, Experimental
SC Linguistics; Neurosciences & Neurology; Psychology
GA FH8BZ
UT WOS:000411418100010
PM 29085183
OA Green Accepted
DA 2021-02-24
ER

EF